<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Thinking Fast and Slow in Large Language Models: a Review of the Decision-Making Capabilities of Generative AI Agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Brady</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin 9</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Nulty</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computing and Mathematical Science</orgName>
								<orgName type="institution">University of London</orgName>
								<address>
									<settlement>Birbeck, London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<addrLine>Dublin 9</addrLine>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Insight SFI Research Centre for Data Analytics</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin 9</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><forename type="middle">E</forename><surname>Ward</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<addrLine>Dublin 9</addrLine>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Insight SFI Research Centre for Data Analytics</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin 9</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">P</forename><surname>Mcgovern</surname></persName>
							<email>david.p.mcgovern@dcu.ie</email>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin 9</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<addrLine>Glasnevin Campus, Dublin 9</addrLine>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">National Academy of Sciences of the United States of America</orgName>
								<address>
									<addrLine>120(44), 1-5</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Thinking Fast and Slow in Large Language Models: a Review of the Decision-Making Capabilities of Generative AI Agents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1007/s11023-023-09646-w</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Large language models (LLMs) are increasingly being used in a wide range of everyday decision-making scenarios, transforming the way people make choices and interact with technology. However, despite their seemingly &apos;superhuman&apos; capabilities, LLMs are not infallible and can exhibit pitfalls in their decision-making abilities if not deployed with caution. This review aims to analyse the decision-making capabilities of LLMs by comparing their abilities to humans through the lens of dual process theory. Guided by this framework, it is clear that LLMs can mimic both human-like System 1 thinking-exhibiting cognitive biases and relying on heuristics to support decision-making processes-and slower System 2 thinking through prompting methods like chain-of-thought reasoning. As LLMs have advanced, they have become more adept at comprehending tasks; however, they can still exhibit biases and make errors, some of which appear similar to human cognitive biases. What remains unclear, however, is the extent to which the processes in AI systems that lead to decision-making biases are truly analogous to those in human cognition, or if they are primarily a byproduct of the human-produced data and algorithms used to train the models. Moreover, LLMs can exhibit their own unique, nonhuman biases, such as hallucinations and overconfidence, that currently limit their application to real-world decision-making applications. Nonetheless, these models hold significant potential to revolutionise the way we make decisions across a diverse range of sectors. Thus, we conclude the review by offering recommendations for future research and practical suggestions on how to leverage LLMs to augment human decision-making.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>In February of 2024, Air Canada was obliged to issue a refund to a passenger in a departure from their usual policy due to their AI chatbot <ref type="bibr" target="#b44">(Garcia, 2024)</ref>. Their chatbot incorrectly told the passenger that the airline provided partial retroactive refunds for flights booked due to bereavement, a service not covered by Air Canada's policy. This led to the airline being taken to court and paying the passenger $812.02 in damages and court fees due to a mistake of their chatbot. Such instances of chatbots providing inaccurate information are not isolated occurrences; these errors represent a significant risk associated with offloading decision-making responsibilities onto large language models (LLMs). If left unchecked by human oversight, these inaccuracies have the potential to propagate misinformation and to lead to harmful outcomes <ref type="bibr">(Au Yeung et al., 2023;</ref><ref type="bibr">Azaria et al., 2023;</ref><ref type="bibr" target="#b70">Kim et al., 2023;</ref><ref type="bibr" target="#b86">Meyrowitsch et al., 2023)</ref>. If used correctly, however, LLMs have the potential to augment human decision-making to enhance efficiency, productivity, and innovation.</p><p>As LLMs gain popularity and wider use, their applications and capabilities continue to expand. These AI systems use deep learning techniques and are trained on vast datasets to predict and generate human-like text based on given prompts <ref type="bibr" target="#b108">(Sartori &amp; Orrù, 2023)</ref>. With each new iteration, LLMs often demonstrate enhanced performance across a wide range of tasks, including more advanced language comprehension, improved knowledge retrieval, and greater generation capabilities. The GPT (Generative Pre-trained Transformer) series of LLMs are at the forefront of this revolution, with claims that these models possess the capability to surpass humans at certain tasks <ref type="bibr" target="#b33">(Dillion et al., 2023;</ref><ref type="bibr" target="#b63">Kaddour et al., 2023)</ref>. As a result, their practical applications have become increasingly widespread across a variety of sectors, with LLMs now being used in businesses, research, software development, and medicine to automate routine tasks and assist in making decisions <ref type="bibr">(Griewing et al., 2024;</ref><ref type="bibr" target="#b59">Jimenez et al., 2024;</ref><ref type="bibr" target="#b62">Jusman et al., 2023;</ref><ref type="bibr" target="#b73">Lee et al., 2023)</ref>. For example, LLMs have the potential to assist in making high-impact strategic decisions by gathering market information, offering advice, and analysing alternative perspectives or scenarios in an effort to increase the quality of a decision to benefit a company <ref type="bibr" target="#b2">(Basir et al., 2023;</ref><ref type="bibr" target="#b46">Gloria et al., 2024;</ref><ref type="bibr" target="#b62">Jusman et al., 2023)</ref>.</p><p>In this review we focus on the kind of generative LLMs that have seen widespread adoption, investment and publicity since the introduction of ChatGPT in 2022 <ref type="bibr" target="#b93">(OpenAI, 2022)</ref>. Following the rapid advances in performance of deep neural systems in the early 2010s, a series of different architectures have at different times been at the forefront for different tasks: Convolutional Neural Networks for image recognition, recurrent architectures such as Long-Short Memory Networks <ref type="bibr" target="#b56">(Hochreiter and Schmidhuber 1997)</ref> for sequence data with context layers, and most recently the transformer architecture <ref type="bibr" target="#b125">(Vaswani et al 2017)</ref> for encoding sequence data with weighted attention connections among all elements of the sequence. The basic transformer design itself has been used in a variety of different architectures for solving problems in natural language processing. The transformer was first introduced as part of a system which embeds an input sequence into a contextual vector representation, and then generates a sequence from this embedding to conduct a task such as question-answering, translation, or text classification. This is known as an encoder-decoder architecture: the input sequence (e.g. a question, or a sentence to be translated) is encoded into an embedding, and the embedding is decoded to produce the output (e.g. an answer to a question, or a translated sentence). Such systems have an auto-regressive language modelling component (pre-trained by predicting the next word), but must also be fine-tuned with example input-output pairs to complete specific tasks. <ref type="bibr" target="#b101">Radford et al (2019)</ref> showed that autoregressive language models alone can achieve good performance at multiple tasks without further fine tuning, and it is these generative, pretrained, "decoder-only" models that we primarily have in mind in this review. However, with the recent turn towards the use of chain-of-thought tokens , 'hidden' reasoning tokens <ref type="bibr" target="#b94">(OpenAI, 2024)</ref>, or even meaningless filler tokens used only to aid quantification <ref type="bibr">(Pfau et al 2024)</ref>, the line between these different classes of architecture is becoming blurred.</p><p>As the use and capabilities of LLMs continue to expand, research in this field has intensified to better understand their inner workings and limitations. One promising approach to better understand LLMs is through psychological testing <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b52">Hagendorff, 2023;</ref><ref type="bibr" target="#b108">Sartori &amp; Orrù, 2023)</ref>. By treating LLMs as participants in psychological experiments, researchers can gain insight into their underlying processes and behaviours, and how they differ from humans. Cognitive testing, in particular, has been a fruitful avenue of research, where the cognitive performance of LLMs has been compared to humans to investigate the similarities and differences in cognition between these models and humans <ref type="bibr">(Abbate, 2023;</ref><ref type="bibr" target="#b9">Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b105">Rich &amp; Gureckis, 2019;</ref><ref type="bibr" target="#b108">Sartori &amp; Orrù, 2023;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023;</ref><ref type="bibr" target="#b118">Suri et al., 2024)</ref>. This comparative approach not only highlights potential shortcomings of AI cognition relative to human performance but also unveils a symbiotic relationship between cognitive science and LLM research <ref type="bibr" target="#b100">(Qu et al., 2024)</ref>. For example, insights from cognitive science can guide the development of more human-like reasoning in LLMs, enhancing their problem-solving capabilities and reducing unwanted biases.</p><p>Conversely, LLMs serve as powerful tools for cognitive modelling, offering new avenues for testing hypotheses about human cognition and potentially uncovering novel perspectives on human behaviour. This bidirectional exchange promises to accelerate progress in both fields, ultimately informing where LLMs require improvement for effective deployment in realworld decision-making scenarios.</p><p>In this review, we investigate the decision-making skills of LLMs through the lens of the dual process theory of decision-making <ref type="bibr" target="#b65">(Kahneman, 2003)</ref>. We adapt insights from the field of cognitive psychology that have shed light on the limitations that can undermine human decision-making if left unchecked. By applying these insights to nonhuman LLMs, we can gain a better understanding of the strengths, limitations, and potential pitfalls of these AI systems. After introducing the intersection between decision-making and LLMs, we examine their rapid, System 1-like decision-making skills of LLMs, highlighting how they can mimic human cognitive biases and heuristics, as well as exhibit nonhuman biases such as "hallucinations". Next, we examine the slow, deliberate System 2 decision-making skills of LLMs and contemplate whether these models can attain a human-like understanding of their decision-making processes. We then discuss the importance of prompting in communicating with LLMs and how -when used appropriately -it can produce more accurate decisions in these models. Finally, we evaluate the effectiveness of LLMs as real-world decision-makers and put forth recommendations for the advancement of this rapidly evolving field, emphasising strategies to enhance the quality of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision-making and LLMs</head><p>As LLMs become integrated into daily life and are increasingly used to support human decision-making, understanding both their capabilities and limitations is of utmost importance. In trying to understand the decision-making processes of LLMs, a useful starting point is to compare their capabilities to those of human decision-making <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b53">Hagendorff et al., 2023;</ref><ref type="bibr" target="#b108">Sartori &amp; Orrù, 2023)</ref>. The field of behavioural economics has helped to identify a number of shortcomings in human decision-making (see Thaler, 2016 for a review), which can offer valuable lessons on how to identify and mitigate similar shortcomings in the performance of AI systems. Collectively, this research has helped reveal two distinct systems that underlie human decision-making: System 1 and System 2 <ref type="bibr" target="#b65">(Kahneman, 2003)</ref>. These two systems operate in fundamentally different ways, with System 1 relying on fast, instinctive and often unconscious processes that allow us to make decisions with little or no deliberation <ref type="bibr" target="#b39">(Evans, 2008;</ref><ref type="bibr" target="#b67">Kahneman &amp; Frederick, 2002)</ref>. The slower and more thought-out decisions denote System 2 thinking, which requires reflection and more effort to reach a decision <ref type="bibr" target="#b39">(Evans, 2008;</ref><ref type="bibr" target="#b65">Kahneman, 2003;</ref><ref type="bibr" target="#b67">Kahneman &amp; Frederick, 2002)</ref>.</p><p>System 1 decisions allow humans to make rapid, "quickfire" choices in our daily lives, such as deciding what food to eat or what to wear, constituting the majority of decisions we face on a regular basis <ref type="bibr" target="#b39">(Evans, 2008;</ref><ref type="bibr" target="#b67">Kahneman &amp; Frederick, 2002)</ref>. In contrast, System 2 decisions tend to be rational and deductive, such as deciding what college course to attend or whether one should accept a job offer. However, while System 2 thinking is generally associated with more deliberate and analytical decision-making that is more resistant to errors <ref type="bibr" target="#b39">(Evans, 2008;</ref><ref type="bibr" target="#b65">Kahneman, 2003)</ref>, the relationship between the two systems is more complex; for example, decisions such as a choosing whether to accept a job offer likely involve a combination of System 1 and System 2 thinking, and mistakes can occur if the rapid, intuitive judgments of System 1 are not adequately regulated by the more deliberate reasoning of System 2 <ref type="bibr" target="#b65">(Kahneman, 2003)</ref>.</p><p>The dual process theory of decision-making to some extent reflects the longstanding debate between symbolic and connectionist approaches in AI and cognitive science <ref type="bibr" target="#b4">(Bellini-Leite, 2022;</ref><ref type="bibr" target="#b47">Goel, 2022;</ref><ref type="bibr" target="#b116">Smolensky, 1987)</ref>. Connectionist systems, including the transformer-based models that are at the heart of the most successful recent LLMs, learn patterns in large amounts of data by modifying weights between relatively uniform units.</p><p>They are typically associative, fast at inference time, robust to imperfections in input, and less transparent and interpretable than symbolic systems. Although the parallel is not exact, many of these same properties are also characteristic of System 1 thinking <ref type="bibr" target="#b5">(Bellini-Leite, 2023;</ref><ref type="bibr" target="#b22">Clark, 2013)</ref>. On the other hand, symbolic AI systems use built-in knowledge and rules about reasoning and inference to arrive at their answers, with the result that the processes that give rise to their answers or behaviours are more amenable to human interpretation <ref type="bibr" target="#b47">(Goel, 2022)</ref>. This is similar to how human System 2 thinking is monitored by operator and control systems such as working memory to achieve a slower and more refined form of reasoning <ref type="bibr" target="#b4">(Bellini-Leite, 2022;</ref><ref type="bibr" target="#b90">Newell, 1980)</ref>. Although the connectionist architecture underpinning modern LLMs is not typically associated with System 2-like reasoning abilities, recent research has shown promising results through iterative prompting approaches that reflect the dual-process decision-making system of humans, producing both quick System-1-like decisions <ref type="bibr" target="#b53">(Hagendorff et al., 2023;</ref><ref type="bibr" target="#b81">Ma et al., 2023)</ref>, as well as methodical System 2 thinking when prompted to do so <ref type="bibr" target="#b53">(Hagendorff et al., 2023;</ref><ref type="bibr" target="#b130">Wei, Wang, et al., 2022)</ref>. Some evidence suggests that LLMs can outperform humans in certain tasks with this combination of a deep neural architecture and explicit prompting for reasoning. For instance, LLMs have been shown to surpass human performance in the multiarmed bandit task which tests decisionmaking under uncertainty <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023)</ref> and they are also more adept at distinguishing between relevant and irrelevant information in reasoning tasks <ref type="bibr" target="#b35">(Du, 2023)</ref>.</p><p>However, recent findings by <ref type="bibr">Zhang et al. (submitted)</ref> challenge this notion, revealing that both GPT-3.5 and GPT-4 exhibit a strong tendency toward exploitation in two-armed bandit experiments, with GPT-4 displaying even greater rigidity and less adaptability to changing rewards than GPT-3.5. This suggests that LLMs may be vulnerable to manipulation in decision-making tasks, potentially due to biases in their training or decision-making processes. Moreover, these models also make errors consistent with human heuristics stemming from System 1 thinking, as well as "hallucinating" -a phenomenon where LLMs confidently generate false or fabricated information, such as citing non-existent sources or facts -and producing other types of errors <ref type="bibr" target="#b5">(Bellini-Leite, 2023;</ref><ref type="bibr" target="#b53">Hagendorff et al., 2023)</ref>.</p><p>Consequently, the dual process theory may offer insights into the decision-making mechanisms of both humans and LLMs, while also highlighting significant differences in their adaptability and susceptibility to manipulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System 1 decision-making in LLMs</head><p>Research has indicated that LLMs are capable of exhibiting human-like fast System 1 and slow System 2 decisions. <ref type="bibr">Hagendorff and colleagues (2023)</ref> showed that, similar to humans, the pre-GPT-3.5 models of GPT can fall for the tricks employed by cognitive reflection tests and semantic illusions that are purposefully designed to elicit System 1 thinking. Cognitive reflection tests assess an individual's ability to resist intuitive but incorrect responses and engage in more analytical thinking. For example, the "bat and ball" problem <ref type="bibr" target="#b41">(Frederick, 2005)</ref> illustrates this: "A bat and a ball cost $1.10. The bat costs $1.00 more than the ball. How much does the ball cost?" The intuitive but incorrect answer is $0.10, while the correct answer, derived through careful consideration, is $0.05. Semantic illusions work similarly. One such illusion asks, "How many animals of each kind did Moses take on the Ark?" The common, incorrect System 1 response is "two", even though it was Noah, not Moses, who built the Ark <ref type="bibr" target="#b37">(Erickson &amp; Mattson, 1981)</ref>. LLMs have also been observed to respond to cognitive reflection tests and semantic illusions in a similar intuitive but incorrect manner as humans, with this tendency becoming more pronounced with increasing model complexity until the GPT-3 models (see <ref type="figure" target="#fig_0">Figure 1</ref>; <ref type="bibr" target="#b53">Hagendorff et al., 2023)</ref>.</p><p>GPT models have been shown to exhibit human-like irrational decision-making by reproducing cognitive biases and heuristics in their decisions, such as the tendency to believe a woman is more likely to be a bank teller and an active feminist, rather than just a bank teller <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b61">Jones &amp; Steinhardt, 2022;</ref><ref type="bibr" target="#b81">Ma et al., 2023;</ref><ref type="bibr" target="#b118">Suri et al., 2024)</ref>. Additionally, LLMs have been shown to be vulnerable to a variety of cognitive biases including content effects, certainty effects, reflection effects, overweighting effects, framing effects, magnitude effects, confirmation bias, and recency bias, all of which are commonly associated with human decision-making <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b61">Jones &amp; Steinhardt, 2022)</ref>. These biases in LLMs contribute to their human-like System 1 thinking, often skewing their decisions. The precise origins of these biases remain uncertain, though some studies suggest that they may arise from the unfiltered data used to train the models <ref type="bibr">(Acerbi &amp; Stubbersfield, 2023;</ref><ref type="bibr">Azaria, 2023;</ref><ref type="bibr" target="#b109">Schramowski et al., 2022)</ref>.</p><p>This raises the possibility that LLMs inadvertently learn and perpetuate the cognitive biases and prejudices present in the human-generated content used to train them.  <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. a) The legend provides a sample cognitive reflection task and semantic illusion used to elicit System 1 thinking alongside potential responses. b) The results of both humans and LLMs on cognitive reflection tasks. c) The models' responses when prompted to think in different ways (System 1-like "shortest possible answer" and the System 2-like "Let's use algebra to solve this problem").</p><p>Research investigating decision-making in LLMs has shown that not only can they recreate human cognitive biases, but they also exhibit their own unique biases, such as hallucinations and overconfidence. Hallucinations involve LLMs making up a fact or source of information, resulting in an incorrect decision being made based on their 'hallucinated' source <ref type="bibr" target="#b14">(Chakraborty et al., 2024;</ref><ref type="bibr" target="#b33">Dillion et al., 2023;</ref><ref type="bibr" target="#b117">Stella et al., 2023)</ref>. Overconfidence refers to the tendency of the models to overestimate their intuition and judgments, even when answering questions incorrectly, due to their inability to extend beyond the provided prompt or express uncertainty <ref type="bibr" target="#b10">(Borji, 2023;</ref><ref type="bibr" target="#b115">Singh et al., 2023;</ref><ref type="bibr" target="#b117">Stella et al., 2023</ref>). These nonhuman biases in LLMs may stem from the training approaches employed, such as autoregression and reinforcement learning from human feedback (RLHF). The "base models" underlying systems such as ChatGPT are trained using autoregressive methods to predict the next word in a string by building a probabilistic model over a very large set of texts from a variety of sources. While effective at producing linguistically valid responses, in the absence of validation from external sources this method often produces factually inaccurate or fictional but plausible sounding answers (i.e. hallucinations; McCoy et al., 2023). RLHF <ref type="bibr" target="#b141">(Ziegler et al., 2019</ref>) -a technique more commonly found in conversational models -uses human input to refine its conversational abilities. This can cause these models to employ a confident tone, which is preferred by human raters, even in cases where the model's responses are incorrect <ref type="bibr" target="#b13">(Casper et al., 2023;</ref><ref type="bibr">Ouyang et al., 2022)</ref>. Current LLMs also lack the capacity to instinctively reevaluate their decisions, rendering them unable to think critically about their responses or a given prompt. As a result, they are susceptible to producing false information or overconfident yet incorrect responses. However, when the models are explicitly trained to reflect on and evaluate their outputs, their tendency to produce hallucinated outputs decreases (L. <ref type="bibr" target="#b17">Chen, Wang, et al., 2023;</ref><ref type="bibr" target="#b58">Ji et al., 2023)</ref>.</p><p>Research in this area is scarce, and future studies could investigate how LLMs' hallucinations and confidence are affected by other types of reasoning, such as chain-of-thought reasoning (where LLMs are prompted to solve problems through slow, deliberate thinking akin to System 2 thinking in humans). Additionally, there is room for a review focusing solely on cognitive biases in LLMs, which would help provide a clearer perspective on which biases appear in LLMs and which ones do not.</p><p>Heuristics -another hallmark of System 1 thinking -have also been observed in LLMs. In humans, heuristics present as mental shortcuts whereby people commonly overlook certain information to make quicker decisions, such as deciding what phone to purchase based on anecdotal information rather than researching different models <ref type="bibr" target="#b45">(Gigerenzer &amp; Gaissmaier, 2011)</ref>. Research has indicated that the GPT series of models recreates commonly observed heuristics in humans including the representativeness heuristic <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref>, the availability heuristic <ref type="bibr">(Azaria, 2023;</ref><ref type="bibr" target="#b118">Suri et al., 2024)</ref>, and anchoring effects <ref type="bibr" target="#b61">(Jones &amp; Steinhardt, 2022;</ref><ref type="bibr" target="#b81">Ma et al., 2023)</ref>. Each heuristic provides people with a distinct shortcut when making decisions. The representativeness heuristic involves stereotyping a situation based on readily available information while disregarding the broader context <ref type="bibr" target="#b67">(Kahneman &amp; Frederick, 2002)</ref>. An example of this is the conjunction fallacy -a cognitive bias where people erroneously believe that the probability of two specific events occurring together is higher than the probability of a single, more general event -has been observed in the responses of LLMs such as GPT-3 <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b118">Suri et al., 2024)</ref>. The availability heuristic involves relying on similar events that easily come to mind while making decisions, leading people to believe these events are more likely than they are in reality <ref type="bibr" target="#b123">(Tversky &amp; Kahneman, 1973)</ref>. Despite LLMs' broader access to information through their training data, they remain susceptible to biases from anecdotal information <ref type="bibr" target="#b118">(Suri et al., 2024)</ref>. Anchoring effects involve how responses can be drawn by initial values, such as thinking an item of clothing is more expensive than it is because you first saw a similar item for a cheaper price <ref type="bibr">(Ariely et al., 2003;</ref><ref type="bibr" target="#b124">Tversky &amp; Kahneman, 1974</ref>). Similar to cognitive biases observed in human decision-making, LLMs' estimates of different figures such as distances or prices can be biased by prior prompts (e.g. prepending a question about the length of the Mississippi with "the length of the Mississippi is greater than 1000 miles" leads the model estimates to be shifted towards this anchor value; <ref type="bibr" target="#b61">Jones &amp; Steinhardt, 2022;</ref><ref type="bibr" target="#b81">Ma et al., 2023</ref>).</p><p>Interestingly, these heuristics observed in the decision-making processes of LLMs appear to align more closely with the intuitive System 1 heuristics of humans, rather than the rule-based heuristics typically associated with traditional AI systems (Bellini-Leite, 2023; <ref type="bibr" target="#b91">Newell &amp; Simon, 2007)</ref>. The presence of human-like heuristics and biases in LLMs was further corroborated by a recent study by <ref type="bibr">Suri and colleagues' (2024)</ref>, who developed a series of novel tests to elicit various heuristics and biases in both humans and GPT-3.5. They found that the anchoring, representativeness, and availability heuristics all appeared in GPT-3.5, providing further evidence that LLMs exhibit decision-making tendencies that align with the intuitive, System 1 heuristics characteristic of human cognition. However, despite developing novel prompts that were not present in the data used to train the LLMs, the study's findings may be somewhat constrained by the relatively small sample size of human participants and the fact that the research focused primarily on GPT-3.5, with some preliminary tests being performed on GPT-4 on anchoring effects.</p><p>In contrast to the findings of Suri et al., other studies have suggested that later versions of GPT tend to exhibit a reduced tendency to display heuristics <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b35">Du, 2023)</ref>. For example, the representativeness heuristic is observed in GPT-3 and GPT-3.5 <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b118">Suri et al., 2024)</ref> but GPT-4 can intuitively acknowledge this bias and can correct for it <ref type="bibr" target="#b35">(Du, 2023)</ref>. Similarly, more advanced LLMs, such as GPT-3.5 and GPT-4, have demonstrated improved ability to mitigate anchoring effects compared to earlier models like GPT-3 <ref type="bibr" target="#b35">(Du, 2023;</ref><ref type="bibr" target="#b61">Jones &amp; Steinhardt, 2022</ref>). This improved performance in later models may be the result of these models rectifying these "errors" in reasoning through the use of reinforcement learning and human feedback in their training <ref type="bibr" target="#b118">(Suri et al., 2024)</ref>. However, this observation fails to explain why <ref type="bibr" target="#b118">Suri et al. (2024)</ref> found evidence for the availability heuristic in ChatGPT-3.5, whereas Y.  <ref type="bibr" target="#b123">Tversky and Kahneman's (1973)</ref> bus stop task, which assesses probabilistic reasoning, whereas Suri et al. used a task involving phone model selection influenced by anecdotal information. ChatGPT-3.5's performance may vary between these tasks due to their distinct cognitive demands, potentially handling structured reasoning tasks more effectively, while being more susceptible to anecdotal biases.</p><p>Additionally, the bus stop task often includes visual aids, which were not applicable to ChatGPT-3.5's text-based format (Y. <ref type="bibr" target="#b123">Tversky &amp; Kahneman, 1973)</ref>. Importantly, frequent updates to LLMs mean that even studies using the same model version (e.g., ChatGPT-3.5) may be testing slightly different iterations, potentially contributing to divergent findings. To mitigate biases in heuristic testing, researchers should employ diverse tasks not present in the models' training data and clearly specify both the model version and testing timeframe <ref type="bibr" target="#b52">(Hagendorff, 2023;</ref><ref type="bibr" target="#b118">Suri et al., 2024)</ref>.</p><p>In computer science, a heuristic is a method used by an AI system to evaluate the current state and determine whether a branch in the tree of possible actions can be pruned in an effort to save time <ref type="bibr" target="#b91">(Newell &amp; Simon, 2007;</ref><ref type="bibr" target="#b133">Yao et al., 2023)</ref>. This evaluation heuristic might be symbolic or connectionist in implementation; the key role of a heuristic is to improve the performance of the system by reducing the cost in time or computation to select an appropriate answer or behaviour, even at the cost of some inaccuracy or bias. In the context of human cognition, heuristics are considered to be a type of System 1 thinkingthey are shortcuts in reasoning or evaluation that help people to solve problems or make decisions quickly at the cost of a higher rate of error and bias. Evidence for this alignment between AI heuristics and System 1 thinking can be seen in the tendency of pre-ChatGPT models to exhibit more pronounced System 1-like biases and errors. In contrast, the ChatGPT models, which have been specifically fine-tuned for conversing with a human agent, appear to be more resistant to these System 1-driven errors <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. Despite both types of heuristics having the goal of saving time in decision-making, their mechanisms may be different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System 2 decision-making in LLMs</head><p>While the infrastructure of LLMs inherently favours System 1 decision-making, they are still capable of exhibiting System 2 reasoning when appropriately prompted. LLMs primarily operate by predicting the next word or phrase in a sequence, which aligns with the intuitive, fast, and automatic nature of System 1 thinking <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. However, LLMs can also engage in more deliberate, analytical processes akin to System 2 thinking when appropriately prompted or when faced with tasks requiring structured reasoning <ref type="bibr" target="#b130">(Wei, Wang, et al., 2022)</ref>. This System 2-like behaviour is particularly evident in problem-solving scenarios that demand step-by-step approaches or algebraic reasoning <ref type="bibr" target="#b71">(Kojima et al., 2022)</ref>.</p><p>For instance, when prompted to "think step-by-step" or to break down complex problems, LLMs can demonstrate a more methodical, explicit reasoning process reminiscent of human System 2 thinking <ref type="bibr">(Weston &amp; Sukhbaatar, 2023)</ref>. Language models can perform better on tasks they struggle with by using these step-by-step approaches and simulating slower human System 2 thinking, such as mathematical problems and creative writing tasks (see <ref type="figure">Figure 2</ref>; <ref type="figure">Figure 2</ref>. Comparison of the solve rates for three maths word problems tests using standard prompting and System 2-like chain-of-thought prompting across three LLM families <ref type="bibr" target="#b130">(Wei, Wang, et al., 2022)</ref>.</p><p>Prompting methods, such as chain-of-thought reasoning or tree-of-thoughts thinking, can also be used to promote human-like System 2 thinking in LLMs, enabling them to systematically break down complex problems (Bellini-Leite, 2023). Chain-of-thought reasoning is a novel form of reasoning observed in AI systems which involves solving problems when specifically prompted to think slowly and deliberately or when provided with a sample solution as guidance <ref type="bibr" target="#b53">(Hagendorff et al., 2023;</ref><ref type="bibr" target="#b71">Kojima et al., 2022;</ref><ref type="bibr" target="#b130">Wei, Wang, et al., 2022)</ref>. By prompting a LLM to think about a problem slowly or use algebra to solve it, researchers can help the models to avoid the pitfalls posed by reasoning tasks such as cognitive reflection tests and syllogisms, enabling them to provide accurate responses instead of defaulting to the instinctive System 1 answer <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. Chain-of-thought reasoning becomes increasingly effective as the number of parameters in a LLM grows, indicating a greater capacity for System 2 thinking as the model's complexity increases <ref type="bibr" target="#b130">(Wei, Wang, et al., 2022)</ref>. This reasoning process may parallel how humans use notebooks when solving problems (e.g. , as LLMs can use their output window to slowly reflect on a problem and enable this refined form of reasoning, similar to short-term memory <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. Tree-of-thought prompting can simulate deliberate human System 2 thinking by prompting a language model to consider a range of possibilities <ref type="bibr" target="#b133">(Yao et al., 2023)</ref>. Unlike the linear progression facilitated by chain-of-thought prompting, tree-ofthought thinking simultaneously considers numerous potential thought-paths originating from a given input and resembles the branching structure of a tree when visually represented (e.g., if A, then B1, B2, or B3, followed by C1, C2, or C3 until a suitable output is reached).</p><p>Heuristics are then used to evaluate these thoughts and select which one is best suited for the problem at hand, similar to control processes of human cognition <ref type="bibr" target="#b91">(Newell &amp; Simon, 2007)</ref>.</p><p>This prompting style is seen to outperform chain-of-thought prompting in a myriad of tasks, such as in creative writing tasks or when completing mini crosswords <ref type="bibr" target="#b133">(Yao et al., 2023)</ref>.</p><p>However, tree-of-thought reasoning is seen as more costly in terms of effort and processing power than simpler prompting strategies, such as chain-of-thought prompting (e.g. <ref type="bibr" target="#b133">Yao et al., 2023)</ref>. The potential promise of tree-of-thought reasoning lies in its combination with reinforcement learning. DeepMind's AlphaZero system can learn to play expert-level chess and Go, given no domain knowledge other than the rules of the game. This is achieved through reinforcement learning, with the reward signal for the evaluation function ultimately deriving from the results of simulated games. Something like this approach underlies the latest best-performing model release from OpenAI, o1:</p><p>Similar to how a human may think for a long time before responding to a difficult question, o1 uses a chain of thought when attempting to solve a problem. Through reinforcement learning, o1 learns to hone its chain of thought and refine the strategies it uses. <ref type="bibr" target="#b94">(OpenAI, 2024)</ref> In the case of Go or chess, the reward signal for the evaluation heuristic ultimately derives from the outcome of the simulated games. In the context of reasoning, coding, or questionanswering tasks, the reward signal may be derived from automated tests, or human evaluation of responses -in the latter case effectively learning the function applied by human annotators in RLHF, and automatically applying it to each branch of the tree-of-thought. The parallel to dual process theory is then quite direct: the pretrained model generates a tree of possibilitiesa comparatively slow process in which reasoning tokens are used to represent a tree of possible intermediate steps in a task -and then a heuristic evaluation function prunes this tree and selects possible paths, just as proposed in the search system of <ref type="bibr">Newell and Simon (1980)</ref>. Even though LLMs are capable of System 2-like thinking, the extent to which they genuinely comprehend the judgments they make remains unclear. Since these models focus on summarising and predicting responses based on algorithms and computer heuristics, it may be that LLMs respond based on learned examples, rather than an inherent understanding of the question being asked <ref type="bibr" target="#b84">(McCoy et al., 2019;</ref><ref type="bibr" target="#b117">Stella et al., 2023;</ref><ref type="bibr" target="#b128">Webson &amp; Pavlick, 2022)</ref>. They rely on the examples of similar prompts within their training data, struggling to respond correctly to an entirely novel problem or question <ref type="bibr" target="#b128">(Webson &amp; Pavlick, 2022;</ref><ref type="bibr" target="#b138">Zheng &amp; Zhan, 2023)</ref>. The reliance of LLMs on examples is evident in their 'few-shot learning' capability, where they can reason effectively after being trained in a given scenario or when provided with an example <ref type="bibr" target="#b11">(Brown et al., 2020;</ref><ref type="bibr" target="#b28">Dasgupta et al., 2022)</ref>. LLMs leverage their ability to solve a given problem by drawing upon relevant examples in their training data or literature searches, but their reasoning capability falters when confronted with unfamiliar questions, resulting in hallucinated responses (e.g., a question about a scientific discovery that occurred after their training data cut-off; <ref type="bibr" target="#b11">Brown et al., 2020;</ref><ref type="bibr" target="#b14">Chakraborty et al., 2024;</ref><ref type="bibr" target="#b138">Zheng &amp; Zhan, 2023)</ref> or nonsense reasoning problems (e.g., a nonsense syllogism that poses the problem "if all zoet is spuff and all spuff are thrund, are all zoet thrund;" <ref type="bibr">Dasgupta et al., 2022, p. 6</ref>). Moreover, upon prompting ChatGPT with a question based on a medical discovery made after its training dataset, <ref type="bibr" target="#b138">Zheng and Zhan (2023)</ref> found that it creates responses without considering their logic or accuracy, leading to instances of misinformation and unwarranted confidence in its outputs. In contrast, humans can manipulate information in their working memory allowing them to fully explore a problem, whereas LLMs cannot expand beyond the context of their chatbox and are limited by their training data <ref type="bibr" target="#b14">(Chakraborty et al., 2024;</ref><ref type="bibr" target="#b88">Mitchell &amp; Krakauer, 2023;</ref><ref type="bibr" target="#b89">Nelson &amp; Shiffrin, 2013;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023;</ref><ref type="bibr" target="#b138">Zheng &amp; Zhan, 2023)</ref>. For example, a language model would never truly understand the sensation of being tickled as they lack physical bodies, which may result in a narrower and potentially less accurate representation of reality relative to human embodied cognition <ref type="bibr" target="#b88">(Mitchell &amp; Krakauer, 2023)</ref>. Hence, while a LLM may rival human benchmarks in certain comparisons, this does not necessarily imply that they are entirely human in their decision-making processes. Accordingly, their skills may not generalise to real-world decision-making scenarios, with the potential of being "right for the wrong reasons," and having no justification behind their decisions other than "parroting" what they were trained on <ref type="bibr" target="#b6">(Bender et al., 2021;</ref><ref type="bibr" target="#b84">McCoy et al., 2019;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023)</ref>. Furthermore, GPT-3's performance on semantic inference tasks was not affected by the type of instructions it was given (instructive vs misleading or irrelevant), while human performance is impaired when provided with misleading instructions <ref type="bibr" target="#b128">(Webson &amp; Pavlick, 2022)</ref>. In sum, it appears that LLMs likely depend on heuristics for their decision-making, raising the question of whether future AI systems will achieve genuine human-like understanding and ability to respond to questions.</p><p>Explanations in favour of LLMs' ability to understand a prompt surrounds their tendency to 'zero-shot' a problem or how they relate a prompt to their training data. Solving a problem zero-shot refers to the ability of LLMs to solve problems without any previous explicit training, either when solely presented with a question ("Is this a cat?"), or when a question is followed by a prompt such as "Let's think step by step" (zero-shot reasoning; <ref type="bibr" target="#b71">Kojima et al., 2022;</ref><ref type="bibr" target="#b127">Webb et al., 2023)</ref>. Their ability to navigate and solve unknown problems -both with and without chain-of-thought reasoning -suggests that they do understand their judgments since they can competently respond to problems without a sample solution or recognise a problem and correctly apply it to the correct part of their training data <ref type="bibr" target="#b71">(Kojima et al., 2022)</ref>. One observed phenomenon of this type is referred to as "grokking", a term coined by the novelist Robert Heinlein in 1961. <ref type="bibr" target="#b99">Power et al. (2021)</ref> show that when trained far beyond the point of overfitting, neural networks can progress from merely interpolating the training data in high-dimensional space to actually learning the algorithm underlying the data generating process on certain simple tasks. In their study, Power et al.</p><p>focused on modular arithmetic problems, observing that the system eventually developed a geometric representation of the data that enabled full generalisation. This shift from memorisation to comprehension occurred suddenly, after an extended period of seeming stagnation in performance on the test set.</p><p>Another explanation could be that LLMs use their training data similarly to how humans use their past experiences to inform present decision-making <ref type="bibr" target="#b110">(Seligman et al., 2013)</ref>, with their training data allowing them to specialise in a certain field and potentially overcome the limitations in their current training data, such as its cut-off point <ref type="bibr" target="#b62">(Jusman et al., 2023;</ref>. Fine-tuning pretrained models on more specialised text corpora also makes it possible to provide LLMs with the ability to have domain-specific expertise and increase their understanding in a given topic <ref type="bibr" target="#b51">(Gu et al., 2021)</ref>. Additionally, even if LLMs do not understand their prompt in a human sense, they may have a nonhuman form of understanding that emerges through statistical correlations <ref type="bibr" target="#b88">(Mitchell &amp; Krakauer, 2023)</ref>. The patternmatching capabilities of LLMs -which allows them to match current prompts with past prompts -could be interpreted as a form of nonhuman understanding, similar to the nonhuman cognitive biases and heuristics they inherit. To help clarify this debate on understanding, future research should investigate how the responses of LLMs are influenced by different training data and past chat history, while also being mindful of the reliance of these models on prompting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompting</head><p>The importance of the prompts given to LLMs should not be understated. Prompts are how people feed information to and ask LLMs questions, and serve as the primary means for how psychological tests are administered to these models <ref type="bibr" target="#b52">(Hagendorff, 2023)</ref>. Slight variations in prompts can lead to vastly different interpretations and responses from LLMs <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b61">Jones &amp; Steinhardt, 2022;</ref><ref type="bibr" target="#b71">Kojima et al., 2022;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023</ref>). The phrasing and information provided in a prompt can significantly influence the performance of LLMs, enabling them to achieve a deeper level of understanding and unlocking new potential, or conversely leading to inaccurate and misleading responses.</p><p>Prompting strategies, such as chain-of-thought and metacognitive prompting -a prompting strategy designed to stimulate introspective reasoning in LLMs with the goal of improving their response accuracy -can cause LLMs to reevaluate their decision and become more accurate in their responses, simulating human-like System 2 reasoning <ref type="bibr" target="#b130">Wei, Wang, et al., 2022)</ref>. Hence, it is critical for research in this area to use a range of paraphrased prompts to enable a comparison of responses and to ensure the robustness of results against content biases that might influence model performance <ref type="bibr" target="#b28">(Dasgupta et al., 2022;</ref><ref type="bibr" target="#b52">Hagendorff, 2023;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023)</ref>.</p><p>While it is important to consider prompting strategies when engaging with LLMs, there is also some evidence to suggest that GPT-4 is becoming more resistant to prompting, with instances of it ignoring requests to use chain-of-thought reasoning. For example, L. <ref type="bibr" target="#b18">Chen, Zaharia, et al. (2023)</ref> found that GPT-4's adherence to prompted instructions drifted across a period of three months, including failures in chain-of-thought reasoning, formatting compliance in code or text generation, and responding to OpinionQA items (a dataset made to identify the opinions of LLMs; <ref type="bibr" target="#b107">Santurkar et al., 2023)</ref>. This unwillingness to follow instructions resulted in a drop in accuracy in various tasks, such as solving maths problems and generating working code. This decrease in prompt-following was only observed in GPT-4, with the GPT-3.5 model becoming more accurate after three months. Upon further testing, it was observed that when GPT-4 was only given one instruction -such as to capitalise every letter in a sentence -its adherence to prompts remained consistent over time. However, when tasked with multiple instructions simultaneously -such as to capitalise every letter and add a comma after each word -GPT-4 became less accurate and more resistant to instructions over three months <ref type="bibr" target="#b18">(L. Chen, Zaharia, et al., 2023)</ref>. Chen et al. suggest that these shifts in responding could be unintended side effects caused by minor updates regularly made to each model aimed at improving their capabilities but have negative consequences to other behaviours. Hence, these issues may be resolved with a future minor update to the AI system. However, since OpenAI does not disclose the complete changelog of their updates publicly, the source of these behaviour shifts remains uncertain as it stands. More longitudinal research should be performed on LLMs to determine how their adherence to instructions changes over time, as well as investigating how cognitive load affects prompt adherence.</p><p>To date, there has been no research comparing decision-making performance in LLMs to humans when prompted in the same way. For example, prompts designed to provoke chain-of-thought reasoning have been exclusively applied to AI agents, without parallel testing in human participants <ref type="bibr" target="#b53">(Hagendorff et al., 2023;</ref><ref type="bibr" target="#b71">Kojima et al., 2022;</ref><ref type="bibr" target="#b130">Wei, Wang, et al., 2022)</ref>. Similarly, <ref type="bibr" target="#b126">Wang and Zhao's (2023)</ref> metacognitive prompting was only applied to LLMs, without the inclusion of a human sample for comparison, with the model's performance instead compared to a metacognition framework derived from previous studies in human participants. Studies surrounding prompting strategies tend to be from a computer science perspective, where the goal of these studies is based on computer behaviour, not how it relates to that of humans. When viewed through a psychological lens, these methods of prompting LLMs may be considered 'unusual' if applied to humans; for example, asking a person to solve the lily pad and the pond cognitive reflection test using algebra when the trick lies in the wording of the question <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. Moreover, the overreliance of LLMs on their prompts could pose a challenge for research in this domain, as they lack the ability to contextualise a given prompt within the broader context of the world in a similar vein to humans <ref type="bibr" target="#b112">(Shiffrin &amp; Mitchell, 2023;</ref><ref type="bibr" target="#b117">Stella et al., 2023;</ref><ref type="bibr" target="#b128">Webson &amp; Pavlick, 2022</ref>).</p><p>Thus, a recommendation for the field is that study authors should document and disclose the exact wording for the prompts and any prompt variations used in their studies, while being mindful of the phrasing used to ensure that the model responses are fully contextualised <ref type="bibr" target="#b52">(Hagendorff, 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Could LLMs replace or augment human decision-makers?</head><p>As the abilities of LLMs improve, it is important to consider how they can assist with human decision-making. LLMs surpass humans in decision-making across various domains and particularly excel in intuitive System 1 decisions <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. Through reinforcement learning and advanced algorithms, LLMs are capable of reaching "superhuman" levels of proficiency, allowing them to outperform human System 2 thinking in activities such as chess <ref type="bibr" target="#b88">(Mitchell &amp; Krakauer, 2023;</ref><ref type="bibr" target="#b113">Silver et al., 2017)</ref>. As a result of their superior capabilities, LLMs are often viewed as ideal candidates to aid in decision-making scenarios; however, the promise of these models in assisting with decision-making should be tempered by the concerns raised in the previous sections of the review and it is crucial to approach their use with caution. Nonetheless, LLMs have achieved some notable successes in a range of real-world decision-making applications, such as in the medical domain. Although not specifically trained for medical purposes, LLMs hold significant potential to enhance medical decision-making due to their training based on openly available medical databases <ref type="bibr" target="#b73">(Lee et al., 2023;</ref><ref type="bibr" target="#b120">Thirunavukarasu et al., 2023)</ref>. As such, GPT-4 has demonstrated impressive performance on sample questions from the United States Medical Licensing Examination and has shown promising results in medical question-answering tasks <ref type="bibr" target="#b92">(Nori et al., 2023)</ref>. In business, LLMs can help summarise information, generate reports, and come up with plans based on real-time data to help people make informed decisions regarding management, finance, and other corporate domains <ref type="bibr" target="#b20">(Chuma &amp; de Oliveira, 2023;</ref><ref type="bibr" target="#b62">Jusman et al., 2023)</ref>.</p><p>LLMs can also be used as a research tool, aiding in tasks such as literature reviews and hypothesis generation <ref type="bibr">(Aydın &amp; Karaarslan, 2022;</ref><ref type="bibr" target="#b29">Demszky et al., 2023;</ref><ref type="bibr" target="#b69">Ke et al., 2024)</ref>.</p><p>These applications point to the significant promise that LLMs hold, with their potential to improve decision-making practices across a variety of fields if used correctly.</p><p>Despite LLMs' apparent competency in making decisions, the flaws of these models should be reiterated. Information provided by AI chatbots may be susceptible to inaccuracies and raises concerns of potential plagiarism from existing sources, further complicating the reliability and authenticity of the content <ref type="bibr">(Aydın &amp; Karaarslan, 2022;</ref><ref type="bibr" target="#b86">Meyrowitsch et al., 2023)</ref>. Moreover, while LLMs show promise in augmenting human decision-making, the capabilities of these models do not equate to that of an expert in that field. For example, <ref type="bibr" target="#b20">Chuma and de Oliveira (2023)</ref> identified that the input provided by ChatGPT on business decisions was not close to an expert level, providing simple and "generic" overviews and explanations for the situations it was presented with. Even if they can outperform medical benchmarks, these skills may not translate into real-world medical scenarios and LLMs are still prone to errors and biases, including gender and racial prejudices <ref type="bibr">Au Yeung et al., 2023;</ref><ref type="bibr" target="#b10">Borji, 2023;</ref><ref type="bibr" target="#b75">Liang et al., 2021;</ref><ref type="bibr" target="#b92">Nori et al., 2023)</ref>. The adoption of LLMs and other AI technologies also presents the risk of degrading job quality and raising unemployment rates, as they can automate jobs previously carried out by human workers <ref type="bibr" target="#b36">(Eloundou et al., 2023;</ref><ref type="bibr" target="#b131">Weidinger et al., 2021)</ref>. Thus, at present, attempts to integrate LLMs into the workplace should focus on how they can be utilised to work in tandem with people to arrive at conclusions as opposed to replacing humans in decision-making tasks <ref type="bibr" target="#b62">(Jusman et al., 2023;</ref><ref type="bibr" target="#b92">Nori et al., 2023)</ref>. Humans can consider a multitude of different factors in making decisions, such as their long-term consequences <ref type="bibr" target="#b62">(Jusman et al., 2023;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023)</ref> while LLMs are over-reliant on their prompted context and cannot expand beyond their training data <ref type="bibr" target="#b62">(Jusman et al., 2023;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023;</ref><ref type="bibr" target="#b131">Weidinger et al., 2021;</ref><ref type="bibr" target="#b138">Zheng &amp; Zhan, 2023)</ref>. Instead of replacing humans, language models can help inform human decision-making as a support system, being supervised by experts to provide information and suggestions to help people reach conclusions <ref type="bibr">(Au Yeung et al., 2023;</ref><ref type="bibr">Azaria et al., 2023;</ref><ref type="bibr" target="#b16">J. Chen, Liu, et al., 2023;</ref>. This thought process also aligns with OpenAI's recommended uses of ChatGPT, being used as a chatbot to assist with a range of tasks such as making informed decisions through conversation <ref type="bibr" target="#b93">(OpenAI, 2022)</ref>. This leads to the conclusion that ChatGPT and other chatbots should aid in human decision-making under expert supervision or rigorous fact-checking, rather than autonomously making decisions on behalf of humans <ref type="bibr">(Azaria et al., 2023;</ref><ref type="bibr" target="#b62">Jusman et al., 2023;</ref><ref type="bibr" target="#b92">Nori et al., 2023)</ref>. However, the limitations of these models still need to be accounted for when using them as decision-making assistants. Risks such as misinformation, hallucinations, and data security all pose problems while using LLMs, even with supervision <ref type="bibr" target="#b131">(Weidinger et al., 2021)</ref>. To mitigate these risks, it will be important to develop effective strategies to highlight the potential pitfalls of LLMs, along with measures to detect misinformation and prevent overreliance on these models <ref type="bibr" target="#b55">(Heersmink, 2024;</ref><ref type="bibr" target="#b62">Jusman et al., 2023;</ref><ref type="bibr" target="#b92">Nori et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The ever-changing nature of LLMs</head><p>With each update, LLMs naturally evolve to become more accurate and intelligent, even developing new cognitive processes that were not present in earlier iterations <ref type="bibr" target="#b53">(Hagendorff et al., 2023;</ref><ref type="bibr" target="#b72">Kosinski, 2023;</ref><ref type="bibr" target="#b127">Webb et al., 2023;</ref><ref type="bibr" target="#b129">Wei, Tay, et al., 2022)</ref>. In <ref type="bibr" target="#b53">Hagendorff et al.'s (2023)</ref> investigation of the System 1 and 2 decision-making abilities across various iterations of GPT, the models demonstrated significant improvements in their System 1 decision-making accuracy with each successive release of GPT. Notably, in this study ChatGPT-3.5 and ChatGPT-4 were able to intuitively engage in chain-of-thought reasoning and answer correctly without being prompted to do so, something which older models such as GPT-3 were not able to do. Furthermore, when explicitly asked to answer as quickly as possible, ChatGPT-3.5 and ChatGPT-4 maintained higher accuracy compared to their predecessors, suggesting a more developed intuition <ref type="bibr" target="#b53">(Hagendorff et al., 2023)</ref>. While these findings are compelling for the GPT family of models, it is important to consider the generalisability of these results to other LLMs and contexts. For example, there have also been reports of GPT-4 being more rigid, conservative in its decision-making relative to GPT-art LLM tending to outperform the benchmarks set by previous models. For instance, the newer Claude 3 Opus model reportedly surpasses GPT-4's abilities across all tested domains, such as general reasoning, maths skills, and common knowledge <ref type="bibr">(Anthropic, 2024)</ref>. It is also noteworthy how differences in responses have been observed within the same model version of GPT to the same prompts at different times due to the minor updates made to each model (see <ref type="figure" target="#fig_2">Figure 3</ref>; L. <ref type="bibr" target="#b18">Chen, Zaharia, et al., 2023)</ref>. Thus, it is important to assess the various iterations of LLMs not only against human performance but also against their own cognitive abilities -both in the present and over time -as well as against other families of LLMs such as comparing Claude and GPT models (for examples of these comparisons, see L. <ref type="bibr" target="#b18">Chen, Zaharia, et al. [2023]</ref>, <ref type="bibr" target="#b28">Dasgupta et al. [2022]</ref>, and <ref type="bibr" target="#b53">Hagendorff et al. [2023]</ref>). Moreover, it is necessary for research in this field to include the timeframe within which assessments were conducted on LLMs within their methodologies in acknowledgement of the constant refinements and adjustments made to these models over time.  <ref type="bibr" target="#b18">Chen, Zaharia, et al., 2023)</ref>.</p><p>Integrating agent-based approaches with LLMs presents a promising pathway to enhance decision-making capabilities in AI systems. Agent-based systems, which are designed to autonomously perceive, reason, and act within an environment, can provide a structured framework for guiding LLMs through more complex decision-making processes.</p><p>This approach helps overcome LLMs' limitations in making goal-oriented, context-sensitive decisions <ref type="bibr" target="#b80">(Luo et al., 2023)</ref>. By embedding LLMs within agent architectures, models can be augmented with features such as continuous learning, situational awareness, and adaptability.</p><p>These agents can simulate different environments, test out scenarios, and interact with other agents or systems, allowing for better-informed, contextually-grounded decisions <ref type="bibr" target="#b136">(Zhang et al., 2022)</ref>. For example, in clinical settings or real-time customer service applications, agentbased approaches can continuously monitor evolving data, adjust the LLM's decision-making strategies, and refine its output to meet specific, time-sensitive goals.This synergy enhances the practicality of LLMs in real-world decision-making tasks by ensuring that the model's responses align with broader, agent-driven objectives and constraints. Recent research has demonstrated the potential of this integration in various domains, including robotics, financial forecasting, and personalised education <ref type="bibr" target="#b15">(Chen et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future research</head><p>Since 2022, LLMs have been investigated as a participant in psychological tests to uncover their cognitive capabilities <ref type="bibr" target="#b52">(Hagendorff, 2023)</ref>. As new models are released and older models are updated, their abilities have steadily improved with each iteration. They have shown promising skills in a variety of cognitive domains, being able to match or outperform humans in some areas <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b108">Sartori &amp; Orrù, 2023)</ref>. Despite the progress made in understanding the decision-making capabilities of these models, this research is in its early stages, with many arguing that the internal processes of LLMs are akin to a "black box" from a cognitive perspective <ref type="bibr" target="#b69">(Ke et al., 2024)</ref>. Much remains unknown about the decision-making skills of LLMs and current research in the field can provide methodological recommendations for future work.</p><p>One such recommendation is that researchers conducting studies on LLMs should incorporate a wide range of prompt variations and psychological tests in order to provide a comprehensive understanding of these models. Previous studies have indicated that slight alterations in prompt wording can produce markedly different responses due to a specific prompt or test being present in the model's training data, or biases caused by the wording of prompts <ref type="bibr" target="#b9">(Binz &amp; Schulz, 2023;</ref><ref type="bibr" target="#b52">Hagendorff, 2023;</ref><ref type="bibr" target="#b78">Loya et al., 2023;</ref><ref type="bibr" target="#b112">Shiffrin &amp; Mitchell, 2023)</ref>. Using diverse prompts can help account for this sensitivity to prompt phrasing and enable research to become more robust and resistant to these confounding variables on a variety of tests. Furthermore, incorporating diverse testing scenarios allows readers to identify specific contexts where behaviours are exhibited or absent (e.g. the availability heuristic; Y. <ref type="bibr" target="#b118">Suri et al., 2024)</ref>. However, when creating prompt variations for research, it is important to validate them first, ensuring that they accurately target the desired variable <ref type="bibr" target="#b52">(Hagendorff, 2023)</ref>. Additionally, the exact wording of the prompts used in studies should be provided by the authors to make readers aware of any potential flaws in prompt design and help with future replications.</p><p>One limitation of current research investigating the decision-making abilities of LLMs is that comparisons between these models and human participants are at a surface level.</p><p>Studies that investigate the performance of language models on benchmarks tend not to compare their results with humans, and when they do, they tend to be underpowered with small sample sizes and forgo reporting statistics such as standard deviations <ref type="bibr" target="#b108">(Sartori &amp; Orrù, 2023)</ref>. Future studies that aim to compare LLMs to humans should address these limitations while also extending beyond merely using humans as benchmarks for accuracy. For instance, comparisons should explore human and AI decision-making across a variety of everyday tasks where accuracy is not the only factor. Just because LLMs can perform to a benchmark, does not mean they can equate to human performance in the real world <ref type="bibr" target="#b84">(McCoy et al., 2019;</ref><ref type="bibr" target="#b92">Nori et al., 2023)</ref>; simply comparing outcomes to human performance on a given test does not provide full insight into the factors at play contributing to a decision, such as how context-dependent LLMs are or their understanding of a question and response <ref type="bibr" target="#b112">(Shiffrin &amp; Mitchell, 2023)</ref>. Probing LLMs for justifications about their decisions could provide insight into these decisions. Furthermore, when comparing the performance of language models, it is important to broaden the scope beyond the GPT family to include other LLMs such as the Mixtral <ref type="bibr" target="#b87">(Mistral AI, 2023)</ref> or the Claude (Anthropic, 2024) families of models, as well as open source and transparent models such as the Hugging Face ecosystem <ref type="bibr" target="#b57">(Hussain et al., 2023)</ref>.</p><p>Proper guidelines for using LLMs in assisting with decision-making need to be established. Due to their ever-increasing uses and applications, it is recommended that future research investigate methods and regulations for using LLMs to help avoid misuse <ref type="bibr" target="#b92">(Nori et al., 2023;</ref><ref type="bibr" target="#b131">Weidinger et al., 2021)</ref>. Developing methods and guidelines to use LLMs in different settings, such as Azaria and colleagues' (2023) flowcharts for academic writing with AI, can help counter risks such as misinformation and data security, and enable an easier application of LLMs in these areas. To enhance the quality and consistency of research that involves cognitive testing in LLMs, it will be important to establish standardised guidelines for administering psychological tests to AI agents. These guidelines should cover the appropriate parameters and settings to use when testing these models, which will serve to reduce the variability in the results that these investigations produce <ref type="bibr">(Azaria et al., 2023;</ref><ref type="bibr" target="#b52">Hagendorff, 2023)</ref>.</p><p>While the focus of this review has been on the decision-making capabilities of LLMs, it is also worth considering how the use of these models will impact human decision-making.</p><p>If used correctly, LLMs can be invaluable assets in enhancing decision-making processes <ref type="bibr" target="#b82">(Martínez et al., 2010;</ref><ref type="bibr" target="#b97">Perlis et al., 2024)</ref> and extending human decision-making capabilities by acting as a cognitive artefact or external decision-making agent <ref type="bibr" target="#b100">(Qu et al., 2024;</ref><ref type="bibr"></ref> potential indirect negative consequences on human cognition that may arise from excessively outsourcing cognitive tasks to LLMs. This concern is not unfounded; for instance, <ref type="bibr" target="#b122">Treiman et al. (2024)</ref> recently found that humans modify their responses when informed that their decisions will be used to train AIs, with this effect persisting even after they are told their answers will no longer be used for AI training. Such findings reflect a broader historical pattern of apprehension regarding the impact of new technologies on cognitive abilities.</p><p>Indeed, these concerns can be traced back to ancient Greek philosophers, with Socrates and Plato believing that the advent of writing would negatively affect human memory <ref type="bibr" target="#b42">(Frentz, 2006)</ref>. This scepticism has persisted through technological advancements, with claims that modern technologies have significantly influenced cognition; for instance, widespread use of smartphones and the internet are believed to have altered memory processes and attention spans <ref type="bibr" target="#b12">(Carr, 2020;</ref><ref type="bibr" target="#b119">Tanil &amp; Yong, 2020)</ref>, while GPS systems have impacted navigation and spatial reasoning skills <ref type="bibr" target="#b24">(Clemenson et al., 2021;</ref><ref type="bibr" target="#b27">Dahmani &amp; Bohbot, 2020)</ref>. In this context, there are growing concerns that overreliance on LLMs for decision-making could potentially diminish critical thinking and independent problem-solving abilities, leading to a form of cognitive offloading where complex reasoning is increasingly delegated to AI systems.</p><p>However, it is also important to consider potential positive effects. LLMs might enhance critical thinking through feedback and supportive learning, serving as cognitive scaffolding that helps users develop more sophisticated thinking strategies <ref type="bibr" target="#b1">(Bai et al., 2023</ref>).</p><p>Furthermore, interaction with AI chatbots has been shown to reduce belief in conspiracy theories, suggesting a potential role in promoting critical evaluation of information <ref type="bibr" target="#b26">(Costello et al., 2024)</ref>. Given the uncertain long-term impact of LLMs on human decision-making and cognitive processes, Heersmink (2024) emphasises the need for longitudinal studies to inform policies and safeguards. These studies should aim to understand how sustained interaction with AI systems affects various cognitive domains, from problem-solving and creativity to memory and attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>LLMs hold huge potential to assist or augment human decision-making; however, they also possess the capacity to introduce biases, errors and misinformation if their output is not properly screened or monitored. Similar to humans, these models are subject to cognitive biases and heuristics previously identified in the fields of cognitive psychology and behavioural economics, necessitating that their responses are treated with caution.</p><p>Additionally, LLMs can exhibit model-specific biases and heuristics posing a new set of problems for industries seeking to use AI systems to replace or augment human decisionmaking.</p><p>Methods of prompting, such as those that promote chain-of-thought reasoning, and agentic AI approaches can allow LLMs to become more accurate in their decision-making, simulating System 2-like thought processes. LLMs can be human-like in their decisionmaking, making the same human System 1 errors to a prompted question, as well as being able to reflect on a question and think methodically about it, akin to System 2 thinking.</p><p>However, there are some limitations to these abilities; for instance, their overreliance on prompting, their tendency to generate misinformation, and a general brittleness in their responses that casts doubt on the level of understanding that they possess. Thus, in their current state, LLMs cannot substitute for human decision-makers in applied settings, but they do have the potential to assist in human decision-making -offering suggestions and summarising research to allow people to make an informed decision in a given situation -if appropriate guardrails are in place. Even if the System 1 reasoning of LLMs becomes more accurate compared to humans, they can still unconsciously show cognitive biases or hallucinate responses, and explicit methods to elicit System 2 thinking should be employed to mitigate the risks of intuitive System 1 thinking.</p><p>This review provides a summary of the current research in the field and indicates where it could be improved upon by considering the lessons we have learned in the study of human decision-making. However, despite mimicking human decision-making skills, their underlying decision-making processes may be distinct from those of humans. Regardless of how 'human' the decision-making of a LLM is, principles from the cognitive psychology of decision-making can still be applied to these AIs to guide our understanding of their overall decision-making skills <ref type="bibr" target="#b50">(Gronchi &amp; Perini, 2024;</ref><ref type="bibr" target="#b105">Rich &amp; Gureckis, 2019)</ref>. Even if the inner workings of LLM decision-making remain a black box, cognitive psychology can help inspire and identify limits of their capabilities and indicate where they need to be improved upon. As LLMs become increasingly integrated into our daily lives, understanding their cognitive processes through the lens of human psychology will be crucial for designing reliable and ethically-aligned AI systems that can effectively complement human decisionmaking in a range of real-world scenarios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Performance of humans and the GPT series of LLMs on a series of cognitive reflection tasks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc> did not. These differences may arise from variations in their testing methods and prompts. Y.Chen et al. employed  </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The change in (a) performance and (b) instruction-following of GPT-4 and GPT-3.5 from March to June of 2023 (L.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot"><ref type="bibr" target="#b133">Yao et al., 2023;</ref><ref type="bibr" target="#b139">Zhu et al., 2023)</ref>. System 2 thinking in LLMs typically requires explicit prompting but from GPT-3.5 onwards, the intuitive System 1 responses from the GPT models have become more accurate, resembling human-like System 2 problemsolving (Y.<ref type="bibr" target="#b53">Hagendorff et al., 2023)</ref>. This is assumed to be a result of newer models automatically engaging in more deliberate chain-of-thought reasoning without being prompted to do so, or having a more developed intuition, both of which are likely consequences of reinforcement learning and human feedback(Ouyang et al., 2022).Alternatively, this difference could be considered a departure from human-like reasoning, suggesting that the model's default reasoning abilities may have evolved beyond typical human cognitive processes. Nevertheless, the emergence of System-2-like reasoning in LLMs -whose infrastructure favours System 1 thinking -brings them a step closer to human-like decision-making.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">on a two-armed bandit task(Zhang et al., submitted). However, the broader trend in LLM development is in keeping with the findings of Hagendorff et al., with each new state-of-the-</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot"><ref type="bibr" target="#b103">Rasmequan &amp; Russ, 2000)</ref>. LLMs may indeed enhance and extend our decision-making processes by taking on part of the cognitive load, thereby enabling us to focus on more complex and strategic aspects of decision-making. However, it is also important to consider</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank Min Wu for feedback and comments on the review.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<idno type="DOI">10.48550/arXiv.2306.03102</idno>
		<idno type="arXiv">arXiv:2306.03102</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2306.03102" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ChatGPT: The cognitive effects on learning and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<idno type="DOI">10.1002/brx2.30</idno>
		<ptr target="https://doi.org/10.1002/brx2.30" />
	</analytic>
	<monogr>
		<title level="j">Brain-X</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Basir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Puspitasari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Aristarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Sulastri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M A</forename><surname>Ausat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ethical Use of ChatGPT in the Context of Leadership and Strategic Decisions</title>
		<idno type="DOI">10.33395/jmp.v12i1.12693</idno>
		<ptr target="https://doi.org/10.33395/jmp.v12i1.12693" />
	</analytic>
	<monogr>
		<title level="j">Jurnal Minfo Polgan</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dual Process Theory: Embodied and Predictive; Symbolic and Classical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Bellini-Leite</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2022.805386</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2022.805386" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dual Process Theory for Large Language Models: An overview of using Psychology to address hallucination and reliability issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Bellini-Leite</surname></persName>
		</author>
		<idno type="DOI">10.1177/10597123231206604</idno>
		<ptr target="https://doi.org/10.1177/10597123231206604" />
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mcmillan-Major</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shmitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">ACM Conference on Fairness, Accountability, and Transparency</title>
		<imprint>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3442188.3445922</idno>
		<ptr target="https://doi.org/10.1145/3442188.3445922" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Using cognitive psychology to understand GPT-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2218523120</idno>
		<ptr target="https://doi.org/10.1073/pnas.2218523120" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="volume">120</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.03494</idno>
		<idno type="arXiv">arXiv:2302.03494</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2302.03494" />
		<title level="m">A Categorical Archive of ChatGPT Failures</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Language Models are Few-Shot Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The shallows: What the Internet is doing to our brains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>WW Norton &amp; Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scheurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Korbak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-R</forename><surname>Segerie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Christoffersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Damani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Slocum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hadfield-Menell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.15217</idno>
		<ptr target="http://arxiv.org/abs/2307.15217" />
		<title level="m">Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hallucination Detection in Foundation Models for Decision-Making: A</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Driggs-Campbell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.16527</idno>
		<ptr target="http://arxiv.org/abs/2403.16527" />
	</analytic>
	<monogr>
		<title level="m">Flexible Definition and Review of the State of the Art</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Applications of integrated LLM-agent systems in diverse domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="312" to="329" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Are Different Versions of ChatGPT&apos;s Ability Comparable to the Clinical Diagnosis Presented in Case Reports? A Descriptive Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.2147/JMDH.S441790</idno>
		<ptr target="https://doi.org/10.2147/JMDH.S441790" />
	</analytic>
	<monogr>
		<title level="j">JOURNAL OF MULTIDISCIPLINARY HEALTHCARE</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3825" to="3831" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajmohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11598</idno>
		<ptr target="http://arxiv.org/abs/2305.11598" />
		<title level="m">Introspective Tips: Large Language Model for In-Context Decision Making</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">How is ChatGPT&apos;s behavior changing over time?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2307.09009</idno>
		<idno type="arXiv">arXiv:2307.09009</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2307.09009" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Manager and an AI Walk into a Bar: Does ChatGPT Make Biased Decisions Like We Do?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andiappan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jenkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ovchinnikov</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4380365</idno>
		<ptr target="https://doi.org/10.2139/ssrn.4380365" />
	</analytic>
	<monogr>
		<title level="m">SSRN Scholarly Paper 4380365</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generative AI for Business Decision-Making: A Case of ChatGPT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Chuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>De Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science and Business Decisions</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="11" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<idno type="DOI">10.52812/msbd.63</idno>
		<ptr target="https://doi.org/10.52812/msbd.63" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Whatever next? Predictive brains, situated agents, and the future of cognitive science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="204" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<idno type="DOI">10.1017/S0140525X12000477</idno>
		<ptr target="https://doi.org/10.1017/S0140525X12000477" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Clemenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Fiannaca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gonzalez-Franco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rethinking GPS navigation: Creating cognitive maps through auditory clues</title>
		<idno type="DOI">10.1038/s41598-021-87148-4</idno>
		<ptr target="https://doi.org/10.1038/s41598-021-87148-4" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Durably reducing conspiracy beliefs through dialogues with AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.adq1814</idno>
		<ptr target="https://doi.org/10.1126/science.adq1814" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">385</biblScope>
			<biblScope unit="issue">6714</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Habitual use of GPS negatively impacts spatial memory during self-guided navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dahmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Bohbot</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-62877-0</idno>
		<ptr target="https://doi.org/10.1038/s41598-020-62877-0" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6310</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Language models show human-like content effects on reasoning tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2207.07051</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2207.07051" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Yeager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clapper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandhok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krettek-Cobb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jonesmitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Dweck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using large language models in psychology</title>
		<idno type="DOI">10.1038/s44159-023-00241-5</idno>
		<ptr target="https://doi.org/10.1038/s44159-023-00241-5" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="688" to="701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adversarial vulnerabilities of human decisionmaking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dezfouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">46</biblScope>
			<biblScope unit="page" from="29221" to="29228" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.2016921117</idno>
		<ptr target="https://doi.org/10.1073/pnas.2016921117" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Can AI language models replace human participants?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dillion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="597" to="600" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.tics.2023.04.008</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2023.04.008" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Machine vs. human, who makes a better judgment on innovation? Take GPT-4 for example. Frontiers in Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<idno type="DOI">10.3389/frai.2023.1206516</idno>
		<ptr target="https://doi.org/10.3389/frai.2023.1206516" />
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eloundou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rock</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.10130</idno>
		<idno type="arXiv">arXiv:2303.10130</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.10130" />
		<title level="m">GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">From words to meaning: A semantic illusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Erickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Mattson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="540" to="551" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/S0022-5371</idno>
		<ptr target="https://doi.org/10.1016/S0022-5371" />
		<imprint>
			<biblScope unit="page" from="90165" to="90166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dual-processing accounts of reasoning, judgment, and social cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">B T</forename><surname>St</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="255" to="278" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<idno type="DOI">10.1146/annurev.psych.59.103006.093629</idno>
		<ptr target="https://doi.org/10.1146/annurev.psych.59.103006.093629" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cognitive Reflection and Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frederick</surname></persName>
		</author>
		<idno type="DOI">10.1257/089533005775196732</idno>
		<ptr target="https://doi.org/10.1257/089533005775196732" />
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="25" to="42" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Memory, Myth, and Rhetoric in Plato&apos;s Phaedrus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Frentz</surname></persName>
		</author>
		<idno type="DOI">10.1080/02773940500511546</idno>
		<ptr target="https://doi.org/10.1080/02773940500511546" />
	</analytic>
	<monogr>
		<title level="j">Rhetoric Society Quarterly</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="262" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Crisafi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11245-008-9045-0</idno>
		<ptr target="https://doi.org/10.1007/s11245-008-9045-0" />
		<title level="m">Mental Institutions. Topoi</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">What Air Canada Lost In &apos;Remarkable&apos; Lying AI Chatbot Case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garcia</surname></persName>
		</author>
		<ptr target="https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/" />
		<imprint>
			<date type="published" when="2024-02-19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Heuristic decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-120709-145346</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-120709-145346" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="451" to="482" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Real-GPT: Efficiently Tailoring LLMs for Informed Decision-Making in the Real Estate Industry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gloria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Melsbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bienert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schoder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Real Estate Portfolio Management</title>
		<imprint>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Looking Back, Looking Ahead: Symbolic versus Connectionist AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goel</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.12026</idno>
		<ptr target="https://doi.org/10.1609/aaai.12026" />
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Griewing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knitza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boekhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hillen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Wagner</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Evolution of publicly available large language models for complex decisionmaking in breast cancer care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of Gynecology and Obstetrics</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Dual-process theories of thought as potential architectures for developing neuro-symbolic AI models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gronchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perini</surname></persName>
		</author>
		<idno type="DOI">10.3389/fcogn.2024.1356941</idno>
		<ptr target="https://doi.org/10.3389/fcogn.2024.1356941" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Cognition</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usuyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<idno type="DOI">10.1145/3458754</idno>
		<idno>2:1- 2:23</idno>
		<ptr target="https://doi.org/10.1145/3458754" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computing for Healthcare</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hagendorff</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.13988</idno>
		<idno type="arXiv">arXiv:2303.13988</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.13988" />
		<title level="m">Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hagendorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Article 10</title>
		<idno type="DOI">10.1038/s43588-023-00527-x</idno>
		<ptr target="https://doi.org/10.1038/s43588-023-00527-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Computational Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Use of large language models might affect our cognitive skills</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Heersmink</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-024-01859-y</idno>
		<ptr target="https://doi.org/10.1038/s41562-024-01859-y" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Long Short-term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Neural Computation MIT-Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">A tutorial on open-source large language models for behavioral science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">U</forename><surname>Wulff</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/f7stn</idno>
		<ptr target="https://doi.org/10.31234/osf.io/f7stn" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=up8EYzyrKV" />
		<title level="m">Towards Mitigating LLM Hallucination via Self Reflection. The 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2023-12-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wettig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swe-Bench</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2310.06770</idno>
		<idno type="arXiv">arXiv:2310.06770</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2310.06770" />
		<title level="m">Can Language Models Resolve Real-World GitHub Issues?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Capturing Failures of Large Language Models via Human Cognitive Biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="11785" to="11799" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Application of ChatGPT in Business Management and Strategic Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Jusman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M A</forename><surname>Ausat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sumarna</surname></persName>
		</author>
		<idno type="DOI">10.33395/jmp.v12i2.12956</idno>
		<ptr target="https://doi.org/10.33395/jmp.v12i2.12956" />
	</analytic>
	<monogr>
		<title level="j">Jurnal Minfo Polgan</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaddour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mozes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raileanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mchardy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<idno type="arXiv">arXiv:2307.10169</idno>
		<ptr target="http://arxiv.org/abs/2307.10169" />
		<title level="m">Challenges and Applications of Large Language Models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Maps of Bounded Rationality: Psychology for Behavioral Economics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1449" to="1475" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title/>
		<idno type="DOI">10.1257/000282803322655392</idno>
		<ptr target="https://doi.org/10.1257/000282803322655392" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Representativeness revisited: Attribute substitution in intuitive judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frederick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Heuristics and biases: The psychology of intuitive judgment</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="49" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<idno type="DOI">10.1017/CBO9780511808098.004</idno>
		<ptr target="https://doi.org/10.1017/CBO9780511808098.004" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.01519</idno>
		<idno type="arXiv">arXiv:2401.01519</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.01519" />
		<title level="m">Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">When ChatGPT Gives Incorrect Answers: The Impact of Inaccurate Information by Generative AI on Tourism Decision-Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>King</surname></persName>
		</author>
		<idno type="DOI">10.1177/00472875231212996</idno>
		<ptr target="https://doi.org/10.1177/00472875231212996" />
	</analytic>
	<monogr>
		<title level="j">Journal of Travel Research</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Large Language Models are Zero-Shot Reasoners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.02083</idno>
		<idno type="arXiv">arXiv:2302.02083</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2302.02083" />
		<title level="m">Theory of Mind Might Have Spontaneously Emerged in Large Language Models</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Petro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1233" to="1239" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title/>
		<idno type="DOI">10.1056/NEJMsr2214184</idno>
		<ptr target="https://doi.org/10.1056/NEJMsr2214184" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Towards Understanding and Mitigating Social Biases in Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6565" to="6576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Using AI-generated suggestions from ChatGPT to optimize clinical decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Wanderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Turer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Sittig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wright</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocad072</idno>
		<ptr target="https://doi.org/10.1093/jamia/ocad072" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1237" to="1245" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">GPT understands, too. AI Open</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.aiopen.2023.08.012</idno>
		<ptr target="https://doi.org/10.1016/j.aiopen.2023.08.012" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Exploring the Sensitivity of LLMs&apos; Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Futrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="page" from="3711" to="3716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title/>
		<idno type="DOI">10.18653/v1/2023.findings-emnlp.241</idno>
		<ptr target="https://doi.org/10.18653/v1/2023.findings-emnlp.241" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Enhancing LLM decision-making through agentbased frameworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1245" to="1278" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Is ChatGPT Humanly Irrational?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saunders</surname></persName>
		</author>
		<idno type="DOI">10.21203/rs.3.rs-3220513/v1</idno>
		<ptr target="https://doi.org/10.21203/rs.3.rs-3220513/v1" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Computing with Words in Decision support Systems: An overview on Models and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computational Intelligence Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="382" to="395" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title/>
		<idno type="DOI">10.2991/ijcis.2010.3.4.2</idno>
		<ptr target="https://doi.org/10.2991/ijcis.2010.3.4.2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Linzen</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1902.01007</idno>
		<idno type="arXiv">arXiv:1902.01007</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1902.01007" />
		<title level="m">Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2309.13638</idno>
		<idno type="arXiv">arXiv:2309.13638</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2309.13638" />
		<title level="m">Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">AI chatbots and (mis)information in public health: Impact on vulnerable communities. Frontiers in Public Health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Meyrowitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Sørensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Varga</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpubh.2023.1226776</idno>
		<ptr target="https://doi.org/10.3389/fpubh.2023.1226776" />
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Mistral</surname></persName>
		</author>
		<ptr target="https://mistral.ai/news/mixtral-of-experts/" />
		<title level="m">Mixtral of experts</title>
		<imprint>
			<date type="published" when="2023-12-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">The debate over understanding in AI&apos;s large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Krakauer</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2215907120</idno>
		<ptr target="https://doi.org/10.1073/pnas.2215907120" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">13</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">The co-evolution of knowledge and event memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0032020</idno>
		<ptr target="https://doi.org/10.1037/a0032020" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="356" to="394" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Physical symbol systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0364-0213(80)80015-2</idno>
		<ptr target="https://doi.org/10.1016/S0364-0213(80)80015-2" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="183" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Computer science as empirical inquiry: Symbols and search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<idno type="DOI">10.1145/1283920.1283930</idno>
		<ptr target="https://doi-org.dcu.idm.oclc.org/10.1145/1283920.1283930" />
	</analytic>
	<monogr>
		<title level="m">ACM Turing Award Lectures</title>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carignan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.13375</idno>
		<idno type="arXiv">arXiv:2303.13375</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.13375" />
		<title level="m">Capabilities of GPT-4 on Medical Challenge Problems</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Introducing ChatGPT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/blog/chatgpt" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Learning to Reason with LLMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/index/learning-to-reason-with-llms/" />
	</analytic>
	<monogr>
		<title level="j">Open AI Blog</title>
		<imprint>
			<date type="published" when="2024-09-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kelton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simens</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Clinical decision support for bipolar depression using large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Perlis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Ostacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Schneck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title/>
		<idno type="DOI">10.1038/s41386-024-01841-2</idno>
		<ptr target="https://doi.org/10.1038/s41386-024-01841-2" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">GROKKING: Generalization beyond overfitting on small algorithmic datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Misra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Mathematical Reasoning in General Artificial Intelligence Workshop, ICLR 2021. OpenAI</title>
		<meeting>the 1st Mathematical Reasoning in General Artificial Intelligence Workshop, ICLR 2021. OpenAI</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Promoting interactions between cognitive science and large language models. The Innovation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2024" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<ptr target="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" />
	</analytic>
	<monogr>
		<title level="j">OpenAI Technical report</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Cognitive artefacts for decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rasmequan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russ</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<pubPlace>Smc</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<idno type="DOI">10.1109/ICSMC.2000.885069</idno>
		<ptr target="https://doi.org/10.1109/ICSMC.2000.885069" />
		<title level="m">Conference Proceedings. 2000 Ieee International Conference on Systems, Man and Cybernetics. &apos;cybernetics Evolving to Systems, Humans, Organizations, and Their Complex Interactions</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="651" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Lessons for artificial intelligence from the study of natural stupidity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s42256-019-0038-z</idno>
		<ptr target="https://doi.org/10.1038/s42256-019-0038-z" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.17548</idno>
		<idno type="arXiv">arXiv:2303.17548</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.17548" />
		<title level="m">Whose Opinions Do Language Models Reflect?</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Language models and psychological sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sartori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Orrù</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2023.1279317</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2023.1279317" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Large pre-trained language models contain human-like biases of what is right and wrong to do</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schramowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Turan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Rothkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-022-00458-8</idno>
		<ptr target="https://doi.org/10.1038/s42256-022-00458-8" />
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Navigating Into the Future or Driven by the Past</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E P</forename><surname>Seligman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Railton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Baumeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sripada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="141" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/1745691612474317</idno>
		<ptr target="https://doi.org/10.1177/1745691612474317" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Probing the psychology of AI models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shiffrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2300963120</idno>
		<ptr target="https://doi.org/10.1073/pnas.2300963120" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<idno type="DOI">10.48550/arXiv.1712.01815</idno>
		<idno type="arXiv">arXiv:1712.01815</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1712.01815" />
		<title level="m">Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Devkota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lamichhane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Dhakal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dhakal</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2309.16145</idno>
		<idno type="arXiv">arXiv:2309.16145</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2309.16145" />
		<title level="m">The Confidence-Competence Gap in Large Language Models: A Cognitive Study</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Connectionist AI, symbolic AI, and the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00130011</idno>
		<ptr target="https://doi.org/10.1007/BF00130011" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="109" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Using cognitive psychology to understand GPT-like models needs to extend beyond human biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Hills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Kenett</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2312911120</idno>
		<ptr target="https://doi.org/10.1073/pnas.2312911120" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">43</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Do large language models show decision heuristics similar to humans? A case study using GPT-3.5</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Slater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ziaee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001547</idno>
		<ptr target="https://doi.org/10.1037/xge0001547" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Mobile phones: The effect of its presence on learning and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Tanil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yong</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0219233</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0219233" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Large language models in medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Thirunavukarasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S J</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Elangovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S W</forename><surname>Ting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1930" to="1940" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41591-023-02448-8</idno>
		<ptr target="https://doi.org/10.1038/s41591-023-02448-8" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">The consequences of AI training on human decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Treiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2408731121</idno>
		<ptr target="https://doi.org/10.1073/pnas.2408731121" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2024" />
			<biblScope unit="volume">121</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Availability: A heuristic for judging frequency and probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285</idno>
		<ptr target="https://doi.org/10.1016/0010-0285" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="90033" to="90042" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Judgment under Uncertainty: Heuristics and Biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.185.4157.1124</idno>
		<ptr target="https://doi.org/10.1126/science.185.4157.1124" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">4157</biblScope>
			<biblScope unit="page" from="1124" to="1131" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1706.03762</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1706.03762" />
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2308.05342</idno>
		<idno type="arXiv">arXiv:2308.05342</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2308.05342" />
		<title level="m">Metacognitive Prompting Improves Understanding in Large Language Models</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Emergent analogical reasoning in large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01659-w</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01659-w" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1526" to="1541" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">Do Prompt-Based Models Really Understand the Meaning of their Prompts?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2109.01247</idno>
		<idno type="arXiv">arXiv:2109.01247</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2109.01247" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2206.07682</idno>
		<idno type="arXiv">arXiv:2206.07682</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2206.07682" />
		<title level="m">Emergent Abilities of Large Language Models</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Weidinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rauh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kasirzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stepleton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birhane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gabriel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<idno type="DOI">10.48550/arXiv.2112.04359</idno>
		<idno type="arXiv">arXiv:2112.04359</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2112.04359" />
		<title level="m">Ethical and social risks of harm from Language Models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Tree of Thoughts: Deliberate Problem Solving with Large Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="11809" to="11822" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.03742</idno>
		<title level="m">Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title/>
		<idno type="DOI">10.48550/arXiv.2305.03742</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.03742" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Agent-augmented language models for complex reasoning tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Neural Information Processing Systems</title>
		<meeting>the Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8790" to="8802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Multimodal chainof-thought reasoning in language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.00923</idno>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">ChatGPT in Scientific Writing: A Cautionary Tale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amjmed.2023.02.011</idno>
		<ptr target="https://doi.org/10.1016/j.amjmed.2023.02.011" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="725" to="726" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Solving Math Word Problems via Cooperative Reasoning induced Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2023" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4471" to="4485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title/>
		<idno type="DOI">10.18653/v1/2023.acl-long.245</idno>
		<ptr target="https://doi.org/10.18653/v1/2023.acl-long.245" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Stiennon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08593</idno>
		<title level="m">Fine-tuning language models from human preferences</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv Preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
