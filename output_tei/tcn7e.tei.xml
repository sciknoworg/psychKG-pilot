<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Peril, Prudence and Planning as Risk, Avoidance and Worry</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Gagne</surname></persName>
							<email>christopher.gagne@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Computational Neuroscience</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<addrLine>Max-Planck-Ring 8</addrLine>
									<postCode>72076</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Peril, Prudence and Planning as Risk, Avoidance and Worry</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>decision making</term>
					<term>risk sensitivity</term>
					<term>anxiety</term>
					<term>avoidance behaviors</term>
					<term>worry</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Risk occupies a central role in both the theory and practice of decisionmaking. Although it is deeply implicated in many conditions involving dysfunctional behavior and thought, modern theoretical approaches to understanding and mitigating risk, in either one-shot or sequential settings, have yet to permeate fully the fields of neural reinforcement learning and computational psychiatry. Here we use one prominent approach, called conditional value-at-risk (CVaR), to examine optimal risk-sensitive choice and a form of optimal, risk-sensitive offline planning. We relate the former to both a justified form of the gambler&apos;s fallacy and extremely risk-avoidant behavior resembling that observed in anxiety disorders. We relate the latter to worry and rumination.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Risk, informally the chance of deleterious, calamitous or even miraculous happenings, drives many of our behaviors and occupies many of our thoughts. This is evident, for instance, in the existence of huge sectors of the economy such as insurance, and in the effects of globally catastrophic black swan events, such as the 2008 financial crisis and the 2020 global pandemic. Individuals treat risk very differently <ref type="bibr" target="#b19">(Choi, Fisman, Gale, &amp; Kariv, 2007;</ref><ref type="bibr" target="#b44">Levin &amp; Hart, 2003)</ref>, with some being largely unaffected by it and others going to extreme lengths to avoid it. Hypersensitivity to risk is often associated with psychopathology, especially anxiety disorders. Anxious individuals exhibit a variety of avoidance behaviors in daily life <ref type="bibr" target="#b3">(Arnaudova, Kindt, Fanselow, &amp; Beckers, 2017)</ref>, and their thoughts are often consumed by worries about potential threats, dangers, or calamities and how to avoid them <ref type="bibr" target="#b8">(Berenbaum, 2010;</ref><ref type="bibr" target="#b79">Watkins, 2008)</ref>. This poses the critical questions of how we should understand behaviors and thoughts involving risk, and the differences between people in these respects.</p><p>Many of the answers to these questions have come from decision theory and the analysis of optimal decision making. Risk and risk preferences have been formalized using non-linear subjective utilities <ref type="bibr" target="#b77">(von Neumann &amp; Morgenstern, 1947)</ref>, non-linear subjective probabilities <ref type="bibr" target="#b59">(Quiggin, 1982;</ref><ref type="bibr" target="#b78">Wang, 2000;</ref><ref type="bibr">Yaari, 1987)</ref>, and the modulation of value according to variance <ref type="bibr" target="#b52">(Markowitz, 1952)</ref>. These notions have successfully helped to explain decisions and behaviors involving risk across a wide range of domains from financial to health <ref type="bibr" target="#b30">(Fox, Erner, &amp; Walters, 2015)</ref>, and have been extensively used in psychology, neuroscience and neuroeconomics, for instance, in investigating risk sensitive decisions in anxiety disorders <ref type="bibr" target="#b17">(Charpentier, Aylward, Roiser, &amp; Robinson, 2017)</ref> and neural representations of risk <ref type="bibr" target="#b71">(Symmonds, Bossaerts, &amp; Dolan, 2010;</ref><ref type="bibr" target="#b81">C. C. Wu, Bossaerts, &amp; Knutson, 2011)</ref>. Even the wealth of psychological research that has emphasized apparent anomalies as biases and heuristics <ref type="bibr" target="#b41">(Kahneman &amp; Tversky, 1979;</ref><ref type="bibr" target="#b75">Tversky &amp; Kahneman, 1992)</ref> can be seen as an outgrowth of some of these formal ideas. Thus, for instance, cumulative prospect theory <ref type="bibr" target="#b75">(Tversky &amp; Kahneman, 1992</ref>) builds on rank-dependent utility theories <ref type="bibr" target="#b59">(Quiggin, 1982;</ref><ref type="bibr">Yaari, 1987)</ref>, combining nonlinear utilities and subjective probabilities with the critical observation that people treat gains (relative to a psychologically-determined reference point) differently from losses.</p><p>However, the application and adaptation of risk-sensitive decision theory to behavioral, psychological, and neurobiological phenomena is lacking in two critical ways: (i) its measures of risk are limited, neither exactly capturing the sort of "outcomes that hurt the most"-the so-called "tail events" that seem to be important drivers of risk-avoidant behavior and thoughts, especially in individuals suffering from anxiety <ref type="bibr" target="#b3">(Arnaudova et al., 2017;</ref><ref type="bibr" target="#b79">Watkins, 2008)</ref>-nor satisfying the attractive theoretical properties <ref type="bibr" target="#b4">(Artzner, Delbaen, Eber, &amp; Heath, 1999)</ref> that are increasingly investigated in finance and machine learning <ref type="bibr" target="#b15">(Bäuerle &amp; Ott, 2011;</ref><ref type="bibr" target="#b20">Chow, Ghavamzadeh, Janson, &amp; Pavone, 2017;</ref><ref type="bibr" target="#b21">Chow, Tamar, Mannor, &amp; Pavone, 2015;</ref><ref type="bibr" target="#b24">Dabney, Ostrovski, Silver, &amp; Munos, 2018;</ref><ref type="bibr" target="#b42">Krokhmal, Zabarankin, &amp; Uryasev, 2013)</ref>; and (ii) it is most often used in the case of single timepoint decisions rather than the sort of sequential decision-making problems that require planning and that are ubiquitous in the real world. To fill the first gap, we adopt a newer risk measure, conditional value-at-risk (CVaR), which is defined as the expected value in the lower α-quantile or tail of a distribution -exactly the tail events. To address the second gap, we exploit two different approaches to applying CVaR in sequential decision making settings, each of which has different, but relevant, implications for modeling human behavior. We also discuss how (CVaR-) optimal behavior and planning can resemble the dramatically risk-avoidant behaviors and thoughts (i.e., worries) that are typically associated with pathological anxiety.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Formalizing Risk Preferences for a Single Choice</head><p>In this first section of the paper, we describe in detail conditional value-at-risk (CVaR) as a risk measure for single decisions. Risk preferences regarding tail events are determined by the value of a parameter α, which defines the relevant, lower, segment of the distribution of possible outcomes. These ideas provide an important foundation for understanding CVaR in the sequential case.</p><p>Consider a decision maker who can make a choice that would lead to a draw from a distribution of potential outcomes (represented by a random variable Z and depicted in <ref type="figure" target="#fig_0">Figure 1a</ref>). The decision-maker seeks to choose according to the risk of this distribution. One way to quantify this risk is to use the α-level CVaR (CVaR α ), which is defined as the mean of those outcomes in the Lower values for α result in more extreme risk preferences: α = 1 corresponds to a risk-neutral preference, whereas α = 0.05 corresponds to a very risk-averse preference (the expected value of the 5% worst-case outcomes). The CVaR α values for each α-level are also shown as the black dashed lines in this panel. (c-d) CVaR can also be calculated as a distorted expectation. Weights ξ(z) are used to distort the outcome probabilities p(z) in order to overweight poor outcomes as much as possible, up to the maximum allowed by 1 /α; arrow width is used to depict distorted probabilities, p(z)ξ(z). For α = 1, the distortion weights ξ(z) = 1, so the outcomes are multiplied by undistorted probabilities, which match the relative frequencies of outcomes in the histograms in <ref type="bibr">(a-b)</ref>. For α = 0.3, the distortion weights effectively select the negative outcomes (z ∈ {−4, −3, −2, −1}) for exclusive consideration.</p><p>lower α-percentage, or lower tail, of the distribution <ref type="figure" target="#fig_0">(Figure 1a</ref> shaded region, for α = 0.3; <ref type="bibr" target="#b4">Artzner et al. 1999;</ref><ref type="bibr" target="#b61">Rockafellar and Uryasev 2000)</ref>. The value that demarcates the lower α-percentage is referred to as the α-level value-at-risk (VaR α ), allowing CVaR α to be formally expressed as the conditional expectation of the outcomes below this value: 1</p><p>CVaR α <ref type="bibr">[Z]</ref> </p><formula xml:id="formula_0">= E[Z|Z ≤ VaR α (Z)]<label>(1)</label></formula><p>Under this formalism, the decision maker's risk preference is given by α. The CVaR α at various values for α are shown by the black dashed lines in <ref type="figure" target="#fig_0">Figure 1b</ref>. As can be seen, when α = 1, the CVaR α corresponds to the expected value of the entire distribution; and when α = 0.05, the CVaR α corresponds to the expected value of the extreme lower tail (i.e., the worst 5% of the cases). In the limit as α approaches zero, the CVaR α becomes equal to the minimum value of Z. Thus by adjusting α, different risk preferences are achieved, from risk-neutral to very risk-averse.</p><p>CVaR can also be expressed as an unconditional expectation, which is useful for evaluating risk in the sequential setting. Here, the probabilities associated with the possible outcomes are pessimistically distorted <ref type="bibr" target="#b4">(Artzner et al., 1999)</ref>:</p><formula xml:id="formula_1">CVaR α [Z] = min ξ∈U (α) E ξ [Z] = min ξ∈U (α) z p(z)ξ(z)z<label>(2)</label></formula><p>Specifically, the probability for each potential outcome, given by p(z) := P (Z = z), is multiplied by a distortion weight ξ(z). Poor outcomes are over-weighted as much as possible subject to individual weights being less than 1 /α and the distorted probabilities still summing to 1. These two conditions are denoted by:</p><formula xml:id="formula_2">U(α) := {ξ : ξ(z) ∈ [0, 1 /α] , z ξ(z)p(z) = 1}.</formula><p>The distortion weights can be obtained by numerically solving the minimization problem in Equation 2 for a given distribution. In <ref type="figure" target="#fig_0">Figure 1c</ref>-d, the calculation of CVaR α=0.3 using distortion weights is contrasted with the calculation of the (undistorted) expected value (i.e., CVaR α=1 ). For the expected value, the outcomes z are multiplied by undistorted probabilities p(z) that correspond to the relative frequencies of the outcomes as depicted in the histograms in <ref type="figure" target="#fig_0">Figure 1a</ref>-b. For α = 0.3, the outcomes are multiplied by distorted probabilities p(z)ξ(z), which select out the negative outcomes (z ∈ {−4, −3, −2, −1}) for exclusive consideration. Note that for this simple distribution the distorted probabilities corresponding to the outcome values above the VaR α=0.3 are zero, but this is not always the case.</p><p>CVaR has psychologically attractive qualities as a risk measure because of the excess weight it gives to extreme negative outcomes. These are particularly salient in both memory and during risk-related decision making <ref type="bibr" target="#b45">(Lichtenstein, Slovic, Fischhoff, Layman, &amp; Combs, 1978;</ref><ref type="bibr" target="#b46">Lieder, Griffiths, &amp; Hsu, 2018;</ref><ref type="bibr" target="#b49">Madan, Ludvig, &amp; Spetch, 2014)</ref>. By comparison, traditional formulations such as non-linear, exponential utility functions and/or mean + β * variance approaches (which are equivalent to up to a first-order approximation; <ref type="bibr" target="#b54">Mihatsch &amp; Neuneier, 2002)</ref> equate the risk of values above and below the mean; and 'mean-semivariance' alternatives that consider variance strictly below the mean also underweight catastrophes. Prospect theory <ref type="bibr" target="#b41">(Kahneman &amp; Tversky, 1979;</ref><ref type="bibr" target="#b75">Tversky &amp; Kahneman, 1992)</ref> and configural weight models <ref type="bibr" target="#b11">(Birnbaum, 2008)</ref> share with CVaR the formal characteristic that risk-sensitivity is produced by reweighting the probabilities of outcomes. However, the ways that probabilities are transformed differ between these models and CVaR-for instance, in prospect theory, small probabilities are overweighted and large probabilities underweighted, but without a tie to the values associated with the outcomes, as in CVaR.</p><p>Of particular importance, these various measures have not been thoroughly investigated in the case of extreme negative events whose avoidance can potentially be planned -which are arguably more representative of the kind of risks (e.g., predation) that animals (and humans) faced throughout their evolutionary history. Planning requires consideration of multiple intermediate states and actions, and so we next turn to consider CVaR in sequential problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluating Risk in Sequential Decision Making</head><p>In this section, we consider a decision maker who, given some fixed decision policy, uses CVaR to evaluate risk in a multi-stage setting with stochastic transitions and multiple possible rewards/costs. Surprisingly, there are multiple methods even for simply evaluating 'tail' risk in such a sequential setting. We consider two normative, yet distinct, approaches. One method (we call nCVaR) maintains a constant value of risk preference (α) over stages. This keeps immediate risk preference fixed-but at the expense of complicating long-run risk evaluation, which can only be described as a nested series of single timepoint evaluations. The second approach (pCVaR) focuses on the risk associated with a privileged start state (e.g., from a home or nest). Electing to privilege this state is a form of precommitment, and maintaining it requires the degree of risk preference (α) to be adjusted as the agent moves through state space.</p><p>To model sequential decision making, we use an infinite-horizon discounted Markov decision process (MDP). We consider a decision maker who can be in different states of the world x ∈ X and chooses from a set of possible actions a ∈ A in each state. Choices are made according to a stationary policy π(a|x), which maps states to probabilities over actions.</p><p>In the MDP, each state is also associated with a reward assigned by a reward function r(x). For convenience, the reward function is fixed and deterministic. Transitions to new states are stochastic, with the probability of transitioning to a new state x from state x having taken action a given by the transition function p(x |x, a). For any stationary policy, the transition function can be simplified as p π (x |x) = a π(a|x)p(x |x, a), which marginalizes out the decision maker's actions, so that only state-to-state transitions need to be considered.</p><p>We write random variables with capital letters and, where necessary, subscripts denoting time, so the decision maker experiences a random sequence of states (X 0 , X 1 , X 2 , . . . ) and random discounted rewards (R 0 , γR 1 , γ 2 R 2 , . . . ), where γ is the discount factor.</p><p>Conventional RL suggests that a decision maker starting in state X 0 = x 0 should calculate (and then optimize) the expected value of the discounted return. This is</p><formula xml:id="formula_3">v π (x 0 ) = E[ ∞ t=0 γ t R t |X 0 = x 0 , π]).</formula><p>As has long been recognized, this calculation can be simplified by writing an equivalent quantity v π (x) starting from state x, and using recursion in the form of what is known as the Bellman expectation equation <ref type="bibr" target="#b7">(Bellman, 1952)</ref>:</p><formula xml:id="formula_4">v π (x) = r(x) + γ x p π (x |x)v π (x )<label>(3)</label></formula><p>Contemporary questions then concern risk-sensitive versions of the return v π (x), and their calculation using recursive, Bellman-like equations. We consider two such versions. Under the first approach, CVaR α is re-applied with the same risk preference at every step <ref type="bibr" target="#b67">(Shapiro, Dentcheva, &amp; Ruszczyński, 2014)</ref>. We denote this static risk preference asᾱ. The reapplication corresponds to a nested sequence of conditional CVaRs (nCVaR):</p><formula xml:id="formula_5">nCVaR π α,x := CVaRᾱ[R 0 + γCVaRᾱ[R 1 + . . . |X 1 ]|X 0 = x, π]<label>(4)</label></formula><p>Here, the initial value of the risk preferenceᾱ is applied not only to future rewards but also to future risk evaluations, which themselves are now random. The subscripts and superscripts denote the risk preference, the stationary policy, and the start state. Note that in the risk neutral case, nCVaR reverts to the regular value function: nCVaR π 1,x = v π (x) By contrast, under the second approach, risk is evaluated by applying CVaR to the discounted sum of future rewards (i.e., the return, R = ∞ t=0 γ t R t |X 0 = x 0 , π) from the perspective of the privileged start state x 0 and an initial risk preference. We write this preference as α 0 = α for reasons that will soon become clear. This precommitted pCVaR approach is defined as:</p><formula xml:id="formula_6">pCVaR π α 0 ,x 0 := CVaR α 0 [R 0 + γR 1 + γ 2 R 2 . . . |X 0 = x 0 , π]<label>(5)</label></formula><p>using the same convention about subscripts and superscripts. We also write the pCVaR value function as pCVaR π α,x for a general start state x and risk preference α. Again, in the risk neutral case, pCVaR reverts to the regular value function: pCVaR π 1,x = v π (x). Both nCVaR and pCVaR satisfy Bellman-like equations <ref type="bibr" target="#b21">(Chow et al., 2015;</ref><ref type="bibr" target="#b64">Ruszczyński, 2010)</ref>. For nCVaR this is straightforward</p><formula xml:id="formula_7">nCVaR π α,x = r(x) + γ min ξ∈U (ᾱ) x p π (x |x)ξ(x |x)nCVaR π α,x<label>(6)</label></formula><p>with the key difference from regular Bellman evaluation (Equation 3) being the distorted expectation of the subsequent nCVaR values. This is similar to the way that CVaR for a single decision involved the distorted expectation over a set of outcomes (Equation 2); however, now the distortion weights ξ(x |x) are applied to the state-to-state transition probabilities p π (x |x) induced by the policy, rather than to the outcome probabilities (i.e., p(z) in Equation 2). For pCVaR, this is more complicated <ref type="bibr" target="#b21">(Chow et al., 2015)</ref>:</p><formula xml:id="formula_8">pCVaR π α,x = r(x) + γ min ξ∈U (α) x p π (x |x)ξ(x |x)pCVaR π αξ(x |x),x<label>(7)</label></formula><p>Compared with Equation 6, this has two unusual features. First, transitions in state x → x also correspond to transitions in risk preference α → α = αξ(x |x), where the shift in risk preference is exactly proportional to the distortion in the transition probabilities. This shift, for which we provide a simple example below, comes from the way that CVaR, in general, is expressed as a conditional expectation <ref type="bibr" target="#b58">(Pflug &amp; Pichler, 2016)</ref>. Second, and as a consequence of this, the state x is augmented by the risk preference α. 2 <ref type="figure" target="#fig_2">Figure 2</ref> provides some intuition into nCVaR and pCVaR. Here, under the policy π, the agent starts at the root (x = s) of a two-stage tree and transitions to one of two possible branches x = b; x = g with probabilities p(b|s) = 0.1 and p(g|s) = 0.9, respectively. Each branch is associated with a distribution of possible outcomes. The b (bad) distribution is entirely worse than the g (good) distribution. The root (or start s) is associated with the mixture of these distributions <ref type="figure" target="#fig_2">(Figure 2a</ref>).</p><p>First, consider calculating the expected value from the start (x = s). To do so, we would simply multiply the expected values for branches b and g by the respective transition probabilities and sum (i.e., v</p><formula xml:id="formula_9">π (s) = p(b|s)v π (b) + p(g|s)v π (g)).</formula><p>We can think of this as a simplified version of  Because the entire distribution at b has a one-to-one correspondence with the bottom 10% at s (as indicated by the dark/light blue shading), the pCVaR α0=0.1 at the start is calculated as the undistorted expectation at b (i.e., CVaR α1=1 ); note that because b is a terminal state, we simply write CVaR. This risk preference adjustment α 1 = α 0 ξ(b|s) is captured by Equation 7. In contrast, for the nCVaRᾱ =0.1 , the risk preferences are held fixed (atᾱ). Thus the nominally 10%-level nCVaRᾱ =0.1 only ultimately corresponds to 1% of s's total distribution of returns.</p><p>Equation 6, this implies that we should set the distortion weight for b to its maximal value (i.e., ξ(b|s) = 10) and the weight for g to its minimal value (i.e., ξ(g|s) = 0), so that our calculation also only involves the bad distribution and the probabilities still sum to 1. Then, Equation 6 mandates using the same risk preference (ᾱ = 0.1) at b-that is, we use the 10%-level CVaRᾱ =0.1,b (shown in red; writing this as CVaR rather than nCVaR since b is a terminal state). Using this value at b implies that the nested nCVaR at the root s for a nominalᾱ = 0.1 only accounts for 1% of the total distribution at s (also shown in red at the top), and is thus a very conservative evaluation of risk. As we will see in the next section, nested nCVaR often results in optimal policies that are more risk-averse for the same nominal level of risk preference.</p><p>By contrast, pCVaR evaluates risk relative to the start state s, so the the 10%-level pCVaR α 0 =0.1,s should calculate the average value of the bottom 10% of the outcomes there. These outcomes are exactly those in the dark versus light blue shading of the distributions in <ref type="figure">Fig-ure</ref> 2b -and all come from the outcomes at b. This is consistent with the distortion weights ξ(b|s) = 10; ξ(g|s) = 0. However, each of the outcomes at b (rather than just the bottom 10% of them) contributes to pCVaR α 0 =0.1,s . Thus, pCVaR α 0 =0.1,s is equivalent to the expected value of the entire distribution in branch b (i.e., the pCVaR α 1 =1,b ). In Equation 7, this reasoning is captured by the risk preference adjustment, α 0 ξ(b|s) → α 1 (i.e., 0.1 × 10 → 1).</p><p>Thus the 10%-level pCVaR for the start is pCVaR α 0 =0.1,s = ξ(b|s)p(b|s)pCVaR 1,b = 10×0.1× pCVaR 1,b = pCVaR 1,b . If the probability of the bad branch b had been p(b|s) = 0.2, the distortion weight would have been ξ(b|s) = 5, which again is the maximum allowed under the constraint that the probabilities still sum to 1. Correspondingly, the adjusted risk preference would have been α 1 = 0.1 × 5 = 0.5, generating the bottom 10% at the start s from the bottom 50% at b.</p><p>Another perspective on the need to adjust risk preferences is that looking only at the state x in the external environment, the conventional Markov property, that the value of a state only depends on the future, is lost. Imagine a more complicated tree that has a second route to b from an alternative start state s † , and that s † also leads to an even worse branch than b. Depending on whether the agent arrived at b from s or s † , the level of risk preference that pertains at b would be different. If b is arrived at using the path coming from s † , the adjusted risk preference α 1 would be lower than the starting risk preference α 0 . This is because b is the good state from the perspective of s † , whereas it is the bad state from the perspective for s. This means that the relevant pCVaR value at b depends on route taken. However, we chose to dissolve this apparent history dependence of the calculation of the values (and later the policies) by introducing the second, risk-preference, dimension of the value function, leaving a more complicated, but stationary problem <ref type="bibr" target="#b21">(Chow et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The 1D problem</head><p>To gain further intuition, we examine the evaluation of nCVaR and pCVaR in a slightly more complex example ( <ref type="figure">Figure 3)</ref>; we use this example later to examine optimal policies and planning. <ref type="figure">Figure 3a</ref> depicts an MDP with states corresponding to different locations in a one-dimensional grid world. Possible actions are to stay put, or go left or right, and each action leads to the intended location with only 90% probability. There are two positive rewards: a smaller one on the right, and a larger one on the left that neighbors an even larger negative outcome (a lava pit), which terminates the agent's interaction with the world and is the sort of catastrophe that a CVaR-riskaverse decision maker might aim to avoid. Figure 3a also shows the return distribution for the start state x 0 for a policy that chooses actions uniformly at random (i.e., π(a|x) = 1 /3; depicted by the three equally sized black-on-white arrows in each grid location).</p><p>For risk neutrality (i.e.,ᾱ = α 0 = 1), the value function for the uniformly random policy (i.e., π(a|x) = 1 /3) is shown in <ref type="figure">Figure 3b</ref>, where the color of the state is used to indicate the value (i.e., the mean of the return distribution starting from that state). <ref type="figure">Figure 3c</ref> shows the nCVaR value function for the same uniformly random policy and its associated distorted probabilities for various values of α. Here, the color of each state (α, x) corresponds to the α-level nCVaR (rather than the mean) of the return distribution starting from that augmented state. The six α-levels shown were chosen to span worst-case α = 0 to risk-neutral α = 1 risk preferences and to highlight interesting qualitative differences in optimal behavior and planning (which are discussed in the next sections). Values naturally become more pessimistic with lower α, since they correspond to increasingly lower tails of the distribution.</p><p>The distorted transition probabilities p π (x |x)ξ(x |x) across different values of α are also depicted in <ref type="figure">Figure 3c</ref>-d as gray arrows, with arrow thickness indicating the probability after distortion has been applied; self-transitions are depicted using curved arrows. The greater the risk aversion specified by α, the more the distorted transitions lead the agent unerringly to doom.</p><p>By contrast, <ref type="figure">Figure 3d</ref> shows the pCVaR value function for the same random policy, using interpolation to approximate the values for other levels of α (see Appendix A). Now the distorted transition probabilities can also change α level (the diagonal arrows)-typically specifying greater risk aversion, or lower α, after a fortunate transition (usually, moving right); or higher α after an unlucky one (moving left). The process for calculating a pCVaR value for a particular augmented state, under the random policy, can be imagined by starting in that state and following the distorted transition probabilities. For example, starting in the middle near the bottom (x 0 = 5, α 0 = 0.05) generally leads to the left, closer to the lava pit, and hence to a negative pCVaR value; an example imagined trajectory is illustrated in <ref type="figure">Figure 3d</ref>, which starts at the location labeled 'example start' and follows the path labeled t = 0, 1, . . . , 4 in blue in the upper right corner of the relevant grid squares. As mentioned above, at α = 1 or α = 0, the evaluation of pCVaR does not require adjusting risk preference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3 Using CVaR to evaluate the risk of a policy in a Markov decision process (MDP). (a)</head><p>Upper: a simple linear grid-world MDP. Possible actions are to stay put or go left or right. Actions succeed with 90% probability; stay leads to the other two locations with 5% probability each; left (right) leads to staying with probability 6% and moving right (left) with probability 4%. There are two reward outcomes (+2,+1); and one terminating negative outcome (−10). The discount factor is γ = 0.9. Following the random policy (π(a|x) = 1 3 ; black-on-white arrows) starting at x 0 leads to the distribution of possible returns (lower). (b) In the typical risk-neutral setting, the value v π (x) of state x is the expected value of the return distribution starting there (indicated by the color; key provided at the bottom). (c-d) The two approaches for risk-sensitive policy evaluation using CVaR are shown for 6 different risk preferences. The nested nCVaR approach (panel c) applies CVaR at the same risk preferenceᾱ at each point in time. Calculating its value involves pessimistically distorted transitions (shown as gray arrows), but transitions only involve state x. Different initial risk preferences are shown (using theᾱ-axis to indicate the risk preference), but there is no transition between these preference levels (hence the separation between rows). The precommitted pCVaR approach (panel d) applies CVaR at the start to the return distribution. Its calculation involves (hypothetically) adjusting risk preferences after the start (potentially transitioning to different rows), according to the pessimistically distorted transitions. For example, the pCVaR for the random policy starting at (x 0 = 5, α 0 = 0.05; see 'example start') can be calculated by sampling transitions from the gray arrows from that state and using the pCVaR value (at the potentially new risk preferences) in the visited states-these transitions generally lead to the left, closer to the negative outcome (for example, t = 0−4 starting from 'example start'); hence the negative evaluation for this state. The distortions are greater for more risk averse preferences, generally leading to more negative evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Risk-sensitive Optimal Policies</head><p>In this section, we examine the structure of CVaR-optimal risk-sensitive behavior for different degrees of risk sensitivity. At the end of the section, we assess how well this optimal behavior captures intuitive notions of risk avoidance, from risk-neutral to extremely (and possibly pathologically) risk-averse behavior. The different characteristics of the two forms of CVaR apparent in evaluation-excess risk aversion (for nCVaR) and risk reweighting (for pCVaR) are a particular focus because of their psychological import.</p><p>For the nested nCVaR approach, which evaluates risk at each point in time using a fixed risk preference, the optimal policy maximizes:</p><formula xml:id="formula_10">max π∈Π H nCVaR π α,x 0 (8)</formula><p>For this objective, the optimal policy, chosen from the set of all potential history-dependent policies, will be stationary over the x state space alone <ref type="bibr" target="#b64">(Ruszczyński, 2010)</ref>. We write this optimal stationary policy as π * α (a|x), again using the subscriptᾱ to specify that the policy depends on the risk preference, but that it does not change as the decision maker interacts with the world.</p><p>For the precommitted pCVaR approach, which evaluates risk solely from the perspective of the start state (x 0 , α 0 ), the optimal policy maximizes:</p><formula xml:id="formula_11">max π∈Π H pCVaR π α 0 ,x 0 (9)</formula><p>As for policy evaluation, the pCVaR optimal policy can either be seen as stationary in the risk augmented state space (α, s), or as non-stationary and history dependent in just x <ref type="bibr" target="#b15">(Bäuerle &amp; Ott, 2011;</ref><ref type="bibr" target="#b21">Chow et al., 2015)</ref>.</p><p>Appendix B reports Bellman equations for finding optimal nCVaR and pCVaR policies. <ref type="figure">Figure 4a</ref> shows the nested nCVaR optimal policy for the 1-D grid world MDP ( <ref type="figure">Figure 3a</ref>) along with the optimal distorted probabilities (gray arrows; noting that each action leads to the intended location with only 90% probability, and thus states closer to the lava pit are riskier). We can see that optimal actions at a risk-neutral preference (ᾱ = 1; top row) tend to point towards the larger, riskier reward on the left, while the actions at more risk-averse preferences (ᾱ ≤ 0.3; bottom rows) tend to point towards the smaller, safer reward on the right. As shown by the red shading, the values associated with the states at lowᾱ-values become extremely negative, because of the way that risk compounds in the nested nCVaR. Thus, the optimal policy for a low alpha (e.g.,ᾱ = 0.05), refuses to stay at the small reward to collect it more than once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1D world</head><p>The pCVaR optimal policies in <ref type="figure">Figure 4b</ref> are again risk-dynamic. The grey arrows show the optimal distorted probabilities, which depict how risk preferences would be adjusted in this example given the actions taken and the actual state transitions that occur. For an example of this optimal adjustment of risk preferences, consider a decision maker who starts in state (x 0 = 5, α 0 = 0.3) and experiences two unfortunate (backwards) transitions, leading first to state (X 1 = 4, α 1 = 0.6) and then to state (X 2 = 3, α 2 = 0.6) 3 . The pCVaR decision maker will then switch directions and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4</head><p>Risk-sensitive (CVaR) optimal policies. Optimal policies for the nested nCVaR and precommitted pCVaR approaches to risk are shown for the same linear grid-world MDP as in <ref type="figure">Figure 3</ref>. (a) For nCVaR, an optimal stationary policy π * α (a|x) (depicted using white-on-black arrows) and optimal distortion weights ξ * (x |x) (depicted using gray arrow) are calculated within the same (x) state space that we examined for risk evaluation and do not involve adjusting risk preference. Correspondingly, the distortion weights point only along one fixed level forᾱ. With little risk aversion (ᾱ &gt;= 0.6), the optimal policy directs the decision maker towards the larger, riskier reward on the left-hand side, while for greater risk aversion (ᾱ &lt; 0.6), it points the decision maker to the smaller, safer reward on the right-hand side. At very low values forᾱ (e.g., 0.05), the policy is extremely conservative, refusing even to collect the small safe reward and instead staying in the far rightmost state. Forᾱ = 0, all policies are equally optimal (or rather sub-optimal), because every action in each state leads to the same worst-case outcome with some nonzero probability. (b) For pCVaR, an optimal stationary policy π * (a|x, α) and optimal distortion weights are calculated within the augmented (x, α) state space. In this example, the pCVaR-optimal policy is similar to the nCVaR-optimal policy across risk preferences, but it is less conservative for low values for α (e.g., 0.05). After the decision maker selects a first action according to the stationary optimal policy, for example starting in the augmented state (x 0 = 5, α 0 = 0.3), risk preference must be adjusted according to the optimal distortion weights (i.e., ξ * (x |x)α 0 → α 1 ). This adjustment can make optimal behavior seem counter-intuitive. For example, if the decision maker experiences two unfortunate transitions, transitioning to (x 1 = 4, α 1 = 0.6) and then to (x 2 = 3, α 2 = 0.6), despite selecting the rightward action, he will switch directions and head towards the larger, riskier reward rather than continue to pursue the smaller, safer reward. In general, the optimal policy for pCVaR requires non-stationarity with respect to the original (x) state space. Again, all policies for α = 0 are equivalently (sub)optimal.</p><p>head towards the larger, riskier reward rather than continue to pursue the smaller, safer reward. In general, as a consequence of risk preference adjustment, if the decision maker experiences an unfortunate transition (i.e., one that has a distortion weight ξ * (X t |X t−1 ) &gt; 1), the risk preference is adjusted to be relatively more risk seeking. If a fortunate transition is experienced (i.e., one with a distortion weight ξ * (X t |X t−1 ) &lt; 1), the risk preference is adjusted to be relatively more risk averse.</p><p>The distortion weights are generally intuitive-as can be seen in <ref type="figure">Figure 4b</ref>, many of the transitions that reverse the optimal policy have distortion weights &gt; 1, and are thus considered unfortunate. However, there are also a few instances, such as in state (x 0 = 3, α 0 = 0.3), in which going against the optimal policy is associated with a distortion weight &lt; 1. This is useful reminder that the distortion weights are calculated through an inner optimization and can sometimes depend intricately on the pCVaR values of the surrounding states.</p><p>If we compare the nCVaR and pCVaR optimal policies and values, we can see that nCVaR is significantly more risk averse (by not adjusting risk levels with unfortunate transitions), and thus has much more negative optimal values -particularly for substantial degrees of risk aversion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cliff world</head><p>In addition to the 1-D grid world, we also examined optimal policies in a 2-D grid world which affords extra opportunities for avoidance. The available actions are to go left, right, up, or down, and they again lead to the intended location (where r(x) = 3) with only 90% probability ( <ref type="figure" target="#fig_3">Figure 5</ref>). In this example, there is a form of cliff that makes the shortest path from the start (on the lower left) to the single rewarding state (on the lower right) come perilously close to dangerous r(x) = −1 states at the bottom. All states with non-zero reward are terminating. <ref type="figure" target="#fig_3">Figure 5a</ref> shows the optimal nCVaR policies and values. For the risk neutral case (i.e., α close to 1) the optimal policy takes a more direct, yet riskier, route toward a goal. However, for lower α, and consistent with intuition, the nCVaR optimal policy takes a more circuitous, safer route, or, forᾱ = 0.05, refuses to pursue the reward at all, moving instead to the safest location in the map (top left corner).</p><p>For α &lt; 1, pCVaR optimal policies <ref type="figure" target="#fig_3">(Fig. 5b)</ref> are mostly less risk-averse than for nCVaR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative formulations</head><p>Before turning to behavioural implications, we briefly discuss more general considerations about risk measures in sequential settings. Various alternatives, such as non-linear expected utility and mean-variance, also share with CVaR the property that their optimal policies can be historydependent <ref type="bibr" target="#b22">(Coraluppi &amp; Marcus, 1999;</ref><ref type="bibr" target="#b51">Mannor &amp; Tsitsiklis, 2011;</ref><ref type="bibr" target="#b54">Mihatsch &amp; Neuneier, 2002)</ref>. To deal with this, state augmentation has sometimes been used, analogous to the use of the additional risk preference dimension that we described for pCVaR <ref type="bibr" target="#b21">(Chow et al., 2015)</ref>. For both non-linear expected utility and mean-variance, the cumulative past reward (or cost) can be used to augment the state space, and this augmented space is sufficient for supporting stationary optimal policies <ref type="bibr" target="#b10">(Bertsekas, 1995;</ref><ref type="bibr" target="#b51">Mannor &amp; Tsitsiklis, 2011)</ref>. Augmenting the state space with cumulative costs has also been done for pCVaR (simply referred to as CVaR in previous work; Bäuerle and Ott 2011). However, calculating the optimal policy in this augmented state space is challenging, because the threshold above which the total cost matters (i.e., the VaR α for a preferred α) also needs to be estimated, and this estimation requires solving the augmented MDP, repeatedly, in an inner loop. Nonetheless, this alternative state augmentation seems to be useful in some circumstances, such as in finding the locally optimal CVaR-constrained policies as part of a policy gradient method <ref type="bibr" target="#b20">(Chow et al., 2017)</ref>. It would be interesting for future work to establish the formal connections between the two types of state augmentations (risk preference α and cumulative reward) and the relative benefits of each. Both quantities could be the target of model-based neuroimaging.  <ref type="bibr">Actions left, right, up,</ref> or down lead to the intended location with 90% probability (and to the each adjacent location with 3.33% probability). Here, the shortest path from the start (x 0 on the lower left) to the single rewarding state (on the lower right r(x) = 3) requires traversing perilously close to a dangerous cliff (r(x) = −1 states at the bottom). (a-b) For risk-neutrality (i.e.,ᾱ = α = 1; with nCVaR and pCVaR being expected values; top of the figure), the optimal stationary policy (white-on-black arrows) takes a direct, yet risky, route toward a goal. Higher risk sensitivity (e.g.,ᾱ = α = 0.3) encourage a more circuitous, and safer, route for both nCVaR and pCVaR. For nCVaR, the optimal policy for even higher risk sensitivity (ᾱ = 0.05; panel a), however, is much more conservative, under which it does not pursue the reward at all; in fact, in most states, all actions aside from going down are equivalently (sub)optimal, because they share the same 5% of worst case transitions. This is similar to the case where α = 0 in <ref type="figure">Figure 4</ref>. For visual convenience, the distorted transition probabilities (shown as grey arrows in earlier figures) are not depicted.</p><p>The question of how to apply CVaR, that is whether to apply it once at the start state or repeatedly (as in nested nCVaR), is also a general issue that has been extensively investigated in finance and operations research for a variety of risk measures (and general classes of risk measures) <ref type="bibr" target="#b5">(Artzner, Delbaen, Eber, Heath, &amp; Ku, 2007;</ref><ref type="bibr" target="#b12">Boda &amp; Filar, 2006;</ref><ref type="bibr">Hardy &amp; Wirch, 2004;</ref><ref type="bibr" target="#b39">Iancu, Petrik, &amp; Subramanian, 2015;</ref><ref type="bibr" target="#b58">Pflug &amp; Pichler, 2016;</ref><ref type="bibr" target="#b62">Roorda &amp; Schumacher, 2007;</ref><ref type="bibr" target="#b63">Rudloff, Street, &amp; Valladão, 2014;</ref><ref type="bibr" target="#b65">Schur, Gönsch, &amp; Hassler, 2019;</ref><ref type="bibr" target="#b66">Shapiro, 2009;</ref><ref type="bibr" target="#b68">Shapiro &amp; Xin, 2020)</ref>. In these communities, the discussion usually involves the notion of time-consistency (or inconsistency), for both risk evaluation and for risk-sensitive policies. However, these notions have been defined differently in different places, and a unified treatment is still needed (see Majumdar and Pavone 2020 for an introduction to the topic, and Shapiro et al. 2014 for more details). In our analysis, we saw that the precommitted objective (pCVaR) led to dynamic risk preferences-this would generally be considered a time-inconsistent evaluation of risk. However, we also saw that pCVaR had a stationary optimal policy in the augmented state space, and thus would probably be considered time-consistent in terms of policy. Nested CVaR (nCVaR), which is part of the broader class of risk measures, was defined specifically so that risk evaluations could be time-consistent (and risk preferences could be static). However, as we saw, these nested risk measures are more complicated to interpret and can sometimes lead to very conservative behavior. One possible reason for why the nested nCVaR may often be more conservative than the precommitted pCVaR is that pCVaR adjusts risks preferences both down (more conservatively) and up (more liberally) depending on whether recent events have been fortunate or unfortunate. This may act to balance the overall level of pessimism for the precommitted pCVaR, but not for the nested nCVaR, which lacks this bi-directional adjustment. Therefore, each approach might better address different problems <ref type="bibr" target="#b50">(Majumdar &amp; Pavone, 2020)</ref>, or as we might suggest, better fit the behavior of different individuals. It will be interesting for future psychological work to find scenarios or individual differences related to a tendency to apply one approach versus the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications for Behavior</head><p>Is there evidence that human behavior for sequential decisions reflects the type of risk sensitivity that CVaR (and optimal policies thereunder) suggests? Recently, Gagne and Dayan (2021) compared a traditional expected value model to a risk-sensitive CVaR model in the intensivelyinvestigated two-step sequential decision task <ref type="bibr" target="#b26">(Daw, Gershman, Seymour, Dayan, &amp; Dolan, 2011;</ref><ref type="bibr" target="#b33">Gillan, Kosinski, Whelan, Phelps, &amp; Daw, 2016)</ref>. They estimated α's for individual participants, observing many to have substantial risk aversion (α 1), and noted that failing to model this had previously led to biased estimates of perseveration and learning rates.</p><p>The two-step task has too few stages for differences between pCVaR and nCVaR to matter. Yet in more complex tasks, these approaches make distinct predictions for human behavior. The nested formulation of nCVaR (Equation 4) implies that risk compounds. Consider sequences of independent intermediate outcomes (denoted by R t in Equation 4) with negative α-tails, but with much higher chances of positive than negative outcomes. For nCVaR, adding more such gambles would increase risk, whereas for pCVaR, adding gambles with favorable, independent outcomes would always reduce risk (as in a well diversified financial portfolio). Similarly, as evident in <ref type="figure" target="#fig_3">Figures 4-5</ref>, nCVaR leads to more conservative behavior under the same nominal α. This effect was especially noticeable for α = 0.05, where the agent does not even pursue the reward more than once in <ref type="figure">Figure 4a</ref> or at all in <ref type="figure" target="#fig_3">Figure 5a</ref>. As we note below, nCVaR with this type of extreme conservatism may provide a natural basis for modeling pathological avoidance behaviors.</p><p>For pCVaR, many effects arise from precommitment's requirement that risk preferences adjust given the results of stochastic transitions. This includes behavior reminiscent of the infamous gambler's fallacy <ref type="bibr" target="#b18">(Chen, Moskowitz, &amp; Shue, 2016;</ref><ref type="bibr" target="#b23">Croson &amp; Sundali, 2005;</ref><ref type="bibr" target="#b43">Laplace, 1796)</ref>. That is, in the same way that a gambler who has been unfortunate (or fortunate) expects their luck to turn, a risk-sensitive pCVaR decision-maker who has already "consumed" their share of bad (or good luck) in historical transitions, can operate with less (or more) concern about risk; see for example the trajectory starting at 'example start' in <ref type="figure">Figure 4b</ref>, where the agent switches from pursuing the smaller safer reward to pursuing the larger riskier reward after experiencing two unfortunate transitions.</p><p>Success or failure to keep precommitments (or inaccurate approximations of the careful calculus necessary) can have prominent behavioral signatures. Thus, <ref type="bibr" target="#b31">Gagne and Dayan (2021)</ref> proposed a task in which participants could be occasionally 'knocked off course' into a higher risk area as they navigate to a goal; precommitment would mandate continued goal pursuit, whereas an nCVaR-like re-assessment of risk, using the same static risk preference on each time-step, would lead to goal abandonment and a directly opposite direction of travel. Equally, <ref type="bibr" target="#b40">Imas (2016)</ref> observed that individuals take on greater risk after a loss (i.e., exhibit the gambler's fallacy), only if that loss is not realized. Realizing a loss (i.e., being 'cashed out') may start a new decision period, distancing the decision maker from previous commitments, effectively resetting α.</p><p>More generally, we can expect a close relationship between sensitivity to risk of catastrophe and avoidance behaviour. Avoidance has been defined broadly as any action aimed at increasing distance (physical or psychological) between the agent and threat (actual or perceived) <ref type="bibr" target="#b3">(Arnaudova et al., 2017)</ref>. This may pertain to specific situations (e.g., social gatherings), locations (e.g., marketplaces), objects (e.g., foods), or activities (e.g., taking public transportation, conversing with a stranger, etc.). Dysfunctional avoidance behaviors are a hallmark of anxiety disorders (American Psychiatric Association, 2013; Hofmann &amp; Hay, 2018), especially social anxiety disorder, specific phobias, panic disorder and agoraphobia. One of the most extreme forms of avoidance, which is associated with agoraphobia, is the refusal to leave one's own home, resulting in individuals potentially being housebound for years <ref type="bibr" target="#b3">(Arnaudova et al., 2017)</ref>.</p><p>Here, we observed that increasing risk aversion (decreasing α) resulted in optimal policies that increasingly resembled the type of avoidance behaviors related to anxiety. In the 2-D cliff grid world, optimal risk-averse routes to the goal were circuitous, maintaining a substantial distance from the lava pit. This is reminiscent of real world avoidance behaviors, such as walking rather than taking public transportation (American Psychiatric Association, 2013). In the 1-D linear grid world, optimal policies were associated with the pursuit of the smaller, safer reward (far away from the lava pit), rather than the larger, riskier reward (right next to it). This resembles decisions observed in the lab made by anxious individuals, who tend to choose gambles with smaller, more certain monetary outcomes over gambles with larger, less certain ones <ref type="bibr" target="#b17">(Charpentier et al., 2017;</ref><ref type="bibr" target="#b60">Raghunathan &amp; Pham, 1999)</ref>. Though qualitative, these comparisons suggest CVaR as a unifying framework for modeling both real-world avoidance behaviors and lab-based risk-sensitive behavior.</p><p>As α approaches 0, optimal policies attempt to avoid any state with a non-zero chance of leading to the worst-case outcome. In this case, even behaviors that are considered extremely pathological, such as refusing to leave one's house in agoraphobia, could still be considered optimal solutions, albeit to an extreme (and arguably pathological) objective function. At α = 0, indifference can arise, with the values for all actions in our MDPs becoming equivalent due to the nature of stochasticity. This may separately lead to a lack of perceived control that often accompanies anxiety <ref type="bibr" target="#b32">(Gallagher, Bentley, &amp; Barlow, 2014)</ref>.</p><p>It might seem odd to relate the sort of optimal risk sensitivity that we have mostly discussed to the sort of pathological avoidance that is sufficiently dysfunctional to lead to diagnosis of a psychiatric condition. However, there are structurally different routes to dysfunction, including "solving the wrong problem" or "solving the right problem, but poorly" <ref type="bibr" target="#b38">(Huys, Guitart-Masip, Dolan, &amp; Dayan, 2015)</ref>. Under the former, values of parameters (in our case, very low α and the use of nCVaR) lead to subjectively optimal behavior that would be considered pathological by others (or the actor, in a different frame of mind). Indeed, the primary determination of whether behavior is deemed pathological (i.e., "out-of-proportion" to the actual danger) and whether it counts towards a diagnosis is made by the clinician 4 , not the individual. Thus, in the current section, we emphasized parallels between anxious pathology and optimal solutions under an extreme attitude towards risk-that is, correctly solving a problem that society deems to be the wrong one.</p><p>However, there are also cases in which incompetent solutions can lead to problems. For instance, the anxious might find it hard to stick to the precepts of pCVaR, even if they wanted to do so, by becoming relatively more risk seeking (i.e., closer to risk neutrality) following unfortunate events (thus staying close to the lava pit in the 1D task if they arrived there via unfortunate transitions). Rather, in a nCVaR-like manner (forᾱ ≤ 0.3 in that problem), they might apply their same risk-averse preference at each future decision consistently, regardless of what had occurred in the past and always moving away. Worse, they might be reluctant to adjust their risk preferences towards a more risk-seeking direction, but be fully willing to adjust it in the more risk-averse direction. These predictions-namely, that individuals with high trait-or pathological-levels of anxiety would be characterized not only by lower α's, but also a reluctance to adjust them (at least in the risk-seeking direction)-could be tested using tasks such as those discussed in the previous section.</p><p>Equally, in CVaR, we saw a boundary between the individual and the environment in which the former is trying to protect themselves against the vicissitudes of the latter-with amplified probabilities of unfortunate outcomes being the target of optimized protection. In terms of the "wrong solution", Zorowitz, <ref type="bibr">Momennejad, and Daw (2020)</ref> have recently suggested placing the distortion closer to home-suggesting that individuals are pessimistic about the future actions they will choose to take (e.g., favoring the worst, rather than the best). This could be associated with a sense of a lack of control or helplessness, something that commonly accompanies the anxious (and depressed) <ref type="bibr" target="#b0">(Abramson, Seligman, &amp; Teasdale, 1978)</ref>. We noted that pessmism over outcomes can also lead to a sense of uncontrollability (as was also noted by Zorowitz et al. 2020), because with stochasticity and extreme risk aversion (α = 0 in our problems), distortions favour the worst outcome, regardless of action choice. Both action-and outcome-directed pessimism are likely involved for anxious individuals. Indeed, those who are more anxious are more likely to endorse beliefs about having less control <ref type="bibr" target="#b32">(Gallagher et al., 2014)</ref> and they are more likely to over-estimate the probabilities for negative outcomes occurring across a wide variety of real-world-like scenarios <ref type="bibr" target="#b14">(Butler &amp; Mathews, 1983;</ref><ref type="bibr" target="#b48">MacLeod &amp; Byrne, 1996;</ref><ref type="bibr" target="#b57">Muris &amp; van der Heiden, 2006;</ref><ref type="bibr" target="#b70">Stöber, 1997)</ref>, especially for those negative outcomes that are more costly <ref type="bibr" target="#b9">(Berenbaum, Thompson, &amp; Pomerantz, 2007)</ref>. Exploring the formal and empirical relationships between these two types of pessimism would be an interesting direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Risk-sensitive Greedily Optimal Planning</head><p>In investigating optimal behavior, we have so far assumed that the optimal value function had been calculated using a standard type of offline planning algorithm (i.e., value iteration), which iterates over all possible states and risk preference levels and updates their values using the Bellman equations (Equations 16 and 15). However, not all states are equally important at each step in this process, and planning can be made more efficient by prioritizing the order of these updates <ref type="bibr" target="#b56">(Moore &amp; Atkeson, 1993;</ref><ref type="bibr" target="#b76">Van Seijen &amp; Sutton, 2013)</ref>. Greedily optimal planning corresponds to choosing at each planning step the update with the largest expected increase in value <ref type="bibr" target="#b53">(Mattar &amp; Daw, 2018)</ref>. Although this is a theoretical ideal-calculating it exactly requires more work than planning-it has proved fruitful as a way of characterizing various neural phenomena. That is, findings such as replay and preplay, have been argued to reflect (near) optimally prioritized memory access or planning <ref type="bibr" target="#b53">(Mattar &amp; Daw, 2018)</ref>. So far, however, optimal planning has only been examined without consideration of risk preferences. In this section, we explore how optimal planning differs under different risk preferences. Since replay and preplay can be seen as forms of rumination, this allows us to examine whether enhanced risk aversion has consequences for negative rumination in the same way it does for anxiety and avoidance.</p><p>We restrict our attention to a prioritized form of the planning algorithm known as value iteration. However, the analysis and simulations presented here could easily be extended to other types of planning methods, especially those which use a model of the environment or past experiences to update a value function. We consider a type of planning that iteratively updates the nCVaR (or pCVaR) value function at only a single state x (or single augmented state (x, α)) for each step k in the planning process (see Appendix C for details). As a result of each update, the policy changes at that state to πᾱ(a|x) → π ᾱ (a|x) (or π(a|x, α) → π (a|x, α)), as the current action is replaced with the best action in that state. In the case of a tie between actions, the policy chooses uniformly at random among the best actions.</p><p>Greedily optimal planning consists of choosing, at each step k, the update that produces the largest increase to the nCVaR (pCVaR) value function for the start state x 0 and preferred risk preferenceᾱ (α 0 ). More specifically, for nCVaR, the optimal next state x * to plan in is that which maximizes the following over all possible x states:</p><formula xml:id="formula_12">x * = argmax x [nCVaR π ᾱ,x 0 ,k − nCVaR π α,x 0 ,k−1 ]<label>(10)</label></formula><p>For pCVaR, the optimal next state (x * , α * ) to plan in is that which maximizes the following over all possible augmented (x, α) states:</p><formula xml:id="formula_13">(x * , α * ) = argmax x,α [pCVaR π α 0 ,x 0 ,k − pCVaR π α 0 ,x 0 ,k−1]<label>(11)</label></formula><p>The difference between Equations 10 and 11 is that in the latter, risk preferences deviate after the start state, so the planner might perform an update at a risk sensitivity that differs from α 0 . To obtain the optimal next state for planning, we enumerate all possible states x (or (x, α)), perform the update hypothetically (Equation 14), and then compare the true value of the resulting policy to the true value of the current policy (Equations 10-11). Only the best of these hypothetical updates is actually implemented, moving the planning process to step k−1 → k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1D world</head><p>We first examined the result of nCVaR greedily optimal planning in the 1-D grid world. Here, the planning process was initialized with a uniformly random policy and a value function equal to zero (except at states with rewards, which were used to initialize the values). The first several updates (k = 1 to 6) for five possible risk preferences (ᾱ's) can be seen in <ref type="figure">Figure 6a</ref>. Here, the optimal planning for a risk-neutral preference (ᾱ = 1) forms a direct path, in reverse, to the larger, riskier reward. For risk-averse preferences, the optimal planning sequence differs depending on the degree of risk aversion. For moderate levels (ᾱ = 0.3 andᾱ = 0.6), optimal planning focuses first on how to safely obtain the reward on the left (should the decision maker be there), and then works out how to obtain the smaller reward on the right. For greater risk aversion (ᾱ = 0.1 or α = 0.05), optimal planning spends the first five updates ensuring that it stays far away from the worst-case outcome.</p><p>For contrast, the first several updates (k = 1 to 6) for pCVaR are shown in <ref type="figure">Figure 7</ref> for three different preferred risk preferences (α 0 = 0.05, 0.3, 1). Risk neutral optimal planning <ref type="figure">(Figure  7a</ref>) is the same as for nCVaR. In both risk-averse cases <ref type="figure">(Figure 7b,c)</ref>, optimal planning focuses on the location adjacent to the worst-case outcome (the lava pit), before planning a route towards the smaller, safer reward on the right. A notable feature of risk-averse optimal planning is that initial updates are not all performed at the preferred risk preference α 0 . Rather, they are performed at higher values for α, because this is where the agent expects to be under the initially random policy, as we saw during policy evaluation <ref type="figure">(Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2D world</head><p>The difference between the risk-neutral and risk-averse optimal planning becomes more salient in a larger state space. In another simple 2-D environment shown in <ref type="figure">Figure 6b</ref>, riskneutral optimal planning again forms a direct path to the reward, whereas risk-averse optimal planning under nested nCVaR focuses entirely on avoiding the pit. Moreover, there is an interesting asymmetry between risk-neutral and risk-averse optimal planning. Risk-neutral planning focuses on a single route, even though the decision maker may occasionally get knocked off course. In the risk-averse planning, however, getting knocked off course is exactly what needs to be considered. That is, risk-averse planning needs to enumerate and deal with the many possible paths that could lead to the worst-case outcome, even those that are highly unlikely (e.g., getting to the pit via the top left corner). One can imagine that as the state space gets larger and the number of routes to catastrophe grow, much more time is required for optimal risk-averse planning to be effective (i.e., to increase nested nCVaR substantially).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristic prioritization</head><p>Prior to considering the relationship between planning, worry and rumination, we should comment on the apparent lack of a practical or neurobiologically plausible algorithm for calculating the risk-sensitive greedily optimal offline planning (i.e., replay and preplay)-our simulations were based on an effective yet brute force approach. In this way, our work is similar to previous analyses <ref type="bibr" target="#b53">(Mattar &amp; Daw, 2018)</ref>. However, it is useful to consider some potential heuristics. For instance, states (and/or state-action pairs) might be tagged with a high priority when surprising outcomes are encountered in them during planning. This is the basis of an algorithm known as prioritized sweeping, in which tagging is based on unsigned prediction errors; and priority is also extended to any predecessor states <ref type="bibr" target="#b56">(Moore &amp; Atkeson, 1993)</ref>. As a result, planning spends more time on states that are more likely to have an impact. Furthermore, there is some evidence that the brain is utilizing such a heuristic, given that replay-like re-evaluation has been shown to be more likely following large unsigned prediction errors <ref type="bibr" target="#b55">(Momennejad, Otto, Daw, &amp; Norman, 2018)</ref>.</p><p>For risk-sensitive (CVaR) planning, tagging surprising states could also be a useful heuristic, but the notion of surprise (or absolute prediction error) would have to be restricted in scope to the lower tail of the distribution. However, this alone would not be enough. For precommitted pCVaR, we saw that the percent of the tail that was relevant to the start state (on which prioritization was</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Risk-sensitive greedily optimal planning for nested nCVaR. Offline planning can be optimized by choosing the next state x to plan in that leads to the greatest increase in the nested nCVaR associated with the start state (state x 0 and the preferred risk preferenceᾱ). The optimal planning sequence is depicted using numbers in the top right-hand corner of each state; only the first few planning steps are shown. (a) Optimal planning is shown for the same 1-D example as before. At a preferred risk preference ofᾱ = 1, the optimal planning sequence replays, in reverse, states leading up to the larger reward. This type of replay behavior is seen in risk-neutral optimal planning, initially proposed in <ref type="bibr" target="#b53">Mattar and Daw (2018)</ref>. Atᾱ = 0.3, the planning focuses mostly on how to obtain the smaller, safer reward on the right-hand side. And atᾱ = 0.05, the replay focuses mostly on how to avoid the pit. Note that forᾱ = 0, all planning sequences are equivalently, yet trivially, (greedily) optimal, because every action in each state has the same true worst-case value. (b) Optimal planning is shown for a 2-D grid world to emphasize the differences between risk-averse and riskneutral planning. In this MDP, possible actions are to go left, right, up or down, each leading to the intended location with 90% probability. Similarly to the 1-D case, the probabilities for unintended transitions were asymmetrically assigned; for example, the go right action would transition up or down with 4% probability and would transition to the left with 2% probability. In this MDP, risk-neutral optimal planning forms a direct path to the reward, whereas risk-averse optimal planning focuses on how to avoid the pit from every possible angle.</p><p>based) depended on how you expected to get there (i.e., on the adjusted risk preference). This also holds true for nested nCVaR. Even though theᾱ-percentage stayed fixed, a change in theᾱ-tail in some distal states may still have very little impact on the start state if the outcomes in these states are all relatively benign. Therefore, for both approaches, the degree of relevance of a distal state (in which a tail-surprising outcome may occur) to the start state still needs to be estimated. For this, it might be useful to think about distilling the distorted transition probability matrices into something that estimated the distorted likelihood of visiting a distal state from the start statethis would look something like a distorted version of the successor representation <ref type="bibr" target="#b27">(Dayan, 1993)</ref>, an undistorted version of which has been proposed to be represented in the brain to support a wide variety of functions <ref type="bibr" target="#b69">(Stachenfeld, Botvinick, &amp; Gershman, 2017)</ref>. Although such a representation might be a useful heuristic, it itself would need to be updated, at least occasionally, throughout</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 7</head><p>Risk-sensitive greedily optimal planning for precommitted pCVaR. Offline planning can be optimized by choosing the next augmented state (state x and risk preference α) to plan in that leads to the greatest increase in the pCVaR associated with the start state x 0 and initial risk preference α 0 . The optimal planning sequence is depicted using numbers in the top right-hand corner of each state; only the first six planning steps are shown. (a) At a preferred risk preference of α 0 = 1 (i.e., risk-neutral), optimal planning stays at the risk-neutral preference and replays states, in reverse, that lead to the higher reward. (b-c) At the preferred risk preferences of α 0 = 0.3 and α = 0.05, the optimal planning sequence first replays states adjacent to the lava pit, across multiple risk preferences. This is because the α-level CVaR α (at low values for α) for the initially random policy depends largely on this state at higher risk preferences; refer to <ref type="figure">Figure 3</ref> and follow the distorted probabilities from the start state. Note that in both these cases, the optimal action taken in these states is often the riskier action of staying put to collect the larger reward. This reflects the fact that the decision maker is constructing dynamic risk preference policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>planning.</head><p>These two heuristics: paying attention to large local changes in value and paying attention to states likely to be visited from the states driving prioritization (i.e., the start state), parallel the components of greedily optimal prioritization analyzed in <ref type="bibr" target="#b53">Mattar and Daw (2018)</ref>, which were called gain and need respectively. Developing further algorithmic heuristics for CVaR planning and establishing their connection to greedily optimal prioritization remains a priority for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications for Anxious Rumination and Worry</head><p>In this section, we consider how the patterns of imagined experiences under CVaR greedily optimal planning examined in the previous section resemble pathological thought processes, such as worry, in anxiety. We propose that more extreme (and even pathological) worries, like avoidance behaviors, might relate to both an increase in risk sensitivity (i.e., lower α values) and a tendency to re-evaluate risk at each point in time (i.e., nested nCVaR). These imagined experiences, aimed at improving the policy, are identified as ruminations and worries -if risk aversion makes them concern very negative states, then the subjective experience of such anxious rumination will be assumed to be highly aversive.</p><p>Worry is often described as a chain of thoughts laden with negative affect (often in the form of "what-if" questions) related to risks, possible threats, or potential catastrophes <ref type="bibr" target="#b13">(Borkovec, Robinson, Pruzinsky, &amp; DePree, 1983;</ref><ref type="bibr" target="#b25">Davey &amp; Meeten, 2016;</ref><ref type="bibr" target="#b35">Hirsch &amp; Mathews, 2012;</ref><ref type="bibr" target="#b79">Watkins, 2008)</ref>. It has also been described as an attempt to engage in mental problem-solving in order to avoid or prevent these negative outcomes from occurring <ref type="bibr" target="#b13">(Borkovec et al., 1983;</ref><ref type="bibr" target="#b79">Watkins, 2008;</ref><ref type="bibr" target="#b80">Wells, 1999)</ref>. Described in this manner, it is easy to see how some forms of worry could be adaptive <ref type="bibr" target="#b73">(Tallis &amp; Eysenck, 1994)</ref>. However, worry can also become pathological and is a prominent characteristic of many anxiety disorders (including being the defining feature of generalized anxiety disorder (GAD)). In contrast to non-pathological worry, pathological worry is often characterized as being more frequent, longer lasting, more distressing, disruptive to everyday functioning, and perceived as uncontrollable <ref type="bibr">(American Psychiatric Association, 2013;</ref><ref type="bibr" target="#b25">Davey &amp; Meeten, 2016;</ref><ref type="bibr" target="#b35">Hirsch &amp; Mathews, 2012)</ref>.</p><p>In our examination of greedily optimal planning, we observed that sequences of prioritized planning operations tended to focus more on states associated with the worst-case outcome (i.e., states adjacent to the lava pit) for risk-averse preferences compared to a risk-neutral preference. This was observed in both nested nCVaR planning ( <ref type="figure">Figure 6</ref>, specifically panel b) and in precommitted pCVaR planning <ref type="figure">(Figure 7)</ref>. In this regard, risk-averse greedily optimal planning shares the content bias related to potential danger, threats, and catastrophes that distinguishes worry from other types of less-anxious thoughts or problem-solving. Here, this bias can be seen as a natural consequence of evaluating the potential policy improvements (i.e., planning steps) based on the lower tail of the return distribution; planning in states associated with negative outcomes (at least those that are relevant to the start state) is more likely to improve the negative tail than is planning in states with mediocre outcomes or high rewards. In CVaR, this tail is relative to the overall return distribution; however, essentially no natural environment will only contain zero or appetitive outcomes, so the lower tail will indeed be negative.</p><p>The degree and nature of the negative content bias also depended on the level α (in a more continuous way). Generally, as α is decreased, potential policies are evaluated based on smaller sets of outcomes, i.e. the shrinking lower tail of the return distribution. Only states that could affect those outcomes are relevant for planning and are prioritized. One consequence of this, as we observed, is that at lower α levels, it takes more steps for planning to switch from states near the lava pit, with its negative value, to states near the smaller, safer positive outcome. We observed this for both the nested nCVaR planning and precommitted pCVaR planning for α = 0.3 relative to α = 0.05 (although the effect is much more salient for the nested nCVaR planning). If we identify worry specifically with planning associated with objectively negative values, then individuals with lower levels of α would experience more or longer-lasting worry (before switching to other types of planning or problem-solving associated with the positive outcome), which is one differentiator of pathological from non-pathological worry. Relatedly, in environments with many potential negative and positive outcomes, lower α's will focus planning towards the worst possible of those outcomes. Thus a low α could also be related to the type of pathological worry known as catastrophizing, which often involves worst-case answers to "what-if" questions <ref type="bibr" target="#b25">(Davey &amp; Meeten, 2016)</ref>, or to negative intrusions that are objectively more negative in content (e.g., serious illness, attack, etc; Hirsch, Mathews, Lequertier, Perman, and Hayes 2013), as observed in some patients with GAD relative to non-GAD high worriers.</p><p>Similarly to optimal policies, greedily optimal planning under precommitted pCVaR seemed to be rather liberal in certain circumstances. For instance in <ref type="figure">Figure 7</ref>, the agent imagined acting in a relatively risk-seeking way, trying to stay in the state next to the lava pit. In contrast, nested nCVaR planning seemed more characteristically anxious in that it imagined acting in a consistently avoidant way. Thus, we suggest that the "wrong problem" <ref type="bibr" target="#b38">(Huys et al., 2015)</ref> associated with both anxious behavior and worry includes the method of application of risk preferences (nCVaR or pCVaR) in addition to the level of risk aversion (i.e., α).</p><p>High trait worriers and those with GAD also often report that they do not have control over the initiation of the worry process and find it very difficult to stop worrying having started <ref type="bibr" target="#b25">(Davey &amp; Meeten, 2016)</ref>. These phenomena could potentially be accounted for via a meta-level optimization problem, trading-off planning and behaving <ref type="bibr" target="#b1">(Agrawal, Mattar, Cohen, &amp; Daw, 2021)</ref>. Here, at each point in time, a meta-level decision would be made whether it would be better to focus on improving the policy (to plan) or to use it (to act). The criterion for this meta-level decision could be the CVaR (pCVaR or nCVaR) of the policy, but perhaps defined in terms of a time-average, rather than infinite horizon. In situations in which the immediate surroundings are safe, our prediction would be that the meta-decision would favor planning over behaving, especially in individuals with low values for α-this is because you can always imagine being near to disaster (and potentially doing something about it) even if none of your current actions are relevant. Interestingly, most worries occur at night and in the bedroom <ref type="bibr" target="#b72">(Tallis, Davey, &amp; Capuzzo, 1994)</ref>, a location where any immediate actions would presumably do little to mitigate the worst-case risks. For this type of worry, it seems especially important to model risk and decisions sequentially, because the threat is remote and is likely to depend on many future states and actions.</p><p>Furthermore, pathological worry is more frequent than non-pathological worry, and, in particular, can also involve repeatedly thinking about the same negative outcome in the same situation across separate worry sessions <ref type="bibr" target="#b8">(Berenbaum, 2010)</ref>. Our simulations do not reproduce this, since planning was always taken to be successful. However, in terms of the "wrong solution" of <ref type="bibr" target="#b38">Huys et al. (2015)</ref>, this may not be true in anxiety. Indeed, many models of pathological worry (and of GAD more broadly; <ref type="bibr" target="#b13">Borkovec et al. 1983;</ref><ref type="bibr" target="#b80">Wells 1999</ref>; for a review, see <ref type="bibr" target="#b6">Behar, DiMarco, Hekler, Mohlman, and Staples 2009)</ref> argue that pathological worries are largely unsuccessful at generating plans or courses of behavior that would actually solve the problems that trigger them. One proposed reason for this is that worries themselves are suppressed (or pruned) once they are triggered and this precludes the processing necessary to work out a solution <ref type="bibr" target="#b13">(Borkovec et al., 1983;</ref><ref type="bibr" target="#b28">Dayan &amp; Huys, 2008)</ref>. Another possibility is that there is conflict between multiple systems that impedes success. For example, one system might be driven to avoid extreme risks, whereas another system might recognize the unacceptability of this objective from an outside perspective, thus halting risk-averse planning before it is completed. Indeed, many GAD patients simultaneously hold both positive and negative beliefs about worry <ref type="bibr" target="#b6">(Behar et al., 2009;</ref><ref type="bibr" target="#b80">Wells, 1999)</ref>, the latter of which is often described as "worry about worry". From this perspective, pathological worry is an example of the malign fusion of "solving the wrong problem" and "solving the right problem, poorly" in which the wrong problem is itself incompetently, and thus incompletely, solved.</p><p>If worry, at least in part, does reflect risk-sensitive greedily optimal planning, how could this be tested? One possibility is to look for biases in offline neural processes, such as replay, preplay, or default mode processing. Recently, it was proposed that patterns of replay and preplay reflect (greedily) optimal planning <ref type="bibr" target="#b53">(Mattar &amp; Daw, 2018)</ref>, and this has been supported by observations both in rodents and in humans <ref type="bibr" target="#b47">(Liu, Mattar, Behrens, Daw, &amp; Dolan, 2020;</ref><ref type="bibr" target="#b53">Mattar &amp; Daw, 2018)</ref>. However, so far, the theory has considered optimal planning only under expected value. Extending it to include differences in risk sensitivity, as we do here, predicts that patterns of replay and preplay should also differ according to how much decisions are driven by negative tail outcomes (i.e., CVaRs at lower values for α). One obvious prediction from this would be that individuals with risk-sensitive preferences would show a bias in replaying or preplaying negative outcomes, especially worst-case outcomes. This could be explored in the types of sequential decision making tasks previously used <ref type="bibr" target="#b29">(Eldar, Lièvre, Dayan, &amp; Dolan, 2020;</ref><ref type="bibr" target="#b47">Liu et al., 2020)</ref>, although more extreme negative outcomes might need to be included. Relatedly, we might expect to see a similar bias in rodents with anxious phenotypes-these could be assayed using the elevated plus maze or the open field test <ref type="bibr" target="#b16">(Calhoon &amp; Tye, 2015)</ref> and replays related to negative outcomes (e.g., shocks) could be examined in paradigms such as C.-T. <ref type="bibr">Wu, Haggerty, Kemere, and Ji (2017)</ref>, in which replay was shown to support the planning of the avoidant behavior (i.e., avoidance of the shocked locations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary and Conclusion</head><p>In this paper, we showed how sequential decision making under risk can be formalized using conditional value-at-risk (CVaR) and drew out psychological implications, especially for anxiety, risk-avoidant behavior and worry.</p><p>We showed how individual sensitivities to "outcomes that hurt the most" relate to the CVaR's risk sensitivity parameter α. More specifically, we saw how lower values for α gave rise to optimal behavior that matches intuitive notions of risk avoidance and to greedily optimal planning that resembles worry. Consequently, we proposed that α could be one key axis of individual variation for anxiety. We also discussed two possible approaches for evaluating risk in sequential choice. We referred to these as nested (nCVaR) and precommitted pnCVaR) approaches, because of the manner in which CVaR was applied to the stream of future rewards. For the nested approach, CVaR was repeatedly re-applied at every point in time, whereas for the precommitted approach, CVaR was applied to the entire discounted reward sequence (i.e., the return) from the perspective of the start. For the former, risk preferences remain fixed at a preferred level ofᾱ, but risk could no longer be evaluated with respect to a single return distribution, and optimal policies and greedily optimal planning could become highly avoidant. For the latter, risk preferences had to be dynamically adjusted for both risk evaluation and for the optimal policy, and resulted in behavior that resembled a sequential form of the gambler's fallacy. We proposed that this difference in the way in which CVaR is applied (in a nested or precommitted manner) could be a second important axis along which to discriminate non-anxious from anxious behavior and thoughts, with avoidance behavior and worry more closely aligned with the former. neural activity and choice. PloS one, 6 (2), e16838. <ref type="bibr">Wu, C.-T., Haggerty, D., Kemere, C., &amp; Ji, D. (2017)</ref>. Hippocampal awake replay in fear memory retrieval. Nature neuroscience, 20 (4), 571-580. <ref type="bibr">Yaari, M. E. (1987)</ref>. The dual theory of choice under risk. Econometrica: Journal of the <ref type="bibr">Econometric Society, 95-115. Zorowitz, S., Momennejad, I., &amp; Daw, N. D. (2020)</ref>. Anxiety, avoidance, and sequential evaluation.</p><p>Computational Psychiatry, 4 , 1-17.</p><p>For the optimal policy, the following interpolated and update version of the pCVaR Bellman optimality equation <ref type="formula" target="#formula_16">Equation 16</ref> </p><p>Similarly to risk evaluation, the value function is initialized to zero and Equation 14 is applied iteratively until convergence, with a threshold of 10e-5. Note that in this equation the stationary policy π(a|x, α) is implicitly changing with each iteration because of the max over actions, hence the change from π → π . <ref type="bibr" target="#b21">Chow et al. (2015)</ref> provide some key theoretical results about the correctness of this interpolation procedure. Importantly, they show that the error introduced by the interpolation (with respect to the true optimal value function) is bounded, and that this error goes to zero when the number of interpolation points is arbitrarily large. Establishing the bound on the interpolation error involves logarithmically-spaced interpolation points, which is why they chose 21 log-spaced interpolation points from 0 to 1 for α. Although we used fewer values of α for illustration purposes, we also ran each of the simulations using the same 21 interpolation points. Doing so and looking at the closest values in this larger set to those in our smaller set yielded the same results as we have shown. We refer the reader to <ref type="bibr" target="#b21">Chow et al. (2015)</ref> for more details.</p><p>For nested nCVaR, we used the same values of [0, 0.05, 0.1, 0.3, 0.6, 1] forᾱ. However, interpolation is not needed between these values, becauseᾱ remains the same on both sides of the Bellman equations (Equation 6 and Equation 15), implying that they can be solved completely separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B Optimal policies for nested nCVaR and precommitted pCVaR</head><p>The optimal policy for nCVaR can be solved for using another version of the maximin Bellman optimality equation <ref type="bibr" target="#b64">(Ruszczyński, 2010;</ref><ref type="bibr" target="#b74">Tamar, Chow, Ghavamzadeh, &amp; Mannor, 2016)</ref>, including the probability distortion weights as in Equation 6. </p><p>This equation can again be solved iteratively, for example, by using a form of value iteration. 5 The same is true for calculating the pCVaR optimal policy, again relating the optimal pC-VaR value at each augmented state (α, x) to the optimal pCVaR value at each possible subsequent augmented state (α , x ):</p><formula xml:id="formula_16">pCVaR * α,x = max a r(x) + γ min ξ∈U (α) x p(x |x, a)ξ(x |x)pCVaR * αξ(x |x),x<label>(16)</label></formula><p>Once again, an interpolated version of this pCVaR equation (Equation 14; Appendix A) is used when solving iteratively for the optimal policy to deal with the fact that α is continuous.</p><p>For pCVaR, the optimal distortion weights ξ * are used to adjust the risk preference dynamically as the decision maker interacts with the world. More specifically, in order to maximize the objective (9) having started in X 0 = x 0 with initial risk preference α 0 , the decision maker would take the first action according to π * (a|x 0 , α 0 ). The risk preference would then be adjusted ξ * (X t |X t−1 )α t−1 → α t for each state transition X t−1 → X t , and the optimal stationary policy would continue to be used in each resulting augmented state π * (a|X t , α t ). This procedure would effectively generate the optimal history-dependent policy, from the perspective of the environment's state space X , that maximizes the precommitted pCVaR for the start state x 0 and initial risk preference α 0 .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Using CVaR to formalize risk preferences for a single choice. (a) Distribution of potential outcomes z for which the decision maker aims to evaluate the risk. CVaR (black dashed line) is defined as the expected value of the outcomes in the lower α-percentage of the distribution. (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Bellman equation (Equation 3) with no intermediate rewards or discounting. This gives the values of both nCVaR π 1,s = pCVaR π 1,s = v π (s). Next, consider calculating the nCVaRᾱ =0.1,s for the root s using Equation 6. The bottom 10% of the distribution of outcomes for s only includes possible outcomes from branch b. In</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Using CVaR to evaluate risk in a simple sequential setting. (a) In this simple example, the decision maker starts at the root (or start) s of a two-stage tree and transitions to one of two possible branches b or g with probabilities p(b|s) = 0.1 and p(g|s) = 0.9. Because each branch is associated with a distribution of possible outcomes, the start is associated with the mixture of these distributions. (b) The differences between the precommitted (pCVaR) and nested (nCVaR) approaches for applying CVaR to the sequential setting are shown. For the calculations of both the 10%-level pCVaR α0=0.1 and the 10%-level nCVaRᾱ =0.1 at the start s, the distortion weights are set to ξ(b|s) = 10 and ξ(g|s) = 0-this is because the bottom of s's distribution consists only of outcomes from the bad branch b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>Risk-sensitive (CVaR) optimal policies in a 2-D problem. The optimal policies for the nested nCVaR and precommitted pCVaR approaches to risk are shown for a 2-D grid-world MDP.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For discrete random variables, if the VaR falls exactly on one of the values for the random variable Z, a different definition is used; see<ref type="bibr" target="#b21">Chow et al. (2015)</ref>. However, this alternative definition is not crucial to the ideas presented in this paper. Note that it is also possible to formalize risk-seeking preferences using CVaR by considering the upper, instead of the lower, tail of the distribution, but here we focus on the spectrum of preferences between extreme risk aversion and risk neutrality. Of course, if the random variable is a cost rather than a reward (as is frequently true in financial applications), risk-aversion is associated with the upper tail.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In practice, since α is continuous between 0 and 1, this system of equations is represented and solved explicitly only for a finite set of α values and is interpolated for points in between<ref type="bibr" target="#b21">(Chow et al., 2015)</ref>; we provide details for this interpolation procedure in Appendix A. Furthermore augmentation is not required for α0 = 1, since U(1) does not allow any distortion, or for α0 = 0 case<ref type="bibr" target="#b34">(Heger, 1994;</ref><ref type="bibr" target="#b54">Mihatsch &amp; Neuneier, 2002)</ref>, since distortion is always maximal.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">In this example, the adjusted risk preferences are, serendipitously, 0.6 and 0.6 to several decimal places. However, in most cases the adjusted risk preferences do not correspond exactly to one of the 6 levels for α. In these cases, the arrows inFigure 4point towards the closest α level.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Similarly to the evaluation case (Equation 7), This leads to a set of optimal values nCVaR * α,x , actions a * , and distortion weights ξ * , for each location x and risk preferenceᾱ, which together satisfy this equation. The optimal actions form the optimal nCVaR stationary policy π * α (a|x).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>CG and PD are funded by the Max Planck Society. PD is also funded by the Alexander von Humboldt Foundation. We would like to thank Rani Moran for his helpful comments on an earlier version of this manuscript.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare that they have no conflict of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Code Availability Statement</head><p>The code used for the simulations in this paper will be made available in a public repository (The Open Science Framework) following publication of this manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A A. Using linear interpolation to estimate the precommitted pCVaR value function</head><p>For evaluating risk and calculating optimal behavior under pCVaR, the state space was augmented to include the dimension of possible risk preferences, α. Since α is continuous between 0 and 1 (including these endpoints), the value functions in Equation 7 and Equation 16 cannot be represented explicitly. The standard way to overcome this issue is to represent the value functions for a finite set of α values and use interpolation for points in between. Such interpolation schemes make all the value functions only approximate; however, if the values are sufficiently smooth and there is an adequate number of interpolation points, then the error can be small. <ref type="bibr" target="#b21">Chow et al. (2015)</ref> used 21 log-spaced values between 0 and 1 as interpolation points for α. For our simulations, we used [0, 0.05, 0.1, 0.3, 0.6, 1]. We chose these points in order to highlight the most interesting phenomena in our simulations. We also checked (data not shown), that these phenomena were generally robust, using different sets of interpolation points.</p><p>We follow Chow et al. <ref type="formula">2015</ref>'s algorithm for interpolation. Its most salient feature is that interpolation is applied to the value function multiplied by the risk preference, that is α pCVaR π α,x , rather than the pCVaR π α,x on its own. This is because the former is piece-wise linear in α and because its Lipschitz property is preserved during Bellman fixed-point iteration. These properties allow for a bound to be derived for the interpolation error (we discuss fixed-point iteration and interpolation error below).</p><p>Slightly adjusting the notation from Chow et al. <ref type="formula">2015</ref>, we denote the linear interpolation of α pCVaR π α,x as I[pCVaR π α,x ] and define it as follows:</p><p>where α i and α i+1 represent the closest interpolation points on either side of the input value α.</p><p>To calculate the value function during risk evaluation or for the optimal policy, interpolated versions of the Equation 7 and Equation 16 are used (leading to Equation 13 and Equation 14, respectively). We discuss the details of each next.</p><p>For the evaluation of risk for a fixed policy π, the value function pCVaR π α,x,k is first initialized (i.e., k = 0) across all α's to be zero. Next, the policy-induced transition dynamics p π (x |x) are calculated. Then, the following interpolated, update-based (marked by the leftwards arrow), version of the pCVaR Bellman equation is applied to each state x and to each risk preference α in the interpolation set:</p><p>Note that the distortion weights are no longer used explicitly to multiply the probabilities; these weights are implicit because the interpolation is defined for α × pCVaR π α,x , and the α here is αξ(x |x) in the equation above. This update is repeated, for steps k = 1, 2, . . . , until convergence (i.e., until an approximate fixed point is reached). A convergence threshold of 10e-5 was used for our simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C Greedily Optimal planning for nested nCVaR and precommitted pCVaR</head><p>The type of planning we consider involves iterative updates to the nCVaR value function at only a single state x for each planning step k using the following version of Equation 15:</p><p>The difference between Equation 15 and Equation 17 is that the latter (planning equation) indexes the value function at each planning step k and describes an algorithmic process, whereas the former (optimality equation) describes the relationships between the CVaR values at different augmented states that must hold true for a policy to be optimal. Greedily optimal planning for nCVaR consists of scheduling the individual planning steps according to criterion given in Equation 10-that is, the next state x * chosen to plan in is that which maximizes the nCVaR for the start state x 0 and preferred risk preferenceᾱ over all possible states x.</p><p>For pCVaR, the value function is similarly updated at only a single augmented state (x, α) using the interpolated and update version of the pCVaR optimality equation <ref type="formula">Equation 14</ref>. Greedily optimal planning for pCVaR similarly consists of using the criterion given in Equation 11 to prioritize individual planning operations (at augmented states (x, α)). This procedure contrasts with that of using value iteration to calculate the optimal policy, which updates the value function (also using Equation 14) sequentially and uniformly for all states, until convergence.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learned helplessness in humans: critique and reformulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Y</forename><surname>Abramson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Seligman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Teasdale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of abnormal psychology</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">49</biblScope>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The temporal dynamics of opportunity costs: A normative account of cognitive fatigue and boredom</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Diagnostic and statistical manual of mental disorders (DSM-5)</title>
	</analytic>
	<monogr>
		<title level="j">American Psychiatric Association</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pathways towards the proliferation of avoidance in anxiety and implications for treatment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Arnaudova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kindt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fanselow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Beckers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behaviour Research and Therapy</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Coherent measures of risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Artzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Delbaen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Eber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">mathematical Finance</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="228" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coherent multiperiod risk adjusted values and Bellman&apos;s principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Artzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Delbaen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Eber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ku</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="22" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Current theoretical models of generalized anxiety disorder (GAD): Conceptual review and treatment implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Behar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Dimarco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Hekler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mohlman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Staples</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of anxiety disorders</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1011" to="1023" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the theory of dynamic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="1952" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">716</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An initiation-termination two-phase model of worrying</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Berenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychology Review</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="962" to="975" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The relation between worrying and concerns: The importance of perceived probability and cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Berenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Pomerantz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behaviour Research and Therapy</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="311" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<title level="m">Dynamic programming and optimal control</title>
		<meeting><address><addrLine>Belmont, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Athena scientific</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">New paradoxes of risky decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Birnbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">463</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Time consistent dynamic risk measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Boda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Filar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Methods of Operations Research</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="169" to="186" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Preliminary exploration of worry: Some characteristics and processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Borkovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pruzinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Depree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behaviour research and therapy</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cognitive processes in anxiety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mathews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in behaviour research and therapy</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="51" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Markov Decision Processes with Average-Value-at-Risk criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bäuerle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Methods of Operations Research</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="361" to="379" />
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Resolving the neural circuits of anxiety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Calhoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Tye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1394" to="1404" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Enhanced risk aversion, but not loss aversion, in unmedicated pathological anxiety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Charpentier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aylward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Roiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">J</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Psychiatry</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1014" to="1022" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decision making under the gambler&apos;s fallacy: Evidence from asylum judges, loan officers, and baseball umpires</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Moskowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1181" to="1242" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Consistency and heterogeneity of individual behavior under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kariv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American economic review</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1921" to="1938" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Risk-constrained reinforcement learning with percentile risk criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Janson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6070" to="6120" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Risk-sensitive and robust decision-making: a cvar optimization approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1522" to="1530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Risk-sensitive and minimax control of discrete-time, finite-state Markov decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Coraluppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="309" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The gambler&apos;s fallacy and the hot hand: Empirical data from casinos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Croson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sundali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of risk and uncertainty</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="195" to="209" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.06923</idno>
		<title level="m">Implicit quantile networks for distributional reinforcement learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The perseverative worry bout: a review of cognitive, affective and motivational factors that contribute to worry perseveration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meeten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological psychology</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="233" to="243" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Model-based influences on humans&apos; choices and striatal prediction errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1204" to="1215" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving generalization for temporal difference learning: The successor representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="613" to="624" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Serotonin, inhibition, and negative mood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Huys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The roles of online and offline replay in planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lièvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>BioRxiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Decision under risk: From the field to the laboratory and back. The Wiley Blackwell handbook of judgment and decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Erner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Walters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="43" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Two steps to risk sensitivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gagne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Perceived control and vulnerability to anxiety disorders: A meta-analytic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Bentley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Barlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive therapy and research</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="571" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Characterizing a psychiatric symptom dimension related to deficits in goal-directed control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Gillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whelan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Phelps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D. ; M R</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Wirch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Elife, 5 , e11305. Hardy</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="62" to="75" />
		</imprint>
	</monogr>
	<note>The iterated CTE: a dynamic risk measure</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Consideration of risk in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Proceedings</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="105" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A cognitive model of pathological worry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mathews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behaviour research and therapy</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="636" to="646" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Characteristics of worry in generalized anxiety disorder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mathews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lequertier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Perman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavior Therapy and Experimental Psychiatry</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="388" to="395" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rethinking avoidance: Toward a balanced approach to avoidance in treating anxiety disorders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Hay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of anxiety disorders</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="14" to="21" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Decision-theoretic psychiatry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Huys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guitart-Masip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychological Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="421" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Tight approximations of dynamic risk measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Iancu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petrik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Subramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="655" to="682" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The realization effect: Risk-taking after realized versus paper losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Imas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2086" to="2109" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Prospect Theory: An Analysis of Decision under Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<ptr target="https://ideas.repec.org/a/ecm/emetrp/v47y1979i2p263-91.html" />
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="291" />
			<date type="published" when="1979-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Modeling and optimization of risk. Handbook of the fundamentals of financial decision making: Part II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krokhmal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zabarankin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uryasev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="555" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">A philosophical essay on probabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-S</forename><surname>Laplace</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Risk preferences in young children: Early evidence of individual differences in reaction to potential gains and losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">P</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="397" to="413" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Judged frequency of lethal events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lichtenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Slovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Layman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Combs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology: Human learning and memory</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">551</biblScope>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Overrepresentation of extreme events in decision making reflects rational use of cognitive resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Experience replay supports non-local learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Anxiety, depression, and the anticipation of future positive and negative experiences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Macleod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of abnormal psychology</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">286</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Remembering the best and worst of times: Memories for extreme outcomes bias risky decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Spetch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="629" to="636" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">How should a robot assess risk? Towards an axiomatic theory of risk in robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics Research</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="75" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Mean-variance optimization in Markov decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tsitsiklis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1104.5601</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Portfolio Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Markowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="91" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Prioritized memory access explains planning and hippocampal replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1609" to="1617" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Risk-sensitive reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mihatsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Neuneier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="267" to="290" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Offline replay supports planning in human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">32548</biblScope>
			<pubPlace>Elife, 7</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Prioritized sweeping: Reinforcement learning with less data and less time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Atkeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="130" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Anxiety, depression, and judgments about the probability of future negative and positive events in children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Muris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Der Heiden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of anxiety disorders</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="252" to="261" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Time-consistent decisions and temporal decomposition of coherent risk functionals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Pflug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pichler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="682" to="699" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A theory of anticipated utility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quiggin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic behavior &amp; organization</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="323" to="343" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">All negative moods are not equal: Motivational influences of anxiety and sadness on decision making. Organizational behavior and human decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="56" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Optimization of conditional value-at-risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Rockafellar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uryasev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of risk</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="21" to="42" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Time consistency conditions for acceptability measures, with an application to Tail Value at Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roorda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Schumacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insurance: Mathematics and Economics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="230" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Time consistency and risk averse dynamic decision models: Definition, interpretation and practical consequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rudloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Street</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Valladão</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">234</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="743" to="750" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Risk-averse dynamic programming for Markov decision processes. Mathematical programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ruszczyński</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="235" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Time-consistent, risk-averse dynamic pricing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gönsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hassler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">277</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="587" to="603" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">On a time consistency concept in risk averse multistage stochastic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research Letters</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="143" to="147" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Lectures on stochastic programming: modeling and theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dentcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ruszczyński</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Time inconsistency of optimal policies of distributionally robust inventory models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1576" to="1584" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The hippocampus as a predictive map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Stachenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1643</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Trait anxiety and pessimistic appraisal of risk and chance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stöber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="465" to="476" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A behavioral and neural evaluation of prospective decision-making under risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Symmonds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">43</biblScope>
			<biblScope unit="page" from="14380" to="14389" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">The phenomenology of non-pathological worry: A preliminary investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tallis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Capuzzo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Worry: Mechanisms and modulating influences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tallis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Eysenck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioural and Cognitive Psychotherapy</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="56" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Sequential decision making with coherent risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3323" to="3338" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Advances in prospect theory: Cumulative representation of uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Risk and uncertainty</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="297" to="323" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Planning by prioritized sweeping with small backups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Van Seijen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="361" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Von Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Morgenstern</surname></persName>
		</author>
		<title level="m">Theory of games and economic behavior</title>
		<imprint>
			<date type="published" when="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A class of distortion operators for pricing financial and insurance risks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of risk and insurance</title>
		<imprint>
			<biblScope unit="page" from="15" to="36" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Constructive and unconstructive repetitive thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Watkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">163</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A metacognitive model and therapy for generalized anxiety disorder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychology &amp; Psychotherapy: An International Journal of Theory &amp; Practice</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="86" to="95" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">The affective impact of financial skewness on</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Knutson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
