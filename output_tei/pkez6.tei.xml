<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structured Action Preparation during Visuomotor Decision-making</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliana</forename><forename type="middle">E</forename><surname>Trach</surname></persName>
							<email>juliana.trach@yale.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<postCode>06510</postCode>
									<settlement>New Haven</settlement>
									<region>CT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">D</forename><surname>Mcdougle</surname></persName>
							<email>samuel.mcdougle@yale.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<postCode>06510</postCode>
									<settlement>New Haven</settlement>
									<region>CT</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Wu Tsai Institute</orgName>
								<orgName type="institution" key="instit2">Yale University</orgName>
								<address>
									<postCode>06510</postCode>
									<settlement>New Haven</settlement>
									<region>CT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<addrLine>100 College Street, New Haven</addrLine>
									<postCode>06510</postCode>
									<region>CT</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structured Action Preparation during Visuomotor Decision-making</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pages</term>
					<term>39 Figures</term>
					<term>4 Tables</term>
					<term>0 Supplemental</term>
					<term>3 figures</term>
				</keywords>
			</textClass>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Decision-making and movement are often tightly intertwined, a phenomenon that has been primarily studied in the case of low-level perceptual decision-making. How higher-level decision processes interface with the motor system during action selection is less clear. Here, we used psychophysics and computational modeling to examine information flow between deciding and acting when actions had to be retrieved from a newly learned visuomotor mapping. Human subjects (N = 182) learned de novo visuomotor mappings with (or without) an imposed latent structure that linked visual stimulus features (e.g., color, shape) to intuitive motor distinctions, like hands and pairs of adjacent fingers. In subjects who learned structured visuomotor mappings, transitional response times between trials indicated that retrieving the correct action from memory invoked "traversal" of a tree-like mental graph of the learned mapping. Control experiments and analyses helped rule out alternative explanations related to intrinsic switch costs between finger responses and perceptual properties of the stimuli. We then used a forced response time paradigm to show that when people traverse these learned visuomotor mappings during action selection, they sequentially potentiate multiple actions along the way in accordance with the structure of the mapping. Our results point to a direct coupling between complex internal memory and decision-making processes and the systematic preparation of actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main</head><p>Deciding and acting are traditionally treated as discrete steps in behavior, where a decision is completed before a corresponding motor command is issued. For example, one could draw a boundary between deciding about a perceptual variable (e.g., the location of a sound source) and subsequently responding with an action (e.g., moving the eyes to the right or left). However, work in both humans and animal models has supported a more interactive framework, where ongoing sensory evidence accumulation is echoed in the motor system <ref type="bibr" target="#b20">(Cisek &amp; Pastor-Bernier, 2014;</ref><ref type="bibr" target="#b33">Gallivan et al., 2018;</ref><ref type="bibr" target="#b35">Gold &amp; Shadlen, 2007;</ref><ref type="bibr" target="#b67">Selen et al., 2012;</ref><ref type="bibr" target="#b69">Shadlen &amp; Kiani, 2013;</ref><ref type="bibr" target="#b71">Song &amp; Nakayama, 2008b</ref><ref type="bibr" target="#b70">, 2008a</ref><ref type="bibr" target="#b73">Spivey &amp; Dale, 2006)</ref>.</p><p>This interaction can occur continuously during deliberation before any overt movements are made, blurring the boundary between perceptual decision-making and sensorimotor control. This tight coupling between low-level perceptual decision-making and sensorimotor control makes sense -many natural behaviors, such as detecting and avoiding a predator, have strict temporal demands and a sharp delineation between these systems would be maladaptive <ref type="bibr" target="#b37">(Gordon et al., 2021)</ref>. However, humans and many other animals can form much more complex and abstract sensorimotor mappings than simple perception-action links, such as those used for spatial navigation, planning, and concept learning <ref type="bibr" target="#b7">(Behrens et al., 2018;</ref><ref type="bibr" target="#b14">Brown et al., 2016;</ref><ref type="bibr" target="#b22">Constantinescu et al., 2016;</ref><ref type="bibr" target="#b44">Karuza et al., 2017)</ref>. Is a blurring of decision-making and movement preparation still seen when more abstract cognitive representations mediate between perception and actions?</p><p>Consider piano sight reading, where clefs (e.g., bass vs treble), note locations (e.g., third line on the staff), and accidentals (e.g., sharps, flats) are combined to determine key presses ( <ref type="figure" target="#fig_0">Figure 1A)</ref>. How does the sight-reading musician rapidly navigate her internal representation of symbol-to-finger mappings in the service of producing fast, accurate finger movements? One possibility is that deciding and acting are separable in these more complex contexts. That is, she may implement a hierarchical decision-making algorithm that parses features of the stimulus, and, only when the decision is complete, shuttle the result (e.g., "d flat") to her motor system. Alternatively, if the integration of deciding and acting goes beyond simpler perceptual choices, she might automatically prepare relevant motor commands while still in the process of parsing the stimulus (i.e., determining the clef potentiates the fingers of one entire hand, then determining the exact note drives movement of one finger on that hand). Here, we aim to test these competing hypotheses using a novel variant of an arbitrary visuomotor association learning task <ref type="bibr" target="#b41">(Hardwick et al., 2019)</ref>. Our primary goal is to understand how these more complex types of decisions -ones that require retrieving information from structured mental maps -may interact with the motor system on short timescales.</p><p>To that end, our task motivated participants to use stimulus features (color, shape, and pattern) to determine correct responses, similar to the musician considering various visual features on the page as she prepares to play a note. Critically, the individual features could be associated with different "levels" of an intuitive motor hierarchy, with the hand at the top level, finger "couplets" (adjacent pairs) in the middle, and the individual fingers within those couplets at the bottom ( <ref type="figure" target="#fig_0">Figure 1B)</ref>. The use of a hierarchically structured mapping allowed us to make precise predictions about behavior and ask whether the structure of an internal visuomotor mapping guides rapid movement selection.</p><p>To preview our findings: We first established that a simple measure -participants' trial-by-trial response times -could reveal the latent structure of a learned visuomotor mapping (Experiments 1-2). We then accounted for various potential alternative explanations, such as intrinsic response time costs when switching between different fingers, in control experiments (Experiments 3-4). Finally, having established the learning of our structured visuomotor mappings, we addressed our main question concerning withintrial decision-movement coupling using a novel variant of a forced response time paradigm <ref type="bibr" target="#b34">(Ghez et al., 1997;</ref><ref type="bibr" target="#b41">Hardwick et al., 2019;</ref><ref type="bibr" target="#b53">McDougle &amp; Taylor, 2019;</ref><ref type="bibr">Experiments 5-6)</ref>. During the paradigm, we interrupted the retrieval of learned visuomotor associations at various time points during deliberation and measured the resulting errors people made. We found evidence that people sequentially "prune" the structured visuomotor mapping from top to bottom (e.g., clef versus sharp/flat in our piano example) during the preparation of single finger movements. That is, we found compelling evidence for rapid, continuous coupling between an abstract visuomotor mapping and motor preparation. These data could be described by a simple computational model in which clusters of motor actions are dynamically potentiated during decision-making, a process which, crucially, could be mediated by a mental representation of task structure.</p><p>The results point to a tighter link between decision-making and motor systems, going beyond earlier findings in simpler perceptual decisions <ref type="bibr" target="#b18">(Cisek &amp; Kalaska, 2002;</ref><ref type="bibr" target="#b33">Gallivan et al., 2018;</ref><ref type="bibr" target="#b67">Selen et al., 2012)</ref>.</p><p>We speculate that retrieving actions from a structured visuomotor memory invokes a latent navigation-like computation over a cognitive graph or neural state space <ref type="bibr" target="#b22">(Constantinescu et al., 2016;</ref><ref type="bibr" target="#b56">Musslick &amp; Bizyaeva, 2024;</ref><ref type="bibr" target="#b58">Peer et al., 2021)</ref> which can produce a continuous flow of information from decisions to actions. press for each of the eight stimuli and illustration of one specific feature-to-level assignment. Visuomotor mappings were counterbalanced across participants. C) Task schematic for the learning task. D) Task schematic for the RT baseline task. E) Visualization of RT baseline correction, with average RTs for each pairwise transition between fingers for the learning and baseline task (Experiment 1) depicted as heatmaps. Baseline RTs subtracted from learning task RTs to yield corrected RTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1: Between-trial reaction time switch costs reflect the structure of learned visuomotor mapping.</head><p>Our goal was to understand how structured visuomotor mental representations, akin to note-key pairings in music sight-reading, dynamically interact with the motor system during action selection. In order to examine this question, we first had to establish a paradigm where people learned a new structured visuomotor mapping. Participants (N = 40) engaged in a visuomotor learning task <ref type="figure" target="#fig_0">(Figure 1B, C)</ref> and a reaction time (RT) baseline task ( <ref type="figure" target="#fig_0">Figure 1D, E)</ref> during the experimental session. During the learning task, participants used binary trial-by-trial reward feedback to learn an eight-to-eight deterministic visuomotor mapping ( <ref type="figure" target="#fig_0">Figure 1B, C)</ref>. The stimuli for the learning task consisted of eight images that varied along three feature dimensions (shape, color, and pattern), with two possible values for each feature (e.g., circle versus square). The unique combinations of the two values for each of the three dimensions thus yielded 8 distinct stimuli (e.g., blue striped circle, red dotted square, etc.) that were each deterministically associated with one correct motor response (responses included any of the eight digits minus the thumbs).</p><p>To embed structure into the mapping, we assigned each dimension to a level of an intuitive motor hierarchy (hand &gt; finger-couplet &gt; finger). For example, if shape was assigned to the highest level of the hierarchy -hand -then the shape of the stimulus determined which hand contained the correct response ( <ref type="figure" target="#fig_0">Figure 1B)</ref>. The assignment of specific stimulus features to particular levels of the motor hierarchy was fully counterbalanced across participants. We note that in broad strokes, the structure of this intuitive hierarchy approximately follows representational similarities of manual digits in human fMRI data <ref type="bibr" target="#b25">(Diedrichsen et al., 2013)</ref>. To confirm the intuitiveness of the applied mappings, we asked a naive group of participants (N = 37) to rank the six possible structured mappings (i.e., all that linked one of the three visual features to either hand, couplet, or finger) and two unstructured mappings (i.e., with no clustering of actions with stimulus features) in order of perceived learnability. We found that all 37 participants (100%) selected a structured mapping as the easiest mapping to learn and 34 of 37 participants (91.9%) ranked an unstructured mapping as the hardest to learn. This finding further suggests that the visuomotor mappings we implemented were intuitive to participants, and that different assignments of the specific visual features to each level of the structure did not, at least explicitly, differ in learnability. Participants in the learning task were never explicitly told about the mapping structure and, crucially, did not necessarily need to learn the structure to perform the task effectively (that is, they could just learn a simple 8-8 mapping from stimuli to actions). We used variation in RT between pairs of trials ("transitional RTs") as an index of whether people were sensitive to the structure of the visuomotor mappings <ref type="bibr" target="#b28">(Dykstra et al., 2022</ref>; see also <ref type="bibr" target="#b62">Reitman &amp; Rueter, 1980)</ref>. Transitional RT analyses involve classifying RTs based on features of the current and previous trials or responses, rather than considering each trial independently of the response that preceded it. However, because the mappings were yoked to physical effectors, any variation in transitional RTs that we observed could be confounded with intrinsic costs involved with simply switching between different hand or finger responses. We thus had participants complete a brief cued-response "RT baseline" task in order to quantify intrinsic switch costs associated with pairwise transitions between the fingers before any learning had occurred ( <ref type="figure" target="#fig_0">Figure 1D</ref>, E). In this baseline task, participants responded to the location of a target green square among white squares that were spatially aligned with their fingers on the computer keyboard. We used the data from this task to isolate the impact of the mapping structure on transitional RTs by subtracting the mean RT for each of the sixty-four pairwise transitions between fingers in the baseline task from the RTs recorded in the learning task that corresponded to the same finger-to-finger transitions ( <ref type="figure" target="#fig_0">Figure 1E)</ref>. Thus, remaining variation in RT switch costs during the learning task should not be driven by intrinsic finger transition biases, but rather by the latent structure of the mapping. We conducted all primary analyses on these "corrected" RTs. We note here that further control experiments also helped rule out intrinsic motor effects and support the claim that this baseline correction was successful (see Experiment 3 below).</p><p>In this initial experiment, we asked whether the structure of the visuomotor mapping was evident in transitional RTs. To do so, we compared participant behavior to the predictions of three theoretical models designed to explain transitional RTs: 1) a Hierarchical graph model (our hypothesis), 2) a Featurebased model, and 3) a Flat model. Illustrations of these theoretical models and their predicted behaviors are shown in <ref type="figure" target="#fig_1">Figure 2</ref>. We entered the corrected RTs (for consecutively correct trials only, see Methods) into three linear mixed effects models that operationalized each theoretical model to predict transitional RTs, and assessed the model fit for each.</p><p>First, the Hierarchical model used distance within the visuomotor mapping structure (i.e., the number of graph edges between the current and previous stimulus in the hierarchical structure; [0,2,4,6]) to predict RTs. We will use the term "path distance" to refer to the number of graph edges between consecutive responses. In this model, longer path distances should be associated with slower transitional RTs. Second, the Feature-based model predicted transitional RTs using the number of stimulus features that switched on a given transition <ref type="bibr">([0,1,2,3]</ref>). This model posits slower transitional RTs when more features of the stimulus change across trials but does not impose any structure or treat switching of specific features differently.</p><p>Third, if participants were simply learning one-to-one associations between stimuli and actions and not representing any latent structure in the mapping (a "flat" representation), nor responding to feature changes, switching from any response to any other should incur comparable RT switch costs. The predictor for the Flat model was simply whether the stimulus (and thus its associated response on correct trials) repeated or switched across trials. In addition to these theoretically grounded models, we included a fourth model that used physical distance between responses (i.e., the distance between fingers on the keyboard with each finger representing one spatial unit) to predict corrected RTs. This spatial distance model was designed to represent a linearly modulated attentional effect where attention would be biased towards the previous response and thus, responses far away from the previous response would take longer to prepare. Main results are visualized as bar graphs for corrected RTs given each path distance, as determined by the Hierarchical model, or the number of feature-switches for the Feature-based model. We use these basic analyses across the four following experiments.</p><p>Our primary analyses provided convergent evidence that participants represented the latent hierarchical structure in the mapping, and that corrected RTs scaled with the path distance through the structure of the visuomotor mapping ( <ref type="figure" target="#fig_2">Figure 3A,C)</ref>: Participant RTs were significantly slower on trials with longer path distances (Bonferroni corrected = .05/6 = .0083; 6-distance vs 0/2/4-distance: ts(39) &gt;= 3.23, ps &lt;= .002, Cohen's d &gt;= 0.30; 4-distance vs 0/2-distance: ts(39) &gt;= 7.12, ps &lt; .001, Cohen's d &gt;= 1.05; 2-distance vs 0-distance: t(39) = 13.92, p = .001, Cohen's d = 1.59). In other words, RTs monotonically increased with our hypothesized path distance metric ( <ref type="figure" target="#fig_2">Figure 3C</ref>). This result was further supported by the mixed effects models: The Hierarchical model reliably produced the best fit to the behavior, compared to our three competing models (Hierarchical: BIC = 330,109; Feature-based: BIC = 330,171, Flat: BIC = 330,581, Physical distance: BIC = 330,880; <ref type="figure" target="#fig_2">Figure 3D</ref>). The Feature-based model was the next best fit for participant behavior, followed by the Flat model and finally the Physical distance model. These findings suggest that participants learned and mentally represented the structure in the visuomotor mapping, although there was no explicit instruction to do so and no obvious benefit for performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2: Patterns of RTs with modified structured mapping replicate results of Experiment 1.</head><p>To further test the robustness of the mapping structure effects, we had another group of participants (N = 27) engage in the same experimental set up but with a modified mapping: In Experiment 2, rather than assigning features according to extrinsic space (i.e., the leftmost couplet in each hand shared a couplet feature, and the finger-level feature was assigned from left to right in each hand; <ref type="figure" target="#fig_2">Figure 3A)</ref>, we aligned the mapping structure with the mirror symmetry of the hands (i.e., based on intrinsic hand space; <ref type="figure" target="#fig_2">Figure   3E</ref>). Participants viewed at least 55 presentations of each stimulus during the task (note that this task was shorter than Experiment 1 as we found that this shorter duration was sufficient for learning). Accuracy and average corrected RT during this task were not significantly different from performance in Experiment 1 when matched for number of iterations (Experiment 1: learning curve: <ref type="figure" target="#fig_2">Figure 3B</ref>; average accuracy across all trials = 61.3%, average corrected RT = 623ms; Experiment 2: learning curve: <ref type="figure" target="#fig_2">Figure 3F</ref>; accuracy = 64.0%, average corrected RT = 594ms; accuracy: t(65.26) = -0.73 p = .47, 95% CI = <ref type="bibr">[-10.2, 4.7]</ref>; RT: t(55.36) = 0.78, p = .44, 95% CI = <ref type="bibr">[-45.0, 102.8]</ref>), suggesting that the modified latent structure was equally learnable for participants. Thus, it appears that both extrinsic and intrinsic reference frames are similarly intuitive in our task.</p><p>We again found evidence that corrected transitional RTs reflected the underlying structure of the visuomotor mapping, such that RTs tracked path distance through the structure between consecutive responses. Specifically, RTs for 0-to 4-path-distance trials scaled as expected ( <ref type="figure" target="#fig_2">Figure 3G</ref>; Bonferroni corrected = .05/6 = .0083; 4-distance vs 0/2-distance: t(27) &gt;= 9.15, p &lt; .001, Cohen's d &gt;= 1.50; 2distance vs 0-distance: t(27) = 11.62, p &lt; .001, Cohen's d = 0.97); however, we note that 6-distance trials were not significantly slower than 4-distance trials (6-distance vs 4-distance: t(27) = 0.52, p = .61) but were slower than the other two path distances (6-distance vs 0/2-distance: t(27) &gt;= 9.17, p &lt; .001, Cohen's d &gt;= 1.33). We again found that the hierarchical model was the best fit to the behavior compared to the three competing models ( <ref type="figure" target="#fig_2">Figure 3H</ref>; BIC: Hierarchical = 82,798; Feature-based = 82,922; Flat = 82,999; Physical distance = 83,034), providing further evidence for the hierarchical account. Again, the Featurebased model was the second best fit for behavior. Thus, mappings with either extrinsic or intrinsic reference frames could lead to the transitional RTs predicted by the hierarchical model. For simplicity, the remainder of our experiments with structured mappings used the extrinsic reference frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments 3 &amp; 4: Training on unstructured mapping yields different behavioral profiles than hierarchical mappings.</head><p>One potential concern about these results is that the RT baseline correction that we implemented might not sufficiently control for the impact of intrinsic motor switch costs on RTs. Thus, we implemented two additional control studies (with two new groups of participants) that addressed this concern in different ways. In both, we removed the latent structure from the task and trained participants on "unstructured" mappings ( <ref type="figure" target="#fig_2">Figure 3I &amp; M)</ref>. In Experiment 3, we used simpler stimuli than in Experiments 1 and 2 in order to ensure that there was no possibility of extracting any latent structure in the mapping. In Experiment 4, we matched stimulus complexity across experiments by constructing "unstructured" mappings using the three-feature stimuli from the previous experiments. The high degree of similarity between these stimuli could, however, allow participants to extract some degree of local structure, even though we aimed to minimize noticeable structure in the mappings we selected (Supplemental <ref type="figure" target="#fig_0">Figure S1)</ref>. Thus, both studies test this alternative hypothesis in different ways. In these experiments, we quantified path distance using the same logic as the hierarchical task (from Experiment 1) and performed the same set of RT analyses.</p><p>In the first control study (Experiment 3; N = 33), we used stimuli that varied along a single feature (eight squares of different colors or eight different shapes that were all black, counterbalanced; <ref type="figure" target="#fig_2">Figure 3I)</ref> to ensure that participants would not infer any latent structure in the visuomotor mapping. Participants learned the mappings well ( <ref type="figure" target="#fig_2">Figure 3J)</ref>, and were more accurate (Experiment .10, p &lt; .001, Cohen's d = 1.6, 95% CI = <ref type="bibr">[-294.39, -148</ref>.64]) relative to Experiments 1 and 2. Better performance in this case is most likely due to the fact that these single-feature stimuli were less confusable than the three-feature stimuli.</p><p>We compared linear mixed effects models that operationalized the Hierarchical, Physical distance, and Flat models of the task (the Feature-based model could not be used as only one feature was present in each stimulus). We found that the Flat model was a better fit for participant behavior (i.e., lower BIC) in Experiment 3 versus the competing Hierarchical or Physical distance models ( <ref type="figure" target="#fig_2">Figure 3L</ref>; BIC: Hierarchical model = 325,695; Flat model = 325,472; Physical distance = 326,048). That is, transitional RTs were effectively equivalent when the stimulus changed across trials ( <ref type="figure" target="#fig_2">Figure 3K</ref>; Bonferroni corrected = .05/6 = .0083; 0-distance vs 2/4/6-distance: ts(32) &gt;= 7.08, ps &lt; .001, Cohen's d &gt;= 1.38; pairwise comparisons between 2-, 4-, and 6-distance trials: ts(32) &lt;= 1.98, ps &gt; .06). If the results of Experiments 1 and 2 were driven by intrinsic finger switch costs and not the underlying mapping structure, we should have seen similar transitional RTs in this experiment as well. Therefore, the uniform transitional RTs observed in Experiment 3 refute the possibility that our previous results were a simple artifact of linking our mapping to physical effectors, and suggest that the learned representation of the mapping itself drove the observed patterns in Experiments 1 and 2.</p><p>In Experiment 4, participants were trained on unstructured, "shuffled" visuomotor mappings using the original three-feature stimuli (Experiment 4; <ref type="figure" target="#fig_2">Figure 3M</ref>). We assigned stimuli to each response in a way that minimized inferable intuitive motor structure (For examples, see Supplemental <ref type="figure" target="#fig_0">Figure S1</ref>). We note, however, that due to the high similarity between stimuli, there was still a possibility that participants could engage in some degree of clustering of stimulus-response associations even though there is no complete structured mapping. The learning curve is pictured in <ref type="figure" target="#fig_2">Figure 3N</ref>. Participants were slightly less accurate overall than participants trained on the hierarchical mappings in Experiments 1 and 2 (Experiment 1 versus Experiment 4: t(63.1) = 1.71, p = .092, 95% CI = [-0.01, 0.14]; Experiment 2 versus Experiment 4: t(51.99) = 2.55, p = .013, Cohen's d = 0.69, 95% CI = [-0.16, -0.02];), suggesting that this unstructured mapping may have been more difficult to learn than the hierarchical mappings with the same stimuli (though we note the average accuracy difference between Experiments 1 and 4 was not significant).</p><p>We again fit mixed effects models to compare theoretical models. In this case, the Flat model outperformed the Feature model in contrast to Experiments 1 and 2, and was only slightly worse than the Hierarchical model ( <ref type="figure" target="#fig_2">Figure 3P</ref>; BIC: Hierarchical model = 58,546; Flat model = 58,555; Feature-based model = 58,607; Physical distance model = 58,650). The decent fit of the Hierarchical model may suggest that individuals spontaneously infer local structure in these shuffled visuomotor mappings, at least withinhand. However, we did not find that RTs neatly increased with path distance with this mapping ( <ref type="figure" target="#fig_2">Figure   3O</ref>; Bonferroni corrected = .05/6 = .008; 6-distance vs 4-distance: t(25) = 0.65, p = .52; 6-distance vs 2distance: t(25) = 2.78, p = .010; 4-distance vs 2-distance: t(25) = 2.22, p = .036; 6/4/2-distance vs 0-distance: ts(25) &gt;= 5.48, ps &lt; .001, Cohen's d &gt; 1.48), supporting the claim that individuals did not learn a fully structured mapping in this case. Overall, these results show that shuffling the mapping weakened the hierarchical effects that we previously observed with participants trained on the more intuitive hierarchical mappings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-free hierarchical clustering of transitional RT matrices reproduces latent mapping structure.</head><p>We also performed a clustering analysis in order to reconstruct the learned mappings from the transitional RT data. We used agglomerative hierarchical clustering (R Packages: cluster, factoextra; <ref type="bibr" target="#b49">Maechler et al., 2022;</ref><ref type="bibr">Kassambara &amp; Mund, 2020)</ref> to identify structure in the transitional RTs during the learning task for each sample (hierarchically structured in Experiments 1 and 2, and unstructured in Experiments 3 and 4) and the RT baseline task. We predicted that this type of analysis would reproduce the hierarchical structure of the mappings for Experiments 1 and 2 but yield idiosyncratic structures for Experiments 3 and 4 (and for the RT baseline task where there was no consistent structure). We calculated the average RT for each pairwise transition between responses to obtain a transitional RT profile for each target stimulus. We then calculated the Euclidean distances between the RT profiles and used the function hclust from the cluster package in R to cluster the transitional RT profiles for each stimulus. Finally, we used dendrograms to visualize the inferred structure of the mapping <ref type="figure" target="#fig_2">(Figures 3 Q-V)</ref>. We combined data across experiments to produce the RT baseline task dendrogram as the baseline task was identical across all experiments. We found that the clustering algorithm faithfully reproduced the latent structure in the mappings from Experiments 1 and 2 ( <ref type="figure" target="#fig_2">Figures 3R &amp; S)</ref>, providing additional support for our interpretation of the linear modeling results. In contrast, experiments without latent structure (Experiments 3, 4, and the baseline task) yielded idiosyncratic dendrograms ( <ref type="figure" target="#fig_2">Figures 3T-V)</ref>. This data-driven analysis further demonstrates that individuals learned and used the structure built into the task when it was available and reiterates our finding that internal representations of visuomotor mappings can be inferred by looking at a relatively simple behavioral measure -transitional RTs. In the next experiments, we tested our hypotheses related to within-trial action preparation dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments 5 &amp; 6: Within-trial dynamics of action selection.</head><p>In Experiments 1-4, we demonstrated that transitional RTs scaled with path distance between trials as measured through the latent structure in a visuomotor mapping. We posited that this result could arise from a process where individuals mentally traverse an internal representation of the visuomotor map to retrieve correct responses, similar to the traversal of structured mental representations of spatial or nonspatial content found in other studies (e.g., <ref type="bibr" target="#b14">Brown et al., 2016;</ref><ref type="bibr" target="#b63">Rmus et al., 2022;</ref><ref type="bibr" target="#b76">Tavares et al., 2015)</ref>.</p><p>We hypothesized that this latent "traversal" process would communicate with the motor system, potentiating the relevant sets of actions at each level of the mapping in real time. We addressed this hypothesis using a forced response paradigm designed to elicit responses at different points during the deliberation process on each trial, allowing us to track the dynamics of action selection in both structured and unstructured visuomotor mappings. To that end, we recruited two new groups of participants and trained them on either the structured visuomotor mapping used in Experiment 1 (Experiment 5) or an unstructured visuomotor mapping with single feature stimuli, as in Experiment 3 (Experiment 6). We then compared the probabilities of different types of errors that participants made as a function of how long they had to prepare their movements on a given trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning task results: Patterns of RTs replicated findings of Experiments 1 and 3.</head><p>We analyzed the data from the learning phase in Experiments 5 and 6 as in the previous section.</p><p>Learning phase results replicated the results of Experiments 1 and 3, respectively (see Supplemental <ref type="figure" target="#fig_1">Figure S2</ref>). That is, the Hierarchical model was the best fit for participant behavior for participants that were trained on the structured mapping (BIC: Hierarchical = 117,458; Feature-based = 117,656; Flat = 117,930; Physical distance = 117,981) and the Flat model was the best fit for participants behavior for participants trained on the unstructured mapping (BIC: Hierarchical = 70,254; Flat = 70,134; Physical distance = 70,350). Additionally, the model-free hierarchical clustering algorithm reliably reproduced the latent structure in the task for participants trained on the structured mapping (Experiment 5) but not the unstructured mapping (Experiment 6), also replicating our previous results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Within-trial dynamics reveal a sequential, structured action preparation process during the selection of single actions from a learned visuomotor mapping.</head><p>Following the learning phase, participants executed a forced response task ( <ref type="figure" target="#fig_4">Figure 4A)</ref>. During this task, participants heard four beeps on every trial and were instructed to synchronize their response with the fourth beep, regardless of whether they felt prepared to respond or not <ref type="bibr" target="#b41">(Hardwick et al., 2019;</ref><ref type="bibr" target="#b53">McDougle &amp; Taylor, 2019)</ref>. We varied the stimulus onset during each trial in order to manipulate the amount of preparation time (PT; i.e., time between stimulus onset and the fourth beep) participants were given. PT varied between 100ms and 1.2s; thus, on some trials, participants had sufficient time to plan and execute their responses, and on other trials they would be forced to guess. In this way, we can probe the state of the decision-making process at the level of action preparation continuously across the trial interval. Our focus is the types of errors participants made as a function of PT.</p><p>Our main question was whether there was evidence that participants sequentially resolved levels of the mapping from top to bottom during action selection (structured action preparation) or not (unstructured action preparation). Consider again the pianist from the Introduction. The structured preparation hypothesis is consistent with a model of behavior where she parses the musical notation in front of her and, at the same time, potentiates likely actions in the motor system as she processes different features of the notation symbol (clef, note location etc.). The unstructured hypothesis, in contrast, describes a dynamic where she processes the stimulus and determines the appropriate action before potentiating that response in the motor system; the dynamics of action selection in this latter case are thus not influenced by structure in the internal representation of the visuomotor mapping. stimulus onset and the response cue (the fourth tone of the tone sequence). B) Error coding scheme for an example trial. Errors were coded based on the highest level that mismatched between the target stimulus and the stimulus associated with the response that the participant made (see methods). C) Forced response results for Experiment 5. D) Forced response results for Experiment 6. E) Probability of errors that share two visual features with the target stimulus in Experiment 5. There are three stimuli in each set that share two features with any target stimulus -one that is a low-level error (purple), one that is a mid-level error (pink), and one that is a top-level error (orange). F) Probability of a within-couplet (purple, i.e., low-level) error versus an across-couplet (pink, i.e., mid-level) error when there are two possible adjacent finger errors. Left panel is Experiment 5 and right panel is Experiment 6. G) Illustration of model logic and different predictions of structured and unstructured action preparation models. H) Model simulation with averaged fitted parameters for bestfitting hierarchical three-model from Experiment 5. I) Model simulation with averaged fitted parameters for best-fitting flat model from Experiment 6. Note that lines for errors at different stimulus levels are on top of each other in this case. Error bars/shading represents 1 SEM. ** p &lt; .01, *** p &lt; .001.</p><p>Crucially, these two processing dynamics should produce different patterns of errors in the forced response paradigm. If participants trained on hierarchically structured mappings (Experiment 5) sequentially process each level of the learned mapping from top to bottom, and simultaneously potentiate the relevant actions, we would expect top-level errors (i.e., hand errors) to be less frequent than mid-or low-level error (couplet or finger-level errors), since resolving the top-level of the response should occur before resolving the lower two levels. Similarly, mid-level couplet errors should be more frequent than lowlevel errors and low-level errors should be the most frequent, since it would take the most amount of time to resolve the subordinate features of the stimuli during action selection. Such a result would be consistent with a continuous flow of information from an internal navigation of the learned cognitive mapping to the motor system (i.e., structured action preparation). In contrast, if participants do not plan their finger movements until a terminal decision about the stimulus is reached, or if they have learned to process the three stimulus features and activate the correct group of actions fully in parallel, we would not expect to see any orderly progression of error types (i.e., unstructured action preparation).</p><p>To visualize our results, we classified each response as either a top-, mid-, or low-level error based on shared features between the target stimulus and the stimulus associated with the response that the participant had made <ref type="figure" target="#fig_4">(Figure 4B)</ref>. For example, if the target response for a trial was key D, then responding with key F would be considered a low-level error (i.e., the hand and couplet are correct but the wrong finger within the couplet was chosen), key A or key S would be considered mid-level errors (i.e., the correct hand was chosen, but not the correct couplet), and responding with any finger on the right hand would be considered a top-level error ( <ref type="figure" target="#fig_4">Figure 4B)</ref>. We used a sliding window of 100ms to smooth the probability of committing each type of error (low-level, mid-level, top-level errors) as a function of preparation time. We then normalized that probability by the number of responses that could be classified as each type of error to account for the fact that there were more ways to commit a top-level error (four responses) than midlevel (two responses) or low-level (one response) errors. We additionally conducted this same type of analysis for each possible response, rather than combining across errors at each level. This is pictured in Supplemental <ref type="figure" target="#fig_2">Figure S3</ref>.</p><p>We found evidence of structured action preparation for participants trained on the structured mapping: the probability of errors at different levels of the task stacked in an orderly fashion, such that toplevel errors were least frequent and resolved quickly, while low-level errors were most frequent and resolved slowly. <ref type="figure" target="#fig_4">Figure 4C</ref> shows the smoothed curves for the probability of making low-, mid-, or toplevel errors as a function of preparation time (also see Supplemental <ref type="figure" target="#fig_2">Figure S3A-C)</ref>. Crucially, we did not see this pattern of results for participants trained on the unstructured mapping (Experiment 6; <ref type="figure" target="#fig_4">Figure   4D</ref> and Supplemental <ref type="figure" target="#fig_2">Figure S3D-F)</ref>, indicating that the pattern of errors was driven by the structure of the learned mapping. We tested this statistically by conducting a mixed factors ANOVA on the normalized probability of errors at each level across all PTs. We found a significant interaction between experiment and error level, providing further evidence that response selection dynamics were different between the two experiments (Experiment x Error Level: F(1.65, 87.51) = 9.34, p &lt; .001, η 2 = 0.15). Thus, it appeared that in Experiment 5, participants arrived at the correct action by sequentially pruning the visuomotor mapping in real time.</p><p>One alternative explanation for the effects observed in Experiment 5 is that participants may be reacting to the visual similarity between the target stimulus and the stimulus associated with the low-level error response. That is, the stimulus associated with the low-level error response shares two of three features with the target stimulus by definition; thus, it is possible that the increased probability of this response could be driven purely by the visual features. Importantly, there are three stimuli that share two visual features with the target stimulus in the structured visuomotor mapping, which makes this possibility straightforward to test: One of these three stimuli is considered a low-level error, one a mid-level error, and one a top-level error, even though they all share two features with the target. We thus compared the probability of making each of these types of errors ( <ref type="figure" target="#fig_4">Figure 4E)</ref>. Participants were still most likely to make the low-level versus mid-or top-level errors, even when the stimuli were matched for visual similarity with the target (low-vs. Another possibility is that spatial proximity to the target response could drive the increased likelihood of low-level errors (i.e., action slips with neighboring fingers). Indeed, the response that corresponds to a low-level error is, by definition, adjacent to the target response, so participants could be making this error due to generic motor execution errors rather than due to the structure of the learned mapping. To address this possibility, we compared the probability of making a low-level error to the probability of making a mid-level error that was also adjacent to the target response. We restricted this analysis to trials where there were responses on either side of the target response within each hand (i.e., excluding trials where the target response was either the index or the pinky finger). If participants are making generic motor errors on these trials, rather than errors that correspond to the structure of the mapping, then we would expect either type of adjacent error to be equally likely. In contrast, if the participants are more likely to commit the low-level error within the cued couplet as compared to the other adjacent error, that would provide evidence that the pattern of errors in the data was indeed driven by the structure of the mapping. For participants trained on the unstructured mapping (Experiment 6), the two types of adjacent errors were equally probable ( <ref type="figure" target="#fig_4">Figure 4F, right panel;</ref> t(18) = 1.04, p = .31, 95% CI = [-0.11, 0.31]), supporting the presence of these spatially-driven generic motor errors. In contrast, participants trained on the structured mapping (Experiment 5) were significantly more likely to commit low-level adjacent errors (i.e., consistent with the structure of the task) than the alternative adjacent errors ( <ref type="figure" target="#fig_4">Figure   4F</ref>, left panel; t(35) = 3.20, p = .003, Cohen's d = 1.07, 95% CI = []). In our view, these two control analyses ( <ref type="figure" target="#fig_4">Figure 4E-F)</ref> provide convincing evidence that the pattern of errors observed in Experiment 5 were a direct result of the structure of the learned mapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forced response results: Computational modeling highlights different processing dynamics between structured and unstructured mappings.</head><p>We used computational models to further clarify the hypothesized visuomotor processing dynamics and compare results across the two forced response time experiments. The basic design of the model posits that preparing an action takes some mean amount of time μ with variance σ and is normally distributed <ref type="bibr" target="#b41">(Hardwick et al., 2019;</ref><ref type="bibr">see Methods)</ref>. These response time distributions can be transformed into speedaccuracy tradeoff curves by taking their cumulative density, which describes the probability of making a specific response as a function of preparation time. We compared four variants of this model to characterize response dynamics in our structured and unstructured tasks. To adapt this model to our hierarchically structured task, we allowed for three μ parameters to vary freely, one for each level of the mapping. This design allowed us to ascertain whether or not participants resolved each level of the task sequentially from top to bottom ( <ref type="figure" target="#fig_4">Figure 4G)</ref>. We fit one version of this Hierarchical model that included a single σ parameter that was used at each level of the mapping and another that included separate σ parameters for each level of the mapping. In addition to these Hierarchical models, we fit a Feature-based model and a Flat model for comparison. The Feature-based model had access to the structure of the mapping, however only used one μ free parameter and one σ free parameter such that levels of the mapping were not treated differently during action preparation. In contrast, the Flat model does not contain the structure of the mapping and posits that participants potentiate a single action during preparation, with uniform probabilities for each other (erroneous) response. We predicted that (one of) the Hierarchical models would best capture participant behavior when they learned a structured mapping (Experiment 5), and that the Flat model would best capture behavior for participants trained on an unstructured mapping (Experiment 6).</p><p>As we predicted, the Hierarchical model with three σ parameters was the best fit for participant behavior for participants trained on the structured mapping, followed by the Hierarchical model with one σ parameter (Hierarchical-three σ: summed BIC = 76,517; Hierarchical-one σ: summed BIC = 76,536 Feature-based: summed BIC = 77,767; Flat: summed BIC = 78,054). This result held on the individual subject level for 30 out of 36 participants. We also examined the average μ values across participants for the best-fitting Hierarchical model. Here, we found that fitted μ parameters were consistent with a sequential pruning process; in other words, μtop (μtop = 0.615s) was smaller than μmid (μmid = 1.01s) and μmid was smaller than μlow (μlow = 1.26s; Wilcoxon signed-rank test: top versus mid: z = 4.32, p &lt; .001, effect size: r = 0.72; mid versus bottom: z = 4.07, p &lt; .001, effect size: r = 0.72). In contrast, model fits to participants trained on the unstructured mapping strongly favored the Flat model (Hierarchical-three σ:</p><p>summed BIC = 34,863; Hierarchical-one σ: summed BIC = 34,732; Flat: summed BIC = 30,917). This result was consistent on the individual subject level for 18 out of 19 participants. Example model simulations are pictured in <ref type="figure" target="#fig_4">Figure 4H</ref>-I. These results provide further evidence of structured action preparation during visuomotor decision-making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In these studies, we examined interactions between decision-making and action preparation in the context of newly learned (de novo) visuomotor mappings. We hypothesized that when retrieving an action from such mappings, there is a continuous flow of information from the decision process to the motor system, and that this information flow would be guided by the structure of the mapping. Overall, our results supported our hypothesis. In Experiments 1 and 2, where participants were trained on hierarchically structured visuomotor mappings, we observed that participant transitional response times (RTs), which refer to RT modulations driven by previous trials, closely tracked the structure of a learned visuomotor mapping. This finding provided behavioral evidence that individuals learned and utilized that structure to select actions on a trial-by-trial basis. Furthermore, this result held after correcting transitional RTs to control for intrinsic switch costs between fingers, and was abolished or weakened when intuitive structure was removed (Experiments 3 and 4). We expanded on this finding in Experiments 5 and 6 to characterize how the learned mappings constrained action selection within the scope of individual decisions.</p><p>Participants' errors systematically varied as a function of movement preparation time in a manner consistent with a structured model of action selection; that is, we found evidence that participants resolved hierarchical levels of an internal representation of the learned mapping from top to bottom while concurrently potentiating relevant sets of actions. This effect was not seen when the learned mapping did not contain a structured relationship between perceptual features and actions (Experiment 6). Taken together, our findings point to a dynamic, rapid interaction between a cognitive process -an internal navigation-or pruning-like computation over a learned sensorimotor representation -and the preparation of individual actions.</p><p>While information flow from sensory evidence accumulation systems to the motor system has been shown before in the context of simple perceptual decisions <ref type="bibr" target="#b15">(Burk et al., 2014;</ref><ref type="bibr" target="#b18">Cisek &amp; Kalaska, 2002;</ref><ref type="bibr" target="#b39">Hagura et al., 2017;</ref><ref type="bibr" target="#b55">Moher &amp; Song, 2014;</ref><ref type="bibr" target="#b67">Selen et al., 2012</ref><ref type="bibr" target="#b65">Selen et al., , 2023</ref><ref type="bibr" target="#b80">Thura &amp; Cisek, 2014)</ref>, to our knowledge, previous work has not extended this basic finding to complex settings that involve richer visuomotor representations. Our findings thus support a more dramatic blurring between decision-making and action, suggesting a rather robust relationship between internal decision processes and the dynamic potentiation of multiple motor commands in real time <ref type="bibr" target="#b18">(Cisek &amp; Kalaska, 2002;</ref><ref type="bibr" target="#b69">Shadlen &amp; Kiani, 2013)</ref>. There is other evidence for interactions between decision-making and motor behavior in more "cognitive" settings; a large body of research using mouse-and eye-tracking methods during simple decision-making tasks has shown that movements may act as continuous read-outs of evolving decision processes <ref type="bibr" target="#b31">(Freeman et al., 2013;</ref><ref type="bibr" target="#b33">Gallivan et al., 2018;</ref><ref type="bibr" target="#b50">Magnuson, 2005;</ref><ref type="bibr" target="#b69">Shadlen &amp; Kiani, 2013;</ref><ref type="bibr" target="#b71">Song &amp; Nakayama, 2008b</ref><ref type="bibr" target="#b70">, 2008a</ref>.</p><p>For example, when asked to rapidly move your mouse to click on an image of candy when an image of a candle is the alternative choice, one's mouse cursor may veer to the candle due to phonological interference <ref type="bibr" target="#b74">(Spivey et al., 2005)</ref>. This family of studies is an elegant demonstration of the continuity inherent to decision-making processes that evolve over time. However, we believe it is not entirely clear if the motor control aspects of these studies reflect true coupling between internal decision states and movement. The findings can likely be explained as people optimizing motor plans to buy themselves time to resolve decision ambiguity using feedback control <ref type="bibr" target="#b1">(Alhussein &amp; Smith, 2021;</ref><ref type="bibr" target="#b40">Haith et al., 2015;</ref><ref type="bibr" target="#b86">Wong &amp; Haith, 2017</ref>). Thus, it may be that previous work looking at cognitive decision-making and continuous actions might not speak to the kind of rapid, obligatory information flow between deciding and acting that has been found in perceptual decision-making <ref type="bibr" target="#b67">(Selen et al., 2012)</ref>. Either way, our current results are fully consistent with these bodies of research.</p><p>What type of dynamic mechanisms might underlie our results? It is possible that distances in a low dimensional neural "state space" may correlate with the "path distances" we posited in our task, where navigation could reflect internal control processes involved with traversing or reconfiguring these state spaces <ref type="bibr" target="#b56">(Musslick &amp; Bizyaeva, 2024)</ref>. This could perhaps occur via sequentially attending to different visual features (and simultaneously activating different action sets) at different times. Indeed, similar explanations of RT costs have been proffered to explain classic task-switching effects <ref type="bibr" target="#b42">(Jaffe et al., 2023)</ref>. Moreover, the structure that participants are learning in our task echoes concepts of "cognitive graphs," which refer to relational mental representations that consist of nodes and paths that link those nodes together <ref type="bibr" target="#b17">(Chrastil &amp; Warren, 2014;</ref><ref type="bibr" target="#b58">Peer et al., 2021)</ref>. Most relevant to the current project, there is evidence that neural activity and participant RTs can scale with path length through putative cognitive graphs <ref type="bibr" target="#b5">(Balaguer et al., 2016;</ref><ref type="bibr" target="#b44">Karuza et al., 2017;</ref><ref type="bibr" target="#b63">Rmus et al., 2022)</ref>. For example, Rmus and colleagues (2022) trained participants on a cognitive graph of objects by sequentially showing them pairs of objects that were adjacent in an arbitrarily structured graph. They then asked participants to make judgments about which of two objects was closer to a target object within that graph. Despite never seeing the whole relational structure of the graph, Rmus and colleagues found that participant response times were modulated by the distance of each option from the target, such that they displayed longer RTs when the options were farther away from the target. They posited that this effect might arise from a pseudo-navigation process where individuals mentally simulate the path to each competitor in order to complete the distance judgment. Whether or not a similar process is occurring in our task is unclear, but certainly worth testing further.</p><p>To date, previous work on structured cognitive graphs has largely focused on spatial, semantic, or episodic information but not action or the structure of the motor system. Our results suggest that graph-like representational formats might be used in the context of action selection as well, and might even interface directly with motor preparation processes during decision-making. At the neural level, such representations are typically believed to exist in traditionally "non-motor" regions such as the hippocampus and orbital frontal cortex <ref type="bibr" target="#b30">(Ekstrom &amp; Ranganath, 2018;</ref><ref type="bibr" target="#b58">Peer et al., 2021;</ref><ref type="bibr" target="#b79">Theves et al., 2021;</ref><ref type="bibr" target="#b85">Whittington et al., 2020;</ref><ref type="bibr" target="#b87">Wu et al., 2020;</ref><ref type="bibr" target="#b88">Zhou et al., 2019)</ref>, raising the possibility that these regions might also be involved in storing and accessing structured perceptuomotor mappings.</p><p>Whether the structured processing dynamics that we identified here are generalizable to other nonmotor forms of hierarchical cognitive representations remains an open question. People use hierarchical cognitive representations across a wide range of domains to organize knowledge and behavior. In particular, hierarchical cognitive representations are widely studied in the domain of cognitive control, where they are hypothesized to allow for flexible and efficient control of contextually sensitive behavior <ref type="bibr" target="#b2">(Badre, 2008;</ref><ref type="bibr" target="#b4">Badre &amp; Nee, 2018;</ref><ref type="bibr" target="#b9">Botvinick et al., 2009;</ref><ref type="bibr" target="#b12">Brennan &amp; Hale, 2019;</ref><ref type="bibr" target="#b23">Cooper &amp; Shallice, 2006;</ref><ref type="bibr" target="#b27">D'Mello et al., 2020;</ref><ref type="bibr" target="#b84">Uithol et al., 2012)</ref>. One consistent finding is that control costs -in the form of heightened RTs when the necessity for cognitive control is higher -increase with the level of abstraction, such that control costs are larger at superordinate levels relative to subordinate levels (e.g., task switch costs &gt; response switch costs; <ref type="bibr" target="#b21">Collins, 2017;</ref><ref type="bibr" target="#b46">Korb et al., 2017;</ref><ref type="bibr" target="#b82">Trach et al., 2021)</ref>. This pattern of behavior echoes our transitional RT results in Experiments 1-4. We speculate that increased switch costs at higher-order task levels could be driven by participants mentally traversing a hierarchical task representation to retrieve appropriate actions.</p><p>In terms of within-decision dynamics (Experiments 5 and 6), however, studies in the cognitive control domain have yielded results that contrast with the structured processing dynamic that we identified here. Specifically, research with behavioral and neural recording methods have found primarily parallel processing dynamics during hierarchically structured cognitive control tasks <ref type="bibr" target="#b16">(Cellier et al., 2022;</ref><ref type="bibr" target="#b61">Ranti et al., 2015)</ref>. Parallelization in these tasks is thought to be possible due to a hypothesized hierarchical gradient of representational abstraction in the prefrontal cortex (PFC; <ref type="bibr" target="#b3">Badre &amp; D'Esposito, 2009;</ref><ref type="bibr" target="#b4">Badre &amp; Nee, 2018)</ref>, where different areas of the PFC can process different task rules/levels in parallel. A useful future direction could be to link previous work on task rules and context-sensitive cognitive control to our current study, where the structured representation was not defined by any strict hierarchical or contextual cues, but rather was directly linked to motor effectors.</p><p>Finally, our focus on newly learned visuomotor mappings naturally raises questions about how action selection dynamics might evolve with experience and, ultimately, expertise. Participants successfully learned relatively complex mappings with a small number of trials, but if subjects performed the task for days (i.e., becoming "experts" at the mapping), would they show "flattening," transforming the structured representation into a direct 8-8 stimulus-response mapping? Or, alternatively, would the learned structure harden with repeated practice? Consider again our pianist learning to parse musical notation while planning finger movements. Early in learning, the pianist is likely explicitly parsing individual symbols in order (clef -&gt; note -&gt; accidentals), which may dynamically potentiate different actions as they determine the correct key to press, consistent with our findings. After years of practice, however, an experienced pianist might be able to forgo this sequential algorithm and access direct stimulus-response mappings to facilitate efficient performance. This change in processing would be consistent with theories of practice and automatic control which suggest that overtrained stimulus-response associations become crystallized into "instances" <ref type="bibr" target="#b47">(Logan, 1988</ref><ref type="bibr" target="#b48">(Logan, , 2018</ref>, or models where practice yields distinct representations that enable automatic performance <ref type="bibr" target="#b57">(Musslick &amp; Cohen, 2021)</ref>. Alternatively, however, it may be that experts who are overtrained on our task would still use a sequential parsing algorithm even after extensive practice, but simply speed the algorithm up (this may even be the case in musical sight-reading). Our task design allows us to test these competing predictions in future studies.</p><p>Our study has several limitations. First, our modeling is somewhat simple; additional computations, such as an evidence accumulation threshold for proceeding through levels of the visuomotor mapping, could be added. However, it is not clear that such an approach would add explanatory power to the model for our task where relevant visual features are binary and fitting such models to an 8-way decision task would require additional developments and likely need much more data than we have here. Second, our model does not delineate between the strictest possible version of a serial processing model -where moving to the next level in the mental mapping can only happen after resolving the previous level -and other variants of serial dynamics -where different levels may be processed simultaneously but perhaps with some being prioritized over others. In any case, it is likely that there are both parallel and sequential processing dynamics at play during our task -an idea that has been debated for decades <ref type="bibr" target="#b13">(Broadbent &amp; Broadbent, 1987;</ref><ref type="bibr" target="#b54">McLean et al., 1983;</ref><ref type="bibr" target="#b83">Treisman, 1977)</ref>. For example, the visual system is likely processing the stimuli holistically, rather than sequentially attending to each feature of each stimulus; in other words, there may be a fast perceptual process followed by slower cognitive processes to utilize the perceptual information to potentiate certain sets of actions. Further psychophysical work could test these ideas.</p><p>One open issue is that we focused on navigation "down" from the superordinate "control node" to an appropriate response in our analyses in Experiments 5 and 6; however, results from Experiments 1-4</p><p>show that the response on the previous trial affects response dynamics on the subsequent trial (i.e., there is evidence for "climbing back up" the putative tree). This raises an interesting question about how people get from a previous response "back" to a putative control node <ref type="bibr" target="#b64">(Rosenbaum et al., 1983)</ref>. One possibility is that they exhibit a level-by-level progression back up, similar to the proposed sequential, structured processing strategy during response selection. Alternatively, this "upward" phase of response selection might happen as a unitary step that takes longer when participants must trek further within the graph to prepare their next response. This question is difficult to address with the current behavioral data. First, we would need a larger number of trials for each transition type (i.e., path distances) in the forced response task in order to adequately sample each type of transition at various preparation times. Further, this type of analysis would require coding people's errors based on features of the previous trial (e.g., the response made versus stimulus seen), but the design of the forced response paradigm relies on participants making incorrect responses; thus, it is difficult to know whether to code path distances based on the response that the participant made on the previous trial or the stimulus that they had viewed on the previous trial. We circumvented this issue in Experiments 1-4 by considering only trials where participants responded correctly on both the current and previous trials, but this same logic is not possible during the forced response task.</p><p>Taken together, our results indicate that information can continuously flow from ongoing decisions to preparatory motor processes, even in the context of a complex visuomotor learning and memory retrieval task. This work goes beyond previous findings in low-level perceptual decision-making <ref type="bibr" target="#b15">(Burk et al., 2014;</ref><ref type="bibr" target="#b18">Cisek &amp; Kalaska, 2002;</ref><ref type="bibr" target="#b39">Hagura et al., 2017;</ref><ref type="bibr" target="#b55">Moher &amp; Song, 2014;</ref><ref type="bibr" target="#b67">Selen et al., 2012</ref><ref type="bibr" target="#b65">Selen et al., , 2023</ref><ref type="bibr" target="#b80">Thura &amp; Cisek, 2014</ref>) by linking the dynamic potentiation of actions to higher-level, learned abstract mappings. Our findings thus demonstrate a tight link between learned, abstract representations of latent structure in the environment to rapid motor control processes. This study also makes novel connections between research on cognitive maps and graphs in organizing behavior and knowledge <ref type="bibr" target="#b7">(Behrens et al., 2018;</ref><ref type="bibr" target="#b17">Chrastil &amp; Warren, 2014;</ref><ref type="bibr" target="#b58">Peer et al., 2021)</ref> and the study of sensorimotor learning and control, perhaps offering a new avenue for understanding the format of mental representations for complex, naturalistic visuomotor skills.</p><p>Overall, our work raises questions about nominal distinctions between high-level cognitive processing and low-level motor processing and provides evidence for highly interactive, dynamic systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited all participants from the Yale University undergraduate community <ref type="formula">(Experiment 1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>Task design. Experimental sessions were approximately 1 hour in duration and consisted of a reaction time (RT) baseline task, a task training phase, and the learning task. The task was coded in jsPsych <ref type="bibr">(version 6.1.0, de Leeuw et al., 2023)</ref>. All data reported in this manuscript was collected on a Lenovo Ideapad 5 (Ubuntu 22.04).</p><p>Reaction time baseline task. Participants first completed a RT baseline task in order to measure intrinsic finger-to-finger switch costs without the influence of the learning task. They performed the baseline task again following the learning task. The tasks before and after learning were identical and lasted approximately 5 minutes in duration. During this task, participants used their left hand (on keys A, S, D, F) and right hand (on keys H, J, K, L) to respond to the position of a target red square on the screen. On each trial, they would see eight squares on the screen that were spatially aligned with their fingers on the keyboard. Seven of the squares were white while one square was green. Their goal was to press the key aligned with the green square. Once they had made the correct response, all squares turned white for 100ms before another square would turn green to initiate the next trial. The next trial would not begin until the participant made the correct response. We used this constraint to avoid having participants rapidly responding with incorrect responses to expedite the task. Only trials where participants made the correct response on their first attempt were included in analysis. Additionally, we excluded the first five trials in the task from analysis to account for slowed reaction times at the beginning of the block. Trial sequences included all pairwise transitions between fingers (including repeating the same finger) a minimum of four times, in order to ensure a stable switch cost estimate for each pairwise transition between fingers.</p><p>Learning task. After the motor task, participants were familiarized with the structure of the learning task with 15 trials of a simplified version of the task. During this practice phase, participants were instructed to use trial-by-trial feedback to learn the correct key to press (H, J, or K) in response to three highly distinguishable emoji stimuli. Participants would see an emoji on every trial and then guess a response before receiving binary feedback as to whether their response was correct or not. Trial duration was unrestricted in this phase.</p><p>After familiarization with the basics of the learning task, participants returned their hands to the keys that they had used during the RT baseline task (left hand: A, S, D, F; right hand: H, J, K, L). Before the learning task began, participants saw an instruction screen with eight stimuli that would be used during the task arranged in a random order on the screen. Once the task began, participants saw one stimulus per trial and used trial-by-trial feedback to learn the correct button to press in response to each stimulus. Correct stimulus-response associations were deterministic. The sequence of stimuli was random, such that every trial was independent. On every trial, participants would see a single stimulus, make a response, and then get feedback as to whether their response was correct or not (feedback duration: 750ms; <ref type="figure" target="#fig_0">Figure 1C)</ref>. The next trial would proceed after the feedback from the previous trial disappeared. If the participant did not make a response within 2.5s of viewing the stimulus, the trial would time out and the participant would receive feedback that they needed to respond more quickly. Participants saw each of the eight stimuli at least 125 times (i.e., 125 iterations of each stimulus) during the learning task.</p><p>Stimulus and visuomotor mapping design. Each stimulus varied along three features: color (red, orange, blue, purple), shape (square, circle, triangle, diamond), and pattern (vertical stripes, diagonal stripes, dots, checkerboard). We randomly selected two possible values for each feature (e.g., red and blue, square and circle, vertical stripes and dots) for each participant. Thus, all of the combinations of specific features yielded eight unique stimuli per participant.</p><p>To embed structure into the task, we assigned each feature to a level of an intuitive motor hierarchy, such that one feature indicated what hand to respond with (top-level), another feature dictated a pair of fingers within each hand or "couplet" (mid-level), and the remaining feature could be used to determine the correct response within a couplet (low-level; <ref type="figure" target="#fig_0">Figure 1B)</ref>. For example, if color was associated with the top level, then all stimuli of one color would be associated with responses in the right hand and all stimuli of the other color would be associated with responses in the left hand. Mid-and low-level features were assigned from left to right in extrinsic space ( <ref type="figure" target="#fig_0">Figure 1B)</ref>. There were six possible assignments of features to level (color &gt; shape &gt; pattern; color &gt; pattern &gt; shape; shape &gt; color &gt; pattern; shape &gt; pattern &gt; color; pattern &gt; shape &gt; color; pattern &gt; color &gt; shape) and we counterbalanced the assignment of features to level across participants. Participants were never instructed about the structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>Task Design. Task design was identical to that of Experiment 1 except for three key details. First, participants only executed the baseline task once at the beginning of the experiment, rather than before and after the learning task. Second, the task duration was shorter (approximately 30min) and participants saw only 55 presentations of each of the eight stimuli. Finally, we modified the hierarchical structure of the visuomotor mapping: Instead of feature values being assigned spatially in extrinsic space from left to right, we aligned the structure with the mirror symmetry of the motor system ( <ref type="figure" target="#fig_2">Figure 3A)</ref>. For example, while the stimuli associated with the left pinky and right index finger shared mid-and low-level features in Experiment 1, the left and right index fingers shared the mid-and low-level features in Experiment 2. As in Experiment 1, we counterbalanced the assignment of features to task levels. The task was coded in jsPsych <ref type="bibr">(version 6.1.0, de Leeuw et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Task Design. Task design was identical to that of Experiment 1, except for the stimuli and structure of the visuomotor mapping. Participants were assigned one of two possible stimulus sets in this experiment.</p><p>In this case, stimuli varied only along one feature (rather than three), either color or shape. Some participants saw eight squares of different colors during the task <ref type="figure" target="#fig_2">(Figure 3E</ref>; orange, green, yellow, red, blue, pink, brown, purple) and others saw eight different shapes that were all black (square, circle, plus, diamond, pentagon, triangle, crescent moon, start). This change meant that there was no learnable visuomotor structure embedded into the task. All other details were the same as in Experiment 1 (RT baseline task before and after learning, 125 iterations of each stimulus). The task was coded in jsPsych <ref type="bibr">(version 6.1.0, de Leeuw et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 4</head><p>Task Design. Overall task design was the same as in the previous three experiments. In this experiment, participants saw 55 iterations of each stimulus and only performed the RT baseline task once in the beginning of the session. We again used the three-feature stimuli described for Experiments 2 and 3;</p><p>however, in this experiment, we created pseudorandomized mappings that minimized the amount of learnable intuitive motor structure in the mapping <ref type="figure" target="#fig_2">(Figure 3I)</ref>. We opted for pseudorandomized mappings rather than fully randomizing the stimulus-response associations because randomizing the limited number of features and stimuli often created somewhat structured mappings (for example shuffled mappings, see Supplemental <ref type="figure" target="#fig_0">Figure S1</ref>). The task was coded in jsPsych <ref type="bibr">(version 6.1.0, de Leeuw et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 5</head><p>Task Design. In Experiment 5, participants started with the RT baseline task before moving into the learning task. Participants saw approximately 55 iterations of each stimulus in this task. Visuomotor mappings followed the same structure as explained in Experiment 1 (Supplemental <ref type="figure" target="#fig_1">Figure S2A)</ref>. After participants had learned the mapping during the learning task, participants performed a forced response task with the learned associations. Experiments 5 and 6 were coded in Octave <ref type="bibr">(version 6.4.0, Eaton et al., 2020), using PsychToolbox (version 3.0.18;</ref><ref type="bibr" target="#b11">Brainard, 1997)</ref>.</p><p>Forced response task. During this task, participants heard four ascending beeps (400ms apart) on each trial ( <ref type="figure" target="#fig_4">Figure 4A)</ref>. Participants were instructed to time their response with the fourth of the beeps, regardless of whether they felt prepared to respond. We varied the time point at which the stimulus appeared on the screen during the beeps in order to manipulate the amount of motor preparation time participants had to make their responses on a trial-by-trial basis. Preparation time (PT) is defined as the interval between when the stimulus appeared and the last beep of the trial. PTs were randomly selected from a uniform distribution from 100ms-1.2s. Thus, on some trials, participants would have sufficient time to prepare, while on others they would have to prepare very rapidly (or guess). Participants were encouraged to respond at the appropriate time on each trial even if they felt that they were guessing. After the participant made a response, they received feedback (750ms) on whether their response was correct or not and whether they had responded in time with the fourth beep. Subjects had a +/-50ms cushion from the exact instructed timing within which they would receive positive feedback.</p><p>Participants were familiarized with the forced response task using the same emoji stimuli that were used to familiarize them with the learning task. This forced response familiarization period occurred after the learning task practice and before the main learning task. After the learning task was completed, participants executed approximately 760 forced response trials (95 iterations per stimulus) and the task took approximately 25 minutes. Participants had the option to take self-timed breaks following each 100-trial block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 6</head><p>Task Design. Experiment 6 followed the same protocol as Experiment 5, with one change. The difference from Experiment 5 was that participants were trained (Supplemental <ref type="figure" target="#fig_1">Figure 2E)</ref> on unstructured mappings using the stimuli from Experiment 3 (eight squares of different colors or eight black shapes, counterbalanced). Again, participants first executed the baseline task, followed by familiarization with the learning and forced response paradigms. After familiarization, participants learned the visuomotor mapping during the learning task. The session ended with the forced response paradigm described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Data and analysis code will be available at https://github.com/jetrach/StructuredActionPrep VMDM upon publication of the manuscript.</p><p>Motor correction. We operationalized structure in the learned visuomotor mappings by linking visual features to intuitive groupings of actions. Because our main interest was how the previous trial's action affected the current trial, we had one major confound to contend with: intrinsic switch costs between the different fingers of each hand. Thus, we wanted to ensure that any reaction time effects that we observed as a result of learning the visuomotor mapping were due to the structure of the mapping, rather than generic spatial or biomechanical influences on transitional RTs between fingers. To do this, we calculated the mean RT for each of the 64 pairwise transitions between fingers during the baseline task. We then subtracted these RTs from the RTs of trials of the same finger-to-finger transitions during the learning task ( <ref type="figure" target="#fig_0">Figure   1E</ref>). Thus, we removed variance in the RTs that was present during the baseline task in order to isolate the impact of the learning task structure on RT. We performed our further analyses on these baseline-corrected RTs. We excluded the first three trials of the task and RTs that were especially slow indicating that the participant was not attending to the task (3 SD above the mean RT).</p><p>Learning task. Our primary analyses in Experiments 1-4 were based on a straightforward logic:</p><p>That after learning, reaction times for correct responses would be influenced by the previous trial in a manner dictated by the learned visuomotor mapping, even though the sequence of stimuli across trials was randomized (i.e., every trial was independent). That is, we reasoned that transitional RTs would spontaneously reflect the structure of the visuomotor mappings that people learned <ref type="bibr" target="#b28">(Dykstra et al., 2022)</ref>.</p><p>Analyses were conducted in R (R version: 4.2.1, 2022) or MATLAB (Version: 9.12.0, 2022a, Update 4).</p><p>We used repeated measures ANOVAs and linear mixed effects models to analyze our data.</p><p>Additionally, we used two-tailed one-or two-sample t-tests where appropriate and corrected for multiple comparisons using a Bonferroni correction. We used Welch t-tests when assumptions of normality were violated.We used Cohen's d to quantify effect sizes (effsize package in R). Transitional RT analyses were performed on trials where participants responded correctly to the current and preceding trial ("consecutively correct trials"). We did this to ensure we were examining response dynamics after the participant had sufficiently learned the mapping, and to avoid confounds from post-error slowing that can occur in reinforcement learning settings <ref type="bibr" target="#b51">(McDougle, 2022)</ref>. We note, however, that the main results do not qualitatively change if we include all correct trials without conditioning on the previous trial being correct.</p><p>We removed outlier reaction times (RTs) by excluding RT under 200ms where participants would not have had sufficient time to respond and RTs three standard deviations above the participant's average RT. In addition, we excluded first three trials for each participant to account for task initiation costs.</p><p>We designed three linear mixed effects models to operationalize our three main theoretical models of behavior. For the "hierarchical" model, the model used the number of graph edges or "path distance" between responses (0, 2, 4, or 6) on a given pair of successive trials to predict corrected reaction times. If the top-level feature (e.g., shape) changed across trials, there were 6 graph edges between consecutive responses. On trials where the top-level feature repeated but the mid-level feature switched, there were 4 graph edges between consecutive responses. When the low-level feature switched, there were 2 edges between responses, and on trials where the exact stimulus repeated there were 0 edges between responses.</p><p>We utilized the structure we embedded into the mapping to calculate these distances in Experiments 1 and 2. In Experiments 3 and 4, where there was no latent structure in the mapping, we used the extrinsic space hierarchical structure to calculate these path distances. This approach allows us to rule out alternative accounts of hierarchical effects in Experiments 1 and 2.</p><p>For the "feature" model, we used the number of visual features that changed between the previous and current trial <ref type="bibr">(0, 1, 2, or 3)</ref> to predict baseline-corrected RTs. For the flat model, we just modeled whether the stimulus repeated or switched (0 or 1) to predict baseline-corrected RTs. Lastly, in addition to these three theoretically motivated models, we also fit a fourth model that counted the number of fingers between responses to predict corrected RT (0-7). This model operationalizes a spatially modulated attentional effect where participants are faster to make responses that are adjacent to their previous response. We included random intercepts and slopes for each subject and compared model fits using the Bayesian Information Criterion (BIC).</p><p>Forced response task (Experiments 5 and 6). Our analyses for this task examined the probability of different types of errors that participants made as a function of preparation time (PT). To do this, we first calculated the actual PT that participants had on each trial by adding their reaction time to the planned preparation time that was hard coded into the trial (i.e., the interval between the visual stimulus appearance and the fourth tone in the countdown). For example, if the stimulus was displayed 700ms before the response cue on a given trial, and the participant made their response 50ms after the response cue, the actual PT on that trial would be 750ms. Similarly, if the participant responds 50ms before the cue, then actual PT on that trial would be 650ms. We did this to quantify preparation time more accurately on a trial-by-trial basis.</p><p>In Experiment 5, we classified errors based on the highest feature level where there was a mismatch between the target stimulus and the stimulus associated with the response that the participant made ( <ref type="figure" target="#fig_4">Figure   4B</ref>). Thus, there was one correct response, one low-level error, two mid-level errors, and four top-level errors possible on each trial. We normalized chance probabilities across error levels by dividing the raw probability of errors at each level by the number of responses associated with that level. In addition to this approach, we conducted primary analyses with errors coded for shared features between the target stimulus and the stimulus mapped to the response that the participant made at each level of the task (i.e., without combining probabilities within error-level). Visualizations of this approach are depicted in Supplemental <ref type="figure" target="#fig_2">Figure S3</ref>. We excluded trials where participants did not respond within 100ms of the response cue.</p><p>Because Experiment 6 operates as a control experiment to rule out generic motor/spatial explanations of our forced response time results, we applied the error coding scheme that we used in Experiment 5 to the responses in Experiment 6, as if those stimuli were structured in the same way. To visualize forced preparation time results, we calculated the average probability of making each type of error in a 100ms sliding window that was moved across the full range of PTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Response preparation models.</head><p>We modified a previous model of response selection <ref type="bibr" target="#b41">(Hardwick et al., 2019)</ref> to formalize three theoretical models of action selection in our forced response task. The basic model assumes that the time (T) it takes to prepare an action a is described by a normal distribution with a mean μ and standard deviation σ:</p><p>(1) Ta = N(μa , σa)</p><p>By taking the cumulative density of this distribution, we get a sigmoidal function pa that describes the probability of having prepared action a at any given preparation time. The probability that a given response is prepared is thus dependent on the amount of preparation time and the μ and σ parameters that describe the response preparation distribution.</p><p>We fit four extensions of this straightforward model to participant data. The first model -the Flat model -assumes that the preparation of the correct action a simply involves an increase in the probability of selecting that action over time (i.e., the cumulative density function of equation 1, pa). Critically, the model treats the selection of any of the seven other actions as equally probable at each time point. This model captures the idea that even if participants mentally represent the structure of the task, only a single action is potentiated at any time during action selection; this would be consistent with a strict separation of deciding on the correct S-R association and preparing actual motor commands. Moreover, this model would be the best candidate for unstructured versions of the visuomotor mapping that have no imbued structure (Experiment 6). In our second model variant -the Hierarchical model -we extend Equation 1 to the preparation of "groupings" of actions associated with each level, j, of the structured visuomotor mapping (Experiments 1, 2, and 5):</p><p>(2) Tj = N(μj , σj)</p><p>With each level having its own μ and σ free parameters, and where each μ describes how long, on average, it takes for a participant to "resolve" level j of the learned mapping and prepare the relevant set of actions. Specifically, preparing the top level involves preparing all four actions on the correct hand, preparing the middle level involves preparing the correct couplet on each hand, and preparing the lowest level involves preparing the correct left versus right finger position across all couplets. According to this model, if sequential resolving from top to bottom of each level of the visuomotor mapping potentiates the associated motor commands in real time, the fitted μ parameters should take the lowest values for the top/hand level (i.e., the top is resolved first), middling values for the middle/couplet level, and the highest values for the low/finger level. In other words, according to this structured action preparation model, the participant arrives at the correct action by sequentially "pruning" the visuomotor mapping in real time.</p><p>We fit an additional variant of this model that included only one σ free parameter that was used at all levels of the structure to see if variance in preparation times was comparable across levels. Lastly, we fit an additional variant of the model to formalize a Feature-based model of action selection. Here, we only allowed for one μ and one σ parameter but maintained the structured preparation of action groupings; this model thus assumes that the learned feature-action associations shaped action selection but with no temporal prioritization of any particular features/levels.</p><p>Finally, we note that people often have to guess in the forced response time task given the strict temporal criteria. Thus, the goal-oriented action preparation processes described above are mixed at each time point with a "guessing" or "lapse" process that assumes a uniform probability of any of the eight possible actions being selected, with a mixture parameter ρ that determines the weighting of guessing versus goal-oriented action preparation. This mixture model thus determines the final speed-accuracy probability function P of selecting action a:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Design. A) Example musical notation and the associated action/key. B) Example visuomotor mapping with the correct key</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Example trial and illustrations of three theoretical models of behavior and predicted transitional RTs under each model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Experiment 1: A) Example mapping aligned with extrinsic space. B) Learning curve. C) Corrected RTs plotted by path distance (consecutively correct trials only). D) Linear mixed effects modeling results plotted as the difference in BIC between the hierarchical model (line at 0) and alternatives (feature, flat, physical distance). Positive values indicate that the hierarchical model was the best fit for participant behavior. Experiment 2: E-H) Same as Experiment 1. Experiment 3: I-L) Same as Experiment 1 -Note that L includes only two points for the flat and physical distance alternative models since stimuli vary only along one feature. Experiment 4: M-P) Same as Experiment 2. Q) Legend for mapping the hierarchical clustering dendrogram results onto fingers. R-U) Hierarchical clustering results for Experiments 1-4. Hierarchical clustering reproduces the latent structure of the visuomotor mapping in Experiments 1 and 2. Unstructured mappings (i.e., Experiments 3 and 4) yield idiosyncratic dendrograms. V) Hierarchical clustering results for the RT baseline task. Error bars/shading = 1 S.E.M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>3 vs Experiment 1: t(69.13) = 3.82, p &lt; .001, Cohen's d = 0.87, 95% CI = [-0.2, -0.06]; Experiment 3 vs Experiment 2: t(54.85) = 3.17, p = .002, Cohen's d = 0.82, 95% CI = [0.04, 0.17]) and faster (Experiment 3 vs Experiment 1: t(70.78) = 8.00, p &lt; .001, Cohen's d = 1.86, 95% CI = [188.03, 312.83]; Experiment 3 vs Experiment 2: t(51,71) = 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>A) Diagram of a forced response trial, including arrows to indicate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>mid-level error: t(107) = 5.83, p &lt; .001, 95% CI = [0.02, 0.04], Cohen's d = 0.63; low-vs. top-level error: t(107) = 8.82, p &lt; .001, 95% CI = [0.04, 0.06], Cohen's d = 1.03; mid-vs. top-level error: t(107) = 3.19, p = .002, 95% CI = [0.007, 0.03], Cohen's d = 0.36). This strongly suggests that our results are not driven by the visual similarity of the cues, but rather by the latent structure of the learned visuomotor mapping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>: N = 44; Experiment 2: N = 29; Experiment 3: N = 34; Experiment 4: N = 28; Experiment 5: N = 40; Experiment 6: N = 20), and all experiments were conducted in line with a protocol approved by the University's Institutional Review Board. Participants received course credit for their participation. All participants reported that they were not colorblind and had normal or corrected-to-normal vision. We planned a priori to exclude participants that did not show reliable evidence of learning by excluding participants that did not show over 25% accuracy for at least 4 of the 8 visuomotor associations (Total exclusions: Experiment 1: N = 3; Experiment 2: N = 1; Experiment 3: N = 0; Experiment 4: N = 1; Experiment 5: N = 4; Experiment 6: N = 1). There were also a small number of exclusions due to technical issues (Experiment 1: N = 1; Experiment 3: N = 1; Experiment 4: N = 1). Additionally, we planned to exclude participants who were not attentive to the task by excluding participants who did not respond on at least 75% of the trials in the learning task for Experiments 1-4 and for the learning or forced response task in Experiments 5-6. No participants met this exclusion criterion. After exclusions, we had 40 participants in Experiment 1 (N female = 17, mean age = 20.1), 28 participants in Experiment 2 (N female = 20, mean age = 19.1), 33 participants in Experiment 3 (N female = 18, mean age = 19.7), 26 participants in Experiment 4 (N female = 16, mean age = 19.3), 36 participants in Experiment 5 (N female = 19, mean age = 19.6), and 19 participants in Experiment 6 (N female = 15, mean age = 20.2).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Alex Forrence, Tolu Adanri, Jed Burde, Katherine Chou, Steph Hu, Liz Pandolpho, and Ophelia Pilkinton for essential support in collecting data for these projects. In addition, we would like to thank Drs. Theresa Desrochers and Jordan Taylor for feedback on early drafts of the manuscript, and the members of the ACT lab at Yale University for productive conversations about this work throughout. JET is supported by the NSF GRFP. SDM is supported by NIH grant R01 NS132926.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p>Data will be available at https://github.com/jetrach/StructuredActionPrepVMDM upon publication of the manuscript. Reviewers are provided a zip file by the editor for review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability and software</head><p>Code will be available at https://github.com/jetrach/StructuredActionPrepVMDM upon publication of the manuscript. Reviewers are provided a zip file by the editor for review. Task code is available upon request. Please refer to Methods for details on software utilized in this project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inclusion and ethics statement</head><p>All authors are properly acknowledged. Additional contributions are noted in the Acknowledgements.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">We ran 50 iterations of each fitting procedure for each participant to avoid local minima in the optimized model fits. To simulate the results, we computed the model&apos;s response probability functions using the best fit parameters for each</title>
		<imprint>
			<pubPlace>Natick, Massachusetts</pubPlace>
		</imprint>
	</monogr>
	<note>P generated by each model at each preparation time (rounded to the nearest ms) were fit directly to actual participant responses and preparation times measured in the forced response tasks (Experiments 5 and 6). participant and then averaged the resulting curves over all</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Motor planning under uncertainty. eLife, 10, e67019</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Alhussein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.67019</idno>
		<ptr target="https://doi.org/10.7554/eLife.67019" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Badre</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2008.02.004</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2008.02.004" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="193" to="200" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Is the rostro-caudal axis of the frontal lobe hierarchical?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Badre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Esposito</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn2667</idno>
		<ptr target="https://doi.org/10.1038/nrn2667" />
	</analytic>
	<monogr>
		<title level="m">Article 9</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Frontal Cortex and the Hierarchical Control of Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Badre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Nee</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2017.11.005</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2017.11.005" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="170" to="188" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Balaguer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Spiers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="893" to="903" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2016.03.037</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2016.03.037" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E J</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C R</forename><surname>Whittington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Baram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Stachenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurth-Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">What is a cognitive map? Organizing knowledge for flexible behavior</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2018.10.002</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2018.10.002" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchically organized behavior and its neural foundations: A reinforcement learning perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Barto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="262" to="280" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2008.08.011</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2008.08.011" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Psychophysics Toolbox</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hierarchical structure guides rapid linguistic predictions during naturalistic listening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Hale</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0207741</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0207741" />
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">From detection to identification: Response to multiple targets in rapid serial visual presentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Broadbent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H P</forename><surname>Broadbent</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03210498</idno>
		<ptr target="https://doi.org/10.3758/BF03210498" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="113" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Prospective representation of navigational goals in the human hippocampus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">I</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">F</forename><surname>Larocque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Favila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Bailenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aaf0784</idno>
		<ptr target="https://doi.org/10.1126/science.aaf0784" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">352</biblScope>
			<biblScope unit="issue">6291</biblScope>
			<biblScope unit="page" from="1323" to="1326" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Motor Effort Alters Changes of Mind in Sensorimotor Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Wolpert</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0092681</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0092681" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamics of Hierarchical Task Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cellier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0233-22.2022</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0233-22.2022" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">From Cognitive Maps to Cognitive Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Chrastil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0112544</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0112544" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simultaneous Encoding of Multiple Potential Reach Directions in Dorsal Premotor Cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cisek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kalaska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1149" to="1154" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<idno type="DOI">10.1152/jn.00443.2001</idno>
		<ptr target="https://doi.org/10.1152/jn.00443.2001" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the challenges and mechanisms of embodied decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cisek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pastor-Bernier</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2013.0479</idno>
		<ptr target="https://doi.org/10.1098/rstb.2013.0479" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<date type="published" when="1655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Cost of Structure Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G E</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_01128</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_01128" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1646" to="1655" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Organizing conceptual knowledge in humans with a gridlike code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Constantinescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E J</forename><surname>Behrens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">352</biblScope>
			<biblScope unit="issue">6292</biblScope>
			<biblScope unit="page" from="1464" to="1467" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hierarchical schemas and goals in the control of sequential behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shallice</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.113.4.887</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.113.4.887" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="887" to="916" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">jsPsych: Enabling an open-source collaborative ecosystem of behavioral experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Luchterhandt</surname></persName>
		</author>
		<idno type="DOI">https://joss.theoj.org/papers/10.21105/joss.05351</idno>
		<ptr target="https://joss.theoj.org/papers/10.21105/joss.05351" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">85</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Two Distinct Ipsilateral Cortical Representations for Individuated Finger Movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diedrichsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wiestler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Krakauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1362" to="1377" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<idno type="DOI">10.1093/cercor/bhs120</idno>
		<ptr target="https://doi.org/10.1093/cercor/bhs120" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evidence for Hierarchical Cognitive Control in the Human Cerebellum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>D'mello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D E</forename><surname>Gabrieli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Nee</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2020.03.028</idno>
		<idno>1881-1892.e3</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2020.03.028" />
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Measuring task structure with transitional response times: Task representations are more than task sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dykstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Schumacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazeltine</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-021-02035-3</idno>
		<ptr target="https://doi.org/10.3758/s13423-021-02035-3" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">GNU Octave version 6.1.0 manual: a high-level interactive language for numerical computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">W</forename><surname>Eaton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bateman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Søren</forename><surname>Hauberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Wehbring</surname></persName>
		</author>
		<ptr target="https://www.gnu.org/software/octave/doc/v6.1.0/" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Space, time, and episodic memory: The hippocampus is all over the cognitive map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Ekstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ranganath</surname></persName>
		</author>
		<idno type="DOI">10.1002/hipo.22750</idno>
		<ptr target="https://doi.org/10.1002/hipo.22750" />
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="680" to="687" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Finger in Flight Reveals Parallel Categorization Across Multiple Social Dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ambady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Cognition</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="792" to="805" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<idno type="DOI">10.1521/soco.2013.31.6.792</idno>
		<ptr target="https://doi.org/10.1521/soco.2013.31.6.792" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Decision-making in sensorimotor control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Gallivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Flanagan</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41583-018-0045-9</idno>
		<ptr target="https://doi.org/10.1038/s41583-018-0045-9" />
	</analytic>
	<monogr>
		<title level="m">Article 9</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Discrete and continuous planning of hand movements and isometric force trajectories: Experimental Brain Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ghez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Favilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Ghilardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bermejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pullman</surname></persName>
		</author>
		<idno type="DOI">10.1007/PL00005692</idno>
		<ptr target="https://doi.org/10.1007/PL00005692" />
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="217" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The Neural Basis of Decision Making. Annual Review of Neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="535" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<idno type="DOI">10.1146/annurev.neuro.29.051605.113038</idno>
		<ptr target="https://doi.org/10.1146/annurev.neuro.29.051605.113038" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The road towards understanding embodied decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Lancia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Thiery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cisek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience &amp; Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="722" to="736" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neubiorev.2021.09.034</idno>
		<ptr target="https://doi.org/10.1016/j.neubiorev.2021.09.034" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Perceptual decisions are biased by the cost to act. eLife, 6, e18422</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hagura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haggard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diedrichsen</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.18422</idno>
		<ptr target="https://doi.org/10.7554/eLife.18422" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Hedging Your Bets: Intermediate Movements as Optimal Behavior in the Context of an Incomplete Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Haith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Huberdeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Krakauer</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1004171</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1004171" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Time-dependent competition between goal-directed and habitual response preparation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hardwick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Forrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Krakauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Haith</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0725-0</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0725-0" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1252" to="1262" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modelling human behaviour in cognitive tasks with latent dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">I</forename><surname>Jaffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Bissett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41562-022-01510-8</idno>
		<ptr target="https://doi.org/10.1038/s41562-022-01510-8" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Process reveals structure: How a network is traversed mediates expectations about its architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Karuza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Thompson-Schill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Bassett</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-017-12876-5</idno>
		<ptr target="https://doi.org/10.1038/s41598-017-12876-5" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">_factoextra: Extract and Visualize the Results of Multivariate Data Analyses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kassambara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mundt</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=factoextra" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 1.0.7</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hierarchically organized medial frontal cortexbasal ganglia loops selectively control task-and response-selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Korb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Egner</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.3289-16.2017</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.3289-16.2017" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="7893" to="7905" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Toward an Instance Theory of Automatization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="492" to="527" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automatic Control: How Experts Act Without Thinking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000100</idno>
		<ptr target="https://doi.org/10.1037/rev0000100" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="453" to="485" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">cluster: Cluster Analysis Basics and Extensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Struyf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=cluster" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>R package version 2.1.3.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Moving hand reveals dynamics of thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Magnuson</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0504413102</idno>
		<ptr target="https://doi.org/10.1073/pnas.0504413102" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page" from="9995" to="9996" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Post-error Slowing During Instrumental Learning is Shaped by Working Memory-based Choice Strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Mcdougle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="page" from="37" to="45" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuroscience.2021.10.016</idno>
		<ptr target="https://doi.org/10.1016/j.neuroscience.2021.10.016" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dissociable cognitive strategies for sensorimotor learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Mcdougle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-018-07941-0</idno>
		<ptr target="https://doi.org/10.1038/s41467-018-07941-0" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">40</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Combining attributes in rapid serial visual presentation tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Mclean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Broadbent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H P</forename><surname>Broadbent</surname></persName>
		</author>
		<idno type="DOI">10.1080/14640748308402123</idno>
		<ptr target="https://doi.org/10.1080/14640748308402123" />
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Perceptual decision processes flexibly adapt to avoid change-of-mind motor costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1167/14.8.1</idno>
		<ptr target="https://doi.org/10.1167/14.8.1" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Examining cognitive flexibility and stability through the lens of dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musslick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bizyaeva</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2024.101375</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2024.101375" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">101375</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rationalizing constraints on the capacity for cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musslick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2021.06.001</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2021.06.001" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="757" to="775" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Structuring Knowledge with Cognitive Maps and Cognitive Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">K</forename><surname>Brunec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Epstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="54" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.tics.2020.10.004</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2020.10.004" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing. R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint>
			<date type="published" when="2022" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Parallel temporal dynamics in hierarchical cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ranti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Chatham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Badre</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2015.05.003</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2015.05.003" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="205" to="229" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Organization revealed by recall orders and confirmed by pauses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Reitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Rueter</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(80)90020-1</idno>
		<ptr target="https://doi.org/10.1016/0010-0285(80)90020-1" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="554" to="581" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Humans can navigate complex graph structures acquired during latent learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bornstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2022.105103</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2022.105103" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">225</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Hierarchical control of rapid movement sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Derr</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.9.1.86</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.9.1.86" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="102" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Single-Trial Dynamics of Competing Reach Plans in the Human Motor Periphery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P J</forename><surname>Selen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Corneil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Medendorp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="2782" to="2793" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.1640-22.2023</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.1640-22.2023" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Deliberation in the Motor System: Reflex Gains Track Evolving Evidence Leading to a Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P J</forename><surname>Selen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2276" to="2286" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.5273-11.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.5273-11.2012" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Decision Making as a Window on Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2013.10.047</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2013.10.047" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="791" to="806" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Numeric comparison in a visually-guided manual reaching task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2007.03.014</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2007.03.014" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="994" to="1003" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Target selection in visual search as revealed by movement trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2007.12.015</idno>
		<ptr target="https://doi.org/10.1016/j.visres.2007.12.015" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="853" to="861" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Hidden cognitive states revealed in choice reaching tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2009.04.009</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2009.04.009" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="360" to="366" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Continuous Dynamics in Real-Time Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Spivey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8721.2006.00437.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-8721.2006.00437.x" />
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="207" to="211" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Continuous attraction toward phonological competitors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Spivey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grosjean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Knoblich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page" from="10393" to="10398" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.0503903102</idno>
		<ptr target="https://doi.org/10.1073/pnas.0503903102" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A Map for Social Navigation in the Human Brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Tavares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendelsohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Trope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="231" to="243" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2015.06.011</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2015.06.011" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title/>
		<idno>MATLAB version: 9.13.0</idno>
		<ptr target="https://www.mathworks.com" />
	</analytic>
	<monogr>
		<title level="j">The MathWorks Inc</title>
		<imprint>
			<date type="published" when="2022" />
			<publisher>The MathWorks Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Learning and Representation of Hierarchical Concepts in Hippocampus and Prefrontal Cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Theves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Doeller</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0657-21.2021</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0657-21.2021" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">36</biblScope>
			<biblScope unit="page" from="7675" to="7686" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Deliberation and Commitment in the Premotor and Primary Motor Cortex during Dynamic Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cisek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1401" to="1416" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2014.01.031</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2014.01.031" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Abstract sequential task control is facilitated by practice and embedded motor sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Trach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Mckim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Desrochers</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0001004</idno>
		<ptr target="https://doi.org/10.1037/xlm0001004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1638" to="1659" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Focused attention in the perception and retrieval of multidimensional stimuli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206074</idno>
		<ptr target="https://doi.org/10.3758/BF03206074" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Hierarchies in Action and Motor Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uithol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Van Rooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bekkering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haselager</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_00204</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_00204" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1077" to="1086" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C R</forename><surname>Whittington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E J</forename><surname>Behrens</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cell.2020.10.024</idno>
		<ptr target="https://doi.org/10.1016/j.cell.2020.10.024" />
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1249" to="1263" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Motor planning flexibly optimizes performance under uncertainty about task goals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Haith</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms14624</idno>
		<ptr target="https://doi.org/10.1038/ncomms14624" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14624</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Similarities and differences in spatial and non-spatial cognitive maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Garvert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Schuck</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1008149</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1008149" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Complementary Task Structure Representations in Hippocampus and Orbitofrontal Cortex during an Odor Sequence Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Montesinos-Cartagena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Wikenheiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P H</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schoenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2019.08</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2019.08" />
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="3402" to="3409" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
