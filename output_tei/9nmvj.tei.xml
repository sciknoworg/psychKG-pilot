<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Overharvesting in human patch foraging reflects rational structure learning and adaptive planning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-12-01">December 1, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nora</forename><forename type="middle">C</forename><surname>Harhen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Cognitive Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">M</forename><surname>Bornstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Cognitive Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for the Neurobiology of Learning and Memory</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<addrLine>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Overharvesting in human patch foraging reflects rational structure learning and adaptive planning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-12-01">December 1, 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T12:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Patch foraging presents a sequential decision-making problem widely studied across organisms-stay with a current option or leave it in search of a better alternative? Behavioral ecology has identified an optimal strategy for these decisions, but, across species, foragers systematically deviate from it, staying too long with an option or &quot;overharvesting&quot; relative to this optimum. Despite the ubiquity of this behavior, the mechanism underlying it remains unclear and an object of extensive investigation. Here, we address this gap by approaching foraging as both a decision-making and learning problem. Specifically, we propose a model in which foragers 1) rationally infer the structure in their environment and 2) use their uncertainty over the inferred structure representation to adaptively discount future rewards. We find that overharvesting can emerge from this rational statistical inference and uncertainty adaptation process. In a patch leaving task, we show that human participants adapt their foraging to the richness and dynamics of the environment in ways consistent with our model. These findings suggest that definitions of optimal foraging could be extended by considering how foragers reduce and adapt to uncertainty over representations of their environment.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>averaging over all previous experiences <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b7">8)</ref> and Bayesian updating <ref type="bibr" target="#b8">(9)</ref>. In this prior work, learning of environment quality is foregrounded while knowledge of environment structure is assumed. In a homogeneous environment, as is nearly universally employed in these experiments, this is a reasonable assumption as a single experience in a patch can be broadly generalized from across other patches. However, it may be less reasonable in more naturalistic heterogeneous environments with regional variation in richness. To make accurate predictions within a local patch, the forager must learn the heterogeneous structure of the broader environment. How might they rationally do so?</p><p>Here, we show that apparent overharvesting in these tasks can be explained by combining structure learning with adaptive planning, a combination of mechanisms with potentially broad applications to many complex behaviors performed by humans, animals, and artificial agents <ref type="bibr" target="#b9">(10)</ref>.</p><p>We formalize this combination of mechanisms in a computational model. For the structure learning mechanism, we use an infinite capacity mixture model <ref type="bibr" target="#b10">(11,</ref><ref type="bibr" target="#b11">12)</ref>, and for the adaptive planning mechanism, we use a dynamically adjusting, uncertainty sensitive discounting factor <ref type="bibr" target="#b12">(13)</ref>. The infinite capacity mixture model assumes that the forager treats structure learning as a categorization problem -one in which they must discover not only a patch's type, or cluster, but also how many patch types varying in richness there are in the environment. And, they must infer these features only based on rewards received. The number of patch types inferred is dependent both on the forager's experience and their prior expectation of environment complexity (i.e. the number of patch types) represented by the parameter, α. In a heterogeneous environment with regions varying in richness, allowing for the possibility of multiple patch types enables better predictions of future rewards <ref type="figure" target="#fig_0">(Fig. 1AB</ref>).</p><p>Unless the forager has strong prior assumptions that there is a single patch type, they will be uncertain regarding their categorization of patches. A rational decision-maker should account for this uncertainty. We therefore adjusted the discount factor on each choice proportionally, capturing the suggestion that it is optimal for a decision-maker using a mental model of the world to set their planning horizon only as far as is justified by their model certainty <ref type="bibr" target="#b12">(13)</ref>. We implemented this principle by setting the effective discount factor on each choice to be a linear function of the representational uncertainty, with intercept (γ base ) and slope (γ coef ) terms fit to each participant <ref type="figure" target="#fig_0">(Fig. 1CD</ref>). This formulation allowed us to test the nested null hypothesis that discount factors would not be sensitive to the agent's fluctuating representational uncertainty.</p><p>We tested the model's predictions with a novel variant of a serial stay-switch task ( <ref type="figure" target="#fig_0">Fig. 2A; (4, 14)</ref>). Participants visited different planets to mine for "space treasure" and were tasked to collect as much space treasure as possible over the course of a fixed length game. On each trial, they had to decide between clusters (α &gt; 0), they learn with experience the cluster-unique decay rates. Initially, the forager is highly uncertain of their predictions. However, with more visitations to different planets, the agent makes increasingly accurate and precise predictions. B.</p><p>Without structure learning If the forager's prior assumes a single cluster (α = 0), the forager makes inaccurate and imprecise predictions -either over or underestimating the upcoming decay, depending on the planet type. This inaccuracy persists even with experience because of the strong initial assumption. Uncertainty adaptive discounting. C. High uncertainty When clusters are similarly probable, the posterior entropy is high. This entropy is taken as the forager's internal uncertainty and is used to adjust their discounting rate, γ ef f ective . When uncertainty is high, they discount future value more heavily. D. Low uncertainty When one cluster is much more likely than the others, entropy or uncertainty is low and consequently, future value is discounted less heavily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-free analyses.</head><p>Participants adapt to local richness. We first examined a prediction of MVT -foragers should adjust their patch leaving to the richness of the local patch. In the task environment, planets varied in their richness or how quickly they depleted. Slower depletion causes the local reward rate to more slowly approach the global reward rate of the environment. Thus, MVT predicts that stay times should increase as depletion rates slow. As predicted, participants stayed longer on rich planets relative to neutral (t(115) = 19.77, p &lt; .0001) and longer on neutral relative to poor (t(115) = 12.57, p &lt; .0001).</p><p>Experience decreases overharvesting. Despite modulating stay times in the direction prescribed by MVT, participants stayed longer or overharvested relative to MVT when averaging across all planets (t(115) = 3.88, p = .00018). However, the degree of overharvesting diminished with experience. Participants overharvested more in the first two blocks relative to the final two (t(115) = 3.27, p = .0014). Our definition of MVT assumes perfect knowledge of the environment. Thus, participants approaching the MVT optimum with experience is consistent with learning the environment's structure and dynamics.</p><p>Local richness modulates overharvesting. We next considered how participants' overharvesting varied with planet type. As a group, participants overharvested only on poor and neutral planets while behaving MVT optimally on rich planets ( <ref type="figure" target="#fig_6">Fig. 3A</ref>; poor -t(115) = 6.92, p &lt; .0001; neutral -t(115) = 9.00, p &lt; .0001; rich -t(115) = 1.38, p = .17).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Environment dynamics modulate decision time and overharvesting.</head><p>We also asked how participants adapted their foraging strategy to the environment's dynamics or transition structure. Upon leaving a planet, it was more common to transition to a planet of the same type (80%, "no switch") than transition to a planet of a different type ("switch"). Thus, we reasoned that switch transitions should be points of maximal surprise and uncertainty given their rareness. However, this would only be the case if the participant could discriminate between planet types and learned the transition structure between them.</p><p>If surprised, a participant should take longer to make a choice following a rare "switch" transition. So, we next examined participants' reaction times (z-scored and logtransformed) for the decision following the first depletion on a planet. We compared when there was a switch in planet type versus where there was none. As predicted, participants showed longer decision times following a "switch" transition suggesting they were sensitive to the environment's structure and dynamics ( <ref type="figure" target="#fig_6">Fig. 3B</ref>; t(115) = 2.65, p = 0.0093).</p><p>If uncertain, our adaptive discounting model predicts that participants should discount remote rewards more heavily and, consequently, overharvest to a greater extent. To test this, we compared participants overharvesting following rare "switch" transitions to their overharvesting following the more common "no switch" transitions. Following the model's prediction, participants marginally overharvested more following a change in planet type (t(115) = 1.86, p = 0.065). When considering only planets that participants overharvested on on average (poor and neutral), overharvesting was significantly greater following a change ( <ref type="figure" target="#fig_6">Fig. 3C</ref>; t(115) = 4.67, p &lt; .0001). Participants traveled to different planets and mined for space gems across 5 6-minute blocks. On each trial, they had to decide between staying to dig from a depleting gem mine or incurring a time cost to travel to a new planet. B. Environment structure. Planets varied in their richness or, more specifically, the rate at which they exponentially decayed with each dig. There were three planet types -poor, neutral, and rich -each with their own characteristic distribution over decay rates. C. Environment dynamics. Planets of a similar type clustered together. A new planet had an 80% probability of being the same type as the prior planet ("no switch"). However, there was a 20% probability of transitioning or "switching" to a planet of a different type.    in 90% of simulations. 76% of participants were above this threshold. Thus, most participants were determined to be "structure learners" using our criteria.</p><p>The threshold for uncertainty-adaptive discounting was assumed to be 0. A majority of participants, 93%, were above this threshold. These participants were determined to be "adaptive discounters", those who dynamically modulated their discounting factor in accordance with their internal uncertainty.</p><p>We next looked for relationships between parameters. Uncertainty should be greatest for individuals who have prior expectations that do not match the environment's true structure, whether too complex or too simple. Consistent with this, there was a non-monotonic relationship between the structure learning and discounting parameters. γ base and γ coef were greatest when α was near its lower bound, 0, and upper bound, 10 (γ base : β = 0.080, p &lt; .0001; γ coef : β = 0.021, p &lt; .0001). An individual's base level discounting constrains the range over which uncertainty can adapt the effective discounting. Reflecting this, the two discounting parameters were positively related to one another (τ = -0.33, p &lt; .0001).</p><p>Parameter validation. Correlations with model-free measures of task behavior confirmed the validity of the model's parameters. We interpret α as reflecting an individual's prior expectation of environment complexity. α must reach a certain threshold to produce inference of multiple clusters and consequently, sensitivity to the transitions between clusters. Validating this interpretation, participants with higher fit α demonstrated greater switch costs between planet types (Kendall's τ = 0.17, p = 0.00076). Moreover, this relationship was specific to α. γ base and γ coef were not significantly correlated with switch cost behavior (γ base : τ = -0.036, p = .57; γ coef : τ = -0.10, p = 0.11). This is a particularly strong validation as the model was not fit to reaction time data. Validating γ coef as reflecting uncertainty-adaptive discounting, the parameter was If a participant has knowledge of the environment's planet types and the transition structure between them, then they should be surprised following a rare transition to a different type. Consequently, they should take longer to decide following these transitions. As predicted, participants spent longer making a decision following transitions to different types ("switch") relative to when there was transition to a planet of the same type ("no switch"). This is consistent with having knowledge of the environment's structure and dynamics. C. Overharvesting increases following rare switch transitions. On poor and neutral planets, participants overhavested to a greater extent following a rare "switch" transition relative to when there was a "no switch" transition. This is consistent with uncertainty adaptive discounting. Switches to different planet types should be points of greater uncertainty. This greater uncertainty produces heavier discounting and in turn staying longer with the current option.*p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001 correlated with the extent overharvesting increased following In standard economic choice tasks, humans have been shown to act in accordance with rational statistical inference of environment structure. Furthermore, by assuming humans must learn the structure of their environment from experience, seemingly suboptimal behaviors can be rationalized including prolonged exploration <ref type="bibr" target="#b15">(16)</ref>, melioration <ref type="bibr" target="#b16">(17)</ref>, social biases <ref type="bibr" target="#b17">(18)</ref>, and overgeneralization <ref type="bibr" target="#b18">(19)</ref>. Here, we extend this proposal to decision tasks with sequential dependencies, which require simultaneous learning and dynamic integration of both the distribution of immediately available rewards and the underlying contingencies that dictate future outcomes. This form of relational or category learning has long been associated with distinct cognitive processes and neural substrates from those thought to underlie reward-guided decisions <ref type="bibr" target="#b19">(20)</ref>, including the foraging decisions we investigate here <ref type="bibr" target="#b20">(21)</ref>. However, a network of neural regions overlapping those supporting relational learning are more recently thought to play a role in deliberative, goal-directed decisions <ref type="bibr" target="#b21">(22,</ref><ref type="bibr" target="#b22">23)</ref>.</p><p>If foragers are learning a model of the environment and using it to make decisions for reward, then this suggests that they may be doing something like model-based reinforcement learning (RL). Seemingly contrary to this, Constantino &amp; Daw (4) found human foragers' choices to be better explained by a MVT model augmented with a learning rule than a standard reinforcement learning model. However, it is important to note that the task environment in that study was homogeneous and the RL model tested was model-free (temporal-difference learning). Thus, the difference in our results could be due to different task environments and class of models. A key way our model deviates from a model-based RL approach is that prospective prediction is only applied in computing the value of staying while the value of leaving is similar to MVT's threshold for leaving -albeit discounted proportionally to the mechanism for how the factor is set let alone dynamically 343 adjusted with experience. In contrast, our model proposes a mechanism through which the discounting factor is rationally set in response to both the external and internal environment.</p><p>Finally, our observation that humans adjust their planning horizons dynamically in response to state-space uncertainty may have practical applications in multiple fields. In psychiatry, foraging has been proposed as a translational framework for understanding how altered decision-making mechanisms contribute to psychiatric disorders <ref type="bibr" target="#b29">(30)</ref>. A substantial body of work has examined how temporal discounting is impacted in a range of disorders from substance use disorder (31) to depression <ref type="bibr" target="#b31">(32)</ref> to schizophrenia <ref type="bibr" target="#b32">(33)</ref>. This wide range has led some to suggest that temporal discounting may be a useful transdiagnostic symptom and a potential target for treatment <ref type="bibr" target="#b33">(34)</ref>. However, it remains unclear why temporal discounting is altered in these disorders and how it relates to known risk factors like an unpredictable early life environment. Our findings may provide further insight, suggesting that it may be related to the individual's internal uncertainty over environment structure, and hence may vary across contexts, rather than being stable and trait-like. Potential treatments, rather than targeting temporal discounting, could address its possible upstream cause of uncertainty -increasing the individual's perceived familiarity with the current context or increasing their self-perceived ability to act efficaciously in it. Another application could be in the field of sustainable resource management, where it has recently been shown that, in common pool resource settings (e.g. waterways, grazing fields, fisheries), the distribution of individual participants' planning horizons strongly determines whether resources are sustainably managed <ref type="bibr" target="#b34">(35)</ref>. Here, we show that discount factor, set as a rational response to uncertainty about environmental Participation was restricted to workers who had completed at least 100 prior studies and had at least a 99% approval rate. Participants earned $6 as a base payment and could earn a bonus contingent on performance ($0-$4). We excluded 60 participants according to one or more of three criteria: 1.</p><p>having average planet residence times 2 standard deviations above or below the group mean (36 participants) 2. failing a quiz on the task instructions more than 2 times (33 participants) or 3. failing to respond appropriately to one or more of the two catch trials (17 participants). On catch trials, participants were asked to press the letter "Z" on their keyboard. These questions were meant to "catch" any participants repeatedly choosing the same option (using key presses "A" or "L") independent of value.</p><p>Task Design. Participants completed a serial stay-switch task adapted from previous human foraging studies <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b35">36)</ref>. Following this initial dig, participants had to decide between staying on the current planet to dig again or leaving to travel to a new planet <ref type="figure" target="#fig_1">(Fig 2A)</ref>. Staying would further deplete the gem mine while leaving yielded a replenished gem mine at the cost of a longer time delay. They made these decisions in a series of five blocks, each with a fixed length of 6 minutes.</p><p>Blocks were separated by a break of participant-controlled length, up to a maximum of 1 minute.</p><p>On each trial, participants had 2 seconds to decide via key press whether to stay ("A") or leave ("L"). If they decided to stay, they experienced a short delay before the gem amount was displayed (1. Unlike previous variants of this task, planets varied in their richness within and across blocks, introducing greater structure to the task environment. Richness was determined by the rate at which the gem amount exponentially decayed with each successive dig <ref type="figure" target="#fig_1">(Fig. 2B</ref>). If a planet was "poor", there was steep depletion in the amount of gems received. Specifically, its 435 decay rates were sampled from a beta distribution with a low 436 mean (mean = 0.2; sd = 0.05; α = 13 and β = 51). In contrast, 437 rich planets depleted more slowly (mean = 0.8; sd = 0.05; α 438 = 50 and β = 12). Finally, the quality of the third planet 439 type -neutral -fell in between rich and poor (mean = 0.5; 440 sd = 0.05; α = 50 and β = 50). The environment dynamics 441 were designed such that planet richness was correlated in time. 442 When traveling to a new planet, there was an 80% probability 443 of it being the same type as the prior planet ("no switch"). If 444 not of the same type, it was equally likely to be of one of the 445 remaining two types <ref type="figure" target="#fig_1">("switch", Fig. 2C</ref>). This information was 446 not communicated to participants, requiring them to infer the 447 environment's structure and dynamics from rewards received 448 alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>449</head><p>Comparison to Marginal Value Theorem. Participants' planet 450 residence times, or PRTs, were compared to those prescribed 451 by MVT. Under MVT, agents are generally assumed to act 452 as though they have accurate and complete knowledge of the 453 environment. For this task, that would include knowing each 454 planet type's unique decay rate distribution and the total 455 reward received and time elapsed across the environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>456</head><p>Knowledge of the decay rate distributions is critical for 457 estimating Vstay, the anticipated reward if the agent were to 458 stay and dig again.</p><formula xml:id="formula_0">459 Vstay = rt * d [1] 460</formula><p>where rt is the reward received on the last dig and d is the 461 upcoming decay. </p><formula xml:id="formula_1">V leave = r total t total * t dig [2] 467</formula><p>r total t total estimates the average reward rate of the environment. 468 Multiplying it by t dig gives the opportunity cost of the time 469 spent exploiting the current planet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>470</head><p>Finally, to make a decision, the MVT agent compares the 471 two values and acts greedily, always taking the higher valued 472 option.</p><formula xml:id="formula_2">473 choice = argmax(Vstay, V leave ) [3] 474</formula><p>Model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>475</head><p>Making the stay-leave decisions. We assume that the forager com-476 pares the value for staying, Vstay, to the value of leaving V leave , 477 to make their decision. Similar to MVT, we assume foragers 478 act greedily with respect to these values.</p><p>experiences in the environment <ref type="bibr" target="#b3">(4)</ref>. This may be reasonable in homogeneous environments but less so in heterogeneous ones where it could introduce substantial noise and uncertainty. Instead, in these varied environments, it may be more reasonable to cluster patches based on similarity and only generalize from patches belonging to the same cluster as the current one. This selectivity enables more precise predictions of future outcomes.</p><p>Clusters are latent constructs. Thus, it is not clear how many clusters a forager should divide past encounters into.</p><p>Non-parametric Bayesian methods provide a potential solution to this problem. They allow for the complexity of the representation -as measured by the number of clusters -to grow freely as experience accumulates. These methods have been previously used to explain phenomena in category learning <ref type="bibr" target="#b10">(11,</ref><ref type="bibr" target="#b36">37)</ref>, task set learning <ref type="bibr" target="#b18">(19)</ref>, fear conditioning <ref type="bibr" target="#b11">(12)</ref>, and event segmentation <ref type="bibr" target="#b17">(18)</ref>.</p><p>To initiate this clustering process, the forager must assume a model of how their observations, decay rates, are generated by the environment. The generative model we ascribe to the forager is as follows. Each planet belongs to some cluster, and each cluster is defined by a unique decay rate distribution:</p><formula xml:id="formula_3">d k ∼ N ormal(µ k , σ k ) [4]</formula><p>where k denotes cluster number. The generative model takes the form of a mixture model in which normal distributions are mixed together according to some distribution P (k) and</p><p>observations are generated from sampling from the distribution P (d|k).</p><p>Before experiencing any decay on a planet, the forager has prior expectations regarding the likelihood of a planet belonging to a certain cluster. We assume that the prior on clustering corresponds to a "Chinese restaurant process" <ref type="bibr" target="#b37">(38)</ref>.</p><p>If previous planets are clustered according to p1:N , then for the current planet: planets and the likelihood of the observations given those clus-540 terings. Thus, we approximate the posterior distribution using 541 a particle filter <ref type="bibr" target="#b38">(39)</ref>. Each particle maintains a hypothetical 542 clustering of planets which are weighted by the likelihood of 543 the data under the particle's chosen clustering. All simulations 544 and fitting were done with 1 particle which is equivalent to 545 Anderson's local MAP algorithm <ref type="bibr" target="#b39">(40)</ref>.</p><formula xml:id="formula_4">P (k) = n k N +α if k is old</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>546</head><p>With 1 particle, we assign a planet definitively to a cluster. 547 This posterior then determines (a) which cluster's parameters 548 are updated and (b) the inferred cluster on subsequent planet 549 encounters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>550</head><p>If the planet is assigned to an old cluster, k, the existing µ k 551 and σ k are updated analytically using the standard equations 552 for computing the posterior for a normal distribution with 553 unknown mean and variance:</p><formula xml:id="formula_5">554 d = 1 n n i=1 di µ ′ 0 = n0µ0 + nd n0 + n n ′ 0 = n0 + n ν ′ 0 = ν0 + n ν ′ 0 σ 2 0 ′ = ν0σ 2 0 + n i=1 (di −d) 2 + n0n n0 + n (µ0 −d) 2 [6] 555</formula><p>where d is a decay observed on the current planet, n is the 556 total number of decays observed on the current planet, n0 is 557 the total number of decays observed across the environment 558 before the current planet, µ0 is the prior mean of the cluster-559 specific decay rate distribution and ν0 is its precision. µ  This initial distribution is updated with the depletions 565 encountered on the current planet upon leaving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>566</head><p>The goal of this learning and inference process is to support 567 accurate prediction. To generate a prediction of the next decay, 568 the forager samples a cluster according to P (k) or P (k|D) 569 depending on whether any depletions have been observed on 570 the current planet. Then, a decay rate is sampled from the 571 cluster specific distribution, d k . The forager averages over 572 these samples to produce the final prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>573</head><p>To demonstrate structure learning's utility for prediction, 574 we show in simulation the predicted decay rates on each planet 575 with structure learning <ref type="figure" target="#fig_0">(Fig. 1A)</ref> and without <ref type="figure" target="#fig_0">(Fig. 1B)</ref>. With 576 structure learning, the forager's predictions approach the mean 577 decay rates of the true generative distributions. Without struc-578 ture learning, however, the forager is persistently inaccurate, 579 underestimating the decay rate on rich planets and overesti-580 mating it on poor planets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>581</head><p>Adapting the model of the environment. Because the inference pro-582 cess is an approximation and foragers' experience is limited, 583 their inferred environment structure may be inaccurate. Theo-584 retical work has suggested that a rational way to compensate 585 for this inaccuracy is to discount future values in proportion 586 to the agent's uncertainty over their representation of the 587 environment <ref type="bibr" target="#b12">(13)</ref>. We quantified an agent's uncertainty by 588 taking the entropy of the approximated posterior distribution over clusters ( <ref type="figure" target="#fig_0">Fig 1CD)</ref>. We sample clusters 100 times proportional to the posterior. These samples are multinomially distributed. We represent them with the distribution, X: X ∼ M ultinomial(100, K) <ref type="bibr" target="#b7">[8]</ref> sampling 100 times from the distribution, P (k) or P (k|d) depending on whether depletions on the planet have been observed. Uncertainty is quantified as the Shannon entropy of distribution X.</p><p>the value of leaving as follows: <ref type="bibr" target="#b8">[9]</ref> γ ef f ective = 1 1 + e (−γ base +γ coef * H(X)) <ref type="bibr" target="#b9">[10]</ref> where γ base and γ coef are free parameters and H(X) is the entropy of the distribution X. </p><formula xml:id="formula_6">V leave = r total t total * t dig * γ ef f ective</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>620</head><p>The parameter configuration that produced the lowest MSE 621 on average was chosen as the best fitting for the individual.  <ref type="bibr" target="#b10">[11]</ref> TD-Learning The temporal difference (TD) agent learns a state-specific value of staying and digging, Q(s, dig) and a non-state specific value of leaving, Q(leave). The state, s is defined by the gem amounts offered on each dig. The state space is defined by binning the possible gems that could be earned from each dig. The bins are spaced are according to log(bj+1)log(bj) = log(k) where bj+1 and bj are the upper and lower bounds of the bins andd is the mean decay rate. This state space specification is taken from (4). We set bj+1 to 135 and bj to 0 as these were the true bounds on gems received per dig. We setk to 0.5 because this would be the mean decay rate if one were to average the depletions experienced over all planets. The agent compares the two values and makes their choice using a softmax policy. P (ai = dig) = 1 (1 + e (−c−β(Q i (s i ,dig)−Q i (leave))) ) Di ∼ Bernoulli(P (ai))</p><formula xml:id="formula_7">δi = r i τ i − ρi ρi+1 = ρi + (1 − (1 − α) τ i ) * δi</formula><formula xml:id="formula_8">δi = ri + γτi(Di * Qi(si) + (1 − Di) * Qi(leave)) − Qi(si−1, ai−1)</formula><p>Qi(si−1, ai−1) = Qi+1(si−1, ai−1) + α * δi <ref type="bibr" target="#b11">[12]</ref> where c, α, β, γ are free parameters. c is a perseveration term, α is the learning rate, β is the softmax temperature, and γ is the temporal discounting factor. Cross Validation Each model's fit to the data was evaluated using a 10-fold cross validation procedure. For each participant, we shuffled their PRTs on all visited planets and split them into 10 separate training/test datasets. The best fitting parameters were those that minimized the sum of squared error (SSE) between the participant's PRT and the model's predicted PRT on each planet in the training set. Then, with the held out test dataset, the model was simulated with the best fitting parameters and the SSE was calculated between the participant's true PRT and the model's PRT. To compute the model's final cross validation score, we summed over the test SSE from each fold. Data sharing statement. All data, data analysis, and model fitting code will be deposited in a public GitHub repository which can be found at https://github.com/noraharhen/Harhen-Bornstein-2022-Overharvesting-as-Rational-Learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS. This work was supported by NIMH</head><p>P50MH096889 and a NARSAD Young Investigator Award by the Brain and Behavior Research Foundation to AMB. NCH was supported by a National Defense Science and Engineering Graduate fellowship.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Structure learning improves prediction accuracy. A. With structure learning A simulated agent's posterior probability over the upcoming decay rate on each planet is plotted. If the forager's prior allows for the possibility of multiple</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>A. Serial stay-switch task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Structure learning with adaptive discounting provide the best account of participant choice. To check the models' goodness of fit, we 173 asked whether the compared models could capture key be-174 havioral results found in participants' data. For each model and participant, we simulated an agent with the best fitting 176 parameters estimated for them under the given model. Only 177 the adaptive discounting model was able to account for over-178 harvesting when averaging across all planets (Fig. 4A, t(115) 179 = 9.03, p &lt; .0001). The temporal-difference learning model 180 predicted MVT optimal choices on average (t(115) = 1.09, 181 p = .28) while the MVT learning model predicted underharvesting (t(115) = -7.17, p &lt; .0001). These differences were 183 primarily driven by predicted behavior on the rich planets 184(Fig. 4B).185Model fit was also assessed at a more granular level (stay 186 times on individual planets) using 10-fold cross validation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>187</head><label></label><figDesc>Comparing cross validation scores as a group, participants' 188 choices were best captured by the adaptive discounting model 189 (Fig. 4C; mean cross validation scores -adaptive discounting:190 16.55, TD: 22.47, MVT learn: 32.31). At the individual level, 191 64% of participants were best fit by the adaptive discounting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>192model, 14% by TD, and 22% by MVT learn.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>193</head><label></label><figDesc>Adaptive discounting model parameter distribution. Because the 194 adaptive discounting model provided the best account of choice 195 for most participants, we examined the distribution of individ-196 uals' best fitting parameters for the model. Specifically, we 197 compared participants' estimated parameters to two thresh-198 olds. These thresholds were used to identify whether a par-199 ticipant 1) inferred and assigned planets to multiple clusters 200 and 2) adjusted their overharvesting in response to internal 201 uncertainty. 202 The threshold for multi-cluster inference, 0.8, was computed 203 by simulating the adaptive discounting model 100 times and 204 finding the lowest value that produced multi-cluster inference 205</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Model-free results A. Planet richness influences over and underharvesting behavior. Planet residence times (PRT) relative to Marginal Value Theorem's (MVT) prediction are plotted as the median (± one quartile) across participants. The grey line indicates the median while the white cross indicates the mean. Individuals' PRTs relative to MVT are plotted as shaded circles. In aggregate, participants overharvested on poor and neutral planets and acted MVT optimally on rich planets. B. Decision times are longer following rare switch transitions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>241a rare transition or "switch" between different planet types 242 (τ = 0.15, p = 0.016). This was not correlated with α nor 243 the baseline discounting factor γ base (α: τ = -0.011, p = .86;244 γ base : τ = 0.082, p = .20). 245 Discussion 246 While Marginal Value Theorem (MVT) provides an optimal 247 solution to patch leaving problems, organisms systematically 248 deviate from it, staying too long or overharvesting. A critical 249 assumption of MVT is that the forager has accurate and com-250 plete knowledge of the environment. Yet, this is often not the 251 case in real world contexts -the ones in which foraging be-252 haviors are likely to have adapted (15). We propose a model of 253 how foragers could rationally learn the structure of their envi-254 ronment and adapt their foraging decisions to it. In simulation, 255 we demonstrate how seemingly irrational overharvesting can 256 emerge as a byproduct of a rational dynamic learning process. 257 In a heterogeneous, multimodal environment, we compared 258 how well our structure learning model predicted participants' 259 choices relative to two other models -one implementing a 260 MVT choice rule with a fixed representation of the environ-261 ment and the other a standard temporal-difference learning 262 algorithm. Importantly, only our structure learning model 263 predicted overharvesting in this environment. Participants' 264 choices were most consistent with learning a representation of 265 the environment's structure through individual patch experi-266 ences. They leveraged this structured representation to inform 267 their strategy in multiple ways. One way determined the value 268 of staying. The representation was used to predict future 269 rewards from choosing to stay in a local patch. The other 270 modulated the value of leaving. Uncertainty over the accuracy 271 of the representation was used to set the discount factor over 272 future value. These results suggest that to explain foraging 273 as it occurs under naturalistic conditions optimal foraging 274 may need to provide an account of how the forager learns to 275 acquire accurate and complete knowledge of the environment, and how they adjust their strategy as their representation is refined with experience.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4 .</head><label>4</label><figDesc>Modeling results A. The adaptive discounting model predicts overharvesting. Averaging across all planets, only the adaptive discounting model predicts overharvesting while the temporal-difference learning model predicts MVT optimal behavior and the MVT learning model predicts underharvesting. This demonstrates that overharvesting, a seemingly suboptimal behavior, can emerge from principled statistical inference and adaptation. B. Model predictions diverge most on rich planets. Similar to participants, the greatest differences in behavior between the models occurred on rich planets. C. The adaptive discounting model provides the best account for participant choices. The adaptive discounting model had the lowest mean cross validation score indicating it provided the best account of participant choice at the group level.agent's internal uncertainty over their representation's accuracy. In the former respect, our model parallels the framework discussed by Kolling &amp; Akam (10) to explain humans sensitivity to the gradient of reward rate change during foraging observed by Wittman et al (24). Given that computing the optimal exit threshold under a pure model-based strategy would be highly computationally expensive, Kolling &amp; Akam (10)'s suggest pairing model-based patch evaluation with a modelfree, MVT-like exit threshold. Under their proposal, the agent 320 leaves once the local patch's average predicted reward rate 321 over n time steps in the future falls below the global reward 322 rate. We build on, formally test, and extend this proposal by 323 explicitly computing the representational uncertainty at each 324 trial and adjusting planning horizon accordingly. 325 While learning a model of the environment is beneficial, it 326 is also challenging and computationally costly. With limited 327 experience and computational noise, an inaccurate model of the 328 environment may be inferred. An inaccurate model, however, 329 can be counteracted by adapting certain computations. In this 330 way, lowering the temporal discounting factor acts as a form 331 of regularization or variance reduction (13, 25-28). Empirical 332 work has found humans appear to do something like this in 333 standard intertemporal choice tasks. Gershman &amp; Bhui (29) 334 found evidence that individuals rationally set their temporal 335 discounting as a function of the imprecision or uncertainty of 336 their internal representations. Here, we found that humans 337 while foraging act similarly, overharvesting to a greater extent 338 at points of peak uncertainty. While temporal discounting has 339 been proposed as a mechanism of overharvesting previously (3-340 5), the discounting factor is usually treated as a fixed, subject-341 level parameter, inferred from choice. Thus, it provides no342</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5 .</head><label>5</label><figDesc>Parameter distributions A. Participants learned the structure of the environment. Distribution of participants' priors over environment complexity, α. Each individual's parameter is shown relative to a baseline threshold, 0.8. This threshold is the lowest value that produced multi-cluster inference in simulation. Most participants (76%) fall above this threshold indicating a majority learned the environment's multi-cluster structure. B. Environment complexity parameters were positively related to reaction time sensitivity to transition frequency. An individual must infer multiple planet types to be sensitive to the transition structure between them. In terms of the model, this would correspond to having a sufficiently high environment complexity parameter. Validating this parameter, it was positively correlated with individual's modulation of reaction time following a rare transition to a different planet type. C. Participants adapted their discounting computations to their uncertainty over environment structure. Distribution of participant's uncertainty adaptation parameter, γ coef . Each individual's parameter is shown relative to a baseline of 0. A majority were above this threshold (93%) indicating most participants dynamically adjusted their discounting, increasing it when they experienced greater internal uncertainty. D. Uncertainty adaptation parameters were positively related to overharvesting sensitivity to transition frequency. If an individual increases their discounting to their internal uncertainty over environment structure, then they should discount more heavily following rare transitions and stay longer with the current option. Consistent with this, we found that the extent an individual increased their overharvesting following a rare transition was related to their uncertainty adaptation parameter.structure, directly impacts the degree to which an individual tends to (over)harvest their locally available resources. The present work suggests that policymakers and institution designers interested in producing sustainable resource management outcomes should focus on reducing uncertainty -about the contingencies of their actions, and the distribution of rewards that may result -for individuals directly affected by resource availability, thus allowing them to rationally respond with an increased planning horizon and improved outcomes for all participants.MethodsParticipants. We recruited 176 participants from Amazon Mechanical Turk (111 male, ages 23-64, Mean=39.79, SD=10.56).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>With the goal of collecting as much space treasure as possible, participants traveled to different planets to mine for gems. Upon arrival to a new planet, they performed an initial dig and received an amount of gems sampled from a Gaussian distribution with a mean of 100 and standard deviation (SD) of 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>5 s). The length of the delay was determined by the time the participant spent making their previous choice (2 -RT s). This ensured participants could not affect the environment reward rate via their response time. If they decided to leave, they encountered a longer time delay (10 s) after which they arrived on a new planet and were greeted by a new alien (5 s). On trials where a decision was not made within the allotted time (2 s), participants were shown a timeout message for two seconds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>planet is poor 0.5 if planet is neutral 0.8 if planet is rich 463 V leave is estimated using the total reward accumulated, 464 r total , total time passed in the environment, t total , and the 465 time delay to reward associated with staying and digging, t dig . 466</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>new Where n k is the number of planets assigned to cluster k, α is a clustering parameter, and N is the total number of planets encountered. The probability of a planet belonging to an old cluster is proportional to the number of planets already assigned to it. The probability of it belonging to a new cluster is proportional to α. Thus, α controls how dispersed the clusters are -the higher α is the more new cluster creation is encouraged. The ability to incrementally add clusters as experience warrants it makes the generative model an infinite capacity mixture model. After observing successive depletions on a planet, the forager computes the posterior probability of a planet belonging to a cluster: J is the number of clusters created up until the current planet, D is a vector of all the depletions observed on the current planet, and all probabilities are conditioned on prior cluster assignments of planets, p1:N . Exact computation of this posterior is computationally demanding as it requires tracking all possible clusterings of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>′ 0 and 560 ν ′ 0</head><label>0</label><figDesc>are the posterior mean and variance respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>561</head><label></label><figDesc>If the planet is a assigned to a new cluster, then a new 562 cluster is initialized with the following distribution:563 dnew ∼ N ormal(µ = 0.5, σ = 0.5) [7] 564</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Model fitting. We compared participant PRTs on each planet to those predicted by the model. A model's best fitting parameters were those that minimized the difference between the607 true participant's and simulated agent's PRTs. We considered 608 1000 possible sets of parameters generated by quasi-random 609 search using low-discrepancy Sobol sequences (41). Prior 610 work has demonstrated random and quasi-random search to 611 be more efficient than grid search (42) for parameter opti-612 mization. Quasi-random search is particularly efficient with 613 low-discrepancy sequence, more evenly covering the parameter 614 space relative to true random search. 615 Because cluster assignment is a stochastic process, the pre-616 dicted PRTs vary slightly with each simulation. Thus, for each 617 candidate parameter setting, we simulated the model 50 times 618 and averaged over the mean squared error (MSE) between 619 participant PRTs and model-predicted PRTs for each planet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>622</head><label></label><figDesc>Model Comparison. We compared three models: the structure 623 learning and adaptive discounting model described above, a 624 temporal difference model previously applied in a foraging 625 context, and a MVT model that learns the mean decay rate 626 and global reward rate of the environment.627 MVT-Learning In this model, the agent learns a threshold 628 for leaving which is determined by the global reward rate, ρ (4). 629 ρ is learned with a simple delta rule with α as a learning rate 630 and taking into account the temporal delay accompanying an 631 action τ . The value of staying is d * ri where d is the predicted 632 decay and ri is the reward received on the last time step. The 633 value of leaving,V leave , is the opportunity cost of the time spent634 digging, ρ * t dig . The agent chooses an action using a softmax 635 policy with temperature parameter, β which determines how 636 precisely the agent represents the value difference between the 637 two options. 638 P (ai = dig) = 1 (1 + e (−c−β(d * r i −ρ * t dig )) )</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="479">Learning the structure of the environment. Learning the structure 480 of the environment affords more accurate and precise predic-481 tions which support better decision-making. Here, the forager 482 predicts how many gems they'll receive if they stay and dig 483 again and this determines the value of staying, Vstay. To gen-484 erate this prediction, a forager could aggregate over all past 485</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimal foraging, the marginal value theorem. Theor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>El Charnov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Popul. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="129" to="136" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Subjective costs drive overly patient foraging strategies in rats on an intertemporal foraging task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Am Wikenheiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stephens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Redish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U. S. A</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="8308" to="8313" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rats value time differently on equivalent foraging and delay-discounting tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ec Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Redish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Gen</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="1093" to="1101" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning the opportunity cost of time in a patch-foraging task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sm Constantino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. Affect. Behav. Neurosci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="837" to="853" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Monkeys are more patient in a foraging task than in a standard intertemporal choice task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tc Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hayden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">117057</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rats exhibit similar biases in foraging and intertemporal choice tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ga Kane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Planning and acting in partially observable stochastic domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lp Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ml Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cassandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. intelligence</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="99" to="134" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Biased belief updating and suboptimal choice in foraging decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">3417</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Uncertainty drives deviations in normative foraging decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zp Kilpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>El Hady</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">reinforcement?) learning to forage optimally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kolling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Akam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="162" to="169" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A more rational model of categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Navarro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context, learning, and extinction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sj Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="197" to="209" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The dependence of effective planning horizon on model accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lewis</surname></persName>
		</author>
		<ptr target="https://nanjiang.cs.illinois.edu/files/gamma-AAMAS-final.pdf" />
		<imprint>
			<biblScope unit="page" from="2022" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">From creatures of habit to goal-directed learners: Tracking the developmental emergence of model-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="848" to="858" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Time discounting and time preference in animals: a critical review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>By Hayden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon. bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="39" to="53" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Structure learning in human sequential decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Acuña</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schrater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1001003</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Melioration as rational choice: sequential decision making in uncertain environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cr Sims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structuring memory through Inference-Based event segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ys Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dubrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Top. Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="106" to="127" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cognitive control over learning: creating, clustering, and generalizing task-set structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Age Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="190" to="229" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interactive memory systems in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ra Poldrack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">414</biblScope>
			<biblScope unit="page" from="546" to="550" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural mechanisms of foraging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kolling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rushworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="page" from="95" to="98" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cortical and hippocampal correlates of deliberation during modelbased decisions for rewards in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Am Bornstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1003387</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hippocampal contributions to model-based planning and spatial memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Om Vikbladh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="683" to="693" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Predictive decision making driven by multiple time-linked reward representations in the anterior cingulate cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mk Wittmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12327</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Biasing approximate dynamic programming with a lower discount factor in Advances in Neural Information Processing Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petrik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; D</forename><surname>Scherrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bottou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On overfitting and asymptotic bias in batch reinforcement learning with partial observability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Francois-Lavet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rabusseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fonteneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Using a logarithmic mapping to enable lower discount factors in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>H Van Seijen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fatemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tavakoli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Discount factor as a regularizer in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ciosek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rationally inattentive intertemporal choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sj Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">3365</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A primer on foraging and the Explore/Exploit Trade-Off for psychiatry research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma Addicott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1931" to="1939" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Steep delay discounting and addictive behavior: a meta-analysis of continuous associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Amlung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedelago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Acker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balodis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mackillop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Addiction</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Temporal discounting in major depressive disorder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pulcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Med</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1825" to="1834" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Delay discounting in schizophrenia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ea Heerey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcmahon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. Neuropsychiatry</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="213" to="221" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Delay discounting as a transdiagnostic process in psychiatric disorders: A meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Amlung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA Psychiatry</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="1176" to="1186" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Caring for the future can turn tragedy into comedy for long-term collective action under risk of collapse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Barfuss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Donges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vv Vasconcelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="12915" to="12922" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Chronic and acute stress promote overexploitation in serial decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jk Lenow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Constantino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phelps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="5681" to="5689" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rational approximations to rational models: alternative algorithms for category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="1144" to="1167" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mixtures of dirichlet processes with applications to bayesian nonparametric problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ce Antoniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1152" to="1174" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Particle filters for mixture models with an unknown number of components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fearnhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The adaptive nature of human categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jr Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="409" to="429" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distribution of points in a cube and approximate evaluation of integrals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Im Sobol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zh. Vych. Mat. Mat. Fiz</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="784" to="802" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" />
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2021" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
