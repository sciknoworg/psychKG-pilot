<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Suprathreshold perceptual decisions constrain models of confidence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shannon</forename><forename type="middle">M</forename><surname>Locke</surname></persName>
							<email>shannon.locke@ens.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Département d&apos;Études Cognitives</orgName>
								<orgName type="laboratory">Laboratoire des Systèmes Perceptifs</orgName>
								<orgName type="institution" key="instit1">École Normale Supérieure</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Département d&apos;Études Cognitives</orgName>
								<orgName type="laboratory">Laboratoire des Systèmes Perceptifs</orgName>
								<orgName type="institution" key="instit1">École Normale Supérieure</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Landy</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Neural Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Center for Neural Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Neural Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Center for Neural Science</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Mamassian</surname></persName>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Laboratoire des Systèmes Perceptifs, Département d&apos;Études Cognitives</orgName>
								<orgName type="institution" key="instit1">École Normale Supérieure</orgName>
								<orgName type="institution" key="instit2">PSL University</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>75005</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Suprathreshold perceptual decisions constrain models of confidence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>confidence</term>
					<term>decision-making</term>
					<term>metacognition</term>
					<term>perception</term>
					<term>modelling</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Perceptual confidence is an important internal signal about the certainty of our decisions and there is a substantial debate on how it is computed. We highlight three confidence metric types from the literature: observers either use 1) the full probability distribution to compute probability correct (Probability metrics), 2) point estimates from the perceptual decision process to estimate uncertainty (Evidence-Strength metrics), or 3) heuristic confidence from stimulus-based cues to uncertainty (Heuristic metrics). These metrics are rarely tested against one another, so we examined models of all three types on a suprathreshold spatial discrimination task. Observers were shown a cloud of dots sampled from a dot generating distribution and judged if the mean of the distribution was left or right of centre. In addition to varying the horizontal position of the mean, there were two sensory uncertainty manipulations: the number of dots sampled and the spread of the generating distribution. After every two perceptual decisions, observers made a confidence forced-choice judgement whether they were more confident in the first or second decision. Model results showed that observers were on average best-fit by a Heuristic model that used dot cloud position, spread, and number of dots as cues. However, almost half of the observers were best-fit by an Evidence-Strength model that uses the distance between the discrimination criterion and a point estimate, scaled according to sensory uncertainty, to compute confidence. This signal-to-noise ratio model outperformed the standard unscaled distance from criterion model favoured by many researchers and suggests that this latter simple model may not be suitable for mixed-di culty designs. An accidental repetition of some sessions also allowed for the measurement of confidence agreement for identical pairs of stimuli. This N-pass analysis revealed that human observers were more consistent than their best-fitting model would predict, indicating there are still aspects of confidence that are not captured by our model. As such, we propose confidence agreement as a useful technique for computational studies of confidence. Taken together, these findings highlight the idiosyncratic nature of confidence computations for complex decision contexts and 1 the need to consider di↵erent potential metrics and transformations in the confidence computation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Introduction</head><p>Perceptual confidence is a metacognitive judgement accompanying a perceptual judgement that is thought to reflect the observer's belief about the quality or correctness of their perceptual decision.</p><p>For example, a person is likely to have more confidence in their judgement of whether the road ahead bends left or right on a bright sunny day than on a foggy evening because the chances of making a mistake are higher in the latter scenario. Confidence is a decision about a decision, and so it is often referred to as a Type 2 judgement to contrast it with the Type 1 perceptual judgement <ref type="bibr" target="#b16">(Clarke et al., 1959)</ref>. Confidence judgements are ubiquitous in everyday life and are one of the many metacognitive evaluations that guide behaviour and learning <ref type="bibr" target="#b67">(Van den Berg et al., 2016;</ref><ref type="bibr" target="#b49">Meyniel et al., 2015;</ref><ref type="bibr" target="#b23">Frömer et al., 2021)</ref>.</p><p>Numerous models of perceptual confidence have been proposed by researchers, often to capture distinct aspects of decision-making behaviour. For example, some models focus on the relationship between the speed of the perceptual decision and confidence <ref type="bibr" target="#b33">(Kiani et al., 2014)</ref> and others on the degree to which confidence reports can distinguish correct from incorrect decisions <ref type="bibr" target="#b47">(Maniscalco and Lau, 2012)</ref>. The majority of confidence models are process models that extract the confidence decision variable from either the original Type decision process, or a comparable decision process, such as a partially or completely independent reconstruction <ref type="bibr" target="#b19">(Fleming and Daw, 2017)</ref> or further evolved Type 1 decision process <ref type="bibr" target="#b56">(Pleskac and Busemeyer, 2010)</ref>. The output of these confidence models is a confidence decision variable that can then be mapped to a behaviour (e.g., pressing a button on a keyboard). Confidence decision variables used by researchers in their modelling can be categorised into three main types <ref type="table">(Table 1)</ref>.</p><p>Probability confidence metrics are consistent with a common definition that confidence is the probability that the perceptual decision is correct <ref type="bibr" target="#b58">(Pouget et al., 2016)</ref>. This is also referred to as statistical confidence, or Bayesian confidence, if it is computed from a Bayesian posterior probability <ref type="bibr" target="#b64">(Sanders et al., 2016;</ref><ref type="bibr" target="#b1">Adler and Ma, 2018;</ref><ref type="bibr" target="#b36">Li and Ma, 2020)</ref>. To compute a probability metric, the observer must consider the probability of all the possible states of the stimulus consistent with their perceptual choice. For example, if they reported a motion direction as clockwise of vertical, this would be the probability of the stimulus being anywhere between 0 180 clockwise of the decision boundary. Thus, computation of a full probability distribution is necessary for this confidence decision variable. Bayesian Probability-metric models are typically used as an upper benchmark of confidence performance, as they consider all available information to assess the probability of being correct for reporting their confidence.</p><p>In contrast, Evidence-Strength confidence metrics are derived from point estimates in the Type 1 decision process and so do not require the representation of full probability distributions. One common Evidence-Strength metric is the Distance-From-Criterion (DFC) metric typically used in extended Signal Detection Theory (SDT) models of confidence <ref type="bibr" target="#b25">(Galvin et al., 2003;</ref><ref type="bibr" target="#b20">Fleming and Lau, 2014)</ref>. In the extended SDT framework, confidence is monotonically related to the unsigned distance between the sensory measurement and the decision criterion. In the case of categorical confidence judgements (e.g., binary report, scale, etc.), additional confidence criteria delineate the mapping between distance and confidence <ref type="bibr" target="#b47">(Maniscalco and Lau, 2012;</ref><ref type="bibr" target="#b19">Fleming and Daw, 2017;</ref><ref type="bibr" target="#b39">Locke et al., 2020a)</ref>. Most DFCmetric models also allow this sensory measurement to di↵er from that used for the perceptual decision <ref type="bibr" target="#b43">(Mamassian, 2016)</ref>, either by additional confidence noise corrupting the measurement <ref type="bibr" target="#b7">(Barrett et al., 2013;</ref><ref type="bibr" target="#b6">Bang et al., 2019)</ref> and/or from altering the measurement with parallel decision processes <ref type="bibr" target="#b19">(Fleming and Daw, 2017;</ref><ref type="bibr" target="#b45">Mamassian and de Gardelle, 2021)</ref>. Variants of the DFC <ref type="table">Table 1</ref>: Some implementations of the three most common confidence metric types used for modelling perceptual confidence and example study that used this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probability</head><p>Evidence-Strength Heuristic</p><p>• Bayesian confidence: posterior probability of being correct <ref type="bibr" target="#b1">(Adler and Ma, 2018)</ref> • Extended SDT: distance between measurement &amp; criterion <ref type="bibr" target="#b25">(Galvin et al., 2003)</ref> • Stimulus Variability: over-or underweighting of external noise as a cue (De Gardelle and <ref type="bibr" target="#b17">Mamassian, 2015)</ref> • Log-Probability-Ratio: of posterior probability or likelihood <ref type="bibr" target="#b1">(Adler and Ma, 2018)</ref> • Drift Di↵usion: di↵usion process state given elapsed time <ref type="bibr" target="#b33">(Kiani et al., 2014)</ref> • Reaction-time: between stimulus onset and response <ref type="bibr" target="#b53">(Patel et al., 2012)</ref> • Two-best: posterior probability di↵erence of the top two choice alternatives <ref type="bibr" target="#b36">(Li and Ma, 2020)</ref> • Balance-of-Evidence: relative final state of separate accumulators <ref type="bibr" target="#b68">(Vickers, 1979)</ref> • Other stimulus cues to task di culty <ref type="bibr" target="#b50">(Mole et al., 2018)</ref> • Entropy: the uncertainty across the posterior distribution of all choice alternatives <ref type="bibr" target="#b36">(Li and Ma, 2020)</ref> • Supporting-evidence: strength of decision-consistent evidence only <ref type="bibr" target="#b71">(Zylberberg et al., 2012;</ref> metric have been proposed to allow a point estimate of sensory uncertainty to remap the confidence criteria <ref type="bibr" target="#b73">(Zylberberg et al., 2014;</ref><ref type="bibr" target="#b1">Adler and Ma, 2018;</ref><ref type="bibr" target="#b18">Denison et al., 2018)</ref>, or allow biases in the distance measures to reflect consideration of only choice-congruent evidence .</p><p>Another common Evidence-Strength metric is the Accumulator metric. In accumulation-to-bound models, the Type 1 decision process is represented with one or more decision variables that are updated according to incoming sensory evidence <ref type="bibr" target="#b28">(Gold and Shadlen, 2007)</ref>. In this manner, accumulation-tobound models capture both the final choice and the temporal dynamics of that choice (e.g., reaction time). Thus, both the distance of the Type 1 decision variable from the initial decision state and total decision time are factored into the computation of the confidence decision variable. Often a mapping that corresponds to the probability of being correct is selected by experimenters (e.g., <ref type="bibr" target="#b33">Kiani et al., 2014;</ref><ref type="bibr" target="#b72">Zylberberg et al., 2016)</ref>. That is, the observer uses a point estimate of the decision process and a well-calibrated mapping function to extract the same confidence decision variable they would have got if they computed it from a full probability distribution. Other confidence decision variables of this type consider the relative states of two or more separate accumulators at the time of the decision <ref type="bibr" target="#b68">(Vickers, 1979)</ref> or partially interacting accumulators <ref type="bibr" target="#b71">(Zylberberg et al., 2012)</ref>. Extended versions of the accumulation-to-bound models allow the final state of the decision variable for the perceptual judgement and the confidence judgement to di↵er based on additional evidence accumulation between the Type 1 and Type 2 reports <ref type="bibr" target="#b56">(Pleskac and Busemeyer, 2010;</ref><ref type="bibr" target="#b5">Balsdon et al., 2020)</ref>.</p><p>The third metric type is the Heuristic metric, an ever-expanding category of confidence decision variables that have been created to capture behaviour beyond that predicted by the favoured standard models mentioned above. While in some cases, the heuristic label has been applied to variants of the Evidence-Strength metric <ref type="bibr" target="#b3">(Aitchison et al., 2015;</ref><ref type="bibr" target="#b36">Li and Ma, 2020)</ref>, the majority of "heuristic" confidence models have focused on the use of stimulus cues to infer decision uncertainty. Support for this method of computing confidence comes from a series of studies demonstrating that observers over-or under-weight external noise in the stimulus when reporting confidence <ref type="bibr" target="#b17">(De Gardelle and Mamassian, 2015;</ref><ref type="bibr" target="#b66">Spence et al., 2015;</ref><ref type="bibr" target="#b11">Boldt et al., 2017;</ref><ref type="bibr" target="#b9">Bertana et al., 2021)</ref>. That is, they display a dissociation between Type 1 and Type 2 performance such that, if perceptual performance is matched for two stimuli with di↵erent levels of external noise, confidence is not equated.</p><p>Other identified heuristic cues are reaction time <ref type="bibr" target="#b53">(Patel et al., 2012)</ref> and task-di culty variables <ref type="bibr" target="#b50">(Mole et al., 2018)</ref>. Importantly, Heuristic metrics do not require access to the Type 1 decision process, and reflect learned associations between stimulus features or di culty cues and confidence, which may or may not be well calibrated to reality. However, we note that for all the evidence of heuristic cue use, participants do not always rely on stimulus-uncertainty cues when they are available (e.g., see <ref type="bibr" target="#b8">Barthelmé and Mamassian, 2010;</ref><ref type="bibr" target="#b40">Locke et al., 2020b)</ref>.</p><p>These variations in the confidence computation alter how stimulus strength and sensory uncertainty influence confidence. Taking the earlier example of judging the bend in the road, stimulus strength would be the magnitude of the bend and sensory uncertainty the amount of external noise in the scene.</p><p>To understand the e↵ect of sensory uncertainty on the confidence decision variable, we will consider two roads, one bending left observed through obscuring fog (i.e., high sensory uncertainty) and the other bending right observed on a sunny day (i.e., low sensory uncertainty). In both cases, the bends in the road are of the same magnitude and the observer correctly identifies the direction of the bends.</p><p>But how does their sense of confidence compare in these two scenarios? <ref type="figure">Figure 1A</ref> depicts how an observer using a probability metric would assign higher confidence in the sunny scenario, as the probability of being correct (i.e., the shaded region) is greater due to the di↵erence in spread (i.e., sensory uncertainty). Note that the two probability distributions are centred on the two sensory measurements, which, in this case, are the most likely sensory measurements and so are equidistant from the unbiased decision criterion (i.e., are matched in terms of stimulus strength). The behaviour of the Probability metric for di↵erent stimulus strengths also depends on whether any transformations are applied. As shown in <ref type="figure">Figure 1D</ref>, the probability metric approaches a ceiling of 100% probability of being correct if stimulus strength is increased. Even with higher sensory uncertainty, this ceiling is approached relatively quickly with slightly greater stimulus strengths.</p><p>However, the probability of being correct for a binary Type 1 decision could also be expressed as a Log-Probability Ratio (LPR), which is the probability of being correct for the selected Type choice divided by the probability of being correct if you had selected the other Type 1 option (see <ref type="bibr" target="#b54">Peirce and Jastrow, 1884;</ref><ref type="bibr" target="#b25">Galvin et al., 2003;</ref><ref type="bibr" target="#b1">Adler and Ma, 2018)</ref>, In this scenario, the confidence metric Figure 1: Sensory uncertainty and stimulus strength in the confidence computation. A-C) Extracting the confidence decision variable from the Type 1 decision process. Scenarios contrasted: left-bending road on a foggy evening (teal; high uncertainty) and a right-bending road, with the same bendmagnitude, on a sunny day (purple; low uncertainty). The observer correctly identifies the roadbend direction, as shown by their response in quotation marks. Vertical line: decision boundary. A) Probability metric. Curves: normalised likelihood functions of the bend angle, given the sensory measurement (marker; the most likely measurement selected for illustrative purposes). Shaded region: probability of the judgement being correct. The shaded region is greater for the sunny scenario, so the observer has higher confidence in this judgement. B) Scaled-distance metric. A signal-to-noise ratio transformation is applied to the distributions in A (i.e., rescaled to units of standard deviation while the areas under the curve on either side of the Type 1 criterion are preserved). The rescaled sensory measurement in the sunny scenario has a greater Distance-from-Criterion (DFC) and is judged as more confident. C) Influence of a centred prior (see inset). The posterior distributions (continuous curves), computed according to Bayes' Rule, are di↵erentially shifted towards the centre from the likelihood function locations (dashed). The foggy scenario is shifted more because of its higher uncertainty. Consequently, Probability metrics and DFC metrics yield higher confidence for the sunny scenario. D-F) How the confidence metric changes with stimulus strength. The greater the stimulus strength, the larger the confidence metric. However, raw probability values asymptote at 100% confident (D), whereas the confidence decision variable is unbounded if a Log-Probability-Ratio transformation is applied to the probability of being correct (E) or a Unscaled-or Scaled-Distance metric is used (F). Note y-axes have been rescaled for illustrative purposes. G) Heuristic confidence metric computed from estimates of stimulus strength (bend angle) and sensory uncertainty (viewing conditions) without consideration of the Type 1 process. The observer sets the weights on these factors, w 1 and w 2 .</p><p>is unbounded, and the di↵erence in the metric between low and high uncertainty increases for larger stimulus strengths (see <ref type="figure">Figure 1E</ref>). So while the relationship of greater confidence for lower uncertainty is typically preserved, the underlying confidence decision variables can di↵er dramatically depending on transformations in the computation.</p><p>An observer who uses the standard DFC Evidence-Strength metric would not behave the same as an observer using the Probability metric. As both measurements have the same DFC, the observer would have the same degree of confidence for the sunny and foggy scenarios. It is only if the observer scales this measurement according to the degree of uncertainty (i.e., computes the signal-to-noise (SNR) ratio) using a point-estimate of sensory uncertainty, would confidence be greater for the sunny scenario ( <ref type="figure">Figure 1B</ref>). The e↵ect of this scaling means the sensory measurement is now further from the decision boundary for the the sunny scenario compared to the foggy scenario. A similar reasoning would apply for an accumulation-to-bound Evidence-Strength metric, where the sensory measurement (i.e., final decision state) and decision time (proportional to uncertainty) jointly determine the degree of confidence. The value of a DFC Evidence-Strength metric scales linearly with stimulus strength.</p><p>In the case of a SNR scaling, the sensory uncertainty a↵ects the slope ( <ref type="figure">Figure 1F</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure</head><p>1C depicts yet another way sensory uncertainty can influence confidence. If the prior expectation about the stimulus is concentrated at the decision boundary (e.g., the majority of roads are straight or with only a slight bend), the current observation can be biased towards this expected stimulus. This enhances the di↵erence between the sunny and foggy scenarios for both a Probability metric and a DFC Evidence-Strength metric. In fact, even an unscaled DFC Evidence-Strength metric would now reflect greater confidence for the sunny scenario due to the prior biasing e↵ect being stronger for measurement from the foggy scenario. Note that we are defining di↵erent states of the Type 1 decision process in Figures 1A-C, with the metric type reflecting di↵erent degrees of access or use of the decision-process information by the metacognitive system (i.e., full probability distributions or only point estimates). Thus, there is no conflict when an observer, who uses the prior for their Type 1 decision, only uses a point estimate of a biased sensory measurement to compute an unscaled DFC metric for confidence.</p><p>Finally, an observer computing a heuristic confidence metric considers the sunniness or fogginess of the day as well as the angle of the bend as independent inputs without considering an underlying Type 1 process. They then combine these inputs with some weighting scheme of their choice ( <ref type="figure">Figure 1G</ref>). If they correctly apply the rule of lower confidence for foggy scenarios, even if it imperfectly captures the relationship between fog and external noise, there will be an e↵ect of sensory uncertainty on confidence.</p><p>Despite the diversity of potential confidence models, only a few studies have directly compared models of di↵erent metric types. One approach has been to compare the behavioural signatures of competing models. Studies using this approach have tended to compare a Probability metric with a Heuristic metric, finding support for the probability metric <ref type="bibr" target="#b8">(Barthelmé and Mamassian, 2010;</ref><ref type="bibr" target="#b64">Sanders et al., 2016)</ref> or di↵ering support for each metric depending on the perceptual task <ref type="bibr" target="#b9">(Bertana et al., 2021)</ref>. Formal model comparisons, on the other hand, have been focused on Probability versus</p><p>Evidence-Strength metrics with mixed results (note that this is according to our metric definitions not those of the authors who used the term "heuristic" more liberally). <ref type="bibr" target="#b3">Aitchison et al. (2015)</ref> investigated simultaneous versus sequential Type 1 and Type 2 reports, finding the Bayesian-confidence probability metric best fits sequential reports, but this metric and an Evidence-Strength metric could explain simultaneous reports equally well. <ref type="bibr" target="#b1">Adler and Ma (2018)</ref> investigated categorisation behaviour when category means di↵ered but variances were matched versus when category variances di↵ered but means were matched. They found that an Evidence-Strength metric with quadratic sensory-uncertaintydependent bounds best fits the behaviour in both tasks. <ref type="bibr" target="#b38">Lisi et al. (2021)</ref> tested if confidence could be used in a subsequent decision where the perceptual evidence depended on the correctness of previous perceptual choice, and found that the model with a discrete Evidence-Strength metric outperformed the Bayesian Probability-metric model. Finally, <ref type="bibr" target="#b36">Li and Ma (2020)</ref> investigated various Probability and Evidence-Strength metrics in the context of a three-alternative forced-choice task. They found a Probability metric that compares the posterior probabilities of the two best alternatives outperformed other metrics. Thus, even with direct comparison of the models, the evidence is mixed for the di↵erent metric types and further work is needed to understand the nature of the confidence decision variable.</p><p>This need was highlighted recently by visual metacognition researchers who stated that determining how confidence is computed with detailed and falsifiable models is important for the field (see .</p><p>The aim of the present study was to compare the fit of confidence models of all three metric types to the behaviour of humans performing a visual decision-making task. Specifically, observers had to infer if the mean of a dot-generating distribution was left or right of centre ( <ref type="figure">Figure 2A</ref>). We employed a mixed-di culty design, varying the position of the mean (i.e., stimulus strength), as well as the spread of the dot-generating distribution (the quality manipulation) and the number of dots drawn (the quantity manipulation). Both of these manipulations a↵ected sensory uncertainty. This design allowed us to assess how the observer took sensory uncertainty into account in the computation of confidence.</p><p>We used the confidence forced-choice method (Mamassian, 2020; Mamassian and de Gardelle, 2021):</p><p>after two consecutive perceptual decisions, the observer reports whether they had greater confidence in the first or second decision. This allowed us to investigate suprathreshold perceptual decisions where confidence is typically high without being concerned with ceiling e↵ects (e.g., always reporting high confidence or the highest scale rating). We targeted this di culty regime because the confidence metrics are particularly divergent for more extreme stimulus strengths ( <ref type="figure">Figure 1D-F)</ref>. We selected seven base models (twelve models total considering variants in the prior distribution) that captured the diversity of potential confidence computations illustrated in Figure 1 (models described in <ref type="table" target="#tab_1">Table 2</ref>).</p><p>In addition to formal model comparison, we also investigated a new, qualitative, behavioural signature of confidence: confidence agreement. Due to a coding error, many sessions were identical repeats, in some cases as many as 5 repeats ( <ref type="figure">Figure 2B</ref>). We compared the confidence agreement of the observers to the confidence agreement of model simulations using the best-fitting parameter values as a benchmark of model fit.</p><p>To preview the results, we found that the confidence judgements were a↵ected by both the quantity and quality manipulations and all three metric types were supported by at least one observer. The best-fitting model was the Heuristic model, followed closely by a DFC Evidence-Strength model where  <ref type="figure">Figure 2</ref>: Experimental methods. A) Task design. Observers were shown dots drawn from a Gaussian generating distribution with seven possible horizontal spatial o↵sets between ±4 from the screen centre. They judged if the distribution mean was left or right of centre. After each pair of perceptual decisions (Interval 1 and Interval 2), they reported the interval in which they had higher confidence in their decision. There were six levels of stimulus uncertainty, defined by information quantity (number of dots: 2 or 5) and quality (sampling distribution SD: 1.5, 2, or 2.5 ), presented in an interleaved design. B) Occurrence of unique stimulus sets (colour coded). Squares: stimulus set in a single session. Sets are ordered by type, not session order, and participants by frequency of stimulus set repeats (5-pass to 1-pass). 3 Results</p><formula xml:id="formula_0">A ISI</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Confirming that the stimulus manipulations a↵ected confidence</head><p>First, we examined whether the confidence reports meaningfully distinguished accuracy in the Type 1 spatial task ( <ref type="figure" target="#fig_3">Figure 3A</ref>). Observers had an overall high level of accuracy of 0.91 ± 0.002 (mean ± SEM, µ = 0 trials excluded from calculation). Despite this near-ceiling performance, the interval chosen as more confident was on average more likely to be correct than the declined interval in the pair: 0.95 ± 0.003 versus 0.85 ± 0.004 (t 15 = 14.96, p &lt; 0.01). Performance was even better if responses are scored according to the mean of the dots displayed on the screen (i.e., the centroid), removing the factor of external noise on performance: 0.94 ± 0.003 for all, 0.98 ± 0.003 for chosen, and 0.90 ± 0.004 for declined (t 15 = 19.55, p &lt; 0.01). These results indicate that observers made meaningful confidence forced-choice judgements.</p><p>The e↵ect of the quantity and quality manipulations on confidence can be seen in the raw response data ( <ref type="figure" target="#fig_3">Figure 3B</ref>). For all trials, the further the dot cloud was from the screen centre, compared to the stimulus of the other interval, the more likely it was to be chosen as more confident. When the two intervals had a di↵erent number of dots (right panel), the interval that contained the greater quantity of dots was more likely to be chosen as more confident. Finally, when the two intervals di↵ered in dot spread, the interval that contained the smaller spread (i.e., larger inverse spread) was more likely to be chosen as more confident. In the plots, positive di↵erence values favour Interval 2 as more confident choices (blue) and negative di↵erences Interval 1 choices (red). Note in the right panel, the interval Same</p><formula xml:id="formula_1">N dots (N1 = N2) Di↵. N dots (N1 = 2, N2 = 5)</formula><p>C B a s ic + Q u a n t it y + Q u a li t y  The left-most bar shows performance for all trials, and the next two bars for trials sorted by confidence, either being in the interval chosen as more confident or declined. B) Raw confidence choices, sorted by stimulus properties across the two intervals of a confidence pair. The colour code represents the proportion of "Interval 2" as more confident choices averaged across observers. Confidence choices are plotted as a function of the di↵erence in distance from centre across intervals (I 2 I 1 ), and di↵erence in inverse dot spread. Left panel: comparisons where the number of dots was the same in each interval. Right panel: comparisons where the number of dots di↵ered, with stimulus information and confidence selectively flipped so that Interval 2 has more dots for plotting purposes. The distance from centre and dot spread were calculated using the empirical mean and SD of the dots displayed, and binned in the range ±3 for plotting. Gold line: the confidence-indi↵erence contour, where the observer is equally likely to report Interval 1 or 2, calculated from the Full model in the nested logistic regression analysis. C) Model comparison for the nested logistic regression analysis. AICc scores are reported relative to the Full model (winner) that contained both quantity and quality predictors. The +Quantity and +Quality models only contained one of these predictors and the Basic model contained neither. The results show that both the quantity and quality manipulations a↵ected confidence. Larger positive scores indicate a worse fit. Error bars: ±SEM.</p><p>with more dots was coded as Interval 2 for plotting purposes.</p><p>To quantitatively confirm both the quantity and quality manipulations a↵ected confidence, we performed a nested logistic regression analysis. The full model, which had the di↵erence in distance from the screen centre, inverse dot spread, and number of dots as predictors, outperformed simpler models without the quantity and/or quality predictors ( <ref type="figure" target="#fig_3">Figure 3C</ref>). See the Supplementary Materials for more details on the models and model comparison. The gold confidence-indi↵erence lines in <ref type="figure" target="#fig_3">Figure 3B</ref> provide a visualisation of the fit of the full model. Together, these results suggest observers' confidence computations were a↵ected by the stimulus strength as well as both sources of sensory uncertainty in this easy perceptual task. To better understand the computation of the confidence decision variable, we next examined several process models that capture the full decision process (i.e., both perceptual and confidence judgements).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Type 1 model comparison results</head><p>Four Type 1 models were considered. All models had three free parameters, a perceptual decision criterion (k 1 ), per-dot sensory noise ( dot ), and a lapse rate ( ). The models di↵ered in two ways: 1) whether the posterior distribution was computed with a flat or centred prior, and 2) if the Type 1 decision variable was the probability that the dot-cloud was on the left/right or the point estimate of the posterior's mode relative to the decision criterion (both metrics are always in 100% agreement).</p><p>The two prior-variants are also often in agreement about the perceptual choice, except for cases close to a biased decision boundary. Thus, it was unlikely to see large di↵erences in the Type 1 modelcomparison results. As expected, we found identical fits for the probability and signed-distance metrics ( <ref type="figure" target="#fig_5">Figure 4A</ref>), and near-identical fits for the prior-variants. The purpose of fitting all four models was to ensure that the Type 1 parameters could be fixed accordingly based on the Type-1 responses for the Type 2 model fits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Type 2 model comparison results</head><p>Twelve Type 2 models were compared, with confidence computed with a Probability metric in seven models, a DFC Evidence-Strength metric in four models, and a Heuristic metric in one model <ref type="bibr">(Figure</ref> 4B; models summarised in <ref type="table" target="#tab_1">Table 2</ref> and their equations detailed in <ref type="table">Table 3</ref>). The Heuristic model had the best AICc score averaged across observers, with 7 of the 16 observers best fit by this model.</p><p>The Scaled-Distance models were a strong competitor, with 4 observers best fit by the flat-prior variant and 3 by the centred-prior variant. The average AICc scores for these variants were respectively 10.8 ± 26.9 and 23.1 ± 20.7 higher than the Heuristic model. The flat-prior variant of the Probability-Di↵erence model best fit 2 observers and had an average relative AICc score of 41.0 ± 23.8. Overall, the Ideal, Basic-Probability, and Unscaled-Distance models fit poorly. Model results were relatively unchanged with alternative prior distributions and likelihood functions (see <ref type="figure">Supplementary Materials)</ref>.  AICc scores for the Type 2 models, with fraction best-fit annotated. Models are grouped by metric type. Note the di↵erent y-axis scales between panels A and B. C) Average best-fitting Heuristic-model coe cients across all observers. Note that the position coe cient was always fixed at 1 in the model, but is graphed to illustrate the relative coe cient weights. D) The best-fitting quantity and quality coe cients per observer. Marker colour and type indicates the best-fitting model for that observer. Dashed lines: the position coe cient for comparison. E) Model recovery results. For each model and observer, 10 data sets were simulated using the participant's best-fitting parameters (1920 data sets total) and then fit by each of the 12 models. The best-fitting model was tallied per dataset per simulated model. Dark squares along the downward diagonal indicate high model recovery success. F) The relative AICc scores compared to the simulated model (downward diagonal of 0). Error bars: ±SEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Examining the Heuristic model fits</head><p>We used the best-fitting parameters of the Heuristic model to investigate choice behaviour further. <ref type="figure" target="#fig_5">Figure 4C</ref> shows the estimated coe cients, which can be compared directly because the predictors were z-scored. Confidence was most strongly determined by the stimulus strength (i.e., dot-cloud position).</p><p>Of the two sensory-uncertainty manipulations, the quantity of dots was given more weight than the quality of the dots, as can be seen by the coe cients, quantity = 0.68±0.10 versus quality = 0.38±0.09</p><p>(t 15 = 3.75, p &lt; 0.01) respectively, which are also both significantly di↵erent from 0 (t 15 = 6.61, p &lt; 0.01 and t 15 = 4.34, p &lt; 0.01 respectively). These are contrasted per participant in <ref type="figure" target="#fig_5">Figure 4D</ref>.</p><p>There appears to be clustering of coe cient values according to best-fitting model (examined in more detail in the Supplementary Materials), with only Heuristic-best-fit participants giving more weight to dot quantity than stimulus strength. There was also a slight but not significant confidence interval bias to choose Interval 2 as more confident ( bias = k 2 = 0.13 ± 0.08; t 15 = 1.63, p &gt; 0.05; <ref type="figure" target="#fig_5">Figure 4C</ref>) and confidence noise was conf = 1.20 ± 0.17, according to the best-fitting parameters for the Heuristic model across all participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Model recovery analysis</head><p>A model recovery analysis further supported our model-comparison results. Data were simulated according to a particular model, with identical experiment structure and parameters consistent with our participants' behaviour. Our simulated data were almost always best-fit by the model that generated them ( <ref type="figure" target="#fig_5">Figure 4E</ref>). This indicates that the models are distinguishable from one another in model comparison. The centred-prior variant of the Basic-Probability model had the lowest recovery success with 78.75% datasets recovered. The Heuristic model was the highest with a 100% recovery rate. On average the recovery rate was 91.72 ± 6.54% (mean ± SD).</p><p>A comparison of the relative AICc scores in <ref type="figure" target="#fig_5">Figure 4F</ref> shows that some model-simulation fit pairs are more similar in model-fit quality than others, even though the simulated model was almost always correctly recovered. First, flat-and centred-prior variants tended to have similar AICc scores. A similar pattern emerges for the Scaled-Distance and LPR models. Then there are the unidirectional similarities. Datasets generated by simulating the Ideal-Confidence-Observer model could often be well fit by the centred-prior variants of other models. This was to be expected if the model converges to the Ideal-Confidence-Observer model when confidence noise and interval bias approach 0. But, by penalising model complexity, the Ideal-Confidence-Observer model is often recovered. The other unidirectional similarity is between the Unscaled-Distance models and the Heuristic model. This is because the Heuristic model with no weight given to the quantity and quality predictors is the likelihood-variant Unscaled-Distance model. However, penalising the extra complexity of the Heuristic model helps to ensure the recovery of the Unscaled-Distance models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Confidence agreement</head><p>Confidence agreement was quantified by counting the number of the most consistent confidence response on a per-trial basis (e.g, 4 "Interval 1" responses out of 5 passes is 80% agreement). The pattern of confidence agreement averaged across observers shows that 1) observers had high overall levels of confidence agreement, and 2) comparisons close to the confidence-indi↵erence line are less consistent than those far from this line ( <ref type="figure" target="#fig_7">Figure 5A</ref>). We then investigated the predicted confidence agreement according to each of the twelve models, simulated using the best-fitting parameters on a per-participant basis (results of an example participant shown <ref type="figure" target="#fig_7">Figure 5B</ref> and all participants in the Supplementary Materials). As expected, the Ideal-Confidence-Observer model always had the highest confidence agreement, because there is no confidence noise in this model. The Basic-Probability models then had the second and third highest levels of confidence agreement, followed by the remaining models, which tended to have more similar levels of confidence agreement. The higher confidence</p><formula xml:id="formula_2">A 3 1.5 0 1.5 3 3 1.5 0 1.5 3</formula><p>Distance From Centre (deg) Inverse Dot Spread (deg)   <ref type="figure">Figure 2B</ref>). A) Heatmaps of average confidence agreement according to the properties of the two stimuli displayed, pooled across observers. Gold: the indi↵erence lines where each interval is equally likely to be selected as more confident according to the preliminary analyses ( <ref type="figure" target="#fig_3">Figure 3B</ref>). B) Comparing the 5-pass confidence agreement of a representative example participant (red; #11) with the predicted confidence agreement of the models. Green: the best-fitting model for this observer (Heuristic model). Black: other models (flat-and centred-prior variants had similar confidence agreement counts so only the flat-prior variant is shown). Grey: the Basic-Probability model with additional late noise (1% SD). Model predictions calculated from 100 simulated datasets using the participant-specific best-fitting parameters. Error bars: ±2 SD.</p><p>agreement of the Basic-Probability models, however, was not robust. As expected, many of the confidence comparisons had values close to 1 ( <ref type="figure">Figure 1D</ref>), with the computer simulations detecting very small di↵erences in probability (e.g., 0.985 versus 0.998). A human observer is unlikely capable of such comparisons, and so to get a more realistic prediction of confidence agreement for the Basic-Probability model, we also simulated a version of the model that included 1% SD late noise (grey lines in <ref type="figure" target="#fig_7">Figure 5B</ref>). The confidence agreement of this model was much closer to the other non-ideal models.</p><p>To investigate if the best fitting model captured the confidence agreement of observers, we compared the proportion of trials for the highest possible agreement count. Note that the minimum and maximum agreement depended on whether the participant did a 3-, 4-, or 5-pass version of the task.</p><p>As the minimum number of passes was 3 (e.g., 2/3 and 3/3 agreement), selecting only a single count value to compare was the only appropriate choice for a statistical comparison. For 14 of the 15 observers, their confidence behaviour was in closer agreement across the repeats than predicted by their best-fitting model. A Wilcoxon signed-rank test confirmed that this di↵erence in confidence agreement is significant (n = 15, z = 3.35, p &lt; 0.01).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>We fit confidence models of all three metric types to confidence forced-choice responses in a suprathreshold spatial-discrimination task. Each metric type was supported by at least one observer, with 44% observers best fit by the Heuristic model (i.e., Heuristic metric), 44% by the Scaled-Distance model (i.e., DFC Evidence-Strength metric with a SNR transformation), and 12% by the Probability-Di↵erence model (i.e., Probability metric with late confidence noise). The Heuristic model was considered the winner overall at the group level. The modelling results suggest there is no universal computational strategy for taking sensory uncertainty into account when judging confidence. All four possibilities (i.e, a probability metric, SNR-scaling, use of a centred-prior, heuristic cue use; see <ref type="figure">Figure 1</ref>) were supported by at least one observer. Taken together, these results suggest that the computation of confidence is highly idiosyncratic in environments where decision uncertainty is influenced by multiple factors, further supporting the hypothesis of a highly individual nature to perceptual confidence <ref type="bibr" target="#b30">(Graziano and Sigman, 2009;</ref><ref type="bibr" target="#b2">Ais et al., 2016;</ref><ref type="bibr" target="#b52">Navajas et al., 2017)</ref>. However, within the metric types, there was a preference for some computations over others, which has implications for our understanding of the computation of perceptual confidence more generally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evidence-Strength metrics</head><p>Our results clearly show that for this mixed-di culty experiment, the Unscaled-Distance model performed significantly worse than the Scaled-Distance model, which took into account sensory uncertainty by applying a SNR transformation to the point estimate used to compute the DFC. In other words, a single point estimate of the decision process was insu cient to capture confidence behaviour and a secondary point estimate of sensory uncertainty is used by the metacognitive system. This finding is particularly relevant for the Extended-SDT framework of perceptual confidence. It is often assumed that the sensory measurement is simply compared to static confidence criteria <ref type="bibr" target="#b47">(Maniscalco and Lau, 2012;</ref><ref type="bibr" target="#b43">Mamassian, 2016)</ref>, which is no issue due to many SDT tasks being of a fixed di culty level (note that this is not true of tasks that staircase di culty, e.g., <ref type="bibr" target="#b21">Fleming et al., 2010;</ref><ref type="bibr" target="#b6">Bang et al., 2019)</ref>. In mixed-di culty designs, however, it has been proposed that confidence criteria are to some degree updated, sometimes on a trial-by-trial basis, according to the level of sensory uncertainty <ref type="bibr" target="#b73">(Zylberberg et al., 2014;</ref><ref type="bibr" target="#b1">Adler and Ma, 2018;</ref>. The reason an observer would do this is to avoid a confidence paradox of more readily assigning high confidence to stimuli with large sensory noise simply because the noise is likely to carry the measurement far from the perceptual decision</p><p>criterion. Yet, it appears that human observers do not shift their criteria appropriately to avoid this paradox <ref type="bibr" target="#b73">(Zylberberg et al., 2014;</ref>. However, the failure to find appropriate scaling by the participants in these studies may be due to the technique of measuring confidence. Without an incentive structure, confidence ratings are essentially meaningless and there is little motivating accurate shifts, but this is not true for the confidence forced-choice judgements as relative comparisons will always have a sensible interpretation even in the absence of an incentive structure.</p><p>From a modelling perspective, shifting the criteria to account for sensory uncertainty and the scaled DFC measure have the same e↵ects on the confidence computation. Previous studies likely favoured the shifting-criterion description simply because criterion plasticity is commonly accepted <ref type="bibr" target="#b60">(Rahnev and Denison, 2018)</ref>, whereas in the current study there were no confidence criteria to shift so only the scaling method was appropriate (see also <ref type="bibr" target="#b45">Mamassian and de Gardelle, 2021)</ref>. This highlights the need to better understand the metacognitive mechanism for accounting for sensory uncertainty. Our results suggest shifting of confidence criteria is not necessary as observers can scale DFC measures, however the "stickiness" of criteria has been used to explain suboptimal behaviour in decision contexts requiring shifting criteria <ref type="bibr" target="#b29">(Gorea and Sagi, 2000;</ref><ref type="bibr" target="#b63">Rahnev et al., 2011;</ref><ref type="bibr" target="#b73">Zylberberg et al., 2014)</ref>. It is unclear how these suboptimalities can be explained in a SNR version of Extended-SDT. If researchers wish to apply this form of scaling to an Extended SDT model, we propose using the log-likelihoodratio representation (ln ), which rescales the decision axis by the amount of sensory noise for a given stimulus level <ref type="bibr" target="#b42">(Macmillan and Creelman, 2005)</ref>, as placing perceptual and confidence criteria in this space removes the need to model multiple shifted criteria.</p><p>At a minimum, computing the SNR requires point estimates of the signal strength and uncertainty, but could also be achieved with a full probability distribution representation. After all, Probability metrics could be fairly well approximated with these point estimates. Thus, it appears that the linear scaling of the DFC confidence metrics is a key aspect of the Scaled-Distance model's success in contrast to the Probability-metric models ( <ref type="figure">Figure 1D-F)</ref>. Further research is needed to understand if this result is due to the way probabilistic computations are implemented in the metacognitive system <ref type="bibr" target="#b57">(Pouget et al., 2013)</ref> versus task-specific influences. In particular, as this task often asked observers to compare two easy perceptual decisions, a scaled DFC allows participants to be certain but not indi↵erent for the confidence forced-choice judgements, whereas comparisons of the raw probability values leads to quibbling over two values close to 1 ( <ref type="figure">Figure 1D</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Heuristic metrics</head><p>The winning Heuristic model is another model where observers are rarely indi↵erent for comparisons of easy trials. The model in this task had to consider three stimulus-based cues when assigning confidence:</p><p>the position of the dot cloud, the number of dots, and the dot spread. The distance of the centroid from the centre was the predictor given the most weight, followed by the number of dots, then dot spread. Heuristic observers tended to give more weight to the number of dots displayed than the other observers, with 5/7 observers giving almost equal or more weight to this predictor than the position of the dot cloud (i.e., stimulus strength). If is unclear why the number of dots was particularly salient to these observers in this task, given the amount of previous evidence suggesting that variability, here dot-cloud spread, is a strong heuristic cue (De Gardelle and <ref type="bibr" target="#b17">Mamassian, 2015;</ref><ref type="bibr" target="#b66">Spence et al., 2015;</ref><ref type="bibr" target="#b11">Boldt et al., 2017;</ref><ref type="bibr" target="#b9">Bertana et al., 2021)</ref>. However, to our knowledge, no other perceptual confidence task has jointly manipulated both the quantity and quality of sensory information. This suggests that future work interested in investigating heuristic cues in confidence should consider targeting the quantity of information provided.</p><p>From a computational perspective, approximately half of all confidence forced-choice comparisons were between intervals that di↵ered in the number of dots and all di↵ered in empirical spread (assuming that was used instead of the unknowable generative spread), so stimulus-based heuristics could have provided quicker and less computationally complex answers to confidence comparisons in most trials of this task <ref type="bibr" target="#b27">(Gigerenzer and Gaissmaier, 2011)</ref>. In contrast, a Bayesian confidence observer would often be faced with comparing similar subjective probabilities of being correct that could prolong deliberation on the confidence report. Furthermore, as many perceptual scenarios in daily life are similarly suprathreshold, it may be advantageous more generally to rely on stimulus-based heuristics (or scaled-distance measurements) simply to avoid indi↵erence between confidence-driven choices. For example, when attempting to select the freshest salad mix at the supermarket, you can be assessing two bags that look equally fresh but you might select the bag without spinach because it expires quickly. This heuristic leads to a satisfactory result quickly. In this regard, the confidence forcedchoice technique with easy perceptual decisions proved a suitable method for investigating heuristic confidence that could be employed with neural measures to increase our understanding of real-world computations of confidence <ref type="bibr" target="#b26">(Gardner, 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Probability metrics</head><p>In addition to the Probability-Di↵erence model, the Probability metric category contained the Ideal Confidence Observer, the Basic-Probability model, and the LPR model. The centred-prior variants of these models conform to the definition of "Bayesian Confidence" according to the Bayesian Confidence Hypothesis <ref type="bibr" target="#b64">(Sanders et al., 2016;</ref><ref type="bibr" target="#b1">Adler and Ma, 2018;</ref><ref type="bibr" target="#b36">Li and Ma, 2020)</ref>, and were not a best-fitting model of any participant. The flat-prior variants of these models also conform to the definition of Bayesian Confidence, as the probability of being correct cannot be computed from an un-normalised likelihood function, and were best fit for two participants. As such, our results do not strongly support the Bayesian Confidence Hypothesis, in agreement with some previous studies <ref type="bibr" target="#b1">(Adler and Ma, 2018;</ref><ref type="bibr" target="#b18">Denison et al., 2018;</ref><ref type="bibr" target="#b38">Lisi et al., 2021)</ref> but not others <ref type="bibr" target="#b3">(Aitchison et al., 2015;</ref><ref type="bibr" target="#b36">Li and Ma, 2020)</ref>.</p><p>Despite this finding, the results of the current study should not be interpreted as against Bayesian computations in the brain more generally. The averaging of the perceived dot locations that is the basis of all models we tested is optimal Bayesian cue combination <ref type="bibr" target="#b35">(Landy et al., 2011)</ref>. Additionally, the A clear finding from the present study is that confidence noise is an important component of confidence models, adding support to the many previous studies that suggest that the perceptual decision variable and the confidence decision variable are not the same due to additional confidence noise <ref type="bibr" target="#b6">Bang et al., 2019;</ref><ref type="bibr" target="#b65">Shekhar and Rahnev, 2021)</ref>. This can be seen best in the Probability-metric models where confidence noise is a particularly important distinguishing factor among the models. For example, the Ideal-Confidence-Observer, Basic-Probability, and</p><p>Probability-Di↵erence models have no noise, early additive Beta noise, or late additive Gaussian noise respectively, which is applied to the estimated probability of being correct. This choice has dramatic consequences for the fit of the models ( <ref type="figure" target="#fig_5">Figure 4B</ref>). According to the best-fitting parameters for the winning Heuristic model, there was also a small confidence interval bias towards reporting Interval 2 that was not significant at the group level, suggesting confidence interval bias plays less of a role than confidence noise in the participants' confidence forced-choice judgements.</p><p>Another consideration in the computation of confidence is the resolution of probability judgements for confidence evaluations. This can be best seen in the contrast of the Basic-Probability model and the LPR model. If the distribution means in both intervals are far from the centre, the raw probability values will be similarly close to 1 ( <ref type="figure">Figure 1D</ref>), but if a LPR transformation is applied, small di↵erences in the relative positions of the distribution means can translate into large di↵erences in confidence ( <ref type="figure">Figure 1E)</ref>. E↵ectively, the LPR model has a very high resolution for extreme probability comparisons.</p><p>Fortunately, this can be assessed in the confidence forced-choice method despite potential distortions in perceived probability <ref type="bibr" target="#b32">(Kahneman and Tversky, 1979;</ref><ref type="bibr" target="#b22">Fox and Poldrack, 2009)</ref> because any distortion would apply to both Interval 1 and 2 and thus not change the relative judgement in confidence, as long as the distortion function is monotonic. In contrast, traditional methods of measuring confidence are likely to su↵er from probability distortions in probability judgements or ceiling e↵ects of ratings at high levels of confidence <ref type="bibr" target="#b20">(Fleming and Lau, 2014)</ref>. Our results are not conclusive on this point.</p><p>While the Probability-Di↵erence model was third best in terms of the number of observers best fit, the LPR model was overall a superior model at the group level and in the model recovery analysis showed some fit similarity to the second best-fitting Scaled-Distance model ( <ref type="figure" target="#fig_5">Figure 4F</ref>). Reviewing previous studies, a high resolution for extreme probabilities does not match with findings of compression of continuous confidence probabilities to a few discrete levels for perceptual confidence <ref type="bibr" target="#b38">(Lisi et al., 2021)</ref> or knowledge of motor uncertainty distributions (i.e., motor confidence <ref type="bibr" target="#b69">Zhang et al., 2015)</ref>. Further work is needed to understand the representation of confidence for extreme probabilities. It is possible that our Probability-metric models were overly simplistic, and models with intermediate resolution,</p><p>such as by allowing the confidence noise to vary with signal strength or including probability distortions in the mapping function <ref type="bibr" target="#b70">(Zhang and Maloney, 2012)</ref>, would improve the fit. However, the increased flexibility of such models is also likely to pose a challenge in distinguishing between candidate models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Use of a centred prior</head><p>We were unable to reach a strong conclusion about the use of centred priors in the computation of confidence. Only three observers were best-fit by a centred-prior variant model ( <ref type="figure" target="#fig_5">Figure 4B</ref>), but this increased to six if the stimulus prior assumed perfect knowledge of the three levels of dot spread tested (see <ref type="figure">Supplementary Materials)</ref>. It is well known that observers do not always adapt perfectly to the experimental environment, causing them to use incorrect priors or priors matching environmental statistics <ref type="bibr" target="#b41">(Ma, 2012;</ref><ref type="bibr" target="#b26">Gardner, 2019)</ref>, and this may have occurred in the current study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Confidence agreement</head><p>The confidence agreement analysis showed that the best-fitting model per observer almost always underestimated the degree of confidence agreement in the N-pass designs. From a modelling perspective, there are three factors that could have limited confidence agreement in the present experiment:</p><p>1) Type 1 sensory noise, 2) Type 2 confidence noise, and 3) the resolution of the confidence decision variable. The e↵ect of sensory noise can be observed in the predicted confidence agreement of the Ideal Confidence Observer ( <ref type="figure" target="#fig_7">Figure 5B</ref>), as this was the only factor relevant in the simulation of this model.</p><p>The remaining models have lower predicted confidence agreement, which is due to the influence of the confidence noise. The Basic-Probability model had higher confidence agreement than the others, likely due to the model using a di↵erent noise distribution <ref type="table">(Table 3</ref>). Examining the model simulations in more detail, we found that many of the confidence comparisons for the Basic-Probability model were between two extremely high probabilities and that the model is not robust to even small amounts of late decision noise. It is unlikely that a human observer has such a high resolution for the confidence decision variable, which is why resolution may be a third factor, e↵ectively discretising confidence into various levels as suggested by <ref type="bibr" target="#b38">Lisi et al. (2021)</ref>. However, lowering the confidence resolution will decrease confidence agreement, so this alone cannot explain why the confidence models with non-discretised confidence variables under-predicted confidence agreement. It is also not due to an interval response bias, as this was included in the model simulations.</p><p>What the Basic-Probability model does illustrate is that the choice of the confidence noise model a↵ects confidence agreement. This suggests that future studies of confidence agreement could investigate di↵erent confidence-noise distributions (e.g., <ref type="bibr" target="#b65">Shekhar and Rahnev, 2021)</ref>, assumptions about noise being independent between the two intervals, partially or fully parallel confidence decision processes <ref type="bibr" target="#b19">(Fleming and Daw, 2017)</ref>, and serial-dependence e↵ects on confidence <ref type="bibr" target="#b62">(Rahnev et al., 2015)</ref>.</p><p>In general, the N-pass technique o↵ers an interesting additional benchmark for assessing confidence models, just as it has proved useful in better understanding the computations of perceptual decisionmaking <ref type="bibr" target="#b13">(Burgess and Colborne, 1988;</ref><ref type="bibr" target="#b37">Li et al., 2006;</ref><ref type="bibr" target="#b31">Hasan et al., 2012)</ref>. Though it is important to keep in mind that the inputs to the confidence computation will never be identical due to sensory noise, so not all analyses developed for perceptual decision-making will be applicable to their confidence counterpart. Overall, confidence agreement appears to be a promising evaluation technique, with some researchers already leveraging the power of multiple presentations mostly in the form of trial "replays" to understand confidence <ref type="bibr" target="#b5">(Balsdon et al., 2020;</ref><ref type="bibr" target="#b15">Charles et al., 2020)</ref>, so we expect that the use of multiple passes in confidence experiments will only increase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Strengths and limitations</head><p>A key strength of this study was the variety of metric types tested. We succeeded in fitting models of the Probability, Evidence-Strength, and Heuristic types while maintaining reasonable model identifiability (see the model recovery analysis in <ref type="figure" target="#fig_5">Figure 4E</ref>). In part, this was due to our novel approach of pairing the confidence forced-choice technique <ref type="bibr" target="#b44">(Mamassian, 2020;</ref><ref type="bibr" target="#b45">Mamassian and de Gardelle, 2021)</ref> with an easy perceptual task. Specifically, the models are more divergent for easy trials and the confidence forced-choice method allowed us to probe the confidence decision variable in this range.</p><p>A downside of the confidence forced-choice technique is that there is only one confidence report for every two perceptual decisions, doubling the number of perceptual trials needed per participant. In our study, participants completed five hours of testing each on trials with very brief stimulus presentations.</p><p>Using stimuli that require long presentation times (e.g., random-dot motion) would have a serious impact on the rate of data collection and introduce concerns over memory of the decision in the first interval. A consequence of using very brief stimulus presentations is that these stimuli are less suitable for studying the accumulation of evidence. Typically, researchers who investigate the temporal dynamics of decision-making use long presentation times, or let the observer decide when to terminate viewing the stimulus, using accumulation-to-bound models (e.g., <ref type="bibr" target="#b33">Kiani et al., 2014;</ref><ref type="bibr" target="#b72">Zylberberg et al., 2016;</ref><ref type="bibr" target="#b5">Balsdon et al., 2020)</ref>. For these reasons, we did not investigate accumulation-to-bound models in the present study. In general, we would not recommend the confidence forced-choice method for evaluating these models or the temporal dynamics of confidence.</p><p>Regarding the use of mostly easy perceptual decisions, we have already highlighted some ways this may have a↵ected the strategy of observers. To avoid indi↵erence in the majority of confidence forcedchoice judgements, observers may have used computational strategies that would give a preference to one interval over the other. Other studies found that the best-fitting model could change according to the task structure <ref type="bibr" target="#b3">(Aitchison et al., 2015;</ref><ref type="bibr" target="#b9">Bertana et al., 2021)</ref>, so it is possible that observers here adapted their computations of confidence to the decision context. If true, this could prevent researchers from reaching a consensus over the computational steps for confidence, and thus knowing the extent of computations possible (e.g., access to a full posterior distribution, point estimate of uncertainty, etc.). The key factors precipitating a switch in strategy (e.g., mixed-di culty contexts, easy choices, etc.) should be the focus of computational e↵orts to study confidence.</p><p>The unintentional repetition of sessions resulting in an N-pass design to the experiment had both strengths and limitations. Obvious concerns are a reduction in the number of unique stimuli and stimulus pairings in the task, which a↵ects the quality of the dataset for model fitting. There is also the possibility of the observer recognising the repetition and repeating responses, though none reported noticing the N-pass nature of the task. The clear advantage was the ability to conduct an exploratory analysis of confidence agreement, which revealed an explanatory deficit in the best-fitting models. We recommend researchers in confidence agreement design the N-pass carefully. For example, shu✏ing the order of repeated pairs to avoid order e↵ects <ref type="bibr" target="#b31">(Hasan et al., 2012)</ref>. Another consideration is the di culty of the task. Di cult trials are more likely to lead to Type 1 judgements that di↵er between passes, whereas in easier designs, such as in the present study, the majority of Type 1 judgements are the same. Finally, we see no reason why confidence-agreement experiments cannot be used with other types of confidence reports besides confidence forced-choice. As such, including at least a 2-pass design into any confidence experiment should be feasible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Conclusion</head><p>By using the confidence forced-choice method, we have shown that observers are not indi↵erent for easy perceptual choices. Almost half of the observers took sensory uncertainty into account by computing the signal-to-noise ratio (SNR) in the Type 1 decision process, while a similar number used stimulusbased heuristic cues to compute confidence. Overall, this suggests that observers use the Distance-From-Criterion (DFC) Evidence-Strength and Heuristic metrics over Probability metrics, the most notable of which is the Bayesian Confidence Hypothesis. Furthermore, while heuristic cue use is likely to vary according to the specifics of the individual experiment, the Scaled-Distance model is applicable in any mixed-di culty design and should be more widely considered. Our results suggest relying on the simple unscaled metric typically used in extended Signal Detection Theory (SDT) could lead to worse model fits or an unnecessary proliferation of confidence criteria to account for this transformation.</p><p>An accidental repetition of the presented stimuli also allowed us to capture the confidence agreement of observers; a novel measure of model fit. This analysis revealed that observers are much more consistent then would be predicted by any of the models except the Ideal Confidence Observer. We propose confidence agreement as a readily accessible model-validation benchmark for future e↵orts in modelling perceptual confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Participants</head><p>Sixteen participants (21 -43 years old, ten female) with normal or corrected-to-normal vision took part in the study. All participants but two were naive to the design of the experiment. Testing was conducted in accordance with the ethics requirements of the Institutional Review Board at New York University. Participants received details of the experimental procedures and gave informed consent prior to the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Apparatus</head><p>Stimuli were displayed on a Sony G400 CRT monitor (36 x 27 cm, 1024 x 768 pixel, 85 Hz). Participants sat 55 cm from the monitor with their head stabilised by a chin rest. All responses were entered on a standard computer keyboard. The experiment was conducted using custom-written code in MATLAB version R2014a (The MathWorks, Natick, MA), using Psychtoolbox version 3.0.11 <ref type="bibr" target="#b12">(Brainard, 1997;</ref><ref type="bibr" target="#b55">Pelli, 1997;</ref><ref type="bibr" target="#b34">Kleiner et al., 2007)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Task</head><p>In this task, participants judged if the mean of an invisible dot-generating distribution, a 2D circular symmetric Gaussian, was left or right of centre (i.e., a Type 1, perceptual judgement). The distribution had seven possible spatial o↵sets of the mean (-4, -2, -1, 0, 1, 2, and 4 deg) and three possible standard deviations (1.5, 2, or 2.5 deg). The distribution mean did not deviate vertically from the half-height of the screen and the screen centre was indicated by a fixation cross prior to stimulus presentation.</p><p>Participants were presented with either two or five independently sampled dots (Gaussian-blobs with 0.1 deg SD). The white dots were simultaneously presented on a mid-grey background for 23.5 ms.</p><p>The number of dots (i.e., quantity manipulation) and the spread of the generating distribution (i.e., quality manipulation), produced in six levels of sensory uncertainty. Fewer dots or larger spread made the distribution mean more di cult to localise. After every two stimulus presentations (denoted Interval 1 and Interval 2), the participant reported if they had greater confidence that their first decision or second decision was correct (i.e., a Type 2, metacognitive judgement). This confidence forced-choice technique avoids over-or under-confidence biases by having the observer report relative confidence <ref type="bibr" target="#b44">(Mamassian, 2020;</ref><ref type="bibr" target="#b45">Mamassian and de Gardelle, 2021</ref>). An example trial pair is shown in <ref type="figure">Figure 2A</ref>. The stimulus location, number of dots, and distribution spread were randomised at the level of individual trials in an interleaved design, with trial pairings left to chance. Consequently, confidence comparisons could be between any combination of stimulus strength and sensory uncertainty (42 ⇥ 42 possibilities). In each session, there were 20 presentations per unique combination of stimulus strength and sensory uncertainty. New dots were sampled for each repeat. Participants completed 5 one-hour sessions of 840 perceptual judgements and 420 confidence forced-choice judgements, resulting in a total of 4200 and 2100 judgements, respectively, per participant. During the experiment, no feedback was provided on the correctness of the perceptual decisions. Data from this experiment are available at https://osf.io/k2nhq/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Stimulus Set Repetition</head><p>Due to a coding oversight, the experiment was conducted with the same random seed for every session.</p><p>This, coupled with the practice of switching o↵ the testing computer between sessions, led to many of the sessions displaying the exact same sequence of stimuli ( <ref type="figure">Figure 2B</ref>). For example, eight participants saw the same identical sequence of dot clouds for all five sessions; three saw this sequence for four out of five sessions; and only one participant was given a unique stimulus set for each session. In the most frequent stimulus set, of the possible pairings of sensory uncertainty for the confidence comparison, the worst sampled combination had seven unique pairs of stimuli. If the interval order is ignored, this number increases to nine unique pairs of stimuli for two same-uncertainty pairings. While this random seed setting limited the richness of the collected dataset, we saw this as an opportunity to investigate the agreement of confidence reports. In our modelling, we were able to leverage these measurements of confidence agreement to perform predictive checks of the model fits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">General modelling framework</head><p>We modelled our participants as Bayesian observers making a joint inference about the mean and precision (i.e., inverse spread) of the dot generating distribution from a noisy observation of the dots presented onscreen. <ref type="figure">Figure 6A</ref> shows the prior, likelihood, and posterior components for an example trial. It was important to include the inference about the precision of the generating distribution because uncertainty in the estimated mean depends on the precision. This can be seen in the triangular shape of the prior, likelihood, and posterior. If the distribution's spread is small, precision is large, and the uncertainty in the distribution's mean is low. To make a spatial judgement, the observer marginalises over all possible precision values to get the probabilistic representation shown in <ref type="figure">Figure 6B</ref>. From this they decide whether the evidence favours a distribution mean to the left or the right, and subsequently their confidence. The advantage of using the same general framework for models of all three metric types (Probability, Evidence-Strength, and Heuristic) was that conclusions drawn from the model fits were more likely to reflect the confidence computation than "nuisance" di↵erences between di↵erent modelling frameworks.  <ref type="figure">Figure 6</ref>: Elements of the decision models. Depicted is the estimated joint probability of the dot-cloud generating distribution mean and precision for an example stimulus presentation of 2 dots. A) Centred Normal-gamma prior distribution (based on the stimulus statistics of the experiment), likelihood function based on the noisy dot observations, and the resulting normal-gamma posterior distribution. All three distributions have the same axes as the ones shown in the posterior panel. B) The marginal prior (grey), likelihood (orange), and posterior (blue) for estimating the generating distribution mean. An unbiased Type 1 decision criterion, k 1 , is also depicted. Inset: the displayed and perceived locations of the two sampled dots, with the dashed line indicating the screen midline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Decision context</head><p>There are two categories of stimuli in the perceptual task: left (C = L) and right (C = R). For each interval, the observer reports their belief about stimulus category (i.e.,Ĉ = L orĈ = R), as their</p><p>Type response based on their noisy sensory measurements of the sampled dots as well as any prior beliefs about the underlying generative sensory process. For the Type 2 confidence judgement, the observer compares the probability of their Type 1 perceptual decisions being correct in Interval 1 and</p><formula xml:id="formula_3">2: p(Ĉ 1 = C 1 ) versus p(Ĉ 2 = C 2 ).</formula><p>In a single interval, a dot sampling distribution, defined by its horizontal mean (µ cloud ) and spread ( cloud ), is drawn from one of the respective categories with equal probability: P (C L ) = P (C R ) = 0.5.</p><p>The exception being the case where µ = 0, which favours neither category and we treat as coming from either category randomly. From the sampling distribution, N dots are independently drawn,</p><p>represented by the vector of horizontal dot locations,</p><formula xml:id="formula_4">D = d 1 , d 2 , ..., d N .</formula><p>During the measurement process, additive sensory noise is applied per dot, ✏ ⇠ N (0, 2 dot ), represented by the vector of noisy horizontal dot-location measurements, X = x 1 , x 2 , ..., x N . We assume the observer knows N (either 2 or 5) but not cloud of the sampling distribution on any given trial. Thus, the observer's Type 1 task is to infer the category of stimulus with uncertain sampling distribution mean and spread based on the observed dot samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">The likelihood function</head><p>The observer must consider two sources of uncertainty when choosing a likelihood function, the noisy draws of N dots from the sampling distribution, a↵ected by 2 cloud , and the internal noise applied to each dot, 2 dot . These two noise sources are additive, resulting in the combined precision per dot of</p><formula xml:id="formula_5">⌧ comb = 1 2 cloud + 2 dot = 1 ⌧ 1 cloud + ⌧ 1 dot .<label>(1)</label></formula><p>Note that we have parameterised the variances in terms of precision:</p><formula xml:id="formula_6">⌧ cloud = 2 cloud and ⌧ dot = 2</formula><p>dot . The likelihood function for the observed dot cloud is</p><formula xml:id="formula_7">p(X|µ cloud , ⌧ cloud , ⌧ dot ) = N Y i=1 p(x i |µ cloud , ⌧ comb ) / ⌧ N 2 comb exp ✓ ⌧ comb 2 N X i=1 (x i µ cloud ) 2 ◆ .<label>(2)</label></formula><p>This likelihood function is centred on the dot-cloud centroid, the average of all the dot locations, because each dot is considered to be an equally reliable cue to the location of the generating distribution.</p><p>An example likelihood function is shown in <ref type="figure">Figure 6A</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">The prior distribution</head><p>In the centred-prior variants, we assumed the observer correctly inferred the joint distribution of the sampling distribution mean and precision through experience with the task. Even though the mean and precision were discretised in our experiment (7 and 3 possible values, respectively), we assumed that the observer could not have such a detailed representation and thus we consider that the prior is a continuous distribution. The conjugate prior for our likelihood function (i.e., inferring a normal distribution with unknown mean and precision) is a normal-Gamma distribution <ref type="bibr" target="#b10">(Bishop, 2006;</ref>:</p><formula xml:id="formula_8">p(µ cloud , ⌧ cloud ) = N G(µ cloud , ⌧ cloud |µ 0 ,  0 , ↵ 0 , 0 ) = N (µ cloud |µ 0 , ( 0 ⌧ cloud ) 1 ) Ga(⌧ cloud |↵ 0 , 0 ).<label>(3)</label></formula><p>To find the parameters of the normal-Gamma prior, we calculated the values of µ 0 ,  0 , ↵ 0 , and 0 such that the marginal means and variances matched the true stimulus statistics from the experiment (derivation in the Supplementary Materials). This prior distribution, shown in <ref type="figure">Figure 6A</ref>, has µ 0 = 0,  0 = 0.68, ↵ 0 = 3.84, and 0 = 13.48. Note that  0 can be interpreted as a number of pseudoobservations, ↵ 0 as related to degrees of freedom, and 0 as related to the prior belief about pooled variance.</p><p>For the flat-prior variants, we applied a uniform distribution over all possible mean and spread values. The posterior distribution is thus equivalent to the normalised likelihood function. For the posterior distribution we detail next, we are referring to the centred-prior variant models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">The posterior distribution</head><p>Using Bayes' theorem, we can write the expression for the posterior that combines the prior beliefs about the joint probability of the distribution's mean and precision with the observed dot evidence.</p><p>Because we have used the conjugate prior, the posterior is also a normal-Gamma distribution (deriva-tion provided in the Supplementary Materials):</p><formula xml:id="formula_9">p(µ cloud , ⌧ cloud |X, ⌧ dot ) / p(X|µ cloud , ⌧ cloud , ⌧ dot )p(µ cloud , ⌧ cloud ) = N G(µ cloud , ⌧ cloud |µ p ,  p , ↵ p , p , ⌧ dot ),<label>(4)</label></formula><p>with the following posterior parameters:</p><formula xml:id="formula_10">µ p =  0 ⌧ cloud µ 0 + N ⌧ combx  0 ⌧ cloud + N ⌧ comb ,<label>(5)</label></formula><formula xml:id="formula_11"> p =  0 ⌧ cloud + N ⌧ comb ⌧ cloud ,<label>(6)</label></formula><formula xml:id="formula_12">↵ p = ↵ 0 + N 2 ,<label>(7)</label></formula><p>and</p><formula xml:id="formula_13">p = 0 + N 2⌧ cloud ✓  0 ⌧ cloud ⌧ comb (x µ 0 ) 2  0 ⌧ cloud + N ⌧ comb + ⌧ comb s 2 + log(⌧ 1 dot ⌧ cloud + 1) ◆ .<label>(8)</label></formula><p>Wherex is the sample mean of the observed dots,</p><formula xml:id="formula_14">x = 1 N N X i=1 x i ,<label>(9)</label></formula><p>and s 2 is the observed sample variance in maximum-likelihood terms,</p><formula xml:id="formula_15">s 2 = 1 N N X i=1 (x i x) 2 .<label>(10)</label></formula><p>An example posterior distribution is shown in <ref type="figure">Figure 6C</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Taxonomy of confidence models</head><p>The seven base confidence models we considered di↵er in the level of access to the posterior distribution. They could access either 1) the full distribution, 2) only the mode, or 3) both mode and spread. Models that made use of the full distribution used Probability-metrics for computing confidence. Confidence computations that used the mode, with or without posterior spread, were DFC Evidence-Strength metrics. The Heuristic model combined separate estimates of stimulus strength and sensory uncertainty factors (i.e., number and spread of dots) in an idiosyncratic weighted sum.</p><p>Model summaries are provided in <ref type="table" target="#tab_1">Table 2</ref> and model equations in <ref type="table">Table 3</ref>.</p><p>We also considered two model variants when relevant, resulting in a total of twelve unique models.</p><p>For the centred-prior variant, the observer uses the informative prior that matched the stimulus statistics (depicted in <ref type="figure">Figure 6</ref>). For the flat-prior variant, the observer uses a non-informative flat prior as if they had used the normalised likelihood function to make their perceptual and confidence decisions.</p><p>In regards to confidence interval bias and noise, as per its definition, the Ideal-Confidence-Observer model did not have either of these elements <ref type="bibr" target="#b44">(Mamassian, 2020)</ref>, but otherwise all confidence models had both. Confidence interval bias in the confidence forced-choice method is a preference for reporting</p><p>Interval 2, for example <ref type="bibr" target="#b44">(Mamassian, 2020;</ref><ref type="bibr" target="#b45">Mamassian and de Gardelle, 2021)</ref>, and should not be confused with an over-or under-confidence bias. Confidence noise was dependent on the individual confidence model. Almost all models had additive Gaussian noise. However, for models that used raw probability values (i.e., the Basic-Probability models), we used Beta-distributed variability to keep the confidence decision variable between 0 and 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Ideal-Confidence-Observer model</head><p>The goal of the observer was to infer if the mean of the dot sampling distribution was left or right of centre. The ideal confidence observer would take into account the unknown precision of the sampling <ref type="table">Table 3</ref>: Equations for the seven base Type 2 Confidence models. The models consider the decision evidence, Ev(), in favour of the perceptual choice, r, given the dot measurements, X, and Type 1 decision criterion, k 1 . The DFC Evidence-Strength models take a point estimate of the posterior's mode (μ), with or without scaling by the posterior's spread (ˆ ), and compare its unsigned distance from k 1 . Confidence forced-choice judgements involve comparing the relative confidence evidence for the intervals (w 1 versus w 2 ), with an influence of a confidence interval bias, k 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Confidence Evidence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision</head><p>Confidence Free</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule Noise Parameters</head><p>Ideal Conf. Observer</p><formula xml:id="formula_16">w = Ev(r|X, k 1 ) w 2 &gt; w 1 none none Basic Probability w ⇠ Beta ⌫p, ⌫(1 p) ; p = Ev(r|X, k 1 ) w 2 + k 2 &gt; w 1 0 &lt; ⌫ &lt; 1 ⌫, k 2 Probability Di↵erence w = Ev(r 2 |X 2 , k 1 ) Ev(r 1 |X 1 , k 1 ) + ✏ w + k 2 &gt; 0 ✏ ⇠ N (0, 2 conf ) conf , k 2 Log Probability Ratio w = | log ⇣ p 1 p ⌘ + ✏|; p = Ev(r|X, k 1 ) w 2 + k 2 &gt; w 1 ✏ ⇠ N (0, 2 conf ) conf , k 2 Unscaled Distance w = |μ k 1 + ✏| w 2 + k 2 &gt; w 1 ✏ ⇠ N (0, 2 conf ) conf , k 2 Scaled Distance w = |μ k 1 + ✏| w 2 + k2 &gt; w 1 ✏ ⇠ N (0, 2 conf ) conf , k 2 Heuristic w = |µc k 1 | + 1 N 2 1 emp + ✏ w + k 2 &gt; 0 ✏ ⇠ N (0, 2 conf ) 1 , 2 , conf , k 2 distribution by marginalising over all possible precision values p(µ cloud |X) = Z p(µ cloud , ⌧ cloud |X, ⌧ dot )d⌧ cloud ,<label>(11)</label></formula><p>which results in the marginal posterior distribution shown in <ref type="figure">Figure 6B</ref>. The evidence for each category,</p><p>given the observed measurements and centred stimulus prior, can be computed by</p><formula xml:id="formula_17">p(C = R|X, k 1 ) = p(µ cloud &gt; k 1 |X, k 1 ) = Z 1 k 1 p(µ cloud |X)dµ cloud ,<label>(12)</label></formula><p>where k 1 is the Type 1 discrimination boundary, and</p><formula xml:id="formula_18">p(C = L|X, k 1 ) = 1 p(C = R|X, k 1 ).<label>(13)</label></formula><p>For the Type 1 judgement, the inferred category of the stimulus,Ĉ, is then determined by the relative probabilities of each category, with the observer selecting the most likely category. They select "right" if p(C = R|X, k 1 ) &gt; p(C = L|X, k 1 ), and "left" otherwise. The observer reports the more likely category with a keypress (r =Ĉ), unless a lapse occurs, where the observer selects the unintended category, with the lapse rate of . As such,</p><formula xml:id="formula_19">p(choose Right) = + (1 2 )p ✓ p(C = R|X, k 1 ) &gt; p(C = L|X, k 1 ) ◆ .<label>(14)</label></formula><p>For the Type 2 confidence judgement, the Ideal Confidence Observer considers the relative strength of the evidence in two consecutive Type 1 judgements, selecting the interval with the response that is more likely to be correct as having higher confidence, where Interval 1 evidence, w 1 , is</p><formula xml:id="formula_20">w1 = Ev(r 1 |X 1 , k 1 ) = max  p(C 1 = R|X 1 , k 1 ), p(C 1 = L|X 1 , k 1 )<label>(15)</label></formula><p>and Interval 2 evidence, w 2 is</p><formula xml:id="formula_21">w2 = Ev(r 2 |X 2 , k 1 ) = max  p(C 2 = R|X 2 , k 1 ), p(C 2 = L|X 2 , k 1 ) .<label>(16)</label></formula><p>The observer reports Interval 1 for the confidence judgement if w 1 &gt; w 2 and Interval 2 if w 2 &gt; w 1 .</p><p>When a lapse in the Type 1 report occurs, the observer selects the unintended response. We assume the participant is aware of the lapse and reflects this in their confidence report. Mathematically, the max operation in the above equations is replaced by a min operation for instances of lapses. The confidence evidence computation and decision rule are shown in <ref type="table">Table 3</ref>, along with those for all Type confidence models we tested. As this is the Ideal-Confidence-Observer model, the observer does not incur any additional metacognitive noise in their computation of confidence, but they are still subject to Type 1 decision bias through parameter k 1 <ref type="bibr" target="#b44">(Mamassian, 2020)</ref>. Following the decision rule of the ideal confidence observer, p(choose I 2 ) = + (1 2 )p(w &gt; w 1 ).</p><p>We assumed the Type 2 lapse rate was identical to the Type 1 lapse rate, , and fixed it in the Type 2 model fits according to the best-fitting value from the Type 1 model fits. For both the Type 1 and 2 judgements, the choice probabilities were estimated by simulation. The Ideal-Confidence-Observer model had no free parameters after fixing the Type-1 parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8">Probability-metric models</head><p>The remaining six Probability-metric models follow a similar logic to the Ideal Confidence Observer at the Type 1 and 2 levels, but included various forms of metacognitive noise <ref type="table">(Table 3)</ref>. We also considered flat-and centred-prior variants. The posterior distribution in Eq. 11 di↵ers between the two variants, but otherwise the model computations are unchanged. In all of the Probability-metric models, we included a confidence interval bias term for interval preferences, which was implemented in the decision rule as 1 &lt; k 2 &lt; 1. Thus, the Probability-metric models had two free parameters:</p><p>⌫ or conf (i..e., confidence noise), and k 2 .</p><p>Basic-Probability models. The observer directly compares the evidence in favour of their choice, but these raw probability values have been corrupted by noise. As probabilities are constrained to the interval [0, 1], we implemented a beta-noise model, with ⌫ as a concentration parameter (larger values: less confidence noise). E↵ectively, ⌫ is a number of "internal" observations, of which a certain fraction are consistent with the chosen category and the rest with the unchosen category, with proportions in line with the observer's beliefs about being correct. Consequently, as ⌫ ! 1, w becomes a Delta distribution at Ev(r|X, k 1 ).</p><p>Probability-Di↵erence models. The decision evidence is first compared for the intervals and then late additive Gaussian noise is applied to their di↵erence. The smaller this confidence noise, conf , the closer the observer is to the ideal confidence observer.</p><p>Log-Probability-Ratio (LPR) models. The decision evidence of each interval is transformed onto a continuous scale of log probability and then Gaussian noise is applied before the intervals are compared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.9">DFC Evidence-Strength metric models</head><p>The Distance-From-Criterion (DFC) Evidence-Strength models rely on point estimates from the decision process. In both the flat-and centred-prior variants, the observer computes the mode of the posterior,μ. Using this point estimate in the Type 1 decision will lead to identical Type choice behaviour as in Eq. 14, for the same prior variant. This is because a posterior mode right of the Type 1 criterion will always corresponds to p(C = R|X, k 1 ) &gt; p(C = L|X, k 1 ) for the normal-gamma posterior distribution in Eq. 4, and vice versa for a posterior mode to the left. However, the DFC Evidence-Strength models make di↵erent predictions for confidence. Similar to the Probability-metric models, we included a confidence interval bias, 1 &lt; k 2 &lt; 1. Thus, the DFC Evidence-Strength models also had two free parameters: conf and k 2 .</p><p>Unscaled-Distance model. For confidence evidence, this model considers the distance ofμ from the Type 1 discrimination boundary, k 1 , with added Gaussian noise, N (0, 2 conf ), per interval. The furtherμ is from the criterion, the stronger the evidence for the spatial discrimination judgement.</p><p>Scaled-Distance models. The observer also considers the decision uncertainty by assessing the spread of the marginal posterior distribution in the form of a second point estimate,ˆ . The distance of the mode from k 1 is then computed units of standard deviation (i.e., signal-to-noise ratio; see Supplementary Materials for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.10">Heuristic model</head><p>The Heuristic model uses an estimate of stimulus strength and estimates of each separate factor a↵ecting sensory uncertainty (i.e, the number of dots and dot spread) as inputs to the confidence computation, without any constraint on the relative weighting of these inputs on confidence. In e↵ect, this model is the best-fitting model from the preliminary logistic regression analysis (see <ref type="figure">Supplementary   Materials</ref>), but fit in accordance with the discrimination behaviour <ref type="table">(Table 3)</ref>. This involved combining the noisy observations of the sampled dots to compute the position predictor (i.e., the centroid DFC |µ c k 1 |), the dot spread for the quality predictor (i.e., the empirical spread, emp ), and a count of the number of dots for the quantity predictor (N ), as well as any confidence interval bias (k ). To avoid equivalent best-fitting regressors, the position coe cient that was expected to be dominant was fixed at 1 in the model and the other two coe cients, 1 (for the di↵erence in the number of dots across intervals) and 2 (for the di↵erence in inverse dot spread), were free to vary. Confidence noise, conf , was also free to vary. In total, the Heuristic model had 4 free parameters: 1 , 2 , conf , and k 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11">Model fitting, comparison, and validation</head><p>Models were fit in a two-step procedure using custom-written Matlab code (available at https: //osf.io/k2nhq/). Type 1 parameters were fit first ( dot , k 1 , and ) using the discrimination responses. Then the Type 2 parameters (⌫ or conf , k 2 , and possibly the two values) were estimated using the confidence forced-choice responses. Type 1 parameters were kept fixed at their best-fitting values for the Type 2 fits. Type 1 models were fit using a brute-force grid method, with response probabilities estimated by simulation of the observer. For the Type 2 model fits, only simulated sensory measurements consistent with the observer's Type 1 responses were used for fitting to ensure the calculated response probabilities were conditional on the discrimination choice. We used Bayesian Adaptive Direct Search (BADS) with the BADS toolbox , for the Type 2 model fits. Models were then compared in terms of their corrected Akaike information criterion (AICc) scores . Further details on the model fitting are provided in the Supplementary Materials. To confirm that the models are distinguishable for this experimental design, we performed a model recovery analysis. Using the MLE of the parameters, 10 data sets were simulated per observer per model. 1 Model fitting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Derivation of the posterior for the Bayesian ideal observer</head><p>Here we show the derivation of the posterior distribution presented in the main paper. Note that for the sake of space, we are using µ = µ cloud for the mean of the dot-sampling distribution, ⌧ = ⌧ cloud the precision of this distribution, and ⌧ c = ⌧ comb the combined precision.</p><p>Prior: The prior for the mean and precision of the dot-generation distribution can be defined as the following normal-Gamma distribution:</p><formula xml:id="formula_23">p(µ, ⌧ ) = N G(µ, ⌧ |µ 0 ,  0 , ↵ 0 , 0 ) = N (µ|µ 0 , ( 0 ⌧ ) 1 )G(⌧ |↵ 0 , 0 ) / ⌧ 1 2 exp ✓  0 ⌧ 2 (µ µ 0 ) 2 ◆ ⇥ ⌧ ↵ 0 1 exp( ⌧ 0 ).<label>(S1)</label></formula><p>The parameters µ 0 and  0 relate to the normal component, and ↵ 0 and 0 to the Gamma component.</p><p>Likelihood: The observer must consider two sources of uncertainty when choosing a likelihood function, the noisy draws of N dots from the dot-generation distribution and the measurement noise applied to each dot, 2 dot (precision: ⌧ dot ). These two noise sources are additive, resulting in the combined precision per dot of</p><formula xml:id="formula_24">⌧ c = 1 2 cloud + 2 dot = 1 ⌧ 1 + ⌧ 1 dot .<label>(S2)</label></formula><p>The observer must consider the information provided by all dot locations X (that are the horizontal component of physical dot locations D corrupted by measurement noise), resulting in the following likelihood function:</p><formula xml:id="formula_25">p(X|µ, ⌧, ⌧ dot ) = N Y i=1 p(x i |µ, ⌧ c ) = N Y i=1 1 (2⇡) 1 2 ⌧ 1 2 c exp ✓ ⌧ c 2 (x i µ) 2 ◆ / ⌧ N 2 c exp ✓ ⌧ c 2 N X i=1 (x i µ) 2 ◆ ,<label>(S3)</label></formula><p>where ⌧ c is defined in Eq. S2 and we assume the observer has accurate knowledge of 2 dot . Note that we have dropped the constant terms from the equation for simplicity as they can be applied by re-scaling the posterior.</p><p>Posterior: As we have used a conjugate prior, the posterior is also a normal gamma of the form</p><formula xml:id="formula_26">N G(µ, ⌧ |µ p ,  p , ↵ p , p , ⌧ dot )</formula><p>. However, to see this clearly, we decompose the posterior into three parts <ref type="bibr">(A, B, and C)</ref>.</p><formula xml:id="formula_27">p(µ, ⌧ |X, ⌧ dot ) / prior ⇥ likelihood / ⌧ 1 2 exp ✓  0 ⌧ 2 (µ µ 0 ) 2 ◆ ⌧ ↵ 0 1 exp( ⌧ 0 )⌧ N 2 c exp ✓ ⌧ c 2 N X i=1 (x i µ) 2 ◆ / A ⇥ B ⇥ C.<label>(S4)</label></formula><p>Part A is the non-exponent term of the normal component,</p><formula xml:id="formula_28">A = ⌧ 1 2 .<label>(S5)</label></formula><p>Part B is the non-exponentiated term of the Gamma component, which can be rearranged as follows</p><formula xml:id="formula_29">B = ⌧ ↵ 0 1 ⌧ N 2 c = ⌧ ↵ 0 1 ✓ ⌧ ⌧ 1 dot ⌧ + 1 ◆ N 2 = ⌧ ↵ 0 +N/2 1 exp ✓ N 2 log(⌧ 1 dot ⌧ + 1) ◆ .<label>(S6)</label></formula><p>The non-exponent part of B will be the non-exponent term of the Gamma component, and the remainder will be placed in Part C:</p><formula xml:id="formula_30">C = exp ✓  0 ⌧ 2 (µ µ 0 ) 2 ◆ exp( ⌧ 0 ) exp ✓ ⌧ c 2 N X i=1 (x i µ) 2 ◆ .<label>(S7)</label></formula><p>Thus, Part B becomes</p><formula xml:id="formula_31">B 0 = ⌧ ↵ 0 +N/2 1 = ⌧ ↵p 1 ,<label>(S8)</label></formula><p>with</p><formula xml:id="formula_32">↵ p = ↵ 0 + N/2,<label>(S9)</label></formula><p>and Part C, which now aggregates all the exponent terms, is</p><formula xml:id="formula_33">C = exp ✓  0 ⌧ (µ µ ) ◆ exp( ⌧ 0 ) exp ✓ ⌧ c 2 N X i=1 (x i µ) 2 ◆ exp ✓ N 2 log(⌧ dot ⌧ + 1) ◆ = exp ✓ 1   0 ⌧ (µ µ 0 ) 2 + ⌧ c N X i=1 (x i µ) 2 ⌧ N 2 log(⌧ 1 dot ⌧ + 1) ◆ = exp ✓ 1 2 D ⌧ 0 N 2 log(⌧ 1 dot ⌧ + 1) ◆ ,<label>(S10)</label></formula><p>which will contribute to both the normal and the Gamma components. Part D of this equation can be simplified, by extracting Part E as follows</p><formula xml:id="formula_34">D =  0 ⌧ (µ µ 0 ) 2 + ⌧ c N X i=1 (x i µ) 2 =  0 ⌧ (µ µ 0 ) 2 + N ⌧ c (µ x) 2 + ⌧ c N X i=1 (x i x) 2 = E + ⌧ c N X i=1 (x i x) 2 ,<label>(S11)</label></formula><p>given that</p><formula xml:id="formula_35">N X i=1 (x i µ) 2 = N X i=1 [(x i µ x +x)] 2 = N X i=1 (x µ) 2 + N X i=1 (x i x) 2 2 N X i=1 (x i x)(µ x) = N (x µ) 2 + N X i=1 (x i x) 2 ,<label>(S12)</label></formula><p>and</p><formula xml:id="formula_36">33 N X i=1 (x i x)(µ x) = (µ x) ✓ N X i=1 x i Nx ◆ = (µ x)(Nx Nx) = 0. (S13) E =  ⌧ (µ µ ) + N ⌧ c (µ x) 2 =  0 ⌧ (µ 2µµ 0 + µ 2 ) + N ⌧ c (µ 2 2µx +x 2 ) = µ 2 ( ⌧ + N ⌧ c ) 2µ( 0 ⌧ µ 0 + N ⌧ cx ) +  0 ⌧ µ 2 0 + N ⌧ cx 2 = ( 0 ⌧ + N ⌧ c )(µ µ p ) 2 +  0 ⌧ µ 2 0 + N ⌧ cx 2 ( 0 ⌧ µ 0 + N ⌧ cx ) 2  0 ⌧ + N ⌧ c = ( 0 ⌧ + N ⌧ c )(µ µ p ) 2 +  0 ⌧ µ 2 0 ( 0 ⌧ + N ⌧ c ) + N ⌧ cx 2 ( 0 ⌧ + N ⌧ c ) ( 0 ⌧ µ 0 + N ⌧ cx ) 2  0 ⌧ + N ⌧ c = ( 0 ⌧ + N ⌧ c )(µ µ p ) 2 +  0 N ⌧ ⌧ c (x µ 0 ) 2  0 ⌧ + N ⌧ c ,<label>(S14)</label></formula><p>where</p><formula xml:id="formula_37">µ p =  0 ⌧ µ 0 + N ⌧ cx  0 ⌧ + N ⌧ c .<label>(S15)</label></formula><p>Thus, Part D can be written as</p><formula xml:id="formula_38">D = ( 0 ⌧ + N ⌧ c )(µ µ p ) 2 +  0 N ⌧ ⌧ c (x µ 0 ) 2  0 ⌧ + N ⌧ c + ⌧ c N X i=1 (x i x) 2 ,<label>(S16)</label></formula><p>and we can now express Part C 0 in terms of two components, C 1 and C 2 ,</p><formula xml:id="formula_39">C 0 = exp ✓ 1 2 D ⌧ 0 N 2 log(⌧ 1 dot ⌧ + 1) ◆ = exp ✓ 1 2 ( 0 ⌧ + N ⌧ c )(µ µ p ) 2 ◆ ⇥ exp ✓ ⌧ 0  0 N ⌧ ⌧ c (x µ 0 ) 2 2( 0 ⌧ + N ⌧ c ) ⌧ c 2 N X i=1 (x i x) 2 N 2 log(⌧ 1 dot ⌧ + 1) ◆ = C 1 ⇥ C 2 ,<label>(S17)</label></formula><p>which contribute to the normal component and the Gamma component respectively. To see this, we must arrange Part C as follows</p><formula xml:id="formula_40">C 1 = exp ✓ 2 ( ⌧ + N ⌧ c )(µ µ p ) 2 ◆ = exp ✓ ⌧ ( 0 ⌧ + N ⌧ c ) 2⌧ (µ µ p ) 2 ◆ = exp ✓  p ⌧ 2 (µ µ p ) 2 ◆ ,<label>(S18)</label></formula><p>where</p><formula xml:id="formula_41"> p =  0 ⌧ + N ⌧ c ⌧ .<label>(S19)</label></formula><p>Similarly, for Part C 2 ,</p><formula xml:id="formula_42">C 2 = exp ✓ ⌧ 0  0 N ⌧ ⌧ c (x µ 0 ) 2 2( 0 ⌧ + N ⌧ c ) ⌧ c 2 N X i=1 (x i x) 2 N 2 log(⌧ 1 dot ⌧ + 1) ◆ = exp ✓ ⌧  0 +  0 N ⌧ ⌧ c (x µ 0 ) 2 2⌧ ( 0 ⌧ + N ⌧ c ) + ⌧ c 2⌧ N X i=1 (x i x) 2 + N 2⌧ log(⌧ 1 dot ⌧ + 1) ◆ = exp ✓ ⌧  0 + N 2⌧ ✓  0 ⌧ ⌧ c (x µ 0 ) 2  0 ⌧ + N ⌧ c + ⌧ c s 2 + log(⌧ 1 dot ⌧ + 1) ◆ ◆ = exp( ⌧ p ),<label>(S20)</label></formula><p>where</p><formula xml:id="formula_43">p = 0 + N 2⌧ ✓  0 ⌧ ⌧ c (x µ 0 ) 2  0 ⌧ + N ⌧ c + ⌧ c s 2 + log(⌧ 1 dot ⌧ + 1) ◆ ,<label>(S21)</label></formula><p>and s 2 is the sample variance</p><formula xml:id="formula_44">s 2 = 1 N N X i=1 (x i x) 2 .<label>(S22)</label></formula><p>To see how this is a normal-Gamma we reassemble</p><formula xml:id="formula_45">p(µ, ⌧ |X, ⌧ dot ) / AC 1 ⇥ B 0 C 2 / ⌧ 1 2 exp ✓  p ⌧ 2 (µ µ p ) 2 ◆ ⇥ ⌧ ↵p 1 exp( ⌧ p ) / N G(µ, ⌧ |µ p ,  p , ↵ p , p ).<label>(S23)</label></formula><p>Validation: We can check this derivation against the simpler case of p(µ, ⌧ |D), which has been documented previously in the literature . The important distinction between these derivations is that there is no additive noise per dot in the likelihood for p(µ, ⌧ |D), with the consequence that ⌧ c = ⌧ . In this case, the parameters of the posterior simplify as follows:</p><formula xml:id="formula_46">µ p =  0 ⌧ µ + N ⌧ cx  ⌧ + N ⌧ c =  0 µ 0 + Nx  0 + N ,<label>(S24)</label></formula><formula xml:id="formula_47"> p =  0 ⌧ + N ⌧ c ⌧ =  0 + N,<label>(S25)</label></formula><formula xml:id="formula_48">↵ p = ↵ 0 + N/2,<label>(S26)</label></formula><p>and</p><formula xml:id="formula_49">p = 0 + N 2⌧ ✓  0 ⌧ ⌧ c (x µ 0 ) 2  0 ⌧ + N ⌧ c + ⌧ c s + log(⌧ 1 dot ⌧ + 1) ◆ = 0 +  0 N (x µ 0 ) 2 2( 0 + N ) + Ns 2 2 .<label>(S27)</label></formula><p>These parameter equations match those reported in the derivation of p(µ, ⌧ |D) in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Selecting the prior distribution parameters</head><p>We adjusted the parameters of the normal-Gamma prior (µ 0 ,  0 , ↵ 0 , and 0 ) to the true stimulus statistics of the dots mean µ and precision ⌧ in the experiment. The possible centre locations of the dots were -4, -2, -1, 0, 1, 2, or 4 deg, and the possible standard deviations of the dots spreads were 1.5, 2, or 2.5 deg. Therefore, the statistics of the mean and precision were E We matched the marginal distributions of the mean and precision variables to these statistics. The marginal distribution of the precision ⌧ variable is the Gamma distribution with parameters (↵ 0 , 0 ).</p><p>The mean and variance of this distribution are</p><formula xml:id="formula_50">E[⌧ ] = ↵ 0 0 ,<label>(S28)</label></formula><formula xml:id="formula_51">Var[⌧ ] = ↵ 0 2 0 .<label>(S29)</label></formula><p>The marginal distribution of the mean µ variable is the non-standardized Student's t-distribution with parameters (⌫ 0 , µ 0 , 2 0 ) = (2↵ 0 , µ 0 , 0 /( 0 ↵ 0 )). The mean and variance of this distribution are</p><formula xml:id="formula_52">E[µ] = µ 0 ,<label>(S30)</label></formula><formula xml:id="formula_53">Var[µ] = ⌫ 0 ⌫ 0 2 =  ↵ 0 2↵ 0 2↵ =  0 (↵ 0 1) . (S31)</formula><p>The match of these marginal statistics results in the following prior distribution parameters 1.3 Computing the standard deviation of the marginal posterior distribution for the Scaled-Distance models</p><formula xml:id="formula_54">µ 0 = E[µ] = 0,<label>(S32)</label></formula><formula xml:id="formula_55"> = E[⌧ ] Var[µ](E[⌧ ] Var[⌧ ]) = 0.68,<label>(S33)</label></formula><formula xml:id="formula_56">↵ 0 = E[⌧ ] 2 Var[⌧ ] = 3.84,<label>(S34)</label></formula><p>The Scaled-Distance models normalised the distance-From-Criterion (DFC) of the posterior mode,μ, by the standard deviation of the marginal posterior distribution,ˆ , for each interval. We calculated the scaled DFC in the model fitting procedure using an inverse cumulative normal function approximation.</p><formula xml:id="formula_57">DFC scaled = |μ k 1 + ✏| ⇡ | inv p(C = R|X, k 1 ) + ✏|.<label>(S36)</label></formula><p>Note the additive confidence noise, ✏ ⇠ N (0, 2 conf ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Model-fitting procedure</head><p>Type 1 models. Type 1 models were fit first, with dot , k 1 , and as free parameters. Models were fit on a per-participant basis with custom MATLAB scripts that calculated the likelihood of the model for specific parameter combinations in a dense grid of parameter values ( dot : 0.1 to 2 deg in 50 log-spaced steps; k 1 : -1 to 1 deg in 20 steps; : 0.01 to 0.1 in 9 steps). Choice probabilities for each parameter combination were estimated by simulation. For each trial, 1000 observations were simulated, with choice probabilities estimated by computing the proportion of rightward choices made by the simulated observer. This involved constructing the prior, likelihood, and posterior distributions shown in <ref type="figure">Figure 6A</ref> of the main paper (grid resolution: µ: -10 to 10 in 200 steps; ⌧ : 0.01 to 1.00 in 100 steps).</p><p>After marginalising the posterior distribution across the ⌧ dimension, the choice probabilities could be calculated using k 1 and . Because this was a computationally expensive simulation, the simulated noisy observations and construction of the prior, likelihood, and posterior grids was done only once per level of dot (for each trial and for each participant). Thus di↵erences in choice probabilities from k 1 and were calculated using the same noisy simulations of the trial. Not taking this approach would have increased the time to fit a single Type 1 model for an observer from hours to days or weeks. Choice probabilities were then put into a Bernoulli model of binary choice behaviour with the participant's actual responses to calculate the likelihood of that specific parameter combination.</p><p>Finally, the best-fitting parameters were extracted from the 3D parameter grid by finding combination that gave the largest the maximum likelihood value. Averages of the best-fitting parameter values are given in <ref type="table" target="#tab_3">Table S1</ref>.</p><p>Type 2 models. The Type 2 models were fit using the same simulation-based approach combined with Bayesian Adaptive Direct Search (BADS;  to find the best-fitting combination of parameters. The number of parameters in the Type 2 model fits depended on the model. The Ideal-Confidence-Observer model had no free parameters, the Heuristic model had 4 free parameters</p><formula xml:id="formula_58">( 1 , 2 , conf , k 2 )</formula><p>, and the remaining models had two free parameters (⌫ or conf , k 2 ). The Type 1 parameters were fixed at their best-fitting values on a per-participant basis and the Type 1 model was matched to the Type 2 model in terms of whether the flat-or centred-prior variant was used because the location of a biased k 1 can di↵er between the variants.</p><p>The first step in Type 2 model fits was simulating the observer. For each participant, we simulated 3000 noisy observations of each trial, and computed the marginalised posterior distribution using the same µ-⌧ grid spacing as in the Type 1 model-fitting procedure. For each simulation, we computed p(C = R|X, k 1 ) of Eq. 12 as well as the mode of the posterior distribution according to the prior variants of the Type 1 models. Each simulation was then coded as favouring a leftward or rightward Type 1 response. We sampled with replacement from the simulations that matched the Type 1 response given by the participant to ensure the simulated observer matched the actual observer in Type 1 choice behaviour. If all simulations were choice-consistent for a given trial we did not perform this sampling step. If no samples were choice-consistent, the trial was flagged as a likely lapse for later processing. Due to the mostly low di culty of the task, the majority of samples usually favoured the same response and it was rare for the sampling to be drawn from a small number of simulations. This simulation procedure was performed only once per trial and observer and used for the fitting of all Type 2 models.</p><p>In the second step, we fit each of the Type 2 models with the set of choice-consistent simulations using BADS. We considered the relative evidence for the Type response given by the observer in each interval, according to the Type model. Likely lapses were given the lowest confidence value possible with a tiny amount of jitter so the confidence report for comparing two lapses is entirely random.</p><p>Thus, we were able to compute the choice probabilities for selecting "Interval 1" and "Interval 2" from the simulated observer. These were compared with the actual confidence forced-choice report of the participant in a Bernoulli model of binary choice behaviour. As choice probabilities were computed by simulation, we used the "uncertainty handling" option in the BADS package and drew 100 final samples to compute the estimate of the negative log-likelihood value of the model for the model comparison.</p><p>The lower bound, upper bound, plausible lower bound, plausible upper bound, and starting location settings for each model can be found in the fitType2.m file available at https://osf.io/k2nhq/.</p><p>Averages of the best-fitting parameter values per Type 2 model are given in <ref type="table" target="#tab_3">Table S1</ref>.   <ref type="figure">Figure S1</ref>: Parameter recovery results for conf (blue) and k 2 (red). Model and prior variant indicated by title. Data points are the mean values and error bars are ±1 SD calculated from the fits of the 10 simulated data sets per observer per model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Parameter recovery</head><p>To confirm that the model-fitting procedure was behaving correctly, we assessed whether refit models in the model-recovery analysis recovered the simulated parameters. <ref type="figure">Figure S1</ref> shows that the confidence noise and bias terms were recovered well in almost all instances. The exception was the confidence-noise parameter for the Basic-Probability model, where the magnitude of the noise was often overestimated.</p><p>We investigated this further and found that the Beta noise distribution was little changed for di↵erent confidence noise values for extreme probability values (i.e., close to 0 or 1). Thus, the design of the experiment likely a↵ected the ability to fit this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Additional results</head><p>2.1 Preliminary logistic analysis to confirm that quantity and quality manipulations a↵ected confidence</p><p>We examined whether the evidence quantity and quality manipulations a↵ected confidence judgements. Observers could have ignored the sensory-uncertainty manipulations, and simply reported whichever interval had the more extreme leftward or rightward stimulus as more confident (the Basic model). Alternatively, the observer may modulate their confidence by information quantity and/or quality: increasing confidence if there were 5 dots or smaller spread, and decreasing it for 2 dots or larger spread. We considered these four possibilities (Basic, only quantity, only quality, and both) in a nested model comparison. It is reasonable to suspect that the observer inferred the mean and spread from the displayed dots, so we repeated the analysis for both the true mean and spread of the generating distribution and the empirical mean and spread values according to the dots displayed. If decision correctness is examined, observer reports better match the empirical mean of the dots (i.e., the centroid) as opposed to the mean of generating distribution ( <ref type="figure">Figure S2A</ref>).</p><p>All models for the preliminary analysis were a logistic function of the probability of choosing</p><p>Interval 2 as more confident, p(choose I 2 ) = + (1 2 )Logit(✓),</p><p>with the predicted probabilities scaled according to the lapse rate, (0.01   0.15). Here lapse rate is the rate of unintentionally giving the opposite decision than desired. The Full model had three predictors related to the distance of the stimuli from the screen centre, the number of dots, and the AICc scores explicitly penalise the number of parameters in a model and correct for sample size.</p><p>We also repeated this nested analysis using a restricted dataset of only trial pairs where both Type 1 judgements were correct. The purpose of this analysis was to reduce the probability that lapse discrimination responses were included, because the logistic regression did not consider Type 1 performance in the confidence report. The pattern of model fits, however, did not change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Results of model variants</head><p>The base model assumed that the likelihood function was calculated from the horizontal locations of the noisy dot measurements. In the centred-prior variant, the prior distribution was a normal-Gamma distribution matched to the stimulus statistics. These modelling choices were investigated by checking whether the main experimental results were robust to changes in this general base model.</p><p>Uniform prior on the three precision levels. In this analysis, we changed the joint meanprecision prior of the centred-prior to reflect that the observer had perfect knowledge of the three levels of distribution spread used in the experiment. On an individual trial, the observer considered the prior probability of the precision as uniform across these three levels. The prior probability of the mean was matched to the stimulus statistics, N (0, 7), for the centred-prior variant. The winning model remained the Heuristic model, with the number best fit for this model unchanged ( <ref type="figure" target="#fig_3">Figure S3A</ref>).</p><p>However, the number of observers best-fit by the Probability-Di↵erence model increased by 2, and the number of observers best-fit with a posterior variant doubled from 3 to 6. Note that the flat-prior variant results are unchanged in this analysis, so changes of the best-fitting model were a result of the centred-prior variants fitting better or worse.</p><p>Empirical spread from Euclidean distance. Here we included the vertical spread of the dots.</p><p>The vertical position of the generating distribution mean was always the half-height of the screen. Yet, the distance of the dots from this half-height reference also give an indication of the true spread of the circular-symmetric Gaussian generating distribution. The Heuristic model remained the overall winner of the model comparison ( <ref type="figure" target="#fig_3">Figure S3B</ref>). However, now the Scaled-Distance model has the slightly more observers best fit compared to the Heuristic model. We do not consider this a significant departure from the results reported in the main article.  <ref type="figure" target="#fig_3">Figure S3</ref>: Type 2 model-comparison results when the form of the general base model was changed. A) Models with a uniform prior on ⌧ instead of the normal-Gamma prior. We assume here that the observer has perfect knowledge of the three levels of dot spread and implements a prior that gives equal weight to each of the three corresponding ⌧ values. Bars: average relative AICc score. Markers: Individual participant results. Colour: flat-prior (orange) or centred-prior (blue) variant. Heuristic model has no prior. B) Models with the empirical spread computed from Euclidean distance instead of horizontal distance. Both the horizontal and vertical position of the dot are used in the standard deviation calculation. Error bars: ±SEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Examining the Heuristic-model coe cients from the simulated datasets</head><p>To better understand the relationship between the best-fitting coe cients from the Heuristic model and the best-fitting model for each observer ( <ref type="figure" target="#fig_5">Figure S4A</ref>), we examined the fits of the model simulations from the model-recovery analysis. In particular, there appeared to be some clustering of coe cient values based on the model type for the non-heuristic models. The model simulations, based on all observers, confirmed this clustering ( <ref type="figure" target="#fig_5">Figure S4B</ref>). It also showed a large spread in the coe cients for the Heuristic model simulations, consistent with the fits to the human data. A similar spread was observed for the Ideal-Confidence-Observer model simulations ( <ref type="figure" target="#fig_5">Figure S4C)</ref>, and a small spread for the Basic-Probability models simulations. The simulated Unscaled-Distance model coe cients are near 0, consistent with these models having little to no influence of information quantity or quality on confidence, for the flat-and centred-prior variants respectively.  <ref type="figure" target="#fig_5">Figure S4</ref>: Comparing the Heuristic-model fit for the behaviour of observers against the Heuristicmodel fit for the model simulations. A) Replotting of observer fits from <ref type="figure" target="#fig_7">Figure 5D</ref>. Each datapoint is a single observer, coloured according to the best-fitting model (note change in colour scheme). Prior variants are flat (F) or centred (C). B) Same as in A for the simulations of the selected models. Each datapoint is the fit from a single model simulation (10 simulations per observer; best-fitting parameters used). C) The best-fitting Heuristic-model coe cients for each of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Confidence agreement behaviour and model predictions</head><p>The confidence agreement behaviour of all observers, and their corresponding model predictions according to their best-fitting parameters are shown in <ref type="figure" target="#fig_7">Figure S5</ref>. The pattern of results reveals the tendency of the observer to be more consistent than their best-fitting model would predict. <ref type="figure" target="#fig_7">Figure S5</ref>: The 5-pass confidence agreement of all observers with the predicted confidence agreement of each model. Model predictions were calculated from 100 simulated datasets using the participantspecific best-fitting parameters. Error bars: ±2 SD. For all observers, the Ideal-Confidence-Observer model had the highest confidence agreement, then the Basic-Probability model, then the remaining models. Red: confidence agreement of the observer. Green: predicted confidence agreement according to the best-fitting model for that observer. Black: predictions of the other models. Note that di↵erent observers had di↵erent maximum agreement counts depending on the number of repeated blocks ( <ref type="figure">Figure 1B</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Confidence manipulation checks. A) Supra-threshold Type 1 task performance. The mean proportion of correct spatial judgements across observers is shown for di↵erent trial categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Model fit results (n = 16). A) Relative AICc scores for the Type 1 models. Scores were compared to the winning flat-prior variant models. Bars: average relative AICc score. Markers: Individual participant results. Colour: flat-prior (orange) or centred-prior (blue) variant. B) Relative</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Same N dots (N1 = N2)Di↵. N dots (N1 = 2, N2 = 5)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Confidence agreement results (n = 15). Confidence agreement was calculated per trial as the proportion of the most-selected confidence choice for the participants who did a 3-, 4-, or 5-pass version of the experiment (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>computation of the posterior mode in the centred-prior variants of the Unscaled-and Scaled-Distance models must also involve a Bayesian computation. This is ambiguous in the case of the flat-prior variants of Unscaled-and Scaled-Distance models, because these models are identical to a model that uses the point estimate from the un-normalised likelihood function. The important distinction made by the Bayesian Confidence Hypothesis is whether the metacognitive system has access to and makes use of the full posterior distribution for reporting confidence and our results are inconclusive in this regard.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>[µ] = 0, Var[µ] = 7, E[⌧ ] = 0.2848, and Var[⌧ ] = 0.0211.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Summary of the seven base models. Models spanned all three metric types and considered di↵erent implementations of confidence noise, prior distributions, and confidence-variable transformations. Standard unbiased Gaussian confidence noise is used unless noted otherwise. There are twelve distinct models for comparison when including the prior variants.</figDesc><table><row><cell>Model</cell><cell>Type</cell><cell>Description</cell></row><row><cell>Ideal Conf. Observer</cell><cell cols="2">Probability Compares the p(correct) for each decision, computed from the posterior distribution. Only</cell></row><row><cell></cell><cell></cell><cell>the centred-prior variant considered for this model.</cell></row><row><cell>Basic Probability</cell><cell cols="2">Probability Compares the p(correct), but with early confidence noise (beta, constrained [0, 1]) applied</cell></row><row><cell></cell><cell></cell><cell>before the comparison, interval bias, and two prior variants considered (flat &amp; centred).</cell></row><row><cell cols="3">Probability Di↵erence Probability Compares the p(correct), but with late confidence noise applied after the comparison, inter-</cell></row><row><cell></cell><cell></cell><cell>val bias, and two prior variants considered (flat &amp; centred).</cell></row><row><cell cols="3">Log Probability Ratio Probability Compares the p(correct), but with a LPR transformation applied, confidence noise, interval</cell></row><row><cell></cell><cell></cell><cell>bias, and two prior variants considered (flat &amp; centred).</cell></row><row><cell>Unscaled Distance</cell><cell>Evidence</cell><cell>Compares the DFC of point-estimates of the Type 1 decision process, with confidence noise</cell></row><row><cell></cell><cell>Strength</cell><cell>and interval bias. Two prior variants considered (flat &amp; centred).</cell></row><row><cell>Scaled Distance</cell><cell>Evidence</cell><cell>Compares the DFC of SNR-scaled point-estimates of the Type 1 decision process, with</cell></row><row><cell></cell><cell>Strength</cell><cell>confidence noise and interval bias. Two prior variants considered (flat &amp; centred).</cell></row><row><cell>Heuristic</cell><cell>Heuristic</cell><cell>Compares a weighted sum of the estimated di↵erence in stimulus strength and estimate</cell></row><row><cell></cell><cell></cell><cell>di↵erence in sensory-uncertainty factors, with late confidence noise and interval bias.</cell></row><row><cell cols="3">evidence strength was scaled by the sensory uncertainty. Together, our results indicate observers were</cell></row><row><cell cols="3">unlikely to compute full probability distributions for confidence and that they might rely on stimulus-</cell></row><row><cell cols="3">based heuristic cues if available. For confidence agreement, the best-fitting model, on a per-participant</cell></row><row><cell cols="3">basis, almost always underestimated the observers' confidence agreement. This finding suggests there</cell></row><row><cell cols="3">is still room for improvement in the modelling of perceptual confidence.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table S1 :</head><label>S1</label><figDesc>Summary of best-fitting parameters per model. Type 1 model fits were near identical, so parameter values were averaged across the four models for each observer before computing the parameter averages across observers. Type 2 models are detailed individually. Where relevant, the parameters from fits of the flat-and centred-prior variants are both reported.</figDesc><table><row><cell>3</cell><cell>4</cell><cell></cell></row><row><cell></cell><cell>Model</cell><cell>Parameter</cell><cell>Mean±SEM</cell></row><row><cell cols="2">All Type 1 (averaged)</cell><cell>dot</cell><cell>0.97 ± 0.04</cell></row><row><cell></cell><cell></cell><cell>k 1</cell><cell>0.01 ± 0.03</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.02±0.002</cell></row><row><cell cols="2">Ideal Confidence Observer</cell><cell>none</cell><cell>none</cell></row><row><cell></cell><cell>Basic Probability</cell><cell>⌫ conf</cell><cell>6.30±1.24; 4.91±0.90</cell></row><row><cell></cell><cell></cell><cell>k 2</cell><cell>0.001±0.001; 0.001±0.001</cell></row><row><cell cols="2">Probability Di↵erence</cell><cell>conf</cell><cell>0.19±0.03; 0.21±0.03</cell></row><row><cell></cell><cell></cell><cell>k 2</cell><cell>0.02±0.01; 0.02±0.01</cell></row><row><cell cols="2">Log Probability Ratio</cell><cell>conf</cell><cell>2.29±0.29; 2.15±0.28</cell></row><row><cell></cell><cell></cell><cell>k 2</cell><cell>0.11±0.16; 0.09±0.14</cell></row><row><cell></cell><cell>Unscaled Distance</cell><cell>conf</cell><cell>2.08 ± 0.18 ; 1.42 ± 0.12</cell></row><row><cell></cell><cell></cell><cell>k 2</cell><cell>0.04 ± 0.11 ; 0.03 ± 0.08</cell></row><row><cell></cell><cell>Scaled Distance</cell><cell>conf</cell><cell>0.98±0.11 sd; 0.94±0.11 sd</cell></row><row><cell></cell><cell></cell><cell>k 2</cell><cell>0.05±0.07 sd; 0.04±0.06 sd</cell></row><row><cell></cell><cell>Heuristic</cell><cell>conf</cell><cell>1.12±0.17</cell></row><row><cell></cell><cell></cell><cell>k 2</cell><cell>0.13±0.08</cell></row><row><cell></cell><cell></cell><cell>1 (quantity)</cell><cell>0.68±0.10</cell></row><row><cell></cell><cell></cell><cell>2 (quality)</cell><cell>0.38±0.09</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Completing the square: ax 2 + bx + c = a(x + d) 2 + e, where d = b/2a and e = c b 2 /4a.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Wei Ji Ma for helpful early discussions on data analysis and Damaris Beutel for her help in collecting the research data. This work was supported by NIH Grant EY08266 (MSL, SML) and National Science Foundation Collaborative Research in Computational Neuroscience Grant 1420262, an Anneliese Maier Award from the Alexander von Humboldt Foundation (PM, SML), a post-doctoral fellowship from the Fyssen Foundation (SML), as well as the French ANR grants ANR-18-CE28-0015-01"VICONTE" and ANR-17-EURE-0017 "FrontCog" (PM, SML).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author note</head><p>Individual author contributions are presented using the CRediT taxonomy (see https://www.casrai. dot spreads in each interval:</p><p>The constant term, 0 , is the confidence bias for choosing Interval 2 and was included in all models.</p><p>The relative distance of the stimuli was parameterised as the relative absolute distance of the dot centroids from the screen centre, |µ|, and was also included in all models. The relative number of dots, N dots , and the inverse of the spreads, 1/ cloud , were optional predictors in the nested models.</p><p>The Basic model did not consider the evidence quantity or quality manipulations when computing confidence,</p><p>Compared to the Basic model, the +Quantity model that included the dot-number predictor ( 2 ) and the +Quality model that included the dot-spread predictor ( 3 ) provided a better fit to the data, with the +Quantity model fitting better than the +Quality model ( <ref type="figure">Figure S2B</ref>). This was true both if the generating distribution spread was used or if the empirical spread was used (i.e., based on the displayed dots). The empirical version did fit slightly better overall.</p><p>The models were fit with custom MATLAB scripts that calculated the maximum-likelihood estimates of the parameters using gradient decent. Corrected Akaike information criterion (AICc) scores   emp. <ref type="figure">Figure S2</ref>: Preliminary results. A) Type 1 judgements. Task performance when decision correctness is scored against the true mean of the generating distribution (pink) versus the empirical mean of the dot cloud (purple). B) Type 2 Logistic regression results. Model fit is compared against the winning model: the Full model with empirical spread. Grey: models without the quality predictor. Pink: models with a quality predictor based on the true generating distribution spread. Purple: quality predictor based on the empirical spread. All error bars: ±SEM.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Practical Bayesian optimization for model fitting with Bayesian Adaptive Direct Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Acerbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1834" to="1844" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Comparing Bayesian and non-Bayesian accounts of human confidence reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1006572</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Individual consistency in the accuracy and distribution of confidence judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barttfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="377" to="386" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Doubly bayesian analysis of confidence in perceptual decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Aitchison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1004519</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A New Look at the Statistical Model Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Confidence controls perceptual evidence accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Balsdon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sensory noise increases meta-cognitive e ciency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="437" to="452" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Measures of metacognition on signal-detection theoretic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dienes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Seth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="535" to="552" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Flexible mechanisms underlie the evaluation of visual confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barthelmé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="20834" to="20839" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dual strategies in human confidence judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bertana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chetverikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Van Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Jehee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="21" to="21" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The impact of evidence reliability on sensitivity and bias in decision confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>De Gardelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1520" to="1531" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Psychophysics Toolbox</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visual signal detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Colborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">iv. observer inconsistency. JOSA A</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="617" to="627" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unifying the derivations for the Akaike and corrected Akaike information criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Cavanaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics &amp; Probability Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="208" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evidence for metacognitive bias in perception of voluntary action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haggard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page">104041</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Two types of ROC curves and definitions of parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Birdsall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Tanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="629" to="630" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Weighting mean and variability during confidence judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>De Gardelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">120870</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Humans incorporate attentiondependent uncertainty into perceptual decisions and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Denison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carrasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">43</biblScope>
			<biblScope unit="page" from="11090" to="11095" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Self-evaluation of decision-making: A general Bayesian framework for metacognitive computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="114" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How to measure metacognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">443</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relating introspective accuracy to individual di↵erences in brain structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rees</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="issue">5998</biblScope>
			<biblScope unit="page" from="1541" to="1543" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Prospect theory and the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A P W</forename><surname>Poldrack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neuroeconomics: Decision Making and the Brain</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="145" to="173" />
		</imprint>
	</monogr>
	<note>Glimcher,</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frömer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stürmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yeung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Response-based outcome predictions and confidence regulate feedback processing and learning</title>
		<imprint>
			<publisher>Elife</publisher>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">62825</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Type 2 tasks in the theory of signal detectability: Discrimination between correct and incorrect decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Galvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Podd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Drga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Whitmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="843" to="876" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Optimality and heuristics in perceptual neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="514" to="523" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Heuristic decision making. Annual review of psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="451" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The neural basis of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="535" to="574" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Failure to handle more than one internal representation in visual detection tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gorea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="12380" to="12384" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The spatial and temporal construction of confidence in the visual scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Graziano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4909</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Estimation of internal noise using double passes: Does it matter how the second pass is delivered? Vision research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A S</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Joosten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Neri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Prospect theory: An analysis of decision under risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="263" to="291" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Choice certainty is informed by both evidence and decision time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Corthell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1329" to="1342" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">What&apos;s new in psychtoolbox-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brainard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ingling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Broussard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ideal-observer models of cue integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Landy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Knill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sensory cue integration</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="5" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Confidence reports in decision-making with multiple alternatives violate the bayesian confidence hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The receptive field and internal noise for position acuity change with feature separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Levi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2" to="2" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discrete confidence levels revealed by sequential decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mongillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dekker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gorea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="280" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Priors and payo↵s in confidence judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Locke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ga N-Cahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hosseinizaveh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Landy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3158" to="3175" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Performance monitoring for sensorimotor confidence: A visuomotor tracking study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Locke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Landy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">205</biblScope>
			<biblScope unit="page">104396</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Organizing probabilistic models of perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="511" to="518" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Detection Theory: A User&apos;s Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Macmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Creelman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Lawrence Erlbaum Associates, Inc</publisher>
			<pubPlace>Mahwah, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Visual confidence. Annual Review of Vision Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="459" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Confidence forced-choice and other metaperceptual tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="616" to="635" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Modeling perceptual confidence and the confidence forcedchoice paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>De Gardelle</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000312</idno>
		<ptr target="https://doi.org/10.1037/rev0000312" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The signal processing architecture underlying subjective reports of sensory awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Neuroscience of Consciousness</publisher>
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="422" to="430" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Heuristic use of perceptual evidence leads to dissociation between performance and metacognitive sensitivity. Attention, Perception, and Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="923" to="937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The sense of confidence during probabilistic learning: A normative account</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meyniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schlunegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1004305</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Metacognitive judgements of perceptual-motor steering performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Mole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jersakova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Kountouriotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J A</forename><surname>Moulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Wilkie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2223" to="2234" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Conjugate Bayesian analysis of the Gaussian distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<ptr target="https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The idiosyncratic nature of confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Navajas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hindocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Foda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keramati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature human behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="810" to="818" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Inferring subjective states through the observation of actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Kilner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">279</biblScope>
			<biblScope unit="page" from="4853" to="4860" />
			<date type="published" when="1748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On small di↵erences in sensation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Peirce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jastrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memoirs of the National Academy of Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="73" to="83" />
			<date type="published" when="1884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The Video Toolbox software for visual psychophysics: Transforming numbers into movies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Pelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="437" to="442" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Two-stage dynamic signal detection: A theory of choice, decision time, and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="864" to="901" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Probabilistic brains: knowns and unknowns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1170" to="1178" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Confidence and certainty: Distinct probabilistic quantities for di↵erent goals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kepecs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="366" to="374" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A robust confidence-accuracy dissociation via criterion attraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience of Consciousness</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Suboptimality in perceptual decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Denison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">223</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Consensus goals for the field of visual metacognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<ptr target="https://psyarxiv.com/z8v5x" />
	</analytic>
	<monogr>
		<title level="j">Psyarxiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Confidence leak in perceptual decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koizumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Y</forename><surname>Mccurdy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1664" to="1680" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Attention induces conservative subjective biases in visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1513" to="1515" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Signatures of a statistical computation in the human sense of confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hangya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kepecs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="499" to="506" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The nature of metacognitive ine ciency in perceptual decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="70" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Computations underlying confidence in visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Dux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="671" to="682" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Confidence is the bridge between multi-stage decisions</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3157" to="3168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Decision processes in visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vickers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Academic Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Human representation of visuo-motor uncertainty as mixtures of orthogonal basis distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Maloney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1152" to="1158" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Ubiquitous log odds: a common representation of probability and frequency distortion in perception, action, and cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Maloney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The construction of confidence in a perceptual decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barttfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Integrative Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The influence of evidence volatility on choice, reaction time and confidence in a perceptual decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Fetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">17688</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Variance misperception explains illusions of confidence in simple perceptual decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="246" to="253" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Practical Bayesian optimization for model fitting with Bayesian Adaptive Direct Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Acerbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1834" to="1844" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A New Look at the Statistical Model Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Unifying the derivations for the Akaike and corrected Akaike information criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Cavanaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics &amp; Probability Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="208" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Conjugate Bayesian analysis of the Gaussian distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<ptr target="https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
