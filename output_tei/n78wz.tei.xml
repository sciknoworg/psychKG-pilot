<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Revisiting the connection between Luce&apos;s Choice Axiom and Signal Detection Theory: Application to visual memory</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">M</forename><surname>Robinson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabella</forename><forename type="middle">C</forename><surname>Destefano</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Vul</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Revisiting the connection between Luce&apos;s Choice Axiom and Signal Detection Theory: Application to visual memory</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In many decision tasks, we have a set of alternative choices and are faced with the problem of how to use our latent beliefs and preferences about each alternative to make a single choice. Cognitive and decision models typically presume that beliefs and preferences are distilled to a scalar latent strength for each alternative, but it is also critical to model how people use these latent strengths to choose a single alternative. Most models follow one of two traditions to establish this link. Modern psychophysics and memory researchers make use of signal detection theory, assuming that latent strengths are perturbed by noise, and the highest resulting signal is selected. By contrast, many modern decision theoretic modeling and machine learning approaches use the softmax function (which is based on Luce&apos;s choice axiom; Luce, 1959) to give some weight to non-maximal-strength alternatives. Despite the prominence of these two theories of choice, current approaches rarely address the connection between them, and the choice of one or the other appears more motivated by the tradition in the relevant literature than by theoretical or empirical reasons to prefer one theory to the other. The goal of the current work is to revisit this topic by elucidating which of these two models provides a better characterization of latent processes in m-alternative decision tasks, with a particular focus on memory tasks. In a set of visual memory experiments, we show that, within the same experimental design, the softmax parameter β varies across m-alternatives, whereas the parameter d ′ of the signal-detection model is stable. Together, our findings indicate that replacing softmax with signal-detection link models would yield more generalizable predictions across changes in task structure. More ambitiously, the invariance of signal detection model parameters across different tasks suggests that the parametric assumptions of these models may be more than just a mathematical convenience, but reflect something real about human decision-making.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>We make choices in virtually every real-world and laboratory task. For example, we decide which item is 'old' in a forced-choice memory study, which cereal we prefer in a supermarket, or which color a word is in a Stroop task. Because decision processes are so prevalent, there is great value in determining the type of quantitative model that best captures them. In this article, we focus on two prominent probabilistic models of choice: signal detection theory (SDT) -a model based on Thurstone's law of comparative judgement <ref type="bibr" target="#b28">(Thurstone, 1927)</ref>, which is commonly instantiated as a Gaussian signal detection model (e.g., <ref type="bibr" target="#b32">Wixted, 2020)</ref>, and Luce's choice axiom (LCA) <ref type="bibr" target="#b13">(Luce, 1959)</ref>, of which the wellknown softmax model is a widely used extension (e.g., <ref type="bibr" target="#b3">Bridle, 1990</ref>).</p><p>We focus on these two models because they are prominent in different domains, such as memory and decision-making, but within each domain, there are relatively few comparisons between them. Furthermore, early work that examines the connections between these models (for recent review see: <ref type="bibr" target="#b20">Pleskac, 2015)</ref>, has yet to have been linked to contemporary research questions. We illustrate these points in the context of recent computational modeling research on visual memory.</p><p>Our article has the following structure. First, we overview each of the theories and their corresponding models. Second, we outline how early work on the relationship between SDT and LCA models applies to contemporary research on visual memory, and describe a critical test that we used to discriminate between them. Finally, we discuss our findings and their relevance for theorizing about decision processes within and outside of visual memory tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Signal detection theory</head><p>The application of SDT to the study of sensory and cognitive process comes from the tradition of perceptual psychophysics (e.g., <ref type="bibr" target="#b8">Green, Swets, et al., 1966)</ref>, which high-lights the relationship between sensory signals that must be used to make a decision, and the physical and neural noise that perturbs them before a decision may be made <ref type="bibr" target="#b30">(Wickens, 2001)</ref>. Over the years, SDT has been used in other domains, such as memory research (e.g., <ref type="bibr" target="#b31">Wixted, 2007)</ref>, to provide a detailed description of processing in a range of detection and discrimination tasks by postulating latent memory-strength signals that are perturbed by noise. The two core assumptions of signal detection models is that the (conceivably rich and multi-dimensional) representation of each alternative is collapsed down into a scalar value (the decision variable) and that the decision variable invoked by a particular alternative is probabilistic. Jointly, these assumptions capture the mainstream view that there are internal and external sources of noise that corrupt sensory and memory signals (e.g., <ref type="bibr" target="#b6">Dosher &amp; Lu, 1998)</ref>. For instance, in the memory domain, a familiar object, such as a backpack, will produce a decision variable with respect to some task (e.g., a familiarity signal for a recognition task) of some magnitude. The decision variable produced by observing a backpack will vary from one instance to another due to variation in external circumstances <ref type="bibr">(lighting, pose, etc.)</ref> and fluctuation of internal states <ref type="bibr">(memory, attention, motivation, etc.)</ref>.</p><p>Because decision variables in this view are seen as random variables, it is common to postulate a probability distribution over them (although see: <ref type="bibr" target="#b11">Kellen et al., 2021)</ref>. While in some low-level perceptual domains, great care has been taken to characterize the functional form of this distribution, and thus the form of the psychometric function (e.g., <ref type="bibr" target="#b8">Green, Swets, et al., 1966)</ref>, in most applications such fidelity is unattainable and researchers simply assume that decision variables are normally distributed. Thus, historically, the normality assumption common in SDT is made primarily for convenience <ref type="bibr" target="#b30">(Wickens, 2001)</ref>, and in contemporary modeling work it is often treated as an auxiliary assumption that does not have a theoretical justification (although see: <ref type="bibr" target="#b11">Kellen et al., 2021)</ref>. To preview our analysis and results, we show that the Gaussian parameterization of signal detection models is not merely ancillary; its use can have a principled theoretical basis that formalizes how sensory signals are converted to decision variables. We discuss this point in depth when reviewing the mathematical link between the signal detection and softmax model. Finally, most mainstream signal detection models postulate that, while decision variables are probabilistic, the decision making process is deterministic (for exceptions see, e.g., <ref type="bibr" target="#b1">Benjamin et al., 2009)</ref>. That is, once decision variables are sampled from their probability distributions, choices are made deterministically by comparing the decision variables to one another, or to a fixed decision criterion. Next we describe how these principles are used to explain performance in mainstream detection and discrimination tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SDT for detection and discrimination tasks</head><p>In detection tasks the observer responds by indicating the presence or absence of a target stimulus, and the classic Gaussian signal detection model posits that this decision is made by collapsing the rich stimulus representation down into a single decision variable and then comparing this decision variable X against a fixed decision threshold C. Accordingly, the probability of responding that a target is "Present" on target present and absent trials is given by Equations 1 and 2, respectively,</p><formula xml:id="formula_0">P('Present' | Present) = P(X T &gt; C),<label>(1)</label></formula><formula xml:id="formula_1">P('Present' | Absent) = P(X F &gt; C).<label>(2)</label></formula><p>In Equation 1 X T denotes the decision variable elicited by the target stimulus, which is a random variable sampled from a normal distribution with free parameters, mean µ &gt; 0 and variance σ 2 : X T ∼ N(µ, σ 2 ). A common assumption is that, on average, decision variables on target present trials will be of greater magnitude than on target absent trials, and it follows that their mean will also be greater. Therefore, with no loss in generality, the mean and variability of the decision variable elicited by foil items, X F in Equation 2, on target absent trials is set to 0 and 1, respectively: X F ∼ N(0, 1). Unlike in detection tasks, in forced-choice discrimination tasks the target is always shown and an observer must select it out of a set of n alternatives. Classic signal detection models postulate that this selection process involves computing the maximum of a set of n independent random variables corresponding to the decision variables invoked by each of the stimuli: X i . More precisely, the probability of identifying a given item i as the target is the probability that the utility generated by the target X i exceeds the decision variables generated by each of the n − 1 foil items X j for j i:</p><formula xml:id="formula_2">P(ID(i)) = P(∀ j i : X i &gt; X j ).<label>(3)</label></formula><p>This general expression can be written out for the special cases of correct choices, when X i corresponds to the target (i = 1), and incorrect choices, when i 1. For correct choices, or Target Identifications, X i is the target (X i = X 1 = X T ) and all X j s are foils, thus X i ∼ N(µ, σ 2 ), and X j ∼ N(0, 1). For incorrect choices, or Foil Identifications, the target is one of the X j s while X i and the remaining X j s are foils. For both of these special cases, we can rewrite the general expression:</p><formula xml:id="formula_3">X 1 = X T ∼ N(µ, σ 2 ) (4) X 2...n ∼ iid N(0, 1) (5) P(ID(Target)) = P(X 1 &gt; max(X 2...n )),<label>(6)</label></formula><formula xml:id="formula_4">P(ID(Foil)) = n i=2 P(X i &gt; max(X 1..n\i )).<label>(7)</label></formula><p>Luce's choice axiom</p><p>Luce's choice axiom (LCA) comes from the decision theory tradition, rather than psychophysics. Unlike SDT, the original framework is silent about the mechanisms of detection and discrimination processes. Instead, this framework consists of a set of axioms that impose "plausible constraints" on choice probabilities. The central axiom is called Independence from Irrelevant Alternatives, which is that the probability of choosing one alternative over another should not change if irrelevant alternatives are added or taken away. Within this framework, response probabilities for each alternative are computed by dividing each response strength by the sum of all response strengths in the set. For instance if a is one alternative out of a larger set T , the probability of choosing a out of S is</p><formula xml:id="formula_5">P(a, S ) = ϕ(a) z∈S ϕ(z) ,<label>(8)</label></formula><p>where ϕ is a response strength function. Note that independence from irrelevant alternatives follows directly from this formula because the odds of choosing a over a different alternative b ∈ S remains the same, even if we consider a larger set of alternatives T where S ⊆ T . That is, for</p><formula xml:id="formula_6">0 &lt; P(x) &lt; 1, P(a, S ) P(b, S ) = P(a, T ) P(b, T ) = ϕ(a) ϕ(b) .<label>(9)</label></formula><p>Equation 8 also implies that the function ϕ lies on a ratio scale. That is, assume there exists another function ϕ ′ that satisfies the equality</p><formula xml:id="formula_7">ϕ(a) ϕ(b) = ϕ ′ (a) ϕ ′ (b) .<label>(10)</label></formula><p>Substituting 1 for ϕ(b) and τ &gt; 0 for ϕ ′ (b) yields τϕ(a) = ϕ ′ (a), showing that the scale ϕ is unique up to multiplication by a positive constant (proof adapted from: <ref type="bibr" target="#b12">Krantz et al., 1971)</ref>. This entails that the response function ϕ lies on a ratio scale, an important and rare property of psychological metrics <ref type="bibr" target="#b7">(Falmagne &amp; Doble, 2015)</ref>.</p><p>Finally, note that in order for choice probabilities in Equation 8 to be restricted between zero and one, response strengths should be constrained to be non-negative. One way to impose this constraint is to parameterize the Luce choice model with an exponential function, such that P(a, S ) = e ϕ(a) z∈S e ϕ(z) .</p><p>This formulation of LCA is equivalent to the exponential form of the multinomial distribution and the softmax function <ref type="bibr" target="#b3">(Bridle, 1990)</ref>, which is routinely used in econometrics <ref type="bibr" target="#b14">(McFadden, 1980)</ref>, machine learning <ref type="bibr" target="#b15">(Murphy, 2012)</ref> and reinforcement learning <ref type="bibr" target="#b25">(Sutton &amp; Barto, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LCA for detection and discrimination tasks</head><p>Through the lens of LCA, performance in detection and discrimination tasks is not determined by random decision variables but by fixed response strengths. In detection tasks, assume that β denotes response strength generated by the target stimulus 1 and V denotes a bias parameter for reporting the stimulus is absent. Then, on target present trials, the probability of correctly responding target present is</p><formula xml:id="formula_9">P('Present' | Present) = e β e β + e V .<label>(12)</label></formula><p>On target absent trials, the probability of incorrectly responding target present is determined by the response strength generated by the foil, which is zero. Thus, the probability of incorrectly responding target present on target absent trials is</p><formula xml:id="formula_10">P('Present' | Absent) = 1 1 + e V .<label>(13)</label></formula><p>Note that the formulas for choice probabilities in Equations 12 and 13 are formally equivalent to a logistic (cumulative) distribution <ref type="bibr" target="#b24">(Suppes &amp; Krantz, 2007)</ref>, a special case of the softmax function for binary choices.</p><p>Extending this logic to discrimination tasks with n alternatives uses the standard assumption that the response strength generated by the target and n − 1 foils is equal to β and zero, respectively. Accordingly, the probability of correctly selecting the target is</p><formula xml:id="formula_11">P(ID(Target)) = e β e β + n − 1 ,<label>(14)</label></formula><p>and the probability of incorrectly selecting a foil item is</p><formula xml:id="formula_12">P(ID(Foil)) = n − 1 e β + n − 1 .<label>(15)</label></formula><p>Connections between SDT and LCA Due to their distinct origins and distinct mathematical instantiations, models based on SDT and LCA may seem extremely different from one another. However, the Gaussian signal detection and softmax models turn out to be close approximations in some tasks. More precisely, in detection tasks, the connection between these models follow simply from the fact that the logistic distribution approximates the normal distribution and vice versa <ref type="bibr" target="#b29">(Treisman &amp; Faulkner, 1985)</ref>. This entails that the LCA for binary choices is equivalent to a signal detection model with a logistic parameterization, which closely approximates the Gaussian signal detection model. Thus, in detection tasks LCA and Gaussian signal detection models are closely related.</p><p>In discrimination tasks with more than two alternatives the Gaussian signal detection and softmax model no longer approximate each other. The relationship between these two models breaks down in m-afc tasks (where m &gt; 2) because the distribution of maximums of normally distributed variables is not a normal distribution. However, it is possible to establish an equivalence between the two models by dropping the normality assumption in the signal detection model. <ref type="bibr" target="#b10">Holman and</ref><ref type="bibr">Marley, 1974 as well as Yellott Jr, 1977</ref> showed that, if decision variables in the signal detection model have a Gumbel distribution, than the signal detection model is mathematically equivalent to the Luce model for any number of alternatives (m) in an m-afc task. We provide our own proof of this result in the Appendix.</p><p>In the current context, the major implication of this result is that comparing the softmax model to the Gaussian signal detection model can be recast as a comparison of two different parameterizations of the signal detection model, that is, a signal detection model with a Gumbel versus a Gaussian parameterization. As we discuss next, these two parameterizations have an important conceptual basis because they describe different ways of translating sensory evidence into decision variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Processing implications of a Gaussian versus Gumbel signal detection (softmax) model</head><p>A common assumption is that the Gaussian parameterization of signal detection models is made for mathematical convenience and does not have a theoretical basis (e.g., <ref type="bibr" target="#b11">Kellen et al., 2021)</ref>. However, early work by <ref type="bibr" target="#b27">Thompson and Singh, 1967</ref> provides one principled justification for using a normal distribution to model decision variables. These researchers noted that each time we observe a stimulus, it produces a sensory response of some variable magnitude. For instance, through the lens of contemporary population coding neural models, these sensory responses can be conceived of as distributed patterns of activation in populations of neurons (e.g., <ref type="bibr" target="#b0">Averbeck et al., 2006)</ref>. If these sensory signals are pooled together by summing or averaging to compute decision variables, then in accordance with the Central Limit Theorem, decision variables will be normally distributed.</p><p>In contrast to the Gaussian, the Gumbel distribution is an extreme value distribution used to model the maximum of a set of random variables <ref type="bibr" target="#b9">(Gumbel, 1954)</ref>. Thus, a signal detection model with a Gumbel parameterization is most consistent with that idea that, rather than pooling, the observer takes the maximum of sensory signals to compute decision variables.</p><p>Figure 1 depicts these predictions by showing how a stimulus produces a neural response profile that consists of a set of tuning functions (colored distributions), and how these neural responses can be converted to a single decision variable through the lens of each model. Together, these parametric assumptions are not merely ancillary, but have different implications for how we think observers convert rich sensory or memory evidence to decision variables when making decisions.</p><p>Critical test: Parameter invariance across changes of m in m-afc tasks</p><p>We compared the Gaussian signal detection and softmax model by examining which model's parameters (d ′ in SDT; β in LCA/softmax) are invariant across variations in the number of alternatives presented at test in an m-afc task. Our test rests on the assumption that, everything else being equal, the way in which observers compute decision variables should be invariant across changes in m-afc. This assumption aligns with the broader view that models that generalize across task structures may also provide better approximations of latent cognitive processes <ref type="bibr" target="#b4">(Busemeyer &amp; Wang, 2000)</ref>.</p><p>We note that a similar test was used in an auditory memory task in an early study by <ref type="bibr" target="#b29">Treisman and Faulkner, 1985</ref>. These authors reported evidence for the Gaussian signal detection model, however, their results were somewhat ambiguous. Mainly, they found that variations in m-afc produces decreases in d ′ and increases β, parameters in the Gaussian signal detection and softmax model, respectively. The researchers interpreted this as evidence for the Gaussian signal detection model because they reasoned that increasing the number of alternatives in the auditory task may increase memory load and hurt performance, but not improve it. Furthermore, this study only used data from 6 participants and may have been underpowered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Application to visual memory</head><p>Together, while the Treisman and Faulkner, 1985 study provides provisional support for the Gaussian signal detection model, we ran a new set of experiments that extends this critical test to the visual memory domain. The first reason we used a visual memory task is because this allows us to present all m-afc alternatives visually, instead of having participants maintain these in working memory. Accordingly, this study design minimizes differences in memory load across m-afc task, addressing the core limitation of the Treisman and Faulkner experiment and providing a strong test bed of parameter invariance. We also increase the number of participants in our experiments to ensure that our studies are sufficiently powered.</p><p>Another reason for extending this test to the visual memory domain is because a comparison between these models Processing implications of the Gaussian versus Gumbel parameterization of the signal detection model. By Central Limit Theorem, the Gaussian signal detection model entails that observes convert sensory evidence (depicted with colored distributions) evoked by a stimulus (such as backpack) to decision variables via pooling. The Gumbel signal detection model, which is formally equivalent to the softmax model, entails that observers convert sensory evidence to decision variables by taking the maximum of the sensory signals.</p><p>has direct relevance for contemporary models of visual memory. That is, both the Gaussian signal detection and softmax models have been used in recent modeling work as response functions that capture how people make decisions in m-afc visual memory tasks <ref type="bibr" target="#b17">(Oberauer &amp; Lin, 2017;</ref><ref type="bibr" target="#b23">Schurgin et al., 2020)</ref>. However, these models have not been compared with critical tests, and the processing implications of these models have not been assessed in empirical studies. Our goal is to fill this gap by comparing these models in a set of visual memory experiments. To this end, we ran two Experiments in which we varied both the presentation format and stimuli to ensure that our results were robust across different processing domains and theoretical assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1: Memory for simple features</head><p>Experiment 1 was designed to test the signal detection and softmax models in a multiple alternative forced choice visual working memory task with simple features (color). The central comparison involves examining which model's parameters are invariant across changes in the number of alternatives in m-afc tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Participants Participants (n = 31) were undergraduate student volunteers, at the University of California, San Diego, who participated in the study for course credit. All participants were at least 18 years old, reported normal or corrected-to-normal vision, and provided informed consent. All experiments were approved by the Institutional Review Board at the University of California, San Diego.</p><p>Our predetermined sample size was n = 30. This sample size is a conservative bound for detecting a medium effect size (d z = 0.6) with 90% power and α = .05 significance criterion. We collected participant data until our sample size reached n = 30 based on our exclusion criteria. Consistent with our standard lab practice, we excluded trials with reaction times less than 100 ms or greater than 5000 ms (average proportion of 3% per participant). We excluded participants who had more than 10% of trials excluded, or who whose performance was at chance in any of the four conditions (one participant).</p><p>Stimuli Stimuli were colored circles. Colors were drawn from the CIE L*a*b* color space, centered in the color space at (L = 54, a = 21.5, b = 11.5) with a radius of 49 (from <ref type="bibr" target="#b23">Schurgin et al., 2020)</ref>.</p><p>Procedure On each trial, participants were shown four circles and instructed to remember their colors and spatial locations. The minimum distance (along the color circle) between each circle in the memory array was 30 degrees. The memory array was shown for 1,000 ms. After a brief retention interval (800 ms), participants were shown a spatial cue that probed one of the four circles shown in the memory array.</p><p>Participants were instructed to use a discretized color wheel to report on their memory for the probed circle. The discretized color wheel consisted of 2, 4, 8, or 16 colors, which were spaced either 180°, 90°, 45°or 22.5°apart in color space, respectively. Participants were instructed to click on the color that they thought best matched the color of the probed circle. One of the colors always matched the color of the probed circle, whereas the others did not. There were a total of 500 trials in the experiment (125 trials per m-afc condition), and each experimental session lasted approximately 50 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retention interval 800ms</head><p>m-afc Until response Memory array 1,000ms</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>Example trial from Experiment 1. On each trial participants were shown a memory array with four colored circles. The memory array was presented for 1,000 ms and followed by an 800 ms retention interval. After a retention interval, participants were shown a self-report screen with 2, 4, 8, or 16 equally spaced colors, and the other positions filled with gray "filler" squares. One of the colors presented at test was always shown on that trial, and the remaining colors were not. Participants had to click one the colors to indicate which color was at the cued position on this trial. Responses were not speeded. The pictured trial shows an 8-AFC test with 8 colors presented at test, and the correct answer is the yellow color on the bottom of the response wheel, as this matches the color presented in the top left location, which is the cued location on this trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Participants' responses were converted to errors by taking their distance along the color wheel from the correct answer, where the correct response is centered at zero. These deviation values were fit with a Gaussian signal detection model and a softmax model to estimate parameters d ′ and β, respectively. Models were fit separately to each participant's data and fitting was implemented in MATLAB using maximum likelihood estimation (MLE).</p><p>Rather than assuming all foils elicit 0 signal regardless of their similarity to the shown color, we fit models to the full distribution of errors under the assumption that the latent memory strength of each alternative scales with the psychophysical similarity to the remembered item. This assumption aligns with classic feature matching models of memory (e.g., <ref type="bibr" target="#b5">Clark &amp; Gronlund, 1996)</ref>, as well as more recent work on visual memory <ref type="bibr" target="#b23">(Schurgin et al., 2020)</ref>. More precisely, both theoretical frameworks predict that foils that are more similar to the target have stronger latent memory strengths than those that are less similar. This fitting procedure used psychophysical similarity values obtained by <ref type="bibr" target="#b23">Schurgin et al., 2020.</ref> Our goal was to determine which model's parameters are more invariant across the m-afc manipulations. We tested this by comparing the relative fits of the signal detection and softmax model when parameters d ′ and β, respectively, were fixed across all m-afc conditions. This analysis provides insight into which model best accommodates the data if we assume that its parameters are invariant across manipulations of m-afc. Since both the signal detection and softmax models have the same number of parameters, we used the log likelihood (LL) to compare models (note that larger values of the LL indicate superior fit). These values were compared at the level of individual participants using a paired t-test.</p><p>We also implemented two secondary analyses that complement our critical test. In the first complementary analysis, we assessed the relative fits of each model when parameters varied freely across m-afc conditions. This analysis provides insight into whether (as expected) the invariance of parameters of these models, as opposed to their functional form, yields better fits to data in our primary analysis when parameters are fixed across m-afc conditions. In the second complementary analysis, we compared the standard deviation of parameters across m-afc conditions when we allowed these to vary freely across m-afc conditions. We expect variability of parameters across m-afc conditions to be smaller in the model that provides the best fit to data when parameters are fixed across m-afc conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Panel A of <ref type="figure" target="#fig_2">Figure 3</ref> shows the difference in log likelihood (LL) between the Gaussian signal detection and softmax model when parameters d ′ and β, respectively are fixed across m-afc conditions. Positive and negative values indicate support for the Gaussian signal detection and softmax model, respectively, whereas values near zero indicate equal  Model fitting and comparison results from Experiment 1. Panel A shows the difference in log likelihood between the Gaussian signal detection and softmax models when we fixed each model's parameters across m-afc conditions. Positive values indicate support for the Gaussian signal detection model, negative values indicate support for the softmax (or Gumbel signal detection model), and values at zero indicate equal support for both models (denoted with the black dotted line). Panel B shows participants raw proportion correct at each m-afc condition (top) as well as the parameter estimates obtained from fitting the Gaussian SDT model (middle) and softmax model (bottom) separately to the full error distributions from each m-afc condition. In each figure, the black dot and error bar denote the average and standard error of the mean across participants within each condition. The black dotted line in Panel B, denotes the mean across participants and condition. The fact that estimates of d ′ are more stable than estimates of β across m-afc conditions is consistent with the model comparison favoring the Gaussian SD model. support for both models. We found that the LL was significantly higher for the Gaussian signal detection (X = −562.2; S EM = 31) than the softmax (X = −565.3; S EM = 31) model (t(29) = 4.26, p &lt; .001; d z = 0.77). Average parameter estimates in the fixed models were d ′ = 1.86 (S EM = .15) and β = 2.69 (S EM = .22).</p><p>Panel B of <ref type="figure" target="#fig_2">Figure 3</ref> shows parameter estimates from each model when they were allowed to vary freely across mafc experimental conditions. In the Gaussian signal detection model, average d ′ equaled 1.79 (S EM = .17), 1.86 (S EM = .16), 1.98 (S EM = .14) and 1.84 (S EM = .16) in the 2, 4, 8, and 16 m-afc conditions, respectively. Average β estimates equaled 2.42 (S EM = .34), 2.5 (S EM = .23), 2.85 (S EM = .19) and 3.07 (S EM = .24) in the 2, 4, 8, and 16 m-afc conditions, respectively. Importantly, based on LL, we found that the Gaussian signal detection (X = −560; S EM = 31) and softmax (X = −560.01; S EM = 31) models fit the data comparably when parameters were free to vary across m-afc conditions (t(29) = .19, p &gt; .84; d z = 0.04). This analysis provides convergent support for the conclusion that the superior fit of the Gaussian signal detection model when its parameters are fixed across m-afc conditions, reflects its superior capacity to capture invariants across m-afc conditions, as opposed to this model having a more flexible functional form. Based on the standard deviation of parameters across m-afc conditions, we also found that there was significantly less variability in parameters in the Gaussian signal detection (X = .21; S EM = .02) than the softmax modelX = .55; S EM = .08) when these were allowed to vary freely (t(29) = 5.26, p &lt; .001; d z = 0.96). Thus, the d ′ parameter of the Gaussian signal detection model was more stable across m-afc conditions than the β parameter of the softmax model.</p><p>Together, our results provide support for the Gaussian signal detection over the softmax model. That is, we find that the Gaussian signal detection model does a better a job at capturing invariance of decision latent processes across mafc conditions, and that these effects are not due to differences in model flexibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments 2: Memory for real-world objects</head><p>The goal of Experiment 2 was to examine the generalizaiblity of our modeling results. To this end, in Experiment 2 we modified both the stimuli and presentation format. More precisely, we had participants remember real-world objects instead of simple features, and presented stimuli sequentially instead of simultaneously.</p><p>Another advantage of using real-world objects instead of colors as stimuli, is that the real-world object stimulus space in unconstrained. This entails that we can select a larger number of foils that are completely dissimilar from the target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Participants Participants (n = 31) were undergraduate student volunteers, at the University of California, San Diego, who participated in the study for course credit. As in Experiment 1, we collected participants until we reached a final sample size of (n = 30). Exclusion criteria were the same as those used in Experiment 1. We excluded an average of 4% of trials per participant, and one participant.</p><p>Stimuli Stimuli were photos of real-world objects taken from <ref type="bibr" target="#b2">Brady et al., 2008</ref>. All objects were from different categories.</p><p>Procedure On each trial, participants were shown a sequence of five unique photos of real-world objects. Each object was presented for 300 ms, and the interstimulus interval was 100 ms. The sequence of objects was followed by a retention interval that lasted 800 ms.</p><p>At memory test, participants were shown 2, 4, or 8 objects and were instructed to click on the object that was shown in the sequence on that trial. We include 3 instead of 4 mafc conditions because trials with sequential presentation are longer and we wanted to ensure that the experimental session did not run over the 50 minute time limit, while maintaining a sufficiently large number of trials per condition. One of the objects always matched an object shown on that trial sequence, whereas the others were completely novel objects that were only shown once throughout the entire experimental session. There were a total of 210 trials (70 trials per m-afc condition), and each experimental session lasted approximately 50 minutes.  Example trial sequence from Experiment 2. On each trial participants were shown a sequence of five unique photos of real-world objects. Each object was presented for 300ms, with an inter-stimulus interval (ISI) of 100ms. The object sequence was followed by an 800ms retention interval, and then a self-report screen. The self-report screen showed 2, 4, 8 objects. One of the objects was always an object shown on the trial sequence, and the remaining objects were foils from different categories, that were not shown again during the experimental session. Participants had to click which object they had seen on that trial. Responses were not speeded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>In this experiment all foils are maximally dissimilar from the target item, and thus there is no structure to the errors (above and beyond percent correct). Therefore, analyzing the accuracy data and error distributions yields identical results. Thus, the analysis was identical to the one used in Experiment 1, with the exception that we fit models to proportion correct alone rather than the complete error distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Panel A in <ref type="figure" target="#fig_6">Figure 5</ref> shows the difference in log likelihood (LL) between the Gaussian signal detection and softmax model when parameters d ′ and β, respectively are fixed across m-afc conditions. As before, positive and negative values indicate support for the Gaussian signal detection and softmax model, respectively, whereas values near zero indicate equal support for both models. We found that the LL was significantly higher for the Gaussian signal detection (X = −106.9; S EM = 19) than the softmax (X = −107.8; S EM = 20) model (t(29) = 4.42, p &lt; .001; d z = .81). Average parameter estimates in the fixed models were d ′ = 1.52 (S EM = .12) and β = 2.04 (S EM = .16).</p><p>Panel B in <ref type="figure" target="#fig_6">Figure 5</ref> shows parameter estimates from each model when these varied freely across experimental conditions. In the Gaussian signal detection model, average d ′ equaled 1.42 (S EM = .12), 1.49 (S EM = .13) and 1.61 (S EM = .13) in the 2, 4 and 8 m-afc conditions, respectively. Average β estimates equaled 1.71 (S EM = .16), 1.96  Model fitting and comparison results from Experiment 2. Panel A shows the difference in log likelihood between the Gaussian signal detection and softmax models when we fixed each model's parameters across m-afc conditions. Positive values indicate support for the Gaussian signal detection model, negative values indicate support for the softmax (or Gumbel signal detection model), and values at zero indicate equal support for both models. Panel B shows participants raw proportion correct at each m-afc condition (top) as well as the parameter estimates obtained from fitting the Gaussian SDT model (middle) and softmax model (bottom) separately to the percent correct from each m-afc condition. In each figure, the black dot and error bar denote the average and standard error of the mean across participants within each condition. The black dotted line in Panel B, denotes the mean across participants and condition. The fact that estimates of d ′ are more stable than estimates of β across m-afc conditions is consistent with the model comparison favoring Gaussian SD.</p><p>(S EM = .17) and 2.30 (S EM = .18) in the 2, 4 and 8 mafc conditions, respectively. Based on the LL, both models yielded identical fits to the data (X = −105.4; S EM = 3.6 for both models; t(29) = 0). Again, this indicates that the superior performance of the Gaussian singal detection model is not due to its having a more flexible functional form. Based on the standard deviation of parameters across m-afc conditions, we also found that there was significantly less variability in parameters in the Gaussian signal detection (X = .24; S EM = .03) than the softmax modelX = .41; S EM = .04) when these were allowed to vary freely (t(29) = 8.77, p &lt; .001; d z = 1.60). Once again, these results provide support for the Gaussian signal detection over the softmax model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>In the current work, we revisited the connection between the Gaussian signal detection and (Luce choice) softmax model. Although these two models come from different traditions, they closely approximate each other in detection tasks, and are formally equivalent when the signal detection model is reparameterized with Gumbel (rather than Gaussian) distributions in the m-afc task. Thus, the distinction between signal detection and softmax choice models can be understood as embodying different assumptions about signal distributions in a signal detection model. As pointed out by <ref type="bibr" target="#b27">Thompson and Singh, 1967</ref>, the Gaussian parameterization is most consistent with people pooling sensory evidence to compute decision variables, whereas the Gumbel distribution is most consistent with people taking the maximum of sensory evidence to compute decision variables. Thus, a test between the Gaussian and signal detection and softmax model can be conceived of as a test between signal detection models with different latent distributions of decision variables, which have different psychological meanings. That is, these two different parameterizations may potentially elucidate how people compute decision variables in a range of cognitive tasks.</p><p>We applied these ideas in the visual memory domain to examine which model provides the best characterization of processes in structurally different visual working memory tasks. To compare the two models, we designed a critical test to assess which model's parameters are invariant across changes in m in m-afc tasks. Our test was motivated by the assumption that, with all else held constant, variations in the number of alternatives in discrimination tasks should not change how observers compute decision variables. More broadly, our test aligns with the view that models that best capture stable latent processes, should yield parameters that are invariant across task structures <ref type="bibr" target="#b4">(Busemeyer &amp; Wang, 2000)</ref>. We used this test in two different working memory experiments, where we varied the types of stimuli (simple features versus real-world objects), foil similarity (similar versus dissimilar) and presentation format (simultaneous versus sequential). Across these two experiments, we found consistent support for the Gaussian signal detection model. These results are consistent with the view that sensory evidence is pooled via summation or averaging, and indicates that out of this suite of models, the Gaussian signal detection model best capture latent processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models of visual working memory</head><p>Our work has direct implications for contemporary models of visual working memory. Relevant in this context are two prominent models, the Target Confusability and Competition (TCC) <ref type="bibr" target="#b23">(Schurgin et al., 2020)</ref> and Interference model <ref type="bibr" target="#b17">(Oberauer &amp; Lin, 2017</ref>). The TCC model combines principles from signal detection and Shepard's law of generalization; it postulates that familiarity is a function of the psychophysical similarity to remembered items, such that items that are more similar to items held in memory generate a stronger familiarity signal. Importantly, an assumption of this model is that the response function that maps familiarity signals (decision variables) to responses is a Gaussian signal detection model. The interference model postulates that memory for items is driven by cued based retrieval. More precisely, access to working memory representations is determined by a spatial retrieval cue, as well as noise that is uniformly distributed across memoranda. Importantly, in this model that response function that maps the decision variable to responses is a softmax function.</p><p>When proposing these models, these researchers do not provide a principled justification for using one response function over the other. Our work suggests that the Gaussian signal detection model is more appropriate. Notably, our conclusions conflict with a recent analysis by Oberauer, 2021. Oberauer, 2021 implemented a factorial comparison of visual working memory models, and found support for the softmax over the Gaussian signal detection model. A major limitation of this work, is that it is not based on a critical test, such as our test of parameter invariance. Instead, Oberauer, 2021 factorially combined different dimensions of each model until he identified a model that provided superior "fit" to the data based on a particular model comparison technique. It is known, however, that superior fit to data alone does not entail that a model's basis theory is also a superior one <ref type="bibr" target="#b21">(Roberts &amp; Pashler, 2000)</ref>. Instead, it could reflect other factors such as, inadequate penalization of a model's flexibility <ref type="bibr" target="#b18">(Piantadosi, 2018;</ref><ref type="bibr" target="#b19">Pitt &amp; Myung, 2002)</ref>. Indeed, unlike in our work, Oberauer considered different combinations of activation functions (e.g., Laplace versus von-Mises) and response rules (e.g., Gaussian signal detection versus softmax), and found that the best fitting model had a von Mises activation and softmax response rule. Our results, in contrast, suggest that the Gaussian signal detection model performs well across a range of experimental conditions and when we make minimal assumptions about the latent activation function. Futhermore, Oberauer's factorial comparison was not driven by a priori predictions, and the winning model does not have clear theoretical foundation. At a minimum our results across two different visual working memory experiments deeply challenge those of Oberauer, 2021.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations and future directions</head><p>Throughout our article we focused on two specific models of choice the Gaussian signal detection and softmax model. In principle, however, we could have compared a much wider range of models; for instance, we could have considered a larger range of signal detection models with different parameterizations. This approach was taken by <ref type="bibr" target="#b22">Rouder et al., 2010.</ref> Most relevant here, is that these researchers used Receiver Operating Characteristics analysis to compare different parameterizations of the signal detection model to a variant of the Gaussian signal detection model, which is most prominent in the recognition memory domain <ref type="bibr" target="#b31">(Wixted, 2007)</ref>. For instance, the authors considered signal detection models with a log-normal and gamma parameterization.</p><p>One reason that we focused on comparing Gaussian signal detection and softmax (Gumbel signal detection) models is because they are prominent across different research domains. Furthermore, there is a large body of work that examines the formal relationship between these models, but it disconnected from more contemporary modeling, with little comparison of these two models. Another major reason is that, unlike the Gaussian and Gumbel parameterization of the signal detection model, these alternative parameterizations do not currently have a clear theoretical interpretation. In short, there is an extremely wide range of parameterizations of the signal detection model; considering a larger subset of these is outside of the scope of the current project, but a potential direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We revisited the connection between the Gaussian signal detection and Luce choice-based softmax model. We found that the Gaussian signal detection model best captures decision processes that underpin mainstream visual working memory tasks. This result suggest that people pool sensory evidence to compute decision variables in such tasks, and paves the way for developing linking propositions <ref type="bibr" target="#b26">(Teller, 1984)</ref> between neural and cognitive models of visual memory.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3</head><label>3</label><figDesc>Figure 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4</head><label>4</label><figDesc>Figure 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5</head><label>5</label><figDesc>Figure 5</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Technically, β denotes how response strengths are weighted. More precisely, as β increases responses become more deterministic, such that alternatives with higher response strengths receive more weighting and are more likely to be chosen. However, since we assume that foil items yield zero response strength in this exposition, we equate β with response strength of the target stimulus.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gumbel signal detection and softmax model</head><p>We provide a proof for equivalence between the Gumbel signal detection and softmax model (original result proved by <ref type="bibr" target="#b10">Holman &amp; Marley, 1974;</ref><ref type="bibr" target="#b33">Yellott Jr, 1977)</ref>. We start with the general form of the signal detection model likelihood for discrimination tasks, given partially in the main text in Equation 3. For simplicity, first consider n independent and identically distributed (i.i.d.) variables with probability and cumulative densities f and F, respectively. Equation 3 can be rewritten as a likelihood of the signal detection model for discrimination tasks in terms of these densities of n variables, as shown below</p><p>Informally, the probability density f in Equation A4 gives the probability that one variable is equal to x, and the cumulative density exponetiated to n−1 gives the probability that the remaining n − 1 variables are less than x. The summation term in Equation A4 denotes that for n i.i.d. random variables this can occur in n different ways. These probabilities are integrated over every possible value of x.</p><p>Next, assume that each of n variables has a Gumbel distribution (for maximums) with scale parameter α = 1. As before, we assume that on target present trials decision variables will be larger on average than on target absent trials, so the shift parameter µ &gt; 0 and µ = 0 on target present and target absent trials, respectively. Thus, the densities for decision variables elicited by the target, f T and F T on target present trials are</p><p>and the densities for decision variables elicited by the foils, f F and F F on target absents trials are</p><p>Replacing the generic densities in Equation A4 with the Gumbel densities in Equations A5 through A8, the likelihood for the Gumbel signal detection model on target present and absent trials is the following,</p><p>(e µ−x e −e µ−x )(e −e −x ) n−1 dx, (A9)</p><p>(n − 1)(e −x e −e −x )(e −e µ−x )(e −e −x ) n−2 dx.</p><p>(A10) For simplicity, we show equivalence between the Gumbel signal detection and softmax model using the likelihood for target present trials (Equation A9), but these steps can be extended to the likelihood for target absent trials (Equation A10).</p><p>First, using substitution, set z = e −e −x . Differentiating, dz dx = e −e −x −x and dx = (e −e −x −x ) −1 dz. Simplifying,</p><p>e µ e −e µ−x +e −x z n−1 dz. <ref type="formula">A12</ref>Replacing x with −ln(−ln(z)), in Equation A12 and simplifying gives,</p><p>e µ e −e ln(−ln(z))+µ +e ln(−ln(z)) z n−1 dz, (A13) = ∞ −∞ e µ e ln(z)e µ −ln(z) z n−1 dz, (A14) = ∞ −∞ e µ z e µ z −1 z n−1 dz. (A15)</p><p>After applying the power rule, Equation A15 can be rewritten as,</p><p>e µ z e µ +n−2 dz = e µ z e µ +n−1 e µ + n − 1 .</p><p>Substituting e −e −x back for z, and plugging in the boundaries, yields P(ID(Target)) = e µ−e −x (e µ +n−1)</p><p>= e µ e µ + n − 1 .</p><p>Equation A18 is identical to softmax expression for P(ID(Target)) in discrimination tasks (Equation 14 in main text) with β = µ, completing the proof.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural correlations, population coding and computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Averbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature reviews neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="358" to="366" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Signal detection with criterion noise: Applications to recognition memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">84</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual long-term memory has a massive storage capacity for object details</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Konkle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">38</biblScope>
			<biblScope unit="page" from="14325" to="14329" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bridle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
	<note type="report_type">Neurocomputing</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Model comparisons and model selections based on generalization criterion methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="189" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Global matching models of recognition memory: How the models match the data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gronlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="60" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Perceptual learning reflects external noise filtering and internal noise reduction through channel reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Dosher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-L</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="13988" to="13993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">On meaningful scientific laws</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Falmagne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doble</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
		<title level="m">Signal detection theory and psychophysics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1966" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistical theory of extreme values and some practical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Gumbel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NBS Applied Mathematics Series</title>
		<imprint>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stimulus and response measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Holman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysical Judgment and Measurement</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">173</biblScope>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Testing the foundations of signal detection theory in recognition memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1022</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Foundations of measurement: Addıtive and polynomial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Krantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Suppes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tver-Sky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Representations</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Individual choice behavior: A theoretical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1959" />
			<publisher>John willey and sons</publisher>
			<pubPlace>new york, ny</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Econometric models for probabilistic choice among products</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcfadden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business</title>
		<imprint>
			<biblScope unit="page" from="13" to="29" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Machine learning: A probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Measurement models for visual working memory-a factorial model comparison. Psychological review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Oberauer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An interference model of visual working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Oberauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">One parameter is always enough</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Piantadosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIP Advances</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">95118</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">When a good fit can be bad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Myung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="421" to="425" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Decision and choice: Luce&apos;s choice axiom. International encyclopedia of the social &amp; behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="895" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">How persuasive is a good fit? a comment on theory testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pashler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page">358</biblScope>
		</imprint>
	</monogr>
	<note>Psychological review</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Latent mnemonic strengths are latent: A comment on mickes, wixted, and wais</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Pratte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="427" to="435" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Psychophysical scaling reveals a unified theory of visual memory strength</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Schurgin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature human behaviour</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1156" to="1172" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Courier Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Suppes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Krantz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of measurement: Geometrical, threshold, and probabilistic representations</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Linking propositions. Vision research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Y</forename><surname>Teller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1233" to="1246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The use of limit theorems in paired comparison model building</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="255" to="264" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A law of comparative judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Thurstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">273</biblScope>
			<date type="published" when="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the choice between choice theory and signal detection theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Faulkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="405" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Elementary signal detection theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Wickens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Oxford university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dual-process theory and signaldetection theory of recognition memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">152</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Journal of experimental psychology: learning, memory, and cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">201</biblScope>
		</imprint>
	</monogr>
	<note>The forgotten history of signal detection theory</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The relationship between luce&apos;s choice axiom, thurstone&apos;s theory of comparative judgment, and the double exponential distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Yellott</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="144" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
