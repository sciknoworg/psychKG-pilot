<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Impact of the Balance between Trust in Advice and Confidence in Human Judgment on Advice Utilization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rina</forename><surname>Kagawa</surname></persName>
							<email>kagawa-r@md.tsukuba.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Medicine</orgName>
								<orgName type="institution">University of Tsukuba</orgName>
								<address>
									<addrLine>1-1-1, Tsukuba-shi</addrLine>
									<postCode>305-8575</postCode>
									<settlement>Ibaraki</settlement>
									<region>Tennoudai</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidehito</forename><surname>Honda</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Psychology</orgName>
								<orgName type="institution">Otemon Gakuin University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokazu</forename><surname>Nosato</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Impact of the Balance between Trust in Advice and Confidence in Human Judgment on Advice Utilization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>decision-making</term>
					<term>algorithm aversion</term>
					<term>algorithm appreciation been generally cited as explanation of how infrequently people use algorithms</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The extent to which people utilize advice from others differs depending on whether the source of the advice is an algorithm or a human. However, no unifying evidence can be used for advice design. Moreover, the use of advice given at intervals (e.g., 70-90%) has not been fully studied. This study proposed a three-step model of the cognitive process of the use of advice with intervals and conducted a simulation and four behavioral experiments (N = 473). These experiments showed that differences in advice sources affected the cognitive process in which judges decide whether to update their initial judgment based on the advice; this cognitive process was influenced by the relative weight between their initial judgment and the advice interval. These results suggested that for judges to adjust their judgments, designing advice itself (interval or advice source) is insufficient and advice must be designed according to the relationship between the advice and judge&apos;s judgments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Advice-Taking in the Era of Artificial Intelligence</head><p>Decision-making is not easy for humans. People frequently refer to advice from others for better decision-making. For example, individuals may ask a bus passenger for directions, a physician asks other specialists about a patient's diagnosis, or politicians refer to an algorithm's calculated forecasting of the number of COVID-19 patients. On the other hand, humans do not fully utilize advice from others (egocentric discounting) <ref type="bibr" target="#b17">(Yaniv &amp; Kleinberger, 2000)</ref>. Although many behavioral experiments have accumulated empirical findings, a general and unifying explanation of the mechanism for why people rarely adjust their judgments to the value of advice remains elusive <ref type="bibr" target="#b9">(Morin, Jacquet, Vaesen, &amp; Acerbi, 2021)</ref>. Another issue is the lack of attempts to design advice.</p><p>Today, computational algorithms (hereafter referred to as "algorithms") have outperformed humans in some tasks with the rapid development of artificial intelligence (AI) (i.e., deep learning). Algorithms already support a variety of decisionmaking, such as automated driving and medical diagnostic support. Conversely, experimental findings have shown that 1 While this paper concerns the effect of seeing an algorithm err has on people's likelihood of choosing the algorithm, this paper has algorithmic advice (i.e., advice calculated by an algorithm) tended to be used less often (algorithm aversion) <ref type="bibr">(Dietvorst, Simmons, &amp; Massey, 2015 1</ref> ) or more often (algorithm appreciation) <ref type="bibr" target="#b7">(Logg, Minson, &amp; Moore, 2019)</ref> than human advice. As a basis for designing algorithmic advice, a widely accepted and unified model that accounts for changes in advice use across different advice sources is expected, but research is still nascent <ref type="bibr" target="#b5">(Himmelstein, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithmic Advice in Real-World Situations</head><p>This study attempts to clarify the cognitive process of advicetaking as a basis for designing algorithmic advice and follows the two assumptions below based on real-world situations in which an algorithmic decision-support is used. Human as the Final Judge: In many situations, humans must make the final judgment based on algorithmic advice, which does not automatically and completely replace human judgment. Moreover, humans make initial judgments before checking algorithmic advice. Case 1: In a level of driving automation (SAE, 2021) that is neither fully manual (level 0) nor fully autonomous (level 5), a human driver must make decisions with the support of algorithms. For example, the human driver first perceives a guardrail as they approach on a curve and judge that there is no need to slow down. The algorithm then determines that a collision is possible and automatically applies the brakes. Lastly, the driver assesses low collision risk by referring to the algorithm's support; the driver makes the final decision to press the accelerator pedal and releases the brake. Case 2: Physicians use diagnostic support systems in daily clinical practice <ref type="bibr" target="#b10">(PÃ¡lfi, Arora, &amp; Kostopoulou, 2022)</ref>; however, the algorithm's prediction is not directly used in diagnosis. For example, physicians first estimate (even if implicitly) a patient's condition when physicians perform physical examinations. Then, the physical examination's results are input into the diagnostic support system, and the algorithm calculates the advice. After reviewing the advice, the physician makes the final diagnosis <ref type="bibr" target="#b13">(Topol, 2019)</ref>.</p><p>The judge-advisor system (JAS; <ref type="bibr" target="#b12">Sniezek &amp; Buckley, 1995</ref>) is a widely used experimental protocol for examining advicebased decision-making; judges first make an initial judgment without advice; they then confirm the advice and make a final judgment. Today, many situations in which decision support systems such as those described above are used follow the JAS context, which this study employed. Advice with Intervals: Algorithmic advice for numerical estimation is often presented as an interval (e.g., algorithm estimated a person's body weight at 72.5-75.5 kg) rather than based on point estimates (e.g., 74 kg). However, few studies discuss advice with intervals, despite the possibility that there are specific trends in the use of advice with intervals. Example 1: The initial judgment, which is within the advice interval, may be unlikely to be updated according to the advice. Example 2: Even if the mean of the advice with interval is the same (e.g., 10), advice presented with a relatively narrow interval (e.g., 9-11) may be more likely to be used than advice presented with a relatively wide interval (e.g., 3-17). Dievorst &amp; Bharti (2020) reported that algorithmic advice with larger intervals is less likely to be used, but their work did not follow the context of JAS. Few cross-domain experimental findings have been collected on changes in advice use with continuous changes in advice intervals and individual differences in advice use between human judges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research Questions</head><p>For numerical estimation tasks, this study proposes a model of the cognitive processes of how human judges use advice with intervals and analyze research questions across domains through four behavioral experiments using three domains. RQ1: How do use of advice and accuracy of final judgments change according to continuous changes in advice intervals? RQ2: Are the use of advice and the accuracy of the final judgment affected by the differences in source of advice? Which cognitive processes of advice taking are affected by the differences in source of advice? RQ3: Do human judges differ in their tendency toward algorithm aversion or appreciation, and what factors influence individual differences in human judges?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of Advice-Taking Scenarios</head><p>This section summarizes the situations where advice is used by human judges and two evaluation metrics of advice effect.</p><p>First, a human judge makes the initial judgment, ! , without advice (80 in <ref type="figure" target="#fig_0">Fig. 1</ref>).</p><p>2 WoA is typically clipped to have bounded magnitude (0: no judgment updating-1: ! = ). However, in this study, only answers of which WoA were infinite values were excluded from Next, the advice with interval " " -# " ( " &lt; # ) is presented to the judge. Of " and # , the one closer to ! is $%&amp;' (75.5 in <ref type="figure" target="#fig_0">Fig. 1</ref>) and the other is (&amp;' (72.5 in <ref type="figure" target="#fig_0">Fig.  1</ref>). This study focused on the advice with intervals whose mean value is correct answer (hereinafter, we call target); in other words, the advice was Â± &amp;)*+,% . The judges see the advice, but not the (74.0 in case of <ref type="figure" target="#fig_0">Fig. 1</ref>). Finally, based on this advice, the judge makes the final judgment, -(75 in <ref type="figure" target="#fig_0">Fig. 1</ref>). There might be many types of the updating in judgment from ! todepending on the task, the judge, and the relationship between ! and the advice <ref type="figure" target="#fig_1">(Fig. 2)</ref>.</p><formula xml:id="formula_0">Adviceï¼ 4 " (&amp;' â $%&amp;' " if ! â â¥ 0, " $%&amp;' â (&amp;' " if ! â &lt; 0. â¥ 0 (&amp;' = 4 + &amp;)*+,% if ! â â¥ 0, â &amp;)*+,% if ! â &lt; 0. $%&amp;' = 4 â &amp;)*+,% if ! â â¥ 0, + &amp;)*+,% if ! â &lt; 0.</formula><p>Evaluation Metrics: This study used two metrics to evaluate the effect of advice. The first is the Weight of Advice (WoA; <ref type="bibr" target="#b4">Harvey &amp; Fischer, 1997)</ref>, a widely used metric for advice utilization 2 . Whenequals , a judge is assumed to perfectly have followed the advice. A positive WoA implies that a judge updated their ! in accordance with the , while a negative WoA implies that the judge updated their ! away from the . This study also used the distance betweenand (hereinafter, we call . ! ) to directly evaluate the accuracy of the final judgment with advice. The smaller the . ! is, the closeris to the .</p><formula xml:id="formula_1">= ( ! â -) ( ! â â )</formula><p>.</p><formula xml:id="formula_2">! = | -â |</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical Analysis</head><p>This study proposed a model of how humans use advice with intervals, and a simulation experiment was conducted.</p><p>Referring to models of a cognitive process that used point estimation advice <ref type="bibr" target="#b5">(Himmelstein, 2022;</ref><ref type="bibr" target="#b16">Vodrahalli, Daneshjou, Gerstenberg, &amp; Zou, 2022)</ref>, our model consists of three steps: a pre-step in which human judges make initial analysis because it is possible that an updating from " to ! may move away from the when using advice with intervals.  judgments before checking advice, an activation step in which the judge decides whether to update their initial judgment based on advice, and an integration step in which the final judgment is determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Three-step Model</head><p>Pre-step: Judges make the initial judgment, , according to ( , ). is the instability of caused by judge's knowledge level or task difficulty. Activation Step: This step illustrates a cognitive process in which judges decide whether to update the initial judgment based on advice.</p><p>Regarding the cognitive process of using point estimation advice, the relationship between ! and advice significantly affects advice use <ref type="bibr">(Himmelstein &amp; Budescu, 2022)</ref>. On the other hand, various findings have been reported on how advice use changes when the distance between ! and advice increases. For example, WoA increases monotonically as distance increases <ref type="bibr" target="#b10">(PÃ¡lfi, Arora, &amp; Kostopoulou, 2022)</ref>; WoA peaks at a certain distance between ! and advice <ref type="bibr" target="#b11">(Schultze, Rakotoarisoa, &amp; Schulz-Hardt, 2015)</ref>. Furthermore, for advice with intervals, the tendency for judges to use the advice may differ between cases where ! is included within the interval and where ! is located outside the interval.</p><p>Therefore, the probability that a human judge updates their initial judgment, ,#&amp;$0% , is considered to be determined by the relative relationship between the weight on the initial judgment (i.e., confidence), â . " , and the weight on the advice (i.e., trust), â &amp;)*+,% , which all depend on the gap between ! and $%&amp;' <ref type="figure" target="#fig_3">(Fig. 3)</ref>.</p><formula xml:id="formula_3">! = 4 ! â $%&amp;' if ! â â¥ 0, $%&amp;' â ! if ! â &lt; 0. â + ( ! ) = + 1 + e 123 # ()+5 " 1, # )7 + + ,#&amp;$0% ( ! ) = â . " ( ! ) Ã â &amp;)*+,% ( ! )</formula><p>When ! is negative, ! is included within the advice interval. When ! is negative and the absolute value is large, ! is far from $%&amp;' and close to the . When ! is positive, ! is outside the advice interval. + and + implies the upper and lower limit of â + . + determines the slope of the change in â + with a change in ! . + affects the value of ! at which the change in â + becomes particularly large or small. Integration Step: This step illustrates a cognitive process in which judges decide the final judgment, -, when the judges decided to update ! based on the advice (i.e., -â  ! ).</p><p>This study refers to a cognitive model <ref type="bibr" target="#b14">(Turner and Schley, 2016)</ref> that assumes that when a human makes a final decision after recognizing a value different from that they originally assumed, they determine the final decision according to a probability density function distributed between the two values.</p><p>follows a normal distribution whose mean value is the mean of the interval ( W (&amp;' + $%&amp;' X 2 â = ) and ! . -represents the instability of -. The  instability ofmight be caused by the judge's knowledge level, task difficulty, relative relationship between â . " and â &amp;)*+,% , and other unknown factors.</p><formula xml:id="formula_4">-= (( + ! ) 2 â , -)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Experiment</head><p>Method: To clarify the changes in advice effect with continuous changes in &amp;)*+,% , simulation experiments were performed that varied each parameter of our proposed three-step model. 500 points following ( , ! ) were randomly generated as ! , and the average WoA and . !</p><p>were calculated based on given parameters and repeated according to 150 levels of &amp;)*+,% ranging between 0-30. Results and Discussion: <ref type="figure" target="#fig_2">Fig. 4</ref> shows the results of certain combinations of parameters. The trend of WoA increasing and</p><p>. ! decreasing as &amp;)*+,% decreased was common across the parameter combinations but not to all combinations (one exception is ! = 15 with the activation step (C) for</p><p>. ! ), and this trend was nonlinear. Furthermore, certain combinations of parameters (e.g., ! = 15, with the activation step (A) for . ! ; ! = 5,10,15, with the activation step (B) for WoA and</p><p>. ! ) showed a nonmonotonic trend: WoA or . ! did not change on average when &amp;)*+,% fell below a certain level. In summary, smaller advice intervals do not necessarily mean that the judge is more likely to use the advice or that the judgments made with the advice will be more accurate. Furthermore, the trend of changes in WoA and . ! depending on changes in &amp;)*+,% is difficult to explain with a single parameter, as it is influenced by the combination of ! and ,#&amp;$0% and is less sensitive to changes in -.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Procedure</head><p>Through the behavioral experiment using four tasks, we evaluated the proposed three-step model and demonstrated how &amp;)*+,% and differences in source of advice affected advice effect. All web experiments were conducted in Japanese. R 4.1.0, brms 2.15.0, RStan 2.21.2, Python 3.9.5, and statsmodels 0.13.0 were used for subsequent analysis. All experiments were approved by the Ethics Committee of Institute of Medicine, University of Tsukuba (Approval No. 3327).</p><p>3 In Japanese, the word "AI" semantically includes algorithms and is more popular than the word "algorithm," so this study used AI instead of algorithm. In our pilot study, 153 laypeople answered the free description question "What is artificial intelligence (AI)?" The first author checked all answers and there were no obvious misunderstandings. Then, we judged that the judges knew about AI.</p><p>4 The three sources of advice are just experimental settings; the presentation to the judges about the source of advice was automatically changed. The "AI" did not actually perform the estimation, nor did the specialists or the "100 laypeople" actually estimate for each task.</p><p>General Procedure: All tasks followed the context of JAS. The advice consisted of a combination of &amp;)*+,% and a source of advice. &amp;)*+,% was set at 10 levels, referring to the variance of targets for each task. For all tasks, three types of advice sources were set: AI 3 , 100 laypeople who had answered the corresponding task in the past (hereafter "laypeople"), and specialists (set specifically for each task) 4 . &amp;)*+,% and a source of advice were randomly changed for each question.</p><p>The judges indicated their confidence in each judgment on a 10-point Likert scale. After all the tasks, the judges provided numeracy scores <ref type="bibr" target="#b3">(Fagerlin, Zikmund-Fisher, Ubel, Jankovic, Derry, &amp; Smith, 2007)</ref>. The judges also indicated the average error they thought each advice source made in answering the corresponding task and the average error they thought they have made when answering the corresponding task: these values are called "prior belief of error" (e.g., if the judge answered that the AI's prediction has been 3.0 off from on average, then the judge's prior belief of error of AI is 3.0; see subsequent section of Analysis 4). Details of the Four Tasks: 1. BMI. Referring to <ref type="bibr" target="#b7">Logg et al (2019)</ref>, this study employed questions to estimate body mass index (BMI) from full-body photos 5 . Each of the 159 nonspecialist judges answered 60 randomly presented questions. The mean of the was 33.4 Â± 17.5, and 10 types of &amp;)*+,% were 0.0, 1.75, â¦, 15.75. The top 25% of low . ! judges got incentive (about $4.5). The specialists as sources of the advice were "physicians" or "nurses," and either of these was randomly presented. 2. BMI_exp. To examine the impact of human judges' expertise on the advice effect, five physicians and five nurses answered the same questions as in the BMI task, but with different photos. The mean of the was 33.8 Â± 10.4, and 10 types of &amp;)*+,% were 0.0, 2.6, â¦, 23.4. 3. Subway. For forecasting geopolitical tasks, algorithmic advice is assumed to be preferred <ref type="bibr" target="#b6">(Himmelstein and Budescu, 2023)</ref>. This study employed questions to forecast the number of riders (in millions) of the New York subway for the following month using the number of riders for the past nine months. Each of the 152 non-specialist judges answered 60 randomly presented questions. The mean of the was 521.2 Â± 198.2. The 10 types of &amp;)*+,% were 0.0, 4.95, â¦, 44.55. The specialists as sources of the advice were "train company employees." 4. Song. For subjective tasks, human advice is assumed to be preferred <ref type="bibr" target="#b8">(Morewedge, 2022)</ref>. This study referred to <ref type="bibr">Logg et 5</ref> The questions used in the paper of <ref type="bibr" target="#b7">Logg et al. (2019)</ref> involved guessing body weight from a person's photo. While the dataset available for this study was mainly Western, the judges of this study were Japanese. Therefore, this study used BMI ( = â ( ) 3â â ( )5 ! â ), which refers to the degree of obesity, which made it possible to obtain BMI without being affected by racial differences in physique. In our pilot study, 95.4% of 153 laypeople initially knew BMI and calculated BMI correctly.</p><p>al. (2019) and employed questions of predicting the following week' Billboard chart ranking (1-100) of a song based on rankings over the past eight weeks. Each of the 152 non-specialist judges answered 60 randomly presented questions. The mean of was 50.4 Â± 26.7, and 10 types of &amp;)*+,% were 0, 1, â¦, 9. The specialists as sources of the advice were "multinational music company employees."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis 1: Evaluation of the Three-Step Model</head><p>Pre-step: The mean value of ! â for each task is as follows; BMI: -1.60 Â± 9.23; BMI_exp: -1.28 Â± 7.99; subway: -11.0 Â± 70.8; song: -5.38 Â± 15.0. This involves about 20% of the variance of the for each task, and we judged that the assumption that follows a probability density function whose mean value is is valid. Activation Step: Hierarchical state space models assuming the hierarchy of &amp;)*+,% were used to estimate of ,#&amp;$0% according to ! for each task and each source of advice. The results of the relationship between ! and ,#&amp;$0% was shown in <ref type="figure" target="#fig_4">Fig. 5 (top row)</ref>.</p><p>Independent of the tasks or sources of advice, ,#&amp;$0% was lower when</p><p>! was under 0, and ,#&amp;$0% was higher when ! was over 0. When ! increased, ,#&amp;$0% was found to be constant in some cases (BMI_exp, subway, song with specialists as the source of advice), while ,#&amp;$0% had a peak point in others (BMI and song with AI and laypeople as the source of advice); then, these experiments suggested that the relationship between ! and ,#&amp;$0% depended on not only domain but also the expertise of the human judges and the source of advice. These results can be interpreted that the relationship between ! and ,#&amp;$0% depends on the relative balance of human judgment and advice.</p><p>The fact that the BMI and BMI_exp tasks differed in the presence of the peak of ,#&amp;$0% , even though the advice sources for both tasks are specialists, implied the influence of human judges' expertise on updating of ! . According to the formulation of activation step, we can assume that when judges are non-specialists, the upper limit of weight to advice ( &amp;)*+,% ) and the inflection point of weight to advice ( &amp;)*+,% ) are smaller than those of physicians and nurses. This result can be interpreted as non-specialist judges tending to give a relatively higher upper limit of weight to their own judgments and place a greater relative weight to advice when ! is near the advice interval, compared to doctors and nurses as judges. Integration Step: For each task, the value ofwas analyzed using a multilevel model with ( + ! ) 2 â as the fixed effect, -as the outcome variable, and &amp;)*+,% , source of advice, and judge as the random effects.</p><p>The  ! and ,#&amp;$0% for each advice source. Points indicate ,#&amp;$0% for each ! , lines indicate the estimation values of ,#&amp;$0% for each advice source, and the shaded area covers the 95% credible intervals. Remark: ,#&amp;$0% was lower when ! was within the advice interval, and ,#&amp;$0% was higher when ! was outside the advice interval. (Bottom) The mean of the and ! , andfor each advice source. Remark: -is approximately the mean of the target and ! . for each advice source. (B) Differences in values between laypeople and AI as an advice source. A value greater than 0 means that the value is larger when the advice source is laypeople. <ref type="figure" target="#fig_0">(B-1)</ref> .</p><formula xml:id="formula_5">! , (B-2) ,#&amp;$0% , (B-3) ( + ! ) 2 â â -.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark: The relationship between</head><p>&amp;)*+,% and advice effect is nonmonotonic and nonlinear. The activation step affected the advice effect.</p><p>95% credible interval <ref type="figure" target="#fig_4">(Fig. 5 bottom row)</ref>. This result showed thatis approximately the mean of the and ! , even though judges are not directly aware of the value of . In summary, the results of the behavioral experiments across the domains supported the proposed three-step model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis 2: Advice Interval and Advice Effect</head><p>For each task, the change in WoA or . ! due to the different &amp;)*+,% was estimated using a hierarchical statespace model assuming the hierarchy of judges. For brevity, this section showed the results for the subway task. <ref type="figure" target="#fig_5">Fig. 6 (A)</ref> showed that changes in the advice effect depending on changes in &amp;)*+,% were nonmonotonic and nonlinear, which was similar to the simulation experiment. While previous studies reported that advice use differed when the source of advice was people versus algorithms, these differences were found to be also affected by &amp;)*+,% ; as shown in <ref type="figure" target="#fig_5">Fig. 6 (A)</ref>, WoA was larger for advice by laypeople with &amp;)*+,% 4.95 than advice by AI with &amp;)*+,% 44.55.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis 3: Cognitive Processes that Influence Differences in the Advice Effect by Source of Advice</head><p>This study examined whether differences in the advice's source (especially between AI and humans, referring to the previous studies about algorithm aversion or appreciation) affected cognitive processes. For brevity, results for . ! between laypeople and AI as the advice source of the subway task are shown in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differences in the Advice Effect by Source of Advice:</head><p>Using a hierarchical state-space model assuming the hierarchy of judges, we estimated the difference of . !</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>according to</head><p>&amp;)*+,% between laypeople and AI as the advice source. <ref type="figure" target="#fig_0">Fig. 6 (B-1)</ref> shows that the estimated differences in</p><p>. ! did not contain 0.0 for all settings of &amp;)*+,% ; therefore, there were significant differences in . ! between laypeople and AI as an advice source for all settings of &amp;)*+,% . Cognitive Process Affecting Differences in the Advice Effect by the Source of Advice: Next, we checked whether the difference in the advice effect by its source depends on the activation or integration step of our proposed model. Using a hierarchical state-space model assuming the hierarchy of judges, we estimated the difference in ,#&amp;$0% for the activation step and the difference in ( + ! ) 2 â â -for the integration step, according to &amp;)*+,% . As shown in <ref type="figure" target="#fig_1">Fig. 6 (B-2, B-3)</ref>, for all &amp;)*+,% , ,#&amp;$0% differed significantly between AI and laypeople as an advice source, while ( + ! ) 2 â â -did not differ significantly between AI and laypeople as an advice source.</p><p>In summary, the activation step affected the differences in advice effect depending on the differences in its source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis 4: Individual Differences among Human Judges in Algorithm Aversion or Appreciation</head><p>This study explored the factors that contribute to individual differences among human judges in the advice effect when the advice source is an AI versus a human <ref type="figure" target="#fig_7">(Fig. 7)</ref>. This study assumed that the tendency of algorithm aversion or algorithm appreciation is continuous. Hereinafter, this tendency is called algorithm priority. For each judge, the difference in WoA between AI and human as an advice source according to &amp;)*+,% was estimated using a state-space model, and the sum of the differences at 10 types of &amp;)*+,% was used as the algorithm priority for that judge. For brevity, this study showed the results when the human source of advice is specialists. For each task, multiple regression was performed with â as the objective variable and the following as explanatory variables: age, sex, education, numeracy score, mean confidence for ! , prior beliefs of error of AI, specialists, and judge, as well as the gap in prior beliefs of errors between AI-specialists, AI-judge, and specialistsjudge. The absolute values of the correlation coefficients across all explanatory variables were below 0.80 for each task.</p><p>The explanatory variables that significantly affected the â were as follows; BMI: education ( = 2.2 95% CI [0.74, 3.66], p = 0.003), prior belief in error of AI ( = -0.10 [-0.18, -0.02], p = 0.013), and gap in prior-beliefs of error between AI-judge ( = -0.09 <ref type="bibr">[-0.15, -0</ref>.03], p = 0.006); BMI_exp: none; subway: age ( = 0.05 [0.00, 0.10], p = 0.033), prior belief of error of AI ( = -0.01 [-0.007, -0.012], p = 0.014), and gap in prior-beliefs of error between AI-judge ( = -0.007 [-0.013, -0.000], p = 0.035); song: prior belief of error of AI ( = -0.02 [-0.04, -0.00], p = 0.032), and specialists ( = 0.03 [0.01, 0.06], p = 0.016), gap in priorbeliefs of error between AI-specialists ( = -0.06 [-0.08, -0.03], p = 0.00), and AI-judge ( = -0.03 <ref type="bibr">[-0.05, -0</ref>.02], p = 0.00).</p><p>This result showed that independent of domains, the judge's assumed error of AI and the gap between the judge's assumed error of AI and that of the judge themself would contribute to judges' individual differences in the advice effect when the advice source is an AI versus a human. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>To clarify the cognitive process of using advice with intervals, this study proposed a three-step model and conducted a simulation and cross-domain behavioral experiments. Our simulation and behavioral experiments unveiled that the effect of advice with intervals changed nonmonotonically and nonlinearly according to continuous changes in the advice's intervals. Differences in the sources of advice were found to affect the cognitive process in which judges decide whether to update their initial judgment based on the advice, and this cognitive process was illustrated by the relative weight between the judge's initial judgment and the advice interval. Moreover, individual differences among judges for algorithm aversion or appreciation were affected by the gap of the judge's prior beliefs of algorithms and judge themself.</p><p>These results suggested that designing only advice or sources of advice, such as reducing the error of advice or changing the advice source presented to the judge, is insufficient for judges to adjust their judgments. Designing advice interval so that initial judgments are outside the interval is required to tailor advice for each initial judgment. Techniques for the detection of ! where ,#&amp;$0% peaks based on past judgments would be effective. For the design of personalized advice for each judge, it would be helpful to adequately demonstrate the accuracy of the advice in advance so that the judge can appropriately recognize the accuracy of the advice source (especially the algorithm) as a prior belief.</p><p>Future work should examine different presentations of advice with interval, such as "10 Â± 1." We predict that the cognitive model of using advice with such a presentation would be a model in which ! would simply be changed to ! â , thus not significantly affecting this study's results. Future work should examine more task types (e.g., tasks that are highly personal, such as prediction of the probability whether the judge has disease), and judges' diversity (e.g., race and culture). However, none of these essentially impact advice utilization <ref type="bibr" target="#b0">(Bailey, Leon, Ebner, Moustafa, &amp; Weidemann, 2022)</ref>, so they are not expected to significantly affect this study's results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Context of real-world situations in which algorithmic advice is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Various updating of the judgment based on the "(&amp;' â $%&amp;' " advice, even if ! or the advice is same.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>&amp;)*+,% and the advice effect (WoA and . ! ) when each parameter of our three step model is varied. In each figure, the horizontal axis is &amp;)*+,% , and the vertical axis is WoA or . ! . The black line implies -= | ! â | 2 â and orange line implies -= | ! â | 6 â for the integration step. Remark: The changes in the advice effects depending on the changes in &amp;)*+,% are nonmonotonic and nonlinear. The trend of changes is diverse mainly depending on parameters of pre-step and activation step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Differences in ,#&amp;$0% due to different â &amp;)*+,% .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>(Top)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Estimated values and 95% credible intervals (shaded areas) for the subway task. (A) WoA or . ! and &amp;)*+,%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>For the BMI_exp task, (A) one judge shows the tendency of algorithm aversion (B) while another that of algorithm appreciation. Remark: Difference in advice effect between AI and human advice varies among judges.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This study was partially supported by JST-Mirai Program Grant Number JPMJMI19G8, JSPS KAKENHI Grant Number JP19K19347 and 22H03915, and a project, JPNP20006, commissioned by the New Energy and Industrial Technology Development Organization (NEDO).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A meta-analysis of the weight of advice in decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Moustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weidemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Psychology</title>
		<imprint>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">People reject algorithms in uncertain decision domains because they have diminishing sensitivity to forecasting error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bharti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1302" to="1314" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring numeracy without a math test: development of the Subjective Numeracy Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fagerlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Zikmund-Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Ubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jankovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Derry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Decision Making</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="672" to="680" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Taking advice: Accepting help, improving judgment, and sharing responsibility. Organizational behavior and human decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="117" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Decline, adopt or compromise? A dual hurdle model for advice utilization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Himmelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page">102695</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Preference for human or algorithmic forecasting advice does not predict if and how it is used</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Himmelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2285</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Algorithm appreciation: People prefer algorithmic to human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Logg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Minson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="90" to="103" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Preference for human, not algorithm aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Morewedge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="824" to="826" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Social information use and social information waste</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Jacquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vaesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acerbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="page">20200052</biblScope>
			<date type="published" when="1828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Algorithmbased advice taking and clinical judgment: impact of advice distance and algorithm information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>PÃ¡lfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kostopoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive Research: Principles and Implications</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effects of distance between initial estimates and advice on advice utilization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schultze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Rakotoarisoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulz-Hardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgment &amp; Decision-making</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Cueing and cognitive conflict in judge-advisor decision-making. Organizational behavior and human decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Sniezek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Buckley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="159" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">High-performance medicine: the convergence of human and artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="56" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The anchor integration model: A descriptive model of anchoring effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Schley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="https://www.sae.org/standards/content/j3016_202104" />
		<title level="m">The Society of Automotive Engineers. Taxonomy and definitions for terms related to driving automation systems for on-road motor vehicles J3016-202104</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Do humans trust advice more if it comes from ai? an analysis of human-ai interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vodrahalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Daneshjou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gerstenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the 2022 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2022-07" />
			<biblScope unit="page" from="763" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Advice taking in decision making: Egocentric discounting and reputation formation. Organizational behavior and human decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yaniv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kleinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="260" to="281" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
