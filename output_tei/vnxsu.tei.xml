<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-parameter utility and drift-rate functions conflate attribute weights and choice consistency</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Krajbich</surname></persName>
							<email>krajbich.1@osu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology Department of Economics</orgName>
								<orgName type="institution">The Ohio State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-parameter utility and drift-rate functions conflate attribute weights and choice consistency</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Standard decision models include two components: subjective-value (utility) functions and stochastic choice rules. The first establishes the relative weighting of the attributes or dimensions and the second determines how consistently the higher utility option is chosen. For a decision problem with M attributes, researchers often estimate M-1 utility parameters and separately estimate a choice-consistency parameter. Instead, researchers sometimes estimate M parameters in the utility function and neglect choice consistency. I argue that while these two approaches are mathematically identical, the latter conflates utility and consistency parameters, leading to ambiguous interpretations and conclusions. At the same time, behavior arises from the interaction of utility and consistency parameters, so for choice prediction they should not be considered in isolation. Overall, I advocate for a clear separation between utility functions and stochastic choice rules when modeling decision-making, and reinforce the notion that researchers should use M-1 parameters for M-attribute decision problems.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In recent years, researchers have been increasingly using mathematical models to study choice behavior. Static models attempt to explain choice outcomes, while sequential sampling models such as the drift diffusion models (DDM), attempt to explain both choice outcomes and reaction times (RT). Both approaches model the tradeoffs between attributes of the choice problem, either with a utility/subjective-value function in the static case, or with a drift-rate function in the dynamic case 1 .</p><p>Nearly all choice problems involve tradeoffs between attributes 2 . What determines a person's preference is their exchange rate between the attributes, i.e. how much they weigh one attribute compared to the other(s). For example, a person may like oranges twice as much as they like apples. In that case, the simplest utility or drift-rate function to describe that person would be ( , ) = 2 + , where o denotes the number of oranges and a denotes the number of apples. Importantly, utility and drift-rate are both ordinal rather than cardinal, and are invariant to affine transformations. In other words, the same preferences could be described by ( , ) = 4 + 2 , ( , ) = 2 + + 1, or more generally ( , ) = (2 + ) + where b and c are arbitrary constants.</p><p>Some recent papers using DDMs have used two-parameter drift-rate functions in two-attribute tasks. For example, <ref type="bibr" target="#b4">Hutcherson et al., (2015)</ref> use a drift function = /012 ($ ) + 89:0; ($ ℎ ) to model social preferences: allocating money between oneself and another; a follow-up paper uses the same function but adds an additional term for inequality <ref type="bibr" target="#b9">(Teoh et al., 2020)</ref>. Another article used a drift function = ( ℎ) + ( ) to model food choice, weighing health considerations against taste <ref type="bibr" target="#b3">(Enax et al., 2016</ref>). Yet another article used a drift function = E ( ) + J ( ) to model intertemporal choices, weighing the amount of money against the time to receive it <ref type="bibr" target="#b0">(Amasino et al., 2019)</ref>.</p><p>parameters. The formulations above are not incorrect, but because of the way they are written, these functions entice the reader/analyst to treat a one-dimensional problem as if it was two-dimensional (or more generally an M-1 dimensional problem as if it was M dimensional). In other words, these tasks have a single tradeoff and yet the models have two weight parameters. Just as one cannot answer the question "how much do you value money?" without asking "relative to what?", one cannot talk about the weights on both self and other payoffs (only self relative to other), the weights on money and time (only money relative to time), or the weights on taste and health (only taste relative to health), without something else to compare them to. <ref type="bibr">3</ref> In these M-parameter formulations, the extra parameter comes from eliminating the choice consistency parameter from the stochastic choice function (typically the inverse-temperature parameter in a logit choice function, or the drift-rate scaling factor in the DDM). Importantly, the tradeoff between attributes should be independent from the consistency with which a person chooses in line with their utility or drift-rate. In theory, one can measure the tradeoff between attributes by asking for the exchange rate directly, for example, "how many apples do you require in order to give up an orange?"</p><p>The problem that can arise from the M-parameter utility function, as opposed to the M-1 parameter version, is that all M parameters then reflect choice consistency. When comparing parameter values across individuals or groups, researchers may come to misleading conclusions. For example, a researcher studying age differences in health vs. taste considerations might find larger weights on health in older individuals and conclude that they are more health conscious, when in reality they are simply more consistent in what they eat (reflected by larger weights on taste as well). To examine the importance of health, the researcher would instead need to examine the ratio of the health weight to the taste weight. This is not an idle concern. For example, <ref type="bibr" target="#b9">Teoh et al. (2020)</ref> report that a larger weight on others' outcomes negatively correlates with selfish gaze biases. However, because they used an M-parameter utility function, the weight on others' outcomes also reflects choice consistency. Thus, an alternative possibility is that individuals with larger selfish gaze biases are less consistent in their choices. Similarly, the authors also conclude that time pressure increases the weights on one's own outcomes and on fairness, but an alternative possibility is that time pressure increases choice consistency. The use of M-parameter utility functions can clearly complicate the interpretation of modeling results.</p><p>Below I outline the basic ambiguity involved in simultaneously estimating preferences and choice consistency, and I propose a simple rule when using such approaches. In particular, I</p><p>argue that one should use M-1 parameters for an M-attribute decision problem. At the same time, researchers need to keep in mind that utility and drift-rate function parameters interact with choice consistency parameters to determine choice outcomes and RTs. Thus, the decision of whether to analyze the decision parameters in isolation, or their interaction, depends on whether the researcher is interested in the underlying preferences or the resulting behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Utility function + Logit</head><p>Despite the power gained by leveraging RT data to enhance our understanding of behavior, it is important to keep in mind that many of the limitations of the utility-function approach also apply to the DDM. Utility functions allow decision analysts to estimate how people trade off different attributes against each other; they establish an "exchange rate" between the attributes in play 4 . The practical implication of this fact is that there is a fixed number of parameters that a utility function can have. For a decision problem with M attributes, the utility function should have at most M-1 free parameters 5 . For each additional attribute beyond the first, we need exactly 1 parameter to establish that attribute's exchange rate with the first.</p><p>chose perfectly consistently, it would be impossible to identify more than M-1 parameters.</p><p>Instead, researchers often use a logit function to model how consistently individuals choose in line with their utility function.</p><p>Take a simple example from the social preference literature, where we are interested in how much a person weighs their own payoff relative to another person's payoff. We can write their utility function as:</p><formula xml:id="formula_0">T V , W X = V + W</formula><p>where V denotes the decision-maker's payoff, W denotes the other's payoff, and is the exchange rate between self and other 6 .</p><p>We can then write their logit choice function for accepting a particular allocation of money between self and other as:</p><formula xml:id="formula_1">( ) = 1 1 + \](^_`a^b)</formula><p>The logit function itself has an "inverse temperature" parameter ( ) that captures the decision maker's consistency (i.e. how often they choose in line with their utility function), as a function of the utility. 7 However, we can use simple algebra to distribute , yielding:</p><formula xml:id="formula_2">( ) = 1 1 + \]^_\]a^b</formula><p>We can define = , leaving us with what looks like a two-parameter utility function:</p><formula xml:id="formula_3">T V , W X = V + W</formula><p>This is merely an illusion. To give our utility function two parameters, we have sacrificed our ability to estimate a separate inverse temperature parameter. In other words, is not really a weight on V ; it is just the inverse temperature parameter in disguise. Moreover, the weight on W now also contains the inverse temperature parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DDM analogue</head><p>When we move to the DDM, we are in a very similar situation. The analogy to the logit example is particularly compelling when one considers that the DDM yields a logit choice function <ref type="bibr" target="#b10">(Webb, 2018)</ref>.</p><p>As with a utility function + logit implementation, a drift rate function has two components: the relative weights of the attributes and the choice consistency (i.e. the rate at which the person chooses in the direction of the drift).</p><p>Consider the example above. To implement a DDM for this type of decision we would typically fix the within-trial noise parameter at = 0.1, estimate the boundary separation a, and then also estimate a drift function:</p><formula xml:id="formula_4">= * ( V + W )</formula><p>one-parameter utility function over the two-parameter utility function, since the former would still allow us to estimate , while the latter would yield = = ∞, telling us nothing about the exchange rate between V and W .</p><p>where is a scaling factor that determines how quickly/consistently the decision variable hits the correct boundary for a given decision problem <ref type="formula">(</ref> </p><formula xml:id="formula_5">= V + W</formula><p>And as before, this is merely an illusion. To give our drift function two parameters, we sacrificed our ability to estimate the scaling parameter. here is not a weight on V it is just the scaling parameter in disguise. Similarly, the weight on W contains the scaling parameter too.</p><p>One can unveil this illusion even more clearly by noting that the DDM is fundamentally not fully identifiable. That is, the units of "evidence" in the model are arbitrary, which means that we are forced/free to set one of the parameters { , a, } equal to a constant. In this case we chose to follow the convention of setting = 0.1 <ref type="bibr" target="#b7">(Ratcliff, 1978)</ref>, but we could just as easily have tried to fit . Had we tried to fit {a, } as well as our two-parameter utility function with { , },</p><p>we would be in a serious bind; there would be an infinite set of best-fitting parameters. For example, a model with = 1, = 1, = 1, and = 0.5 is identical to a model with = 2, = 2 , = 2, and = 1. If we did not want to set a or to a constant, we would be forced to abandon our two-parameter drift function in favor of a single-parameter one.</p><p>In other words, an arbitrary modeling choice on the part of the analyst can make it impossible to estimate an M parameter drift function for a decision problem with M attributes. As with the utility + logit approach, one can really only estimate M-1 drift-function parameters for an M attribute choice problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A simple solution for existing results with M-parameter functions</head><p>If a researcher has already run their analysis, or are using, for example, a logistic regression, they may be stuck with parameters on all the attributes. However, this does not mean that the results need to be analyzed or written up that way. Suppose the following model has been run:</p><formula xml:id="formula_6">= V + W</formula><p>All one needs to do is to divide through by or and this will separate out the scaling/temperature parameter from the preference component 9 :</p><formula xml:id="formula_7">= ( V + W )</formula><p>Then one can report the preference parameter l m = , and separately, the scaling/temperature parameter . Note that one needs to know both parameters in order to quantify how much an increase in W or V will change behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>When researchers use utility functions or drift functions with M parameters for M-attribute problems, they are not wrong, but they have to recognize that those parameters reflect a mix of relative weights between attributes and overall choice consistency. Thus, those parameters 9 One might wonder whether it matters whether you divide through by or . The answer is that globally it does not matter, but locally one does need to be consistent about it within a study. An easy way to see this is to again think of the preference parameter as an exchange rate: think of V as being money in USD and W as being money in Euros. Because drift rates and exponents are unitless this means that is in units of USD -1 and is in units of Euros -1 . If you factor out then you are using USD as your units within the parentheses and your preference parameter cannot simply be thought of as weights on attributes. So, to reduce ambiguity, I recommend sticking to the simple rule: when you have M attributes, only fit M-1 utility or drift-rate function parameters. If a researcher is more interested in behavior than in the underlying preferences, they can always additionally consider the interaction between the utility/drift parameters and the choice consistency parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relationship between inverse temperature and DDM parameters</head><p>In the DDM, there is a fundamental identification problem where we can only fit two out of three of the parameters: drift multiplier, boundary separation, and within-trial noise. In the standard formulation of the DDM, people assume the within-trial noise parameter is constant across conditions. After accounting for non-decision time, the boundary separation parameter can be estimated purely from RT, by looking at the RT distribution for trials where drift rate is zero (i.e. where the subject is indifferent). The drift multiplier can then be estimated based on the accuracy data, conditional on the estimated boundary separation. So, in the standard DDM formulation, the drift multiplier (multiplied by boundary separation) is analogous to the inverse temperature parameter in the logit. One can derive similar relationships for other formulations.</p><p>For example, if we set the boundary separation constant across conditions (as in the aDDM; <ref type="bibr">Krajbich, Armel, &amp; Rangel, 2010)</ref>, then it is the within-trial noise parameter that can be determined from the RTs (in trials where the drift rate is zero), and the drift multiplier (divided by the noise) again is analogous to the inverse temperature in the logit. Note that all of this assumes no across-trial variability in starting point, drift rate, or non-decision time; parameters that are often also fit in DDM studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models with attributes that enter at different times (i.e. latency models)</head><p>Recently some papers have introduced the idea that attributes enter the drift rate at different points in time <ref type="bibr" target="#b6">(Maier et al., 2020)</ref>. For instance, <ref type="bibr" target="#b8">Sullivan et al. (2014)</ref> argue that in food decisions, tastiness is considered earlier than healthiness. Similarly, <ref type="bibr" target="#b0">Amasino et al. (2019)</ref> argue that in temporal discounting decisions, patient subjects consider amounts earlier than delays.</p><p>The question is whether such models are subject to the same criticism presented in this paper.</p><p>The answer is yes.</p><p>First consider the simpler modeling exercise using just the utility + logit approach discussed earlier. For decisions that terminate before the latency for the second attribute, one would estimate the following logistic regression:</p><formula xml:id="formula_8">( ) = 1 1 + \](^_)</formula><p>Here would represent how often the subject chooses "accept" when V is positive.</p><p>Essentially, here captures the alignment between choice and attribute V when not considering the other attribute(s).</p><p>Separately, on decisions that terminate after the latency for the second attribute, one would estimate a different logistic regression: <ref type="bibr">`a^b)</ref> Note that here would take on a different value than in the first logit, unless W is nonpredictive of choice. In other words, incorporating additional information (i.e. the second attribute) will change how consistently the decision-maker chooses. Clearly, it would still be misleading to think of either as an absolute weight on V .</p><formula xml:id="formula_9">( ) = 1 1 + \](^_</formula><p>The DDM case is analogous. Up until the latency for the second attribute, one would model the drift rate as:</p><formula xml:id="formula_10">= * ( V )</formula><p>Here would represent how quickly the decision variable approaches the choice threshold for a given value of V , ignoring the other attribute(s).</p><p>After the latency period, one would then estimate a different drift rate:</p><formula xml:id="formula_11">= * ( V + W )</formula><p>As in the logit case, here would take on a different value than in the first case. Just like with the logit, incorporating more information should change the drift rates. As above, it would still be misleading to think of either value as an absolute weight on V .</p><p>When estimating these parameters in a DDM, <ref type="bibr" target="#b0">Amasino et al. (2019)</ref> estimate a single under the implicit assumption that in the first case is equal to in the second case. This is a restriction in the model, which amounts to saying that considering additional information does not change choice consistency. It is possible that this kind of restriction may lead to inaccurate parameter estimates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>lm</head><label></label><figDesc>is in units of USD per Euro. On the other hand, if you factor out then you are using Euros as your units within the parentheses and your preference parameter m l is in units of Euros per USD. Similarly, in the preference domain, one can talk about tradeoffs between money and time as $ per day or days per $, or between taste and health as lip-licks per calorie or calories per lip-lick.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>V + W ) and boundary separation a.8    So, what we are left with is a drift function that looks almost exactly like what we had in the logit equation above. Just like in that case, we can distribute the parameter through the</figDesc><table><row><cell>equation and we're left with</cell><cell></cell></row><row><cell></cell><cell>= V +</cell><cell>W</cell></row><row><cell>Similar to before, we can define =</cell><cell cols="2">which leaves us with what looks like a two-parameter</cell></row><row><cell>drift function:</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In the DDM, the drift rate determines how evidence accumulates over time towards one of two possible decision boundaries.2 One notable exception is learning, where the tradeoff is instead between exploring and exploiting.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This issue has also appeared in the literature on model-based (MB) vs. model-free (MF) reinforcement learning. In early years, this tradeoff was modeled as * NO + (1 − ) * NQ , but recently some researchers have switched to modeling it as NO * NO + NQ * NQ<ref type="bibr" target="#b1">(Decker et al., 2016)</ref>. Here Q refers to the learned value of an alternative, based either on the MB or MF system.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Here I am assuming a linear utility function; for more complex functions the problem is more nuanced.5  This assumes no intercept in the utility function. If there is an intercept, that adds one additional parameter. However, this should not affect any arguments in the paper.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Note that the choice of where to put is arbitrary; we could just as easily have put it in front of V .7  In keeping with the idea that decision makers always maximize utility, is meant to capture the weight on the attributes in the modeled utility function, relative to the attributes that are not modeled in the utility function. This means that the value of depends both on the units of V , but also on which attributes appear in the utility function. The more predictive the modeled attributes, the higher should be. In the limit where the utility function perfectly explains all of a subject's choices, = ∞. In this scenario one can see a clear advantage for the</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Note that the estimation of the boundary separation can be done independently, based on the RT distribution when the drift rate is zero, i.e. when V = − W .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Thanks to Dianna Amasino, Scott Huettel, Nicolette Sullivan for multiple rounds of comments on earlier drafts, and Cendri Hutcherson, Antonio Rangel, Bernd Weber, Todd Hare, Fadong Chen, and Arkady Konovalov for comments and conversations. Thanks also to the Cattel Sabbatical Fund and the National Science Foundation Career Award 1554837 .</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Amount and time exert independent influences on intertemporal choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Amasino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kranton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Huettel</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0537-2</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0537-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">From Creatures of Habit to Goal-Directed Learners: Tracking the Developmental Emergence of Model-Based Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="848" to="858" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0956797616639301</idno>
		<ptr target="https://doi.org/10.1177/0956797616639301" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Salient nutrition labels increase the integration of health attributes in food decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Enax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="460" to="471" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Neurocomputational Model of Altruistic Choice and Its Implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hutcherson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bushong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="451" to="462" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2015.06.031</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2015.06.031" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dissociable mechanisms govern when and how strongly reward attributes affect decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">U</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raja Beharelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Polanía</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Hare</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-020-0893-y</idno>
		<ptr target="https://doi.org/10.1038/s41562-020-0893-y" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="949" to="963" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A theory of memory retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="59" to="108" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dietary Self-Control Is Related to the Speed With Which Attributes of Healthfulness and Tastiness Are Processed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hutcherson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="page">0956797614559543</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attentional priorities drive effects of time pressure on altruistic choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Teoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hutcherson</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-020-17326-x</idno>
		<ptr target="https://doi.org/10.1038/s41467-020-17326-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The (Neural) Dynamics of Stochastic Choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Webb</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.2017.2931</idno>
		<ptr target="https://doi.org/10.1287/mnsc.2017.2931" />
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="230" to="255" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
