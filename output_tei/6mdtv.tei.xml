<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Waiting for Baseline Stability in Single-Case Designs: Is It Worth the Time and Effort?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">J</forename><surname>Lanovaz</surname></persName>
							<email>marc.lanovaz@umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="laboratory">École de psychoéducation</orgName>
								<orgName type="institution">Université de Montréal</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Centre de recherche de l&apos;Institut universitaire en santé mentale de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Primiani</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">École de psychoéducation</orgName>
								<orgName type="institution">Université de Montréal</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Centre de recherche de l&apos;Institut universitaire en santé mentale de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Université de Montréal</orgName>
								<address>
									<addrLine>C.P. 6128, succursale Centre-Ville</addrLine>
									<postCode>H3C 3J7</postCode>
									<settlement>Montreal</settlement>
									<region>QC, Canada</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Waiting for Baseline Stability in Single-Case Designs: Is It Worth the Time and Effort?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.3758/s13428-022-01858-9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>AB design</term>
					<term>baseline</term>
					<term>data analysis</term>
					<term>machine learning</term>
					<term>n-of-1 trial</term>
					<term>single-case design</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Researchers and practitioners often use single-case designs (SCDs), or n-of-1 trials, to develop and validate novel treatments. Standards and guidelines have been published to provide guidance as to how to implement SCDs, but many of their recommendations are not derived from the research literature. For example, one of these recommendations suggests that researchers and practitioners should wait for baseline stability prior to introducing an independent variable. However, this recommendation is not strongly supported by empirical evidence. To address this issue, we used Monte Carlo simulations to generate graphs with fixed, response-guided, and random baseline lengths while manipulating trend and variability. Then, our analyses compared the Type I error rate and power produced by two methods of analysis: the conservative dualcriteria method (a structured visual aid) and a support vector classifier (a model derived from machine learning). The conservative dual-criteria method produced fewer errors when using response-guided decision-making (i.e., waiting for stability) and random baseline lengths. In contrast, waiting for stability did not reduce decision-making errors with the support vector classifier. Our findings question the necessity of waiting for baseline stability when using SCDs with machine learning, but the study must be replicated with other designs to support our results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Waiting for Baseline Stability in Single-Case Designs: Is It Worth the Time and Effort?</head><p>Researchers in the healthcare and behavioral sciences are increasingly using single-case designs (SCD) to develop and validate novel treatments <ref type="bibr">(McDonald &amp; Nickles, 2021;</ref><ref type="bibr" target="#b27">Rader et al., 2021)</ref>. When testing the effects of a treatment or intervention, SCDs aim to demonstrate the presence of a functional relation between the introduction of a treatment and a change in behavior or other relevant outcomes <ref type="bibr" target="#b13">(Horner et al., 2005;</ref><ref type="bibr" target="#b30">Tate and al., 2013)</ref>. At this point, the reader should note that that the utility of these designs is not limited to researchers: Practitioners may also use SCDs to monitor the effects of treatment or intervention <ref type="bibr" target="#b24">(Mitteer et al., 2018)</ref>. In SCDs, an experimenter exposes one or more participants to two or more conditions. The first condition (Phase A), which is comparable to the control group in a group design, consists of repeatedly measuring the dependent variable (e.g., behavior, product) prior to introduction of treatment. On the other hand, Phase B involves the implementation of the treatment while continuing the repeated measurement of the dependent variable <ref type="bibr" target="#b21">(Ledford &amp; Gast, 2018)</ref>. This sequence, referred to as an AB comparison, is particularly important in SCDs because it represent the basic unit of multiple experimental designs. For example, the AB comparison is central to the demonstration of functional relations in reversal (ABAB) designs, in multiple baseline designs, and in changing-criterion designs.</p><p>When analyzing the repeated changes between Phases A and B, researchers and practitioners may identify the presence of a functional relation if the independent variable generates reliable and consistent changes in the dependent variable <ref type="bibr" target="#b12">(Fisher et al., 2003;</ref><ref type="bibr" target="#b34">Vannest et al., 2018)</ref>. When assessing the effects of a treatment, the demonstration of a functional relation indicates that it is at least partly effective. On the contrary, the lack of a functional relation indicates that the treatment may be ineffective. To conduct these analyses, many researchers and practitioners use visual inspection despite its limitations and sometimes poor accuracy <ref type="bibr" target="#b7">(Falligant et al., 2020;</ref><ref type="bibr" target="#b18">Lanovaz &amp; Hranchuk, 2021;</ref><ref type="bibr" target="#b25">Ninci et al., 2015)</ref>. Visual raters rely on multiple data features to help them identify the presence of a functional relation such as comparing level, trend, variability, consistency and overlap across phases <ref type="bibr" target="#b15">(Kratochwill et al., 2010;</ref><ref type="bibr" target="#b23">Manolov &amp;Vannest, 2019)</ref>. A function relation is said to exist when one or more of these characteristics change consistently across replications <ref type="bibr" target="#b20">(Ledford et al., 2019)</ref>.</p><p>When implementing SCDs, researchers and practitioners typically follow guidelines to design their procedures. For example, What Works Clearinghouse (WWC; 2020) developed the most highly cited guidelines <ref type="bibr" target="#b15">(Kratochwill et al., 2010)</ref>, which provide guidance how to implement SCDs. When using SCDs, an issue that researchers and practitioners must deal with involves trend stability during baseline. That is, too much trend during baseline may obscure changes observed in subsequent phases. One solution proposed by the original WWC guidelines involves "waiting to see whether the [baseline] series stabilizes as more data are gathered" <ref type="bibr">(Kratochwill et al., 2010, p.19-20)</ref>. This manipulation facilitates the comparison of patterns across phases, especially when using visual inspection. Some of the most popular introductory textbooks for teaching single-case designs (e.g., <ref type="bibr" target="#b1">Barlow et al., 2009;</ref><ref type="bibr" target="#b6">Cooper et al., 2020;</ref><ref type="bibr" target="#b14">Kazdin 2011;</ref><ref type="bibr" target="#b21">Ledford &amp; Gast, 2018)</ref> also recommend waiting for baseline stability prior to introducing treatment.</p><p>Although this "response-guided" approach is commonly recommended, waiting for stability may lead to reductions in variance, which may have an impact on the analyses <ref type="bibr">(Swan et al., 2021)</ref>. Furthermore, having an experimenter selecting the "right" time to introduce a baseline may actually increase Type I error rates when using visual inspection and randomization tests <ref type="bibr" target="#b0">(Allison et al., 1992;</ref><ref type="bibr" target="#b4">Byun et al., 2017;</ref><ref type="bibr" target="#b9">Ferron et al., 2003;</ref><ref type="bibr" target="#b33">Todman &amp; Dugard, 1999)</ref>. In other words, waiting for stability may increase the probability of concluding that a graph shows a change when no true change has occurred. Nevertheless, the extent to which response-guided decisions in baseline increase Type I error rate remains to be further validated with analyses methods beyond randomization tests and visual inspection.</p><p>Recently, researchers have examined the use of a blind response-guided approach to analyze multiple baseline graphs, which was referred to as masked visual analysis <ref type="bibr" target="#b10">(Ferron et al., 2017)</ref>. Masked visual analysis involves randomly introducing the independent variable within a random tier of a multiple baseline design when data show stability in all tiers, and subsequently introducing it in other tiers when the visual raters conclude that the treatment was introduced in a tier. Then, the probability of the blind raters specifying the correct treatment order at random can be computed. If this value is less than .05 and the blind raters identify the correct treatment order, researchers may deem that the graphs as showing a clear functional relation. Promisingly, the masked visual analysis can be applied to a variety of designs such as multiple baseline, reversal, and changing-criterion designs <ref type="bibr" target="#b4">(Byun et al., 2017;</ref><ref type="bibr" target="#b8">Fallon et al., 2020;</ref><ref type="bibr" target="#b10">Ferron et al., 2017;</ref><ref type="bibr" target="#b11">Ferron et al., 2019;</ref><ref type="bibr" target="#b10">Joo et al., 2017)</ref>. That said, the main limitation of masked visual analysis is that it continues to rely on visual inspection, which does not always produce consistent results and is difficult to apply on very large datasets <ref type="bibr" target="#b12">(Fisher et al., 2003;</ref><ref type="bibr" target="#b18">Lanovaz &amp; Hranchuk, 2021;</ref><ref type="bibr">Wolfe et al., 2016)</ref>.</p><p>Our study examined the effects of response-guided decision-making on the most basic unit of analysis, the AB comparison. Given that the multiple baseline, reversal, and changingcriterion designs are based on the repetition of this unit, studying how waiting for baseline stability affects decision-making errors in AB designs may produce results that are generalizable to multiple experimental designs. As indicated earlier, prior studies on the topic have limited their analysis to randomization tests and visual inspection. However, multiple other methods exist to analyze single-case graphs. To extend prior research, we selected two methods that have never been used to examine response-guided decision making for single-case designs: the conservative dual-criteria (CDC; <ref type="bibr" target="#b12">Fisher et al., 2003)</ref> and machine learning <ref type="bibr" target="#b18">(Hranchuk &amp; Lanovaz., 2021)</ref>. Both these methods perform well with short data series, which may make them relevant methods to examine the effects of response-guided decisions. Analysis methods may behave differently on graphs with various characteristics (e.g., trend vs. no trend), which is why testing more than one method appears important <ref type="bibr" target="#b23">(Manolov &amp; Vannest, 2019)</ref>. In sum, our study compared the Type I error rate and power of two methods of analyses for AB graphs with fixed baseline lengths, response-guided baseline lengths, and random baseline lengths for sets of graphs with different characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1 -Waiting for Stability in Trend</head><p>One type of stability in single-case designs involves trend. When using single-case designs, researchers and practitioners typically wait for baseline to show minimal-to-no trend before introducing the independent variable <ref type="bibr">(Ledford &amp; Gast, 2016)</ref>. The purpose of the first experiment was to examine the effects of waiting for baseline trend stability in datasets that showed an initial trend resulting from random variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The first step of the method involved generating time series and AB graphs by conducting Monte Carlo simulations. Next, we applied the CDC method and the support vector classifier (i.e., a machine learning algorithm) to determine whether each graph showed an effect or not. Finally, our analyses compared Type I error rates and power across graphs with fixed, response-guided, and random baseline lengths. All our code is freely available under a MIT permissive software license: https://doi.org/10.17605/OSF.IO/H7BSG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monte Carlo Simulation</head><p>Our study used a Monte Carlo approach to simulate a total of 160,000 time series that contained 30 points each. To generate our time series, we programmed Python (version 3.7.7) to use the following formula:</p><formula xml:id="formula_0">= + 10 where = −1 +</formula><p>In the formula, xt represents the autocorrelated value at time point t, which is composed of (a) the autocorrelated value from the previous time point, xt -1, (b) a lag 1 autocorrelation of a, and (c) an error term, εt, randomly generated from a normal distribution with a mean of 1 and standard deviation of 0. To produce our final values, yt, the code added a constant of 10 to prevent graphs with negative values. Half the time series contained no autocorrelation whereas the other half had an autocorrelation value of 0.4, which is the approximate mean autocorrelation reported in a recent study on single-case graphs <ref type="bibr" target="#b2">(Barnard-Brak et al., 2021a)</ref>. We focused on first-order autocorrelations as more proximal events tend to produce larger effects than more distal events when analyzing behavior <ref type="bibr" target="#b6">(Cooper et al., 2020)</ref>. Each initial time series contained exactly 30 points.</p><p>As the purpose of our study was to examine whether waiting for stability produced more or fewer errors than simply implementing the treatment when the trend was still unstable, our analyses required initially unstable time series. During data generation, we only kept time series that showed a trend above a maximum absolute threshold after a specific minimum number of points in baseline. The maximum allowable absolute threshold was set at 15 degrees for half the time series and at 30 degrees for the other half. The minimum number of points for Phase A was equally distributed with values of either 3 or 5. We selected these values because applied researchers and practitioners typically want to reduce their number of baseline sessions to minimize the inconvenience to their clients <ref type="bibr" target="#b19">(Lanovaz et al., 2017)</ref>. The code involved a loop that continued creating novel 30-point series that met the previous criteria. As an example, assume that the maximum allowable trend was 30 degrees and the series had to have a minimum of 5 points in baseline. In this case, we would only keep a time series if it showed a trend larger than 30 degrees, or smaller than -30 degrees, after five points.</p><p>The next step involved transforming these time series to AB graphs. Each 30-point data series yielded three separate AB graphs. The first graph involved setting the number points in Phase A at the minimum (i.e., three or five), which yielded a graph with a fixed baseline length.</p><p>Then, we added either 5 or 10 points in Phase B to the graph because treatment phases tend to be longer than baseline phases. Therefore, the AB graph did not use all the points from the times series. For example, a graph with three points in Phase A and ten points in Phase B would only use the first 13 points in the time series 1 for the fixed baseline length. For half the series, we added a standardized mean difference (SMD) value to Phase B, which simulated an effect to test for power. This SMD value was uniformly distributed integers from 1 to 5, inclusively. For the other half of the series, we did not simulate an effect (SMD = 0) to examine Type I error rate.</p><p>The second graph required waiting for stability using the same time series (i.e., responseguided decision to terminate Phase A). That is, Phase A ended when the trend was below the absolute value of the maximum allowable trend. Thus, the response-guided graphs always contained more points in Phase A than the fixed baseline graphs. The other values (i.e., number of points in Phase B and SMD) remained the same as for the first graph designed using the same time series. Using the same time series and keeping the other values constant allowed us to control the effects of waiting for stability. If Phase A achieved stability after seven points and the Phase B was set at ten points, the response-guided AB graph would contain 17 points (i.e., the first 17 points of the same 30-point series).</p><p>The third graph consisted of randomly selecting the number of points in Phase A. To control for the potential confound of phase lengths, the frequency distribution of these phase lengths were exactly the same as the one for the response-guided graphs. That is, we picked the phase lengths randomly without replacement from the distribution of phase lengths observed in the responded-guided baselines. The SMD and number of points in Phase B remained the same as for the first and second graphs derived from the same time series.</p><p>Our code repeated this process for 160,000 times series creating an initial dataset containing a total of 480,000 AB graphs. <ref type="table">Table 1</ref> presents the characteristic distributions of these times series. Note that the characteristics of the time series graphs were perfectly counterbalanced to control for interaction effects. Our dataset contained 5,000 time series for each combination of characteristics showing no effect and 5,000 times series for each set of characteristics simulating an effect (i.e., 1,000 for each of the five SMD values).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyses</head><p>To identify whether each graph showed a clear change, we applied the two objective methods that have been shown to perform best on baseline with few data points: the CDC method <ref type="bibr" target="#b12">(Fisher et al., 2003)</ref> and a support vector classifier developed by <ref type="bibr" target="#b18">Lanovaz and Hranchuk (2021)</ref>. The CDC relies heavily on level and trend whereas the support vector classifier considers additional dimensions of data analysis such as variability. The CDC method involved tracing a continuation of mean and trend lines from Phase A unto Phase B and increasing their height by 0.25 standard deviations. Then, we counted the number of points that fell above points lines. If this number of points was equal or higher than a threshold based on the binomial distribution, the graph was labeled as showing an effect. Otherwise, the graph was categorized as showing no effect.</p><p>The support vector classifier is a machine learning algorithm that involves projecting the data into a higher dimension and then separating them with a hyperplane (i.e., a plane projected in more than two dimensions). The current study did not train the classifier: we simply downloaded the model previously developed by <ref type="bibr" target="#b18">Lanovaz and Hranchuk (2021)</ref> and applied it to our data. Prior to its application, our code transformed the graphs to z scores and extracted the eight features required by the classifier: means of Phases A and B, standard deviations of Phases A and B, intercept and slope of Phase A, and intercept and slope of Phase B. Based on this input, the classifier categorized each graph as either showing an effect (1) or showing no effect (0).</p><p>Our initial analysis involved examining Type I error rate and power across graphs having the minimum number of points (i.e., fixed graphs), response-guided graphs, and graphs having a random number of points in Phase A. Computing Type I error involved dividing the number of graphs with a SMD of 0 that showed an effect according to the method of analysis (i.e., CDC or support vector classifier) by the total number of graphs with a SMD of 0. This measure represents the probability of concluding that a graph shows an effect when the graph includes no true effect (false positives). To compute power, we instructed Python to divide the number of graphs with a SMD of 1 or more that showed an effect according to the method of analysis by the total number of graphs with a SMD of 1 or more. Power identifies the proportion of graphs with a true effect that were correctly categorized as such by each method of analysis.</p><p>Following our main analysis, we examined the effects of initial confounding trend (i.e., decreasing or increasing) on Type I error rate and power. This analysis assumed that the initial trend (i.e., trend following the minimum number of points) could differentially affect each method. The final analysis involved examining the impact of each characteristic manipulated during time series generation: minimum number of points in Phase A, number of points in Phase B, autocorrelation, maximum absolute allowable trend, and standardized mean differences. The analyses were conducted twice: once for the dataset generated with the normal distribution and a second time for the dataset generated with the uniform distribution were</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>Figure 1 presents that Type I error rate and power for the graphs having the minimum number of points (fixed), response-guided graphs, and graphs with a random number of points in Phase A. For the CDC method, the responded-guided graphs produced marginally more Type I errors than the fixed and random baseline graphs. Graphs with fixed baseline lengths had significantly less power than response-guided and random graphs when applying the CDC. In contrast, the support vector classifier produced consistent results for Type I error rate and power regardless of baseline length. <ref type="figure">Figure 2</ref> depicts Type I error rate and power according to the direction of the initial trend. For both methods of analysis, we observed more Type I errors and more power when the trend was initially decreasing. Notably, the CDC method produced Type I error rates above .05 in this case. The difference between graphs with increasing and decreasing trends is also larger for the CDC method than for the support vector classifier. <ref type="table" target="#tab_1">Table 2</ref> shows the Type I error rate and power based on the minimum number of points in Phase A. Generally, increasing the number of points in Phase A marginally decreased both Type I error rate and power. The only exception is the higher power for fixed graphs with 5 points in Phase A using the CDC.  <ref type="table" target="#tab_4">Table 5</ref> examines the effects of manipulating the stringency of the response-guided criterion. When the maximum allowable trend was higher, power and to a lesser extent Type I error decreased. This issue was more salient for the graphs analyzed with the CDC. Finally, <ref type="table" target="#tab_5">Table 6</ref> presents the effects of increasing the standardized mean difference. For a SMD of 1, the CDC produced the highest power whereas this pattern was reversed for SMDs of 3 or more (i.e., the support vector classifier performed best). For the CDC, the response-guided graphs produced the highest power closely followed by the graphs with random baseline lengths whereas the fixed graphs produced considerably less power than the two prior categories. For the support vector classifier, power remained similar across fixed, response-guided, and random graphs.</p><p>In general, the results of the first experiment show that waiting for stability with the CDC had minimal impact on Type I error, but it considerably increased power when compared to fixed baselines. That said, randomly selecting the number of points in Phase A produced similar conclusions to response-guided decisions. Given that the random selection of points may allow for the application of randomization tests (e.g., <ref type="bibr">Levin et al., 2018)</ref>, randomly selecting the number of points in Phase A seems preferable when using the CDC. In contrast, both Type I error rate and power remained consistent regardless of baseline length when the support vector classifier analyzed the data. In others word, waiting for stability provided no additional gains for Type I error rate and power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2 -Waiting for Stability in Variability</head><p>Another dimension of single-case graphs that may show stable or unstable patterns involves variability. In single-case designs, "variability refers to the fluctuation of the data (as reflected by the data's range or standard deviation) around the mean" <ref type="bibr">(Kratochwill, 2010, p. 5</ref>).</p><p>Hence, a graph may show no trend, but still remain unstable in terms of variability <ref type="bibr" target="#b3">(Barnard-Brak et al., 2021b)</ref>. To examine this issue, we replicated our first experiment by creating datasets with high variability and examining the effects of waiting for stability on Type I error rate and power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The data generation and analysis procedures remained the same as in the first experiment with the following four changes. First, the code generated the points using a random uniform distribution ranging from -3 to 3, which produced more variable patterns than a normal distribution (i.e., more spread around the mean). This manipulation allowed us to produce graphs with higher variability. Second, the maximum allowable trend value was replaced by a maximum allowable standard deviation value, which was computed using the last three points of Phase A.</p><p>The two cut-off values were standard deviations of 1.0 and 1.5 to reduce the amount of variability. Third, the theoretical standard deviation of the uniform distribution was larger than for the normal distribution (1.73 instead of 1.00). To control for this issue, our code multiplied the SMDs by 1.73 during data generation to allow comparisons across experiments. Finally, we did not repeat the trend analysis (see <ref type="figure">Figure 2</ref>) as it was not relevant to the type of stability being studied in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>Figure 3 displays the Type I error rate (upper panel) and power (lower panel) of waiting for stability in variability during baseline. For the CDC method, having a fixed number of points produced the lowest Type I error rate whereas the random number of points produced the highest power. For the support vector classifier, Type I error rate and power remained generally consistent regardless of whether we waited for stability to introduce an effect. <ref type="table" target="#tab_6">Tables 7 and 8</ref> present the analysis for the lengths of Phases A and B, respectively. Increasing the number of points in Phase A marginally decreased Type I error rate while increasing power when using the CDC. Manipulating the lengths of Phase A had a no systematic effect on the support vector classifier. Having a larger number of points in Phase B increased both Type I error rate and power for the CDC. The support vector classifier with 10 points produced lower Type I error rates for the response-guided and random baseline lengths, and higher power for all baseline lengths. <ref type="table" target="#tab_8">Table 9</ref> presents the effects of autocorrelation while waiting for stability in variability.</p><p>For the CDC method, autocorrelation was associated with higher Type I error rate and lower power. For the support vector classifier, only Type I error increased with the addition of autocorrelation. <ref type="table" target="#tab_9">Table 10</ref> examines the stringency of our standard deviation stability criterion.</p><p>The effects of the maximum allowable standard deviation involved a small decrease in Type I error rate when the criterion was less stringent criterion (i.e., SD &lt; 1.5) for both methods of analysis. Making the criterion less stringent also decreased power with the CDC method. Finally, <ref type="table" target="#tab_10">Table 11</ref> displays the evolution of power when the value of the SMD increases. Similarly to what was observed during our trend analyses, the CDC had more power than the support vector classifier for low SMDs, but this pattern was reversed for higher SMDs (i.e., 3 or more).</p><p>Interestingly, the random baseline length showed the most power when applying the CDC method.</p><p>Once again, the second experiment suggests that the support vector classifier is less affected by changes in baseline stability than the CDC method. The results for the CDC analyses are mixed. Both the response-guided and random baseline lengths produced the highest power, but the response-guided baseline was also associated with the highest Type I error rate. Amongst the three baseline lengths, the random length produced the fewest errors overall, which suggest that the benefits of the response-guided decision-making are an artefact of longer baseline phases. For the support vector classifier, the three approaches produced similar patterns of errors and power, which questions the relevance of conducting additional baseline sessions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>The results of our study suggest that the relevance of waiting for baseline stability depends on the method of analysis being applied. For the CDC method, the response-guided and random baseline lengths typically produced fewer errors than the fixed baseline length. In contrast, the three baseline lengths yielded similar results for the support vector classifier.</p><p>Consistent with prior studies, the support vector classifier produced, on average, fewer decisionmaking errors than the CDC method <ref type="bibr" target="#b16">(Lanovaz et al., 2020;</ref><ref type="bibr" target="#b18">Lanovaz &amp; Hranchuk, 2021)</ref>. One potential explanation for the better performance and stability of the support vector classifier is that <ref type="bibr" target="#b18">Lanovaz and Hranchuk (2021)</ref> trained their model on graphs with and without trend.</p><p>Therefore, the support vector classifier "learned" to differentiate between trend and background noise. In comparison, the CDC struggled with power when the trend of data was initially increasing. This observation may be explained by the development of the CDC, which emphasized reductions in Type I error rate at the expense of power <ref type="bibr" target="#b12">(Fisher et al., 2003)</ref>.</p><p>For both methods, initially decreasing trends produced higher Type I error rates and power. Contrarily, initially increasing trends produced lower Type I error rates and power.</p><p>Conceptually, we expected these patterns because false positives are more likely when the trend is in the same direction as the expected behavior change. Moreover, changes in Type I error rate are typically accompanied by corresponding changes in power <ref type="bibr" target="#b18">(Lanovaz &amp; Hranchuk, 2021)</ref>, which explains the variations in the latter. Prior studies had shown that the number of points in Phase B, but not in Phase A, reduced Type I error rates (e.g., <ref type="bibr" target="#b7">Falligant et al., 2020;</ref><ref type="bibr" target="#b19">Lanovaz et al., 2017)</ref> when using the CDC. Our results were not consistent with prior research: Increasing the number of points in Phase A marginally reduced Type I error rate while increasing the number of points in Phase B increased Type I error rate for the CDC in both experiments. For the support vector classifier, increasing the number of points only decreased Type I error rate for Phase B when we manipulated variability (for two of three baselines). One hypothesis for why the results differ is that prior studies did not systematically introduce trends and variability in their datasets, which may have biased the results. The presence of autocorrelation increased Type I error rate for both methods, but to a greater extent for the CDC. Taken together, these results underline the robustness of using machine learning to analyze single-case data with short, fixed baseline lengths.</p><p>As discussed previously, waiting for stability did not reduce decision-making errors when using the support vector classifier. Thus, these results suggest that waiting for stability in trend and variability may not be worth the additional time and effort involved in conducting additional baseline sessions. This surprising result may reduce the effort related to baseline data collection as researchers and practitioners may simply set a minimum number of points (e.g., 3 or 5), and then start treatment (or introduce the independent variable) regardless of trend and variability when applying the support vector classifier. Reducing the number of baseline sessions may decrease the costs and limitations of implementing single-case designs in research and practice.</p><p>For example, researchers and practitioners may want to reduce to a minimum the number of baseline sessions conducted with an individual who exhibits dangerous behavior. Conducting fewer baseline sessions may also allow for the recruitment of more participants in single-case studies by reducing the cost of research per participant. In practice, publicly-funded services may be able to reduce wait lists by conducting fewer baseline sessions with each individual.</p><p>Similarly, individuals on private health plans with a coverage limit may benefit from more treatment sessions if the number of baseline sessions is reduced. As such, reducing the number of baseline sessions could produce beneficial outcomes in both research and practice.</p><p>A limitation of our study is that we did not include visual inspection, which is often described as a recommended practice in the analysis of single-case graphs <ref type="bibr" target="#b18">(Lanovaz &amp; Hranchuk, 2021;</ref><ref type="bibr" target="#b23">Manolov &amp; Vannest, 2019)</ref>. Future research should continue examining how visual inspection is affected by response-guided decision-making. Second, the stability criterion for the second experiment was based on the three last points of Phase A. This manipulation was necessary because Phase A could have as few as three points. In the future, it may be relevant to examine whether requiring a larger number of points showing stability (e.g., 5) produces differential results. Finally, we limited our analyses to AB comparisons as it is the basic unit of analysis for many single-case experimental designs. Replicating our study with single-case experimental designs (i.e., reversal designs, multiple baseline designs, and changing-criterion designs) seems essential to examine whether fixed baseline lengths with machine learning would perform the same when the effects are replicated within and across participants. Research on SCDs should also examine the relevance of other recommendations proposed by standards and guidelines to address their limitations and promote their adoptions by a growing number of researchers and practitioners.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations</head><p>Funding: This work was supported in part by a salary award from the Fonds de recherche du Québec -Santé to the first author (#269462).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of interest:</head><p>The authors have no conflicts of interest to declare that are relevant to the content of this article.</p><p>Ethics approval: This study relied exclusively on simulated data, which did not require ethical approval.</p><p>Data and code availability: The data and code generated during the current study are available in the OSF repository, https://doi.org/10.17605/OSF.IO/H7BSG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open practices statement:</head><p>The data and code for all analyses are freely available at https://doi.org/10.17605/OSF.IO/H7BSG and none of the experiments was preregistered.</p><p>What Works Clearing House. (2020). Standards handbook (version 4.1).</p><p>https://ies.ed.gov/ncee/wwc/Docs/referenceresources/WWC-Standards-Handbook-v4-1-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>508.pdf</head><p>Wolfe, K., <ref type="bibr">Seaman, M. A., &amp; Drasgow, E. (2016)</ref>. Interrater agreement on the visual analysis of individual tiers and functional relations in multiple baseline designs. Behavior <ref type="bibr">Modification,</ref><ref type="bibr">40(6)</ref>, 852-873. https://doi.org/10.1177/0145445516644699 <ref type="table">Table 1</ref> Characteristics With effect: SMD = 0 (n = 80,000) SMD = 1 (n = 16,000) SMD = 2 (n = 16,000) SMD = 3 (n = 16,000) SMD = 4 (n = 16,000) SMD = 5 (n = 16,000)</p><p>Note. a: autocorrelation coefficient, n: number of times series with the value, SMD: standardized mean difference.   Note. a: autocorrelation values, CDC: conservative dual-criteria, SVC: support vector classifier. Note. CDC: conservative dual-criteria, SVC: support vector classifier.  Note. CDC: conservative dual-criteria, SVC: support vector classifier. Note. CDC: conservative dual-criteria, SVC: support vector classifer. Note. a: autocorrelation values, CDC: conservative dual-criteria, SVC: support vector classifier. Note. CDC: conservative dual-criteria, SVC: support vector classifier. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3</head><label>3</label><figDesc>shows that manipulating the number of points in Phase B produced larger differential effects across methods. For the CDC, increasing the number of points in Phase B increased Type I error rate while keeping a generally consistent power. For the support vector classifier, increasing the number of points in Phase B reduced Type I error rate while increasing the power. InTable 4, Type I error increased with autocorrelation for both methods, but it reached above .05 for the CDC only. In comparison, power remained typically consistent for the support vector classifier and was marginally lower for the response-guided and random graphs for the CDC.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Type I Error Rate and Power Across Different Minimum Lengths of Phase A for Trend Stability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>3 points</cell><cell>5 points</cell><cell>3 points</cell><cell>5 points</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.053</cell><cell>.036</cell><cell>.486</cell><cell>.503</cell></row><row><cell>Response-Guided</cell><cell>.058</cell><cell>.044</cell><cell>.710</cell><cell>.652</cell></row><row><cell>Random</cell><cell>.051</cell><cell>.041</cell><cell>.651</cell><cell>.632</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.025</cell><cell>.015</cell><cell>.709</cell><cell>.686</cell></row><row><cell>Response-Guided</cell><cell>.024</cell><cell>.014</cell><cell>.715</cell><cell>.679</cell></row><row><cell>Random</cell><cell>.022</cell><cell>.013</cell><cell>.715</cell><cell>.681</cell></row><row><cell cols="4">Note. CDC: conservative dual-criteria, SVC: support vector classifier.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Type I Error Rate and Power Across Different Lengths of Phase B for Trend Stability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>5 points</cell><cell>10 points</cell><cell>5 points</cell><cell>10 points</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.030</cell><cell>.059</cell><cell>.498</cell><cell>.492</cell></row><row><cell>Response-Guided</cell><cell>.038</cell><cell>.064</cell><cell>.671</cell><cell>.690</cell></row><row><cell>Random</cell><cell>.033</cell><cell>.058</cell><cell>.634</cell><cell>.649</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.018</cell><cell>.023</cell><cell>.647</cell><cell>.748</cell></row><row><cell>Response-Guided</cell><cell>.022</cell><cell>.016</cell><cell>.676</cell><cell>.718</cell></row><row><cell>Random</cell><cell>.020</cell><cell>.015</cell><cell>.670</cell><cell>.726</cell></row><row><cell cols="4">Note. CDC: conservative dual-criteria, SVC: support vector classifer.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Type I Error Rate and Power in the Absence and Presence of Autocorrelation for Trend Stability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>a = 0</cell><cell>a = 0.4</cell><cell>a = 0</cell><cell>a = 0.4</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.033</cell><cell>.057</cell><cell>.496</cell><cell>.494</cell></row><row><cell>Response-Guided</cell><cell>.027</cell><cell>.075</cell><cell>.693</cell><cell>.668</cell></row><row><cell>Random</cell><cell>.026</cell><cell>.065</cell><cell>.654</cell><cell>.630</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.011</cell><cell>.030</cell><cell>.696</cell><cell>.699</cell></row><row><cell>Response-Guided</cell><cell>.007</cell><cell>.031</cell><cell>.701</cell><cell>.694</cell></row><row><cell>Random</cell><cell>.007</cell><cell>.028</cell><cell>.699</cell><cell>.697</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>Type I Error Rate and Power Across Maximum Absolute Trend Values Allowed for Trend Stability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>15 degrees</cell><cell>30 degrees</cell><cell>15 degrees</cell><cell>30 degrees</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.048</cell><cell>.041</cell><cell>.544</cell><cell>.445</cell></row><row><cell>Response-Guided</cell><cell>.054</cell><cell>.048</cell><cell>.749</cell><cell>.613</cell></row><row><cell>Random</cell><cell>.047</cell><cell>.044</cell><cell>.683</cell><cell>.600</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.024</cell><cell>.016</cell><cell>.716</cell><cell>.679</cell></row><row><cell>Response-Guided</cell><cell>.021</cell><cell>.017</cell><cell>.709</cell><cell>.685</cell></row><row><cell>Random</cell><cell>.019</cell><cell>.016</cell><cell>.709</cell><cell>.687</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6</head><label>6</label><figDesc>Power Across Different Standardized Mean Difference Values for Trend Stability</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Standardized Mean Difference</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>0.217</cell><cell>0.427</cell><cell>0.536</cell><cell>0.604</cell><cell>0.689</cell></row><row><cell>Response-Guided</cell><cell>0.274</cell><cell>0.563</cell><cell>0.757</cell><cell>0.869</cell><cell>0.941</cell></row><row><cell>Random</cell><cell>0.259</cell><cell>0.543</cell><cell>0.710</cell><cell>0.812</cell><cell>0.884</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>0.176</cell><cell>0.547</cell><cell>0.829</cell><cell>0.948</cell><cell>0.988</cell></row><row><cell>Response-Guided</cell><cell>0.167</cell><cell>0.545</cell><cell>0.836</cell><cell>0.949</cell><cell>0.989</cell></row><row><cell>Random</cell><cell>0.164</cell><cell>0.548</cell><cell>0.836</cell><cell>0.952</cell><cell>0.990</cell></row><row><cell cols="4">Note. CDC: conservative dual-criteria, SVC: support vector classifier.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7</head><label>7</label><figDesc>Type I Error Rate and Power Across Different Minimum Lengths of Phase A for Stability in Variability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>3 points</cell><cell>5 points</cell><cell>3 points</cell><cell>5 points</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.029</cell><cell>.027</cell><cell>.512</cell><cell>.671</cell></row><row><cell>Response-Guided</cell><cell>.040</cell><cell>.031</cell><cell>.645</cell><cell>.706</cell></row><row><cell>Random</cell><cell>.035</cell><cell>.030</cell><cell>.669</cell><cell>.720</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.013</cell><cell>.014</cell><cell>.701</cell><cell>.708</cell></row><row><cell>Response-Guided</cell><cell>.016</cell><cell>.017</cell><cell>.705</cell><cell>.699</cell></row><row><cell>Random</cell><cell>.016</cell><cell>.017</cell><cell>.706</cell><cell>.700</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8</head><label>8</label><figDesc>Type I Error Rate and Power Across Different Lengths of Phase B for Stability in Variability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>5 points</cell><cell>10 points</cell><cell>5 points</cell><cell>10 points</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.021</cell><cell>.035</cell><cell>.590</cell><cell>.593</cell></row><row><cell>Response-Guided</cell><cell>.027</cell><cell>.045</cell><cell>.667</cell><cell>.684</cell></row><row><cell>Random</cell><cell>.025</cell><cell>.040</cell><cell>.683</cell><cell>.707</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.013</cell><cell>.014</cell><cell>.661</cell><cell>.748</cell></row><row><cell>Response-Guided</cell><cell>.024</cell><cell>.010</cell><cell>.681</cell><cell>.723</cell></row><row><cell>Random</cell><cell>.024</cell><cell>.009</cell><cell>.681</cell><cell>.726</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9</head><label>9</label><figDesc>Type I Error Rate and Power in the Absence and Presence of Autocorrelation for Stability in Variability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>a = 0</cell><cell>a = 0.4</cell><cell>a = 0</cell><cell>a = 0.4</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.019</cell><cell>.037</cell><cell>.603</cell><cell>.580</cell></row><row><cell>Response-Guided</cell><cell>.024</cell><cell>.047</cell><cell>.699</cell><cell>.652</cell></row><row><cell>Random</cell><cell>.020</cell><cell>.044</cell><cell>.719</cell><cell>.670</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.005</cell><cell>.022</cell><cell>.708</cell><cell>.701</cell></row><row><cell>Response-Guided</cell><cell>.010</cell><cell>.023</cell><cell>.707</cell><cell>.697</cell></row><row><cell>Random</cell><cell>.010</cell><cell>.023</cell><cell>.706</cell><cell>.700</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10</head><label>10</label><figDesc>Type I Error Rate and Power Across Maximum Allowable Standard Deviations for Stability in Variability</figDesc><table><row><cell></cell><cell cols="2">Type I Error Rate</cell><cell>Power</cell><cell></cell></row><row><cell></cell><cell>SD &lt; 1.0</cell><cell>SD &lt; 1.5</cell><cell>SD &lt; 1.0</cell><cell>SD &lt; 1.5</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.033</cell><cell>.023</cell><cell>.605</cell><cell>.578</cell></row><row><cell>Response-Guided</cell><cell>.039</cell><cell>.032</cell><cell>.694</cell><cell>.657</cell></row><row><cell>Random</cell><cell>.035</cell><cell>.030</cell><cell>.713</cell><cell>.676</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>.017</cell><cell>.010</cell><cell>.713</cell><cell>.696</cell></row><row><cell>Response-Guided</cell><cell>.022</cell><cell>.011</cell><cell>.706</cell><cell>.698</cell></row><row><cell>Random</cell><cell>.022</cell><cell>.011</cell><cell>.705</cell><cell>.701</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11</head><label>11</label><figDesc>Power Across Different Standardized Mean Difference Values for Stability in Variability Note. CDC: conservative dual-criteria, SVC: support vector classifier. 5266 Type I Error Rate and Power Across Fixed, Response-Guided (RG), and Random Baseline Lengths for the Conservative Dual-Criteria and Support Vector Classifier for Trend Stability Type I Error Rate and Power Across Fixed, Response-Guided (RG), and Random Baseline Lengths When the Initial Trend Was Increasing and Decreasing Type I Error Rate and Power Across Fixed, Response-Guided (RG), and Random Baseline Lengths for the Conservative Dual-Criteria and Support Vector Classifier for Stability in Variability</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Standardized Mean Difference</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>CDC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>0.192</cell><cell>0.509</cell><cell>0.682</cell><cell>0.766</cell><cell>0.808</cell></row><row><cell>Response-Guided</cell><cell>0.238</cell><cell>0.587</cell><cell>0.770</cell><cell>0.864</cell><cell>0.919</cell></row><row><cell>Random</cell><cell>0.234</cell><cell>0.604</cell><cell>0.804</cell><cell>0.892</cell><cell>0.941</cell></row><row><cell>SVC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fixed</cell><cell>0.146</cell><cell>0.555</cell><cell>0.853</cell><cell>0.971</cell><cell>0.997</cell></row><row><cell>Response-Guided</cell><cell>0.149</cell><cell>0.553</cell><cell>0.849</cell><cell>0.965</cell><cell>0.995</cell></row><row><cell>Random</cell><cell>0.145</cell><cell>0.556</cell><cell>0.852</cell><cell>0.968</cell><cell>0.995</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We needed longer time series because the second graph involved achieving stability in baseline. Creating 30-point series ensured that we always had enough points to achieve stability.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Reflections on visual inspection, response guided experimentation, and Type I error rate in single-case designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Allison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Heshka</surname></persName>
		</author>
		<idno type="DOI">10.1080/00220973.1992.9943848</idno>
		<ptr target="https://doi.org/10.1080/00220973.1992.9943848" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Experimental Education</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="51" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Single case experimental designs : Strategies for studying behavior for change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Barlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Pearson/Allyn Bacon</publisher>
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Autocorrelation and estimates of treatment effect size for single-case experimental design data. Behavioral Interventions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barnard-Brak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Richman</surname></persName>
		</author>
		<idno type="DOI">10.1002/bin.1783</idno>
		<ptr target="https://doi.org/10.1002/bin.1783" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimal number of baseline sessions before changing phases within single-case experimental designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barnard-Brak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Richman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.beproc.2021.104461</idno>
		<ptr target="https://doi.org/10.1016/j.beproc.2021.104461" />
	</analytic>
	<monogr>
		<title level="j">Behavioural Processes</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Masked visual analysis: Minimizing type I error in visually guided single-case design for communication disorders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Byun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Hitchcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Speech, Language, and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1455" to="1466" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<idno type="DOI">10.1044/2017_JSLHR-S-16-0344</idno>
		<ptr target="https://doi.org/10.1044/2017_JSLHR-S-16-0344" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">O</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Heron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Heward</surname></persName>
		</author>
		<title level="m">Applied behavior analysis</title>
		<imprint>
			<publisher>Pearson</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using dual-criteria methods to supplement visual inspection: Replication and extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Falligant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Mcnulty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Rooker</surname></persName>
		</author>
		<idno type="DOI">10.1002/jaba.665</idno>
		<ptr target="https://doi.org/10.1002/jaba.665" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Behavior Analysis</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1789" to="1798" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Measuring academic output during the good behavior game: A single case design study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marcotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferron</surname></persName>
		</author>
		<idno type="DOI">10.1177/1098300719872778</idno>
		<ptr target="https://doi.org/10.1177/1098300719872778" />
	</analytic>
	<monogr>
		<title level="j">Journal of Positive Behavior Interventions</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="246" to="258" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The functioning of single-case randomization tests with and without random assignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Foster-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Kromrey</surname></persName>
		</author>
		<idno type="DOI">10.1080/00220970309602066</idno>
		<ptr target="https://doi.org/10.1080/00220970309602066" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Experimental Education</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Monte Carlo evaluation of masked visual analysis in response-guided versus fixed-criteria multiple-baseline designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ferron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Levin</surname></persName>
		</author>
		<idno type="DOI">10.1002/jaba.41</idno>
		<ptr target="https://doi.org/10.1002/jaba.41" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Behavior Analysis</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="701" to="716" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Randomization procedures for changing criterion designs. Behavior Modification. Advance online publication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ferron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Rohrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Levin</surname></persName>
		</author>
		<idno type="DOI">10.1177/0145445519847627</idno>
		<ptr target="https://doi.org/10.1177/0145445519847627" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Visual aids and structured criteria for improving visual inspection and interpretation of single-case designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Lomas</surname></persName>
		</author>
		<idno type="DOI">10.1901/jaba.2003.36-387</idno>
		<ptr target="https://doi.org/10.1901/jaba.2003.36-387" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Behavior Analysis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="406" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The use of single-subject research to identify evidence-based practice in special education</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Horner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Halle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Odom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wolery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exceptional children</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="165" to="179" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Single-case research designs: Methods for clinical and applied settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kazdin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Single-case designs technical documentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Kratochwill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hitchcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Horner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Odom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Rindskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Shadish</surname></persName>
		</author>
		<ptr target="http://files.eric.ed.gov/fulltext/ED510743.pdf" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Machine learning to analyze singlecase data: A proof of concept</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Lanovaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Giannakakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Destras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Behavior Science</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="38" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/s40614-020-00244-0</idno>
		<ptr target="https://doi.org/10.1007/s40614-020-00244-0" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Machine learning to analyze single-case to analyze single-case graphs: A comparison to visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Lanovaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hranchuk</surname></persName>
		</author>
		<idno type="DOI">10.1002/jaba.863</idno>
		<ptr target="https://doi.org/10.1002/jaba.863" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Behavior Analysis</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using the dual-criteria methods to supplement visual inspection: An analysis of nonsimulated data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Lanovaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Huxley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Dufour</surname></persName>
		</author>
		<idno type="DOI">10.1002/jaba.394</idno>
		<ptr target="https://doi.org/10.1002/jaba.394" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Behavior Analysis</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="662" to="667" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A primer on singlecase research designs: Contemporary use and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Ledford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Severini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Zimmerman</surname></persName>
		</author>
		<idno type="DOI">10.1352/1944-7558-124.1.35</idno>
		<ptr target="https://doi.org/10.1352/1944-7558-124.1.35" />
	</analytic>
	<monogr>
		<title level="j">American Journal on Intellectual and Developmental Disabilities</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="56" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Single case research methodology: Applications in special education and behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Ledford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Gast</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>3rd ed.). Routledge</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">N-of-1trials in healthcare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nikles</surname></persName>
		</author>
		<idno type="DOI">10.3390/healthcare9030330</idno>
		<ptr target="https://doi.org/10.3390/healthcare9030330" />
	</analytic>
	<monogr>
		<title level="j">Healthcare</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">330</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A visual aid and objective rule encompassing the data features of visual analysis. Behavior Modification. Advance online publication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Vannest</surname></persName>
		</author>
		<idno type="DOI">10.1177/0145445519854323</idno>
		<ptr target="https://doi.org/10.1177/0145445519854323" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Teaching behavior technicians to create publication-quality, single-case design graphs in graphpad prism 7</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Mitteer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Greer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">L</forename><surname>Cohrs</surname></persName>
		</author>
		<idno type="DOI">10.1002/jaba.483</idno>
		<ptr target="https://doi.org/10.1002/jaba.483" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Behavior Analysis</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="998" to="1010" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interrater agreement between visual analysts of single-case data: A meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ninci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Vannest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Willson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Modification</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="510" to="541" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0145445515581327</idno>
		<ptr target="https://doi.org/10.1177/0145445515581327" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The progression of experimental design and data analysis in applied behavior analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Rader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Rader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Leaf</surname></persName>
		</author>
		<idno type="DOI">10.1080/15021149.2021.1932199</idno>
		<ptr target="https://doi.org/10.1080/15021149.2021.1932199" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Behavior Analysis</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The impact of response-guided designs on count outcomes in single-case experimental design baselines. Evidence-Based Communication Assessment and Intervention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Beretvas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="82" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/17489539.2020.1739048</idno>
		<ptr target="https://doi.org/10.1080/17489539.2020.1739048" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Revision of a method quality rating scale for single-case experimental designs and n-of-1 trials: The 15-item Risk of Bias in N-of-1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Tate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perdices</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Rosenkoetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wakim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Godbee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Togher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trials</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Neuropsychological Rehabilitation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="619" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/09602011.2013.824383</idno>
		<ptr target="https://doi.org/10.1080/09602011.2013.824383" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Accessible randomization tests for single-case and small-n experimental designs in AAC research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Todman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dugard</surname></persName>
		</author>
		<idno type="DOI">10.1080/07434619912331278585</idno>
		<ptr target="https://doi.org/10.1080/07434619912331278585" />
	</analytic>
	<monogr>
		<title level="j">Augmentative and Alternative Communication</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="82" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Results reporting in single case experiments and single case meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Vannest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Peltier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
	<note>Research in Developmental Disabilities</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.ridd.2018.04.029</idno>
		<ptr target="https://doi.org/10.1016/j.ridd.2018.04.029" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
