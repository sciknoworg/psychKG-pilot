<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bayesian observational learning of other&apos;s risk attitude: Investigating the role of inferential uncertainty in the approximate delta rule social inferences</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-08-24">August 24, 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirhossein</forename><surname>Tehrani-Safa</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Cognitive and Brain Sciences</orgName>
								<orgName type="institution">Shahid Beheshti University</orgName>
								<address>
									<postBox>P.O. Box 19839-63113</postBox>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Ghaderi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Cognitive and Brain Sciences</orgName>
								<orgName type="institution">Shahid Beheshti University</orgName>
								<address>
									<postBox>P.O. Box 19839-63113</postBox>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atiye</forename><surname>Sarabi-Jamab</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Cognitive Sciences</orgName>
								<orgName type="institution">Institute for Research in Fundamental Sciences (IPM)</orgName>
								<address>
									<postBox>P.O. Box 19395-5746</postBox>
									<settlement>Tehran</settlement>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bayesian observational learning of other&apos;s risk attitude: Investigating the role of inferential uncertainty in the approximate delta rule social inferences</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-08-24">August 24, 2023</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Trait, attitude and preference learning encompasses the encoding of stable characteristics from observed behaviors, which are then used to make predictions and influence how one interacts with an individual in various contexts. Being able to understand the risk-taking tendencies of others is a complex example of such social inference job. In this research, we used a Bayesian framework to explore how humans can gauge another person&apos;s risk-taking tendency. We used a sequential scenario where an observer watched the other person&apos;s choices between a high-risk gamble and a guaranteed smaller reward. We proposed an approximate Bayesian observer to assess an agent&apos;s risk attitude. This learner utilizes a probabilistic generative model to model the decision making process of others and then employs a variational Bayesian method to invert the generative model. Our research adds to the accumulating evidence that inverting generative models are an essential computing tool for understanding social behavior. The learner updates the posterior estimation of the other&apos;s risk attitude on a trial-by-trial basis, with the discrepancy between the model predictions and the choices observed followed the widely accepted prediction error framework namely delta rule. By combining the algorithmic advantages of delta rule with the computational advantage of Bayesian framework, we fashioned a more effective and comprehensible learner. We showed that the accumulated uncertainty the observer builds up while predicting the agent&apos;s choices is the main factor that determines inferential uncertainty, i.e., the uncertainty the learner has in estimation of the agent&apos;s hidden attitude, which is the impetus for learning and discovery. The model begins with a high learning rate and gradually reduces it as more trials take place. This reflects the way humans learn from examples sequentially, exploring and then making use of the information as they progress. As more data is accumulated from someone who follows a consistent decision-making process, the observer&apos;s faith in his own judgments should grow, and he should be less affected by each new observation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>As social beings, humans can accumulate knowledge through observational learning, which refers to the cognitive process of acquiring attitudes, values, beliefs, and associated behaviors by observing patterns displayed by others <ref type="bibr" target="#b0">[1]</ref>. For example, youngsters observing their parents take risks and make calculated decisions can acquire their risk attitudes, and in turn, come to understand the importance of taking calculated risks in life. Comparatively to experiential learning <ref type="bibr" target="#b1">[2]</ref>, where the individual experiences the outcomes directly, observational learning is perceived as less hazardous <ref type="bibr" target="#b2">[3]</ref>.Three distinct forms of observational learning have been distinguished by contemporary research <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, namely, (1) vicarious (indirect) reinforcement-learning <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b1">(2)</ref>  person does and what we thought they would do, known as action prediction error <ref type="bibr" target="#b3">[4]</ref>.</p><p>Unlike imitation learning, which does not involve learning about internal variables, the final type involves learning about others' intentions, attitudes, and preferences. By doing so, we can better understand those around us. Observing how a colleague interacts with his/her manager can provide insight into their relationship; asking a friend what his/her favorite restaurant is can reveal his/her food preferences; observing nonverbal cues, like facial expressions and body language, can reveal another's emotional state. Lastly, frequent visits to a website may indicate intention to purchase.</p><p>Social neuroscience studies addressed the question of how we can infer individuals'</p><p>preferences and beliefs from their observable behavior: See <ref type="bibr" target="#b5">[6]</ref> for learning about other person reputation and trust, see <ref type="bibr" target="#b6">[7]</ref> for evaluating the expertise of others, see <ref type="bibr" target="#b7">[8]</ref> for learning about the abilities of other people in cooperative and competitive social situations, see <ref type="bibr" target="#b8">[9]</ref> for the validity of partner's advice, see <ref type="bibr" target="#b9">[10]</ref> for inferring another person's discounting rates, and see <ref type="bibr" target="#b10">[11]</ref> for learning about others' prudence, impatience and laziness.</p><p>Learning about others often takes place in a context where there are no right or wrong answers. One kind of such mental state is the risk attitude. In behavioral economics, a risk situation is a situation where all the possible events are known, but their occurrence depends on probability <ref type="bibr" target="#b11">[12]</ref>. Taking risks can yield substantial benefits, but may also result in negative outcomes or none at all <ref type="bibr" target="#b11">[12]</ref>. As a general rule, August 24, 2023 2/26 taking risks involves choosing the option with the most uncertainty <ref type="bibr" target="#b12">[13]</ref>. Essentially, a risk attitude is an implicit belief about how to evaluate risks most effectively <ref type="bibr" target="#b10">[11]</ref>.</p><p>Observational learning can provide insight into others' risk preferences. For instance, a person who chooses to take a high-risk gamble with a large reward would appear to be more risk tolerant than someone who chooses to take a low-risk gamble with a small reward. Furthermore, observing someone place large bets on a game may suggest that the individual is taking a high risk and may take on other risky bets in the future.</p><p>As internal variables, such as attitudes and subjective values, cannot be directly measured from task design, they need to be inferred from participants' behavior <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref>. Inferring internal variables from computational (generative) models, is based on the assumption that humans perceive sensory input as a statistical inference machine <ref type="bibr" target="#b13">[14]</ref>. Additionally, some cognitive theories describe cognition as probabilistic Bayesian inference in an uncertain world <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, leading to a Bayesian brain hypothesis <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>.The process involves combining prior beliefs and evidence from observations of others' behavior to update one's beliefs about other people's intentions and attitudes <ref type="bibr" target="#b3">[4]</ref>.The approach at hand is similar to the well-known inverse reinforcement learning strategy <ref type="bibr" target="#b20">[21]</ref> whereby the observer acquires knowledge of the world that is ultimately abstracted from observations <ref type="bibr" target="#b21">[22]</ref>.</p><p>Bayesian learning assumes a generative model, which includes explicit probabilistic assumptions about how decisions are made <ref type="bibr" target="#b22">[23]</ref>. Inversion of the generative model using Bayes' rule provides optimal estimates of posterior densities of internal variables.</p><p>In complex situations, exact inversion is generally unattainable, so algorithmic inference requires additional approximations <ref type="bibr" target="#b23">[24]</ref>. In technical terms, Bayesian integrals are intractable and require approximate inference, which is achieved by using variational Bayesian inference <ref type="bibr" target="#b24">[25]</ref>. Traditional sampling methods can also approximate the posterior without addressing the integral, but doing so can be computationally costly <ref type="bibr" target="#b25">[26]</ref>.</p><p>To gain an understanding of people's unobservable characteristics and beliefs, we explored how their visible behavior can be interpreted. We used probabilistic models to quantify the risk attitude of an observable agent based on how they make decisions. We utilized a Bayesian inference approach and used a variational Bayesian method to simplify the task. This led to the development of the Bayesian observer which is able to estimate an individual's risk attitude by observing how they act in various decision-making scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model inversion</head><p>Generally, generative models consist of a joint probability density of all states. Generic models are created by combining likelihood functions and state priors.</p><formula xml:id="formula_0">P C (k) , ρ (k) β, p (k) , r (k) = P C (k) ρ (k) , β, p (k) , r (k) × P ρ (k) β, p (k) , r (k)<label>(1)</label></formula><p>In Eq (1), the term P C (k) ρ (k) , β, p <ref type="bibr">(k)</ref> , r <ref type="bibr">(k)</ref> is the likelihood function which is defined by Eqs. <ref type="bibr" target="#b23">(24)</ref>, <ref type="bibr" target="#b24">(25)</ref>, <ref type="bibr" target="#b25">(26)</ref> and <ref type="bibr" target="#b26">(27)</ref> (see Computational model of risky behavior ).</p><p>A model inversion problem involves finding the term P ρ (k) C (k) , β, p <ref type="bibr">(k)</ref> , r <ref type="bibr">(k)</ref> which describes the posterior probability of the state ρ (k) that is of interest. As <ref type="table">August 24, 2023  3/26</ref> opposed to likelihood, which predicts choice from hidden parameters and states, posterior density of the state predicts the desired state from what choices have been observed. However, an analytical solution to the exact Bayesian model inversion is not feasible for our problem, so we should rely on some fast, but sufficiently accurate approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variational energies</head><p>The first step in this process is to incorporate what is known as the mean-field approximation, which transforms the joint distribution into the product of marginal posterior distributions <ref type="bibr" target="#b26">[27]</ref>:</p><formula xml:id="formula_1">P C (k) , ρ (k) β, p (k) , r (k) =q(C (k) ) ×q(ρ (k) )<label>(2)</label></formula><p>With the help of mean-field approximation, marginal posterior distributions can be expressed as follows in terms of variational energy I(•) <ref type="bibr" target="#b26">[27]</ref>:</p><formula xml:id="formula_2">q(C (k) ) = 1 Z C exp I C (k) , I(C (k) ) = ln P C (k) , ρ (k) q(ρ (k) ) q(ρ (k) ) = 1 Z ρ exp I ρ (k) , I(ρ (k) ) = ln P C (k) , ρ (k) q(C k )<label>(3)</label></formula><p>where,</p><formula xml:id="formula_3">⟨f (x)⟩ q(x) def = q(x)f (x)dx<label>(4)</label></formula><p>In Eq (3), the normalization factors Z C and Z ρ are used to ensure that the total probability equals one.</p><p>As a next step, the maximum entropy principle is used to create approximate posteriors with minimal assumptions. This principle states that the least arbitrary distribution is the one that maximizes entropy <ref type="bibr" target="#b27">[28]</ref>. The Bernoulli distribution is the most entropy-rich distribution for C <ref type="bibr">(k)</ref> due to its binary nature:</p><formula xml:id="formula_4">98 q(C (k) ) ∼ Bernoulli C (k) ; µ (k) C<label>(5)</label></formula><p>Additionally, we choose the Gaussian distribution for ρ <ref type="bibr">(k)</ref> because it provides the most randomness among continuous probability distributions:</p><formula xml:id="formula_5">100 q(ρ (k) ) ∼ N ρ (k) ; µ (k) ρ , σ (k) ρ<label>(6)</label></formula><p>Having determined the form of the distributions, the inverse problem is relegated to identifying moments in the distributions that have been represented by µ II) After observing the value of C k represented by C k o , the update step is taken.</p><p>In this step, given the current choice data, the observer computes an updated posterior belief for ρ <ref type="bibr">(k)</ref> , which includes the updated mean µ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I) Prediction Step</head><p>Starting from equation Eq(3), the variational energy I(C (k) ) can be expanded as follows:</p><formula xml:id="formula_6">I(C (k) ) = ln P C (k) , ρ (k) q(ρ (k) ) = ln P C (k) ρ (k) q(ρ (k) ) + ln P ρ (k) q(ρ k )<label>(7)</label></formula><p>Due to the fact that ln P ρ <ref type="bibr">(k)</ref> q(ρ k ) does not depend on C k , the Eq (7) can be simplified as follows:</p><formula xml:id="formula_7">I(C (k) ) = ln P C (k) ρ (k) q(ρ (k) )<label>(8)</label></formula><p>If we insert P C (k) ρ (k) (Eq(27)) into Eq (8), we get:</p><formula xml:id="formula_8">I(C (k) ) = C k ln S F (ρ (k) ) + (1 − C k ) ln 1 − S F (ρ (k) ) q(ρ (k) ) = C k ln S F (ρ (k) ) q(ρ (k) ) + (1 − C k ) ln 1 − S F (ρ (k) ) q(ρ (k) )<label>(9)</label></formula><p>There is no closed form analytical solution for integrals in Eq <ref type="bibr" target="#b8">(9)</ref>. Additionally, remember that ρ is updated in accordance with the C (k) , at the time when we wish to estimate the C <ref type="bibr">(k)</ref> , the last updated moments of ρ would be those values obtained from the previous trial (µ</p><formula xml:id="formula_9">(k−1) ρ , σ (k−1) ρ</formula><p>). So it seems reasonable to approximate the integrals using µ</p><formula xml:id="formula_10">(k−1) ρ</formula><p>in place of ρ <ref type="bibr">(k)</ref> . This results in the subsequent structure forq(C (k) ):</p><formula xml:id="formula_11">q(C (k) ) = 1 Z C exp I C (k) = S F (µ (k−1) ρ ) C (k) × 1 − S F (µ (k−1) ρ ) 1−C (k)<label>(10)</label></formula><p>As a result, the Eq(10) naturally has the Bernoulli distribution form, where:</p><formula xml:id="formula_12">µ (k) C = S F (µ (k−1) ρ ) σ (k) C = S F (µ (k−1) ρ ) × 1 − S F (µ (k−1) ρ )<label>(11)</label></formula><p>The parameter µ</p><formula xml:id="formula_13">(k) C = S F (µ (k−1) ρ</formula><p>) determines the shape ofq(C (k) ) and provides the most accurate estimate regarding the agent's choice at trial k, C <ref type="bibr">(k)</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II) Update Step</head><p>Having observed the value of</p><formula xml:id="formula_14">C (k) = C (k)</formula><p>o , it is now time to modify the model parameter ρ <ref type="bibr">(k)</ref> in accordance with the new observed value. We begin by rewriting the definition of variational energy for ρ <ref type="bibr">(k)</ref> as follows:</p><formula xml:id="formula_15">I(ρ (k) ) = ln P C (k) , ρ (k) q(C k ) = ln P C (k) ρ (k) q(C k ) + ln P ρ (k) q(C k )<label>(12)</label></formula><p>August 24, 2023 5/26</p><formula xml:id="formula_16">C (k)</formula><p>is an observable variable, and when the observer wishes to update the estimate of ρ, the value of</p><formula xml:id="formula_17">C (k) = C (k) o</formula><p>is readily available. Therefore, it is acceptable to substitute</p><formula xml:id="formula_18">C (k) with C (k) o</formula><p>in the Eq <ref type="bibr" target="#b11">(12)</ref>. As a result, the expectation operator is simply cancelled:</p><formula xml:id="formula_19">I(ρ (k) ) = ln P C (k) o ρ (k) + ln P ρ (k)<label>(13)</label></formula><p>According to Eq <ref type="bibr" target="#b26">(27)</ref>, P C (k) o ρ <ref type="bibr">(k)</ref> represents the likelihood function, and P ρ <ref type="bibr">(k)</ref> represents the prior knowledge of ρ's distribution. Once we have placed the prior distribution and likelihood into Eq (13), we have the following equation:</p><formula xml:id="formula_20">I(ρ (k) ) = C k o × ln S F (ρ (k) ) + (1 − C (k) o ) × ln 1 − S F (ρ (k) ) − ρ (k) − µ (k−1) ρ 2 2σ (k−1) ρ<label>(14)</label></formula><p>If we simplify the expression (see Appendix S1:), we will arrive at the following result:</p><formula xml:id="formula_21">I(ρ (k) ) = ln S F (ρ (k) ) + β × (C (k) o − 1) × F (ρ (k) ) − ρ (k) − µ (k−1) ρ 2 2σ (k−1) ρ<label>(15)</label></formula><p>Considering that the obtained equation (Eq (15)) doesn't have a quadratic form with respect to ρ <ref type="bibr">(k)</ref> , it cannot be used as an exponent of a Gaussian distribution. Applying a quadratic approximation to the variational energy I(ρ <ref type="bibr">(k)</ref> ) (see Appendix S2:), we arrive at the following equations for updating µ ρ :  <ref type="bibr" target="#b28">[29]</ref>. RL models are generally structured as follows:</p><formula xml:id="formula_22">µ (k) ρ = µ (k−1) ρ + β ×   ∂F (ρ (k) ) ∂ρ (k) ρ (k) =µ (k−1) ρ   × σ (k) ρ × C (k) o − S F (µ (k−1) ρ ) (16) 1 σ (k) ρ = 1 σ (k−1) ρ +β 2 ×   ∂F (ρ (k) ) ∂ρ (k) ρ (k) =µ (k−1) ρ   2 × S F (µ (k−1) ρ ) × 1 − S F (µ (k−1) ρ )<label>(17</label></formula><formula xml:id="formula_23">µ (k) ρ posterior (k) = µ (k−1) ρ posterior (k−1) + α (k) learning rate (k) × δ (k) prediction error (k)<label>(18)</label></formula><p>As per our model, the prediction error δ (k) refers to the difference between the actual choice C  </p><formula xml:id="formula_24">C = S F (µ (k−1) ρ</formula><p>) made prior to the actual choice</p><formula xml:id="formula_25">C (k) o</formula><p>being observed:</p><formula xml:id="formula_26">δ (k) = C (k) o − µ (k) C<label>(19)</label></formula><p>August 24, 2023 6/26</p><p>By introducing δ <ref type="bibr">(k)</ref> into Eq <ref type="bibr" target="#b15">(16)</ref> and then comparing it to Eq (18), we can derive the expression for the time-varying learning rate α <ref type="bibr">(k)</ref> :</p><formula xml:id="formula_27">α (k) = β × γ (k) × σ (k) ρ (20)</formula><p>In Eq <ref type="bibr" target="#b19">(20)</ref>, γ <ref type="bibr">(k)</ref> is the derivative of function F (ρ (k) ) (Eq (25)) relative to ρ (k) at point</p><formula xml:id="formula_28">ρ (k) = µ (k−1) ρ . γ (k)</formula><p>is influenced by both the probability p <ref type="bibr">(k)</ref> and reward r (k) of the gamble proposed at trial k. At usual probabilities and rewards, γ (k) remains positive (please refer to Eq (S2.13) for more details about γ <ref type="bibr">(k)</ref> and Experimental Task for more information about gambles' settings).</p><formula xml:id="formula_29">γ (k) = ∂F (ρ (k) ) ∂ρ (k) ρ (k) =µ (k−1) ρ<label>(21)</label></formula><p>In addition, β is also a non-negative term (see Computational model of risky behavior). Note that since β is not provided to the observer, it will be estimated by fitting to the entire set of choice data.</p><p>Additionally, the learning rate α (k) varies depending on the level of the positive</p><formula xml:id="formula_30">measure of variance σ (k) ρ . Considering that σ (k) ρ</formula><p>represents the variance of posterior distribution, it is plausible that the learning rate α (k) will be proportional to σ</p><formula xml:id="formula_31">(k) ρ . It</formula><p>is expected that upcoming observations will be more impactful on an observer who is less certain of what he or she knows.</p><p>Eq <ref type="formula" target="#formula_22">17</ref>gives us σ</p><formula xml:id="formula_32">(k)</formula><p>ρ , which can be rewritten in the following manner:</p><formula xml:id="formula_33">1 σ (k) ρ = 1 σ (k−1) ρ + β 2 × (γ (k) ) 2 × σ (k) C (22) σ (k)</formula><p>C (see Eq <ref type="formula" target="#formula_12">11</ref>) represents the degree of uncertainty in the choice prediction. We can see that the amount of σ C is non-negative and has a peak value of 0.25.</p><p>Due to the recursive nature of Eq <ref type="bibr" target="#b21">(22)</ref>, σ</p><formula xml:id="formula_34">(k−1) ρ</formula><p>can be replaced by the value specified in the equation. This process can be repeated for σ</p><formula xml:id="formula_35">(k−2) ρ</formula><p>and onward:</p><formula xml:id="formula_36">1 σ (k) ρ = 1 σ (k−2) ρ + β 2 × (γ (k−1) ) 2 × σ (k−1) C + β 2 × (γ (k) ) 2 × σ (k) C = 1 σ (0) ρ + β 2 × (γ (1) ) 2 × σ (1) C + (γ (2) ) 2 × σ (2) C + • • • + (γ (k) ) 2 × σ (k) C = 1 σ (0) ρ + β 2 × k i=1 (γ (i) ) 2 × σ (i) C<label>(23)</label></formula><p>It is clear from Eq (23) that σ</p><formula xml:id="formula_37">(k) ρ</formula><p>is inversely proportional to the sum of σ</p><formula xml:id="formula_38">(i) C weighted by (γ (i) ) 2 .</formula><p>Taking into consideration all of the above theoretical results, it seems that predictive uncertainty σ (k)</p><p>C keeps the learning rate lower than otherwise. This is understandable since prediction error should be less magnified when the predictions are less certain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation results</head><p>Each run of simulation contains a couple of blocks used in <ref type="bibr" target="#b29">[30]</ref>  In order to ensure that the task is at an appropriate level of difficulty for the learners, β was set to 1, so that the agent's actions were neither too predictable nor too unpredictable. This balance allowed for the learner to be able to learn successfully, while still facing a challenging task. In the upcoming sections of the simulation part, we will examine quantitatively how β value affects learning (see <ref type="figure" target="#fig_16">Fig 4)</ref>. learning rate technique that starts with a broad exploration of the parameter space and gradually transits to a more focused exploration of the parameter space as trials progress. As expressed through Eq (18), the learning rate α (k) governs the impact of prediction errors δ (k) on the model expectations. Through the course of the trials, the learning rate α (k) is reduced, allowing the learner to build on the knowledge gained from earlier trials and become less responsive to new data.</p><p>We depicted the y-axis of middle panel in log scale since the learning rate α (k) in starting trials is much larger than that in last trials. In the final trials, a low learning rate does not allow the model to alter its expectations in a significant way, even with high prediction error signals. This is because the model is confident that it has almost found the exact value of risk attitude, and that any discrepancies in the later trials are likely just noise. This approach is advantageous for our risk attitude learning problem as it is assumed that the underlying parameter of interest ρ is unchanging.  </p><formula xml:id="formula_39">C = S F (µ (k−1) ρ ) .</formula><p>Eq <ref type="bibr" target="#b19">(20)</ref>, which demonstrates that α <ref type="bibr">(k)</ref> and σ Consequently, a reduction in learning rate is coupled with a decrease in σ (k) ρ . As the trials advanced, the model's risk attitude estimates became increasingly certain, as the variance of the posterior expectation of risk attitude decreased. In addition, the learning rate trajectory showed variations that could not be explained by the variance of the risk attitude, but rather by another factor, γ (k) (as depicted in <ref type="figure" target="#fig_9">Fig Figure S1</ref>:</p><p>and described by Eq <ref type="bibr" target="#b19">(20)</ref>).</p><p>When the model felt sure of its prediction (σ (k)</p><formula xml:id="formula_40">C = 0), the σ (k) ρ</formula><p>was kept unchanged to maintain a high learning rate. This was because if the prediction was incorrect but the model was still highly confident, it had to be adjusted according to the error signal that was received. As the model's certainty in prediction decreased, the σ As the trials continue, the σ (k) ρ decreases until it converges to zero, but at a slower and slower pace. Consequently, the learning rate α (k) follows the same path as σ meaning that the learning process persists even after many trials, albeit at a very slow rate. The fitted line for the log-transformation of the σ  in the prediction lessens, which indicates that less random choices are more likely to be accurately predicted by the learner. In the most extreme case, σ and β remain in equilibrium, so the effect on α (k) is minimal. This indicates that while β has a significant impact on σ (k) ρ , it does not have a significant effect on learning rate α <ref type="bibr">(k)</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model comparison</head><p>We compared the Bayesian learner to the <ref type="bibr">Rescorla</ref>  To compare the two learning models, we utilized the data collected by Suzuki et al <ref type="bibr" target="#b29">[30]</ref>. We utilized the data from session 1, and 5, in which the risk attitudes of the participants were assessed. <ref type="figure" target="#fig_17">Fig 5 displays</ref> the learning trajectories of one of the participants involved in the experiment.</p><p>We employed the BFGS optimization algorithm from the TAPAS (https://tnu.ethz.ch/tapas) <ref type="bibr" target="#b30">[31]</ref> to determine the best parameters for our models, which were then used to calculate the quality measures of the models. This optimization technique maximizes the log-joint posterior density across all parameters, based on the models' trial-wise predictions. We used the Log Model Evidence (LME) and the Bayesian Information Criterion (BIC) to measure the performance of the models. The Model Evidence is essentially the probability of the data given the model, which we approximated with the Free Energy <ref type="bibr" target="#b31">[32]</ref>. When selecting the best model, the Free Energy performs better than the Akaike Information Criterion (AIC) or the BIC, as the latter two focus solely on the number of parameters, rather than taking into account their covariance <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref>. Bayesian Information Criterion (BIC) and the Log Model Evidence (LME) scores confirm that BL with one free parameter is superior to R-W with two free parameters, even if the accuracy likelihood score is marginally lower. <ref type="table" target="#tab_3">Table 1</ref> provides a summary of the results of the models quality assessments.</p><p>We implemented a Random-Effects Bayesian Model Selection (RFX-BMS) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34]</ref> to compare the alternative models and determine their relative strength. The posterior probability of each model was then used to calculate the Exceedance Probability (EP) and Protected Exceedance Probability (PEP) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>We leveraged the open-source VBA toolbox <ref type="bibr" target="#b34">[35]</ref>      We proposed a Bayesian approach to address this problem, which we then simplified into a more accessible and computationally efficient algorithm, namely delta rule <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>. The delta rule expresses that belief updates depend on the previous belief and the error made in predicting the most recent observation <ref type="bibr" target="#b37">[38]</ref> and has biological foundations examined in <ref type="bibr" target="#b38">[39]</ref>. Delta rule has been used to analyze social behavior in the field of social psychology <ref type="bibr" target="#b39">[40]</ref>.</p><p>Early investigations showed that social learning in the lab can be comprehended through the same delta rule learning principles employed in non-social learning <ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref>.</p><p>The discrepancies between what we anticipate and what we experience (the prediction error) can reveal how we acquire social value, such as how generous another can be <ref type="bibr" target="#b43">[44]</ref>, or if someone's willingness to punish impacts our own <ref type="bibr" target="#b44">[45]</ref>. In our problem, the model updates the posterior estimation of the other's risk attitude on a trial-by-trial basis, with the discrepancy between the model predictions and the choices observed. By combining the algorithmic advantages of delta rule with the Bayesian framework, we fashioned a more effective and comprehensible learner.</p><p>Bayesian learning posits that estimation uncertainty, also called inferential uncertainty <ref type="bibr" target="#b45">[46]</ref>, is the impetus for exploration <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47]</ref>. Research on human learning demonstrated that such uncertainty plays a role in how humans learn and attain knowledge <ref type="bibr" target="#b37">[38]</ref>. The feeling-of-knowing, or subjective confidence <ref type="bibr" target="#b47">[48]</ref>, is believed to be associated with the inferential uncertainty that arises during learning process <ref type="bibr" target="#b45">[46]</ref>, leading to the idea of defining confidence as a Bayesian probability <ref type="bibr" target="#b47">[48]</ref>. In this framework, the precision of the distribution (its inverse variance) is seen as the manifestation of confidence <ref type="bibr" target="#b48">[49]</ref>. Furthermore, from a biological perspective, it appears that the brain not only estimates a value, but also the level of certainty of that estimate, along with its entire probability distribution <ref type="bibr" target="#b18">[19]</ref>. In our Bayesian risk attitude learner, σ ρ characterizes the inferential uncertainty of the model in estimating other's risk attitude. Mathematically, the confidence level is formulated as a negative logarithm of variance in the distribution <ref type="bibr" target="#b45">[46]</ref>. <ref type="figure" target="#fig_12">In Fig 2, Fig 3 and</ref> Fig4, we showed the trajectories of σ ρ using the log scale, which is the natural space for illustrating August 24, 2023 14/26</p><p>variance <ref type="bibr" target="#b49">[50]</ref>, making the transition from variance to confidence much simpler.</p><p>The Bayesian computational framework gives us the chance to investigate further how confident humans are when learning others' preferences, which can build upon prior research into human confidence in areas such as memorization <ref type="bibr" target="#b50">[51]</ref>, perceptual decision-making <ref type="bibr" target="#b51">[52]</ref>, and probabilistic learning task <ref type="bibr" target="#b45">[46]</ref>. In contrast, the Rescorla-Wagner model cannot express inferential uncertainty; it provides only a single point estimate, without giving any indication of the reliability of the estimation <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref>. Although progress has been made in understanding how the brain uses prediction errors to learn, there is still limited knowledge about the learning rate <ref type="bibr" target="#b37">[38]</ref>.</p><p>In our theoretical analysis, we connected the learning rate to the uncertainty the model experiences when predicting an agent's choice. Additionally, we showed that the accumulated uncertainty the observer experiences when predicting the agent's decisions is what determines the width of the posterior distribution. To validate our theoretical findings, we simulated data to assess the observer's capability to precisely guess the decision maker's risk attitude ρ. Furthermore, since simulation allows us to pick the number of trials, we conducted the simulations with a larger than usual number of trials to thoroughly explore the properties we discovered in the theoretical section, particularly concerning the connection between the learning rate and the three types of uncertainty: variance of posterior belief (σ Research on human social learning and cognition has shown that the greatest rate of learning takes place in the beginning of an experiment when there is the most uncertainty about what others will do <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref>. In this line, our Bayesian observer begins with a high learning rate to explore all potential values, holding this rate at a high level as long as the model is confident in its predictions.</p><p>However, when the observer is uncertain (e.g., assuming a 50-50 chance for each option), the model decreases the learning rate in order to prevent unhelpful information from affecting its current estimation. The Bayesian learner is able to adjust its learning speed according to the uncertainty of its beliefs. The width of the posterior belief distribution reflects the range in which the true value is likely to lie, and the learning rate is therefore proportional to this width, aiding the learner in finding the most probable true value.</p><p>We compared our Bayesian learner with an uncertainty-based learning rate to the Rescorla-Wagner reinforcement learning model, which uses a constant learning rate.</p><p>We discovered that the Bayesian learner had greater model quality scores. This is due to the Bayesian learner having an intrinsic mechanism for determining the learning rate, which the Rescorla-Wagner model lacks. The Rescorla-Wagner model must use a fitting algorithm to determine an optimal learning rate, which requires an additional fitting parameter. In contrast, the Bayesian observer eliminates the need for this extra parameter through its inherent strategy for determining the learning rate, which is derived from Bayesian optimality principles.</p><p>The Rescorla-Wagner model's best-fit learning rate for the exemplar participant's dataset was equivalent to the Bayesian observer's average learning rate. Although this delta-rule algorithm with a fixed learning rate (i.e., Rescorla-Wagner model), similar to the Bayesian approach, had good accuracy in predicting others' attitudes, it does not accurately replicate the human exploration-exploitation heuristic. For this reason, a fixed learning rate model is not a precise representation of behavior for this task.</p><p>Our Bayesian learner, by contrast, started with a high learning rate and decreased it as trials progress. The process reflects the way humans learn from examples in a sequential manner, exploring and then exploiting the information as they go. It is expected that confidence would increase with the number of observations made during stable periods <ref type="bibr" target="#b45">[46]</ref>. As more data is collected from someone following a consistent decision-making process, the observer's confidence in his own judgments should increase and he should be less influenced by each new observation.</p><p>Inferential social learning posits that people interpret information from others based on an intuitive understanding of how their minds work. In the RL paradigm, inverse reinforcement-learning <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b55">56]</ref> attempts to use the agent's behavior to infer the underlying reward structure of the environment which is not directly observable <ref type="bibr" target="#b21">[22]</ref>.</p><p>Inverse RL is also applied to understand how humans learn about others <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>However, these models lack a generative element that would explain how those actions came to be. By incorporating generative models into the process, learners can gain a richer understanding of the information they receive <ref type="bibr" target="#b56">[57]</ref>. Bayesian learning, with its probability-based generative models, has the potential to be more powerful than reinforcement learning on its own.</p><p>Generative models are essential for understanding others' risk preferences.</p><p>Predicting a decision-maker's behavior involves understanding his attitude towards risk. In a gamble, agents make decisions based on rewards and probabilities, and these parameters vary from trial to trial, making past decisions in isolation no longer a reliable indicator of current behavior. For this reason, a generative model that takes into account gamble variables and a person's attitude is required in order to assess the risk preference of the decision-maker and predict whether they will accept the new gamble (Computational model of risky behavior). Uncovering the rationale behind a decision entails tracing it back to the desires that prompted it, by turning the generative model of choice on its head <ref type="bibr" target="#b57">[58]</ref>. We used Variational Bayesian technique as a way of approximate reasoning to avoid complex and intractable integrals usually encountered in Bayesian inference. This method, developed by Karl Friston <ref type="bibr" target="#b17">[18]</ref> and utilized in computational neuroscience, is a powerful tool for approximate reasoning, which has been widely applied in neuroscience <ref type="bibr" target="#b25">[26]</ref>.</p><p>Our research contributes to the ever-growing body of evidence which suggests that inverting generative models is a vital computational tool for social inference <ref type="bibr" target="#b57">[58]</ref>.</p><p>Studies examining this phenomenon have implemented a range of formal assumptions, such as those conducted by <ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref><ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref>. While each of these studies have their own distinct formal assumptions, they all lead to the same conclusion that inverting generative models is a powerful psychological tool for social inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Task</head><p>The experimental task that has been employed in this study is based on the work of Suzuki and his colleagues <ref type="bibr" target="#b29">[30]</ref>. In each simulation run, there are two blocks, each with 28 trials; therefore , there are 56 trials in total. The order in which trials are presented is random. In each trial, artificial agents are required to decide whether to accept or reject a risky gamble. The gamble has two possible outcomes: either receiving the certain reward or not receiving it. The result of rejecting a gamble is a fixed guaranteed payment. As a general rule, the reward of a gamble is greater than the payment that is guaranteed. Essentially, gambles are characterized by two parameters: p and r, with p being the probability and r being the amount of the reward. Each of the 28 trials had its own August 24, 2023</p><p>16/26 combination of reward probability p and reward magnitude r. There were three possibilities for reward probabilities: 0.3, 0.4, and 0.5. We modified the actual reward magnitude in each trial by adding a small integer noise, ranging from -1 to 1.</p><p>Guaranteed payments are fixed at 10 dollars <ref type="figure" target="#fig_23">(Fig.7)</ref>. Points correspond to gambles, which are described by reward probability p and reward magnitude r. The red color code is indicative of gambles that risk-neutral individuals prefer to certain payments, and the blue color code is indicative of gambles that risk-neutral individuals do not prefer to certain payments. The yellow graph illustrates a curve of indifference when risk-neutral attitudes are adopted, in which a gamble is just as valuable as a certain payment of ten dollars. As can be seen on the right side of the plot, there are two distinct points. These points correspond to two risk-free gambles that were used in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational model of risky behavior</head><p>Artificial agents choices were generated by a mathematical algorithm. We assumed that the simulated agents would make decisions based on the computational model described here. The model is widely used to study decision making under risk <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b63">[64]</ref><ref type="bibr" target="#b64">[65]</ref><ref type="bibr" target="#b65">[66]</ref><ref type="bibr" target="#b66">[67]</ref>.</p><p>Let us imagine that the decision-maker is faced with a choice between gambling or receiving a guaranteed monetary payment. Choosing between options requires the decision maker to calculate subjective expected values. Depending on the decision maker's attitude toward risk, this evaluation may differ. According to one of the most common approaches based on a power utility function <ref type="bibr" target="#b67">[68]</ref><ref type="bibr" target="#b68">[69]</ref><ref type="bibr" target="#b69">[70]</ref>, the utility of the risky option is denoted by U R as follows:</p><formula xml:id="formula_41">U R (r, p) = p × r ρ<label>(24)</label></formula><p>In Eq <ref type="bibr" target="#b23">(24)</ref>, p is the probability of receiving a reward and r is the magnitude of the reward. We do not use small probabilities (p &lt; 0.3), so the subjective probability distortion <ref type="bibr" target="#b68">[69]</ref> is not relevant to our analysis. ρ refers to the participant's risk attitude, August 24, 2023 17/26 which is the curvature of the utility function. Depending on whether the individual is risk-averse or risk-taking, ρ is lower or greater than 1.</p><p>Based on the principles of classical decision theory and behavioral economics, people's choices may reflect their relative preferences for different outcomes <ref type="bibr" target="#b70">[71]</ref>. To decide between the risky option and the sure option, one must compare their values using the function F (•) , where U S represents the certain payoff.</p><formula xml:id="formula_42">F = U R − U S<label>(25)</label></formula><p>Generally, the greater the value of F (•), the more likely it is that the decision maker will prefer the risky option to the sure option. Next, a probabilistic rule called Softmax S(•) calculates the probability of choosing a risky option over a sure option.</p><formula xml:id="formula_43">S(F (ρ)) = 1 1 + exp (−β × F (ρ))<label>(26)</label></formula><p>In Eq <ref type="bibr" target="#b25">(26)</ref>, β is a non-negative free parameter that measures how much the choice probability relates to utility differences or how random are the subject's decisions.</p><p>The probability of choosing a risky option will always be half if β is zero. Therefore, Lastly, a Bernoulli distribution is used to describe the choice of decision-maker, C.</p><p>The value of C can be either 0 or 1. One means that the decision-maker chooses the risky option, and zero means that he or she rejects it.</p><formula xml:id="formula_44">P (C|ρ) = [S (F (ρ))] C × [1 − S (F (ρ))] 1−C<label>(27)</label></formula><p>Supporting information <ref type="figure" target="#fig_9">Figure S1</ref>:</p><formula xml:id="formula_45">γ (k) = ∂F (ρ (k) ) ∂ρ (k) Fig Supp 1. γ (k) = ∂F (ρ (k) )</formula><p>∂ρ <ref type="bibr">(k)</ref> operations yields the following expression:</p><formula xml:id="formula_46">I(ρ (k) ) = C (k) × ln S F (ρ (k) ) + (1 − C (k) ) × −β × F (ρ (k) ) + ln S F (ρ (k) ) − ρ (k) − µ (k−1) ρ 2 2σ (k−1) ρ = ln S F (ρ (k) ) + β × (C (k) − 1) × F (ρ (k) ) − ρ (k) − µ (k−1) ρ 2 2σ (k−1) ρ (S1.2)</formula><p>Appendix S2: Obtaining a quadratic approximation of the variational energy I(ρ (k) ).</p><p>Here one can observe the second order approximation of the variational energy, resulting in an update equation. The equation obtained for I(ρ (k) ) contains non-quadratic terms:</p><formula xml:id="formula_47">I(ρ (k) ) = ln S F (ρ (k) ) + β × (C (k) 0 − 1) × F (ρ (k) ) − ρ (k) − µ (k−1) ρ 2 2σ (k−1) ρ</formula><p>In order to approximate a Gaussian distribution, it is necessary to find a quadratic polynomialĨ(ρ (k) ) that approximates I(ρ (k) ). By doing so, the Gaussian distribution can be accurately represented.</p><formula xml:id="formula_48">I(ρ (k) ) = − ρ (k) − µ (k) ρ 2 2σ (k) ρ (S2.1)</formula><p>When the second order Taylor series of function I(ρ <ref type="bibr">(k)</ref> ) is expanded around a particular expansion point, an approximate quadratic functionĨ(ρ (k) ) can be August 24, 2023</p><p>19/26</p><p>obtained. This technique is referred to as Laplace approximation when the Taylor expansion is carried out at the peak of I(ρ (k) ) <ref type="bibr" target="#b71">[72]</ref>. An alternative site for the expansion point would be the mean value of ρ (k) that has been previously updated, symbolized by µ (k−1) ρ <ref type="bibr" target="#b72">[73]</ref>. The second suggestion is what we are going to use here.</p><p>ConsideringĨ(ρ (k) ) to be the second order Taylor expansion of I(ρ (k) ) about</p><formula xml:id="formula_49">µ (k−1) ρ</formula><p>, the first and second derivatives of bothĨ(ρ (k) ) and I(ρ <ref type="bibr">(k)</ref> ) are equivalent at this point:</p><formula xml:id="formula_50">∂I ∂ρ (k) ρ (k) =µ (k−1) ρ = ∂Ĩ ∂ρ (k) ρ (k) =µ (k−1) ρ ∂ 2 I ∂(ρ (k) ) 2 ρ (k) =µ (k−1) ρ = ∂ 2Ĩ ∂(ρ (k) ) 2 ρ (k) =µ (k−1) ρ (S2.2)</formula><p>The derivatives ofĨ(ρ (k) ) at the point µ (k−1) ρ can be determined from Eq (S2.1).</p><p>Substituting these values into Eq(S2.2) leads to the following results:</p><formula xml:id="formula_51">∂I ∂ρ (k) ρ (k) =µ (k−1) ρ = µ (k) ρ − µ (k−1) ρ σ (k) ρ ∂ 2 I ∂(ρ (k) ) 2 ρ (k) =µ (k−1) ρ = − 1 σ (k) ρ (S2.3)</formula><p>Rearranging Eq(S2.3) yields into an updating equation for µ ρ :</p><formula xml:id="formula_52">µ (k) ρ = µ (k−1) ρ + σ (k) ρ × ∂I ∂ρ (k) ρ (k) =µ (k−1) ρ 1 σ (k) ρ = − ∂ 2 I ∂(ρ (k) ) 2 ρ (k) =µ (k−1) ρ (S2.4)</formula><p>The final step to obtain the explicit update equations for µ . We begin by computing the first derivative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∂I ∂ρ</head><formula xml:id="formula_53">(k) = ∂ ∂ρ (k)      ln S F (ρ (k) ) + β × (C (k) o − 1) × F (ρ (k) ) − ρ (k) − µ (k−1) ρ 2 2σ (k−1) ρ      = ∂ ∂ρ (k) ln S F (ρ (k) ) + β × (C (k) o − 1) × F (ρ (k) ) − ∂ ∂ρ (k)      ρ (k) − µ (k−1) ρ 2 2σ (k−1) ρ      = ∂ ∂ρ (k) ln S F (ρ (k) ) + β × (C (k) o − 1) × ∂F (ρ (k) ) ∂ρ (k) − ρ (k) − µ (k−1) ρ σ (k−1) ρ (S2.5)</formula><p>Using a chain rule, it is possible to derive ∂ ∂ρ (k) ln S F (ρ (k) ) as follows: ∂ ∂ρ <ref type="bibr">(k)</ref> ln S F (ρ (k) ) = 1 S F (ρ (k) ) × ∂S ∂F (ρ (k) ) × ∂F (ρ (k) ) ∂ρ (k) (S2.6) August 24, 2023 20/26 where ∂S ∂F (ρ (k) ) is:</p><formula xml:id="formula_54">∂S ∂F (ρ (k) ) = β × S F (ρ (k) ) × 1 − S F (ρ (k) ) (S2.7)</formula><p>Finally we have: ∂ ∂ρ <ref type="bibr">(k)</ref> ln S F (ρ (k) ) = β × ∂F (ρ (k) ) ∂ρ (k) × 1 − S F (ρ (k) ) (S2.8)</p><p>The following equation for ∂I ∂ρ (k) can be calculated by substituting the value achieved for ∂ ∂ρ (k) ln S F (ρ (k) ) in the Eq (S2.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∂I ∂ρ</head><formula xml:id="formula_55">(k) = β × ∂F (ρ (k) ) ∂ρ (k) 1 − S F (ρ (k) ) + β × ∂F (ρ (k) ) ∂ρ (k) × (C k o − 1) − ρ (k) − µ (k−1) ρ σ (k−1) ρ = β × ∂F (ρ (k) ) ∂ρ (k) × C k o − S F (ρ (k) ) − ρ (k) − µ (k−1) ρ σ (k−1) ρ (S2.9)</formula><p>By differentiating Eq (S2.9), we can obtain the expression for ∂ 2 I ∂(ρ (k) ) 2 :</p><p>∂ I ∂(ρ (k) ) 2 = ∂ ∂ρ <ref type="bibr">(k)</ref> ∂I ∂ρ <ref type="bibr">(k)</ref> = ∂ ∂ρ <ref type="bibr">(k)</ref> </p><formula xml:id="formula_56">β × ∂F (ρ (k) ) ∂ρ (k) × C k o − S F (ρ (k) ) − ρ (k) − µ (k−1) ρ σ (k−1) ρ = ∂ ∂ρ (k) β × ∂F (ρ (k) ) ∂ρ (k) × C k o − S F (ρ (k) ) − ∂ ∂ρ (k) ρ (k) − µ (k−1) ρ σ (k−1) ρ = β × ∂ 2 F (ρ (k) ) ∂(ρ (k) ) 2 × C k o − S F (ρ (k) ) − β × ∂F (ρ (k) ) ∂ρ (k) 2 × ∂S ∂F (ρ (k) ) − 1 σ (k−1) ρ (S2.10)</formula><p>Omitting the initial term which incorporates the second order derivative ∂ 2 F (ρ (k) ) ∂(ρ (k) ) 2 yields a more straightforward formula:</p><formula xml:id="formula_57">∂ 2 I ∂(ρ (k) ) 2 ≊ −β 2 × ∂F (ρ (k) ) ∂ρ (k) 2 × S F (ρ (k) ) × 1 − S F (ρ (k) ) − 1 σ (k−1) ρ (S2.11)</formula><p>The value of ∂ 2 I ∂(ρ (k) ) 2 is always kept at a negative level due to the presence of negative components. This ensures that σ (k) ρ is maintained at a positive value, which is a necessary requirement based on its underlying characteristics.</p><p>Lastly, by substituting the values of ∂I ∂ρ (k) and ∂ 2 I ∂(ρ (k) ) 2 at the point ρ (k) = µ</p><formula xml:id="formula_58">(k−1) ρ</formula><p>into Equation Eq(S2.4), the update equation for µ <ref type="bibr">(k)</ref> ρ and σ (k) ρ can be obtained: Where the value of ∂F (ρ (k) )</p><formula xml:id="formula_59">µ (k) ρ = µ (k−1) ρ + β ×   ∂F (ρ (k) ) ∂ρ (k) ρ (k) =µ (k−1) ρ   × σ (k) ρ × C (k) 0 − S F (µ (k−1) ρ ) 1 σ (k) ρ = 1 σ (k−1) ρ + β 2 ×   ∂F (ρ (k) ) ∂ρ (k) ρ (k) =µ (k−1) ρ   2 × S F (µ (k−1) ρ ) × 1 − S F (µ (k−1) ρ )<label>(S2.</label></formula><formula xml:id="formula_60">∂ρ (k) ρ (k) =µ (k−1) ρ</formula><p>is:</p><formula xml:id="formula_61">∂F (ρ (k) ) ∂ρ (k) ρ (k) =µ (k−1) ρ = ∂ ∂ρ (k) p k × (r k ) ρ k − U s ρ (k) =µ (k−1) ρ = p k × ln r k × (r k ) µ (k−1) ρ (S2.13)</formula><p>See Eqs. <ref type="bibr" target="#b23">(24)</ref>, <ref type="bibr" target="#b24">(25)</ref> for the definition of function F (•).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>action imitation, and (3) inference about other people's beliefs and intentions. Vicarious reinforcement-learning is aptly understood within the reinforcement-learning framework and involves computing reward prediction errors from observing other agents' actions. By comparing the predicted rewards of another agent with the actual outcomes, these prediction errors are calculated. Action imitation learning, however, involves calculating the difference between what another</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>6)). Identifying these moments involves two recursive steps: I) During the prediction step, a decision C k is predicted based on previously updated posterior beliefs regarding the agent's attitude toward risk. This is accomplished by estimating the moment of choice distribution (µ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>to the amount of σ (k) C . As long as the observer is confident about his prediction (σ (k) C = 0 ), σ ρ (k) remains the same, unless σ ρ (k) decreases trial to trial. It should be noted that as a variance of Bernoulli distribution, σ (k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig</head><label></label><figDesc>depicts the Bayesian learning process in the structure of reinforcement learning model, with each panel corresponding to one element of Eq<ref type="bibr" target="#b17">(18)</ref>. The bottom panel illustrates the observed choices C(k) oand associated choice prediction errors δ(k)  , the middle panel depicts the dynamic learning rate α(k)  , and the top panel presents the posterior expectation of the parameter of interest µ(k) ρ . As shown in the bottom panel of Fig 1, the simulated agent with the least willingness to take risks (ρ = 0.85) consistently turned down the offers. As the risk attitude was increased from its minimum to its highest (ρ = 1.15), the simulated agents gradually became more likely to take risks. This trend reaffirms the presumption that agents who are more disposed to risk are more likely to gamble. Remarkably, the agent with the highest risk attitude accepted the gambles in the majority of trials, with only rare exceptions. Through these simulations, we can deeply examine the capacity of the learning model to adapt to a variety of situations in numerous ways. When the learner's predictions µ (k) C match the decision-maker's choice C (k) o , the posterior expectation of risk attitude µ (k) ρ remains the same. On the other hand, when the learner's predictions are at odds with the decision-maker's choice, the posterior expectation is impacted accordingly. If the learner underestimates the decision-maker's risk attitude (δ (k) &gt; 0), the expected risk attitude increases; contrarily, if the learner overestimates the decision-maker's risk attitude(δ (k) &lt; 0), the expected risk attitude decreases. The Bayesian learner initially posits a prior mean and prior variance for the parameter of interest: µ (0) ρ = 1, σ (0) ρ = 0.01. The Bayesian learner employs a dynamic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>The top panel inFig 2illustrates that there is a close link between learning rates α(k)  and the degree of uncertainty in posterior expectations σ(k)    ρ . This is evident from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig 1 .</head><label>1</label><figDesc>Computational trajectories of learning risk attitudes ρ for simulated agents. Risk attitude values: ρ = {0.85, 0.95, 1, 1.05, 1.15} and β = 1. Each column corresponds to one agent. Two blocks (56 trials) make up each simulation run for each agent. Top: -blue line: Posterior expectation µ (k) ρ of risk attitude ρ. The regions within one standard deviation of the mean σ (k) ρ were shaded in blue. The mild green area is indicative of a risk-taking attitude (ρ &gt; 1), while the mild red area is indicative of a risk-averse attitude(ρ &lt; 1). The black dot line indicates neutrality (ρ = 1). Middle: -orange line: Graph representing the Baysian dynamic learning rate α (k) modulating the impact of choice prediction errors δ (k) on µ (k) ρ .The y-axis is shown in log scale. Bottom: gray dot: simulated agent choices C (k)o . red bar: Prediction error δ(k)  , the difference between the actual choice C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>the prediction uncertainty, and experienced the most drastic decrease when the uncertainty was at its highest (σ C max = 0.25) .The result of the simulation was in agreement with Eq (22), showing that the theoretical and simulated results were consistent Fig 3 illustrates the trajectory of σ (k) ρ and α (k) across thousands of trials. This graph, with both the x-and y-axes in log scale, shows that there is a negative linear relationship between σ (k) ρ and trial number k in log space. In other words, the logarithm of σ (k) ρ decreases linearly with the increase of logarithm of trial number k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig 2 .</head><label>2</label><figDesc>The relationship between the rate of learning and the model's uncertainties. Top: -orange line (right axis): Learning rate α (k) . -purple line (left axis): Variance of the posterior expectation σ (k) ρ . The y-axis is scaled in logarithmic units on both sides. Middle: -purple line (right axis): Variance of the posterior expectation σ (k) ρ . The y-axis is shown in log scale. black bar (left axis): The bar chart illustrates the collective uncertainty of the learning model in predicting decisions made by the agent. Bottom: The chart displays the model's uncertainty in predicting agent's choices σ (k) C . The value is confined to a positive number that is less than one-fourth (0 ≤ σ (k) C ≤ 0.25), as it reflects the variance of a Bernoulli distribution employed to model predictions. The upper bound σ max is represented by a black dotted line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>at -2, indicating that the initial value σ (0) ρ was 0.01, as set initially. In Fig4, β is a parameter that controls how random an agent's decisions are (see Computational model of risky behavior). Near-zero values of β producing completely unpredictable choices (σ (k) C = 0.25). As the level of β rises, the amount of uncertainty August 24, 2023 10/26</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig 3 .</head><label>3</label><figDesc>The figure demonstrates the convergence of σ (k) ρ and α (k) trajectories towards a stable equilibrium throughout numerous simulation trials. The line Y=-X-2 serves as an asymptotic line for σ (k) ρ , depicting the pattern of variation of σ (k) ρ over the course of numerous trials. both x and y axis depicted in log scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>approach zero at the highest values of β, where the agent chooses in a predictable fashion, demonstrating that deterministic choices are the easiest to comprehend.Subsequently, we ran a simulation to explore the impact of β on σ(k) ρ and α (k) . The upper panel of Fig 4 illustrates the outcome of the simulation. σ (k) ρ and β have an inversely proportional relationship according to Eq (22), which shows that when β increases, σ (k) ρ decreases. Furthermore, β's influence on σ (k) C (bottom panel) also impacts σ (k) ρ in a complex way: as β rises, σ (k) C decreases, which in turn causes σ (k) ρ to increase (Eq 22). Simulations indicate that when these two opposing forces are in contention, σ (k) ρ ultimately diminishes when β increases. Turning next to α (k) , Eq (20) elucidates its direct relationship to both σ (k) ρ and β. So too, we see an opposition between two forces here. However, the simulations indicate that as β increases, the opposing forces between σ (k) ρ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig 4 .</head><label>4</label><figDesc>effect of β on σ α (k) . For each level of β, four blocks of twenty-eight trials were run, with the average of each variable in the last block represented in the figure. Risk attitude ρ was 1 in all simulations. Top: -orange line: Learning rate α (k) . -purple line: Variance of the posterior expectation σ (k) ρ . The y-axis is scaled in logarithmic units. Bottom: The model's uncertainty in predicting agent's choices σ (k) C .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig 5</head><label>5</label><figDesc>reveals that the Bayesian learner's average learning rateᾱ BL is comparable to the fixed learning rate of the R-W reinforcement learning model α RL , despite a slight downward trend. This accomplishment is attributed to BL's ability to implement a vague prior and adjust its learning rate according to its uncertainty. This systematic tuning of the learning rate enables BL to achieve a similar accuracy score to R-W, while only needing one fitting parameter instead of two. Furthermore, the August 24, 202312/26</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>to conduct the analysis and the results indicated that the Bayesian learner was the superior model compared to the R-W model in explaining the participants' behavior (EF= 0.99, EP=1, PEP=1). Please refer toFig 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig 5 .</head><label>5</label><figDesc>Fig 5. Figure displays the learning trajectories of both R-W reinforcement learning and Bayesian learning (BL) models. It is based on the choice behavior of one subject from the study conducted by Suzuki et al. [30]. The R-W trajectories represents by -light blue line and the BL trajectories represents by -dark blue line. On the top panel, -dark green line illustrates the maximum likelihood estimation (MLE) of the subject's risk attitude, which has been calculated separately for each session. Here, we present the fitted parameters for each model in each sessions. Additionally, we calculated the average dynamic learning rate of the Bayesian Learner to compare with the fixed rate of the Reinforcement Learner. Session 1:ᾱ BL = 0.08 ; α R−W = 0.08 ; β BL = 1.45 ; β R−W = 1.44 / Session 3:ᾱ BL = 0.03 ; α R−W = 0.04 ; β BL = 0.54 ; β R−W = 0.55 / Session 5:ᾱ BL = 0.06 ; α R−W = 0.07 ; β BL = 0.77 ; β R−W = 1.10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>Figure displaysthe learning trajectories of both R-W reinforcement learning and Bayesian learning (BL) models. It is based on the choice behavior of one subject from the study conducted by Suzuki et al.<ref type="bibr" target="#b29">[30]</ref>. The R-W trajectories represents by -light blue line and the BL trajectories represents by -dark blue line. On the top panel, -dark green line illustrates the maximum likelihood estimation (MLE) of the subject's risk attitude, which has been calculated separately for each session. Here, we present the fitted parameters for each model in each sessions. Additionally, we calculated the average dynamic learning rate of the Bayesian Learner to compare with the fixed rate of the Reinforcement Learner.Session 1:ᾱ BL = 0.08 ; α R−W = 0.08 ; β BL = 1.45 ; β R−W = 1.44 / Session 3:ᾱ BL = 0.03 ; α R−W = 0.04 ; β BL = 0.54 ; β R−W = 0.55 / Session 5:ᾱ BL = 0.06 ; α R−W = 0.07 ; β BL = 0.77 ; β R−W = 1.10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig 6 .</head><label>6</label><figDesc>Bayesian Model Selection R-W vs BL</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>C</head><label></label><figDesc>) and decision maker randomness (β). The simulation results corroborated the hypothesis that the learning rate α (k) was contingent on σ(k) ρ and σ (k)C , as indicated by the theoretical analysis. Furthermore, the simulation results demonstrated that an increase in β has an adverse effect on both other types of uncertainty (σ impact on the learning rate α(k)  .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig 7 .</head><label>7</label><figDesc>(a) Schematic illustration of a gambling game. The reward probability p and magnitude of the reward r are presented in the form of a pie chart. In the pie chart, there is a blue area indicating the likelihood of receiving a reward, and a gray area indicating the likelihood of receiving nothing. The amount of the reward is displayed within the blue area, which in this example is 25$. (b) A set of gambles employed in simulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>the decision is made at random. Conversely, a large β suggests that the person frequently makes non-random decisions. The S(•) value tends to 1 when F (•) is large and positive. As a result, the decision-maker is certainly willing to take the risky option. In contrast, when F (•) is large and negative, S(•) tends to 0, and the decision-maker rejects the risky options.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>the first and second derivatives of I(ρ (k) ) with respect to µ (k−1) ρ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>) Update Equations: structural interpretation</head><label></label><figDesc></figDesc><table><row><cell cols="4">It is evident from Eqs. (16) and (17) that inverting the model by variational Bayes</cell></row><row><cell>approximation provides straightforward rules for updating µ</cell><cell>(k) ρ and σ</cell><cell>(k) ρ</cell><cell>in a</cell></row><row><cell cols="4">trial-by-trial basis that are computationally feasible. Although the updating equations</cell></row><row><cell cols="4">are derived from Bayesian optimality, without consideration of reinforcement learning</cell></row><row><cell cols="4">(RL) structure, they are well captured by the Rescorla-Wagner reinforcement learning</cell></row><row><cell>model</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>(see Experimental Task). Fig illustrates the computational trajectories of learning risk attitude ρ for five simulated agents. The agents were designed to emulate a range of risk preferences and behaviors. Simulated agents are characterized by their risk attitudes ρ, the values of which are outlined below: ρ = {0.85, 0.95, 1, 1.05, 1.15}</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>-Wagner (R-W) model<ref type="bibr" target="#b28">[29]</ref>, a widely used reinforcement learning model. The R-W model adjusts estimations through a prediction error weighted by a preset learning rate, whereas the Bayesian model adjusts the learning rate at each trial, eliminating the need for a predetermined learning rate. As each participant's data is unique, the R-W learner's accuracy is reduced if the optimal learning rate is not found for each individual. Therefore, the Bayesian model only requires one adjustable parameter to fit β to each set of data, whereas the R-W model requires two.</figDesc><table><row><cell>August 24, 2023</cell><cell>11/26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Comparison of the goodness-of-fit between the Bayesian learner and the Rescorla-Wagner learner. For the Bayesian Information Criterion (BIC), the smaller the value, the better the fit. The Log-likelihood (LL) and Log Model Evidence (LME) both indicate better fit with bigger values; # prms, number of free parameters. Each session's best model is bolded.</figDesc><table><row><cell>session</cell><cell>Model</cell><cell>LL</cell><cell>BIC</cell><cell># prms</cell><cell>LME</cell></row><row><cell>session 1</cell><cell>Bayesian Learner</cell><cell cols="2">−245.96 571.89</cell><cell>1</cell><cell>-277.79</cell></row><row><cell cols="4">Rescorla-Wagner Learner −236.02 631.98</cell><cell>2</cell><cell>−313.44</cell></row><row><cell>session 3</cell><cell>Bayesian Learner</cell><cell cols="2">−173.69 427.35</cell><cell>1</cell><cell>-200.82</cell></row><row><cell cols="4">Rescorla-Wagner Learner −180.71 521.36</cell><cell>2</cell><cell>−259.29</cell></row><row><cell>session 5</cell><cell>Bayesian Learner</cell><cell cols="2">−182.54 445.05</cell><cell>1</cell><cell>-210.40</cell></row><row><cell cols="4">Rescorla-Wagner Learner −168.12 496.19</cell><cell>2</cell><cell>−234.89</cell></row><row><cell>Discussion</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">In this research, we applied a Bayesian framework to explore how humans may judge</cell></row><row><cell cols="6">another person's risk-taking tendency based on a few examples presented in succession.</cell></row></table><note>Our findings offer insights into the intricate social psychology of risk-assessment. We designed a scenario where an observer, online, could watch another person's decisions and form an opinion about him. The observer was presented with a choice between a high-risk gamble with a larger potential reward or a risk-free option with a guaranteed smaller reward for the person being observed. The observer would infer the other person's attitude sequentially based on these observed choices.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">August 24, 2023 7/26</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">August 24, 2023</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">August 24, 202315/26</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">August 24, 2023 22/26</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">August 24, 2023 25/26</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">August 24, 2023 26/26</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are thankful to Shinsuke Suzuki for providing us access to the experimental dataset utilized in this study.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix S1: Simplifying the variational energy. It is possible to simplify the expression ln 1 − S F (ρ <ref type="bibr">(k)</ref> in Eq <ref type="bibr" target="#b13">(14)</ref> in the following manner:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Observational learning. The international encyclopedia of communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bandura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Toward an applied theory of experiential learning. Theories of group processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Kolb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Insights from the application of computational neuroimaging to social neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dunne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current opinion in neurobiology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="392" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The application of computational models to social neuroscience: promises and pitfalls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Charpentier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="637" to="647" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Vicarious reinforcement and imitative learning. The Journal of abnormal and social psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bandura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Ross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963" />
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">601</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Getting to know you: reputation and trust in a two-person economic exchange</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>King-Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tomlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Anen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Quartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="issue">5718</biblScope>
			<biblScope unit="page" from="78" to="83" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The behavioral and neural mechanisms underlying the tracking of expertise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Boorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Adolphs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1558" to="1571" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Self-other mergence in the frontal cortex during cooperation and competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Wittmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kolling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Faber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scholl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nelissen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Rushworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="482" to="493" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inferring on the intentions of others by hierarchical Bayesian learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Diaconescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mathys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kasper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Lomakina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1003810</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning-induced plasticity in medial prefrontal cortex predicts preference malleability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Garvert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moutoussis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="418" to="428" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning about and from others&apos; prudence, impatience or laziness: The computational bases of attitude alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1005422</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dealing with uncertainty: Testing risk-and ambiguity-attitude across adolescence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Blankenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Crone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Den Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Van Duijvenvoorde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental neuropsychology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="77" to="92" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A meta-analysis on age differences in risky decision making: adolescents versus children and adults</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">N</forename><surname>Defoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Dubas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Figner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Van Aken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The helmholtz machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimal inference with suboptimal models: addiction and active Bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schwartenbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mathys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kronbichler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical hypotheses</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="117" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bayesian natural selection and the evolution of perceptual systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Diehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London Series B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="page" from="419" to="448" />
			<date type="published" when="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A free energy principle for the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kilner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of physiology-Paris</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="70" to="87" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The free-energy principle: a unified brain theory?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature reviews neuroscience</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="138" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Bayesian brain: the role of uncertainty in neural coding and computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Knill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TRENDS in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="712" to="719" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic brains: knowns and unknowns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1170" to="1178" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Algorithms for inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Icml. vol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural computations underlying inverse reinforcement learning in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Collette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Pauli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">29718</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning the value of information in an uncertain world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Woolrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Rushworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1214" to="1221" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A simple model for learning in volatile environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">1007963</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Observing the observer (I): meta-bayesian models of learning and decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Den Ouden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pessiglione</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kiebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">15554</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Primer on Variational Laplace (VL)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zeidman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Parr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="page">120310</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Free-energy and the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="417" to="458" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Information theory and statistical mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">620</biblScope>
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and non-reinforcement. Classical conditioning, Current research and theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rescorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="64" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Behavioral contagion during learning about another agent&apos;s risk-preferences acts on the neural representation of decision-risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="3755" to="3760" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">TAPAS: an open-source software package for translational neuromodeling and computational psychiatry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frässle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Aponte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bollmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Brodersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">K</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychiatry</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">680811</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bayesian model selection for group studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Penny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1004" to="1017" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Comparing dynamic causal models using AIC, BIC and free energy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Penny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="319" to="330" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bayesian model selection for group studies-revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rigoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="971" to="985" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">VBA: a probabilistic treatment of nonlinear models for neurobiological and behavioural data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rigoux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1003441</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heasly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">37</biblScope>
			<biblScope unit="page" from="12366" to="12378" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Reinforcement learning in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The computational challenge of social learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Feldmanhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1045" to="1057" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neural mechanisms of observational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Tobler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baddeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">32</biblScope>
			<biblScope unit="page" from="14431" to="14436" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Associative learning of social value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Woolrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Rushworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">456</biblScope>
			<biblScope unit="issue">7219</biblScope>
			<biblScope unit="page" from="245" to="249" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neural correlates of reinforcement learning and social preferences in competitive bidding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Den Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcclure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2137" to="2146" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Instrumental learning of traits versus rewards: dissociable neural correlates and effects on choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Hackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Doll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Amodio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1233" to="1235" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning moral values: Another&apos;s desire to punish enhances one&apos;s own punitive behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Feldmanhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Phelps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1211</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The sense of confidence during probabilistic learning: A normative account</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meyniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schlunegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1004305</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Payzan-Lenestour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1001048</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Confidence as Bayesian probability: From neural origins to behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meyniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">F</forename><surname>Mainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="92" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Metacognition in human decision-making: confidence and error monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="1310" to="1321" />
			<date type="published" when="1594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Bayesian data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Comparing objective and subjective learning curves: judgments of learning exhibit increased underconfidence with practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koriat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma'ayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">147</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Evaluation of objective uncertainty in the visual system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barthelmé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1000504</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The anterior cingulate gyrus and social cognition: tracking the motivation of others</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Apps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Rushworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="692" to="707" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Social learning in the medial prefrontal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Apps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="151" to="152" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Resolving uncertainty in a social world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Feldmanhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature human behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="426" to="435" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Apprenticeship learning via inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Learning from other minds: An optimistic critique of reinforcement learning models of social learning. Current opinion in behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vélez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gweon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="110" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">People learn other people&apos;s preferences through inverse decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="page" from="46" to="64" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Rational quantitative attribution of beliefs, desires and percepts in human mentalizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saxe</forename><forename type="middle">R</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Action understanding as inverse planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="349" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Help or hinder: Bayesian models of social goal inference. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Macindoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">22</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Using inverse planning and theory of mind for social goal inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tauber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
		<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A decision network account of reasoning about other people&apos;s choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page" from="12" to="38" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Information about others&apos; choices selectively alters risk tolerance and medial prefrontal cortex activation across adolescence and young adulthood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Braams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Davidow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Somerville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">101039</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Adolescents&apos; risk-taking behavior is driven by tolerance to ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tymula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosenberg</forename><surname>Belmaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Ruderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Manson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Glimcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">42</biblScope>
			<biblScope unit="page" from="17135" to="17140" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Neural representation of subjective value under risk and ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neurophysiology</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1036" to="1047" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Neural systems responding to degrees of uncertainty in human decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Adolphs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tranel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">310</biblScope>
			<biblScope unit="issue">5754</biblScope>
			<biblScope unit="page" from="1680" to="1683" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Exposition of a New Theory on the Measurement of Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bernoulli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="36" />
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Advances in prospect theory: Cumulative representation of uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Risk and uncertainty</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="297" to="323" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Prospect Theory: An Analysis of Decision under Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="292" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Consumption theory in terms of revealed preference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Samuelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economica</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">60</biblScope>
			<biblScope unit="page" from="243" to="253" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Variational free energy and the Laplace approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mattout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Trujillo-Barreto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Penny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="220" to="234" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A Bayesian foundation for individual learning under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mathys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in human neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
