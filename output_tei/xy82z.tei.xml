<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Language Model (LLM) Algorithms in Reshaping Decision-Making and Cognitive Biases in the AI-Leading World: An Experimental Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>MPCP</roleName><forename type="first">Haleema</forename><surname>Khatoon¹</surname></persName>
							<email>haleema.khatoon786@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mbhs</forename><forename type="middle">;</forename><surname>Muhammad</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>PhD, MS;</roleName><forename type="first">Luqman</forename><surname>Khan²</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asmara</forename><surname>Irshad³</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>MPCP, MBHS</roleName><forename type="first">Haleema</forename><surname>Khatoon</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">BEd _____________________________________________________________________ ¹Cognitive Psychologist</orgName>
								<orgName type="institution" key="instit1">MPCP</orgName>
								<orgName type="institution" key="instit2">Behavioral Scientist</orgName>
								<orgName type="institution" key="instit3">Mental Health Researcher</orgName>
								<address>
									<settlement>Dubai</settlement>
									<country>United Arab</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Head Department of Psychology</orgName>
								<orgName type="department" key="dep2">³Clinical Psychologist</orgName>
								<orgName type="institution" key="instit1">Emirates ²Associate Professor</orgName>
								<orgName type="institution" key="instit2">Riphah International University</orgName>
								<address>
									<settlement>Faisalabad</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Adolescent&apos;s Mental Well-Being Research</orgName>
								<address>
									<settlement>Faisalabad</settlement>
									<country key="PK">Pakistan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Cognitive Psychologist &amp; Behavioral Scientist Independent Mental Health Researcher Pyramid Towers</orgName>
								<address>
									<addrLine>Oud Mehta Dubai</addrLine>
									<country key="AE">United Arab Emirates</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large Language Model (LLM) Algorithms in Reshaping Decision-Making and Cognitive Biases in the AI-Leading World: An Experimental Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human-technology interaction</term>
					<term>Heuristics</term>
					<term>Decision making competence</term>
					<term>Deep learning</term>
					<term>Natural language processing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The rise of artificial intelligence (AI) has accelerated decision-making since AI algorithmic recommendation may help reduce human limitations while increasing decision accuracy and efficiency. Large language model (LLM) algorithms are designed to enhance human decisionmaking competencies and remove possible cognitive biases. However, these algorithms can be biased and lead to poor decision-making. Building on previously existing LLM algorithm (i.e., ChatGPT and Perplexity.ai), this study examines whether users who get AI assistance during task-based decision-making have greater decision-making abilities than their peers who employ their own cognitive processes to make decisions. By using domain-independent LLM 1 , incentives, and scenario-based task decisions, we find that the advice suggested by these AIs in the decisive situations were biased and wrong, and that resulted in poor decision outcomes. It has been observed that using public access LLM in crucial situations might result in both ineffective outcomes for the advisee and inadvertent consequences for third parties. Findings highlight the need of having an ethical AI algorithm and the ability to accurately assess trust in order to effectively deploy these systems. This raises concerns regarding the use of AI in decision making with careful assistance. 1 A domain-independent large language model (LLM) is an artificial intelligence model that can create and interpret text from a variety of topics and settings without being trained on a single subject.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The Large Language Models (LLMs) signify a substantial leap forward in Artificial Intelligence, specifically in the field of Natural Language Processing (NLP). Such models have been increasingly integrated into various decision-making processes across multiple domains, from academia and business to healthcare and software engineering <ref type="bibr" target="#b24">(Chien et al., 2024;</ref><ref type="bibr" target="#b42">Imam &amp; Altawaiha, 2023)</ref>. LLMs like GPT-4 have demonstrated the ability to automate complex decision-making tasks by acting as virtual experts, thereby enhancing efficiency and reliability in areas such as cybersecurity <ref type="bibr" target="#b3">(Anas et al., 2024)</ref>. Moreover, LLMs have been employed to optimize wireless networks through in-context learning, evading the need for extensive model training and fine-tuning <ref type="bibr" target="#b84">(Zhou et al., 2024)</ref>. However, the application of LLMs in decisionmaking is not without challenges. The cost of calibrating LLMs to achieve desired performance levels can be substantial, and there is a need to balance this with the potential benefits <ref type="bibr" target="#b34">(Gaikwad &amp; Nagale, 2021)</ref>. Additionally, LLMs can exhibit biases, which necessitates the development of system of measurement like the Large Language Model Bias Index (LLMBI) to quantify and mitigate these biases to ensure fair and reliable decision-making <ref type="bibr" target="#b3">(Anas et al., 2024)</ref>.</p><p>Furthermore, the use of LLMs in generating case reports in medicine, such as in the study of synchronous bilateral breast cancer, illustrates the potential of these models to aid in clinical decision-making <ref type="bibr" target="#b34">(Gaikwad &amp; Nagale, 2021)</ref>. In summary, LLMs are gaining recognition for their ability to revolutionize decision-making across various sectors. While they offer the promise of automating and enhancing decision-making processes, it is crucial to address the associated costs, biases, and the need for regulating it to fully harness their capabilities. The continued exploration and refinement of LLMs in decision-making contexts underscore their transformative potential and the importance of developing robust, unbiased, and cost-effective LLM-based solutions <ref type="bibr" target="#b3">(Anas et al., 2024;</ref><ref type="bibr" target="#b34">Gaikwad &amp; Nagale, 2021;</ref><ref type="bibr" target="#b84">Zhou et al., 2024)</ref>.</p><p>This study explores whether human-AI collaborative decision making is better as compared to human intuitive and cognitive processing based decision making. To examine this hypothesis we used an incentivized, task based decision making experimentation based on culturally adapted task sets 2 (see Appendix-A), that has to be completed with collaborative AI recommendation. We test whether human-AI assisted decision-making was efficient and better in any way than human decision-making without technology aid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Literature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Human-AI collaboration vs Human Intuition in Decision-Making</head><p>Human-AI collaboration and human intuition in decision-making are not mutually exclusive but rather complementary elements in the decision-making process. Human-AI collaboration leverages the capabilities of both AI and humans, with AI offering insights based on data and the humans contributing in nuanced decision-making that often involves intuition <ref type="bibr" target="#b64">(Neyigapula, 2023)</ref>. Intuition plays a crucial role in strategic decisions and can be integrated into AI-aided decisions either through interaction models or by attempting to replicate human intuition within AI systems <ref type="bibr" target="#b0">(Abbasi et al., 2024)</ref>. Interestingly, while AI can enhance decision-making, it can also lead to overreliance, especially when AI explanations are not effectively aiding the decision-makers' understanding. The decision-makers harmonize their sense of intuition with AI information to choose whether to defy AI forecasts, and this interplay can be complex <ref type="bibr" target="#b22">(Chen et al., 2023)</ref>. Moreover, ethical considerations emerge when AI is involved in decisions, such as in environmental policy, where collaboration must be managed carefully to ensure ethical outcomes <ref type="bibr" target="#b36">(Goalla et al., 2023)</ref>. In conclusion, human-AI collaboration in decision-making is a multifaceted interaction that benefits from the integration of human intuition and the analytical capabilities of AI algorithms. The challenge lies in designing AI systems and interfaces that support effective collaboration without fostering overreliance, while also considering the ethical implications of such collaborations <ref type="bibr" target="#b0">(Abbasi et al., 2024;</ref><ref type="bibr" target="#b22">Chen et al., 2023;</ref><ref type="bibr" target="#b36">Goalla et al., 2023;</ref><ref type="bibr" target="#b64">Neyigapula, 2023)</ref>.</p><p>The interplay between human intuition and artificial intelligence (AI) in decisionmaking processes has garnered significant attention in recent literature. This review explores the complexities of Humans and AI reciprocity, emphasizing the potencies and drawbacks of both human intuition and AI capabilities. Human intuition is often characterized by its reliance on experiential knowledge and emotional intelligence. Research indicates that human decisionmakers utilize intuitive reasoning to assess outcomes, especially in complex and uncertain situations <ref type="bibr" target="#b27">(Dane et al., 2012)</ref>. This intuition can be categorized into three types: intuition about task outcomes, intuition regarding AI predictions, and contextual intuition that integrates human experience with AI-generated data <ref type="bibr">(Sadler-Smith et al., 2022)</ref>. For instance, while AI excels in processing vast datasets and identifying patterns, humans are better equipped to interpret these insights within a broader context, considering ethical implications and emotional factors that AI cannot comprehend <ref type="bibr" target="#b48">(Kahneman, 2011)</ref>. Conversely, AI systems are designed to complement the decision-making of humans by delivering information driven by data and predictive analytics. Recent studies highlight the capacity of AI to accelerate decision-making through its ability to automate information gathering and processing, thereby reducing cognitive loads on human users <ref type="bibr" target="#b16">(Brynjolfsson et al., 2008)</ref>. AI can aggregate predictions from multiple sources, offering recommendations that can significantly improve the accuracy and efficiency of decisions. However, the effectiveness of this collaboration hinges on the trust and transparency established between human users and AI systems. Trust is critical, as users must feel confident in the capabilities of AI and understand its decision-making processes to rely on its outputs effectively <ref type="bibr">(Sadler-Smith et al., 2022;</ref><ref type="bibr" target="#b57">Lee &amp; See, 2004)</ref>.</p><p>The concept of Human-AI synergy suggests that optimal decision-making occurs when both human intuition and AI capabilities are integrated. This synergy allows for a more comprehensive approach to problem-solving, where AI provides analytical support while humans apply their creativity and critical thinking skills <ref type="bibr" target="#b79">(Shneiderman, 2020)</ref>. For example, in hiring decisions, AI can evaluate candidates based on quantifiable metrics, while human decision-makers can interpret these findings within the context of organizational culture and values <ref type="bibr" target="#b13">(Binns, 2022)</ref>. Ultimately, the literature indicates that the future of decision-making will likely involve a synergic approach where the humans and AI collaborate while exploiting their particular abilities. This partnership not only enhances decision quality but also fosters innovation and adaptability in various fields, including healthcare, finance, and human resources. By embracing this collaborative approach, organizations can navigate the complexities of modern decision-making landscapes more effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Human Cognitive Biases &amp; AI Reshaped Decision-Making</head><p>The integration of cognitive debiasing techniques into AI to enhance decision-making is a nuanced topic. <ref type="bibr" target="#b38">Hagendorff et al. (2023)</ref> suggests that incorporating human cognitive debiasing into AI algorithms could improve its performance in complex, real-world situations.</p><p>Conversely, <ref type="bibr" target="#b74">Romanov et al. (2023)</ref> introduces a method to eliminate biases, such as the order effect, from AI systems to promote fairness and transparency. These contrasting perspectives indicate a dichotomy in the approach to biases within AI-assisted decision-making.</p><p>Interestingly, while <ref type="bibr">Kaplan et al. (2023)</ref> acknowledges the presence of biases in human decision-making and the potential for unforseen consequences when humans collaborate with AI, it also emphasizes the need for guidelines to address the human factor in AI-based systems. <ref type="bibr" target="#b82">Vold (2024)</ref> and <ref type="bibr" target="#b19">Chanda (2024)</ref> further discuss the benefits of AI in supporting human cognitive resources and decision-making, yet caution against over-reliance on AI systems. <ref type="bibr" target="#b71">Prajapati et al. (2022)</ref> and <ref type="bibr" target="#b34">Gaikwad and Nagale (2021)</ref> highlight the application of AI in clinical decision support systems, with the latter discussing the use of AI algorithms in disease diagnosis. However, <ref type="bibr" target="#b71">Prajapati et al. (2022)</ref> also raise ethical concerns regarding the use of AI in clinical settings.</p><p>In summary, the literature presents a complex picture of the function of cognitive biases in making decisions with the assistance of AI. While some research advocates for the deliberate implementation of biases to mirror human cognition <ref type="bibr" target="#b38">(Hagendorff et al., 2023)</ref>, others focus on mitigating these biases to ensure equitable and unbiased AI systems <ref type="bibr" target="#b74">(Romanov et al., 2023)</ref>.</p><p>The importance of human-AI collaboration is recognized, but with an emphasis on the careful design of systems to manage the influence of human biases <ref type="bibr">(Kaplan et al., 2023)</ref> and the risks of dependency on AI <ref type="bibr" target="#b19">(Chanda, 2024;</ref><ref type="bibr" target="#b82">Vold, 2024)</ref>. Ethical considerations are also paramount in the deployment of AI in sensitive areas such as healthcare diagnosis, security checks <ref type="bibr" target="#b34">(Gaikwad &amp; Nagale, 2021;</ref><ref type="bibr" target="#b71">Prajapati et al., 2022)</ref>. Therefore, the development and application of AI in decision-making must balance the benefits of bias implementation with the need for fairness, transparency, and ethical responsibility <ref type="bibr" target="#b19">(Chanda, 2024;</ref><ref type="bibr" target="#b34">Gaikwad &amp; Nagale, 2021;</ref><ref type="bibr" target="#b38">Hagendorff et al., 2023;</ref><ref type="bibr">Kaplan et al., 2023;</ref><ref type="bibr" target="#b71">Prajapati et al., 2022;</ref><ref type="bibr" target="#b74">Romanov et al., 2023;</ref><ref type="bibr" target="#b82">Vold, 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Research Design and Speculations</head><p>The majority of studies that have been conducted thus far have been substantially domaindriven and highly reliant on complicated context descriptions. Examples of these studies include those that look at advice in legal <ref type="bibr" target="#b4">(Araujo et al., 2020;</ref><ref type="bibr" target="#b12">Bigman &amp; Gray, 2018)</ref>, dating or financial <ref type="bibr" target="#b18">(Castelo et al., 2019;</ref><ref type="bibr" target="#b76">Schaap et al., 2023)</ref>, as well as the medical domains <ref type="bibr" target="#b60">(Longoni et al., 2019;</ref><ref type="bibr" target="#b70">Prahl &amp; Van Swol, 2017)</ref>. Studies that are domain-agnostic and seek to supplement the existing literature with a more broadly applicable methodology are scarce. Even though some preceding investigations have incorporated somewhat abstract objectives, specifically estimating the weight of humans or projecting the recognitions of songs <ref type="bibr" target="#b59">(Logg et al., 2019)</ref>, these tasks imply limited influence on users and scarcely reflect genuine situations of decision making with AI assistance <ref type="bibr" target="#b76">(Schaap et al., 2023)</ref>. Contrary to this, our experiment strives to be as generic as feasible while keeping core aspects of the recent use cases based on AI advice: A context of uncertainty, guidance on an ambiguous real life scenario, framing biasness, recognizing social norms, risk perception, sunk cost fallacy, under and over confidence and applying decision rules in real life. Whether it is a medical counsel influencing doctor-patient interactions, HR advice influencing recruiter-applicant interactions, or juridical guidance influencing judge-defendant encounters, most AI-assisted decisions occur in potentially hazardous settings and have a consequential effect on human interaction in one way or another.</p><p>To reflect such practicality, we are exploring how the participants respond to AI-generated advice in a connected environment with a third party.</p><p>To accomplish this, we are employing modified task-sets , where there are sequential tasks based decision starting from four sets of seven real-life scenarios (RC1, RC2, A1 and A2) wherein the human decision maker (HDM) was required to select from a variety of options (tasks based on positive and negative framing). Their decision can go from 1 to 6, with two alternates. Next comes two sets (SN1 &amp; SN2) of sixteen statements. SN1 enquires whether it is occasionally "OK" to do different things. The score options for SN1 are binary (yes or no).</p><p>SN2 consists of statements that ask, "Out of 100 people your age, how many would say it is sometimes OK to do different things." The options range from 0 (none) to 100 (everyone). The next task-set focusses on under and overconfidence, it consists of 33 statements to which the participant responds by selecting true or false and then stepping into a number on the scoring sheet to indicate their choice confidence (%). The scale ranges from 50% (you were guessing) to 100% (you were certain). After that, the participant moves on to another task where they apply decision rule. They have 10 different tasks to select the best features in the preferred choice item. This task is demanding and difficult. The participant must select one of the potential possibilities and write their response in the specified section. Before initiating next tasks, the participants were provided with a short relaxation break, to avoid mental fatigue.</p><p>Next ten probability questions related to risk perception were in the task, which were split into two sets (A and B), each asked for the best estimation of the likelihood that a certain event will occur in the future. Users must select a mark on the "probability scale" at a particular moment and record that point on the scoring sheet in order for the score value to be determined. Sunk cost based ten problems with two options each, is the final task, it primarily based on sunk cost fallacy 4 . Each task represents a real-world situation that involves the fallacy of sunk costs. For every task, a scale ranging from 1 (one option) to 6 (the other option) is provided. The users (experimental group) have been provided with LLM's based AI as their co-pilot in performing these tasks.</p><p>Thus, our work is broadly domain-independent but it still includes essential components of AI-assisted decision making, human user interaction, and a motivational academic incentive for the participants. The setting is theoretically simple, majorly requires making a binary decision that have commonly employed in behavioral experiments to analyze how people interact in particular. We may assess its effect on respondents' decision-making despite the need for in-depth background explanations, topic expertise, or previous knowledge by including an LLM as an assistance. Therefore, one of our objectives is to clarify how individuals mold their decision with AI assistance in a broader context, free from the effect of particular situations or domains that frequently result in algorithm repulsion or recognition in first place <ref type="bibr" target="#b30">(Dietvorst et al., 2015;</ref><ref type="bibr" target="#b59">Logg et al., 2019)</ref>. This methodological decision further enables us to discern between the decisionmaking process of participants based on the AI and their attitude of trust towards it. A number of studies have only examined one of the two conceptions of trust and decision, and existing empirical research frequently fails to conceptually separate the two enough <ref type="bibr" target="#b52">(Kohn et al., 2021;</ref><ref type="bibr" target="#b77">Scharowski et al., 2023)</ref>. Numerous researches just employ questionnaires to measure technology use, but this provides fewer resources for drawing conclusions about the real behavior which is a crucial consideration for any practical ramification. Nevertheless, the majority of algorithm aversion or appreciation research only look at the behavioral measures of dependence which prevents inferences about the underlying decision-making process <ref type="bibr" target="#b54">(Körber, 2018;</ref><ref type="bibr" target="#b57">Lee &amp; See, 2004;</ref><ref type="bibr" target="#b62">Miller et al., 2016)</ref>. In this sense, we respond to the need that both notions be distinguished and measured <ref type="bibr" target="#b77">(Scharowski et al., 2023)</ref>. The fact that there are no obstacles between trusting (being prepared to take on risk) and depending (actually accepting risk) which is one of the benefits of our controlled experiment setup. In addition, there is no mechanism that compels the participants to follow suggestions by LLM, giving them complete control over their decision. Therefore, in line with previous researches <ref type="bibr" target="#b52">(Kohn et al., 2021;</ref><ref type="bibr" target="#b68">Pearson et al., 2019)</ref>, we are anticipating that the participants with LLM assistance will also exhibit better decision outcome. Still, our interest regarding AI assisted decision making is largely on the behavioral repercussions during task performance whether the participant will continue to ignore erroneous and biased advice of AI or will take that decision.</p><p>Trusting more on AI guidance has been demonstrated as contributing to reduced cognitive effort and poor performance on tasks in previous researches <ref type="bibr" target="#b2">(Alexander et al., 2018</ref>).</p><p>However, a large portion of the empirical research that is now available was either undertaken through behavioral studies that were constrained by concentrating only on the effects on the advisee, or it was centered around surveys where respondents may be vulnerable to bias in selfreport and there are often no stakes involved <ref type="bibr" target="#b35">(Glikson &amp; Woolley, 2020;</ref><ref type="bibr" target="#b40">Hou &amp; Jung, 2021;</ref><ref type="bibr" target="#b47">Jussupow et al., 2024)</ref>. However, in many real use cases such as loan approval or applicant screening, AI advice will affect more people than the advisee alone. Hence, it is crucial to examine that how seeking advice from AI in real life situations might have both negative consequences for oneself as well as adverse effects on other parties. For this objective, present experiment supplements earlier results by offering academically incentivized motivation to be engaged, these tasks were individualized and the time allocation was 60-90 minutes excluding the short break. Participants from experimental group have received computer-version of the task sets along with LLM algorithms as AI assistance for task performance, meanwhile respondents from the control group independently reach their decision using paper based task sets. Participants from the experimental group might choose to heed guidance concerning their first intuition and seeking advice on their decision from the AI. The task were purely real life decisions during crucial times, stimulating a variety of real-life situations where the AI offers guidance in a confusing scenario, where the result is ambiguous because it depends on its future interactions with humans, for example, the guidelines by AI on loan approval, where the advice may turn out to be incorrect, if the debtor defaults on his commitments. As per earlier research <ref type="bibr" target="#b11">(Berg et al., 1995;</ref><ref type="bibr" target="#b65">Parasuraman &amp; Riley, 1997)</ref>, the outcome of our approach is that humans and AI integrated decision-making might result into better decision making, encountering cognitive biasness and enhanced decision making competency. The other possibilities could be that the AI shows results that are wrong or biased and subsequently the user over trust AI and takes biased decision. We expect that the AI will be helpful in de-biasing cognitive errors during this task based decision making.</p><p>To evaluate this hypothesis, the research question has been divided into three testable speculations:</p><p>1. Human decision-makers who work in collaboration with AI assisted decision on task set are likely to have better and unbiased decision making as compared to control group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Human decision makers are likely having high technology use and low cognitive biases</head><p>to have better decision outcomes.</p><p>3. Technology interaction, presence of cognitive biases and the decision making competency are interlinked.</p><p>In conclusion, the following contributions are the focus of this study: a) It clarifies human behavior in a domain-independent environment including generative AI, adding to the LLM's algorithm aversion and appreciation discussion; b) It offers an experimental design that adheres to controlled experimental procedures and is academically incentivized, collaborative and free from deception; c) examines the relationship between affinity of technology interaction, cognitive biases and decision making competency by evaluating both the attitudinal and behavioral measurements; and d) offers proof of whether the AI helps in de-biasing cognitive errors present during decision making, where contrary intuitive thoughts interact with available decision of AI trained LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Study Participants</head><p>We recruited psychology undergraduate students using the online student portal of the university (Moellim database, 2024). There were 210 students enrolled on the portal, 88 students initially participated in this research and later nine students were found ineligible for the study and final sample pool was N=79. The age ranges of the participants were from 17 to 24 years (Mage = 20.5, SD = 1.48). There was a total of 79 participants who were divided into two groups: the experimental group consisting of 39 individuals (n=39) and the control group comprised 40 individuals (n=40). Within these groups, there were 97.5% women in the control group and the experimental group had 94.9% women, constituted the majority of the participants. The high proportion of female participants is due to the male-to-female ratio in the Psychology department being (1:25) i.e., there is one male for every 25 females (Moellim database, 2024). 100% of individuals in the experimental group and 97.5% of participants in the control group were unmarried. In the control group, 5% of individuals were employed, but 100% of participants were unemployed in the experimental group. Participants in the experimental group (97.4%) and control group (87.5%) socioeconomically belong to middle class families. All respondents ranked the proficiency of their English language ability as outstanding, above average, or good. Most participants rated their technological proficiency as good. In the experimental group, 66.7% of participants were familiar with artificial intelligence (AI) compared to 77.5% in the control group. Additionally, half of the participants such as 62.5% in the control group and 53.8% in the experimental group reported that they were employing AI on regular basis in their routine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tasks based Decision Making</head><p>Participant performed ten task sets of a modified decision-making competence (mADMC). It has been utilized to evaluate task based decision making competence, comprises six components: resistance to framing <ref type="bibr" target="#b66">(Parker &amp; Fischhoff, 2005)</ref>, recognition of social norms <ref type="bibr" target="#b43">(Jacobs et al., 1995)</ref>, under or overconfidence <ref type="bibr" target="#b66">(Parker &amp; Fischhoff, 2005)</ref>, applying decision rules <ref type="bibr" target="#b67">(Payne et al., 1993)</ref>, consistency in risk perception <ref type="bibr" target="#b66">(Parker &amp; Fischhoff, 2005)</ref> and sunk costs <ref type="bibr" target="#b6">(Arkes &amp; Blumer, 1985)</ref>. The mADMC includes ten components, with 134 items being provided in the exact same sequence as used in previous studies (Bruine <ref type="bibr" target="#b15">de Bruin et al., 2007;</ref><ref type="bibr" target="#b9">Bavolar, 2013;</ref><ref type="bibr" target="#b10">Bavoľár &amp; Orosová, 2015</ref>).</p><p>There are six distinct tasks in the mADMC battery: Resistance to Framing, which consists of matching negative problems in RC2 and A2 and positive framing tasks in RC1 and A1. The human decision maker (HDM) in these tasks had to choose from a variety of options in seven real-life scenarios. They have two alternates and a choice rating system that goes from 1 to 6. Recognizing Social Norms (SN1 and SN2): There are sixteen statements in these two tasks. SN1 queries whether it is occasionally "OK" to act in different situations. For SN1, the scoring options are binary (yes/no). "Out of 100 people your age, how many would say that it is sometimes "OK" to do different things?" is one of the problems in SN2. From 0 (no one) to 100 (everyone), the scores are assigned. Under/Overconfidence (CAL): The task has 33 statements, to which HDM must select true or false, and then record their confidence in percentage by putting a number on the scoring sheet. The scale ranges from 50%, which denotes guess, to 100%, which signifies certainty. Applying Decision Rules (DR): Selecting the ten best features from the chosen choice item is one of the decisions. The HDM is required to select an option and record their choice in the specified sheet. Consistency in Risk Perception (RP): This task had 10 probability questions (A and B), each asking for the best estimate of the chance that a given event will occur in the future. Because the score is determined by a "probability scale," HDM must select a mark at a certain position on the scale and note that point on the scoring sheet. Resistance to Sunk Costs (SC): There are ten separate activities with two possibilities each. Every task is a real-world scenario with a possible sunk cost fallacy. For each task, a scale of 1 (one choice) to 6 (the other option) is provided.</p><p>The participants from both group (control and experimental) has followed the sequential task order; the experimental group has performed the e-version of these tasks using computer and AI based LLM algorithm to finalize their decision while control group has used paper based task sets and scoring sheets without any technical assistance or computer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Design</head><p>The study employed an experimental setup with between-subjects design (Independent groups design) that was relied on the post-test measure <ref type="bibr" target="#b78">(Shaughnessy et al., 2000)</ref> including the control group that retains the same experimental setting as indicated above, yet excluding AI assistance. The manipulations featured an AI advisor based LLM, that delivers recommendations to participants whereby content (choose A vs. choose B).</p><p>Participants thoroughly go through the instruction related to respective task set and comprehend the task based scenario and make their initial decision after that they confirm the choice with the help of AI algorithm where they received either option A (good decision) or B (bad decision) as a positive or negative advice from LLM. Participants were randomly divided into the group of five but their performance has been recorded in their individual capacity within the separated experimental cubicle. Participants got informed upon receiving suggestions from an AI algorithm based on the condition. The participants obtained information that the AI algorithm is more analytical and reasoned when making recommendations because it is knowledgeable about such tasks. Thus, there may have not been any justification to think that the AI had a greater understanding regarding the tasks compared with the participant when it generated suggestions, even if it is plausible that individual participants would have expected the AI for being more reliable.</p><p>More importantly, we were genuinely concerned about the influence of AI advice in comparison to no advice (control group). Our aim was to evaluate whether AI help participants to get the better decision outcomes while comparing it without such aid. If the decision compliance with the best of the AI algorithm, then the decision outcome will be effective and trusting the algorithm will be the worth trusting. The prompt used by all the participants were identical but the resultant AI recommendations varied for instance, AI suggested option A for one participant and option B for other. So there were two potential recommendations (option A vs option B). There was no deception involved and the participants were informed that although the perplexity.ai, ChatGPT, OpenAI's LLM algorithm is analytically strong and reasoned but there are possibilities it may give you contradictory responses so you need to work in collaborative way by incorporating human reasoning into logic.</p><p>The participants understood that the recommendations could occasionally be incorrect, and they such as a primary decision maker were solely responsible for ensuring the correct and effective decision outcome. This design was deliberate to enhance human cognitive processing and reasoning the suggestive recommendation by the LLM algorithm and participants trust and reliance over AI-assisted decision. As mentioned earlier LLM has basically generated either of two choices and there were some instances where the AI posted and unclear choice and the recommendations were posited in a manner that was ambiguous. So by trusting and reliance mean here that whether in such situations the participant follows the advice or make the human reasoning. When the accumulative behavior within treatments meets two additional requirements: 1) The participants comply with the guidance regardless of whether it challenges accessible information about the context, and 2) dependence results in less favorable outcomes, then we shall call this tendency as "overreliance". These circumstances capture key aspects of our study as they enable us to examine whether and to what extent the participants consistently fail to reject guidance in improbable scenarios. We tested whether the respondents were rely on guidance of AI since they obtain one of either support positive or the negative decision outcome intended for all ten task sets, or will reason the suggestion by AI, by doing this we aim to differentiate between AI-human collaborative decision making vs no AI used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Procedure</head><p>Our experiments for both groups have been conducted in the laboratory setting. Experimental group used Intel CORE i5, 12 generation computer system along with LLMs Based AI algorithm for task based decision-making. While control group received paper based task sets along with scoring manual to perform the tasks without any technological aid. Experiment lasted for 60-90 minutes as a whole, where all respondents earned a total of 5 points credit marks as incentive. Data collection occurred over two months in February-April 2024. We received clearance from the ethical committee of the university before commencing this experiment.</p><p>The participants that were directed to the e-version task sets and LLM cites i.e., ChatGPT-3.5 and Perplexity.ai, after their consent for the study, finished the introductory part, proceeded by the interacting experiment and the post experimental assessment. In addition to the comprehension testing, the introductory session addressed informed consent, confidentiality as well as the basic guidelines. Participants were split into two groups at random and given detailed research guidelines. All the participants received the same instruction, with the exception of the control group members who were not provided with any AI assistance and were thus not made aware of it. The interactive tasks then started following the instructions in section 4.2. Participants sequentially performed the tasks and after reading the task instructions they seek advice from LLM to finalize their choice. Participants were guided about the good and effective prompts to get best of the AI advice and these prompts were constant for all participants in experimental group. The participants were informed that they are independent in their choice to either rely on AI or taking a collaborative approach by doing their cognitive reasoning.</p><p>At the end, we delivered a complete set of post-experimental measures including attributes independant to the task, like Affinity for technology interaction, (9-items rated at a 6-point Likert scale) and DACOBS assessment of biases in cognition (42 items on a 7-point scale). Though we acknowledge that this approach cannot completely exclude the possibility of advice to bias the answer, our study goal was to avoid influencing the behavior. Lastly, before getting their completion check-out, the participants might choose to review a debriefing regarding the design of the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Outcome Variables (Dependent)</head><p>We integrate objective and subjective measures to verify our hypotheses. Regarding behavior, our areas of interest include how the respondents perform in their task based decision making using AI assistance. For this analysis, we employed three variables to assess the respondent's interaction with technology, presence of cognitive biases and the subsequent behavioral performance based decision making (Bruine de <ref type="bibr" target="#b15">Bruin et al., 2007)</ref>. Technology interaction represents the collaboration among humans and the technological devices such as computers or mobile-phones, as well as using AI algorithms <ref type="bibr" target="#b33">(Franke et al., 2018)</ref>. across several levels rather of looking at individual decisions. This implies that even while we are able to identify which specific individuals make a decision in effective or ineffective manner, we may still look at how decision making is shown on aggregate level. In this sense, variations in decision making competencies in contrast to control group permit us to discern the impact of AI used in task performance while taking along human cognitive biases.</p><p>Similarly, when it comes to conformity with the AI suggested decision, it cannot be explained alone that how many participants actually taken the AI advice as it is and how many just brainstorms, observing the difference is only by comparing the experimental group with those who did not receive any assistance and their decision is purely conscious and intuitive.</p><p>Task based decision making was a performance based objective behavioral assessment.</p><p>Likewise the technology interaction from <ref type="bibr" target="#b33">Franke et al. (2018)</ref>, consists of nine items rated on 6-point Likert-type scale, ranged from 'Completely Disagree' (score 1) to 'Completely Agree' (score 6). The item numbers 3, 6, and 8 are reverse-scored. The items on the scale were averaged (α = 0.92). The respondents also informed the presence of biases in cognition (Van der Gaag et al., 2013) by rating statement on 7-point scale, with total scores ranging from 42 to 294. A score above 140 indicates a high level of cognitive biases (reliability α = 0.90).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>The data analysis largely showed inconsistent results with our predictions but it is in support of the existing literature on human-AI collaborative decision making. We integrate the findings in the following key outcomes:</p><p>Result 1: Human decision-makers who work in collaboration with AI assisted decision on task set are likely to have better and unbiased decision making as compared to control group.</p><p>Starting with data aggregated from all ten task sets, we compared an average of decision competence for both groups. Such as the decision-making performance based on real life scenarios and the choices made were independent, we had no influence upon the decisions' distribution. Thus, as would be expected, the ex-post assessment showed that participants' data were normally distributed due to random assignment of treatment and that there were no appreciable variations in their frequency ranges. As depicted in <ref type="figure" target="#fig_1">Fig. 1</ref>, all observations value is presented as a colored bubble along with mean group value (µ) across two groups.</p><p>Nevertheless, in contrast to a control group exclusively the LLM based on AI algorithm resulting into insignificant change. The experimental group mean mADMC score is (µ=0.54, p=0.11, SD=3.01) with an effect size d=-0.35, whereas the control group mean score is (µ=0.53, p=0.11, SD=2.99), effect size (d) is -0.35. Between the two groups, the mean difference is (M.D=-1.06). The t-test value is (t=-1.58), yielding a p-value of 0.11. Directly comparing AIhuman collaborative decision making vs. human only, these results showed there is an insignificant variation in group of minor effect size. Hence, the assistance of AI did not dramatically modify the human cognitive biases instead the assistance provided by LLM was also ineffective and biased as control group.  So far, task based decision making was analyzed across all ten task sets. However, to test whether having high technology interaction and low level of cognitive biases have any spurious relation with better decision outcomes, we examined each observation (n=79) against the levels of these variables. We calculated the unweighted standardized z scores for categorizing "good decision" and "poor decision". This way, we can infer whether the decision making levels are having possible connection with levels of technology interaction (by computing mean values) and levels of cognitive biases (following established norm score) by <ref type="bibr" target="#b81">Van der Gaag et al. (2013)</ref>.</p><p>Different values are being observed when levels of decision making and cognitive biases were tested (χ2= 4.14, p = 0.39, φ = 0.23), but the effect was insignificant. Cross tabulation reported that participants with above-average cognitive biases exhibit a higher incidence of good decision-making (2.6%) compared to those with below or average biases, where no good decision-making competence is observed. Interestingly, 17.9% of individuals with high cognitive biases make good decisions, surpassing the 17.5% who make poor decisions <ref type="figure" target="#fig_2">(Fig.2)</ref>.</p><p>However, among those with very high cognitive biases, 70% demonstrate low decision-making competency, suggesting that while some biases may enhance decision-making, excessive biases tend to impair it.</p><p>Technology interaction was the key element when we explored it with decision-making competency levels, the groups emerged on the basis of low and high level of technology interaction. Interestingly it resulted in insignificant findings with no effect size (χ2=1. <ref type="bibr">06, p=0.30, φ=0.11)</ref>. Participants having high technology interaction are more inclined to have strong decision making abilities (61.5%) in contrast to those having low interaction (38.5%).</p><p>Both groups show equal rates of poor decision-making competence (50%). These findings suggest that the intensity of technology interaction plays a role in enhancing decision-making abilities, but further detailed evaluation is suggested <ref type="figure" target="#fig_2">(Fig.2)</ref>.</p><p>Cognitive biases are relatively independent to technology interaction but often studied together in many cognitive sciences and computer sciences researches. For this study we have use established score norms to group the level of cognitive biases as "low", "above average", "high" etc. Participants have reported to subjective evaluation for expressing their level of biases and the findings were quite interesting. Data reveals a notable pattern i.e., participants with higher technology interaction tend to have lower cognitive biases, with 2.3% and 6.8% of them showing below average and average biases, respectively, while none in the low technology interaction group fall into these categories. Conversely, 22.9% of the low technology interaction group displays high cognitive biases, compared to 13.6% in the high technology interaction group, indicating a higher inclination for cognitive biases among those with less technology interaction <ref type="figure" target="#fig_2">(Fig.2)</ref>. However, a majority in both groups exhibit very high cognitive biases, suggesting that while increased technology interaction may lower cognitive biases overall, it doesn't significantly affect the prevalence of very high biases (χ2= 6.72, p = 0.15, φ = 0.29).  In general, the actual results are highly inconsistent in contrast to our expectations, and supporting the argument that LLMs algorithms, analytically trained using millions of data sets, unfortunately did not assisted human participants in effective and good decision making. Also it has been noted that cognitive biases and human interaction with technology and technical aids are independent in their functions. Hence LLM algorithms are unsuccessful in de-biasing cognitive biases present during Human-AI collaborative decision-making. In the next section, we present an explanation of our findings by examining them in the light of previous researches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion, Limitations and Conclusions</head><p>6.1 Discussion of findings <ref type="bibr" target="#b28">Darioshi and Lahav (2021)</ref>, who noted that while AI can aid in making smarter decisions, it can also introduce biases. They explored the primary causes of these biases and developed a theoretical model to assess the feasibility of using technology in decision-making. The literature highlights that an excess of digital information can lead to "cognitive overload,"</p><p>impairing judgment by increasing cognitive load and causing ineffective decisions <ref type="bibr" target="#b41">(Hurwitz et al., 2021)</ref>. This overload hampers the decision-making process by making it difficult to filter and assess large volumes of data, ultimately leading to unreliable conclusions and overreliance or trusting the AI. In our study similar results has obtained, although it has been predicted that AI-Human collaboration will result in effective and better decision making outcomes but the disparities have been observed. <ref type="bibr" target="#b28">Darioshi &amp; Lahav (2021)</ref> emphasize the importance of timely, reliable data in decision-making, warning that biased data can distort decision outcomes. AI technologies, increasingly used in various industries, have been shown to outperform humans in decision-making tasks but numerous studies reveal that humans often over-rely on AI, even when it provides incorrect advice, leading to poor decisions than if they had relied solely on their intuition <ref type="bibr" target="#b17">(Buçinca et al., 2020;</ref><ref type="bibr" target="#b37">Green &amp; Chen, 2021;</ref><ref type="bibr" target="#b7">Bansal et al., 2021)</ref>. But the findings of our study have challenged this fact and revealed that human intuitive and independent decision was also biased and ineffective. Explainable AI (XAI) was introduced to reduce this overreliance by providing explanations for AI decisions, but few research reported that XAI has not significantly improved decision quality <ref type="bibr" target="#b7">(Bansal et al., 2021;</ref><ref type="bibr" target="#b44">Jacobs et al., 2021)</ref>. The dual-process theory, which distinguishes between quick, heuristic-based System 1 thinking and slower, effortful System 2 thinking, helps explain why people over-rely on AI. Reliance on System 1, heuristics makes humans susceptible to biases, even when interacting with AI <ref type="bibr" target="#b48">(Kahneman, 2011)</ref>. While experts are not resistant to these biases, balancing System 1 and System 2 thinking is crucial. However, most explainable AI systems assume that users will critically evaluate each explanation, an assumption that often proves unrealistic due to aversion of humans to cognitive effort <ref type="bibr" target="#b53">(Kool &amp; Botvinick, 2018)</ref>.</p><p>This study also discusses the role of default options in biased decision-making. For instance, pilots in an experiment by <ref type="bibr" target="#b80">Skitka et al. (1999)</ref> often accepted computer-suggested default solutions, even when it contradicted their training. This highlights the risks of partial automation in decision-making, where ease of implementation can lead to biased choices.</p><p>Significant number of organizations are experimenting with AI, recognizing its potential to perform complex cognitive tasks and improve decision-making <ref type="bibr" target="#b72">(Ransbotham et al., 2022)</ref>.</p><p>However, the use of AI remains debatable, with concerns about its potential negative impacts on society <ref type="bibr" target="#b29">(Davenport et al., 2019;</ref><ref type="bibr" target="#b46">Johnson &amp; Verdicchio, 2017</ref>) the impact of AI on human decision-making is well-documented. It can introduce biases, affect judgment, and influence decision outcomes. Algorithms can alter perceptions and build trust and overreliance, leading to reduced critical thinking and autonomy <ref type="bibr" target="#b58">(Lipai et al., 2021)</ref>. In financial markets, automated trading systems can cause herd behavior and increase volatility, demonstrating significant influence on decision-making <ref type="bibr" target="#b21">(Che et al., 2024)</ref>. AI algorithms based LLMs may reshape cognitive decisions, particularly in microeconomic contexts. <ref type="bibr" target="#b32">Feng et al. (2021)</ref> found that LLM algorithms influence human behavior and decisions by altering cognition through information shocks, while these technologies can assist in decision-making, they may require human oversight to avoid bias and misinformation.</p><p>Previous studies on human-AI interaction proved that AI has a capability to enhance decision-making capabilities <ref type="bibr" target="#b56">(Lai et al., 2023;</ref><ref type="bibr" target="#b8">Bao et al., 2023)</ref>. However, contradictory evidence exists, with some studies suggesting that increased reliance on technology can hinder decision-making competence due to issues like loss of situational awareness and skill decay <ref type="bibr" target="#b23">(Chiang et al., 2024)</ref>. Similarly our study has predicted that high technology use and low cognitive biases would lead to better decision-making and the findings revealed that high technology interaction had a higher percentage of good decision-making compared to those with low technology interaction. The facts reported association between technology use and decision-making quality. Also it has been observed that high cognitive biases showed a mixed relationship between bias levels and decision-making competence. Some research suggests that certain cognitive biases can enhance decision-making in specific contexts <ref type="bibr" target="#b45">(Johnson et al., 2013;</ref><ref type="bibr" target="#b55">Korteling et al., 2023)</ref>, while the majority of studies indicate that cognitive biases generally impair decision-making <ref type="bibr" target="#b1">(Acciarini et al., 2020)</ref>. Present study findings revealed that higher technology interaction has lower levels of cognitive biases for instance, 77.3% of participants with high technology interaction were classified as having very high cognitive biases, compared to 71.4% in the low technology interaction group. Despite the mixed findings, some literature suggests that higher levels of technology interaction may influence the prevalence of certain cognitive biases, particularly in high-tech environments <ref type="bibr" target="#b39">(Holzinger et al., 2022;</ref><ref type="bibr" target="#b14">Booker et al., 2021)</ref>. Overall, the relationship between cognitive biases, technology interaction, and decision making competence is intricate and context-dependent. While some studies show positive correlations, others highlight potential drawbacks, underscoring the need for further research to clarify these associations and identify the underlying mechanisms.</p><p>Furthermore we examined the possible correlation between interaction with technology, cognitive biasness, and decision-making competence. Data representation posted insignificant association between interaction with technology and decision making, while significant association was present with cognitive biases. This argument that increased human-technology interaction correlates with a higher influence of biases on decision-making. Literature highlights how cognitive biases, such as overconfidence and confirmation bias, can be exacerbated by technology, which facilitates access to vast amounts of information and may reinforce biases like availability and anchoring biases <ref type="bibr" target="#b50">(Kahneman &amp; Tversky, 1972)</ref>.</p><p>Contradictory studies suggest that technology can also mitigate biases by fostering analytical thinking and structured decision-making processes, thus reducing biases like hindsight and confirmation bias. The domains of technology interaction were found to be strongly related with confirmation bias, concentration for threat bias and external attribution bias while weak association with problems in social reasoning and problems in subjective cognitions. This implies that those with a higher liking for technological interaction may have significant biases in cognition involving inflexibility in their views, elevated perception of threat as well as external attribution bias. While some research supports these findings, other studies propose that technology can enhance belief flexibility, desensitize individuals to threats, and foster an internal locus of control.</p><p>Correlation matrix suggested that social norms can contribute to overconfidence <ref type="bibr" target="#b31">(Emami &amp; Khajeheian, 2018;</ref><ref type="bibr" target="#b26">Chung &amp; Rimal, 2016)</ref>. However, other studies argue that biases like overconfidence are not easily influenced by social norms <ref type="bibr" target="#b49">(Kahneman &amp; Klein, 2009)</ref>.</p><p>Similarly, the relationship between social norms and sunk cost fallacy is complex, with some studies indicating that social norms may influence resistance to sunk costs, while others suggest that this relationship is not straightforward <ref type="bibr" target="#b83">(Yoder et al., 2014;</ref><ref type="bibr" target="#b69">Polites &amp; Karahanna, 2012)</ref>.</p><p>Lastly, the data revealed that jumping to conclusion bias is associated with various other cognitive biases indicating that individuals prone to this bias may also exhibit rigid beliefs, heightened threat perception, and external attribution bias. However, some research shows conflicting results, suggesting variability in the strength of these correlations across different studies. Additional investigation is required to examine these relationships as well as their implications for comprehending cognitive biases and mental health in this era of AI and technology accessibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Limitation and outlook</head><p>Our study offers robust insights into the intersection of AI and decision-making, it is accompanied by several notable limitations. One of the primary concerns is the absence of significant differences in decision-making results among the control and the experimental groups. This lack of differentiation calls into question the effectiveness of AI algorithmic model in altering cognitive biases. It suggests that the anticipated impact of algorithm on modifying such biases might not be as straightforward as hypothesized, pointing to the need for more detailed exploration into the dynamics of human-AI interaction. Understanding why these AI algorithms failed to produce the expected outcomes requires a deeper exploration into the factors that influence decision-making processes when AI assistance is involved.</p><p>Furthermore, the sample size presents another significant limitation. Restricted sample selection limits the generalizability of the findings, meaning that the results observed in this study might not accurately reflect the broader population's response. alteration. This approach would also help identify any delayed effects of AI model that might not be immediately apparent in post-test assessments alone. Exploring the precise processes by which artificial intelligence affects decision making is another promising avenue for future research. In this regard, studying the importance of trust in the interaction between human and AI <ref type="bibr" target="#b61">(Meske &amp; Bunde, 2020;</ref><ref type="bibr" target="#b25">Choung et al., 2022)</ref> might reveal critical perspectives about why individuals may or may not follow AI-generated advice. Understanding the factors that enhance or diminish trust in AI could lead to the development of more effective and targeted interventions aimed at improving decision-making outcomes.</p><p>Moreover, the use of AI in fields such as psychopathology and mental health presents new and exciting opportunities for enhancing decision-making abilities. AI-driven approaches could be instrumental in generating predictive tasks or designing personalized treatment strategies that specifically de-bias cognitive errors. By leveraging capabilities of AI in these areas, it may be possible to develop more sophisticated algorithms that not only enhance decision-making processes but also contribute to overall mental well-being. Overall, by embracing longitudinal studies, expanding sample diversity, adopting mixed-methods approaches, and delving deeper into the underlying mechanisms of the AI influence, future research can significantly advance our understanding of how AI can improve decision-making competence and reduce cognitive biases. Such efforts will be critical in refining AI models and algorithms and ensuring they are both effective and applicable across various real-world contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Conclusions</head><p>Our experimental study has explored the collaborative decision making of humans and AI algorithms i.e., LLM in the emergence of cognitive biases at the time of task-based decision making. The findings reveal that LLMs, such as Perplexity.ai and ChatGPT did not considerably modify the decision making processes or reduce biases in cognition when compared with control group. This aligns with previous research by <ref type="bibr" target="#b50">Kahneman and Tversky (1972)</ref>, which demonstrated the deeply ingrained nature of cognitive biases and heuristics that resist de-biasing techniques, including AI-based decision support systems <ref type="bibr" target="#b5">(Arkes, 1991)</ref>. The study highlights the persistent nature of cognitive biases, even when decisions are made with AI assistance. This persistence may be due to factors such as over-reliance on AI, which can undermine critical analysis and perpetuate existing biases <ref type="bibr" target="#b73">(Rodriguez et al., 2020)</ref>. While AI technology shows potential in aiding decision-making, its effectiveness is limited by the complexities of human-AI interaction and the enduring nature of cognitive biases. Moreover, this research has successfully validated the culturally modified version of the Adult Decision</p><p>Making Competence (mADMC) battery. The rigorous methodological approach, including cultural adaptation and advanced statistical analyses, has enhanced the validity and analytical depth of the study. The clear and structured experimental design, which included group comparisons and post-test assessments, ensured robust internal validity and allowed for a systematic evaluation of LLM impact on decision-making. Overall, this study underscores the need for further investigation into the coding of AI algorithms that can more effectively de-bias cognitive biases while promoting critical reasoning and autonomous decision-making.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Cognitive biases measure the seven types of cognitive errors i.e., jumping to conclusion bias, belief inflexibility bias (also called confirmation bias), consideration of threat bias, external attribution bias, social reasoning problems and problems in subjective cognition as well as safety-related behaviors (Van der Gaag et al., 2013). Both technology interaction along with cognitive biases are evaluated on a broader level, as opposed to an individual one, such as we analyze distributions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Participant's mean differences of decision making based on respective group. Independent sample t-test value, p-value and 95% confidence intervals</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Result 2 :</head><label>2</label><figDesc>Human decision makers are likely having high technology use and low cognitive biases to have better decision outcomes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Rate of participant's decision making based on their interaction with technology and the level of cognitive biases.Result 3: Technology interaction, presence of cognitive biases and the decision making competency are interlinked.Participants have been exposed to two other measures for observing their interaction with technology and the level of cognitive biases present while making task based decision making. The statistical test revealed decision making competence and technology interaction posited weak and negative association with zero effect size (r = -0.01, p &gt; 0.05, r² = 0.00) 5 .Correspondingly cognitive biases and participant's interaction with technology found statistically significant with minimum effect size (r = 0.32, p = 0.01, r² = 0.10), indicating that as human and technology interaction rises, the impact of cognitive biases on decision-making also increases likewise. The domain of cognitive biases related to technology use, were further examined and noted that confirmation bias (r = 0.28, p &lt; 0.05, r² = 0.08), consideration for threat bias (r = 0.23, p &lt; 0.05, r² = 0.05), and external attribution bias (r = 0.30, p &lt; 0.01, r² = 0.09) were highly correlated to interaction with technology. Additionally, problems in subjective cognition (r = 0.27, p &lt; 0.05, r² = 0.07) and social reasoning problems (r = 0.28, p &lt; 0.05, r² = 0.08) showed weak correlation with technology use. The results imply that when participant's technological involvement rises, they likely to display greater amounts of specific cognitive biases, like becoming inflexible in their views, paying more attention to dangers, and linking occurrences to external forces. Yet, the correlation coefficients are quite moderate, indicating that the associations are not exceptionally robust even if they are significant statistically.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Pearson' correlation between decision-making, interaction with technology and cognitive biases</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>To draw more reliable and widely applicable conclusions, future research might benefit from having more varied and large sample sizes that encompass a broader range of demographic and psychographic profiles. Such diversity would help to uncover how different groups might uniquely interact with AI in decision-making scenarios, thereby providing a deeper comprehension of AI impact. One more critical drawback is the study's dependency on post-test assessments as the sole method ofevaluation. While post-test assessments can capture immediate reactions and decisions, they may not adequately reflect the cognitive changes that occur over time. Cognitive biases, particularly those targeted by AI algorithm, are complex and may not shift in a linear or immediate fashion. As such, the study may have missed observing how participants' biases evolved or diminished long after the intervention was administered. This highlights the importance of longitudinal studies that track participants over extended periods. Such studies would provide richer insights into the long-term effects of AI-based interventions on cognitive biases, offering a clearer picture of whether these interventions can produce lasting changes in decision-making processes. Looking ahead, upcoming researches in the realm of the human-AI collaboration and decision making competency might greatly take advantage from numerous methodological enhancements. Longitudinal studies should be prioritized to analyze the enduring impacts of AI algorithms on the cognitive biases and decision making procedures. These studies would allow researchers to observe how these biases develop, persist, or diminish over time, providing an intricate understanding of the role of AI in cognitive de-biasing. Expanding the sample size and ensuring a more diverse participant pool would also be crucial. A broader demographic representation would enhance the generalizability of the findings, enabling researchers to draw more universally applicable conclusions about AI's impact. In addition, incorporating pre-test and follow-up evaluations alongside post-test assessments would offer a more comprehensive view of cognitive changes. By comparing baseline measurements with outcomes observed at multiple time points, researchers could better understand the trajectory of cognitive bias</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">See Modified Adult Decision Making Competence battery (Task-sets) by Prof Wandi Bruine de Bruin and colleagues(2007), can be accessed on https://sjdm.org/dmidi/Adult_-_Decision_Making_Competence.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Task set based of Adult Decision Making Competence battery. 4 Sunk cost fallacy: The sunk cost fallacy occurs when people continue to make decisions based on previous investments, despite the fact that it is better to reduce losses and move on.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">r²= effect size (it is square of correlation value)</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pathways for Design Research on Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Parsons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">R L</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarker</surname></persName>
		</author>
		<idno type="DOI">10.1287/isre.2024.editorial.v35.n2</idno>
		<ptr target="https://doi.org/10.1287/isre.2024.editorial.v35.n2" />
	</analytic>
	<monogr>
		<title level="j">Information Systems Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="441" to="459" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cognitive biases and decision-making strategies in times of change: a systematic literature review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Acciarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brunetta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boccardelli</surname></persName>
		</author>
		<idno type="DOI">10.1108/md-07-2019-1006</idno>
		<ptr target="https://doi.org/10.1108/md-07-2019-1006" />
	</analytic>
	<monogr>
		<title level="j">Management Decision</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="638" to="652" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Why trust an algorithm? Performance, cognition, and neurophysiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Zak</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2018.07.026</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2018.07.026" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="279" to="288" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Can Generative AI Models Extract Deeper Sentiments as Compared to Traditional Deep Learning Algorithms?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Anas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saiyeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sohail</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<idno type="DOI">10.1109/mis.2024.3374582</idno>
		<ptr target="https://doi.org/10.1109/mis.2024.3374582" />
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="5" to="10" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">In AI we trust? Perceptions about automated decision-making by artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Helberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kruikemeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>De Vreese</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-019-00931-w</idno>
		<ptr target="https://doi.org/10.1007/s00146-019-00931-w" />
		<imprint>
			<date type="published" when="2020" />
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="611" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Costs and benefits of judgment errors: Implications for debiasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Arkes</surname></persName>
		</author>
		<idno type="DOI">10.1037//0033-2909.110.3.486</idno>
		<ptr target="https://doi.org/10.1037//0033-2909.110.3.486" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="486" to="498" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The psychology of sunk cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Arkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blumer</surname></persName>
		</author>
		<idno type="DOI">10.1016/0749-5978(85)90049-4</idno>
		<ptr target="https://doi.org/10.1016/0749-5978(85)90049-4" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="124" to="140" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nushi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v35i13.17359</idno>
		<ptr target="https://doi.org/10.1609/aaai.v35i13.17359" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="11405" to="11414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Literature Review of Human-AI Synergy in Decision Making: From the Perspective of Affordance Actualization Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.3390/systems11090442</idno>
		<ptr target="https://doi.org/10.3390/systems11090442" />
	</analytic>
	<monogr>
		<title level="j">Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">442</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Validation of the Adult Decision-Making Competence in Slovak students</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bavolar</surname></persName>
		</author>
		<idno type="DOI">10.1017/s1930297500006057</idno>
		<ptr target="https://doi.org/10.1017/s1930297500006057" />
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="386" to="392" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Decision-making styles and their associations with decisionmaking competencies and mental health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bavoľár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Orosová</surname></persName>
		</author>
		<idno type="DOI">10.1017/s1930297500003223</idno>
		<ptr target="https://doi.org/10.1017/s1930297500003223" />
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="122" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Trust, Reciprocity, and Social History</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dickhaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mccabe</surname></persName>
		</author>
		<idno type="DOI">10.1006/game.1995.1027</idno>
		<ptr target="https://doi.org/10.1006/game.1995.1027" />
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="122" to="142" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">People are averse to machines making moral decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">E</forename><surname>Bigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2018.08.003</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2018.08.003" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="21" to="34" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human Judgment in algorithmic loops: Individual justice and automated decisionmaking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Binns</surname></persName>
		</author>
		<idno type="DOI">10.1111/rego.12358</idno>
		<ptr target="https://doi.org/10.1111/rego.12358" />
	</analytic>
	<monogr>
		<title level="j">Regulation &amp; Governance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="197" to="211" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cognitive Biases and the Cultural Disconnect between Engineers and Decision-makers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Booker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Knights</surname></persName>
		</author>
		<idno type="DOI">10.47577/tssj.v17i1.2752</idno>
		<ptr target="https://doi.org/10.47577/tssj.v17i1.2752" />
	</analytic>
	<monogr>
		<title level="j">Technium Social Sciences Journal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="35" to="62" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adult Decision-Making Competence Index [dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bruine De Bruin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischhoff</surname></persName>
		</author>
		<idno type="DOI">10.1037/t07882-000</idno>
		<ptr target="https://doi.org/10.1037/t07882-000" />
	</analytic>
	<monogr>
		<title level="m">PsycTESTS Dataset</title>
		<imprint>
			<publisher>APA</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scale Without Mass: Business Process Replication and Industry Dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mcafee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sorell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.980568</idno>
		<ptr target="https://doi.org/10.2139/ssrn.980568" />
	</analytic>
	<monogr>
		<title level="j">SSRN Electronic Journal</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Proxy tasks and subjective measures can be misleading in evaluating explainable AI systems. Explainable AI Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Buçinca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Z</forename><surname>Gajos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Glassman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3377325.3377498</idno>
		<ptr target="https://doi.org/10.1145/3377325.3377498" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 25th International Conference on Intelligent User Interfaces</title>
		<meeting>25th International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Task-Dependent Algorithm Aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Castelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
		<idno type="DOI">10.1177/0022243719851788</idno>
		<ptr target="https://doi.org/10.1177/0022243719851788" />
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Research</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="809" to="825" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Human Judgment In Artificial Intelligence For Business Decision-Making: An Empirical Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Chanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Innovation Management</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<idno type="DOI">10.1142/s136391962450004x</idno>
		<ptr target="https://doi.org/10.1142/s136391962450004x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Integrating generative AI into financial market prediction for improved decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<idno type="DOI">10.54254/2755-2721/64/20241376</idno>
		<ptr target="https://doi.org/10.54254/2755-2721/64/20241376" />
	</analytic>
	<monogr>
		<title level="j">Applied and Computational Engineering</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="161" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Information fusion and artificial intelligence for smart healthcare: a bibliometric study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2022.103113</idno>
		<ptr target="https://doi.org/10.1016/j.ipm.2022.103113" />
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="113" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Enhancing AI-Assisted Group Decision Making through LLM-Powered Devil&apos;s Advocate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3640543.3645199</idno>
		<ptr target="https://doi.org/10.1145/3640543.3645199" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Intelligent User Interfaces</title>
		<meeting>the 29th International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">AI-Assisted Summarization of Radiologic Reports: Evaluating GPT3davinci, BARTcnn, LongT5booksum, LEDbooksum, LEDlegal, and LEDclinical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jagessar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Salamon</surname></persName>
		</author>
		<idno type="DOI">10.3174/ajnr.a8102</idno>
		<ptr target="https://doi.org/10.3174/ajnr.a8102" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Neuroradiology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="244" to="248" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Trust in AI and Its Role in the Acceptance of AI Technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2022.2050543</idno>
		<ptr target="https://doi.org/10.1080/10447318.2022.2050543" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1727" to="1739" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Social norms: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Rimal</surname></persName>
		</author>
		<idno type="DOI">10.12840/issn.2255-4165.2016.04.01.008</idno>
		<ptr target="https://doi.org/10.12840/issn.2255-4165.2016.04.01.008" />
	</analytic>
	<monogr>
		<title level="j">Review of Communication Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">When should I trust my gut? Linking domain expertise to intuitive decision-making effectiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Rockmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Pratt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.obhdp.2012.07.009</idno>
		<ptr target="https://doi.org/10.1016/j.obhdp.2012.07.009" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="194" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The impact of technology on the human decision-making process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Darioshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lahav</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbe2.257</idno>
		<ptr target="https://doi.org/10.1002/hbe2.257" />
	</analytic>
	<monogr>
		<title level="j">Human Behavior and Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="391" to="400" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">How artificial intelligence will change the future of marketing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bressgott</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11747-019-00696-0</idno>
		<ptr target="https://doi.org/10.1007/s11747-019-00696-0" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Academy of Marketing Science</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="42" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000033</idno>
		<ptr target="https://doi.org/10.1037/xge0000033" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="114" to="126" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Social Norms and Entrepreneurial Action: The Mediating Role of Opportunity Confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Emami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Khajeheian</surname></persName>
		</author>
		<idno type="DOI">10.3390/su11010158</idno>
		<ptr target="https://doi.org/10.3390/su11010158" />
	</analytic>
	<monogr>
		<title level="j">Sustainability</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Internet and Cognition-Based Decision Making: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1145/3503181.3503190</idno>
		<ptr target="https://doi.org/10.1145/3503181.3503190" />
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Crowd Science and Engineering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Personal Resource for Technology Interaction: Development and Validation of the Affinity for Technology Interaction (ATI) Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Attig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wessel</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2018.1456150</idno>
		<ptr target="https://doi.org/10.1080/10447318.2018.1456150" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="456" to="467" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Principles And Perspective Of Medical Diagnostic Systems Using Artificial Intelligence (Ai) Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gaikwad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nagale</surname></persName>
		</author>
		<idno type="DOI">10.33564/ijeast.2021.v06i07.020</idno>
		<ptr target="https://doi.org/10.33564/ijeast.2021.v06i07.020" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Engineering Applied Sciences and Technology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="120" to="130" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Human Trust in Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Glikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Woolley</surname></persName>
		</author>
		<idno type="DOI">10.5465/annals.2018.0057</idno>
		<ptr target="https://doi.org/10.5465/annals.2018.0057" />
	</analytic>
	<monogr>
		<title level="j">Review of Empirical Research. Academy of Management Annals</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="627" to="660" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Human-AI Collaboration in Environmental Decision Making. Exploring Ethical Dimensions of Environmental Sustainability and Use of AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shefali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sushmitha</surname></persName>
		</author>
		<idno type="DOI">10.4018/979-8-3693-0892-9.ch016</idno>
		<ptr target="https://doi.org/10.4018/979-8-3693-0892-9.ch016" />
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="page" from="330" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Algorithmic Risk Assessments Can Alter Human Decision-Making Processes in High-Stakes Government Contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3479562</idno>
		<ptr target="https://doi.org/10.1145/3479562" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">CSCW2</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hagendorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kosinski</surname></persName>
		</author>
		<idno type="DOI">10.1038/s43588-023-00527-x</idno>
		<ptr target="https://doi.org/10.1038/s43588-023-00527-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Computational Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="833" to="838" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holzinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Emmert-Streib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jurisica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Díaz-Rodríguez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.inffus.2021.10.007</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2021.10.007" />
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="263" to="278" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Who is the Expert? Reconciling Algorithm Aversion and Algorithm Appreciation in AI-Supported Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">T Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Jung</surname></persName>
		</author>
		<idno type="DOI">10.1145/3479864</idno>
		<ptr target="https://doi.org/10.1145/3479864" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">CSCW2</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Financial less is more&quot;: An experimental study of financial communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hurwitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lahav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mugerman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.socec.2021.101756</idno>
		<ptr target="https://doi.org/10.1016/j.socec.2021.101756" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral and Experimental Economics</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">The Use of the Pre-Trained BERT and GPT-3 Models to Automate the Composing of Use Case Descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Imam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Altawaiha</surname></persName>
		</author>
		<idno type="DOI">10.22541/au.169205044.43001223/v1</idno>
		<ptr target="https://doi.org/10.22541/au.169205044.43001223/v1" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
	<note type="report_type">Authorea Preprints</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Developmental differences in baserate estimates of social behaviors and attitudes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Osgood</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9507.1995.tb00058.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9507.1995.tb00058.x" />
	</analytic>
	<monogr>
		<title level="j">Social Development</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="165" to="181" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How machine-learning recommendations influence clinician treatment selections: the example of antidepressant selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Pradier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Perlis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Z</forename><surname>Gajos</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41398-021-01224-x</idno>
		<ptr target="https://doi.org/10.1038/s41398-021-01224-x" />
	</analytic>
	<monogr>
		<title level="j">Translational Psychiatry</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The evolution of error: Error management, cognitive constraints, and adaptive decision-making biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Blumstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Haselton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tree.2013.05.014</idno>
		<ptr target="https://doi.org/10.1016/j.tree.2013.05.014" />
	</analytic>
	<monogr>
		<title level="j">Trends in ecology &amp; evolution</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="474" to="481" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verdicchio</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11023-017-9417-6</idno>
		<ptr target="https://doi.org/10.1007/s11023-017-9417-6" />
		<title level="m">Reframing AI Discourse. Minds and Machines</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="575" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">An Integrative Perspective on Algorithm Aversion and Appreciation in Decision-Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jussupow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Benbasat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heinzl</surname></persName>
		</author>
		<idno type="DOI">10.25300/misq/2024/18512</idno>
		<ptr target="https://doi.org/10.25300/misq/2024/18512" />
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Thinking, Fast and Slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Farrar, Straus and Giroux</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Conditions for intuitive expertise: A failure to disagree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0016755</idno>
		<ptr target="https://doi.org/10.1037/a0016755" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="515" to="526" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Subjective probability: A judgment of representativeness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(72</idno>
		<ptr target="https://doi.org/10.1016/0010-0285(72" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="90016" to="90019" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Trust in Artificial Intelligence: Meta-Analytic Findings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Hancock</surname></persName>
		</author>
		<idno type="DOI">10.1177/00187208211013988</idno>
		<ptr target="https://doi.org/10.1177/00187208211013988" />
	</analytic>
	<monogr>
		<title level="j">Human Factors: The Journal of the Human Factors and Ergonomics Society</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="337" to="359" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Measurement of Trust in Automation: A Narrative Review and Reference Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Shaw</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2021.604977</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2021.604977" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mental labour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-018-0401-9</idno>
		<ptr target="https://doi.org/10.1038/s41562-018-0401-9" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="899" to="908" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Theoretical Considerations and Development of a Questionnaire to Measure Trust in Automation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Körber</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-96074-6_2</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-96074-6_2" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Congress of the International Ergonomics Association</title>
		<meeting>the 20th Congress of the International Ergonomics Association</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="13" to="30" />
		</imprint>
	</monogr>
	<note>IEA 2018</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Cognitive bias and how to improve sustainable decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><forename type="middle">E</forename><surname>Korteling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Hans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Paradies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Sassen-Van Meer</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2023.1129835</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2023.1129835" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Towards a Science of Human-AI Decision Making: An Overview of Design Space in Empirical Human-Subject Studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smith-Renner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3593013.3594087</idno>
		<ptr target="https://doi.org/10.1145/3593013.3594087" />
	</analytic>
	<monogr>
		<title level="m">2023 ACM Conference on Fairness, Accountability, and Transparency</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Trust in Automation: Designing for Appropriate Reliance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>See</surname></persName>
		</author>
		<idno type="DOI">10.1518/hfes.46.1.50.30392</idno>
		<ptr target="https://doi.org/10.1518/hfes.46.1.50.30392" />
	</analytic>
	<monogr>
		<title level="j">Human Factors: The Journal of the Human Factors and Ergonomics Society</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="80" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Corporate governance reform in the era of artificial intelligence: research overview and prospects based on knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lipai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiqiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mengyuan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10479-021-04416-2</idno>
		<ptr target="https://doi.org/10.1007/s10479-021-04416-2" />
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">326</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="105" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Algorithm appreciation: People prefer algorithmic to human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Logg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Minson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.obhdp.2018.12.005</idno>
		<ptr target="https://doi.org/10.1016/j.obhdp.2018.12.005" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="90" to="103" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Resistance to Medical Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Longoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bonezzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Morewedge</surname></persName>
		</author>
		<idno type="DOI">10.1093/jcr/ucz013</idno>
		<ptr target="https://doi.org/10.1093/jcr/ucz013" />
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="650" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Transparency and Trust in Human-AI-Interaction: The Role of Model-Agnostic Explanations in Computer Vision-Based Decision Support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bunde</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-50334-5_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-50334-5_4" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in HCI</title>
		<imprint>
			<biblScope unit="page" from="54" to="69" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Behavioral Measurement of Trust in Automation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sirkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ju</surname></persName>
		</author>
		<idno type="DOI">10.1177/1541931213601422</idno>
		<ptr target="https://doi.org/10.1177/1541931213601422" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Factors and Ergonomics Society Annual Meeting</title>
		<meeting>the Human Factors and Ergonomics Society Annual Meeting</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1849" to="1853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Riphah international University, Student enrolled database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moellim Database</surname></persName>
		</author>
		<ptr target="https://moellim.riphah.edu.pk/login/index.php" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Human-AI Collaborative Decision-making: A Cognitive Ergonomics Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Neyigapula</surname></persName>
		</author>
		<idno type="DOI">10.21203/rs.3.rs-3258718/v1</idno>
		<ptr target="https://doi.org/10.21203/rs.3.rs-3258718/v1" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Humans and Automation: Use, Misuse, Disuse, Abuse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Parasuraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Riley</surname></persName>
		</author>
		<idno type="DOI">10.1518/001872097778543886</idno>
		<ptr target="https://doi.org/10.1518/001872097778543886" />
	</analytic>
	<monogr>
		<title level="j">Human Factors: The Journal of the Human Factors and Ergonomics Society</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="230" to="253" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Decision-making competence: External validation through an individual-differences approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischhoff</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.481</idno>
		<ptr target="https://doi.org/10.1002/bdm.481" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">The adaptive decision maker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.1017/cbo9781139173933</idno>
		<ptr target="https://doi.org/10.1017/cbo9781139173933" />
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Who&apos;s the real expert here? Pedigree&apos;s unique bias on trust between human and automated advisers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Mayhorn</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.apergo.2019.102907</idno>
		<ptr target="https://doi.org/10.1016/j.apergo.2019.102907" />
	</analytic>
	<monogr>
		<title level="j">Applied Ergonomics</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">102907</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Shackled to the Status Quo: The Inhibiting Effects of Incumbent System Habit, Switching Costs, and Inertia on New System Acceptance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Polites</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Karahanna</surname></persName>
		</author>
		<idno type="DOI">10.25300/misq/2012/36.1.02</idno>
		<ptr target="https://doi.org/10.25300/misq/2012/36.1.02" />
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="42" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Understanding algorithm aversion: When is advice from automation discounted</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Swol</surname></persName>
		</author>
		<idno type="DOI">10.1002/for.2464</idno>
		<ptr target="https://doi.org/10.1002/for.2464" />
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="691" to="702" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Aspects of Artificial Intelligence in Agriculture, Healthcare and Education</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prajapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Prajapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gohil</surname></persName>
		</author>
		<idno type="DOI">10.22214/ijraset.2022.47746</idno>
		<ptr target="https://doi.org/10.22214/ijraset.2022.47746" />
	</analytic>
	<monogr>
		<title level="j">International Journal for Research in Applied Science and Engineering Technology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1959" to="1965" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Chapter 11 Are You Making the Most of Your Relationship with Al? The Rise of AI-Powered Companies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ransbotham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khodabandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Candelon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lafountain</surname></persName>
		</author>
		<idno type="DOI">10.1515/9783110775112-011</idno>
		<ptr target="https://doi.org/10.1515/9783110775112-011" />
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="75" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Measuring complacency in humans interacting with autonomous agents in a multi-agent system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Deep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zaroukian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and machine learning for multi-domain operations applications II</title>
		<meeting><address><addrLine>Arizona, USA</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="258" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Removing order effects from human-classified datasets: A machine learning method to improve decision making systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Romanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Molokanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kazantsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jha</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dss.2022.11</idno>
		<ptr target="https://doi.org/10.1016/j.dss.2022.11" />
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page">113891</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Identifying the linguistic markers of intuition in human resource (HR) practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sadler-Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Akstinaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Akinci</surname></persName>
		</author>
		<idno type="DOI">10.1111/1748-8583.12410</idno>
		<ptr target="https://doi.org/10.1111/1748-8583.12410" />
	</analytic>
	<monogr>
		<title level="j">Human Resource Management Journal</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="584" to="602" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">The ABC of algorithmic aversion: not agent, but benefits and control determine the acceptance of automated decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schaap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hendriks Vettehen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-023-01649-6</idno>
		<ptr target="https://doi.org/10.1007/s00146-023-01649-6" />
		<imprint>
			<date type="published" when="2023" />
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1947" to="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Exploring the effects of human-centered AI explanations on trust and reliance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Scharowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A C</forename><surname>Perrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Svab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Opwis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brühlmann</surname></persName>
		</author>
		<idno type="DOI">10.3389/fcomp.2023.1151150</idno>
		<ptr target="https://doi.org/10.3389/fcomp.2023.1151150" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Computer Science</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Research methods in psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Shaughnessy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Zechmeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Zechmeister</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>Columbus, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Human-Centered Artificial Intelligence: Reliable, Safe &amp; Trustworthy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2020.1741118</idno>
		<ptr target="https://doi.org/10.1080/10447318.2020.1741118" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="495" to="504" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Does automation bias decision-making?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Mosier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burdick</surname></persName>
		</author>
		<idno type="DOI">10.1006/ijhc.1999.0252</idno>
		<ptr target="https://doi.org/10.1006/ijhc.1999.0252" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="991" to="1006" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Development of the Davos Assessment of Cognitive Biases Scale (DACOBS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Der Gaag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schütz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ten Napel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Landa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Delespaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tschacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Hert</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.schres.2012.12.010</idno>
		<ptr target="https://doi.org/10.1016/j.schres.2012.12.010" />
	</analytic>
	<monogr>
		<title level="j">Schizophrenia Research</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="63" to="71" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Human-AI cognitive teaming: using AI to support state-level decision making on the resort to force</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vold</surname></persName>
		</author>
		<idno type="DOI">10.1080/10357718.2024.2327383</idno>
		<ptr target="https://doi.org/10.1080/10357718.2024.2327383" />
	</analytic>
	<monogr>
		<title level="j">Australian Journal of International Affairs</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="236" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Culture-related factors affect sunk cost bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Yoder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mancha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Agrawal</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0101086</idno>
		<ptr target="https://doi.org/10.1037/h0101086" />
	</analytic>
	<monogr>
		<title level="j">Behavioral Development Bulletin</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="105" to="118" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3626772.3657788</idno>
		<ptr target="https://doi.org/10.1145/3626772.3657788" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2024" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
