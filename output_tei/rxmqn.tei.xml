<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Separating random and deterministic sources of computational noise in explore-exploit decisions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2024-05-16">May 16, 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">Current Address: Laboratory of Neuropsychology</orgName>
								<orgName type="institution" key="instit1">National Institute of Mental Health</orgName>
								<orgName type="institution" key="instit2">National Institutes of Health</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>¤</roleName><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Neuroscience and Physiological Sciences Graduate Interdisciplinary Program</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Cognitive Science Program</orgName>
								<orgName type="institution">University of Arizona</orgName>
								<address>
									<settlement>Tucson</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Separating random and deterministic sources of computational noise in explore-exploit decisions</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-05-16">May 16, 2024</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Human decision making is inherently variable. While this variability is often seen as a sign of suboptimal behavior, recent work suggests that variability can actually be adaptive. An example arises when we must choose between exploring unknown options or exploiting options we know well. A little randomness in these &apos;explore-exploit&apos; decisions is remarkably effective as it can encourage us to explore options we might otherwise ignore. In line with this idea, several studies have found evidence that people increase their behavioral variability when it is valuable to explore. A key question, however, is whether this variability in so-called &apos;random exploration&apos; is actually random. That is, is random exploration driven by stochastic processes in the brain or by some unobserved deterministic process that we have failed to account for when measuring behavioral variability? By designing an exploreexploit task in which, unbeknownst to them, participants are presented with the exact same choice twice, we provide a partial answer to this question. By modeling behavior in this task, we were able to estimate a lower bound on the amount of variability that is deterministically driven by the stimulus and an upper bound on the amount of variability that is random. Using this approach, we find evidence that at least 14% of the variability in random exploration in our studied task can be accounted for by deterministic processing of the stimulus. Conversely, this suggests that up to 86% of the variability is truly &apos;random&apos;, although it is still possible that this variability is driven by deterministic factors not related to the stimulus. Finally, our results suggest that both deterministic and random sources of variability change proportionally to each other as the value of exploration increases, suggesting that a common noise gating mechanism may be at play in random exploration.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Imagine trying to decide where to go to dinner on a date. You can go to your favorite restaurant, the one you both really enjoy and always go to, or you can try a new restaurant that you know nothing about. Such decisions, in which we must choose between a well-known 'exploit' option and a lesser known 'explore' option, are known as explore-exploit decisions. From a theoretical perspective, making optimal exploreexploit choices, i.e. choices that maximize long-term reward, is computationally intractable in most cases <ref type="bibr">(Basu et al., 2018, Gittins and</ref><ref type="bibr" target="#b16">Jones, 1974)</ref>. In part because of this computational complexity, there is considerable interest in how humans and animals solve the explore-exploit dilemma in practice <ref type="bibr" target="#b21">(Mehlhorn et al., 2015</ref><ref type="bibr" target="#b25">, Schulz and Gershman, 2019</ref>.</p><p>One particularly effective strategy for solving the explore-exploit dilemma is choice randomization <ref type="bibr" target="#b7">(Bridle, 1990</ref><ref type="bibr" target="#b27">, Thompson, 1933</ref><ref type="bibr" target="#b29">, Watkins, 1989</ref>, also known as random exploration. In this strategy, high value 'exploit' options are not always chosen and exploratory choices are sometimes made by chance.</p><p>From a modeling perspective, random exploration works by adding 'decision noise' to the value of the options such that sub-optimal exploratory options can sometimes have a higher total score (i.e., value + noise) than the exploit option and get chosen. Such random exploration, is surprisingly effective and, if implemented correctly, can come close to optimal performance <ref type="bibr" target="#b0">(Agrawal and Goyal, 2011</ref><ref type="bibr" target="#b7">, Bridle, 1990</ref><ref type="bibr" target="#b8">, Chapelle and Li, 2011</ref><ref type="bibr" target="#b27">, Thompson, 1933</ref>.</p><p>It has recently been shown that humans appear to use random exploration and can increase decision noise when it is more beneficial to explore <ref type="bibr" target="#b15">(Findling et al., 2019</ref><ref type="bibr">, Gershman, 2018</ref><ref type="bibr" target="#b30">, Wilson et al., 2014</ref>. In one of these tasks, known as the Horizon Task <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref>, the key manipulation is the horizon condition, i.e. the number of decisions remaining for the participant to make. Increasing the horizon makes exploration more valuable as there is more time to use the information gained by exploration to maximize future rewards. For example, if you are leaving town tomorrow (short horizon), you will probably exploit the restaurant you know and love, but if you are in town for a while (long horizon), you will be more likely to explore the new restaurant. Using such a horizon manipulation it has been shown that people's behavior is more variable in long horizons than short horizons, suggesting that they use adaptive decision noise to solve the explore-exploit dilemma <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref>.</p><p>One limitation of this previous research, however, is that it is difficult to tell whether what we have called 'decision noise' actually reflect a noise process. From a modeling perspective, decision noise as defined in previous research essentially quantifies the extent to which behavior cannot be explained by a computational model. A missing deterministic component from the model could give rise to variability in behavior that might appear to be random noise. For example, in the restaurant example, my usual preference for one restaurant or another may be overruled if I see an ex romantic partner going into one of them. Avoiding an ex is a deterministic process, but if we fail to take the ex's presence into account as scientists modeling the decision, then over a series of such decisions where the ex is present or not, we would mistakenly attribute the ensuing 'variability' in choice to randomness.</p><p>In this paper, we investigate the extent to which the apparent randomness in random exploration can be explained by deterministic processing of the stimulus (which we refer to as 'deterministic noise') vs other processes, including deterministic processing that is unrelated to the stimuli as well as truly stochastic processes (which we refer to as 'random noise'). To distinguish between these two types of noise, we modify the Horizon Task <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref> to have people face the exact same explore-exploit choice twice. If the decision is a purely deterministic function of the stimulus (i.e., decision noise is purely deterministic noise), then people's choices should be identical for both decisions, since the stimulus is the same both times. Conversely, if the decision is a purely random function of the stimulus (i.e., decision noise is purely random noise), then people's choices will be different 50% of the time, since the random noise is different each time. In between these two extremes of purely deterministic and purely random drivers of behavioral variability, the extent to which people's decisions are consistent between the two decisions can be used to estimate the amount of deterministic and random noise.</p><p>In the following, we analyze behavior on the repeated decisions version of the Horizon Task in both a model-free and model-based manner. Our model-free analysis estimates the extent to which people's behavior is consistent across repeated versions of the same decision. By measuring how this choice consistency changes as a function of horizon, this model-free analysis offers qualitative insight into the extent to which behavioral variability is driven by deterministic vs random noise. Our model-based analysis uses a computational model of the explore-exploit decision in the Horizon Task that incorporates both noise processes. By fitting this model to the behavioral data, this model-based analysis allows us to quantify the relative size of the two sources of noise and how they change in the service of exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Repeated-Games Horizon Task</head><p>We used a modified version of the 'Horizon Task' <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref> to show the influence of stimulusdriven 'deterministic noise' vs non-stimulus-driven 'random noise' in explore-exploit decisions ( <ref type="figure">Figure   1</ref>). In this task, participants make a series of choices between two slot machines, or 'one-armed bandits', that pay out probabilistic rewards. They are asked to choose between the two bandits to maximize the total rewards. One bandit always has a higher mean payout than the other. Participants need to try each bandit a few times to learn about the distribution of payout from that bandit. Because they are initially unsure as to the mean payoff of each bandit, this task requires that participants carefully balance exploration of the lesser known bandit with exploitation of the better known bandit to maximize their overall rewards.</p><p>The task is organized in games ( <ref type="figure">Figure 1A</ref>). The mean payout of the two bandits are held fixed within a game and reset between games. Each game consists of either 5 or 10 trials. The first four trials of each game are 'forced-choice' trials. In the first four trials, participants are instructed about which bandit to choose, this allows us to manipulate what information from both bandits participants receive before they make their first free choice between the two bandits. From the 5th trial, participants make free choices between the two bandits. Participants have either 1 or 6 free choices to make.</p><p>The Horizon Task has two key features that together allow it to quantify explore-exploit behavior. The first of these features is the time horizon -the number of decisions participants will make in the future.</p><p>By changing this horizon from short (1 free-choice trial) to long (6 free-choice trials), the Horizon Task allows us to control the relative value of exploration and exploitation. Just like the restaurant example in the introduction, when the horizon is short, participants should be more likely to exploit the option they believe to be best, because this leads to the highest payoff in the short term. Conversely, when the horizon is long, participants should be more likely to explore at first, because this allows them to gather information to make better choices later on. By contrasting behavior between short and long horizon conditions on the very first free-choice trial, when all else is equal, the Horizon Task allows us to quantify how behavior changes, when it is more valuable to explore.</p><p>The second key feature of the Horizon Task are the 4 forced-choice trials at the start of each game that allow us to control exactly what participants know about the two bandits before they make their choice.</p><p>In these forced-choice trials, participants are instructed which of the bandits to play allowing us to control how much information they have about each of the options. The forced-choice trials are used to set up one of two information conditions: an 'unequal information' or [1 3] condition, in which participants play one bandit once and the other three times, and an 'equal information' or [2 2] condition, in which participants play both bandits twice.</p><p>Relative to the original Horizon Task, the key modification in this paper is to give people 'repeated games' ( <ref type="figure">Figure 1B</ref>), in which they see the exact same set of forced-choice plays twice in two separate games separated by several minutes in time so as to avoid detection. By repeating the forced-choice plays for each game twice, we can set up a situation where (unbeknownst to the participants) they are faced with the exact same explore-exploit choice, with the exact same stimuli twice. Thus, if their behavior is a deterministic function of the stimuli, then they will make the same decision in both games and their choices will be consistent. Conversely, if their behavior is not driven by a deterministic function of the stimulus, then their choices on the repeated games will be inconsistent some fraction of the time. The extent to which participants' choices are consistent on the repeated versions of the games allow us to quantify the extent to which the variability in their behavior was driven by a deterministic process vs a random noise process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Both behavioral variability and information seeking increase with horizon</head><p>Before discussing the results for repeated games, we first confirm that the basic behavior in this task is consistent with our previously reported results using both a model-free and model-based approach <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref>. In both analyses, we focus on just the first free-choice trial in each game, where the only thing that differs between the horizon conditions is the number of choices that participants will make in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-free analysis</head><p>In the model-free analysis, we quantify random and directed exploration using simple choice probabilities.</p><p>Random exploration is quantified as the probability of choosing the option that has the lower average payout in the forced-choice plays in the equal, or [2 2], condition, p(low mean). The idea here is that, in the equal condition, the optimal strategy is to compute the mean payout for each bandit from the forcedchoice plays and then always choose the option with the highest mean. When participants do not choose the option with the higher mean, the assumption is that this is due to some kind of 'decision noise', making the probability of choosing the low mean option a measure of behavioral variability. In this view, random exploration corresponds to an increase in p(low mean) with horizon, which is exactly what we see in the data <ref type="figure" target="#fig_0">(Figure 2A</ref>; t(64) = 7.99, p &lt; 0.001).</p><p>Directed exploration is quantified as the probability of choosing the more informative option p(high info)</p><p>in the unequal, or [1 3], condition. The more informative option is the option played once during the forced-choice plays as choosing this option gives relatively more information (doubling the number of samples from 1 to 2) than choosing the option played three times (only increasing the number of sample by a third, from 3 to 4). In this view, directed exporation corresponds to an increase in p(high info) with horizon, which is exactly what we see in the data ( <ref type="figure" target="#fig_0">Figure 2B</ref>; t(64) = 6.92, p &lt; 0.001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-based analysis</head><p>Another approach to understanding behavior in the Horizon Task is to use a computational model <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref>. In this case, we model participants' choices on the first free-choice trial by assuming they make decisions by computing the difference in value (or utility) ∆Q between the right and left options, choosing right when ∆Q &gt; 0 and left otherwise. Specifically, we write</p><formula xml:id="formula_0">∆Q = ∆R + A∆I + b + n (1)</formula><p>where, the experimentally controlled variables are ∆R = R right − R lef t , the difference between the mean of rewards shown on the forced-choice trials, and ∆I, the difference in information available for playing the two options on the first free-choice trial. For simplicity, and because information is manipulated categorically in the Horizon Task, we define ∆I to be +1 if one reward is drawn from the right option and three are drawn from the left in the [1 3] condition, -1 if one from the left and three from the right in the [1 3] condition, and in [2 2] condition, ∆I is 0.</p><p>Here, n denotes decision noise, which, in this version of the model is a combination of deterministic and random noise. n is assumed to come from a logistic distributions with mean 0 and standard deviations σ.</p><p>The free parameters of this model are: the information bonus A, which controls the level of directed exploration; the noise standard deviation, σ, which controls the level of random exploration, and the spatial bias, b, which determines the extent to which participants prefer the option on the right. These free parameters are fit separately for each participant in each horizon condition, allowing us to test whether directed and random exploration increase with horizon. Consistent with previous research, we find that this is indeed the case ( <ref type="figure" target="#fig_0">Figure 2C</ref>; t(64) = 5.35, p &lt; 0.001. <ref type="figure" target="#fig_0">Figure 2D</ref>; t(64) = 3.54, p &lt; 0.001). Taken together, our model-free and model-based analyses agree with previous findings showing in-creased behavioral variability and increased information seeking in the long horizon condition, consistent with humans using random and directed exploration ( <ref type="figure" target="#fig_0">Figure 2</ref>, Supplementary <ref type="figure">Figure S1</ref>). However, for random exploration, this previous analysis cannot distinguish between deterministic and random sources of noise. For this we analyze the extent to which people's choices are consistent on the repeated games.</p><p>Model-free analysis of repeated games suggests that random exploration involves both random and deterministic noise</p><p>Next we asked whether participants' choices were consistent or inconsistent in the two repetitions of each game. The idea behind this measure is that purely deterministic noise should lead to consistent choices as the deterministic stimulus is identical both times. Conversely, if choice is not entirely driven by a deterministic process and is also driven by random noise, participants' choices should be more inconsistent across the repetitions of the game. Moreover, if decision noise is purely random noise, meaning there is no unobserved deterministic process, we will show that we can actually predict the expected level of choice inconsistencies across repetitions of games by accounting for the known deterministic processes and assuming that the random noise process is independent in repetitions of the game.</p><p>To quantify choice inconsistency we computed the frequency with which participants made different responses for pairs of repeated games <ref type="figure" target="#fig_1">(Figure 3</ref>, Supplementary <ref type="figure" target="#fig_0">Figure S2</ref>). Using this measure we found that participants made inconsistent choices in both the unequal ([1 3]) and equal ([2 2]) information conditions (p(inconsistent) &gt; 0), suggesting that not all of the noise was stimulus driven. In addition, we found that choice inconsistency was higher in horizon 6 than in horizon 1 for both <ref type="bibr">[</ref>  To gain more quantitative insight into these results, we computed theoretical values for the choice inconsistency for the purely deterministic and purely random noise cases. For purely deterministic noise this computation is simple because people should make the exact same decisions each time in repeated games, meaning that p(inconsistent) = 0 in this case. For purely random noise, the two games should be treated independently, allowing us to compute the choice inconsistency in terms of the probability of choosing the low mean option, p(low mean), as</p><formula xml:id="formula_1">p(consistent) = p(low mean) 2 + p(high mean) 2 = p(low mean) 2 + (1 − p(low mean)) 2 hence, p(inconsistent) = 1 − p(consistent) = 2p(low mean)(1 − p(low mean))</formula><p>Furthermore, to account for the fact that p(low mean) is a function of reward difference ∆R between the two bandits and the information condition I, we estimated the conditional probability:</p><formula xml:id="formula_2">p(inconsistent|∆R, I) = 2p(low mean|∆R, I)(1 − p(low mean|∆R, I))</formula><p>Then based on the likelihood that each condition (∆R and I) occurs in the task ρ(∆R, I), we have</p><formula xml:id="formula_3">p(inconsistent) = ∆R,I ρ(∆R, I)p(inconsistent|∆R, I)</formula><p>As shown in <ref type="figure" target="#fig_1">Figure 3,</ref>   <ref type="figure" target="#fig_1">Figure S3</ref>). Together, our results suggest that both random noise and deterministic noise contribute to the choice variability in random exploration. However, the relative contribution from each of these types of noise, as well as how each type of noise changes with horizon, are difficult to discern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-based analysis provides a lower-bound estimate of deterministic noise and an upper-bound estimate of random noise</head><p>To more precisely quantify the contribution of deterministic noise and random noise, we turned to model fitting. We modeled behavior on the first free choice of the Horizon Task using a version of the logistic choice model (Equation 1) that was modified to differentiate between components of the noise that are deterministically driven by the stimulus ('deterministic noise') and components of the noise that are not deterministically driven by the stimulus ('random noise'). In particular, we assume that in repeated games, the value of stimulus-driven deterministic noise is frozen whereas random noise is drawn independently both times.</p><p>To model participants' choices on the first free-choice trial, we use a modified version of Equation 1.</p><formula xml:id="formula_4">∆Q = ∆R + A∆I + b + n det + n ran (2)</formula><p>where, as before ∆R, is the the difference in mean rewards shown on the forced-choice trials, ∆I, is the difference in information, A is the information bonus, and b is the spatial bias. New in Equation 2 are the terms n det and n ran . n det denotes the deterministic noise, which is identical on the repeat versions of each game; and n ran denotes random noise, which is uncorrelated between repeated plays and changes every game. n det and n ran are assumed to come from logistic distributions with mean 0, and standard deviations σ det and σ ran .</p><p>For each pair of repeated games, the set of forced-choice trials are exactly the same, so the deterministic noise, n det , should be the same while the random noise, n ran may be different. This is exactly how we distinguish deterministic noise from random noise. In symbolic terms, for repeated games i and j, n i det = n j det and n i ran ̸ = n j ran . We used hierarchical Bayesian analysis to fit the parameters of the model (see <ref type="figure">Figure 8</ref> for a graphical representation of the model in the style of Lee and Wagenmakers (2014a)). In particular, we fit values of the information bonus A, spatial bias b, variance of random noise σ 2 ran , and variance of deterministic noise σ 2 det for each participant in each horizon. Model fitting was performed using the MATJAGS and JAGS software <ref type="bibr" target="#b11">(Depaoli et al., 2016</ref><ref type="bibr" target="#b26">, Steyvers, 2011</ref> with full details given in the Methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model validation</head><p>To be sure that our fit parameter values were meaningful and to understand the limits of our model, we evaluated our model extensively using simulated data. This allowed us to quantify whether deterministic and random noise can be identified under ideal conditions where the behavior is generated by the model with known parameters. Full details are presented in the Supplementary Materials section 2.</p><p>In this section we focus on our results for parameter recovery <ref type="bibr" target="#b31">(Wilson and Collins, 2019)</ref>. In a parameter recover analysis, behavioral data is simulated by the model with known parameters and then this simulated behavioral data is fit with the model to quantify the extent to which fit parameters match the input simulated parameters -that is, whether the simulated parameters can be recovered. Parameter recover in this task was good for this model, with fit values for σ ran and σ det showing strong correlations with their simulated values in both horizon (H) conditions (For σ ran , R = 0.91(H = 1) and 0.84(H = 6), p &lt; 0.001, For σ det , R = 0.60(H = 1) and 0.59(H = 6), p &lt; 0.001). However, while the relationship was near perfect for random noise ( Recovered σran Simulated σran = 1.01), there was a systematic bias to underestimate the level of deterministic noise by about 32% ( Recovered σ det Simulated σ det = 0.68). Despite this underestimation of deterministic noise in both horizon conditions, the difference in deterministic noise between horizons is much better captured (see <ref type="figure" target="#fig_0">Supplementary Materials section 2.2)</ref>. This is because the underestimation of deterministic noise is partially canceled out when the difference is taken between horizon conditions. In addition, we see better parameter recovery for random noise than deterministic noise. This is likely because we effectively have half as many trials for deterministic noise. In particular, while we generate two samples of random noise for each repeated game pair, we only generate one sample of deterministic noise, which by definition is the same in both of the repeated games.</p><p>In addition to the conventional subject-level parameter recovery analysis presented here, we also performed parameter recovery analysis that examined how faithful the full posterior distribution of grouplevel parameters can be recovered in simulated data (Supplementary <ref type="figure" target="#fig_3">Figure S5, S6)</ref>. Qualitatively, we also showed that our way of modeling deterministic noise is capable of capturing known deterministic processes intentionally omitted from the full model (Supplementary <ref type="figure" target="#fig_2">Figure S4)</ref>. Full details of these additional analysis are presented in the Supplementary Materials.</p><p>Overall, we were able to detect both deterministic and random noises using our model. Because random noise is modeled as non-stimulus-driven noise, it can reflect both true stochastic random noise and possible deterministic noises which do not depend on the stimuli. Thus conceptually our random noise estimate provides an upper bound for the true 'random noise' induced by intrinsic stochastic processes in the brain. Thus, our model provides a lower bound for deterministic noise and an upper bound for random noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-based results</head><p>Posterior distributions over the group-level means of the deterministic and random noise standard deviation σ det and σ ran are shown in <ref type="figure" target="#fig_3">Figure 5</ref> and Supplementary <ref type="figure">Figure S11</ref>. Consistent with our model-free results, we see that both random and deterministic noise are non-zero. Numerically, random noise is about 2-3 times larger than the deterministic noise. By computing the posterior distribution of σ 2 det /(σ 2 det + σ 2 ran ), our data suggests that 14.25% of the variability in random exploration is accounted for by deterministic noise ([4.90%, 28.81%], 95% CI). In addition, we find that both random and deterministic noise increase with horizon. This increase was larger for random noise (mean = 7.13, 100% of samples showed an increase in random noise with horizon) than deterministic noise (mean = 2.59, 98.64% of samples showed an increase in deterministic noise with horizon). But intriguingly, the relative increase in both types of noise was similar ( <ref type="figure" target="#fig_4">Figure 6</ref>). That is, when we compute the relative increase in deterministic noise with horizon, σ det horizon6 /σ det horizon1 , it is very similar to the relative increase in random noise with horizon σ ran horizon6 /σ ran horizon1 .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Posterior predictive checks</head><p>In addition to fitting the model to behavior, it is also important to check whether the model captures the qualitative patterns of the data <ref type="bibr" target="#b31">(Wilson and Collins, 2019)</ref> -specifically how p(high info), p(low mean) and p(inconsistent) change with horizon.</p><p>To perform this 'posterior predictive check', we created a set of simulated data by taking the subjectlevel parameters from the hierarchical Bayesian fits and having the model play the same sequence of games as seen by the subjects. We then applied the same model-free analysis as described in the previous sections to this simulated data set and compared the model's behavior to that of participants. As shown in <ref type="figure" target="#fig_5">Figure   7</ref>, the model can account for all qualitative patterns in the data -the increase in p(high info), p(low mean), and p(inconsistent) with horizon, and that p(inconsistent) is in between pure random and pure deterministic noise. As a control, we also applied posterior predictive checks on alternative models that consider only deterministic or only random noise, and these reduced models fail to capture all qualitative patterns (Supplementary <ref type="figure" target="#fig_1">Figure S13</ref>). Full details of this analysis can be found in Supplementary Materials section 3.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this paper, we investigated whether random exploration is really random or whether it is driven deterministically by aspects of the stimulus we have previously ignored when measuring 'decision noise'.</p><p>Using a version of the Horizon Task with repeated games, we found evidence that at least some of the noise in random exploration could be explained by such 'deterministic noise'. In particular, we found that deterministic noise accounted for around 14% of the overall variability in people's behavior.</p><p>One interpretation for this low level of deterministic noise is that most of the variability in random exploration is truly random. Such a random noise interpretation, would be consistent with recent work showing that variability in perceptual decisions may be driven by imperfections in mental inference <ref type="bibr" target="#b12">(Drugowitsch et al., 2016)</ref>. In this view, apparently random behavior is not due to sensory processing or response selection, but to suboptimal computations in the brain. Although suboptimal inference is different from simply adding random noise to neural circuitry <ref type="bibr" target="#b4">(Beck et al., 2012)</ref>, as long as the suboptimality in neural computation is not a deterministic function of the stimuli, it is a form of random noise in our definition. Indeed, a strong interpretation of this hypothesis would suggest that randomness in explore-exploit behavior is due to imperfect inference about the correct course of action. In the context of the Horizon Task, such computational errors would likely be larger in the long horizon condition as the correct course of action in these cases is much harder to compute <ref type="bibr" target="#b31">(Wilson et al., 2020)</ref>.</p><p>Although the random noise interpretation is theoretically appealing, our approach, while an improvement on previous methods, is not without limitations. Most important is that our measure of 'random' noise is only an upper bound on the true level of randomness and that, in principle, the random decision noise could be lower. Specifically, in our model, what we labeled random noise was really 'non-stimulusdriven variability'. While this non-stimulus-driven variability could be driven by truly random stochastic processes, it could also be driven by deterministic processing that is unrelated to the stimuli in the task.</p><p>For example, such deterministic noise could be driven by differences in where people look, or for how long they look, or by whether they were fidgeting or scratching their nose <ref type="bibr" target="#b22">(Musall et al., 2019)</ref>. In addition to this conceptual limitation in measuring deterministic noise, parameter recovery simulations suggest that our estimation method also slightly underestimates deterministic noise (see <ref type="figure" target="#fig_2">Figure 4</ref>, <ref type="figure" target="#fig_3">Supplementary   Figure S5, S6)</ref>. As a result, from both a conceptual and methodological perspective, it is possible that the remaining 86% of the decision noise that is not stimulus-driven noise, could be deterministic.</p><p>Like the random noise account, the deterministic noise account is also in line with previous work in which neural variability can be accounted for by fluctuations in sensory inputs. For example, MT neurons were shown to have a reproducible temporal modulation in response to a fixed random motion stimuli <ref type="bibr" target="#b2">(Bair and Koch, 1996)</ref>. In other words, 'irrelevant' features in the stimuli are represented in a reliable way in the brain that could drive downstream choices in a predictable way.</p><p>Regardless of whether we interpret the noise as random or deterministic, a key finding in this paper is that both types of noise change with horizon. Such a horizon increase is a hallmark of an exploratory process and suggests that the modulation of deterministic and random processes may underlie random exploration. Moreover, the fact that the horizon change in the two types of noise are proportional to each other ( <ref type="figure" target="#fig_4">Figure 6</ref>) suggests a possible mechanism for random exploration: a reduction in the strength with which reward drives the choice.</p><p>To see how a change in reward processing could affect random and deterministic noise, consider the simple decision model we introduced in Equation 2. In this model, choice is determined by the sign of the difference in utility ∆Q between the two options, where</p><formula xml:id="formula_5">∆Q = ∆R + A∆I + b + n det + n ran<label>(3)</label></formula><p>Now imagine a case where the reward signal is scaled by a factor β. In this case, ∆Q becomes</p><formula xml:id="formula_6">∆Q = β∆R + A∆I + b + n det + n ran (4)</formula><p>Because the choice only depends on the sign of ∆Q, scaling ∆Q by a factor of 1/β will not change the behavior of the model. Thus, if we divide both sides of the above equation by β we get</p><formula xml:id="formula_7">∆Q/β = ∆R + A∆I/β + b/β + n det /β + n ran /β<label>(5)</label></formula><p>which is equivalent to a scaling of both deterministic and random noise by the same factor 1/β. Thus, one interpretation of our result that both deterministic and random noise change across horizons with the same ratio, is that this reflects a change in reward processing. That is, the reward signal is reduced in the longer horizon condition (smaller β in horizon 6 than horizon 1).</p><p>Such a reduction in the strength of reward coding in exploration, is consistent with our recent work using a drift diffusion model (DDM) to model explore-exploit decisions <ref type="bibr" target="#b14">(Feng et al., 2021)</ref>. In the drift diffusion model, changes in behavioral variability can be driven by changes in the decision threshold (smaller threshold = more noise) or changes in the signal-to-noise ratio with which reward is encoded (lower SNR = more noise). By fitting both choices and response times, we were able to distinguish between these two accounts showing that the majority of the horizon-change in variability was driven by changes in SNR not threshold. However, this model could not determine whether the changes in SNR were driven by signal or noise. By showing that the change in deterministic and random noise have approximately the same ratio, the present work suggests that this SNR change is driven by changes in reward-signal processing, not noise. Of course, to truly see whether changes in signal or noise are driving random exploration will require more direct measurements of neural processing such as with neuroimaging and electrophysiology <ref type="bibr" target="#b9">(Costa et al., 2019</ref><ref type="bibr" target="#b13">, Ebitz et al., 2018</ref><ref type="bibr" target="#b17">, Hogeveen et al., 2022</ref><ref type="bibr" target="#b28">, Tomov et al., 2020</ref> Materials and Methods Participants 80 participants (ages 18-25, 37 male, 43 female) from the University of Arizona undergraduate subject pool participated in the experiment. 15 were excluded on the basis of performance, using the same exclusion criterion as in <ref type="bibr" target="#b30">Wilson et al. (2014)</ref>. In this exclusion criteria, we measured the accuracy of each participant's choices by calculating the percentage of times that a participant chose the bandit with the higher underlying mean payouts in the last choice of a long horizon game, intuitively people should figure out which bandit has a higher mean payout by the last trial and should have an accuracy measure significantly above 50%, specifically, we computed the likelihood that the measured accuracy can be achieved by making a completely random choice between the two options and excluded participants with a likelihood greater than 0.1%, in other words, participants who didn't show an accuracy significant above chance with p &lt; 0.001 were excluded in the analysis. This left 65 for the main analysis. Note that including the 15 badly performing subjects did not change the main results ( <ref type="figure" target="#fig_0">Supplementary Figures S1, S2</ref>, S11)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task</head><p>The task was a modified version of the Horizon Task <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref>  <ref type="figure">(Figure 1)</ref>. In this task, participants play a set of games in which they make choices between two slot machines (one-armed bandits) that pay out rewards from different Gaussian distributions. In each game they made multiple decisions between two options. Each option paid out a random reward between 1 and 100 points sampled from a Gaussian distribution. The means of the underlying Gaussians were different for the two bandit options, remained the same within a game, but changed with each new game. One of the bandits always had a higher mean than the other. Participants were instructed to maximize the points earned over the entire task. To maximize their rewards in each game, participants need to exploit the slot machine with the highest mean, but they cannot identify this best option without exploring both options first.</p><p>The number of games participants played depended on how well they performed, which acted as the primary incentive for performing the task. Thus, the better participants performed, the sooner they got to leave the experiment. On average, participants played 153.7 games (minimum = 90 games, maximum = 192 games) and the whole task lasted between 12.37 and 32.15 minutes (mean 22.78 minutes). Participants As in the original paper <ref type="bibr" target="#b30">(Wilson et al., 2014)</ref>, the distributions of payoffs tied to bandits were independent between games and drawn from a Gaussian distribution with variable means and fixed standard deviation of 8 points. Differences between the mean payouts of the two slot machines were set to either 4, 8, 12 or 20. One of the means was always equal to either 40 or 60 and the second was set accordingly.</p><p>Participants were informed that in every game one of the bandits always has a higher mean reward than the other. The order of games was randomized. Mean sizes and order of presentation were counterbalanced.</p><p>Each game consisted of 5 or 10 choices. Every game started with a fixation cross, then a bar of boxes appeared indicating the horizon for that game. For the first 4 trials -the instructed 'forced-choice' trials, we highlight the box on one of the bandits to instruct the participant to choose that option. On these trials, they have to press the corresponding key to reveal the outcome. From the fifth trial, boxes on both bandits will be highlighted and they are free to make their own decision. There was no time limit for decisions.</p><p>During free choices participants could press either the left arrow key or right arrow key to indicate their choice of left or right bandit. The score feedback was presented for 300ms. The task was programmed using Psychtoolbox in MATLAB <ref type="bibr" target="#b6">(Brainard, 1997</ref><ref type="bibr" target="#b24">, Pelli, 1997</ref>.</p><p>The first four trials of each game were forced-choice trials, in which only one of the options was available for the participant to choose. We used these forced-choice trials to manipulate the relative ambiguity of the two options, by providing the participant with different amounts of information about each bandit before their first free choice. The four forced-choice trials set up two uncertainty conditions: unequal uncertainty(or [1 3]) in which one option was forced to be played once and the other three times, and equal uncertainty(or [2 2]) in which each option was forced to be played twice. After the forced-choice trials, participants made either 1 or 6 free choices (two horizon conditions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-based analysis</head><p>We modeled behavior on the first free choice of the Horizon Task using a version of the logistic choice model in <ref type="bibr" target="#b30">Wilson et al. (2014)</ref> that was modified to differentiate deterministic noise from random noise.</p><p>Because the stimuli are identical in the repeated games, by definition, deterministic noise remains the same in repeated games, whereas random noise can change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchical Bayesian Model</head><p>To model participants' choices on this first free-choice trial, we assume that they make decisions by computing the difference in value ∆Q between the right and left options, choosing right when ∆Q &gt; 0 and left otherwise. Specifically, we write</p><formula xml:id="formula_8">∆Q = ∆R + A∆I + b + n det + n ran (6)</formula><p>where, the experimentally controlled variables are ∆R = R right − R lef t , the difference between the mean of the rewards shown on the forced trials, and ∆I, the difference of information available for playing the two options on the first free-choice trial. For simplicity, and because information is manipulated categorically in the Horizon Task, we define ∆I to be +1, -1 or 0, +1 if one reward is drawn from the right option and three are drawn from the left in the [1 3] condition, -1 if one from the left and three from the right, and in [2 2] condition, ∆I is 0. The other variables are: the spatial bias, b, which determines the extent to which participants prefer the option on the right; the information bonus A, which controls the level of directed exploration; n det and n ran are deterministic noise and random noise respectively. n det denotes the deterministic noise, which is identical on the repeat versions of each game; and n ran denotes random noise, which is uncorrelated between repeat plays and changes every game.</p><p>Each subject's behavior in each horizon condition is described by 4 free parameters <ref type="table" target="#tab_5">(Table 1)</ref>: the information bonus A, the spatial bias, b, the standard deviation of the deterministic noise, σ det , and the standard deviation of the random noise, σ ran . Each of the free parameters is fit to the behavior of each subject using a hierarchical Bayesian approach <ref type="bibr" target="#b1">(Allenby et al., 2005)</ref>. In this approach to model fitting, each parameter for each subject is assumed to be sampled from a group-level prior distribution whose parameters, the socalled 'hyperparameters', are estimated using a Markov Chain Monte Carlo (MCMC) sampling procedure <ref type="figure">(Figure 8</ref>). The hyper-parameters themselves are assumed to be sampled from 'hyperprior' distributions whose parameters are defined such that these hyperpriors are broad.</p><p>The particular priors and hyperpriors for each parameter are shown in <ref type="table" target="#tab_5">Table 1</ref>. For example, we assume that the information bonus, A is , for each horizon condition i and for each participant s, is sampled from a Gaussian prior with mean µ A i and standard deviation σ A i . These prior parameters are sampled in turn from their respective hyperpriors: µ A i , from a Gaussian distribution with mean 0 and standard deviation 10, and σ A i from an Exponential distribution with parameters 0.1.   Model fitting using MCMC</p><formula xml:id="formula_9">∼ Gaussian(µ A i , σ A i ) θ A i = (µ A i , σ A i ) µ A i ∼ Gaussian( 0, 100 ) σ A i ∼ Exponential(0.01) spatial bias, b is b is ∼ Gaussian(µ b i , σ b i ) θ b i = (µ b i , σ b i ) µ b i ∼ Gaussian( 0, 100 ) σ b i ∼ Exponential(0.01) deviation of deterministic noise, σ det isg σ det is ∼ Gamma(k det i , λ det i ) θ det i = (k det i , λ det i ) k det i ∼ Exponential(0.01) λ det i ∼ Exponential<label>(</label></formula><p>The model was fit to the data using Markov Chain Monte Carlo approach implemented in the JAGS package <ref type="bibr" target="#b11">(Depaoli et al., 2016)</ref> via the MATJAGS interface (psiexp.ss.uci.edu/research/programs data/jags).</p><p>This package approximates the posterior distribution over model parameters by generating samples from this posterior distribution given the observed behavioral data.</p><p>In particular we used 10 independent Markov chains to generate 50000 samples from the posterior distribution over parameters (5000 samples per chain). Each chain had a burn in period of 5000 samples, which were discarded to reduce the effects of initial conditions, and posterior samples were acquired at a thin rate of 1. Convergence of the Markov chains was confirmed post hoc by eye.  <ref type="formula">10</ref>Subject specific parameters</p><formula xml:id="formula_10">∆R isg ∆I isg c isgr A is b is σ ran is σ det is µ A i σ A i µ b i σ b i k ran i λ ran i k det i λ det i n</formula><formula xml:id="formula_11">A is ∼ Gaussian(µ A i , σ A i ) B is ∼ Gaussian(µ B i , σ B i ) σ ran is ∼ Gamma(k ran i , λ ran i ) σ det is ∼ Gamma(k det i , λ det i )</formula><p>Deterministic noise for repeated game n det isg ∼ Logistic(0, σ det is ) Random noise for each game n ran isgr ∼ Logistic(0, σ ran is )</p><p>Observed choices ∆Q isgr ← ∆R isg + A is ∆I isg + b is + n ran isgr + n det isg c isgr ∼ Bernoulli (Q isgr &gt; 0) <ref type="figure">Figure 8</ref>: Schematic of the hierarchical Bayesian model using notation of Lee and Wagenmakers (2014b)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and code</head><p>Behavioral data as well as MATLAB codes to recreate the main figures from this paper will be made available upon publication.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Replication of previous findings that people use both random and directed exploration in this task. (A) model-free measure of behavioral variability, p(low mean), increases with horizon. (B) modelfree measure of information seeking, p(high info), increases with horizon. (C) model-based measure of behavioral variability, decision noise σ, increases with horizon. (D) model-based measure of information seeking, information bonus A, increases with horizon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Model-free analysis suggests that both deterministic and random noise contribute to the choice variability in random exploration. For both the [1 3] (A) and [2 2] (B) condition, people show greater choice inconsistency in horizon 6 than horizon 1. However, the extent to which their choices are inconsistent lies between what is predicted by purely deterministic and random noise, suggesting that both noise sources influence the decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Parameter recovery analysis for random (A,B) and deterministic (C,D) noises in the two horizons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Model based analysis showing the posterior distributions over the group-level mean of the standard deviations of random and deterministic noise. Both random (A, B) and deterministic (C,D) noises are nonzero (A, C) and increase with horizon (B, D).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>(A) Model based analysis showing the posterior distributions over the ratio of the group-level mean of the standard deviations of random and deterministic noise between horizon 6 and horizon 1 respectivelly. The ratios in the standard deviations of noises between horizon 6 and horizon 1 are similar for random and deterministic noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Our model accounts for all qualitative patterns of the data, namely, (A) p(high info) and (B) p(low mean) increase as a function of horizon, p(inconsistent) increases as a function of horizon for both [1 3] (C) and [2 2] (D) conditions and it lies between the pure random and pure deterministic noise prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>played an average of 65.3 repeated pairs of games (minimum = 30 repeated pairs, maximum = 79 repeated pairs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Gaussian(0, 100), σ A i ∼ Exponential(0.01) µ b i ∼ Gaussian(0, 100), σ b i ∼ Exponential(0.01) k ran i ∼ Exponential(0.01), λ ran i ∼ Exponential(10) k det i ∼ Exponential(0.01), λ det i ∼ Exponential</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>people's behavior falls in between the pure deterministic noise prediction and the pure random noise prediction. Specifically, behavior is different from the pure random noise prediction</figDesc><table><row><cell>in the both the [1 3] condition (t(64) = 4.83, p &lt; 0.001 for horizon 1, t(64) = 3.12 p = 0.003 for horizon</cell></row><row><cell>6) and the [2 2] condition (t(64) = 3.92, p &lt; 0.001 for horizon 1, t(64) = 3.71, p &lt; 0.001 for horizon</cell></row></table><note>6). Likewise, behavior is different from pure deterministic noise prediction in both the [1 3] condition (t(64) = 13.72, p &lt; 0.001 for horizon 1, t(64) = 16.71, p &lt; 0.001 for horizon 6) and the [2 2] condition (t(64) = 9.55, p &lt; 0.001 for horizon 1, t(64) = 17.93, p &lt; 0.001 for horizon 6). As a negative control of our method for estimating p(inconsistent) for purely random noise, we simulated choices using a decision model that only includes random noise (Equation 2), and found that p(inconsistent) in this simulated data is not different from our pure random noise prediction in all horizon and uncertainty conditions (p &gt; 0.05, Supplementary</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 :</head><label>1</label><figDesc>Model parameters, priors, hyperparameters and hyperpriors.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Analysis of thompson sampling for the multi-armed bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipra</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navin</forename><surname>Goyal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Hierarchical bayes models: A practitioners guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Mcculloch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Temporal Precision of Spike Trains in Extrastriate Cortex of the Behaving Macaque Monkey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wyeth</forename><surname>Bair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Koch</surname></persName>
		</author>
		<idno>08997667. doi: 10.1162/ neco.1996.8.6.1185</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1185" to="1202" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Belman: Bayesian bandits on the belief-reward manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debabrota</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stéphane</forename><surname>Bressan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Not noisy, just wrong: the role of suboptimal inference in behavioral variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pitkow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><forename type="middle">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xaq</forename><surname>Pitkow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pouget</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2012.03.016</idno>
		<ptr target="https://www.ncbi.nlm.nih.gov/pubmed/22500627" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="896" to="6273" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">Print</note>
	<note>Linking. Alexandre eng R01 EY020958/EY/NEI NIH HHS/</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">2012/04/17 Neuron</title>
		<idno type="DOI">10.1016/j.neuron.2012.03.016</idno>
		<editor>R01EY020958/EY/NEI NIH HHS/ Research Support, N.I.H., Extramural Research Support, Non-U.S. Gov&apos;t Research Support, U.S. Gov&apos;t, Non-P.H.S.</editor>
		<imprint>
			<date type="published" when="2012-04-12" />
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="30" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The psychophysics toolbox</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimates of parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bridle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="211" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An empirical evaluation of thompson sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2249" to="2257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Subcortical substrates of explore-exploit decisions in primates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Mitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Averbeck</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2019.05.017</idno>
		<ptr target="NIHHHS/ZIAMH002928/ImNIH/IntramuralNIHHHS/ZIA" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="896" to="6273" />
			<date type="published" when="2019" />
			<publisher>Vincent D Mitz</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Print</note>
	<note>Linking</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Intramural 2019/06/15 Neuron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nih</forename><surname>Intramural</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hhs/ Research</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">I H</forename><surname>Support</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2019.05.017</idno>
		<imprint>
			<date type="published" when="2019-06-10" />
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="533" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Just another gibbs sampler (jags): Flexible software for mcmc implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">P</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><forename type="middle">R</forename><surname>Cobb</surname></persName>
		</author>
		<idno type="DOI">10.3102/1076998616664876</idno>
		<ptr target="https://doi.org/10.3102/" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="628" to="649" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computational Precision of Mental Inference as Critical Source of Human Choice Suboptimality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Devauchelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koechlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1398" to="1411" />
			<date type="published" when="2016-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploration disrupts choice-predictive signals and alters dynamics in prefrontal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Ebitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Albarran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2018.01.011</idno>
		<idno>doi: 10.1016/j.neuron.2018.01.011</idno>
		<ptr target="https://www.ncbi.nlm.nih.gov/pubmed/29346756" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">475</biblScope>
			<date type="published" when="2018-01-17" />
		</imprint>
	</monogr>
	<note>Linking. Tirin eng Published Erratum 2018/01/19 Neuron</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The dynamics of explore-exploit decisions reveal a signal-to-noise mechanism for random exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Zarnescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-021-82530-8</idno>
		<ptr target="https://doi.org/10.1038/s41598-021-82530-8" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3077</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Computational noise in rewardguided learning drives behavioral variability in volatile environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Findling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Skvortsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dromnelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wyart ; Charles Skvortsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasilisa</forename><surname>Dromnelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Orcid</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41593-019-0518-9.1546-1726Findling</idno>
		<idno>doi: 10.1038/s41593-019-0518-9</idno>
		<ptr target="doi:10.1016/j.cognition.2017.12.014" />
	</analytic>
	<monogr>
		<title level="j">Journal Article Research Support</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2066" to="2077" />
			<date type="published" when="2019-10-28" />
		</imprint>
	</monogr>
	<note>Gov&apos;t United States 2019/10/30 Nat Neurosci</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A dynamic allocation index for the sequential design of experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Gittins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in Statistics</title>
		<imprint>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The neurocomputational bases of explore-exploit decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hogeveen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Mullins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eversole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rogge-Obando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Costa ; Teagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Eversole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Rogge-Obando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Costa</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2022.03.014</idno>
		<ptr target="VincentDengP51OD011092/OD/NIHHHS/P30GM122734/GM/NIGMSNIHHHS/ZIAMH002929/ImNIH/IntramuralNIHHHS/P20GM109089/GM/NIGMSNIHHHS/ZIA" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="896" to="6273" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">Print</note>
	<note>Linking</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">2022/04/08 Neuron</title>
		<idno type="DOI">10.1016/j.neuron.2022.03.014</idno>
		<editor>MH002928/ImNIH/Intramural NIH HHS/ R01 MH125824/MH/NIMH NIH HHS/ Research Support, N.I.H., Extramural Research Support, N.I.H., Intramural Research Support, U.S. Gov&apos;t, Non-P.H.S.</editor>
		<imprint>
			<date type="published" when="2022-04-06" />
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="1869" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Bayesian Cognitive Modeling: A Practical Course. Cambridge University Press</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric-Jan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139087759</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Bayesian Cognitive Modeling: A Practical Course. Cambridge University Press</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric-Jan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139087759</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Unpacking the exploration-exploitation tradeoff: A synthesis of human and animal literatures. Decision, 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Braithwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hausmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Fiedler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cleotilde</forename><surname>Gonzalez</surname></persName>
		</author>
		<idno type="DOI">10.1037/dec0000033</idno>
		<imprint>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Single-trial neural dynamics are dominated by richly varied movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Juavinett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gluf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Churchland</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41593-019-0502-4</idno>
		<ptr target="https://www.ncbi.nlm.nih.gov/pubmed/31551604.Musall" />
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1097" to="6256" />
			<date type="published" when="2019" />
			<publisher>Simon Kaufman</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Print</note>
	<note>Linking</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashley</forename><forename type="middle">L</forename><surname>Juavinett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Gluf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Churchland</surname></persName>
		</author>
		<idno>019-0502-4. Epub</idno>
		<editor>Anne K eng R01 EY022979/EY/NEI NIH HHS/ Research Support, N.I.H., Extramural Research Support, Non-U.S. Gov&apos;t Research Support</editor>
		<imprint>
			<date type="published" when="2019-09-24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The VideoToolbox software for visual psychophysics: transforming numbers into movies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Pelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spat Vis</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="437" to="442" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The algorithmic architecture of exploration in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2018.11.003.URLhttps://www.sciencedirect.com/science/article/pii/S0959438818300904</idno>
		<idno>0959-4388. doi</idno>
		<ptr target="https://doi.org/10.1016/j.conb.2018.11.003.URLhttps://www.sciencedirect.com/science/article/pii/S0959438818300904" />
	</analytic>
	<monogr>
		<title level="m">Machine Learning, Big Data, and Neuroscience</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">An interface for MATLAB to JAGS version 1.3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matjags</surname></persName>
		</author>
		<ptr target="http://psiexp.ss.uci.edu/research/programs_data/jags/" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the likelihood that one unknown probability exceeds another in view of the evidence of two samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">R</forename><surname>Thompson</surname></persName>
		</author>
		<idno>00063444</idno>
		<ptr target="http://www.jstor.org/stable/2332286" />
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="285" to="294" />
			<date type="published" when="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dissociable neural correlates of uncertainty underlie different exploration strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Tomov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">Q</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Hundia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman ; Momchil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hundia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gershman</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-020-15766-z</idno>
		<idno>doi: 10.1038/s41467-020- 15766-z</idno>
		<ptr target="https://www.ncbi.nlm.nih.gov/pubmed/32398675.Tomov" />
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<editor>Samuel J eng R01 MH109177/MH/NIMH NIH HHS/ S10 OD020039/OD/NIH HHS/ Research Support, N.I.H., Extramural Research Support, Non-U.S. Gov&apos;t Research Support, U.S. Gov&apos;t, Non-P.H</editor>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2371</biblScope>
			<date type="published" when="2020-05-12" />
		</imprint>
	</monogr>
	<note>Nat Commun</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning from delayed rewards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J C H</forename><surname>Watkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
		<respStmt>
			<orgName>Cambridge University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Humans use directed and random exploration to solve the explore-exploit dilemma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Gen</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2074" to="2081" />
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Ten simple rules for the computational modeling of behavioral data. eLife</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><forename type="middle">G E</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/uj85c</idno>
		<idno>doi: 10.31234/osf.io/uj85c</idno>
		<ptr target="https://doi.org/10.31234/osf.io/uj85c" />
		<imprint>
			<date type="published" when="2019-02" />
		</imprint>
	</monogr>
	<note>account of explore-exploit behavior</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Balancing exploration and exploitation with information and randomization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Robert C Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Becket</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ebitz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2020.10.001.URLhttps://www.sciencedirect.com/science/article/pii/S2352154620301467.Com-putationalcognitiveneuroscience</idno>
		<idno>2352-1546. doi</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2020.10.001.URLhttps://www.sciencedirect.com/science/article/pii/S2352154620301467.Com-putationalcognitiveneuroscience" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="49" to="56" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
