<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">&quot;Clinical Reach into the Cognitive Space&quot; (CRITiCS) -An outline conceptual framework for the safe use of generative artificial intelligence in mental health decision making</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Hider</surname></persName>
							<email>andrew.hider@iriscaregroup.co.uk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Consultant Clinical and Forensic Psychologist and Clinical Director, Iris Care Group</orgName>
								<address>
									<settlement>Cardiff</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lesa</forename><surname>Wright</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Consultant Psychiatrist and Chief Technology Officer</orgName>
								<orgName type="institution">Psychiatry UK Ltd</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Needle</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Assistant Psychologist</orgName>
								<orgName type="department" key="dep2">Iris Care Group</orgName>
								<address>
									<region>Cardiff</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">&quot;Clinical Reach into the Cognitive Space&quot; (CRITiCS) -An outline conceptual framework for the safe use of generative artificial intelligence in mental health decision making</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>This article introduces the &quot;CRITiCS&quot; framework for designing and deploying generative AI systems to support clinical decision-making in mental health services. Advances in generative AI, particularly through large language models like GPT-4, have opened opportunities to develop cognitive agents to enhance clinical productivity, especially in complex secondary and tertiary care settings. As AI begins to occupy the &apos;cognitive space&apos; traditionally held by human clinical reasoning, transparency becomes a significant concern. Unlike human decisionmaking, AI-generated outputs may not be traceable to a transparent chain of clinical reasoning, potentially impacting safety if used without adequate clinician reach into the reasoning space of AI. This paper highlights the need for a consensus framework to guide the responsible use of generative AI in mental healthcare, which it is argued has cognitive demands and features distinct from physical medicine. This paper aims to spark dialogue and interest in both the clinical and AI development communities.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"...much of the meaning of a represented piece of information derives from the context in which</head><p>the information is encoded and decoded. This can be a tremendous advantage. To the extent that the two thinking beings are sharing a common rich context, they may utilize terse signals to communicate complex thoughts." Douglas <ref type="bibr" target="#b0">Lenat (1975)</ref> We will not review the entire history of artificial intelligence developments here, but it is clear the recent advances have surpassed initial timescale predictions as to the emergence of human level processing generative AI, and perhaps even accelerated progress towards general artificial intelligence <ref type="bibr" target="#b1">2</ref> . For clinicians seeking a comprehensive overview that supports an understanding of how the new 'transformer' based large language models such as GPT4 work, we would suggest reading Wolfram <ref type="bibr" target="#b2">3</ref> as an adjunct to the ideas contained within this paper. By way of definition, a large language model (LLM) is a type of algorithm capable of generating text based on a particular context due to the associated patterns in the vast quantities of data it has been trained on. These patterns convey an apparent ability to reason when the LLM is presented with particular information. In comparison with physical medicine, use cases for AI in mental healthcare have been limited in scope given the differences between mental health treatment and those applied in physical medicine. For example, AI use for diagnostic purposes in radiology is established, initial models have already been deployed and consensus governance frameworks developed <ref type="bibr" target="#b3">4</ref> . We would argue that this situation is due to both the ontological and procedural structure of mental health care.</p><p>It is important to delineate the distinct features of mental health care before considering how a conceptual model might support the development and governance of AI systems that can be used safely in the clinical domain. It is also of note that the majority of conversations about the applications of AI in mental health services have to date focused on clinical 'expert models' that replicate the (psychological) therapeutic task via chatbot interfaces. This paper starts from the position that 'AI therapy' is not likely to be the main use case for generative AI in mental healthcare. Rather, we believe that the use case will centre on expert models that undertake "cognitive space" work such as case formulation, and therefore augment clinician cognition, to improve productivity and increase time available for direct clinical contact. This is particularly relevant in secondary and tertiary care services, where information load and clinical administration burden is high, and where patient safety is a function of good global awareness of historical and current clinical factors. We also envisage that areas of the world with significant shortages of trained mental health clinicians would benefit from access to a generative AI cognitive space that mirrors that of a highly trained clinician, particularly in the context of specialism specific demand.</p><p>Mental health care is ontologically and theoretically diverse.</p><p>Mental health care rests on the application of theories of mind and behaviour that are typically contested and are pragmatic in nature to a greater extent than those in physical medicine <ref type="bibr" target="#b4">5</ref> .</p><p>Clinical constructs, derived from and constitutive of these theories, are used and manipulated in cognitive space by clinicians. These constructs do not typically map onto the world in the same way as those manipulated by clinicians working in physical medicine. For example, many, if not most, commonly used mental health ontological constructs such as for example 'schemata', 'automatic thoughts', 'overvalued ideas', 'primary affect', 'executive function' are, we would argue, heterotopic to reality. In other words, these ontologies map reality onto often speculative or inferred psychophysical states, and/or onto higher level factor-analytically, neuropsychologically and/or biologically derived constructs from the fields of clinical psychology and psychiatry. Further, constructs may be ontologically distinct across multiple theoretical areas (e.g., "schemata" is a construct used with variable meaning across different kinds of cognitive therapy, and neuropsychological theory). It is therefore far more challenging to map a negative mental or emotional experience against a single apparent root cause. In contrast, physical medical constructs are often more measurable, visible, and more homotopic to reality (such as measures of neoplasm cell division in oncology). This makes it far simpler to map a negative experience such as a painful lump in the neck against a root causefor example, a neoplastic growth. We recognise that we are to some extent generalising and that with respect to some medical conditions (e.g., chronic inflammatory conditions such as fibromyalgia, and some chronic pain conditions), this is generally not the case. However, it is arguable that in mental healthcare, even quantitative psychometric and neuropsychometric data, is not at root measuring "states of the world '' analogous to such observational measures in physical medicine. This feature of mental healthcare has profound implications for the safe clinical use of artificial intelligence.</p><p>Given that clinical decision making in mental healthcare uses, in almost all cases, these "heterotopic" constructs, the transparency of a system's ontology increases in importance, as does a governance framework that ensures that the model 'knows' the ontological status of the constructs it is representing, when constructing and mapping a high-dimensional cognitive space for the purposes of undertaking those cognitive tasks relevant to mental healthcare.</p><p>Patient Safety in mental health care is often a function of "weak signal" detection in unstructured datasets.</p><p>Serious adverse events related to mental health such as suicide and homicide are rare in the general population. While the incidence of these is higher in specific clinical mental health populations, general purpose language models may not be equipped to identify these correctly in unstructured datasets. The clinical record in mental health is dominated by unstructured data.</p><p>'Weak signals' in this data, such as a single sentence in a clinical note that reports a particular risk indicator, or patterns in collective clinical data across a single site, may in hindsight be drivers of significant harm <ref type="bibr" target="#b5">6</ref> . Serious incident reviews in the field are replete with such examples 7 . While, arguably, the automation of clinical history review is likely to improve signal detection, given the known variabilities of humans in their ability to digest and detect weak signals in large data sets, it is also the case that the accountability of the agent (the clinician) remains intact, post hoc, even if a weak signal was missed. When applying AI to mental health clinical review, a transparent governance framework to ensure sufficient 'clinician reach' into the processes of signal definition, signal detection and the activation of a response to both weak and strong signals in the data (in order to maintain patient safety), is</p><formula xml:id="formula_0">critical 8 .</formula><p>Conversely, in mental healthcare, over-emphasising weak signals due to lack of clinical experience can lead to iatrogenic harm, through over treatment and stigmatisation -for example, the misinterpretation of normative yet subjectively severe psychological distress and precipitous use of diagnosis and treatment. This can occur in grief or adjustment disorder states which may be misconstrued as severe depressive episodes. Any governance framework for the use of autonomous clinical agents will also need to be able to protect against this risk. Mental Health care delivery is driven by idiographic case formulation.</p><p>There are some components of mental health care that yield to diagnostically based heuristics (for example, protocols for antipsychotic use in schizophrenia and other psychotic illnesses).</p><p>However, in the majority of cases the overall treatment heuristic incorporates some degree of idiographic case formulation that drives ongoing treatment and risk management. Case formulation may either be theory naive -for example generic '5P' models as outlined by <ref type="bibr">Winiarski 9</ref> , single-theory dependent, for example, cognitive behavioural formulation models <ref type="bibr" target="#b8">10</ref> , or procedurally theoretically integrated, for example, process-based therapy <ref type="bibr" target="#b9">11</ref> . NICE in the UK provides guidance on the broad theoretical constraints around which treatment for specific conditions should be provided, but given that in mental health care, multiple morbidity is the norm, clinicians often undertake case formulation from a theory diverse perspective in order to construct an individual map of the presenting difficulty, alongside the patient wherever possible, to support treatment selection, clinical staging, and outcome evaluation. This is a highly idiographic task that is dependent heavily on clinician available knowledge, training level and both clinician and patient preference. There is limited predictive power to idiographic formulation, particularly in complex cases, such that a hindsight review can definitively conclude that the formulation was 'wrong' in a manner analogous to a treatment or assessment omission in the management of a physical disease. This has implications in the use of case formulations as "fine tuning" material for both clinicians and generative artificial agents. As treatment histories get longer, multiple formulations typically exist in the clinical record.</p><p>The passage of time may invalidate formulations simply because they are missing more recent datapoints. Further, case formulations are approximations of the whole. Suitably skilled mental clinicians have the ability to distil a vague sense of meaning into concrete signals via learned clinical reasoning. This skill is hard to operationalise in the terms of a formal cognitive space in the context of mental healthcare, perhaps even more so than in physical healthcare. Finally, the nature of human mental health is that it is profoundly influenced by stochastic variables external to the person -(such as social and economic circumstances and life events that may impact on the genesis and pathway of illness and in many instances, define it). However, there have been recent advances in the literature <ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b11">13</ref> .</p><p>Agentive "Reach" into the Clinical Cognitive Space Computational models of the kinds of complex human cognition that account for all of the cognitive processes underpinning mental health clinical work remain matters of active investigation <ref type="bibr" target="#b12">14</ref> . Nonetheless, mapping and creating a high dimensional computational space that broadly (albeit not fully transparently) models the cognitive space of a clinician when constructing a mental health case formulation is now technologically achievable, as is a system that automates the process of clinical formulation. However, there is a clear need to ensure that the "agentive reach" of clinicians into the finalisation of hypothesis driven case formulations into those constructed by an artificially intelligent agent is significant and sufficient. There is also a need to ensure that objective and transparent confidence metrics are built into such processes, to reduce the risk of automation bias, i.e. clinician overconfidence in case formulations generated by such agents. Furthermore, future clinicians will need to be able to explain these metrics and their meaning to their patients. Development of confidence metrics and paradigms using current 'explainable AI' protocols is an urgent task.  The area space of each triangle represents the degree of cognitive space occupied by each agent (human and AI). As such, it represents a combined human / machine cognitive space. As the area of cognitive space each agent controls decreases, the degree to which "supervisory" attention is required by each agent (to the decision-making process) increases, to support weak signal detection and to ensure human penetrance into areas of case consideration that require, for example, empathic or derived relational responses originating in human (clinician) learning.</p><p>Similarly, machine attention is deployed to some degree throughout the space, in order to support safety in areas where human cognitive and psychological weaknesses may affect the heuristic process.</p><p>Solving the challenge of the 'alignment problem' as applied to AI use in mental healthcare will involve both ensuring adequate human reach into machine cognitive spaces in healthcare applications of AI, as well as using the current technological advances to introduce intelligent agent "reach" into the cognitive space of human clinical decision making. This view sees AI reach as a potential safety enhancing process, given that human errors make such a large contribution to patient safety incidents in mental healthcare. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cognitive Space Artificial</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1 -CRITiCS model -Nature and Degree of Agentive Reach by Cognitive Space</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The framework -that we have called 'CRITiCS' -suggests a potential conceptual basis through which to map existing AI healthcare governance principles, such as those outlined by Reddy et. al. <ref type="bibr" target="#b15">17</ref> , to support the safe application of the new LLM technologies in the field of mental health. We have argued that mental healthcare needs such a framework, given its ontological and epistemological status as associated but distinct from physical medicine. The clinical vision for such technologies must be a human one. As such, it is important that practising cliniciansnot just those with an understanding of technology -are involved in the development of the new computational tools. We believe that these tools will inevitably transform clinical practice in mental healthcare in coming years. Clinicians are, to paraphrase <ref type="bibr" target="#b0">Lenat (1975)</ref>, the 'thinking beings' most likely to ensure that this new artificial cognitive space is used safely and responsibly and in a manner that preserves the sound clinical reasoning, wisdom, and interpersonal process that we would argue is the hallmark of all good mental healthcare.</p><p>Finally, we would appeal for all users of mental health services to be involved as partners in the transformative changes yet to come. Psychological distress is still uniquely human. Most people use or love those who use mental health services, so it is in all our interests for human partnerships to be the fulcrum of this process.</p><p>Declaration of Interest: Both authors are involved in designing AI systems for potential use in clinical settings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Large language models make it possible, depending on the interface used, for clinicians to question in vivo the information presented to them. This would permit trained clinicians to ask the right questions and properly examine weak signals. Furthermore, the domain knowledge that practising clinicians have would allow them to question the absence of signals where they might otherwise be expected. Taking this a step further, the clinician can explore the relationships between the weak signals and related biopsychosocial factors as established in the literature with relative ease.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Hauser 15 , talking from the viewpoint of computational psychiatry, refer to this move towards increased process transparency as the development of 'Grey Box' models. Regulators and clinicians developing such tools may usefully develop objective measures of 'reach' using the proposed model as a general frame. The question of what is sufficient 'reach', and by what measure, into such automated clinical systems in mental healthcare, is an open one. We would suggest that all those seeking to develop new mental health clinical technologies based on LLMs should expect to be asked to demonstrate governance principles and measures across each of the domains of the framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig 1 :</head><label>1</label><figDesc>An outline proposal -the CRITiCS framework for generative AI patient safety in mental health care.This diagram presents an outline framework that could be used by practising clinicians without advanced knowledge of LLM and other AI technology, to conceptualise the interaction between the traditional cognitive space of the mental health clinician, and the new cognitive (clinical) space of the intelligent artificial agent.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Knowledge as Interacting Experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Lenat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4 th international joint conference on Artificial intelligence</title>
		<meeting>the 4 th international joint conference on Artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1975" />
			<biblScope unit="page" from="126" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<idno type="DOI">10.48550/arxiv.2303.12712</idno>
	</analytic>
	<monogr>
		<title level="j">Sparks of Artificial General Intelligence: Early experiments with GPT-4. arXiv</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">What is ChatGPT Doing … and Why Does It Work?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfram</forename><forename type="middle">S</forename></persName>
		</author>
		<ptr target="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/" />
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">DECIDE-AI: a new reporting guideline and its relevance to artificial intelligence studies in radiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vasey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ather</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcculloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin Radiol</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="130" to="166" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mental illness is like any other medical illness&quot;: a critical examination of the statement and its impact on patient care and society</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Malla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Joober</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Psychiatry Neurosci</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="147" to="50" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Developing an analytical framework to identify early warnings of serious problems with the quality and safety of care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wilson</surname></persName>
		</author>
		<ptr target="https://www.england.nhs.uk/publications/reviews-and-reports/invest-reports/" />
	</analytic>
	<monogr>
		<title level="j">NHS England. Independent investigation reports. NHS England</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="208" to="224" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Int J Health Gov</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The AI Revolution in Medicine: GPT-4 and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kohane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
			<publisher>Pearson</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Review of Multiperspective case formulation: A step towards treatment integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Winiarski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Psychother Integr</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="183" to="85" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Is cognitive case formulation science or science fiction?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Bieling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kuyken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin Psychol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="52" to="69" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Future of Intervention Science: Process-Based Therapy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="37" to="50" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clinical Reasoning: A Missing Piece for Improving Evidence-Based Assessment in Psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wilcox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Drefs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using clinical reasoning ontologies to make smarter clinical decision support systems: a systematic review and data synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">I</forename><surname>Dissanayake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Colicchio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Cimino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">High dimensional vector spaces as the architecture of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CogSci</title>
		<imprint>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The promise of a model-based psychiatry: building computational models of mental ill health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">U</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Skvortsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koutsouleris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Digital Health</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="816" to="844" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Valley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiens</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Reimagining Healthcare Teams: Leveraging the</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A governance model for the application of AI in health care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Coghlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMIA</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="491" to="97" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Artificial intelligence in behavioral and mental health care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Luxton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Elsevier/Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<ptr target="https://www.anthropic.com/news/contextual-retrieval)" />
	</analytic>
	<monogr>
		<title level="j">Anthropic. Introducing Contextual Retrieval. Anthropic</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
