<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">dockerHDDM: A user-friendly environment for Bayesian Hierarchical Drift-Diffusion Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanke</forename><surname>Pan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Nanjing Normal University</orgName>
								<address>
									<postCode>210024</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Adolescent Education and Intelligence Support Lab of Nanjing</orgName>
								<orgName type="laboratory" key="lab2">Laboratory of Philosophy and Social Sciences at Universities in Jiangsu Province</orgName>
								<orgName type="institution">Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyang</forename><surname>Geng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tianqiao and Chrissy</orgName>
								<orgName type="institution">Chen Institute for Translational Research</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution" key="instit1">Centre for Human Brain Health</orgName>
								<orgName type="institution" key="instit2">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Institute for Mental Health</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Centre for Developmental Science</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department" key="dep1">Department of Cognition, Emotion, and Methods in Psychology</orgName>
								<orgName type="department" key="dep2">Faculty of Psychology</orgName>
								<orgName type="laboratory">Social, Cognitive and Affective Neuroscience Unit</orgName>
								<orgName type="institution">University of Vienna</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fengler</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Department of Cognitive, Linguistic and Psychological Sciences</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<settlement>Providence</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Department of Cognitive, Linguistic and Psychological Sciences</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<settlement>Providence</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ru-Yuan</forename><surname>Zhang</surname></persName>
							<email>ruyuanzhang@sjtu.edu.cn</email>
							<affiliation key="aff8">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200030</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff9">
								<orgName type="department" key="dep1">School of Medicine</orgName>
								<orgName type="department" key="dep2">Michael J. Frank https://orcid.org</orgName>
								<orgName type="institution" key="instit1">Shanghai Mental Health Center</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<addrLine>Author Note Wanke Pan https://orcid.org/0000-0002-0896-6833 Hu Chuan-Peng https://orcid.org, 0000-0001-6115-807X Lei Zhang https://orcid.org/0000-0002-9586-595X Alexander Fengler https://orcid.org</addrLine>
									<postCode>200030, 0000-0002-7503-513, 0000-0002-0104-3905, 0000-0001-8451-0523, 0000-0002-0654-715X</postCode>
									<settlement>Shanghai, Haiyang Geng https://orcid.org, Ru-Yuan Zhang https://orcid.org</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Chuan-Peng</surname></persName>
							<email>hu.chuan-peng@nnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">Nanjing Normal University</orgName>
								<address>
									<postCode>210024</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">Adolescent Education and Intelligence Support Lab of Nanjing</orgName>
								<orgName type="laboratory" key="lab2">Laboratory of Philosophy and Social Sciences at Universities in Jiangsu Province</orgName>
								<orgName type="institution">Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="department">School of Psychology Nanjing Normal University (</orgName>
								<address>
									<addrLine>Suiyuan campus) #122 Ninghai Road, Gulou District</addrLine>
									<postCode>210024</postCode>
									<settlement>Nanjing, Jiangsu Province</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="department">School of Psychology and Shanghai Mental Health Center Shanghai Jiao</orgName>
								<orgName type="institution">Tong University</orgName>
								<address>
									<addrLine>1954 HuaShan RD, Xuhui District</addrLine>
									<postCode>200030</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">dockerHDDM: A user-friendly environment for Bayesian Hierarchical Drift-Diffusion Modeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1177/25152459241298700</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>HDDM, Drift diffusion models, Bayesian hierarchical modeling, Reproducibility, Docker, Python ESS, effective sample size, LOO, leave-one-out cross-validation</term>
					<term>WAIC, widely applicable information criterion</term>
					<term>PPC, posterior predictive checks</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Drift diffusion models (DDMs) are pivotal in understanding evidence accumulation processes during decision-making across psychology, behavioral economics, neuroscience, and psychiatry. Hierarchical drift diffusion models (HDDM), a Python library for hierarchical Bayesian estimation of DDMs (Wiecki et al., 2013), has been widely used among researchers, including those with limited coding proficiency, in fitting DDMs and other sequential sampling models. However, issues of compatibility in installation and lack of support for more recently Bayesian modeling functionalities poses serious challenges for new users, limiting broader adaptation and reproducibility of HDDM. To address these issues, we created dockerHDDM, a user-friend computational environment for HDDM with new features. dockerHDDM brings three improvements: (1) easy-to-install once docker is installed, ensuring reproducibility and saving time for researchers; (2) compatible with machine with apple chips; (3) seamlessly integration with ArviZ, a state-of-the-art Bayesian modeling library. This tutorial serves as a practical, hands-on guide for researchers to leverage dockerHDDM&apos;s capabilities in conducting efficient Bayesian hierarchical analysis of DDMs. The notebook presented here and within the docker image will enable researchers with various programming levels to model their data with HDDM.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Log pointwise predictive density, ∑</head><p>(</p><formula xml:id="formula_0">1 ∑ ( | ) =1 ) =1</formula><p>, likelihood of each observed data point conditional on the model parameters . In practice, this quantity is estimated using samples (for = 1,2,3, … , ) drawn from the posterior distribution.</p><p>The drift-diffusion model (DDM) is one of the most widely used computational models (for an overview, see <ref type="bibr" target="#b83">Ratcliff et al., 2016)</ref> to quantify the evidence accumulation processes during decision-making in neuroscience <ref type="bibr" target="#b15">(Cavanagh et al., 2011;</ref><ref type="bibr" target="#b42">Herz et al., 2017;</ref><ref type="bibr" target="#b88">Shadlen &amp; Shohamy, 2016)</ref>, psychology <ref type="bibr" target="#b44">(Hu et al., 2020;</ref><ref type="bibr" target="#b46">D. J. Johnson et al., 2017;</ref><ref type="bibr" target="#b58">Kutlikova et al., 2023)</ref>, behavioral economics <ref type="bibr" target="#b18">(Desai &amp; Krajbich, 2022;</ref><ref type="bibr" target="#b89">Sheng et al., 2020)</ref>, and psychiatry <ref type="bibr" target="#b38">(Ging-Jehli et al., 2021;</ref><ref type="bibr" target="#b29">Pedersen et al., 2022)</ref>. According to the DDM, experimentally observed pairs of response times and choices arise from a process of stochastic evidence accumulation to a decision boundary (e.g., <ref type="bibr" target="#b105">Voss et al., 2013</ref>; <ref type="figure">Figure 1</ref> and the related DDM glossary <ref type="table">Table 1</ref>). This theoretical framework has been shown not only to correlate robustly with established neural substrates <ref type="bibr" target="#b17">(Chandrasekaran et al., 2017;</ref><ref type="bibr" target="#b31">Forstmann et al., 2016)</ref>, but also to serve as a powerful measurement tool for examining individual differences across cognitive tasks, experimental manipulations, and participant populations <ref type="bibr" target="#b5">(Boag et al., 2024;</ref><ref type="bibr" target="#b21">Donkin &amp; Brown, 2018;</ref><ref type="bibr" target="#b25">Evans &amp; Wagenmakers, 2020</ref>; but see <ref type="bibr" target="#b64">Liu et al., 2023)</ref>. Despite its theoretical contributions, the DDM is difficult to apply to experimental data in practice, because the derivation of inference-relevant quantities (e.g., the likelihood , a measure of outof-sample predictive performance for new data ̃ generated by the true data-generating process.</p><p>(̃) is the predictive density for ̃ based on the posterior distribution, f is the true underlying model, and denotes the expectation that averages over the true data-generating distribution <ref type="bibr" target="#b34">(Gelman et al., 2014)</ref>. ELPPD is commonly used to compare the predictive performance of different models, as it provides an estimate of how well a model is expected to perform on new data.</p><p>Highest density interval (HDI), an estimate of a parameter's credible range in the context of Bayesian statistics. It encompasses an interval of the posterior distribution where each point within this interval has a higher density than points outside of it. For instance, a 95% HDI means that there is a 95% chance that the true parameter value falls within this range, making it a reliable indicator of parameter uncertainty. HDIs are commonly used for hypothesis testing regarding effect sizes, as well as comparisons across different conditions or groups.</p><p>A region of practical equivalence (ROPE), a predefined range of parameter values that are considered practically equivalent to zero, which could be based on existing literature or theoretical reasoning <ref type="bibr" target="#b54">(Kruschke, 2018</ref><ref type="bibr" target="#b56">(Kruschke, , 2021</ref>. To determine whether a parameter estimate is significantly different from zero, a ROPE might be set as a range around zero. If the 95% HDI of the parameter lies entirely outside this ROPE, the parameter is considered credibly different from zero. If the HDI is entirely within the ROPE, the parameter is effectively zero for practical purposes. Partial overlap suggests that the parameter's result should be interpreted with caution. Note that caution should be taken when using the HDI + ROPE method for statistical inference on transformed parameters, because of an inconsistency in transformation properties between ROPE and HDI <ref type="bibr" target="#b22">(Etz et al., 2024)</ref>.</p><p>Bayes Factor (BF) and Savage-Dickey Density Ratio (SDDR). BF quantifies the strength of evidence for one statistical model over another. A value greater than 1 suggests more support for the alternative model relative to the original model, offering a continuous measure of evidence <ref type="bibr" target="#b48">(Kass &amp; Raftery, 1995)</ref>. The SDDR simplifies Bayes Factor computation for nested models by comparing a parameter's posterior density at a specific point (typically zero) to its prior density at the same point. This method is efficient and effective for evaluating whether a parameter is significantly different from zero <ref type="bibr" target="#b108">(Wagenmakers et al., 2010)</ref>. function) requires a mathematical understanding of the complex stochastic process of evidence accumulation. <ref type="figure">Figure 1</ref>. Illustration of the evidence accumulation process assumed by DDM. DDM has four basic parameters: drift rate ( ), decision boundary ( ), initial bias ( ), and non-decision time ( ). The drift rate ( ) is the average speed of evidence accumulation toward a decision; the decision boundary ( ) is the distance between two decision thresholds, and the evidence needed to make a decision increase as increases; the initial bias ( ) reflects the starting point of evidence accumulation. non-decision time ( ) is the time not used for evidence accumulation, e.g., stimulus encoding or motor execution. A more detailed description of the DDM and its parameters is given in <ref type="table">Table 1.</ref> Several software packages have been developed to facilitate the application of DDM (see Section 5.1), proving particularly beneficial for researchers with limited computational expertise.</p><p>Among them, HDDM, a Python library for hierarchical drift diffusion modeling, is by far the most cited toolbox in the community <ref type="bibr" target="#b113">(Wiecki et al., 2013</ref>, with 996 citations in Google Scholar, accessed 26 August 2024). Despite the success and popularity of HDDM, it suffers from several practical issues. First, the installation process of HDDM is cumbersome, exacerbated by its reliance on PyMC 2.3.8 for Markov Chain Monte Carlo (MCMC) sampling, a package that is no longer supported and may clash with latest computer modules. Second, and for the same reason, out of the box HDDM is not compatible with apple chips, which creates a significant barrier for Mac users. Third, although HDDM natively centers around Bayesian methods, it does not conveniently support all aspects of the evolved standards in Bayesian modeling workflows <ref type="bibr" target="#b0">(Ahn et al., 2017;</ref><ref type="bibr" target="#b37">Gelman et al., 2020;</ref><ref type="bibr" target="#b56">Kruschke, 2021)</ref>. Significant progress has recently been made in supporting the principled Bayesian modeling workflow in easy-to-use toolkits, such as the Python package ArviZ <ref type="bibr" target="#b57">(Kumar et al., 2019)</ref>. Bridging these new capabilities with HDDM facilitates a one-stop Bayesian modeling pipeline for experimentalists and computational modelers interested in applying the DDM to their experimental data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1 DDM Glossary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Term Description</head><p>Accumulator A component of the DDM that accumulates evidence for different decision options until a threshold is reached, triggering a decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random walk</head><p>A stochastic process that describes a path consisting of a sequence of random steps. It refers to the modeling of decision-making as a process of accumulating evidence over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diffusion</head><p>The diffusion refers to the variability in the evidence accumulation process that represents random fluctuations in the decision variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optional stopping</head><p>The concept of stopping the decision-making process at a point chosen by the decision-maker, often when a certain level of confidence or evidence threshold is reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drift rate ( )</head><p>The average rate of evidence accumulation towards one of the decision boundaries. The more difficult the task, the less stimulus discrimination and the smaller the drift rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision boundary ( )</head><p>The threshold that, when reached by the accumulated evidence, triggers a decision. It represents the speed-accuracy trade-off or caution, and the higher its value, the higher the accuracy at the expense of slower response time.</p><p>Non-decision time ( ) The time taken by processes other than decision-making (e.g., sensory encoding and motor execution). It simply shifts response time distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial bias ( )</head><p>The initial value of the decision variable, which indicates any initial bias in evidence accumulation, is also called 'starting point' in the literature. The closer it is to a boundary (1 and 0 correspond to the upper and lower boundaries, respectively), the faster and more frequent the response.</p><p>Drift Rate variability ( ) The variability in the drift rate parameter across trials. It increases the proportion of slow errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial bias variability ( )</head><p>The across-trial variability in the starting point parameter in the DDM. It increases the proportion of fast errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-decision time variability ( )</head><p>The across trial variability in the non-decision time parameter in the DDM. It simultaneously increases the probability of both faster and slower responses, resulting in a thicker tail of the RT distribution.</p><p>Note: The terms used here are defined within the framework of the sequential sampling model <ref type="bibr" target="#b31">(Forstmann et al., 2016;</ref><ref type="bibr" target="#b83">Ratcliff et al., 2016)</ref>, and some of them, such as diffusion and optional stopping, differ from those used in the mathematical literature. RT = reaction/response time.</p><p>To address the above issues, we leveraged the Docker container technology to create dockerHDDM, a stable and complete virtualized Python computing environment that enables out-of-the-box implementations of Bayesian hierarchical drift-diffusion models. dockerHDDM has three major advantages <ref type="table" target="#tab_0">(Table 2)</ref>. First, it benefits from the easy-to-deploy nature of the Docker environment to avoid compatibility issues. Second, it is compatible with both Intel or Apple chips.</p><p>Third, it augments HDDM with ArviZ, a Python module that enables a wide range of advanced Bayesian modeling analyses. We expect dockerHDDM to provide an easy-to-use environment to help researchers across various backgrounds efficiently use DDM in their research.  <ref type="bibr">Plotting (e.g., HDI,)</ref> No Yes <ref type="bibr">Diagnosis (e.g., ESS)</ref> No Yes</p><p>Model Comparison <ref type="bibr">(LOO, WAIC)</ref> No Yes</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Installation</head><p>Hard Easy</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parallel processing Hard Easy</head><p>Compatibility with Apple chips Hard Easy</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">How to Follow This Tutorial</head><p>The primary goal of this paper is to present a practical guide to dockerHDDM for beginners with little modeling experience. The tutorial starts with step-by-step instructions on how to configure the dockerHDDM environment and how to use it in practical data analysis ( <ref type="figure">Figure 2</ref>). To assist reproducibility and easy application, a corresponding step-by-step video walk-through is available on YouTube at https://www.youtube.com/watch?v=ZU1fbXEuP8s or on OSF at https://osf.io/ 3upng/files/osfstorage/66d5c2a3f2abc7a7a359a26c/.</p><p>In the setup section (top panel in <ref type="figure">Figure 2</ref>, corresponding to Section 2.1 in this paper), we provide instructions on how to install Docker. After that, we demonstrate how to obtain the dockerHDDM image and how to use this image to access the Jupyter notebook interface (middle   After installing Docker Desktop (or Docker Engine for Linux users), one can verify the installation by running the following command in a terminal <ref type="figure">(Figure 3</ref>). If the container starts and runs successfully, it will display a confirmation message and then exit ( <ref type="figure">Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Box 2. Basic Introduction to Docker</head><p>Docker is an open source platform that automates the deployment, scaling and management of applications. It achieves this through containerization, a process that packages an application and its dependencies into a single, portable, and consistent unit known as a container image. Containers ensure that applications run reliably regardless of the environment <ref type="bibr" target="#b78">(Peikert &amp; Brandmaier, 2021;</ref><ref type="bibr" target="#b112">Wiebels &amp; Moreau, 2021)</ref>. Docker utilizes a client-server architecture where the Docker client communicates with the Docker daemon, responsible for building, running, and distributing containers. The core components of Docker are the Docker Engine, Docker Hub, and Docker Compose. The Docker Engine is the runtime that enables containerization, while Docker Hub is a cloud-based registry for sharing and managing container images. Docker Compose, on the other hand, is a tool for defining and running multi-container Docker applications. $ docker run hello-world <ref type="figure">Figure 3</ref>. Command to check Docker installation in Terminal. After running the command `docker run hello-world` (highlighted at first line), the printout tells us that Docker has been successfully installed on the system. The schematic interfaces of the Terminal on different platforms: MacOS (left), Windows (middle), and Ubuntu (right).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Pull dockerHDDM Image</head><p>After ensuring that Docker has been successfully installed and the Docker engine is running <ref type="figure">(Figure 3</ref>), you can pull the dockerHDDM image by simply running the command in the terminal (see the meaning of each argument in <ref type="figure" target="#fig_3">Figure 4A</ref>): $ docker pull hcp4715/hddm or $ docker pull hcp4715/hddm:latest This command will pull the latest default version of dockerHDDM, which corresponds to the image with the tag `1.0.1`. One can also select different tags for different versions of HDDM (see https://hub.docker.com/r/hcp4715/hddm/tags). Note that the tutorial in this paper works with the `latest` or `1.0.1` tags, it is compatible with 0.8.0, with minor grammar changes. . Docker commands to download and run dockerHDDM. (A) Download/pull dockerHDDM from the Docker hub. The command by default downloads the latest version of `hcp4715/dockerHDDM` if the image tag is not specified. The CPU architecture (Apple or Intel chips, corresponding to ARM64 and AMD64 architectures, respectively) is automatically recognized when the image is downloaded. (B) Command to start a container. Note, "\" separates different lines of a command in Linux and MacOS Terminal but not in Windows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Run dockerHDDM Container</head><p>After pulling the Docker image to a local machine, you can start a computing environment by running the dockerHDDM image with the command in the terminal ( <ref type="figure" target="#fig_3">Figure 4B</ref>): $ docker run -v $(pwd):/home/jovyan/work -p 8888:8888 -it --rm hcp4715/hddm jupyter notebook This command creates a Docker container, which is a specialized environment encapsulated within the Docker platform. The `-v` option is used to mount a local folder into the container's filesystem, enabling file exchange from the host machine. The example code `$(pwd):/home/jovyan/work` specifies two paths separated by a colon. The path on the left, denoted by `$(pwd)`, represents the current working directory on the host machine; and the path on the right, `/home/jovyan/work`1, is the location inside the container where the folder will be mounted ( <ref type="figure" target="#fig_3">Figure 4B</ref>). This means that you can read and write the files from your local machine in the "work" directory in the browser. `$(pwd)` can be replaced with a valid folder path on your local machine. For example, for a folder named "ddm_project" on the drive D, it can be mounted with the following arguments in the respective operating systems:</p><formula xml:id="formula_1">in Linux, `-v /mnt/d/ddm_project:/home/jovyan/work`; in Windows `-v D:\ddm_project:/home /jovyan/work`; and in MacOS `-v /Volumes/D/ddm_project:/home/jovyan/work`.</formula><p>The other arguments in the command are explained in <ref type="figure" target="#fig_3">Figure 4B</ref>.</p><p>After running the `docker run …` command, a URL appears at the end of the terminal output (middle panel in <ref type="figure">Figure 2</ref>). You can copy and paste this URL "http://127.0.0.1:8888/?token=..." into any web browser (such as Firefox or Chrome) to launch a Jupyter interface based on the dockerHDDM container. If the URL does not load properly, check whether port 8888 is being used by other docker containers or programs. If so, close those containers or programs. Alternatively, you may change the port, e.g. use port 7777, i.e. set `-p 7777:8888`, in this case, you should replace the "8888" in the URL to "7777", e.g., "http://127.0.0.1:7777/?token=...". You can then open or initialize a Jupyter notebook 2 to code, run and view the output directly. It is worth noting that the `--rm` flag included in the command means that the dockerHDDM container, along with any data or newly installed Python modules, will be deleted when the container stops. However, any files or data mounted to the container from the `$(pwd)` path will remain unaffected. This ensures the reproducibility of the computing environment. If you wish to modify the computing environment, for example by installing additional Python modules, we recommend that you first read the Docker API before removing `--rm` directly.</p><p>In the Jupyter interface, you will find two files and two folders (middle panel in <ref type="figure">Figure 2</ref>).</p><p>The notebook dockerHDDM_workflow.ipynb offers a detailed reproduction of the analyses presented in this article, which we will discuss further in Section 4. In contrast, the notebook dockerHDDM_Quick_View.ipynb provides a brief overview of the dockerHDDM image's new features and an introduction to basic modeling processes. One folder is "work", which mounts the local path into the docker environment. The other folder, "OfficialTutorials" contains notebooks that reproduce the official tutorials available at https://hddm.readthedocs.io/en/latest/tutorials.html. LAN_Tutorial.ipynb introduces advanced use of LAN functions that address the problematic likelihood of more complicated models based on neural network methods <ref type="bibr" target="#b30">(Fengler et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Novel Features of dockerHDDM</head><p>The dockerHDDM_Quick_View.ipynb illustrates two novel features in dockerHDDM (compared to HDDM installed directly without Docker): parallel computing for MCMC chains and creating InferenceData data for ArivZ analyses (as shown in the &lt;Code Block 1&gt;). For all models defined by methods such as `hddm.HDDM()` or `hddm.HDDMRegressor()`, we can employ the `.sample()`, method to run the MCMC algorithm for model fitting. The original HDDM provided two main parameters to set the MCMC algorithm, the first parameter was the number of samples (`500`) and the second was the number of burn-ins (`burn=100`) 3 .</p><p>In dockerHDDM, we included five extra arguments in `.sample()` method to provide parallel computing for MCMC chains and create InferenceData.</p><p>To preserve compatibility and consistent output with origin HDDM, the arguments are configured with the following defaults: `return_infdata=False`, `sample_prior= False`, `loglike=False`, and `ppc=False`, `save_name=None`, and `chains=1`.</p><p>The `chains` argument determines the number of MCMC chains. Using more than two chains triggers multi-threaded parallel computation, which can significantly reduce the time when multiple chains are needed to compute model diagnosis index ̂ (see Section 4.4). The number of parallel MCMC chains is limited by the number of available CPU cores/threads available. For example, the maximum number of chains for a computer with 4 cores (8 threads) is 8. Setting the "chains" argument more than 8 may degrade performance. Nonetheless, whenever possible, a number of 4 chains is commonly used.</p><p>The `return_infdata` argument converts HDDM results into the InferenceData structure 4 , accessible via `model.infdata`, by default set to `False` to maintain compatibility with original HDDM output. Additionally, we have included `loglike` for computing and saving log-likelihood values (see Section 4.5); `ppc` for posterior predictive checks (see Section 4.6); and `sample_prior=True` for calculating Savage-Dickey Density Ratio <ref type="bibr" target="#b108">(Wagenmakers et al., 2010)</ref> to approximate the Bayes Factor (see Section 4.7). When setting `ppc` as `True`, it defaults to generating 500 predictions for each observed data, but users can adjust this by adding argument `n_ppc`. Similarly, when setting `sample_prior` as `True`, it defaults to sampling 2000 draws for each prior parameter, but users can adjust this by adding argument `n_prior`.</p><p>Finally, the `save_name` argument specify the path and filename for saving the model and InferenceData, which is convenient for reusing results. One can load the model using `model = hddm.load('example.hddm')` and the InferenceData with `infdata = az.from_netcdf('example.nc')`.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Example of Workflow</head><p>In this section (bottom panel of <ref type="figure">Figure 2</ref>), we demonstrate how to use dockerHDDM (i.e., HDDM and ArviZ) to perform key steps of Bayesian modeling <ref type="bibr" target="#b37">(Gelman et al., 2020;</ref><ref type="bibr" target="#b67">Martin et al., 2024)</ref>:  "subj_idx is" the subject index; "rt" is the response time (in seconds), and "response" in this case represents the accuracy, where 1 is correct and 0 is incorrect. These three columns of data are mandatory when using HDDM and must be kept consistent with the column names, as well as the units <ref type="bibr">(rt, seconds)</ref>. "conf" is an optional variable, corresponding to the conflict level, where "HC" denotes high conflict and "LC" denotes low conflict. "conf" is not a mandatory variable or column, meaning that different factor names and levels can be used depending on the experimental design. In addition, multiple variables may be maintained in the data, which may be categorical or continuous.</p><formula xml:id="formula_2">model</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Example data</head><p>For convenience, we use the data from <ref type="bibr" target="#b15">Cavanagh et al. (2011)</ref>, which is built within HDDM, as an example to demonstrate how to implement the modeling workflow. This dataset contains response time and choice data from 14 Parkinson's patients (see <ref type="table" target="#tab_4">Table 3</ref>). In the experiment, participants were asked to choose between two options associated with either high or low reward values (i.e., reward probabilities in typical reinforcement learning tasks). The relative value differences between the two options define two levels conflict: high conflict for low-low and high-high trials ("HC" in variable "conf"), and low conflict for low-high trials ("LC" in variable "conf").</p><p>Note that, HDDM requires the inclusion of three columns of variables, "subj_idx", "rt" and "response", to construct the hierarchical model. This means that when analyzing your own data, these three columns of variables must appear in the dataset with identical column names. In addition, the unit of "rt" must be seconds, and "response" is coded as 1 for the upper boundary of the corresponding choice and 0 for the lower boundary (see https://hddm.readthedocs.io/en/ latest/howto.html for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Box 3. Parameters in hierarchical drift-diffusion models</head><p>HDDM employs hierarchical Bayesian modeling by default, where each participant's free parameters are sampled from population-level distributions <ref type="bibr" target="#b113">(Wiecki et al., 2013)</ref>. Taking full DDM (Model 0) as an example, non-decision time is assumed to be drawn from a normal distribution: ~( , ), where and are the mean and standard deviation of the population-level normal distribution of non-decision time t. Similarly, / / and / / are the means and standard deviations for the other three parameters, respectively. In addition, three free parameters / / indicate the trial-by-trial variability of non-decision time ( ), drift rate ( ), and initial bias ( ), which are estimated only at the population level.</p><p>Consequently, there are a total of 11 population-level parameters. At the subject level, each subject has her own estimate of the parameter of a, v, t, z, leading to a total of 4 * subject -level parameters. Thus, in the full DDM, the number of parameters is 11 plus 4 * .</p><p>The hierarchical structure of the full DDM in HDDM. The parameters inside and outside the rectangle are subject and population level parameters, respectively. / are the indices of participants ( = 1, 2, . . . , ) and trials ( = 1, 2, … . ), where , is the data (choice/response time) of the i-th trial in the p-th subject. HDDM provides two types of priors: weakly informative priors and non-informative priors. By defa ult, dockerHDDM uses weakly informative priors as summarized in the Table below <ref type="bibr" target="#b113">(Wiecki et al., 2013)</ref>. T he default informative priors are suitable for most perceptual tasks. However, for tasks with longer response times, it is recommended to use non-informative priors. In this case, one has to set the parameter `informa tive=False` when defining the model, e.g., `m = hddm.HDDM(data, informative=False)`.</p><p>DDM parameters' informative prior</p><formula xml:id="formula_3">~(2,3) ~ℋ (2) ~( , 2 ) ~(1.5,0.75) ~ℋ (2) ~( , 2 ) ~( (0.5,0.5)) ~ℋ (0.05) ~( , 2 ) ~(0.4,0.2) ~ℋ (1) ~( , 2 ) ~ℋ (2) ~ℋ (0.3) ~ℬ(1,3)</formula><p>Note, table extracted and refined from <ref type="bibr" target="#b113">(Wiecki et al., 2013)</ref>. represents a Normal distribution parameterized by the mean ( ) and standard deviation ( ). ℋ represents a Half-Normal distribution, which is a positive-only distribution parameterized by the standard deviation. represents a Gamma distribution, parameterized by the mean ( ) and the rate ( ). ℬ represents a Beta distribution, parameterized by alpha and beta. The term represents the inverse logit function also known as the logistic function.</p><p>HDDM also allows parameters to vary with variables by integrating hierarchical linear regression models (also called linear mixed models or multi-level models). Specifically, the `hddm.HDDMRegressor()` function allows any or all of the four parameters of DDM <ref type="bibr">(a, v, t, z)</ref> to be modelled as a function of experimental conditions or other variables (e.g., EEG signal). In HDDM, the regression models are defined using the Python package patsy (see https://patsy.readthedocs.io/en/latest/quickstart.html), which uses the same syntax for defining regression functions as in other commonly used statistical packages. For example, in Model 2 in the main text, we used the expression ` ~ 1 + C conf Tre men 'LC' `, where the term to the left of "~" is the dependent variable and the term to the right of "~" is the regression equation. The term '1' refers to the intercept, which corresponds to the variable _ in the output. The term 'C(conf, Treatment('LC'))' indicates the slope coefficient, which corresponds to the variable _ ( , (' ')) <ref type="bibr">[ . ]</ref> . As in other hierarchical regression models, both the intercept and the slope can be estimated at the population level and the subject level (referred to as "fixed effects" and "random effects" or "varying effects" respectively, D. J. <ref type="bibr" target="#b46">Johnson et al., 2017;</ref><ref type="bibr" target="#b74">Pedersen &amp; Frank, 2020;</ref><ref type="bibr" target="#b113">Wiecki et al., 2013)</ref>, depending on how the model is specified. In `hddm.HDDMRegressor()`, the default is hierarchical model with random intercept but no random slope. We need to set `group_only_regressors=False` to include the random slope (as we did int Model 2).</p><p>Although both the `depends_on` argument and the `HDDMRegressor` function allow parameters to vary with discrete variables (e.g., conflict levels), there is an important difference between them. The `depends_on` argument defines the parameter split by condition. Specifically, the means of the parameters under each condition are derived from a share prior, whereas the variability of the parameters is consistent across conditions. The `HDDMRegressor` function defines the relation between parameters and condition by a linear model specification, which mean the intercept and slope in the linear regression both has their own priors. In a word, `depends_on` is unable to utilize within-subject effects because each subject's condition is derived from the population prior, whereas `HDDMRegressor` allows each subject to have their own intercept, which allows for the estimation of within-subject variation across conditions. Thus, the choice of model definition is relevant to the assumptions made about the relationship between parameters and the experimental conditions. See <ref type="bibr" target="#b113">Wiecki et al. (2013)</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model Specification</head><p>As a demonstration of model specification, we will test an example question: is there an effect of conflict levels on drift rate <ref type="bibr" target="#b113">(Wiecki et al., 2013</ref>). To answer the question, we constructed three computational models (see <ref type="table">Table 4</ref>). <ref type="table">Table 4</ref>. Models used in this tutorial.</p><p>Note: `hddm.HDDM()` is the default function for constructing a hierarchical drift diffusion model. The `include` argument allows the addition of free parameters, which are fixed by default. The `depends_on` argument specifies a parameter (e.g., v) that depends on a categorical independent variable (e.g., 'conf'). The `hddm.HDDMRegressor()` is a HDDM function that includes effects of conditions in a linear regression fashion. The `keep_regressor_trace` argument allows a trace of the regressor to be kept, which is needed for posterior predictive checks. By default, the hierarchical regression allows only the intercept to vary across participants, while the slope is fixed at the population level. The `group_only_regressors = FALSE` argument additionally estimates the slopes at the individual level in the regression model. 11 + = 67 free parameters.</p><p>Model 1 allows the drift rate to vary as a function of the conflict levels (i.e.,</p><p>`depend _on {' ': 'conf'}` in HDDM). Specifically, Model 1 sets two drift rate variables each for low and high conflict levels at the both population-and individual-level, respectively.</p><p>Thus, Model 1 has 12 population-level parameters: the mean and standard deviation for , , and ; two means ("v_(LC)" and "v_(HC)") and one standard deviation for ; and three inter-trial variability parameters ( / / ). Similarly, at the individual level, there are 5 ( / / / / ) x 14 (subjects) = 70 individual-level parameters. Thus, Model 1 has a total of 82 free parameters.</p><p>Note that Model 1 assumes complete independence between high and low levels of conflict within subjects. This assumption may be inappropriate, as it is likely that a person who responded relatively quickly in the "LC" condition will also respond relatively quickly in the "HC" condition, and vice versa. See Box 3 for more detailed differences between Model 1 and Model 2.</p><p>Model 2 was constructed to include correlations between drift rates across conflicting levels. In Model 2, we use a hierarchical regression model with `hddm.HDDMRegressor()` by using the formula ` ~ 1 + C conf Tre men 'LC' ` (see Box 3). This formulation automatically assigns two free parameters, the intercept and slope, to each subject. Thus, there are 5 * 14 = 70 individual-level parameters in Model 2. Accordingly, Model 2 has four parameters for v: "v_Intercept" and "v_Intercept_std" are the mean and standard deviation of the intercept;</p><p>"v_C(conf)[T.HC]" and "v_C(conf)[T.HC]_std" are the mean and standard deviation of the slope.</p><p>Therefore, Model 2 has 13 population-level parameters: the mean and standard deviation for , , and ; the mean and standard deviation of the slope and the intercept of the regression for ; and three inter-trial variability parameters ( / / ). Taken together, Model 2 has a total of 13 + 70 = 83 free parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Model Fitting</head><p>The defined HDDM model allows the MCMC algorithm to be run using the `.sample()` To accurately estimate parameters and ensure convergence in hierarchical modeling, we set up four MCMC chains of 10,000 samples with 5,000 burn-ins (i.e., a total of 20,000 samples for each parameter). Please refer to Section 3 for the more detailed settings and arguments description.</p><p>With the new functionality introduced by dockerHDDM, we can calculate the loglikelihood of the model and generate posterior predictions after model fitting. Furthermore, the output of the model fitting can be converted into InferenceData, `m2_infdata`, for subsequent analyses as described in Section 3. We emphasize that model fitting is demanding in terms of computational resources and memory. For example, in our tests with the Apple M1 chip, Intel i7-10700 CPU and AMD Ryzen 9-5900HX, model fitting took around 2-3 hours for 10,000 samples. Consequently, fitting three models took about 6-9 hours, with memory usage ranging between 8-12 GB. Additionally, if pointwise likelihood calculations (i.e., with the argument `loglike=True`) and posterior predictive data generation (i.e., with the argument `ppc=True`) are enabled, an extra 1-3 hours are needed for each model. More importantly, the memory consumption could escalate to 20-30 GB because pointwise likelihood and posterior predictive data generation will result in a large number of new data. See discussion for recommendations to improve efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Model Diagnosis</head><p>In Bayesian inference, it is crucial to ensure the convergence of MCMC chains. With ArivZ, dockerHDDM supports both visual inspection and quantitative convergence checks (see Chapter 10 in <ref type="bibr" target="#b67">Martin et al., 2024)</ref>. <ref type="figure">Figure 5</ref>. Model diagnosis. (A) Visualization of the traces of all chains using `az.plot_trace()`, with the argument `var_names` set to focus on the parameter "v_Intercept" as an example. `compact=False` and `legend=True` ensured that the individual traces of each chain would be visible. The MCMC chains are valid and reliable when they fluctuate around a value and different chains are indistinguishable from each other, a scenario often referred to as a "caterpillar" shape. (B) Output of `az.summary()`, which includes the mean and standard deviation of the Monte Carlo standard error (MCSE), the effective sample sizes (bulk-ESS and tail-ESS), and ̂. Note that the summary data frame has been sorted by ̂ so that we can easily compare the minimum and maximum values of ̂. `az.plot_trace()` can be used to visualize the posterior distributions of parameters (i.e., trace plots of the MCMC, <ref type="figure">Figure 5A</ref>).</p><p>The Gelman-Rubin statistics (̂), and effective sample size (ESS) provide quantitative measures (see Box 1).</p><p>`az.rhat()`computes ̂, which should be close to 1 for good convergence; values below 1.01 are typically recommended <ref type="bibr" target="#b36">(Gelman &amp; Rubin, 1992)</ref>.</p><p>`az.ess()` calculates ESS, a measure of the precision of posterior estimates. If the ESSbulk is over 400 (see Box 1), the distribution's center is well-resolved, and we should ensure high ESS across all regions of the parameter space <ref type="bibr" target="#b67">(Martin et al., 2024;</ref><ref type="bibr" target="#b104">Vehtari et al., 2021)</ref>.</p><p>The latter two methods are covered by ArviZ's `az.summary()` <ref type="figure">(Figure 5B</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Model Comparison</head><p>Upon verifying chain convergence, we proceed with model comparison to identify the best-fitting model. The evaluation metric provided in the original HDDM is deviance information criterion <ref type="bibr">(DIC, Spiegelhalter et al., 2002)</ref>. We include two more methods in dockerHDDM: widely applicable information criterion (WAIC, <ref type="bibr" target="#b111">Watanabe, 2010)</ref> and Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO-CV, <ref type="bibr" target="#b102">Vehtari et al., 2017)</ref>. These methods comprehensively integrate posterior samples for model comparison and evaluation (see Box 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Box 4. Linking DIC, WAIC, and PSIS-LOO-CV to AIC</head><p>The Deviance Information Criterion (DIC), Widely Applicable Information Criterion (WAIC), and Pareto-Smoothed Importance Sampling Leave-One-Out Cross-Validation (PSIS-LOO-CV) are criteria founded on the concept of out-of-sample predictive accuracy, i.e., the accuracy of using the fitted model to predict new data generated by the assumed data-generating process. Predictive accuracy is often encapsulated by the log predictive density (Box 1). However, the log predictive density approximated using the observed data and the posterior estimates of parameters is biased, and an adjustment is required to correct the bias. Thus, the key difference between DIC, WAIC and PSIS-LOO-CV lies in the difference between the two terms of log predicted density and corrected bias (see the table below).</p><p>DIC uses the Bayesian posterior means for estimating log predictive density and includes an adjustment based on the effective number of parameters ( ). It is particularly suited for hierarchical models, offering an improved estimate of predictive density <ref type="bibr" target="#b95">(Spiegelhalter et al., 2002)</ref>.</p><p>WAIC further refines DIC, evaluating the log predictive density across the entire posterior and correcting bias via the variability of log predictive density (̂). This adjustment is crucial for measuring model robustness and guarding against overfitting <ref type="bibr" target="#b111">(Watanabe, 2010)</ref>. Both DIC and WAIC rely on estimating the effective number of parameters, but DIC assumes a Gaussian distribution for the likelihood, which simplifies the calculation <ref type="bibr" target="#b65">(Lunn et al., 2012)</ref>. In contrast, WAIC does not rely on this strict assumption and uses the full posterior distribution, offering greater flexibility and accuracy but at a higher computational complexity <ref type="bibr" target="#b34">(Gelman et al., 2014)</ref>.</p><p>For the demonstration, we compared three models across all three evaluation metrics (lower value is better) . As shown in <ref type="table" target="#tab_6">Table 5</ref>, Model 2 exhibits the lowest values on all three metrics, indicating it is the best model. The results of model comparison revealed that Models 1 and 2 are much better than the baseline Model 0, suggesting that experimental conflict conditions have a substantial effect on drift rates. Moreover, Models 2 is slightly better than Model 1, suggesting that regression model may suit the data better. Nevertheless, the similarities between Model 1 and Model 2 suggests that both models fit the data adequately in this case. PSIS-LOO-CV estimates the predictive density by simulating the leave-one-out cross-validation, which by definition is the out-of-sample predictive accuracy, so bias correction is no longer needed for PSIS-LOO-CV. Please see <ref type="bibr" target="#b34">Gelman, Hwang, &amp; Vehtari (2014)</ref> and <ref type="bibr" target="#b102">Vehtari, Gelman, &amp; Gabry (2017)</ref> for more details on these three indices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predictive accuracy Adjustment</head><p>Formula  <ref type="bibr" target="#b95">(Spiegelhalter et al., 2002)</ref>. ̂ is the WAIC's approach to adjusting the effective number of parameters <ref type="bibr" target="#b111">(Watanabe, 2010)</ref>.</p><formula xml:id="formula_4">AIC ( | ̂) k −2 ( ( | ̂) − ) DIC ( | ̂) −2 ( ( | ̂) − ) WAIC ̂ ̂ −2 (̂ − ̂) PSIS-LOO-CV ̂− N.A. −</formula><p>posterior trace (see Box 1). This variable is not directly provided in the HDDM object and must be customized to be calculated via the likelihood function and posterior trace.</p><p>In dockerHDDM, the pointwise log-likelihood can be computed at sampling and fitting stage, via `m.sample(... , retutn_infdata = True, loglike = True)` (see &lt;Code Block 2&gt;), or after the model has been sampled and fitted, by `m.to_infdata(loglike = True)`. Both ways return InferenceData, allowing users to immediately compute WAIC and PSIS-LOO-CV. After that, the evaluation metrics for each model's InferenceData are available using ArviZ's `compare` method (see &lt;Code Block 3&gt;), which returns the results of WAIC for the argument `ic="w c"` or PSIS-LOO-CV for `ic=" oo"`.</p><p>&lt;Code Block 3&gt;</p><p>```Python compare_dict = { 'm0': m0_infdata, 'm1': m1_infdata, 'm2': m2_infdata } az.compare(compare_dict, ic = 'loo') ``` inally, it's important to note that the model comparison metrics only allow us a relative ranking of alternatives. To assess the absolute goodness-of-fit of the model, we recommend performing the posterior predictive check (PPC), as discussed in the next section, alongside the diagnostic information provided by LOO and WAIC (see Chapter 5 in <ref type="bibr" target="#b67">Martin et al., 2024;</ref><ref type="bibr" target="#b102">Vehtari et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Posterior Predictive Check</head><p>In addition to model comparison, which assesses relative performance, the posterior predictive check (PPC) evaluates how well predictive data generated from posterior samples of parameters align with the actual data. PPC is crucial because model comparison only evaluates the "least worst" model, but this model may not necessarily account for the data very well (see Chapter 5 in <ref type="bibr" target="#b67">Martin et al., 2024)</ref>.</p><p>ArviZ offers convenient visualization tools for inspecting PPC <ref type="bibr" target="#b57">(Kumar et al., 2019)</ref>. The function `az.plot_ppc()` is helpful to visualize PPC at the individual or condition level ( <ref type="figure">Figure 6</ref>). In the demonstration, the synthetic data from Model 2 match more closely the actual data compared to the baseline Model 0, and this difference becomes apparent when examining PPC at the individual-( <ref type="figure">Figure 6A</ref>) and condition-level ( <ref type="figure">Figure 6B</ref>). Other approaches for PPCs can be used to quantify accordance between data and model across quantiles of the RT distribution, for example using Bayesian predictive versions of quantile probability plots <ref type="bibr" target="#b32">(Frank et al., 2015;</ref><ref type="bibr" target="#b38">Ging-Jehli et al., 2021)</ref>, and example code in HDDM is available upon request. <ref type="figure">Figure 6</ref>. Posterior predictive check plot `az.plot_ppc()` for Model 0 "m0" and Model 2 "m2". Solid black lines are the density plot of the observed RT data; blue lines are the posterior predictive samples; each line represents the predicted RT distribution based on one posterior predictive sample; yellow dashed lines represent the mean of all predicted RT distributions across all posterior predictive samples. (A) shows the results of the comparison between the two models (m0 vs. m2) at the individual level (subjects 3 and 11 as an example); (B) shows the results of the comparison at the condition level (i.e., "LC" represents lower conflict and "HC" represents higher conflict). All plots in the left column are for m0 and all plots in the right column are for m2. Note that the argument `coords` specifies the PPC level (individual or group level) that should be preprocessed before plotting. `num_pp_samples` is used to set the number of predictive data required for plotting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Statistical Inference</head><p>A final step in Bayesian modeling is to draw statistical inferences from the posterior parameter distributions in the best-fitting model. In our example, we will test the hypothesis whether drift rates significantly differ between high and low conflict conditions based on Model2 ("m2" in the Notebook). This hypothesis will be tested using the posterior samples of the regression coefficient in "m2", which has a variable name "v_C(conf, Treatment('LC'))[T.HC]". `var_names` argument can be used to select both group-level and individual-level parameters for analysis. `hdi_prob` argument specifies the probability of the HDI, typically set at 0.95 to correspond to a 95% confidence interval. `rope` defines the limitations of ROPE, which is a range considered to be equivalent to the null hypothesis or a reference value for the parameter.</p><p>The results show no overlap between the 95% HDI and the ROPE, indicating that the parameter is credibly different from zero. (B) Violin plot of parameter posteriors at two conflict levels. The black line is the 95% HDI and the white dot is the mean. The drift rate is lower in high conflict (HC) than in low conflict (LC) conditions.</p><p>Note that there are several acceptable methods for Bayesian hypothesis testing, such as Bayes factors <ref type="bibr" target="#b9">(Boehm et al., 2023;</ref><ref type="bibr" target="#b108">Wagenmakers et al., 2010)</ref>, Maximum a posteriori (MAP) based p-value <ref type="bibr" target="#b71">(Mills, 2018)</ref>, Directional Probabilities (PD, <ref type="bibr" target="#b66">Makowski et al., 2019)</ref>, and the Full Bayesian Significance Test (FBST, <ref type="bibr" target="#b50">Kelter, 2022)</ref>. In cognitive science and psychology, while Bayesian factors are often advocated as a Bayesian alternative to frequentist p-values <ref type="bibr" target="#b49">(Kelter, 2021;</ref><ref type="bibr" target="#b100">van de Schoot et al., 2017;</ref><ref type="bibr" target="#b108">Wagenmakers et al., 2010)</ref> should be used in which settings of scientific hypothesis testing <ref type="bibr" target="#b51">(Kelter, 2023;</ref><ref type="bibr" target="#b66">Makowski et al., 2019)</ref>. Therefore, it is useful to consider various Bayesian hypothesis testing methods depending on the study objectives and design <ref type="bibr" target="#b51">(Kelter, 2023;</ref><ref type="bibr" target="#b56">Kruschke, 2021;</ref><ref type="bibr" target="#b66">Makowski et al., 2019)</ref>.</p><p>Here, we demonstrate Bayesian inference using an approach that combines the approach HDI of the regression coefficient to this ROPE, we find that the HDI falls completely outside the ROPE ( <ref type="figure" target="#fig_9">Figure 7A</ref>), suggesting that the drift rate is higher in the low conflict condition than the high conflict condition ( <ref type="figure" target="#fig_9">Figure 7B</ref>).</p><p>Therefore, considering the results from various aspects (model comparison, PPC, and posterior inference), we conclude that the model which takes into account the influence of conflict level on drift rate performs the best. Moreover, high conflict affects the cognitive process of decision-making by impeding the speed of evidence accumulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>This tutorial focuses on an easy-to-use computational environment for HDDM, including installation of the tool, its features, and case applications. While some conceptual discussions have been addressed in other papers <ref type="bibr" target="#b5">(Boag et al., 2024;</ref><ref type="bibr" target="#b92">Shinn et al., 2020;</ref><ref type="bibr" target="#b105">Voss et al., 2013)</ref>, we have nevertheless discussed some relevant issues below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Why use dockerHDDM among tools?</head><p>Inference for the DDM can be implemented via multiple software/packages, such as fast-DM <ref type="bibr" target="#b106">(Voss &amp; Voss, 2007)</ref>, flexDDM (LaFollette et al., 2024), rtdists <ref type="bibr" target="#b93">(Singmann et al., 2022)</ref>, EZ-DDM <ref type="bibr" target="#b110">(Wagenmakers et al., 2007)</ref>, pyDDM <ref type="bibr" target="#b92">(Shinn et al., 2020)</ref>. For more details on tool and algorithm <ref type="bibr">6</ref> The ROPE should be tailored to the specific paradigm and research question <ref type="bibr" target="#b20">(Dienes, 2021)</ref> and reflect the range of possible values for each parameter (e.g., <ref type="bibr" target="#b98">Tran et al., 2021)</ref>. For example, a recent systematic parameter review of DDM found that the absolute value of a drift rate ranged from 0.01 to 18.51, with a median of 2.25 <ref type="bibr" target="#b98">(Tran et al., 2021)</ref>; another simulation and metaanalysis of conflict tasks showed that a drift rate between 0.05 and 0.35 captured the conflict effect <ref type="bibr" target="#b39">(Hedge et al., 2018)</ref>. Thus, we choose ROPE [-0.2 0.2] for illustrative purposes, implying that effects on drift rates smaller than 0.2 are not of interest.</p><p>Running title: dockerHDDM for Bayesian HDDM Modeling comparisons, see <ref type="bibr" target="#b92">Shinn et al. (2020)</ref>. While all the above tools are estimated in a frequency framework and fit data at the individual participant level, HDDM takes the Bayesian approach and estimates model parameters at both the individual and group level (i.e., the hierarchical models or multilevel model approach, see <ref type="bibr" target="#b113">Wiecki et al., 2013)</ref>. Tools that also allow the Bayesian hierarchical modeling approach of DDM include brms based on RStan <ref type="bibr" target="#b40">(Henrich et al., 2023)</ref>, the Wiener module in JAGS <ref type="bibr" target="#b107">(Wabersich &amp; Vandekerckhove, 2014)</ref>, EMC2 <ref type="bibr" target="#b97">(Stevenson et al., 2024)</ref> and</p><p>hBayesDM <ref type="bibr" target="#b0">(Ahn et al., 2017)</ref>. See <ref type="table" target="#tab_11">Table 6</ref> for comparison between these tools and HDDM.  <ref type="bibr" target="#b68">(Matzke &amp; Wagenmakers, 2009)</ref>, and applicable to typical cognitive experiments.</p><p>Another advantage of HDDM is its support for diverse accumulation models, including models with collapsing boundaries and those integrated with reinforcement learning, called RLDDM <ref type="bibr" target="#b29">(Fengler et al., 2022;</ref><ref type="bibr" target="#b76">Pedersen et al., 2017;</ref><ref type="bibr" target="#b74">Pedersen &amp; Frank, 2020)</ref>. Additionally, the latest version of HDDM provides many likelihood-free models, broadening its applications. For instance, its integration with neural networks, such as the LANs <ref type="bibr">(Likelihood Approximation Networks, Fengler et al., Fengler et al., 2021)</ref>, has greatly enhanced the efficiency of model design and development.</p><p>A notable limitation of dockerHDDM is its lack of integration with the most advanced parameter estimation techniques. For instance, its successors, HSSM and EMC2, have begun incorporating advanced MCMC methods. Moreover, innovative neural network approaches, such as LANs <ref type="bibr" target="#b30">(Fengler et al., 2021)</ref>, MNLE <ref type="bibr" target="#b10">(Boelts et al., 2022)</ref>, and Bayesflow <ref type="bibr" target="#b79">(Radev et al., 2022)</ref>, have the potential to significantly enhance these estimation procedures. However, the mastery of these cutting-edge techniques requires a higher level of expertise to prevent misuse.</p><p>Consequently, we propose that the mission of dockerHDDM should be to streamline operations and lower the barrier to entry, facilitating analogical learning, and ultimately preparing users for the transition to the more sophisticated methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Whether to include parameters' inter-trial variability?</head><p>As a demonstration, we utilized the seven-parameter full Drift Diffusion Model. If a user wishes to fit only the four-parameter model, the unnecessary parameters can be removed from the include argument, such as `include= <ref type="bibr">['a', 'v', 't', 'z']</ref>`. In contrast, the full model, which integrates trial-by-trial variability, is known for its robustness in fitting various datasets and accommodating extreme response times, including fast and slow errors <ref type="bibr" target="#b87">(Schubert et al., 2017)</ref>.</p><p>However, <ref type="bibr" target="#b62">Lerche &amp; Voss (2016)</ref> argue that exclude trial-by-trial parameters can enhance the fit and recovery of fundamental parameters.</p><p>Consequently, the choice to include trial-by-trial variability requires a delicate balance between the prediction and complexity of the model and the specific requirements of the data.</p><p>Given the extensive data requirements for inferring across-trial variability, our stance is to cautiously include across-trial variability in the model for a more robust fit and more precise inference of the basic parameters (see similar discussion in <ref type="bibr" target="#b5">Boag et al., 2024)</ref>. For instance, since the variability of the non-decision time tends to be easily recovered (e.g., the result of the parameter recovery in Appendix <ref type="figure">Figure S2</ref>), it may be prudent to include only this parameter, but not the other variability parameters by default. Nevertheless, when the dataset is substantial and the research objective prioritizes the analysis of specific response time pattern, such as fast or slow errors, the selective integration (the parameter variability of drift and start point, also see <ref type="table">Table 1)</ref> of these parameters may be warranted. We recommend reading the work by <ref type="bibr">Boehm et al. (2018)</ref>, which offers expert advice and recommendations on estimating across-trial variability parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Data quantity and quality for fitting DDM</head><p>Both the number of subjects and the number of trials should be considered. Due to the hierarchical nature of the model, hierarchical models typically require fewer trials than non-hierarchical models <ref type="bibr" target="#b1">(Alexandrowicz &amp; Gula, 2020;</ref><ref type="bibr" target="#b113">Wiecki et al., 2013)</ref>. In general, 12 subjects are sufficient to obtain stable results <ref type="bibr" target="#b113">(Wiecki et al., 2013</ref>), but we recommend collecting data from more than 20 subjects for a more robust fit. However, the number of sufficient trials vary depending on the parameters of interest. For the basic four-parameter model, the number of trials has a small effect on parameter estimates <ref type="bibr" target="#b1">(Alexandrowicz &amp; Gula, 2020)</ref>. 20 trials appear to be the minimum standard, and more than 50 trials tend to produce robust results <ref type="bibr" target="#b113">(Wiecki et al., 2013)</ref>. Estimates of and tend to be superior to those of and . To obtain more accurate estimates of , a number of trials greater than 100 is recommended <ref type="bibr" target="#b1">(Alexandrowicz &amp; Gula, 2020)</ref>. For parameters such as , , and , a large number of trials are required for estimation, preferably more than 120 trials <ref type="bibr" target="#b113">(Wiecki et al., 2013)</ref>. Recent discourse emphasizes that the determination of the number of subjects and trials should be aligned with considerations of experimental design, desired target effects, and parameter recovery simulations <ref type="bibr" target="#b5">(Boag et al., 2024)</ref>. For further empirical guidelines, see <ref type="bibr">Boehm et al. (2018)</ref> and <ref type="bibr" target="#b63">Lerche &amp; Voss (2017)</ref>.</p><p>It is important to note that parameter estimation can be affected by extreme values, such as very fast response times. HDDM addresses this issue by assuming a mixture model where a proportion of the response times are from a uniform distribution <ref type="bibr" target="#b85">(Ratcliff &amp; Tuerlinckx, 2002;</ref><ref type="bibr" target="#b113">Wiecki et al., 2013)</ref>. The proportion of response time is controlled by the parameter `p_outlier`, which is set to 0.05 by default. This approach helps mitigate the effect of extreme values and ensures a more robust parameter estimation.</p><p>Finally, it is essential to conduct posterior predictive checks to validate the model (see Section 4.6). These checks help to ensure that the model is capable of accurately reproducing the observed data, thus providing confidence in the evaluation of the model and parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Computational Resources and Tips</head><p>To achieve accurate estimates, more subjects, more trials, and often more samples are required, leading to increased demands on computational resources. This is not unique to dockerHDDM;</p><p>other tools using MCMC algorithms, such as DMC and brms mentioned earlier, are also affected by these factors. In the examples provided in this article, fitting each model with 14 subjects and 3988 trials takes 2-3 hours and requires 8-12 GB of memory. Running out of memory can cause the Jupyter kernel to suspend and restart, interrupting the process. Predictably, computational resources become a limiting factor with increasing data. To facilitate better model analysis, we offer the following tips and recommendations:</p><p>1. Initial Testing: When initially building the model, use subset data from a small number of subjects and reduce the MCMC sample size to verify that the model definition and code are correct.</p><p>Once validated, increase the data and sample sizes.</p><p>2. Adjust memory settings. If users experience a Jupyter kernel suspension or restart due to memory constraints, they can attempt to configure or increase virtual memory. For Windows users, it is necessary to check and remove the memory usage limitations imposed by WSL (Windows Subsystem for Linux).</p><p>3. Separate Execution: Model fitting, calculation of point-wise log-likelihood, and generation of posterior predictive checks (PPC) data can be executed separately. This approach helps prevent interrupting long-running processes due to errors and ensures that each step can be independently validated and debugged before proceeding to the next.</p><p>4. Notebook Segmentation: Fit models into separate notebooks to reduce the resource load of loading multiple models.</p><p>5. Model Saving: Save the fitted models and then load only the inferenceData files instead of the entire models to reduce resource usage.</p><p>6. Cloud Deployment: Docker is easily deployed in cloud computing environments (or use the docker image in Singularity). Use your institution's computing services or rent cloud computing services to handle larger datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>In this article, we introduce dockerHDDM, a user-friendly, out-of-the-box, and one-stop Docker image for implementing HDDM analysis within a modern Bayesian hierarchical workflow. Our dockerHDDM has three major advantageous: (1) it leverages Docker to solve compatibility issues and simplify the installation process;</p><p>(2) it ensures broad support across different machines equipped with either Intel or Apple chips; and (3) it integrates state-of-the-art Bayesian modeling practices with ArviZ, facilitating a more principled Bayesian workflow. We also provide a stepby-step video tutorial on how to use dockerHDDM.</p><p>While we have provided a step-by-step guide to using dockerHDDM, it is unfortunately not possible to provide a comprehensive introduction to computational modeling. Given the extensive knowledge required for principled computational modeling, we recommend readers refer to the materials in Box 5 for a deeper understanding of the DDM family, computational modeling,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Box 5. Recommendation for Further Reading</head><p>A full understanding of how Bayesian hierarchical drift-diffusion modeling works requires not only basic knowledge of DDM, but also knowledge of Python programming, Bayesian statistics, and hierarchical regression models. This background knowledge is generally not part of the coursework in psychology or neuroscience education, although the situation is changing in recent years. We recommend the following resources to quickly catch up and avoid misuse or abuse of HDDM.</p><p>Background knowledge/skills Resource Bayesian statistics <ref type="bibr" target="#b23">Etz &amp; Vandekerckhove, 2018;</ref><ref type="bibr" target="#b53">Kruschke, 2014</ref><ref type="bibr" target="#b54">Kruschke, , 2018</ref><ref type="bibr" target="#b60">Lambert, 2018;</ref><ref type="bibr" target="#b67">Martin et al., 2024;</ref><ref type="bibr" target="#b69">McElreath, 2020;</ref><ref type="bibr" target="#b99">van de Schoot et al., 2021.</ref> (Bayesian) Hierarchical (regression) models https://twiecki.io/blog/2014/03/17/bayesian-glms-3/; https://github.com/lei-zhang/BayesCog_Wien; Capretto et al., 2020.</p><p>Computational modeling <ref type="bibr" target="#b4">Blohm et al., 2020;</ref><ref type="bibr" target="#b11">Busemeyer, 2015;</ref><ref type="bibr" target="#b12">Busemeyer &amp; Diederich, 2009;</ref><ref type="bibr" target="#b23">Etz &amp; Vandekerckhove, 2018;</ref><ref type="bibr" target="#b27">Farrell &amp; Lewandowsky, 2018;</ref><ref type="bibr" target="#b61">Lee &amp; Wagenmakers, 2014;</ref><ref type="bibr" target="#b114">Wilson &amp; Collins, 2019;</ref><ref type="bibr" target="#b115">Zhang et al., 2020</ref><ref type="bibr">. Drift Diffusion Models Boag et al., 2024</ref><ref type="bibr" target="#b83">Ratcliff et al., 2016;</ref><ref type="bibr" target="#b81">Ratcliff &amp; McKoon, 2008;</ref><ref type="bibr" target="#b105">Voss et al., 2013.</ref> Sequential sampling models beyond DDMs <ref type="bibr" target="#b29">Fengler et al., 2022;</ref><ref type="bibr" target="#b31">Forstmann et al., 2016;</ref><ref type="bibr" target="#b83">Ratcliff et al., 2016.</ref> hierarchical models, and Bayesian modeling. We expect that dockerHDDM and this detailed tutorial will reduce the technical burden and help readers get started with computational modeling.</p><p>Ultimately, we hope that this tool and the computational modeling concepts presented in the tutorial will promote the computational reproducibility of drift-diffusion modeling for users of all levels of computational expertise. <ref type="bibr" target="#b113">Wiecki et al. (2013)</ref> demonstrated the superiority of Bayesian methods and hierarchical models for parameter recovery in HDDM. We illustrate the parameter recovery analysis of Model 2 in <ref type="figure">Figure S2</ref>. The results show that our model fitting approach can yield good parameter recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter recovery result</head><p>For the code that repeats this result, see https://github.com/hcp4715/dockerHDDM/blob/master/ dockerHDDMTutorial/Parameter_recovery.ipynb. <ref type="figure">Figure S2</ref>. Model 2 parameter recovery results. Blue is the true parameter; orange is the recovered parameter; white dots are the means; and the bar is the 95% HDI range. Subplot A shows the parameter recovery results at the group level, including 8 parameters, of which the first 5 are basic parameters and the last 3 are trial-by-trial variants; Subplot B shows the parameter recovery results at individual level, including 5 basic parameters for 13 subjects out of 65.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>panel in Figure 2, corresponding to Sections 2.2 and 2.3). Finally, within a working Jupyter notebook we show how to analyze an example dataset with dockerHDDM in a principled Bayesian workflow (bottom panel in Figure 2, corresponding to Section 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure</head><label></label><figDesc>Figure 2. dockerHDDM usage flowchart. Note that the code in the figures is for demonstration purposes only. Specific instructions and copyable code can be found in the corresponding sections. The top panel describes how to install Docker, corresponding to Section 2.1; the middle panel describes how to pull and run dockerHDDM, corresponding to Sections 2.2 and 2.3; and the bottom panel shows the workflow in dockerHDDM, corresponding to Section 4. A video tutorial is available at: https://www.youtube.com/watch?v=ZU1fbXEuP8s or at https://osf.io/3upng/ files/osfstorage/66d5c2a3f2abc7a7a359a26c/.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4</head><label>4</label><figDesc>Figure 4. Docker commands to download and run dockerHDDM. (A) Download/pull dockerHDDM from the Docker hub. The command by default downloads the latest version of `hcp4715/dockerHDDM` if the image tag is not specified. The CPU architecture (Apple or Intel chips, corresponding to ARM64 and AMD64 architectures, respectively) is automatically recognized when the image is downloaded. (B) Command to start a container. Note, "\" separates different lines of a command in Linux and MacOS Terminal but not in Windows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Beginners can follow HDDM_Basic_Tutorial.ipynb to get a basic understanding of HDDM, as discussed in Wiecki et al. (2013); HDDM_Regression_Stimcoding.ipynb covers more advanced models with regression, where parameters can vary based on experimental conditions and other covariates; Posterior_Predictive_Checks.ipynb introduces posterior predictive checks, showing how to generate predicted data from fitted parameter posteriors and how to analyze these predicted data;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>specification and fitting, model diagnosis, model comparison, posterior predictive check, and statistical inference. The code reproduced in this section can be found in dockerHDDM_Workflow.ipynb in dockerHDDM environment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Model 0 served as the baseline without considering the effect of conflict level on the model parameters. The model contains the seven parameters, referred to as the full DDM, including the decision boundary ( ), drift rate ( ), non-decision time ( ), and decision bias ( ), as well as , , and that indicates the trial-by-trial variations of , , and(Boehm et al., 2018;<ref type="bibr" target="#b85">Ratcliff &amp; Tuerlinckx, 2002)</ref>.By default, HDDM considers the hierarchical modeling approach that includes parameters at both the individual-and the group-level (see Box 3). Model 0 has 11 population-level parameters, including the mean and the standard deviation for the four basic parameters ( / / / ) and three parameters ( / / ) for the inter-trial variations. At the individual level, each subject also has a full set of four basic parameters, yielding a total of 56 = 14 * 4 parameters. Thus, Model 0 has Models Describe HDDM functions for defining a model (`df` is the data from Cavanagh et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>method for model fitting and parameter estimation. The definition and fitting of Model 2 are used here as an example (see &lt;Code Block 2&gt;):&lt;Code Block 2&gt; ```Python # define a model by hddm.HDDMRegressor m2 = hddm.HDDMRegressor( df, 'v ~ C(conf, Treatment('LC'))', group_only_regressors = False, keep_regressor_trace = True, include=['a', 'v', 't', 'z', 'sv', 'st', 'sz']) # fitting model and return InferenceData m2_infdata = m2.sample( 10000, chains = 4, save_name = 'm2', return_infdata = True, sample_prior = True, loglike = True, ppc = True) ```</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>(A) Statistical inference of parameters. The high-density interval (HDI, black line and texts) is compared with the region of practical equivalence (ROPE, red line and text).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>Comparisons between dockerHDDM and the original HDDM package</figDesc><table><row><cell>HDDM</cell><cell>dockerHDDM</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>2. Install and Use dockerHDDM 2.1. Install Docker</head><label></label><figDesc>2. dockerHDDM usage flowchart. Note that the code in the figures is for demonstration purposes only. Specific instructions and copyable code can be found in the corresponding sections.</figDesc><table><row><cell>Docker serves us to create an all-in-one, fast, cross-platform computing environment. The Docker</cell></row><row><cell>website provides easy-to-follow installation instructions (https://docs.docker.com/get-docker/)</cell></row><row><cell>and supports Windows, MacOS, and Linux (see Box 2). Windows users should ensure their system</cell></row><row><cell>version is 21H2 (build 19044) or higher and have either WSL or Hyper-V configured prior to</cell></row><row><cell>installation (see https://docs.docker.com/desktop/install/windows-install/).</cell></row><row><cell>The top panel describes how to install Docker, corresponding to Section 2.1; the middle panel</cell></row><row><cell>describes how to pull and run dockerHDDM, corresponding to Sections 2.2 and 2.3; and the</cell></row><row><cell>bottom panel shows the workflow in dockerHDDM, corresponding to Section 4. A video tutorial</cell></row><row><cell>is available at: https://www.youtube.com/watch?v=ZU1fbXEuP8s or at https://osf.io/3upng/</cell></row><row><cell>files/osfstorage/66d5c2a3f2abc7a7a359a26c/.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Example dataset from Cavanagh et al. (2011).</figDesc><table><row><cell cols="3">subj_idx rt response</cell><cell>conf</cell></row><row><cell>0</cell><cell>1.21</cell><cell>1.0</cell><cell>HC</cell></row><row><cell>0</cell><cell>1.63</cell><cell>1.0</cell><cell>LC</cell></row><row><cell>0</cell><cell>1.03</cell><cell>1.0</cell><cell>HC</cell></row><row><cell>0</cell><cell>2.77</cell><cell>1.0</cell><cell>LC</cell></row><row><cell>0</cell><cell>1.14</cell><cell>0.0</cell><cell>HC</cell></row></table><note>Note: The data structure required for HDDM is long-format data, where each row represents one trial.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Model comparison with different criteria. Rank is from the best model to the worst. Models 0 to 2 are referred to as m0 to m2.Note that WAIC and PSIS-LOO-CV require the pointwise log-likelihood of each data point given a posterior sample of parameters, which must be computed using the likelihood function and</figDesc><table><row><cell>Rank*</cell><cell>DIC</cell><cell>PSIS-LOO-CV</cell><cell>WAIC</cell></row><row><cell>1</cell><cell>m2 (10654.89)</cell><cell>m2 (10646.25)</cell><cell>m2 (10646.20)</cell></row><row><cell>2</cell><cell>m1 (10655.24)</cell><cell>m1 (10647.21)</cell><cell>m1 (10647.15)</cell></row><row><cell>3</cell><cell>m0 (10835.24)</cell><cell>m0 (10824.93)</cell><cell>m0 (10824.89)</cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6</head><label>6</label><figDesc>HDDM stands out for its ease of use, enabling users to construct and fit basic models with just a few lines of code. It facilitates the definition of complex mixed-effects models without the need for prior specifications, making it more accessible for beginners. While brms and EMC2 also defines mixed effects models well, it necessitates users to manually define prior distributions for random effects and covariance structures. Additionally, RStan and JAGS require expertise in linear model reparameterization. The absence of these expertise may result in model fitting failures or biased estimates. On the other hand, the simplicity of HDDM comes at the cost of flexibility, as it restricts users to the default priors (see Box 3) and does not allow for customization. However, the weakly informative prior implemented in HDDM was based on previous meta-analyses of published results</figDesc><table><row><cell cols="3">Tools comparison for modeling hierarchical DDM</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(docker)HDDM</cell><cell>brms/RStan/hBayesDM</cell><cell>JAGS</cell><cell>EMC2</cell></row><row><cell>Language</cell><cell>Python</cell><cell>R</cell><cell>R</cell><cell>R</cell></row><row><cell>MCMC</cell><cell>Metropolis-Hastings</cell><cell>NUTS</cell><cell>Gibbs</cell><cell>Particle</cell></row><row><cell>Algorithm</cell><cell></cell><cell></cell><cell>Sampling</cell><cell>Metropolis</cell></row><row><cell>Support Models</cell><cell>DDM, full DDM,</cell><cell>DDM,</cell><cell>DDM</cell><cell>DDM,</cell></row><row><cell></cell><cell>RLDDM,</cell><cell>full DDM</cell><cell></cell><cell>LBA,</cell></row><row><cell></cell><cell>collapsing boundary</cell><cell></cell><cell></cell><cell>RDM,</cell></row><row><cell></cell><cell>variants,</cell><cell></cell><cell></cell><cell>etc.</cell></row><row><cell></cell><cell>etc.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Custom Prior</cell><cell>No</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>Linear Mixed</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>extension</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Likelihood-free</cell><cell>Yes</cell><cell>No</cell><cell>No</cell><cell>No</cell></row><row><cell cols="5">Note: DDM = drift-diffusion model; MCMC = Markov chain Monte Carlo; RLDDM = reinforcement</cell></row><row><cell cols="5">learning drift diffusion model; LBA = linear ballistic accumulator; RDM = racing diffusion model.</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Running title: dockerHDDM for Bayesian HDDM Modeling</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that `/home/jovyan/{any_folder_name}` is a path mounted in the Jupyter Docker image, and `{any_folder_name}` will be visible in the browser. The default username is `jovyan`, and it cannot be changed.2 For beginners unfamiliar with Jupyter Notebook, do not panic! It is just an interface where you can write code and immediately check results. You may visit the official website at https://jupyter.org/try-jupyter/notebooks/?path=notebooks/Intro.ipynb to try out a web-based platform online. The Jupyter website also provides extensive documentation for users who want to learn more about Jupyter Notebook and Python programming (see https://docs.jupyter.org/en/latest/).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">To run the example notebooks faster, we only use 500 samples here. For a more in-depth understanding of the MCMC settings, we recommend reading<ref type="bibr" target="#b100">(van de Schoot et al., 2017;</ref><ref type="bibr" target="#b113">Wiecki et al., 2013)</ref>. The burn-in samples serve to calibrate the fitting, so the final samples need to exclude burn-in samples, yielding a total of 500 -100 = 400 samples per chain. Generally, a larger number of samples improves the estimation accuracy of a model.4  InferenceData is a more modern data construct that contains prior, posterior, a posterior predictive samples and observed data, facilitating the visualization and analysis of multiple joint datasets<ref type="bibr" target="#b43">(Hoyer &amp; Hamman, 2017;</ref><ref type="bibr" target="#b57">Kumar et al., 2019)</ref>.Running title: dockerHDDM for Bayesian HDDM Modeling</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">DIC can be extracted directly from the model rather than InferenceData, e.g. `m0.dic`.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the National Natural Science Foundation of China (32100901) and</p><p>Natural Science Foundation of Shanghai (21ZR1434700) to R-Y. Z.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code Availability</head><p>All resources are available on the Open Science Framework (OSF) at https://osf.io/3upng/?view_only=2425347775e749c3bab67af68607b918, which is linked to the GitHub repository at https://github.com/hcp4715/dockerHDDM/ and other resources.</p><p>The software, data, and scripts (Jupyter notebooks) used to generate the models and results described in this article can be accessed via the dockerHDDM image at https://hub.docker.com/r/hcp4715/hddm. Alternatively, readers can find our online notebooks and related materials here: https://git hub.com/hcp4715/dockerHDDM/ and https://github.com/hcp4715/dockerHDDM/tree/master/Off icialTutorials.</p><p>Additionally, the code used to create our dockerHDDM images is available at https://github.com/hcp4715/dockerHDDM/blob/master/Dockerfile.</p><p>For any questions regarding this tutorial or related dockerHDDM images, discussions can be held at: https://github.com/hcp4715/dockerHDDM/discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest</head><p>The authors declare no competing financial interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>H. C-P., H.G., L.Z., and R-Y.Z. conceived and designed the study. W.P. &amp; H. C-P. implemented and have been maintaining the dockerHDDM Docker image. H. C-P., H.G., L.Z., and R-Y.Z. made the first draft of the manuscript. W.P., H. C-P., and R-Y.Z. re-organized the draft since version 7 of the preprint. All authors edited the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian hypothesis testing with savage-dickey method</head><p>Another method to test the experimental effect is to compute the Savage-Dickey Density Ratio to approximate the Bayes Factor (see Box 1). ArviZ provides the `plot_bf` function to visualize the differences between prior and posterior distributions and compute the Bayes Factor. Note that the Savage-Dickey ratio is related to the prior, which is weak in HDDM, resulting in a very large Bayes Factor values. We therefore urge caution in using this method, and that inference should be drawn by combining as many as possible (e.g. HDI or HDI+ROPE as mentioned in section 4.7).</p><p>In <ref type="figure">Figure S1</ref>, the left panel displays the Bayes Factor favoring the alternative hypothesis ( 10 = 1.5 * 10 236 , 01 =0), indicating extremely strong evidence supporting the alternative hypothesis over the null hypothesis. This implies that the conflict condition significantly affects the drift rate. The right panel shows the Bayes Factor favoring the null hypothesis ( 10 = 0.14, 01 = 7.15), indicating moderate evidence supporting the null hypothesis over the alternative hypothesis. This suggests that there is no response bias, as evidenced by z being close to 0.5. <ref type="figure">Figure S1</ref>. Bayes Factor test. This figure illustrates the prior (blue line) and posterior (orange line) density distributions for the drift rate parameter under the conflict condition. The dashed vertical line represents the reference/null value (zero), and the black dot indicates the Bayes Factor at this point. The notable difference between the probabilistic density of prior and posterior distributions at the reference value, which is used to calculate the Savage-Dickey Density Ratio and approximate the Bayes Factor, provides evidence to accept or reject the experimental effect.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Revealing neurocomputational mechanisms of reinforcement learning and decision-making with the hBayesDM package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Haines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1162/cpsy_a_00002</idno>
		<ptr target="https://doi.org/10.1162/cpsy_a_00002" />
	</analytic>
	<monogr>
		<title level="j">Computational Psychiatry</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="24" to="24" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Comparing eight parameter estimation methods for the ratcliff diffusion model using free software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Alexandrowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gula</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2020.484737</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2020.484737" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">484737</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bayesian inference with stan: A tutorial on adding custom distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Annis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="863" to="886" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13428-016-0746-9</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0746-9" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A how-to-model guide for neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Blohm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Kording</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Schrater</surname></persName>
		</author>
		<idno type="DOI">10.1523/ENEURO.0352-19.2019</idno>
		<idno>ENEURO.352-19.2019</idno>
		<ptr target="https://doi.org/10.1523/ENEURO.0352-19.2019" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">An expert guide to planning experimental tasks for evidence accumulation modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Innes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bahg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hedge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lilburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miletic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">.</forename><surname>Osth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Palmeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Sederberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Orstmann</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/snqgp</idno>
		<ptr target="https://doi.org/10.31234/osf.io/snqgp" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Annis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Krypotos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Ravenzwaaij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Servant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Estimating across-trial variability parameters of the Diffusion Decision Model: Expert advice and recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Starns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="46" to="75" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.jmp.2018.09.004</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2018.09.004" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Inclusion Bayes factors for mixed hierarchical diffusion decision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">F</forename><surname>Gronau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000582</idno>
		<ptr target="https://doi.org/10.1037/met0000582" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Flexible and efficient simulationbased inference for models of decision-making. eLife, 11, e77220</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boelts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Lueckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Macke</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.77220</idno>
		<ptr target="https://doi.org/10.7554/eLife.77220" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The Oxford handbook of computational and mathematical psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diederich</surname></persName>
		</author>
		<title level="m">Cognitive modeling</title>
		<imprint>
			<publisher>SAGE Publications, Inc</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Bambi: A simple interface for fitting Bayesian linear models in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Capretto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Piho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Westfall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yarkoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<idno type="DOI">10.48550/ARXIV.2012.10754</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2012.10754" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Subthalamic nucleus stimulation reverses mediofrontal influence over decision threshold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cavanagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Figueroa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Samanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1462" to="1467" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/nn.2925</idno>
		<ptr target="https://doi.org/10.1038/nn.2925" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Laminar differences in decision-related neural activity in dorsal premotor cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peixoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-017-00715-0</idno>
		<ptr target="https://doi.org/10.1038/s41467-017-00715-0" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">614</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decomposing preferences into predispositions and evaluations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology-General</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1883" to="1903" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/xge0001162</idno>
		<ptr target="https://doi.org/10.1037/xge0001162" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Obtaining evidence for No effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dienes</surname></persName>
		</author>
		<idno type="DOI">10.1525/collabra.28202</idno>
		<ptr target="https://doi.org/10.1525/collabra.28202" />
	</analytic>
	<monogr>
		<title level="j">Collabra: Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Response times and decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781119170174.epcn509</idno>
		<ptr target="https://doi.org/10.1002/9781119170174.epcn509" />
	</analytic>
	<monogr>
		<title level="m">Stevens&apos; Handbook of Experimental Psychology and Cognitive Neuroscience</title>
		<editor>J. T. Wixted</editor>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="33" />
		</imprint>
	</monogr>
	<note>1st ed.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The HDI + ROPE decision rule is logically incoherent but we can fix it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Etz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Chá Vez De La Peña</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Baroja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Medriano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000660</idno>
		<ptr target="https://doi.org/10.1037/met0000660" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Introduction to Bayesian inference for psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Etz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<idno type="DOI">10.3758/s13423-017-1262-3</idno>
		<ptr target="https://doi.org/10.3758/s13423-017-1262-3" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evidence accumulation models: Current limitations and future directions. The Quantitative Methods for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="73" to="90" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<idno type="DOI">10.20982/tqmp.16.2.p073</idno>
		<ptr target="https://doi.org/10.20982/tqmp.16.2.p073" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Computational modeling of cognition and behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781316272503</idno>
		<ptr target="https://doi.org/10.1017/CBO9781316272503" />
		<imprint>
			<date type="published" when="2018" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Running title: dockerHDDM for Bayesian HDDM Modeling</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Beyond drift diffusion models: Fitting a broad class of decision and reinforcement learning models with HDDM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fengler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_01902</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_01902" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Likelihood approximation networks (LANs) for fast inference of simulation models in cognitive neuroscience. eLife, 10, e65074</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fengler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Govindarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.65074</idno>
		<ptr target="https://doi.org/10.7554/eLife.65074" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sequential sampling models in cognitive neuroscience: Advantages, applications, and extensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-122414-033645</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-122414-033645" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="641" to="666" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">fMRI and EEG predictors of dynamic decision parameters during human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gagne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nyhus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Masters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cavanagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Badre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="485" to="494" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.2036-14.2015</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.2036-14.2015" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Understanding predictive information criteria for Bayesian models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="997" to="1016" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/s11222-013-9416-2</idno>
		<ptr target="https://doi.org/10.1007/s11222-013-9416-2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Inference from iterative simulation using multiple sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="457" to="472" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Margossian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Modrá K</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.01808</idno>
		<ptr target="http://arxiv.org/abs/2011.01808" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">Bayesian Workflow.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improving neurocognitive testing using computational psychiatry-A systematic review for ADHD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Ging-Jehli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Arnold</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000319</idno>
		<ptr target="https://doi.org/10.1037/bul0000319" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="169" to="231" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Low and variable correlation between reaction time costs and accuracy costs explained by accumulation models: Meta-analysis and simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hedge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bompas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vivian-Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sumner</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000164</idno>
		<ptr target="https://doi.org/10.1037/bul0000164" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1200" to="1227" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The seven-parameter diffusion model: An implementation in stan for Bayesian analyses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Henrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pratz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Klauer</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-023-02179-1</idno>
		<ptr target="https://doi.org/10.3758/s13428-023-02179-1" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Running title: dockerHDDM for Bayesian HDDM Modeling</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Distinct mechanisms mediate speed-accuracy adjustments in cortico-subthalamic networks. eLife, 6</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Herz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Brittain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheeran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Z</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ashkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Foltynie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Limousin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zrinzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.21481</idno>
		<ptr target="https://doi.org/10.7554/eLife.21481" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">xarray: N-D labeled arrays and datasets in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hamman</surname></persName>
		</author>
		<idno type="DOI">10.5334/jors.148</idno>
		<ptr target="https://doi.org/10.5334/jors.148" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Research Software</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Good me bad me: Prioritization of the goodself during perceptual decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Macrae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sui</surname></persName>
		</author>
		<idno type="DOI">10.1525/collabra.301</idno>
		<ptr target="https://doi.org/10.1525/collabra.301" />
	</analytic>
	<monogr>
		<title level="j">Collabra: Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Bayes rules! An introduction to applied Bayesian modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Q</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dogucu</surname></persName>
		</author>
		<ptr target="https://www.bayesrulesbook.com/" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Advancing research on cognitive processes in social and personality psychology: A hierarchical drift diffusion model primer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Hopwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cesario</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Psychological and Personality Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="413" to="423" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/1948550617703174</idno>
		<ptr target="https://doi.org/10.1177/1948550617703174" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1995.10476572</idno>
		<ptr target="https://doi.org/10.1080/01621459.1995.10476572" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">430</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Bayesian model selection in the M-open setting-Approximate posterior inference and subsampling for efficient large-scale leave-one-out cross-validation via the difference estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kelter</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2020.102474</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2020.102474" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">fbst: An R package for the full Bayesian significance test for testing a sharp null hypothesis against its alternative via the e value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kelter</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-021-01613-6</idno>
		<ptr target="https://doi.org/10.3758/s13428-021-01613-6" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1114" to="1130" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">How to choose between different Bayesian posterior indices for hypothesis testing in practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kelter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="160" to="188" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/00273171.2021.1967716</idno>
		<ptr target="https://doi.org/10.1080/00273171.2021.1967716" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Rejecting or accepting parameter values in bayesian estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="280" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/2515245918771304</idno>
		<ptr target="https://doi.org/10.1177/2515245918771304" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bayesian analysis reporting guidelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-021-01177-7</idno>
		<ptr target="https://doi.org/10.1038/s41562-021-01177-7" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Article 10</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">ArviZ a unified library for exploratory analysis of Bayesian models in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hartikainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Martí N</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.01143</idno>
		<ptr target="https://doi.org/10.21105/joss.01143" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page">1143</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Testosterone eliminates strategic prosocial behavior through impacting choice consistency in healthy males</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Kutlikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eisenegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Honk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lamm</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41386-023-01570-y</idno>
		<ptr target="https://doi.org/10.1038/s41386-023-01570-y" />
	</analytic>
	<monogr>
		<title level="m">Article 10</title>
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="volume">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">FlexDDM: A flexible decisiondiffusion python package for the behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lafollette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Puccio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Demaree</surname></persName>
		</author>
		<ptr target="https://escholarship.org/uc/item/4q57r2x0" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2024" />
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A student&apos;s guide to Bayesian statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SAGE</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Bayesian cognitive modeling: A practical course</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139087759</idno>
		<ptr target="https://doi.org/10.1017/CBO9781139087759" />
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
	<note>1st ed.</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Model complexity in diffusion modeling: Benefits of making the model more parsimonious</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.01324</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.01324" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Retest reliability of the parameters of the ratcliff diffusion model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-016-0770-5</idno>
		<ptr target="https://doi.org/10.1007/s00426-016-0770-5" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="629" to="652" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">A multiverse assessment of the reliability of the self matching task as a measurement of the self-prioritization effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chuan-Peng</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/g6uap</idno>
		<ptr target="https://doi.org/10.31234/osf.io/g6uap" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<idno type="DOI">10.1201/b13613</idno>
		<ptr target="https://doi.org/10.1201/b13613" />
		<title level="m">The BUGS Book: A Practical Introduction to Bayesian Analysis</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>0 ed.</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Indices of effect existence and significance in the Bayesian framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Makowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Ben-Shachar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lüdecke</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2019.02767</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2019.02767" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Bayesian analysis with python: A practical guide to probabilistic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fonnesbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wiecki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
	<note>Third edition. Packt</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Psychological interpretation of the ex-gaussian and shifted wald parameters: A diffusion model analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.3758/PBR.16.5.798</idno>
		<ptr target="https://doi.org/10.3758/PBR.16.5.798" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="798" to="817" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcelreath</surname></persName>
		</author>
		<title level="m">Statistical rethinking: A Bayesian course with examples in R and Stan</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title/>
		<idno type="DOI">10.1201/9780429029608/statistical-rethinking-richard-mcelreath</idno>
		<ptr target="https://www.taylorfrancis.com/books/mono/10.1201/9780429029608/statistical-rethinking-richard-mcelreath" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Objective Bayesian precise hypothesis testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Mills</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>University of Cincinnati</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Alnaes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Der Meer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fernandez-Cabello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Berthet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kjelkenes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Barch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Andreassen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Computational modeling of the N-Back task in the ABCD study: Associations of drift diffusion model parameters to polygenic scores of mental disorders and cardiometabolic diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Westlye</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bpsc.2022.03.012</idno>
		<ptr target="https://doi.org/10.1016/j.bpsc.2022.03.012" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Simultaneous hierarchical Bayesian parameter estimation for reinforcement learning and drift diffusion models: A tutorial and links to neural data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Brain &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="458" to="471" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/s42113-020-00084-w</idno>
		<ptr target="https://doi.org/10.1007/s42113-020-00084-w" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The drift diffusion model as the choice rule in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Biele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1251" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13423-016-1199-y</idno>
		<ptr target="https://doi.org/10.3758/s13423-016-1199-y" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">A Reproducible Data Analysis Workflow. Quantitative and Computational Methods in Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<idno type="DOI">10.5964/qcmb.3763</idno>
		<ptr target="https://doi.org/10.5964/qcmb.3763" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">BayesFlow: Learning complex stochastic models with invertible neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">K</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ardizzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Running title: dockerHDDM for Bayesian HDDM Modeling Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1452" to="1466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title/>
		<idno type="DOI">10.1109/TNNLS.2020.3042395</idno>
		<ptr target="https://doi.org/10.1109/TNNLS.2020.3042395" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">The diffusion decision model: Theory and data for twochoice decision tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="873" to="922" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title/>
		<idno type="DOI">10.1162/neco.2008.12-06-420</idno>
		<ptr target="https://doi.org/10.1162/neco.2008.12-06-420" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Diffusion Decision Model: Current Issues and History</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="260" to="281" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.tics.2016.01.007</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2016.01.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03196302</idno>
		<ptr target="https://doi.org/10.3758/bf03196302" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="438" to="481" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">The Metropolis-Hastings Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4757-4145-2_7</idno>
		<ptr target="https://doi.org/10.1007/978-1-4757-4145-2_7" />
	</analytic>
	<monogr>
		<title level="m">Monte Carlo Statistical Methods</title>
		<editor>C. P. Robert &amp; G. Casella</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="267" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Evaluating the model fit of diffusion models with the root mean square error of approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-L</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hagemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bergmann</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2016.08.004</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2016.08.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="29" to="45" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Decision making and sequential sampling from memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2016.04.036</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2016.04.036" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="927" to="939" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Seok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thelaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Platt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Decomposing loss aversion from gaze allocation and pupil dilation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<biblScope unit="page">117</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1919670117</idno>
		<ptr target="https://doi.org/10.1073/pnas.1919670117" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">A flexible framework for simulating and fitting generalized drift-diffusion models. eLife</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Murray</surname></persName>
		</author>
		<idno type="DOI">10.7554/elife.56938</idno>
		<ptr target="https://doi.org/10.7554/elife.56938" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Terry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>rtdists: Response time distributions (Version 0.11-5) [Computer software</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<idno type="DOI">10.32614/CRAN.package.rtdists</idno>
		<ptr target="https://10.32614/CRAN.package.rtdists" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Bayesian Measures of Model Complexity and Fit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">G</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Der Linde</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9868.00353</idno>
		<ptr target="https://doi.org/10.1111/1467-9868.00353" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B: Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="639" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Running title: dockerHDDM for Bayesian HDDM Modeling</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">EMC2: An R package for cognitive models of choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Donzallaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Innes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/2e4dq</idno>
		<ptr target="https://doi.org/10.31234/osf.io/2e4dq" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Systematic Parameter Reviews in Cognitive Modeling: Towards a Robust and Cumulative Characterization of Psychological Processes in the Diffusion Decision Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Maanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2020.608287</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2020.608287" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Bayesian statistics and modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mä Rtens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Tadesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vannucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Veen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Willemsen</surname></persName>
		</author>
		<idno type="DOI">10.1038/s43586-021-00017-2</idno>
		<ptr target="https://doi.org/10.1038/s43586-021-00017-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Methods Primers</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zondervan-Zwijnenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">A systematic review of bayesian articles in psychology: The last 25 years</title>
		<idno type="DOI">10.1037/met0000100</idno>
		<ptr target="https://doi.org/10.1037/met0000100" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Practical Bayesian model evaluation using leaveone-out cross-validation and WAIC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1413" to="1432" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/s11222-016-9696-4</idno>
		<ptr target="https://doi.org/10.1007/s11222-016-9696-4" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Ranknormalization, folding, and localization: An improved R 2 for assessing convergence of MCMC (with discussion)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<idno type="DOI">10.1214/20-BA1221</idno>
		<ptr target="https://doi.org/10.1214/20-BA1221" />
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Diffusion models in experimental psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nagler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<idno type="DOI">10.1027/1618-3169/a000218</idno>
		<ptr target="https://doi.org/10.1027/1618-3169/a000218" />
	</analytic>
	<monogr>
		<title level="j">Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="385" to="402" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Fast-dm: A free program for efficient diffusion model analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03192967</idno>
		<ptr target="https://doi.org/10.3758/BF03192967" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="767" to="775" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Extending JAGS: A tutorial on adding custom distributions to JAGS (with a diffusion model example)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wabersich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-013-0369-3</idno>
		<ptr target="https://doi.org/10.3758/s13428-013-0369-3" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="28" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Bayesian hypothesis testing for psychologists: A tutorial on the savage-dickey method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lodewyckx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuriyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grasman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2009.12.001</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2009.12.001" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="158" to="189" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Running title: dockerHDDM for Bayesian HDDM Modeling</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">An EZ-diffusion model for response time and accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L J</forename><surname>Van Der Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P P P</forename><surname>Grasman</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03194023</idno>
		<ptr target="https://doi.org/10.3758/BF03194023" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="22" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Leveraging containers for reproducible psychological research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wiebels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moreau</surname></persName>
		</author>
		<idno type="DOI">10.1177/25152459211017853</idno>
		<ptr target="https://doi.org/10.1177/25152459211017853" />
	</analytic>
	<monogr>
		<title level="m">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">HDDM: Hierarchical bayesian estimation of the drift-diffusion model in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.3389/fninf.2013.00014</idno>
		<ptr target="https://doi.org/10.3389/fninf.2013.00014" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroinformatics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">Ten simple rules for the computational modeling of behavioral data. eLife, 8, e49547</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.49547</idno>
		<ptr target="https://doi.org/10.7554/eLife.49547" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Using reinforcement learning models in social neuroscience: Frameworks, pitfalls and suggestions of best practices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lengersdorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mikus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glascher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lamm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="695" to="707" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title/>
		<idno type="DOI">10.1093/scan/nsaa089</idno>
		<ptr target="https://doi.org/10.1093/scan/nsaa089" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Running title: dockerHDDM for Bayesian HDDM Modeling</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
