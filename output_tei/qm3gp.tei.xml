<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Do model-based and model-free reinforcement learning correspond to goal-directed and habitual actions, respectively? A systematic review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Yee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Do model-based and model-free reinforcement learning correspond to goal-directed and habitual actions, respectively? A systematic review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Model-based</term>
					<term>Model-free</term>
					<term>Reinforcement learning</term>
					<term>Goal-directed</term>
					<term>Habitual</term>
					<term>Systematic review</term>
					<term>Psychology</term>
					<term>Neural</term>
					<term>Computational</term>
					<term>Behavior</term>
					<term>Algorithms</term>
					<term>Cognitive processes</term>
					<term>Neural networks</term>
					<term>Decision-making</term>
					<term>Learning theories</term>
				</keywords>
			</textClass>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outline</head><p>The idea that model-based reinforcement learning (RL) corresponds to goal-directed actions and model-free RL corresponds to habitual actions is deeply entrenched in psychology. To test this hypothesis, we will first review and evaluate the evidence base from behavioral and neural studies.</p><p>Behaviorally, positive correlations between behavioral parameters that index model-based/model-free RL and goal-directed/habitual actions would support the hypothesis. Neurally, overlapping neural substrates that underlie the model-based/goal-directed constructs and between the modelfree/habitual constructs, as well as a dissociation between the neural substrates underlying both groups of constructs, would support the hypothesis. We will then discuss alternative classes of computational theories beyond the model-based/model-free framework that purport to describe goaldirected and habitual behaviour, and compare these theories against the model-based/model-free framework as well as against each other. Some of the alternative theories covered in this review include dichotomy-based frameworks (e.g., value-based vs. value-free), hierarchical frameworks (e.g., action sequences or active inference), and biological frameworks (e.g., actor-critic models). We then outline potential approaches to synthesize the findings and future avenues of research. Overall, we find that model-based RL maps onto certain facets of goal-directed actions but not necessarily onto other facets. On the other hand, there is much evidence suggesting that model-free RL does not track habitual actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Do model-based and model-free reinforcement learning correspond to goaldirected and habitual actions, respectively? Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goal-directed versus habitual behaviour</head><p>Traditional cognitive psychology delineates behaviour into two systems of control: goaldirected versus habitual behaviour <ref type="bibr" target="#b90">(Tolman, 1948)</ref>. Goal-directed behaviour is flexible, adaptable, and tailored to achieving specific goals, whereas habitual behaviour is inflexible and more automatic.</p><p>Compared to habitual behaviour, goal-directed behaviour has higher cognitive demands, offers more flexibility, can be partially distinguished by its neural substrates, and is sensitive to the relationship between actions and their expected outcome (Schawbe and Wolf, 2010). Experimentally, two crucial elements of goal-directed learning are contingency learning and incentive learning <ref type="bibr" target="#b52">(Hammond, 1980;</ref><ref type="bibr" target="#b0">Adams, 1982)</ref>. In instrumental learning tasks, animals learn that a specific (set of) action leads to specific rewarding or aversive outcomes. Contingency learning involves understanding the relationship between an action and its outcome, and is often tested using contingency degradation, where an animal's behaviour is considered as goal-directed if its behaviour is sensitive to breakdowns in the action-outcome contingency. Incentive learning pertains to the motivational significance of the expected outcome of an action, and is usually tested through outcome devaluation, where behaviour is deemed as goal-directed if it is sensitive to reductions in the desirability of the outcome. In contrast to goal-directed behaviour, insensitivity to contingency degradation and/or outcome devaluation is a hallmark of habitual behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-based versus model-free reinforcement learning</head><p>The distinction between goal-directed and habitual actions is often formalized within and understood using the "reinforcement learning" (RL) computational framework. RL frameworks typically conceive the environment as a Markov Decision Process (MDP), which can be defined by a set of states (S), transitions between states (P), possible actions (A), and the rewards that can be obtained at each state (R). In RL, an agent's objective is to maximise long-term reward by selecting the optimal action at each state. The RL literature distinguishes between algorithms that drive actions in a model-based or model-free manner <ref type="bibr">(Sutton and Barto, 1998)</ref>. Model-based RL involves learning and maintaining an internal model of the environment, such as transition probabilities and contingencies between states. In other words, values of possible actions can be computed by representing the states, transition probabilities between them, and the rewards in each state. Action values and state transition structures (e.g., contingencies and probabilities) can be integrated to make decisions prospectively. In contrast, model-free agents solely learn through direct, trial-and-error interactions with the environment, in the absence of an internal representation of the environment. On each trial, the agent carries out an action, observes the outcome, and computes a reward prediction error, which is the difference between expected and observed reward. One class of influential model-free algorithms that utilises reward prediction errors is called temporal difference (TD) learning. For example, the positive reward prediction errors (i.e., observed &gt; expected reward) lead to an increase in action value whereas negative reward prediction errors (i.e., observed &lt; expected reward) lead to a decrease in action value. In the long run, these cached value representations approximate long-term expected value of actions, providing that the environmental structure is unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conceptual parallels</head><p>That goal-directed decisions map onto model-based RL and habits map onto model-free RL is a popular and enduring idea <ref type="bibr" target="#b25">(Daw et al., 2005;</ref><ref type="bibr" target="#b33">Dolan and Dayan, 2013)</ref>. <ref type="bibr" target="#b90">Tolman (1948)</ref> suggested 5 that goal-directed behaviour does not only depend on the history of past actions and rewards, but also relies on an internal representation of environmental structure, which parallels computational descriptions of model-based RL. Potential mechanisms that underlie the formation of internal environmental models in goal-directed learning could include mental stimulation <ref type="bibr" target="#b56">(Hassabis and Maguire, 2007)</ref> and preplay <ref type="bibr" target="#b39">(Foster and Wilson, 2006)</ref>. Additionally, it is an intuitive idea that model-free values derived from prior rewards can reinforce habit strength.</p><p>Today, the hypothesis that model-based RL underlies goal-directed behaviour and model-free RL underlies habitual behaviour is so entrenched in the literature that the terms model-based/goaldirected and model-free/habits are often used interchangeably <ref type="bibr" target="#b67">(Miller et al., 2018)</ref>. Additionally, researchers have depended on this hypothesis to generate novel ideas that apply to various psychological areas, such as impulsivity <ref type="bibr" target="#b79">(Rangel, 2013)</ref>, addiction <ref type="bibr">(Lucantonio et al., 2014)</ref>, and moral judgement <ref type="bibr" target="#b15">(Buckholtz, 2015)</ref>. Given the theoretical/clinical significance and the ubiquity of this hypothesis, this dissertation aims to verify this hypothesis by examining the strength of the evidence base (behavioural, neural), and by reviewing classes of theoretical proposals that pertain to the relationship between goal-directed/habitual behaviour and computational algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidence relating to the model-based/goal-directed versus model-free/habits hypothesis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioural findings</head><p>To investigate if model-based RL corresponds to goal-directed actions and if model-free RL corresponds to habits, recent experiments have attempted to correlate behavioural indexes of modelbased/model-free behaviour (e.g., in the two-step task; <ref type="bibr" target="#b23">Daw et al., 2011)</ref> with indexes of goaldirected/habitual behaviour (e.g., in contingency degradation and outcome devaluation tasks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1:</head><p>A simplified task schematic of the original two-step task, adapted from <ref type="figure">Figure 2A</ref> from <ref type="bibr" target="#b70">Morris and Cushman (2019)</ref>. In each of the two sequential "steps", participants choose from one of two actions: A1 or A2. Each action in State 1 commonly leads to a particular Step 2 state and infrequently leads to the other Step 2 state. Each Step 2 action probabilistically transitions to either a rewarded terminal state or a non-rewarded terminal state, with transition probabilities that continuously drift over trials. The two-step task putatively distinguishes between participants' tendency to utilise modelbased versus model-free RL on a trial-by-trial basis <ref type="figure">(Figure 1</ref>). In each trial, participants make a binary choice (A1 or A2) in each of the two "steps". First, the participant chooses the A1 or A2 action in Step 1. A1 is probabilistically biased towards one of the Step 2 "states" such that A1 leads to State 2 most of the trials (e.g., 70% of trials; <ref type="bibr" target="#b40">Friedel et al., 2014)</ref>, and only leads to State 3 in a minority (30%) of trials. Conversely, A2 has the opposite transition probability profile such that choosing A2 commonly transitions to State 3 and infrequently transitions to State 2. All the states in these two steps are unrewarded and are represented by abstract visual stimuli on a screen. In other words, there is an inherent probabilistic structure within the task environment that should be detectable by a model-based agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Each choice in</head><p>Step 2 probabilistically transitions to a rewarded terminal state or a nonrewarded terminal state. In the standard version of the two-step task, the terminal states are binary (rewarded, non-rewarded) and do not contain graded reward magnitudes. Each of the four possible actions (2A, 2B, 3A, 3B) in Step 2 has its own action value -derived from probability of reward -that probabilistically drifts over the course of the experiment. To maximise rewards, the optimal strategy would involve tracking the action values (i.e., reward probabilities) of all Step 2 actions, and choosing the optimal action in Step 1 that leads to the Step 2 action(s) with the highest probability of yielding a reward.</p><p>Model-free and model-based RL logically result in different behavioural predictions. For example, consider a rare transition from Step 1 choice A1 to State 3 that is followed by a rewarded</p><p>Step 2 choice. A model-based agent would use update its internal model of the task and increase the value estimate of the Step 1 choice that commonly leads to State 3, which is A2 (not A1). Conversely, a model-free agent, who does not represent the transition probabilities between Step 1 and Step 2, should increase the value estimate of the Step 1 choice that leads to a reward, which is A1. Therefore, in this specific scenario of a rare transition that ultimately leads to reward, a model-free agent should have a higher likelihood of repeating the same Step 1 choice, in contrast to the model-based agent's "optimal" response of selecting the other Step 1 choice. In other words, a model-based agent's value function of Step 1 actions includes the interaction between the transition probability (common vs. rare) and the reward outcome history (rewarded vs. non-rewarded), whereas a model-free agent's value function of Step 1 actions solely depends on these actions' reward history.</p><p>Findings show that individual participants tend to utilise a combination of model-based and model-free RL in the two-step task <ref type="bibr">(Glascher et al., 2010;</ref><ref type="bibr" target="#b23">Daw et al., 2011)</ref>. Individual differences in the likelihood to prefer model-based over model-free RL could be linked to individual variances in working memory <ref type="bibr">(Otto et al., 2013)</ref>, temporal discounting <ref type="bibr" target="#b84">(Shenhav et al., 2016)</ref>, cognitive control <ref type="bibr" target="#b25">(Daw et al., 2005;</ref><ref type="bibr" target="#b44">Otto et al., 2015)</ref>, social cognition <ref type="bibr">(Hackel et al., 2019)</ref>, psychiatric conditions associated with compulsivity and social isolation <ref type="bibr" target="#b46">(Gillan et al., 2016)</ref>, and neurodevelopmental disorders <ref type="bibr" target="#b72">(Nissan et al., 2023)</ref>.</p><p>Given individual variability in the propensity to adopt one RL algorithm over the other, researchers have correlated parameters indexing model-based/model-free learning from the two-step task with parameters indexing goal-directed/habitual control in instrumental learning paradigms. A high correlation would provide support for the model-based/goal-directed versus model-free/habits hypothesis. <ref type="bibr" target="#b40">Friedel et al. (2014)</ref> cross-validated the two-step task with a selective devaluation task <ref type="bibr" target="#b94">(Valentin et al., 2007)</ref>. In said outcome devaluation task, participants are instrumentally trained to associate actions with different food stimuli (e.g., chocolate and tomato soup). After a selective devaluation of one reward by feeding the participant to satiety on that food item, participants are tested in extinction (i.e., in the absence of all food delivery). Goal-directed behaviour is captured by sensitivity to outcome devaluation.</p><p>The researchers found that individual degrees of goal-directed behaviour correlated with model-based behaviour, which suggests that sensitivity to outcomes might be a component of modelbased learning. Additionally, <ref type="bibr">Sjoerds et al., (2016)</ref> carried out the two-step experiment and a different instrumental learning task ("slips-of-action"; de Wit et al., 2012b) that similarly measured sensitivity to outcome devaluation. Their results also suggested that goal-directed and model-based behaviour are part of a shared construct, albeit with a limited degree of shared variance (R 2 = .055).</p><p>Promisingly, <ref type="bibr" target="#b42">Gillan et al. (2015b)</ref> measured goal-directed and model-based behaviour in a single paradigm that combined the two-step task with an outcome devaluation procedure, and showed that individuals who were more model-based were also more sensitive to devaluation of outcomes.</p><p>Crucially, sensitivity to outcome devaluation was not correlated with parameters of model-free RL across all three experiments. Example parameters of model-free RL include the main effect of reward and the reinforcement eligibility parameter, which determines how much each previous action in a sequence of preceding actions contributes to the updated value of an action <ref type="bibr" target="#b40">(Friedel et al., 2014)</ref>.</p><p>Despite the null results for model-free RL, the positive findings are consistent with the longheld assumption that model-based RL directly corresponds to goal-directed devaluation sensitivity.</p><p>Disorders of compulsivity, such as obsessive-compulsive disorder (OCD), are associated with deficits in both outcome devaluation sensitivity <ref type="bibr">(Gillan et al., 2014;</ref><ref type="bibr" target="#b87">Sjoerds et al., 2013)</ref> and modelbased learning <ref type="bibr">(Voon et al., 2014)</ref>. Similarly, stress responses have a detrimental impact on both outcome devaluation sensitivity <ref type="bibr">(Schwabe and Wolf, 2009)</ref> and model-based learning <ref type="bibr">(Otto et al., 2013)</ref>. In summary, model-based RL might track goal-directed actions whereas model-free RL and habits appear uncorrelated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations of behavioural findings</head><p>These lines of evidence must be interpreted with caution. First, it is possible that the individual tasks that purport to measure outcome devaluation or RL algorithms index some facets of these constructs (e.g., goal-directed sensitivity to outcomes) better than other facets (e.g., habits' role in outcome sensitivity). <ref type="bibr" target="#b96">Watson and de Wit (2018)</ref> suggested that insensitivity to outcome devaluation is a consequence of weak goal-directed control rather than a consequence of habit formation in traditional devaluation tasks. Lesion and knockout studies have demonstrated that there might be dissociable brain regions that independently contribute to goal-directed and habitual learning <ref type="bibr" target="#b60">(Lingawi et al., 2016)</ref>. Additionally, a review of five experiments revealed that it is extremely difficult to induce outcome insensitivity via extensive overtraining <ref type="bibr" target="#b96">(de Wit et al., 2018)</ref> when there are more than one response-outcome contingencies (as is the case in the Friedel et al.</p><p>(2014) experiment). As overtraining is often associated with a shift from goal-directed to habitual behaviour <ref type="bibr" target="#b74">(Ostlund and Balleine, 2008)</ref>, the fact that participants demonstrated outcome insensitivity following extensive overtraining suggests that goal-directed processes and/or strategies remain dominant over the course of outcome devaluation tasks. It is possible to thereby speculate that the null correlation between model-free and habitual behaviour is a consequence of outcome devaluation tests' limited ability to tap on habitual processes. Therefore, future studies should eliminate this possibility by adopting alternative tests of habit formation (e.g., Pavlovian-to-instrumental transfer task; <ref type="bibr" target="#b17">Cartoni et al., 2016)</ref> or by directly examining the construct validity of the selected outcome devaluation test (e.g., by measuring outcome insensitivity following extensive overtraining). Additionally, seemingly model-based behaviour in two-stage decision tasks could arise from model-free RL algorithms. Human participants could potentially utilise a range of strategies in twostep tasks that are not limited to the "win-stay vs. lose-switch" model-free strategy or the "optimal" model-based strategy <ref type="bibr" target="#b22">(Silva and Hare, 2019)</ref>. <ref type="bibr" target="#b1">Akam et al., (2015)</ref> identified several model-free strategies that could masquerade as model-based RL. These model-free agents exploit statistical regularities in the task structure to outperform simple model-based agents. For example, an agent is able to represent chunked Step 1 and Step 2 actions as a single unit (e.g., A1A1, A1A2, A2A1, A2A2). The agent is able to produce behaviour that is similar to that of a model-based agent without learning or encoding the transition probabilities between Step 1 actions and Step 2 states using model-based algorithms. Therefore, seemingly insignificant modifications in task structure or incomprehensive analysis could erroneously identify model-free behaviour as model-based. To improve analytical rigour, the use of models with forgetting-process and gradual-perseveration terms could be important in minimizing estimation biases concerning model-based and model-free RL algorithms <ref type="bibr" target="#b91">(Toyama et al., 2019)</ref>. In the future, it is important for researchers to consider the comprehensive set of model-based and model-free strategies that could be adopted.</p><p>Furthermore, the null correlation between habitual responding and model-free learning could be explained by findings that variations in the balance between model-based and model-free behaviour are primarily driven by variations in the model-based index. Model-based parameters are shown to be more sensitive to experimental manipulations and individual differences <ref type="bibr">(Otto et al., 2013;</ref><ref type="bibr">Voon et al., 2014)</ref>. For example, the balance between model-based and model-free RL is incredibly sensitive to small changes in task procedures that induce model-based behaviour, such as task instructions <ref type="bibr" target="#b22">(Silva and Hare, 2019)</ref>. Additionally, the recruitment of unrepresentative participant demographics (young, educated) could contribute to a predominance of the model-based parameter, resulting in low variability of the model-free index and a low signal-to-noise ratio that masks any true correlations between the model-free and habitual systems. For example, the average weighting parameter in <ref type="bibr">Sjoerds et al. (2016)</ref> and Gillian et al.,'s (2015) studies are 0.70 and 0.86 respectively, indicating that participants were heavily biased towards model-based (vs. model-free) RL. It might be beneficial for future researchers to experimentally manipulate the balance between modelbased/goal-directed and model-free/habitual systems, for example through stress induction <ref type="bibr">(Schwabe and Wolf, 2009)</ref>.</p><p>In general, there exists a need to replicate the finding that model-based RL corresponds to goal-directed behaviour using a much wider range of measures. There is increasing recognition that the model-based versus model-free dichotomy is oversimplified <ref type="bibr" target="#b38">(Silva et al., 2023)</ref>. For example, <ref type="bibr" target="#b37">Doody et al., (2022)</ref> found that model-based learning might retrospectively update model-free values, suggesting that there is crosstalk between the systems. Similarly, the model-based system could be influenced by the model-free system <ref type="bibr">(Moran et al., 2021)</ref>. Therefore, researchers should be careful in task design and statistical analysis to preclude or elucidate the interaction effects between modelbased and model-free indexes. On the other hand, extant studies that investigate the linkage between RL algorithms and goal-directed/habitual systems have primarily focused on outcome value degradation, but not on action-outcome contingency degradation, which is another hallmark of goaldirected behaviour. These two processes could potentially be dissociated at a neural level as insular cortex lesions impaired sensitivity to only outcome degradation but not contingency degradation <ref type="bibr" target="#b6">(Balleine and Dickinson, 1998b)</ref>. Due to the difficulties in establishing a perfect correspondence between outcome degradation and contingency degradation, the current findings on outcome degradation cannot be generalized to the general construct of goal-directed learning. It is possible that the computation of outcome and action values in model-based RL (e.g., via mental stimulation;</p><p>Drummond and Niv, 2020) activates similar processes that underlie outcome valuation in goaldirected learning, but that model-based RL and goal-directed learning are fundamentally dissociable constructs. In the future, researchers could cross-validate the two-step task with a contingency degradation test as another test of the mapping between model-based and goal-directed behaviour.</p><p>Overall, there exists a need to use a wider range of behavioural and non-behavioural measures (e.g., eye-tracking in two-step tasks; Konovalov and Krajbich, 2016).</p><p>Finally, it is important for these variables to be observed and measured under ecologically valid paradigms. The two-step task has been criticised for breaking the world into discrete "states" or "steps" (Balleine and Dezfouli, 2019), which does not reflect decision-making in real life. In the future, decision-making tasks should be extended to environments where participants are free to explore the environment, learn novel actions, and initial responses on their own accord (e.g., free operant actions; <ref type="bibr" target="#b32">Dickinson et al., 1996)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural findings</head><p>The goal-directed network includes regions such as the prefrontal cortex and anterior caudate (including dorsomedial striatum) (Schawbe et al., 2010). Lesions revealed that both of these areas are important for the acquisition of goal-directed behaviour, whereas dorsomedial striatum might be especially important for the expression of goal-directed behaviour <ref type="bibr">(Ostlund and Balleine, 2005;</ref><ref type="bibr">Yin et al., 2005)</ref>. Neuroimaging studies revealed that the medial prefrontal cortex and anterior caudate could be responsible for encoding action-outcome contingencies <ref type="bibr" target="#b51">(Griffiths et al., 2014)</ref> whereas the orbitofrontal cortex might be important for encoding outcome value and current motivational state <ref type="bibr" target="#b71">(Morris and Dolan, 2001;</ref><ref type="bibr" target="#b94">Valentin et al., 2007)</ref>. Crucially, integration of action-outcome contingency and outcome value might take place in the dorsomedial striatum <ref type="bibr" target="#b51">(Griffiths et al., 2014)</ref>. The brain regions that underlie goal-directed behaviour is relatively dissociable from the neural regions associated with habitual behaviour <ref type="bibr" target="#b8">(Balleine and O'Doherty, 2010;</ref><ref type="bibr" target="#b102">Yin and Knowlton, 2006)</ref>.</p><p>Earlier views held that there might be neuroanatomical overlaps between goal-directed learning and model-based RL. A cross-species review suggested that the neural circuitries underlying devaluation sensitivity and model-based learning might overlap <ref type="bibr" target="#b8">(Balleine and O'Doherty, 2010)</ref>.</p><p>Specifically, magnetic resonance imaging (MRI) data found that individual differences in the tendency to engage in model-based (vs. model-free) actions positively correlate with gray matter volume in the caudate, medial orbitofrontal cortex, and lateral prefrontal cortices, which are regions important for goal-directed control <ref type="bibr" target="#b95">(Voon et al., 2015)</ref>. In contrast, there are no clear neural overlaps between the regions that represent habits and model-free learning <ref type="bibr" target="#b27">(Daw and O'Doherty, 2014)</ref>, which aligns with the (null) behavioural findings.</p><p>However, model-free and model-based RL processes recruit many overlapping areas, invalidating the view that goal-directed networks only overlap with model-based RL networks <ref type="bibr" target="#b23">(Daw et al., 2011;</ref><ref type="bibr" target="#b35">Doll et al., 2012;</ref><ref type="bibr" target="#b98">Wimmer et al., 2012)</ref>. For example, a study that combined functional magnetic resonance imaging (fMRI) and the two-step task found that ventral striatum signals reflect both model-free and model-based computations <ref type="bibr" target="#b23">(Daw et al., 2011)</ref>. Although striatal dopamine signals could potentially represent reward prediction errors that form the basis of temporal difference learning algorithms (a form of model-free RL) <ref type="bibr">(Schultz et al., 1997;</ref><ref type="bibr" target="#b10">Bayer and Glimcher, 2005;</ref><ref type="bibr" target="#b16">Caplin and Dean, 2008)</ref>, they also respond to task structure in higher-order, complex tasks (e.g., <ref type="bibr" target="#b12">Bromberg-Martin et al., 2010)</ref>. Thus, they are not merely a model-free reward prediction error signal.</p><p>Despite the lack of evidence suggesting distinct neuroanatomical substrate underlying modelbased versus model-free RL algorithms <ref type="bibr" target="#b22">(Silva and Hare, 2019)</ref>, evidence points towards neuroanatomically distinct striatal systems that process goal-directed and habitual actions <ref type="bibr" target="#b8">(Balleine and O'Doherty, 2010)</ref>. Additionally, neural networks implicated in model-based and model-free RL mainly overlap with regions responsible for processing goal-directed actions rather than regions that process habits <ref type="bibr" target="#b8">(Balleine and O'Doherty, 2010)</ref>. Taken together, these neural findings suggest that 1.) the model-based and model-free dichotomy is oversimplified <ref type="bibr" target="#b19">(Collins and Cockburn, 2020)</ref>, and that 2.) habits might operate in a manner that is largely independent of model-based or model-free RL mechanisms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations of neural findings</head><p>First, findings that both model-based and model-free reward prediction error signals co-exist simultaneously in the ventral striatum might be spurious <ref type="bibr" target="#b38">(Silva et al., 2023)</ref>. The researchers argued that previous studies failed to distinguished between second step-and feedback-evoked signals.</p><p>When adjusted for these confounds, they could not find model-free reward prediction error signals in any brain region during the second step of the two-step task.</p><p>Second, imaging studies that investigate striatal signals (e.g., <ref type="bibr" target="#b23">Daw et al., 2011)</ref> could only assume that these signals are attributed to dopamine activity and not to alternative types of striatal activity (e.g., amino acid neurotransmission). To specifically associate the striatal signals with dopaminergic transmissions, voltammetric procedures could be considered. Although researchers have recently devised animal analogues of the two-step task, they used pharmacological inactivation methods that could have caused the lesion to extend beyond the loci of interest (e.g., <ref type="bibr" target="#b66">Miller et al., 2017</ref>). In contrast, other studies that combined modern calcium imaging/optogenetics techniques and animal-based two-step tasks produced stronger causal evidence that certain areas (e.g., anterior cingulate cortex) are necessary nodes in the model-based control network <ref type="bibr" target="#b2">(Akam et al., 2020</ref><ref type="bibr" target="#b3">, Akam et al., 2021</ref>. The mapping of nodes and interactions between nodes in animal-based, causal RL studies is a promising avenue of neuroscience research that could yield mechanistic insights into RL algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative theoretical perspectives</head><p>Are there better computational algorithms that account for habitual and goal-directed control?</p><p>If so, should we do away with the model-based and model-free framework? To answer these questions, any alternative theory to the model-based/model-free framework must consider a few critical challenges that plague the current RL literature. First, the theory must provide satisfactory explanations for the behavioural and neural dissociations between habits and model-free learning.</p><p>Second, it must yield testable hypotheses that apply to a wide range of behavioural measures that are robust, ecologically valid, sensitive to the underlying construct, and comprehensively represent the criteria for goal-directed and habitual behaviour (e.g., both outcome and contingency devaluation).</p><p>Third, it should attempt to reconcile findings from different levels of analyses, such as computational, behavioural, neural, clinical, and developmental perspectives. Finally, it should make explicit the computational mechanisms by which habitual and goal-directed control interact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative dichotomies</head><p>A class of theories argue that the distinction between goal-directed and habitual behaviour could be formalized using alternative dichotomies of computational algorithms. For example, goaldirected and habitual control could be distinguished using a value-based versus value-free dichotomy <ref type="bibr" target="#b67">(Miller et al., 2018)</ref>, a belief-based versus belief-free dichotomy <ref type="bibr" target="#b41">(Friston et al., 2016)</ref>, or memorybased/verbal-based taxonomies (e.g., <ref type="bibr" target="#b57">Hikosaka et al., 2017;</ref><ref type="bibr" target="#b4">Ashby and Maddox, 2011)</ref>. We will focus our discussion on the most widely explored framework of value-based versus value-free mechanisms.</p><p>The value-based versus value-free framework addresses the challenges that 1.) habits do not seem to correspond to model-free learning, and that 2.) model-based and model-free RL share many overlapping neural circuits. According to alternate definitions of habits (e.g., <ref type="bibr">Wood and Runger, 2016)</ref>, habits strengthen through repetition of prior actions without requiring that they are positively reinforced. The theory argues that habits operate via simple, direct, Hebbian stimulus-response associations. In contrast, goal-directed control is driven by representations of expected value or utility, where actions are chosen based on their expected rewards. Both model-based and model-free RL agents operate within this value-based system and correspond to different goal-directed mechanisms. Crucially, the value-based and value-free systems are not binary, but rather vary on a continuum, with initially value-based goals-directed actions gradually transitioning to value-free habits <ref type="bibr" target="#b92">(Tricomi et al., 2009)</ref>.</p><p>The value-based/value-free framework is able to explain some findings that the modelbased/model-free framework fails to explain. First, value-free habits could explain behavioural perseverance in the absence of instrumental feedback <ref type="bibr">(Miller et al., 2016)</ref> whereas model-free habits could not. Therefore, the value-based/value-free framework might represent a valuable perspective in clinical research (e.g., addiction). Additionally, model-based and model-free processes activate overlapping neural regions as they recruit a common network of goal-based control networks, such as the prefrontal cortex, basal ganglia, and dopamine circuits <ref type="bibr">(Miller et al., 2019)</ref>. In contrast, habits are supported by separate neural processes that support basic, Hebbian associative learning. Another strength of the value-based/value-free proposal is its parsimonious explanations and descriptions of goal-based versus habitual mechanisms. Nevertheless, the value-based/value-free framework has a few critical limitations. First, the model equivocates on the underlying computational processes and neural circuitries that could produce different flavours (model-based versus model-free) of goal-directed behaviour. Additionally, the framework states that value-based or motivational-based learning could still optionally play a role in a value-free system, for example as a modulator of habit strength <ref type="bibr">(Miller et al., 2019)</ref>. However, it fails to sufficiently distinguish between such a proposed mechanism and the operations of the valuebased controller that also uses expected values to adjust decision variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchical frameworks -motor actions</head><p>In contrast to theories that map goal-directed and habitual actions to different computational dichotomies, another class of theories asserts that goal-directed and habitual actions form a single action hierarchy, in which model-based and model-free control operate at different levels. Balleine and Dezfouli's (2012; 2019) action sequences model aims to explain the experimental challenges in mapping habits to model-free RL. The action sequences model presents a hierarchical interaction between goal-directed and habitual actions, and proposes that certain types of habits are model-based sequences of chained actions. As goal-directed actions transition to being habitual over time, they gradually become part of a larger, integrated, "chunked" sequence of actions. The agent encodes the entire sequence as a single unit of action and executes the chunk without further feedback from individual actions' outcomes.</p><p>For example, we tie our shoelaces by activating the higher-order, abstract idea of "tie my shoes", without considering the actions and outcomes associated with every single step.</p><p>The theory proposes that certain types of actions traditionally classified as model-free in the two-step task are actually model-based action sequences. These action sequences comprise a pair of actions from Step 1 and Step 2 (e.g., A1A1, A1A2, A2A1, A2A2), and are executed without consideration of the Step 2 state the agent transitions to. In other words, these action sequences operate as a single unit with a single estimated action value. If the action sequence is rewarded, the agent updates its internal model of the environment -which does not explicitly compute transition probabilities -and is more likely to select the same action sequence again in the next trial. If the action sequence is not rewarded, the agent is more likely to switch to another action sequence. Therefore, seemingly model-free behaviour can emerge from purely model-based RL in two-step tasks with binary terminal reward states.</p><p>As opposed to other models that conceptualize goal-directed and habitual actions using alternative dichotomies (i.e., not model-based or model-free RL), the action sequences model embeds habitual actions in an action hierarchy that ranges from single-step actions to multi-stage actionsequences, and proposes that model-based and model-free RL operate at different levels within this hierarchy. Within the hierarchical architecture, habits allow the goal-directed system to more efficiently execute habit-linked, chained sequences of actions.</p><p>Importantly, the action sequences model claims that habits could represent either modelbased action sequences or model-free "single-step" actions (i.e., single-step in the sense that it only encodes the Step 1 action). To experimentally distinguish between model-based action sequences and model-free single-step actions in the two-step task, <ref type="bibr" target="#b70">Morris and Cushman (2019)</ref>  The action sequences model solves a few key computational challenges that would be difficult for the standard model-based/model-free interpretations. First, it can better explain the phenomenon that overtrained animals are insensitive to contingency devaluation (Dezfouli and <ref type="bibr">Balleine, 2012</ref>). The standard model-free RL view would predict that after extensive overtraining, reward prediction errors are at a minimum and any subsequent reward prediction errors would have a huge effect on performance. In contrast, the action sequences model argues that agents gradually become insensitive to contingency changes between habit-linked chunks within an action sequence.</p><p>Second, the action sequences model accords with recent data <ref type="bibr">(Halbout et al., 2019)</ref> suggesting that rats use two different strategies (action chunks vs. single-step actions) in a free-operant lever pressing task. Finally, it is able to explain more variance in the two-step task (Dezfouli and Balleine, 2013).</p><p>Model-based and model-free RL algorithms were unable to predict and explain Step 2 choices. In contrast, Bayesian comparison of model families reveal that a hierarchical RL model could explain both Step 1 and Step 2 choices better than competing models (e.g., non-hierarchical and hybrid models) across human and animal data.</p><p>Additionally, the action sequences model also compares favourably to alternative and similar models. For example, <ref type="bibr" target="#b20">Cushman and Morris (2015)</ref> proposed a reversed hierarchical relationship whereby a model-free controller generates goal-directed actions (e.g., habitual response of starting an assignment 3 hours before the deadline). However, the theory poorly defines habits in terms of vague higher-order cognition whereas the action sequences model defines habits using concrete and specific motor processes. Nevertheless, it remains an intriguing possibility that goal-directed control and habits interact in hierarchical fashions over different psychological scales. Alternatively, <ref type="bibr" target="#b58">Keramati et al., (2016)</ref> proposed a "planning until habit" approach whereby a goal-directed planner initiates actions for the initial few steps before model-free habits take over and complete the actions. However, the crux of this theory hinges on the intractable problem of model-free habits whereas the action sequences model delineates specific scenarios where model-based habits could operate. Crucially, the action sequences model is not mutually exclusive with the value-free/value-based perspective if action sequences are conceptualized as value-free habits nested within a value-based controller.</p><p>However, the value-free/value-based framework struggles to explain the finding that action chunks are less sensitive to outcome devaluation compared to single-step actions <ref type="bibr">(Halbout et al., 2019)</ref> when these single-step actions are supposedly value-free.</p><p>There are a few limitations of the action sequences model. First, it points out that modelbased habits could exist in the motor domain but equivocates on its descriptions of model-free habits, which remain an unsolved problem. In fact, behavioural results suggesting model-free control of single-step actions could be produced by model-based algorithms with false beliefs <ref type="bibr" target="#b70">(Morris and Cushman, 2019)</ref>. Second, the evidence suggesting that action sequences are model-based rather than model-free is weak. Model-fitting data indicated that agents used both model-based and model-free RL to evaluate action sequences in a sub-experiment <ref type="bibr" target="#b70">(Morris and Cushman, 2019)</ref>. In fact, <ref type="bibr" target="#b1">Akam et al., (2015)</ref> demonstrated model-free control of action sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchical frameworks -active inference</head><p>Active inference <ref type="bibr" target="#b77">(Pezzulo et al., 2015</ref>) is a theoretical framework that explains individuals' choices and beliefs in their environments. It suggests that individuals aim to minimize prediction errors. The degree of precision or confidence assigned to different types of information (e.g., priors, beliefs, sensorimotor information) are crucial determinants in balancing between modes of behaviour.</p><p>Active inference is usually studied in exploration versus exploitation contexts. When faced with uncertain environments and multiple options, agents face the exploration-exploitation dilemma <ref type="bibr" target="#b49">(Gijsen et al., 2022)</ref>. Agents have to actively weigh the trade-offs between exploring new options and gathering information versus exploiting known options to maximize rewards. Exploration entails actively seeking out new information and experimenting with different actions to reduce uncertainty and adapt to changing environments. Directed exploration is a subset of the exploration process that aims to maximize information gain, and has been linked to the goal-directed system <ref type="bibr" target="#b14">(Brands et al., 2023)</ref>. In contrast, exploitation utilizes existing knowledge and selects valuable actions based on the assumption that past success is a reliable indicator of future rewards.</p><p>Although there have been recent attempts to synthesize active inference and RL <ref type="bibr" target="#b64">(Marino and Yue, 2019)</ref>, active inference traditionally characterizes goals and habits in more nuanced ways compared to a simple model-based versus model-free dichotomy <ref type="bibr" target="#b77">(Pezzulo et al., 2015;</ref><ref type="bibr">Schwobel et al., 2020)</ref>. A model-based, goal-directed exploration process is carried out when its expected benefits (e.g., information gains) outweighs its computational costs. Otherwise, habitual actions that exploit current actions and rewards should occur. The active inference model's characterization of habits diverges from the model-free description of habits. <ref type="bibr" target="#b77">Pezzulo et al. (2015)</ref> proposes that model-based and model-free controllers occupy different levels on a hierarchical continuum. Compared to the aforementioned action sequence hierarchies, active inference refers to a more general hierarchy that ranges from modelbased, goal-directed cognition to model-free, low-level sensorimotor processes (e.g., arc reflex).</p><p>Higher-order levels send descending feedback projections to lower-order levels that carry contextualization information. The strength of this feedback depends on the balance between the precision of higher-level information and the precision of lower-level sensorimotor information, with decision-making weighted towards more precise information.</p><p>Within this framework, devaluation in instrumental behaviour is described as high-level motivational information appropriately contextualizing low-level instrumental inference. On the other hand, resistance to devaluation (e.g., in overtrained animals; <ref type="bibr">Balleine and Dickinson, 1998)</ref> is characterized as an inability of high-level motivational information to contextualize low-level sensory (prediction error) information that gained a high degree of precision from overtraining. Therefore, habits are not necessarily best represented as model-free RL algorithms, but rather arise from precise prediction errors. In the context of the exploration-exploitation dilemma, the model predicts that a high degree of confidence or precision in low-level actions and plans lead to less exploratory and more habit-like exploitation behaviour (e.g., pressing a lever repeatedly instead of exploring other levers). In contrast, goal-directed exploration dominates when high-level contextual, environmental, or cognitive information are precise and valuable.</p><p>Crucially, active inference's characterization of habits aligns with the value-free description of habits. Habits are viewed as simple stimulus-response pairs that do not utilise reward information.</p><p>Therefore, dopamine does not encode reward prediction errors, but rather the precision of multimodal prediction errors at different stages of the hierarchical continuum. For example, the dorsolateral striatum might be able to generate simple predictions based on motor and somatosensory information <ref type="bibr" target="#b76">(Pennartz et al., 2011)</ref>. An extension of the active inference framework suggests that habits could form via the "caching" or "compression" of goal-directed, model-based polices, strategies, or actions (e.g., through chunking of actions into sequences), which aligns with the action sequence model <ref type="bibr" target="#b63">(Maisto et al., 2019)</ref>. Stimulated active inference agents are able to display various key hallmarks of habits, including insensitivity to outcome and contingency degradation, increased habit strength after overtraining, and contextual renewal of habitual responses <ref type="bibr">(Schwobel et al., 2020)</ref>. Critically, the agents are able to display typical behavioural performance on the two-step task with using modified active inference models that included environment-specific variables (e.g., forgetting factor for rewards). In another study, re-analyses of four publicly available datasets on the human two-step task revealed that two datasets are better described by active inference and the other two datasets are better described by model-based inference <ref type="bibr" target="#b49">(Gijsen et al., 2022)</ref>. In the former two datasets, active inference performed better due to its ability to model probabilistic inferences and exploration behaviour. Therefore, active inference is not only able to theoretically account for goal-directed and habitual actions, it might also better explain experimental data in the two-step task.</p><p>In the context of goal-directed and habitual actions, one key reason for active inference's potentially superior theoretical and computational properties relates to its description of the environment that humans operate in. Active inference aims to model actions in a natural, foraginglike environment that contains exploration and exploitation behaviour. In contrast, model-based and model-free RL's description of goal-directed and habitual actions is primarily based on two-step tasks, which only capture a limited portion of human behaviour <ref type="bibr">(Silva and Hare, 2020)</ref>. First, agents in the two-step task are able to observe the entire environment whereas humans often operate in partially-observable environments <ref type="bibr" target="#b64">(Marino and Yue, 2019)</ref>. Second, the two-step task breaks the world into discrete "states" or "steps" <ref type="bibr" target="#b5">(Balleine and Dezfouli, 2019)</ref> whereas humans often freely interact with the environment and initiate responses. As a result, humans might not receive reward information about their selected actions immediately or at all <ref type="bibr" target="#b49">(Gijsen et al., 2022)</ref>. Even in the twostep task, active inference could capture variances in naturalistic behaviour like exploration, which model-based and model-free RL algorithms fail to do <ref type="bibr" target="#b49">(Gijsen et al., 2022)</ref>. Another study demonstrated that model-based RL algorithms, when coupled with heuristic-based exploration mechanisms, provide the best fit for the data <ref type="bibr" target="#b14">(Brands et al., 2023)</ref>.</p><p>To summarise, active inference model provides a potentially unifying computational framework of goal-directed and habitual actions that incorporates elements of other theories (e.g., value-free habits and model-based action sequences). Under this view, model-based control corresponds to goal-directed contextualization of lower-level hierarchical processes and goal-directed exploration behaviour. On the other hand, habits could be better characterized by value-free actions that occur when low-level sensorimotor precision and/or computational costs are high. A future avenue of research would involve synthesis of different active inference models that utilise different computational mechanisms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biologically-based models</head><p>There exists limited discussion on how these computational mechanisms, whether RL or active inference, could be instantiated in the brain. It is crucial to not only integrate these two levels of descriptions, but also build and modify computational models that are neurologically plausible and valid.</p><p>It is possible that a common set of neural mechanisms underlie both model-based and modelfree learning. As we have previously explored, model-based and model-free RL algorithms have overlapping neural substrates in the brain. Therefore, it has been suggested that successor representation <ref type="bibr" target="#b80">(Russek et al., 2017)</ref> could stem from a common striatal system and could act as an intermediate representation between model-based and model-free RL. Simulations show that successor representations could explain how dopaminergic temporal difference learning underlies both model-free and model-based learning. Specifically, dopamine in different regions of the striatum might compute different types of information that ultimately leads to model-based and model-free learning <ref type="bibr" target="#b11">(Bogacz, 2020)</ref>. For example, model-based-like outcome valuations and predictions take place in the ventral and dorsomedial striatum whereas model-free-like simple prediction errors take place in the dorsolateral striatum <ref type="bibr" target="#b76">(Pennartz et al., 2011)</ref>.</p><p>These diverse dopaminergic signals could then form the inputs to frontostraital loops that underlie both goal-directed and habitual decision-making <ref type="bibr" target="#b73">(O'Reilly et al., 2020)</ref>. The author proposes a proposer-predictor-actor-critic model that involves multiple, nested processing loops that include the basal ganglia, prefrontal cortex, and dopaminergic system. The cortical "proposer" uses information about the current situation to produce candidate plan representations. The cortical "predictor" then estimates the likely outcome or reward of this action plan. The basal ganglia "actor" uses the predicted outcome of the proposed action to either accept or reject the plan. The dopamine release system (amgydala, ventral striatum, and related areas) serves as a "critic" by comparing the expected outcome of the action with the observed outcome, and sends the reward prediction error to the basal ganglia actor system. Critically, the authors argue that the relationship between model-based/model-free RL and goal-directed/habitual actions break down under this model. Despite the fact that the model putatively processes both goal-directed and habitual actions, the computations of the basal ganglia remain simple (value-based Go/NoGo decision) and are analogous to model-free computations.</p><p>Therefore, the authors argue that there is a necessary model-free component to goal-directed actions.</p><p>More generally, due to the recursive and nested nature of these processing loops, the basal ganglia essentially act as an arbiter of how much resource should be invested into any decision, plan, routine, or sub-routine. The implication follows that even habitual behaviour might depend on model-based computations to inhibit goal-directed actions. In short, the central argument is that when sub-computations are delegated to a series of sequential, simple neural networks, it is possible to have model-free computations in goal-directed actions, or model-based computations in habits. Nevertheless, the model is underdeveloped. It only assigns high-level responsibilities to these brain regions and equivocates on the specific computational mechanisms that they serve. Additionally, it localizes specific functions to specific brain areas, but the same brain area could serve different functions. For example, more recent animal studies have shown that the anterior cingulate cortex could predict the state that actions will lead to, and monitor whether outcomes match these predictions <ref type="bibr" target="#b3">(Akam et al., 2021)</ref>. In contrast, the model only delegates the outcome-monitoring function to the dopaminergic subcortical system. Along the same lines, the striatal dopaminergic system might carry out both model-based and model-free computations <ref type="bibr" target="#b76">(Pennartz et al., 2011)</ref>, which the model fails to account for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Putting it all together</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>The allure and intuitiveness of a goal-directed/habitual and model-based/model-free mapping have meant that this framework is firmly and habitually entrenched in many areas of psychology.</p><p>Our review of behavioural and neural findings reveals a putative correspondence between goaldirected and model-based RL algorithms. Behavioural parameters of both constructs show moderate correlation and neural substrates of both constructs show partial overlap. On the other hand, there is very strong evidence against the habits/model-based mapping. Behavioural parameters of both constructs do not correlate and neural substrates of both constructs are distinct. These findings, however, are plagued by a few key limitations. First, it is unclear why model-based and model-free RL tap on overlapping neural regions. Second, model-based RL is unable to explain all the statistical variance and criterion (contingency degradation) associated with goal-directed actions. Finally, there exists many methodological shortcomings especially in the behavioural data, such as insensitive/inappropriate measures and an overreliance on the two-step task.</p><p>We then reviewed multiple theoretical classes of computational mechanisms that underlie goal-directed and habitual actions. Most of these alternative frameworks agree with a modelbased/goal-directed mapping but differ in their conceptualization of habits. Some scholars argue that the distinction between goal-directed and habitual actions is better formalized under different dichotomies/continua, such as under a value-based / value-free framework. Alternatively, the action sequences model argues that habits could be model-free single-step actions or model-based action sequences. The active inference framework conceptualizes habits as a failure of higher-order processes to contextualize low-level sensorimotor information that have high precision. Finally, some neurocomputational approaches aim to delegate goal-directed and habitual processes to different nodes in a neural network. A possible implication of this view is that behaviour is a consequence of multiple, complex, and interacting computations which could be either model-based or model-free in nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications and next steps</head><p>One possible approach involves integrating these theories into a unifying framework. There is agreement between the value-free/value-based framework and the active inference framework that habits are value-free in nature. Additionally, many models suggest that there exists a hierarchical relationship between the constructs, for example higher-level, model-based action sequences versus low-level, model-free actions, or higher-level, goal-directed/model-based contextualization that interacts with lower-level habits. These models also flesh out multiple ways in which goaldirected/model-based processes interact with habitual/model-free processes, such as the gradual transition from goals-directed actions to habits. One example unifying framework could include an active inference theory with value-free habits and action sequences in the form of cached action policies.</p><p>However, we would argue that attempts to create such "Frankensteined" theories run into many fundamental challenges. These theories aim to solve different problems, draw on different parts of the literature, and are based on different assumptions and paradigms. For example, the value-based / value-free framework is well-suited to tackle neural questions regarding valuation-based and valuefree processes in the brain. The action sequences framework pertains to a specific subset of motor actions. The active inference framework is powerful in its ability to contextualize goal-directed and habitual actions under a range of decision-making environments (e.g., foraging). Neuroscience, on the other hand, shows promise in its ability to systematically map out the nodes and interaction between nodes in the goal-directed and habitual networks. Therefore, it is very difficult to directly compare the utilities of these models as they operate on different levels of analyses, complementing and contradicting each other at the same time.</p><p>Instead, future research should start by establishing shared and standardized terminologies for these key constructs of goal-directed / habitual and model-based / model-free processes. Additionally, future research should also investigate and operate at different levels of analyses within the same study to facilitate the process of piecing the different puzzle pieces together. More effort should also be directed towards validating the current measures or devising new measures of these constructs.</p><p>Importantly, the fact that model-based and model-free RL algorithms might not neatly map onto goal-directed and habitual processes does not mean that we should do away with these RL findings and investigations. RL can be a powerful normative theory that does not necessarily have to converge with descriptions of the goal-directed / habitual processes. With the advent of artificial intelligence, model-based and model-free RL represents powerful tools and paradigms in the computer scientist's toolbox. Clinically, RL can uncover mechanisms that have gone awry and deviate from optimal goal-directed or habitual processes (e.g., <ref type="bibr" target="#b83">Seow et al., 2021)</ref>. Developmentally, RL research has yielded fruitful insights into the gradual maturation of a goal-directed and modelbased cognitive system across adolescence and adulthood <ref type="bibr" target="#b28">(Decker et al., 2016)</ref>. In fact, performance on the two-step task has been used to distinguish between developmental disorders <ref type="bibr" target="#b72">(Nissan et al., 2023)</ref>. Additionally, the widespread interest in RL has generated many new studies and unexpected findings in the areas of goal-directed and habitual research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>Model-based RL maps onto certain facets of goal-directed actions (e.g., outcome sensitivity) but not necessarily onto others (e.g., contingency sensitivity). On the other hand, there is much evidence suggesting that model-free RL does not track habit formation or expression.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>of Contents Outline ...................................................................................................................................................Introduction ..........................................................................................................................................</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>modified the terminal reward states such that rewards are not binary and are graded (e.g., 10 reward values). It logically follows that model-free actions should ignore information about Step 2 actions, whereas model-based action sequences should distinguish between Step 2 actions that lead to differentiated reward outcomes. The researchers found both types of actions, leading to the suggestion that modelbased action sequences operate at higher levels of the action hierarchy whereas model-free singlestep actions operate at lower levels of the action hierarchy. A follow-up experiment demonstrated that the action sequence "units" are model-based and not model-free by showing that action sequences are able to encode novel Step 2 states without affecting current action sequence values (i.e., the introduction of State 4 does not affect action sequences that involve States 2 and 3). In short, habits could be higher-level, model-based action sequences, or lower-level, model-based single-step actions. Goal-directed actions, on the other hand, represent higher-level, model-based sequences that consist of nested habit-linked actions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Variations in the sensitivity of instrumental responding to reinforcer devaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Adams</surname></persName>
		</author>
		<idno type="DOI">https://psycnet.apa.org/doi/10.1080/14640748208400878</idno>
		<ptr target="https://doi.org/10.1080/14640748208400878" />
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology B: Comparative and Physiological Psychology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="98" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Simple Plans or Sophisticated Habits? State, Transition and Learning Interactions in the Two-Step Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1004648</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1004648" />
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Anterior cingulate cortex represents action-state predictions and causally mediates modelbased reinforcement learning in a two-step decision task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rodrigues-Vaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Marcelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Costa</surname></persName>
		</author>
		<idno type="DOI">10.1101/126292</idno>
		<ptr target="https://doi.org/10.1101/126292" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Anterior Cingulate Cortex Predicts Future States to Mediate Model-Based Action Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rodrigues-Vaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Marcelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Costa</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2020.10.013</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2020.10.013" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="149" to="163" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Human category learning 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">G</forename><surname>Ashby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Maddox</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1749-6632.2010.05874.x</idno>
		<ptr target="https://doi.org/10.1111/j.1749-6632.2010.05874.x" />
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1224</biblScope>
			<biblScope unit="page" from="147" to="161" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical action control: Adaptive collaboration between actions and habits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dezfouli</surname></persName>
		</author>
		<idno type="DOI">https://psycnet.apa.org/doi/10.3389/fpsyg.2019.02735</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2019.02735" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Goal-directed instrumental action: contingency and incentive learning and their cortical substrates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropharmacology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="407" to="419" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/s0028-3908(98</idno>
		<ptr target="https://doi.org/10.1016/s0028-3908(98" />
		<imprint>
			<biblScope unit="page" from="33" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Human and rodent homologies in action control: corticostriatal determinants of goal-directed and habitual action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychopharmacology : official publication of the American College of Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="69" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/npp.2009.131</idno>
		<ptr target="https://doi.org/10.1038/npp.2009.131" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Midbrain dopamine neurons encode a quantitative reward prediction error signal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2005.05.020</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2005.05.020" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="129" to="141" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Dopamine role in learning and action inference. eLife, 9</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.53262</idno>
		<ptr target="https://doi.org/10.7554/eLife.53262" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dopamine in motivational control: rewarding, aversive, and alerting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Bromberg-Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hikosaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="815" to="834" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2010.11.022</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2010.11.022" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Signatures of heuristic-based directed exploration in two-step sequential decision task behaviour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Brands</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mathar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
	<note>bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Social norms, self-control, and the value of antisocial behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Buckholtz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2015.03.004</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2015.03.004" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="122" to="129" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dopamine, Reward Prediction Error, and Economics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caplin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/25098912" />
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="663" to="701" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Appetitive Pavlovian-instrumental Transfer: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cartoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Balleine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Baldassarre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience and biobehavioral reviews</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="829" to="848" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neubiorev.2016.09.020</idno>
		<ptr target="https://doi.org/10.1016/j.neubiorev.2016.09.020" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Beyond dichotomies in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G E</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cockburn</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41583-020-0355-6</idno>
		<ptr target="https://doi.org/10.1038/s41583-020-0355-6" />
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="576" to="586" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Habitual control of goal selection in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="13817" to="13822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1506367112</idno>
		<ptr target="https://doi.org/10.1073/pnas.1506367112" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Humans are primarily model-based and not model-free learners in the two-stage task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Model-based influences on humans&apos; choices and striatal prediction errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1204" to="1215" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2011.02.027</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2011.02.027" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1704" to="1711" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/nn1560</idno>
		<ptr target="https://doi.org/10.1038/nn1560" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiple Systems for Value Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-0-12-416008-8.00021-8</idno>
		<ptr target="https://doi.org/10.1016/B978-0-12-416008-8.00021-8" />
	</analytic>
	<monogr>
		<title level="m">Neuroeconomics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="393" to="410" />
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">From Creatures of Habit to Goal-Directed Learners: Tracking the Developmental Emergence of Model-Based Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hartley</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797616639301</idno>
		<ptr target="https://doi.org/10.1177/0956797616639301" />
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="848" to="858" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De Wit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kindt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Knot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A C</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gasull-Camos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Evans</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Shifting the balance between goals and habits: Five failures in experimental habit induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Gillan</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000402</idno>
		<ptr target="https://doi.org/10.1037/xge0000402" />
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology. General</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1043" to="1065" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Corticostriatal connectivity underlies individual differences in the balance between habitual and goal-directed action control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De Wit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Harsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Van De Vijver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Ridderinkhof</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1088-12.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.1088-12.2012" />
	</analytic>
	<monogr>
		<title level="j">The Journal of neuroscience : the official journal of the Society for Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">35</biblScope>
			<biblScope unit="page" from="12066" to="12075" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Context conditioning and free-operant acquisition under delayed reinforcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Watt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">I</forename><surname>Varga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology B: Comparative and Physiological Psychology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="110" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Goals and habits in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="312" to="325" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2013.09.007</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2013.09.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The ubiquity of model-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Doll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current opinion in neurobiology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1075" to="1081" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.conb.2012.08.003</idno>
		<ptr target="https://doi.org/10.1016/j.conb.2012.08.003" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Model-based learning retrospectively updates model-free values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Doody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M H</forename><surname>Van Swieten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Manohar</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-05567-3</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-05567-3" />
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rethinking model-based and model-free influences on mental effort and striatal prediction errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feher Da Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lombardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Edelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Hare</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01573-1</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-" />
	</analytic>
	<monogr>
		<title level="j">Nature human behaviour</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Reverse replay of behavioural sequences in hippocampal place cells during the awake state</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature04587</idno>
		<ptr target="https://doi.org/10.1038/nature04587" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">440</biblScope>
			<biblScope unit="page" from="680" to="683" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Devaluation and sequential decisions: linking goal-directed and model-based behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Friedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wendt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schlagenhauf</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2014.00587</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2014.00587" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in human neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The dysconnection hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Siemerkus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.schres.2016.07.014</idno>
		<ptr target="https://doi.org/10.1016/j.schres.2016.07.014" />
	</analytic>
	<monogr>
		<title level="j">Schizophrenia research</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Functional neuroimaging of avoidance habits in obsessive-compulsive disorder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Gillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Apergis-Schoute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Morein-Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Urcelay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sule</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Fineberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Sahakian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American journal of psychiatry</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="284" to="293" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<idno type="DOI">10.1176/appi.ajp.2014.14040525</idno>
		<ptr target="https://doi.org/10.1176/appi.ajp.2014.14040525" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Model-based learning protects against forming habits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Gillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Phelps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive, affective &amp; behavioral neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="523" to="536" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13415-015-0347-6</idno>
		<ptr target="https://doi.org/10.3758/s13415-015-0347-6" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Gillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Sahakian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Van Den Heuvel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Wingen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">European neuropsychopharmacology : the journal of the European College of Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="828" to="840" />
		</imprint>
	</monogr>
	<note>The role of habit in compulsivity</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.euroneuro.2015.12.033</idno>
		<ptr target="https://doi.org/10.1016/j.euroneuro.2015.12.033" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Active inference and the two-step task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gijsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grundei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Blankenburg</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-21766-4</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-21766-4" />
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">17682</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gläscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2010.04.016</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2010.04.016" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="585" to="595" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Translational studies of goal-directed action as a framework for classifying deficits across psychiatric disorders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Systems Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Article 101</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The effect of contingency upon the appetitive conditioning of free-operant behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Hammond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Experimental Analysis of Behavior</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">297</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<idno type="DOI">https://psycnet.apa.org/doi/10.1901/jeab.1980.34-297</idno>
		<ptr target="https://doi.org/10.1901/jeab.1980.34-297" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Halbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Azimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liljeholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Mahler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Wassum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ostlund</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Mesolimbic dopamine projections mediate cue-motivated reward seeking but not reward retrieval in rats. eLife, 8, e43551</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<idno type="DOI">10.7554/eLife.43551</idno>
		<ptr target="https://doi.org/10.7554/eLife.43551" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deconstructing episodic memory with construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Maguire</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2007.05.001</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2007.05.001" />
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="299" to="306" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Parallel Basal Ganglia Circuits for Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okihide</forename><surname>Hikosaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ghazizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Whitney</forename><surname>Griggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidetoshi</forename><surname>Amita</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00702-017-1691-1</idno>
		<ptr target="https://doi.org/10.1007/s00702-017-1691-1" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neural Transmission</title>
		<imprint>
			<date type="published" when="2017-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Adaptive integration of habits into depth-limited planning defines a habitual-goal-directed spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keramati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smittenaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="12868" to="12873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1609094113</idno>
		<ptr target="https://doi.org/10.1073/pnas.1609094113" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The psychological and physiological mechanisms of habit formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Lingawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dezfouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Wiley handbook on the cognitive neuroscience of learning</title>
		<editor>R. A. Murphy &amp; R. C. Honey</editor>
		<imprint>
			<publisher>Wiley Blackwell</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="411" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lucantonio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bali-Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shaham</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Orbitofrontal activation restores insight lost after cocaine use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Lupica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schoenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3763</idno>
		<ptr target="https://doi.org/10.1038/nn.3763" />
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1092" to="1099" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Caching mechanisms for habit formation in Active Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maisto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2019.05.083</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2019.05.083" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page" from="298" to="314" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">An inference perspective on model-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m">ICML Workshop on Generative Modeling and Model-Based Reasoning for Robotics and AI</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Dorsal hippocampus contributes to model-based planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brody</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.4613</idno>
		<ptr target="https://doi.org/10.1038/nn.4613" />
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1269" to="1276" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Chapter 18-Realigning Models of Habitual and Goal-Directed Decision-Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<editor>R. Morris, A. Bornstein, &amp; A</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shenhav</surname></persName>
		</author>
		<title level="m">Goal-Directed Decision Making</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="407" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/B978-0-12-812098-9.00018-8</idno>
		<ptr target="https://doi.org/10.1016/B978-0-12-812098-9.00018-8" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Model-Free RL or Action Sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2019.02892</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2019.02892" />
	</analytic>
	<monogr>
		<title level="m">Frontiers in psychology</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2892</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Involvement of human amygdala and orbitofrontal cortex in hunger-enhanced memory for food stimuli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.21-14-05304.2001</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.21-14-05304.2001" />
	</analytic>
	<monogr>
		<title level="j">The Journal of neuroscience : the official journal of the Society for Neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="5304" to="5310" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Distinct reinforcement learning profiles distinguish between language and attentional neurodevelopmental disorders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nissan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gabay</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12993-023-00207-w</idno>
		<ptr target="https://doi.org/10.1186/s12993-023-00207-w" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain functions : BBF</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">How Sequential Interactive Processing Within Frontostriatal Loops Supports a Continuum of Habitual to Controlled Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Russin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Herd</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2020.00380</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2020.00380" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">On habits and addiction: An associative analysis of compulsive drug seeking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Ostlund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug discovery today. Disease models</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="235" to="245" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.ddmod.2009.07.004</idno>
		<ptr target="https://doi.org/10.1016/j.ddmod.2009.07.004" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The hippocampal-striatal axis in learning, prediction and goal-directed behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Pennartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Verschure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Robbins</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tins.2011.08.001</idno>
		<ptr target="https://doi.org/10.1016/j.tins.2011.08.001" />
	</analytic>
	<monogr>
		<title level="j">Trends in neurosciences</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="548" to="559" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Active Inference, homeostatic regulation and adaptive behavioural control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rigoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in neurobiology</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.pneurobio.2015.09.001</idno>
		<ptr target="https://doi.org/10.1016/j.pneurobio.2015.09.001" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Regulation of dietary choice by the decision-making circuitry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3561</idno>
		<ptr target="https://doi.org/10.1038/nn.3561" />
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1717" to="1724" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Predictive representations can link model-based reinforcement learning to model-free mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Russek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1005768</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1005768" />
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Learning under stress impairs memory formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schwabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">T</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nlm.2009.09.009</idno>
		<ptr target="https://doi.org/10.1016/j.nlm.2009.09.009" />
	</analytic>
	<monogr>
		<title level="j">Neurobiology of learning and memory</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Balancing control: a Bayesian interpretation of habitual and goal-directed behavior. bioRxiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schwobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Markovi Ć</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Smolka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kiebel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">836106</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Model-Based Planning Deficits in Compulsivity Are Linked to Faulty Neural Representations of Task Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">X F</forename><surname>Seow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dempsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jennings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Gillan</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0031-21.2021</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0031-21.2021" />
	</analytic>
	<monogr>
		<title level="j">The Journal of neuroscience : the official journal of the Society for Neuroscience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="6539" to="6550" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Dorsal anterior cingulate cortex and the value of control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.4384</idno>
		<ptr target="https://doi.org/10.1038/nn.4384" />
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1286" to="1291" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sjoerds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dietrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De Wit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Villringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schlagenhauf</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Slips of Action and Sequential Decisions: A Cross-Validation Study of Tasks Assessing Habitual and Goal-Directed Action Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Horstmann</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnbeh.2016.00234</idno>
		<ptr target="https://doi.org/10.3389/fnbeh.2016.00234" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in behavioral neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Behavioral and neuroimaging evidence for overreliance on habit learning in alcohol-dependent patients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sjoerds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De Wit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Den Brink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transl Psychiatry</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">337</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/tp.2013.107</idno>
		<ptr target="https://doi.org/10.1038/tp.2013.107" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Cognitive maps in rats and men</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Tolman</surname></persName>
		</author>
		<idno type="DOI">https://psycnet.apa.org/doi/10.1037/h0061626</idno>
		<ptr target="https://doi.org/10.1037/h0061626" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="189" to="208" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Biases in estimating the balance between model-free and model-based learning systems due to model misspecification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Katahira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ohira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">A specific role for posterior dorsolateral striatum in human habit learning. The European journal of neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tricomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2225" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.1460-9568</idno>
		<ptr target="https://doi.org/10.1111/j.1460-9568" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Determining the neural substrates of goaldirected learning in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Valentin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0564-07.2007</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0564-07.2007" />
	</analytic>
	<monogr>
		<title level="j">The Journal of neuroscience : the official journal of the Society for Neuroscience</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="4019" to="4026" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Voon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Derbyshire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rück</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Worbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Enander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Fineberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Sahakian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Bullmore</surname></persName>
		</author>
		<idno type="DOI">10.1038/mp.2014.44</idno>
		<ptr target="https://doi.org/10.1038/mp.2014.44" />
	</analytic>
	<monogr>
		<title level="m">Disorders of compulsivity: a common bias towards learning habits</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="345" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Conflicted between Goal-Directed and Habitual Control, an fMRI Investigation. eNeuro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Wingen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De Wit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="240" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/ENEURO.0240-18.2018</idno>
		<ptr target="https://doi.org/10.1523/ENEURO.0240-18.2018" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Preference by association: how memory mechanisms in the hippocampus bias decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Wimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">6104</biblScope>
			<biblScope unit="page" from="270" to="273" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title/>
		<idno type="DOI">10.1126/science.1223252</idno>
		<ptr target="https://doi.org/10.1126/science.1223252" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Psychology of Habit. Annual review of psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rünger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="289" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title/>
		<idno type="DOI">10.1146/annurev-psych-122414-033417</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-122414-033417" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">The role of the basal ganglia in habit formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Knowlton</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn1919</idno>
		<ptr target="https://doi.org/10.1038/nrn1919" />
	</analytic>
	<monogr>
		<title level="j">Nature reviews. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="464" to="476" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
