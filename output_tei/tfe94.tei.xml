<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SHOULD I SAMPLE OR SHOULD I GO</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esin</forename><surname>Turkakin</surname></persName>
							<email>esin.turkakin@ugent.be</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution">Ghent University</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Verguts</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution">Ghent University</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kobe</forename><surname>Desender</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Brain and Cognition</orgName>
								<address>
									<settlement>Leuven</settlement>
									<region>KU</region>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elise</forename><surname>Lesage</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution">Ghent University</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SHOULD I SAMPLE OR SHOULD I GO</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>decision making</term>
					<term>optimality</term>
					<term>urgency</term>
					<term>computational modeling</term>
				</keywords>
			</textClass>
			<abstract>
				<p>All simulation code, analysis code and data have been deposited in a freely accessible depository [insert link upon publication]. All task materials are available upon request.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>How much information would you gather before choosing one brand of coffee over another? If you decide after only a brief look at the packaging, you may end up with a month's supply of mediocre coffee. If you keep comparing the brands for too long, you may well find the perfect coffee, but end up with no time left to pick a good milk to go with it. Life is full of decisions that need to be made based on limited noisy information, and where one must decide how much information is optimal to commit to a choice. Sampling extensively to minimize uncertainty results in more accurate decisions, but also incurs an opportunity cost by consuming limited time resources that can no longer be devoted to other decisions. Striking an optimal balance between sampling sufficient information while not spending excessive time is essential for decision-makers to navigate such problems. In the current work we will investigate whether humans implement optimal strategies about the decision to stop sampling and commit to a choice.</p><p>In sequential sampling models (such as the drift diffusion model; DDM; <ref type="bibr" target="#b31">Ratcliff, 1978)</ref>, the process of decision making is described as an accumulation of evidence towards one of two opposing decision bounds. These models estimate parameters, such as the rate of evidence accumulation (drift rate) and height of the decision bounds, using response time (RT) distributions of accurate and inaccurate decisions. Such models can account for a variety of effects in the decision-making literature, such as the influence of stimulus discriminability on behavior and the trade-off between speed and accuracy <ref type="bibr" target="#b3">(Bogacz et al., 2010)</ref>. More generally, sequential sampling models have yielded great insights into the (neural) mechanism involved in making rapid two-alternative forced choice decisions <ref type="bibr" target="#b14">(Gold &amp; Shadlen, 2007;</ref><ref type="bibr" target="#b33">Ratcliff et al., 2016)</ref>.</p><p>Some parameters of sequential sampling models, such as the height of the decision bound, are thought to be under the strategic control of the agent. When participants are instructed to make fast SHOULD I SAMPLE OR SHOULD I GO 4 versus accurate decisions, model fits reveal that participants can indeed strategically decrease or increase the decision boundary, respectively. In the absence of such explicit instructions, however, the question arises on what basis the observer would set the decision bound at a specific value. Given that the decision bound controls the trade-off between speed and accuracy, a useful exercise is to consider the consequences of making an error. If the consequences of making an incorrect decision are large, agents should set a higher decision bound in order to strive for a higher accuracy level (accepting the cost of an increased RT). Conversely, when time resources are scarce, agents should set lower decision boundaries in order to make fast decisions (accepting the cost of decreased accuracy). Theoretical work has shown that, if there are just two competing choices, implementing a constant boundary allows the highest possible level of accuracy for a given RT to be achieved; and the lowest RT for a given level of accuracy <ref type="bibr" target="#b2">(Bogacz et al., 2006;</ref><ref type="bibr" target="#b39">Wald, 1947)</ref>. However, although much research has studied whether parameters such as the decision bound change across conditions, whether such changes are in fact optimal remains unclear.</p><p>From a reinforcement learning perspective, the optimal policy is not necessarily to be as fast or as accurate as possible. Instead, from such a perspective, parameters that are under the agent's strategic control (such as the decision boundary) should be set such that they maximize reward. Within the context of sequential sampling models and typical lab tasks, reward can be thought of as accuracy per unit of time, often referred to as the reward rate. Using this approach, <ref type="bibr" target="#b3">Bogacz et al. (2010)</ref> found that humans can adjust the height of the decision bound such that it maximizes reward rate. There is also evidence that people initially prioritize accuracy over reward rate, and need extensive practice with the task before they maximize reward <ref type="bibr" target="#b1">(Balci et al., 2011)</ref>. Expanding on this line of work, <ref type="bibr" target="#b19">Malhotra et al. (2017)</ref> formulated the boundary setting problem as a Markov decision process problem. Using such an approach, it is possible to provide mathematically optimal (reward-maximizing) solutions to specific decision problems. For example, they showed that in tasks with multiple levels of difficulty it is optimal SHOULD I SAMPLE OR SHOULD I GO 5 to collapse the decision boundary with time (see <ref type="bibr" target="#b19">Malhotra et al. (2017)</ref> for empirical support of this prediction). However, the downside of approaching boundary setting as a Markov decision problem is that each experimental manipulation requires a new analytic derivation about the optimal parameter settings. Moreover, even if these computationally expensive calculations reveal the optimal strategy for each condition, it remains unclear how the brain would be able to solve the corresponding Bellman equations required to implement these strategies <ref type="bibr" target="#b37">(Sutton &amp; Barto, 2018)</ref>.</p><p>To address this issue, we propose a computationally light model of sampling decisions, whereby decisions are based on the accumulation of the evidence. Our model considers three factors that determine a stopping decision: sampling bias, elapsed time, and cumulative evidence. Specifically, we propose that:</p><p>Weighted Evidence = -wSamplingBias + wUrgency Â´ t + Evidence</p><p>(1)</p><p>The sampling bias, wSamplingBias, is a constant term that accounts for the baseline sampling policy of the observer (e.g., how long do you initially plan to compare the coffee packages before making a choice); this parameter corresponds to the intercept, or height of the decision bound in sequential sampling models. Time (t) is a measure of how many samples have been collected for the current decision (e.g., how long have you been comparing the coffee packages so far). The weight of time, wUrgency, accounts for the sense of urgency (e.g., how impatient do you get if you remain indecisive after each comparison). This is conceptually similar to how quickly the decision bound changes as a function of time; it can also be considered as the slope of the decision bound. Finally, the cumulative evidence term, Evidence, represents the total evidence observed towards the current decision (e.g., which coffee package is currently winning and by how much); it reflects the information provided rather than a parameter under strategic control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 6</head><p>The linear combination of the three terms in (1) makes up Weighted Evidence, which determines whether a decision is made, based on a hard boundary. Specifically, the agent commits to a decision if</p><p>Weighted Evidence is positive; and asks for more evidence if not (see <ref type="figure">Figure 1</ref> to see the model in action). Equivalently, we could say that the model stops sampling if Evidence &gt; wSamplingBias -wUrgency Â´ t;</p><p>for this reason, we can think of wSamplingBias as being the intercept of a decision bound, and of wUrgency as being its slope. Our model proposes that intercept (wSamplingBias) and slope (wUrgency) can in principle both be strategically controlled to determine the optimal stopping point for sampling information; that is, we propose that humans can change these parameters to maximize reward. Via model simulations, we will determine what the optimal strategy is in different experimental conditions; via model fitting, we will determine to what extent humans deviate from this optimum.   <ref type="bibr" target="#b16">(Irwin et al., 1956)</ref> can elucidate this process. The expansion and discretization of decision steps provide a rich source of information about the underlying cognitive processes (e.g., <ref type="bibr" target="#b34">(Rouault et al., 2022)</ref>). For example, expanded judgment tasks have been used to address conflicting findings about whether decision boundaries are stable within a trial or collapse across time <ref type="bibr" target="#b6">(Drugowitsch et al., 2016;</ref><ref type="bibr" target="#b11">Glickman &amp; Usher, 2019;</ref><ref type="bibr" target="#b13">Gluth et al., 2012;</ref><ref type="bibr" target="#b19">Malhotra et al., 2017;</ref><ref type="bibr" target="#b38">Tickle et al., 2021)</ref>. Here, we introduce a novel expanded judgement task in which participants are explicitly asked at each timepoint whether they want to sample additional information. The task also explicitly incorporates the cost of acquiring new information (sampling cost) and the cost of committing to an under-informed decision (error cost), allowing us to examine their specific effects on sampling decisions.</p><p>We hypothesize that decisions about when to stop sampling information can be explained by this model that linearly combines baseline sampling tendency, time pressure, and evidence. First, we used simulations from our model to discover the optimal strategies that maximize reward under two different error cost and sampling cost scenarios, targeting the sampling bias and urgency parameters, respectively. Second, using our novel paradigm we tested whether human participants follow these optimal strategies. Specifically, we created variants of the task in which it was optimal to change the sampling bias parameter (Study 1a and 1b), and in which it was optimal to change the urgency parameter (Study 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 8</head><p>Study 1</p><p>Some decisions have higher stakes than others: buying the wrong house is more consequential than buying the wrong pack of coffee beans. When making decisions, one might collect more information before committing to a decision when the cost of making an error is high, in order to avoid the (potentially) high error cost. In our proposed model this corresponds to a higher sampling bias. This means that the weighted evidence, which determines whether more samples will be collected, starts further away from the bound and thus requires more evidence and/or time to commit to a decision. In Study 1, we manipulated the cost of making an error to test the intuition that selectively changing the sampling bias would be optimal when the consequence of errors changed. Next, we empirically tested whether human participants changed their strategies accordingly. The empirical part involved two experiments, one serving as a high-powered replication of the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Design</head><p>SHOULD I SAMPLE OR SHOULD I GO We developed an expanded judgement task where participants decide which of two decks of cards yields higher numbers on average, based on limited samples from each deck <ref type="figure">(Figure 2A</ref>). On each trial, either the left or the right deck was randomly chosen to be the high-average deck. Numbers ranging from 1 to 9 were sampled from beta distributions with a mean of 5.5 for the high-average deck and 4.4 for the low-average deck, with a variance of 2.3 for the distribution of each of the decks ( <ref type="figure">Figure   2C</ref>). Participants started each block with 150 sampling opportunities, where each sample corresponds to the participant seeing two cards, one from each deck. Upon seeing the two cards, participants were asked to indicate which deck they thought had the cards with a higher average, and how strongly they believed this. They indicated their choice and confidence simultaneously, by pressing E, R, T, or P, O, I on a computer keyboard with the ring, middle and index fingers of their left and right hand, corresponding to "probably left", "maybe left", "guess left", "guess right", "maybe right", or "probably right", respectively; <ref type="figure">Figure 2B</ref>). Next, participants had 750ms to press the spacebar to commit this as their final answer about the deck pair. If they did not press within the deadline, they were presented with a new pair of cards from the active deck pair, spending another sampling opportunity. If their committed answer was correct (regardless of belief strength), they earned a point. If their committed answer was incorrect, they did not earn a point, and lost either 5 samples (Low Cost condition) or 30 samples (High Cost condition).</p><p>After their final answer, the feedback screen was shown for 750ms for correct answers, and for 5000ms for incorrect answers. The long waiting period following an incorrect answer was implemented to discourage random responding for participants who cared less about points and sampling opportunities and more about their own time. Participants were instructed to try to earn as many points as they could and received a monetary bonus proportional to the points they accumulated by the end of the experiment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulations</head><p>We used simulations to discover the optimal strategy (i.e., to get the highest number of points) in each of the two conditions described above. The decisions to commit to a final decision after each sample were based on the Weighted Evidence. If Weighted Evidence Â£ 0, the agent opted to see another number pair, spending one sample. If Weighted Evidence was positive, the agent committed to choosing the distribution favored by the accumulated evidence at that point. We simulated 100 runs (blocks) each SHOULD I SAMPLE OR SHOULD I GO 11 for 2666 agents, each with a unique combination of the two parameters. The simulated observers had sampling biases ranging from 8 to 0.5 (86 values) and urgency weights ranging from -1 to 2 (31 values).</p><p>Figure 3 (panels A and B) shows the simulated average points earned for each combination of parameter values in the two conditions. When comparing the optimality landscape for Low Cost decisions ( <ref type="figure" target="#fig_1">Figure 3A)</ref> and High Cost decisions ( <ref type="figure" target="#fig_1">Figure 3B</ref>), the optimal strategy is to have a higher sampling bias when erroneous decisions cost more sampling opportunities. Importantly, in both contexts the optimal strategy is to use an urgency weight of 0, corresponding to a decision boundary that does not change over the course of a decision. Based on these simulations, we proceeded to test human participants on the same two conditions, in order to test whether humans follow the optimal strategy as described by the simulations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 1a</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Methods</head><p>Participants. Power analysis based on pilot data indicated that we needed 27 participants to detect the model outcome effect with a power of 0.80. To accommodate attrition and err on the highpower side, we recruited 53 participants via the online crowdsourcing platform Prolific. Only native speakers of English who did not report any cognitive deficiencies were recruited in order to ensure comprehension and execution of task instructions. The study was carried out in accordance with the Decleration of Helsinki and approved by the Ethics Committee of the Faculty of Psychology and Educational Sciences at Ghent University. All participants gave their informed consent on the initial screen of the online task. Participation was compensated by at least Â£5, with a chance to earn more (up to an additional Â£5) depending on task performance. Participants who did not perform above chance level and/or took too many (&gt;50%) quick guesses with no evidence were excluded from all analyses (see Supplements for exclusion criteria details). After exclusions, we had 40 participants (22F), mean age = 36.9 Â± 14.5 years (range: 19-72 years, median = 32).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis.</head><p>Descriptive. We tested whether the error cost condition influenced three outcome metrics: the number of samples used per decision, accumulated evidence per decision, and accuracy. For all three outcomes, we conducted normality tests, followed with parametric tests if the outcomes were normally distributed and non-parametric tests if they were not.</p><p>Model fitting. The stopping decisions (whether sample collection stopped or not), accumulated evidence (cumulative difference between the two decks), and sample count data (number of samples seen for the deck pair) were used to estimate individual model parameters under the different error cost conditions. We used a SoftMax transformation to construct a likelihood function in order to account for the noise and fit the data, and a differential evolution optimization algorithm with 1000 iterations to find the parameters that best fit the data. For each participant, the model fit was repeated 10 times, and means of the parameter estimates from the highest likelihood fits were taken to be the final estimates. In cases where fits with matching highest likelihood values elicited highly variable estimates, we considered the fits as non-converged and thus unreliable.</p><p>We compared four versions of our model with varying complexity. In the NULL model (2 free parameters), a single urgency weight and a single sampling bias were estimated regardless of the cost condition. In the URG and SAMP models (3 free parameters), which had separate urgency weights or sampling biases, respectively, for each error cost condition, were estimated. The FULL model (4 free parameters) allowed both urgency weight and sampling bias to change in response to the error cost condition. Model comparison was done based on a total BIC value calculated for each model by adding the BIC values of that model for each subject. The model with the lowest cumulative BIC value was determined to be the model that best explained the observed pattern of stopping decisions.</p><p>We tested whether the estimates from the winning model indicated a change in strategy that was in line with the optimal strategies for each cost condition. We conducted a Wilcoxon signed rank test to examine the effect of the error cost condition on the sampling bias.</p><p>Transparency and Openness. We report all sample size calculations, all data exclusions, all manipulations, and all relevant measures in the study. Data were analyzed using R, version 4.1.2 (R Core Team, 2021), with the packages tidyverse <ref type="bibr" target="#b40">(Wickham et al., 2019)</ref>, DEOptim <ref type="bibr" target="#b25">(Mullen et al., 2011)</ref>, and coin <ref type="bibr" target="#b15">(Hothorn et al., 2006</ref>  <ref type="figure" target="#fig_2">Figure 4A</ref> and 4B). Error cost did not significantly influence accuracy ( <ref type="figure" target="#fig_2">Figure 4C</ref>;</p><p>MHC=0.801, MLC=0.799, V(39)=433, p=0.76). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 15</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 16</head><p>Model fitting. The data were best explained by the SAMP model, suggesting that participants selectively adjusted their sampling bias depending on the error cost condition ( <ref type="figure">Figure 5A</ref>). For the participants whose data was fit well by this model (36/40; see Supplements for details of the convergence tests), sampling bias estimates were significantly different between the two error cost conditions (see <ref type="figure">Figure 5D</ref>). On average, participants had a higher sampling bias in High Cost blocks compared to the Low Cost blocks ( <ref type="figure">Figure 5B</ref>; MHC=8.52, MLC=6.85, V(36)=163, p=0.007 r=0.45). Within the SAMP model, a single urgency weight was estimated across the two conditions. Notably, this urgency weight was significantly above 0 ( <ref type="figure">Figure 5C</ref>; M=0.75, p=0.002), meaning that participants implemented a collapsing decision bound instead of a fixed one, and this was the case in both cost conditions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 1b</head><p>Study 1a found that human participants change their sampling strategy in the optimal direction in response to changes in error cost. Specifically, they sample more evidence before committing to a decision when errors cost more sampling opportunities, and they do so by changing the same model parameter (the sampling bias) as predicted by the simulations. Study 1b aims to replicate the findings of Study 1a using a larger sample on a different online experimental platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Methods</head><p>Participants. Power analysis based on the sampling bias effect in Study 1a indicated that we needed 72 participants to detect the previously observed model outcome effect (r=0.45) with a power of 80% (see Supplements for details). Considering the behavioral exclusion (24.5%) and nonconvergence rates (10%) in the previous experiment, we recruited 120 participants. Participants were recruited from the Ghent University undergraduate population via the research participation platform SONA. All participants indicated informed consent on the initial screen of the online task. Participation was compensated with course credit instead of monetary reward. The task was identical to the one described in Study 1a <ref type="figure">(Figure 2)</ref>, apart from the fact that participants received course credit rather than a monetary reward. After exclusions based on the same criteria as Study 1a, the final sample comprised 90 participants (65F, 23M, 2 undisclosed) aged 19.36 Â± 2.34 years (range:17-32 years, median:19).</p><p>Analysis. We carried out the same analyses planned and conducted for Study 1a to test whether we could replicate the previously observed effects of error cost context on descriptive (samples used per decision, accuracy, and accumulated evidence) and model (sampling bias) outcomes. Model fitting. The model fits also replicated the findings of Study 1a. Data were best explained by the SAMP model, in which a separate sampling bias was estimated for each error cost condition ( <ref type="figure">Figure 5E</ref>). For participants whose data was fit well by this model (80/90, see Supplements for details of the convergence tests), the sampling bias was estimated to be higher in High Cost blocks than in Low Cost blocks <ref type="figure">(Figure 5F</ref>,H; MedianHC=7.71, MedianLC=6.74, V(80)=513, p&lt;0.001, r=0.59). Mean urgency weight shared between the two conditions was again significantly above 0 ( <ref type="figure">Figure 5G</ref>; M=1.21, p&lt;0.001),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Descriptive</head><p>meaning that people used a collapsing decision bound instead of a fixed one in both conditions. In sum, we observed that participants changed their sampling bias in the optimal direction to adapt to the High Cost condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 19</head><p>The cost of sampling information is not always stable in real world decisions. In many cases (for example you may have a meeting after the grocery run for coffee) there is no negative consequence up to a deadline, but past that point, consequences become more severe as time goes on (e.g., being five minutes late versus twenty minutes late for said meeting would have different consequences). In such cases where the cost of sampling information changes throughout a decision, one might dynamically adjust the stopping criterion accordingly. Our model implements this property using the urgency weight parameter which increases or decreases the contribution of time (or specifically, the number of samples in our experiment) towards the weighted evidence, independently of the observed evidence. In Study 2, we tested whether the optimal strategy is to selectively change the urgency weight parameter, in cases where the cost of sampling evidence is manipulated. Following these simulations, we also test how human participants behave under these conditions and whether they change their strategies optimally as was the case in the previous studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Design</head><p>The experiment was similar to Study 1 except for the following: instead of changing the cost of choosing the inaccurate deck, we changed the cost of sampling new cards. In the Constant Cost condition, every new card pair costs participants 1 sample (as was the case in Study 1a and 1b). In the Dynamic Cost condition, participants were allowed 5 free draws for each new deck pair they started (i.e., they could see the first 5 pairs of cards from each new deck set without losing any sampling opportunities). These free draws were followed by an increasing sampling cost, where each additional draw from the same deck set cost the participant more and more draws. For example, if the participant drew 8 cards from each deck, the initial 5 draws would cost them nothing, the 6 th draw would cost 1, the 7 th draw would cost 2, the 8 th draw would cost 3, and therefore the 8 draws would end up costing the participant 6 samples. Both conditions had an error cost of 30 samples, which made the Constant Cost condition identical to the High Cost condition from Study 1a and 1b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 20</head><p>Experiment 2 started with 2 practice blocks, followed by 3 Dynamic Cost blocks and 6 Constant Cost blocks. The number of practice blocks was increased relative to the previous experiments, as the Dynamic Cost condition introduced a notably more complex rule that was crucial to the intended manipulation. After completing the first practice block with the Dynamic Cost condition, participants were asked comprehension questions about the task setup. Participants who answered all three questions correctly could proceed to the second practice block with the Constant Cost condition, followed by the experimental blocks. Those who responded erroneously to at least one comprehension question received the correct answers and explanations and repeated the dynamic cost practice block. If they answered the questions incorrectly after their second attempt, they could not proceed with the task. The order for the experimental blocks was counterbalanced in the same way as with the previous experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulations</head><p>We simulated observers completing the new conditions of the task, using the same parameter combinations as the simulations for Study 1. The simulated task was adapted for the new manipulation, and all other properties remained the same as the previous simulations.</p><p>The simulations indicate that the optimal strategy for the dynamic cost condition is to keep a similar sampling bias and increase the urgency weight compared to the constant-cost condition (see <ref type="figure" target="#fig_1">Figure 3B</ref> and 3C). The optimal urgency weight for the dynamic cost condition corresponds to an increasing time pressure during the decision, with the agent requiring gradually less evidence to commit to a decision as they spend more time on that decision. Based on these simulations, we proceeded to test human participants with the hypothesis that people would adapt their strategy to the dynamic sampling cost by optimally increasing their urgency weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 21</head><p>Participants. Similar to Study 1b, we recruited 120 Ghent University undergraduate students on the research participation platform SONA. All participants indicated informed consent on the initial screen of the online task. Participation was compensated with course credit. After exclusions based on the same criteria as the previous studies, the final sample comprised 100 participants (85F, 15M) aged</p><p>19.07 Â± 3.27 years (range:17-47 years, median:18).</p><p>Analysis. The analysis plan for Study 1a and 1b was repeated for the sampling cost manipulation to test its effects on behavior (number of samples used per decision, accumulated evidence, and accuracy) and model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Descriptive. The differences in two behavioral outcomes of interest, number of cards per decision and cumulative evidence, were normally distributed (Shapiro-Wilk Test, p=0.807 and p=181, respectively), so these were tested using paired-samples t-tests. The differences in accuracy were not normally distributed (Shapiro-Wilk Test, p=0.013), so the Wilcoxon signed rank test was used as the nonparametric alternative. In Dynamic-Cost blocks compared to the Constant-Cost blocks, participants drew more cards ( <ref type="figure" target="#fig_2">Figure 4G</ref>; MDC=3.88, MCC=3.25, t(99)=-10.1, p&lt;0.001, d=-1.01) and gathered more evidence ( <ref type="figure" target="#fig_2">Figure 4H</ref>; MDC=4.74, MCC=4.40, t(99)=-6.1, p&lt;0.001, d=-0.61) per final decision. They were also more accurate in their final decisions in Dynamic-Cost blocks ( <ref type="figure" target="#fig_2">Figure 4I</ref>; MDC=0.811, MCC=0.789, V(99)=1476, p&lt;0.001, r=-0.42).</p><p>Model fitting. Contrary to our expectations and violating the optimal strategy, the data were best explained by the SAMP model, suggesting that participants selectively adjusted their sampling bias depending on the sampling cost condition (see <ref type="figure">Figure 5I</ref>). For the participants whose data were fit well by this model (82/100; see Supplements for details of the convergence tests), sampling bias estimates differed significantly between the two sampling cost conditions. On average, participants had a higher sampling bias in Dynamic-Cost blocks compared to the Constant-Cost blocks <ref type="bibr">(Figure 5J,</ref><ref type="bibr">L;</ref><ref type="bibr">MDC=10.7,</ref><ref type="bibr">MCC=8.19,</ref><ref type="bibr">V(82)=3013,</ref><ref type="bibr">p&lt;0.001,</ref><ref type="bibr">r=0.67)</ref>. The average common urgency weight of the two conditions was significantly above 0 ( <ref type="figure">Figure 5K</ref>; M=2.47, p&lt;0.001), suggesting that participants did implement a collapsing boundary, but the size of the collapse did not differ between the two conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Deciding how much information to sample from an uncertain environment before committing to a decision is a task that humans face every day. In the current work, we developed a computationally light linear model describing how people might tackle this problem. Using model simulations under different cost scenarios, we determined the optimal strategies in each of these conditions.</p><p>Subsequently, we used an expanded judgments task to compare whether people's decision-making behavior followed the optimal strategy. We found that irrespective of the optimal strategy, human participants altered their sampling bias in response to changes in both error and sampling cost.</p><p>In Study 1, our simulations showed that it is optimal to have a higher sampling bias (intercept) but an unchanged urgency weight (slope) when the cost of making an error is higher. Thus, the resulting optimal behavior was to sample, on average, more cards per decision in the High Cost versus Low Cost condition. Participants in Study 1 demonstrated this shift in strategy both behaviorally and in model fits.</p><p>Specifically, they sampled more information and accumulated more evidence before committing to a decision when the error cost was high. Model fits showed that participants' behavior indeed was best explained by a higher sampling bias in the High Cost condition. We found that, overall, people are able to shift their sampling strategy in an optimal manner when the cost of making an error changes.</p><p>The picture was very different in Study 2. Here, we manipulated the cost of a sample, such that there is no negative consequence (cost) up to a deadline, and past that point, consequences become more severe as the trial continues. In our simulations, we found that the optimal strategy to adapt to this dynamic cost condition was to selectively change the urgency weight (slope) and not the sampling bias (intercept). That is, it was optimal to have a higher urgency weight (and thus a collapsing decision SHOULD I SAMPLE OR SHOULD I GO 23 boundary) in the dynamic cost condition, but to have a fixed boundary in the constant cost condition.</p><p>The resulting optimal behavior in our simulations is to draw fewer cards for the decisions in the dynamic cost condition. Interestingly, unlike in Study 1, participants in Study 2 did not demonstrate this optimal shift in their behavior and model parameters. Contrary to the optimal strategy, they sampled more information and thereby accumulated more evidence when the cost of sampling was dynamic.</p><p>Moreover, they did so by increasing the sampling bias parameter rather than the urgency weight. Thus, while people did change their strategy when the cost of sampling information changed, they did not do so in an optimal manner.</p><p>In Study 1, we investigated the effect of cost magnitude, manipulated symmetrically for the choices. The effect of cost and reward on decisions has largely been studied in scenarios with asymmetrical payoff structures. For example, if one of the available options incurs a higher cost when it is erroneously picked, the decision boundary for that option is set higher than for the alternative option <ref type="bibr" target="#b8">(Edwards, 1965;</ref><ref type="bibr" target="#b24">Mulder et al., 2012;</ref><ref type="bibr" target="#b30">Rapoport &amp; Burkheimer, 1971;</ref><ref type="bibr" target="#b35">Simen et al., 2009)</ref>. Another way in which a manipulation of potential payoffs can bias the decision-making process is through differential drift rates, whereby the evidence is accumulated more efficiently for the option with the more favorable payoff potential <ref type="bibr" target="#b0">(Ashby, 1983;</ref><ref type="bibr" target="#b32">Ratcliff &amp; Hacker, 1981)</ref>. There is some evidence that these two processes can also work in combination <ref type="bibr" target="#b5">(Diederich &amp; Busemeyer, 2006)</ref>. There is little research investigating the effect of symmetrically manipulated costs and rewards <ref type="bibr" target="#b4">(Bottemanne &amp; Dreher, 2019)</ref>, which is what we tested in the current work. We manipulated the cost of incorrect decisions and found that higher cost decisions require and elicit higher, more cautious decision boundaries, which is in line with the literature on bias in asymmetrical payoff scenarios.</p><p>The current work also contributes to a rich literature studying whether decision boundaries are fixed or dynamic, and which is optimal in what situation. In our simulations, we found that it is optimal to have a fixed boundary when difficulty and sampling cost are stable. This is congruent with the SHOULD I SAMPLE OR SHOULD I GO</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>24</head><p>literature showing that when a task features only a single level of difficulty, the optimal strategy to maximize reward rate is to use a fixed boundary and disregard time information when deciding when to commit to a decision <ref type="bibr" target="#b2">(Bogacz et al., 2006)</ref>. In the empirical part of our studies, we find that people tend to use non-optimal collapsing boundaries. The results of previous studies are mixed as to whether people implement collapsing boundaries and whether they are optimal when they do <ref type="bibr">(Hawkins et al., 2015)</ref>. There is some data showing that people use fixed boundaries to optimize their reward rate in single-difficulty conditions <ref type="bibr" target="#b1">(Balci et al., 2011;</ref><ref type="bibr" target="#b3">Bogacz et al., 2010;</ref><ref type="bibr" target="#b35">Simen et al., 2009)</ref>, but others have found evidence for use of collapsing boundaries even in cases where a fixed boundary is optimal <ref type="bibr" target="#b13">(Gluth et al., 2012;</ref><ref type="bibr" target="#b19">Malhotra et al., 2017)</ref>, similar to our findings. In addition, researchers have found that in conditions where a dynamic boundary was optimal <ref type="bibr" target="#b10">(Frazier &amp; Yu, 2007;</ref><ref type="bibr" target="#b18">Karsilar et al., 2014)</ref>, people tend to use them in non-optimal forms <ref type="bibr" target="#b27">(Murphy et al., 2016)</ref>. Our findings lend support to the view that people do use dynamic boundaries but not in an entirely optimal manner.</p><p>One of the key findings of the current work was that when the cost of sampling was manipulated, people did not change their sampling strategies optimally. Instead of increasing urgency in the dynamic sampling cost condition, participants kept using the same level of urgency and instead altered the magnitude of the sampling bias. We can see several reasons why this might be the case.</p><p>First, perhaps people are simply not capable of dynamically adjusting the level of urgency and may behave non-optimally in this regard. Study 1 shows that, while the participants were able to shift their sampling bias optimally, they had non-optimal urgency weights. That is, most people used collapsing boundaries for both conditions even though it was optimal to have a constant boundary. This is in line with the findings of <ref type="bibr" target="#b19">Malhotra et al. (2017)</ref>, where people also used collapsing boundaries both when it was optimal to do so and when it was not. It is possible that a certain amount of increasing sense of urgency is typical, and that this amount does not change as a function of the circumstances, perhaps due to working memory limitations (but see <ref type="bibr" target="#b27">Murphy et al. (2016)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO 25</head><p>Second, the context of our experiments may have led people to change their strategy based on sampling bias instead of urgency. In all three studies presented here, the participants used, on average, fewer than 5 draws per decision. The Dynamic Cost condition in Study 2 was only dynamic after the fifth draw. Thus, for most of the decisions our participants ended up making, it was simply a consistently cheaper version of the alternative condition. Our simulations and the resulting optimal strategies were based on the full context of sampling costs, but our participants may have focused on the non-dynamic beginning of the dynamic condition. This may have prompted people to draw fewer cards in this more expensive condition (which corresponds to a higher sampling bias in the model) despite such behavior resulting in worse overall performance when the entire range of sampling strategies are considered.</p><p>Thus, focusing on the constant difference in sampling cost in the first few draws of the second study may have led participants in a non-optimal direction.</p><p>Finally, it is possible that a more complex, non-linear model might have performed better for the cost increase that we implemented in Study 2. In particular, it might seem surprising that in our simulations the optimal strategy in the dynamic sampling cost condition does not use all the available free samples. While this behavior may seem counter-intuitive, it is in line with empirical evidence as to how people actually deal with scenarios that involve non-linear changes in cost. For example <ref type="bibr" target="#b22">, Malhotra et al. (2018)</ref> observed that in asymmetric reward scenarios, where an error in one direction resulted in a large cost, people tend to set their decision criteria non-optimally to steer clear of these "cliff edges"</p><p>and avoid the dramatic change in cost. Thus, our linear model, while perhaps only approximately optimal, was able to capture how people behave in these scenarios.</p><p>In sum, in this study we have developed a computationally light linear model that can be used to study how people behave in sampling decisions. We have found that people are able to selectively shift their sampling strategy in the optimal direction in response to different error costs, and replicated this SHOULD I SAMPLE OR SHOULD I GO 26 finding. We have also found that when sampling cost is manipulated instead of the error cost, people do not change their strategy optimally.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure</head><label></label><figDesc>Figure 1. Example trials using our model with three different parameter combinations. The table shows</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Simulations of the three conditions used in the current study. For all three panels, the x axis shows the range of sampling bias values, and the y axis shows the range of urgency weight that we simulated. Each square on the heatmaps represents one strategy combining the two parameters, and the luminance of the squares shows the average performance (over a 100 simulations) of the simulated agent with those parameters. Lighter squares indicate better performance, and blue diamonds on each</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Behavioral results from all three studies. First row shows results from Study 1a, second row from Study 1b, and third row from Study 2. For all plots, the LC condition is shown in red, HC and CC (the shared condition between the studies) is shown in blue, and DC is shown in green. The first column shows the distribution of number of samples used for all final decisions. The second column shows the absolute accumulated evidence at the final decision. The third row shows the distribution and central tendency of accuracy for all participants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure</head><label></label><figDesc>Figure 5. Model outcomes from all three studies. First row shows results from Study 1a, second row</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>.</head><label></label><figDesc>Non-parametric significance tests were used for sampling and evidence outcomes, as the difference scores were not normally distributed (Shapiro-Wilk Test, all p&lt;0.05). The differences in accuracy were normally distributed (Shapiro-Wilk Test, p=0.371), so we used a paired samples t-test for this outcome. Fully in line with the finding of Study 1a, participants drew more cards (Figure 4D; MHC=4.25, MLC=3.56, V(91)=3872, p&lt;0.001, r=0.774) and accumulated more evidence (Figure 4E;MHC=5.12, MLC=4.61, V(91)=3454, p&lt;0.001, r=0.642) per final decision in High Cost blocks compared to the Low Cost blocks. Likewise, there was no effect of error cost on accuracy (Figure 4F; MHC=0.809, MLC=0.807, t(91)=0.289, p=0.77).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1. Example trials using our model with three different parameter combinations. The</head><label></label><figDesc></figDesc><table><row><cell>SHOULD I SAMPLE OR SHOULD I GO</cell><cell>7</cell></row><row><cell>but a lower sampling bias, and the blue line has the same sampling bias as green but a higher urgency</cell><cell></cell></row><row><cell>weight. Note that both changes result in the agent deciding earlier (to a different extent) and</cell><cell></cell></row><row><cell>inaccurately.</cell><cell></cell></row><row><cell>Sequential sampling models are typically fit on data that include only the endpoints of the</cell><cell></cell></row><row><cell cols="2">decision, namely response time and choices, leaving the underlying process of evidence accumulation a</cell></row><row><cell>black box. Expanded judgement tasks, which present evidence in sequential units instead of</cell><cell></cell></row><row><cell>simultaneously</cell><cell></cell></row><row><cell cols="2">table shows</cell></row><row><cell>the numbers on the cards for the first ten draws, where deck A has a generative distribution with a</cell><cell></cell></row><row><cell>higher average than that of deck B. The green line shows the weighted evidence for a simulated agent</cell><cell></cell></row><row><cell cols="2">with a sampling bias of 4 and an urgency weight of 0. The red line has the same urgency weight as green</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>9</head><label></label><figDesc>Figure 2. (A) The trial sequence. Participants see a pair of cards for at least 0.5s and are asked to indicate which side they think is the deck with a higher average (the confidence judgement instructions seen in panel (B)). Once they respond, they are asked whether this is their final answer for the current deck. If they do not respond within the deadline of 0.75s, they see a new pair of cards from the same deck. If they do indicate that they are ready to commit, the side of their latest confidence judgement is taken to be their final decision. If they picked the correct deck, they see a brief feedback screen and earn a point.</figDesc><table /><note>If they picked the incorrect deck, they see a longer feedback screen and lose a certain number of samples, depending on the condition. Screen contents from the task in this figure have been partially altered for clarity. (C) Generative distributions of the decks: beta distributions with means of 4.5 (orange line) or 5.5 (blue line), with identical variance.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>High Cost (losing 30 samples after an error) blocks. More High Cost blocks were required to balance the trial count between conditions, as the loss of 30 samples following errors resulted in a lower trial count in the High Cost condition. The blocks were presented in two alternative orders (HLH HLH HLH or LHH LHH LHH; H for High Cost, L for Low Cost), counterbalanced between participants. The task lasted on average 44 minutes Â± 17, depending on the pace and accuracy of participants.</figDesc><table /><note>Participants completed one practice block with an intermediate error cost (losing 15 samples after an error), with some interactive guidance if they were making some of the common mistakes that we observed in the pilot stages (see Supplements for details). This was followed by 3 Low Cost blocks (losing 5 samples after an error), and 6</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>SHOULD I SAMPLE OR SHOULD I GO 12panel mark the optimal strategy. Study 1 involves conditions in Panel A (Low Cost; LC) and B(High Cost;   HC), where the sampling bias shifts for the optimal strategy. Study 2 involves conditions in Panel B(Constant Cost; CC)  andPanel C (Dynamic Cost; DC), where the urgency weight shifts for the optimal strategy.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>The task was written using PsychoPy<ref type="bibr" target="#b28">(Peirce et al., 2019)</ref>, version 2020.2.3, and made available online on Pavlovia (https://pavlovia.org/) for participants to complete remotely. The task code and relevant materials are available upon request from the authors. The design and analysis for the studies reported in this manuscript were not pre-registered.</figDesc><table><row><cell>Results</cell></row><row><cell>Descriptive. All three behavioral outcomes of interest were non-normally distributed (Shapiro-</cell></row><row><cell>Wilk Test, all p&lt;0.05), so we used non-parametric significance tests. Participants drew more cards</cell></row><row><cell>(Figure 4A; MHC=4.71, MLC=3.83, V(39)=802, p&lt;0.001, r=0.833) and gathered more evidence (Figure 4B;</cell></row><row><cell>MHC=5.56, MLC=4.89, V(39)=712, p&lt;0.001, r=0.642) per final decision in High Cost compared to the Low</cell></row><row><cell>Cost blocks (see</cell></row></table><note>). All data, simulation code, and analysis code is available at [link to github SHOULD I SAMPLE OR SHOULD I GO 14 repo].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>First row shows results from Study 1a, second row from Study 1b, and third row from Study 2. First column shows the model comparison in terms of BIC, where the lowest value is the best model. Second column shows the distribution of estimates for</figDesc><table><row><cell>sampling bias for the participants from the best performing model (the SAMP model in all cases,</cell></row><row><cell>resulting in a separate distribution for each of the two conditions in all three studies). Third column</cell></row><row><cell>shows the spread of urgency weight estimates from the best performing model (a single estimate for</cell></row><row><cell>each participant in each study). The fourth column shows the distribution of the difference between the</cell></row><row><cell>sampling bias estimates for the two conditions (HC-LC for Study 1, DC-CC for Study 2).</cell></row></table><note>5. Model outcomes from all three studies.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>ET, KDS, TV, and EL were supported by grant G010419N from the Research Council Flanders. EL was supported by grant 12T2517N from Marie SkÅodowska-Curie Actions under COFUND grant agreement 665501, and by grant 12T2521N from the Research Foundation Flanders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHOULD I SAMPLE OR SHOULD I GO</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A biased random walk model for two choice reaction times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">G</forename><surname>Ashby</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-2496(83</idno>
		<ptr target="https://doi.org/10.1016/0022-2496(83" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="90011" to="90012" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Acquisition of decision making criteria: Reward rate ultimately beats accuracy. Attention, Perception, and Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Balci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-010-0049-7</idno>
		<ptr target="https://doi.org/10.3758/s13414-010-0049-7" />
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="640" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moehlis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.113.4.700</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.113.4.700" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="700" to="765" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Do humans produce the speed-accuracy tradeoff that maximizes reward rate?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210903091643</idno>
		<ptr target="https://doi.org/10.1080/17470210903091643" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="863" to="891" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vicarious rewards modulate the drift rate of evidence accumulation from the drift diffusion model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottemanne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Dreher</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnbeh.2019.00142</idno>
		<ptr target="https://doi.org/10.3389/fnbeh.2019.00142" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Behavioral Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling the effects of payoff on response bias in a perceptual discrimination task: Bound-change, drift-rate-change, or two-stage-processing hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diederich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193669</idno>
		<ptr target="https://doi.org/10.3758/BF03193669" />
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="194" to="207" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computational Precision of Mental Inference as Critical Source of Human Choice Suboptimality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Devauchelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koechlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1398" to="1411" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2016.11.005</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2016.11.005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="312" to="329" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/0022-2496</idno>
		<ptr target="https://doi.org/10.1016/0022-2496" />
		<imprint>
			<biblScope unit="page" from="90007" to="90013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sequential hypothesis testing under stochastic deadlines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">I</forename><surname>Frazier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20 -Proceedings of the 2007 Conference</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Integration to boundary in decisions between numerical sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2019.104022</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2019.104022" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<date type="published" when="2018-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deciding when to decide: Time-variant sequential sampling models explain the emergence of value-based decisions in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>BÃ¼chel</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0727-12.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0727-12.2012" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page" from="10686" to="10698" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The Neural Basis of Decision Making. Annual Review of Neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.neuro.29.051605.113038</idno>
		<ptr target="https://doi.org/10.1146/annurev.neuro.29.051605.113038" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Lego system for conditional inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hothorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Van De Wiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeileis</surname></persName>
		</author>
		<idno type="DOI">10.1198/000313006X118430</idno>
		<ptr target="https://doi.org/10.1198/000313006X118430" />
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="263" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tests of two theories of decision in an &quot;expanded judgment&quot; situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">W</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="261" to="268" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/h0041911</idno>
		<ptr target="https://doi.org/10.1037/h0041911" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Speed accuracy trade-offunder response deadlines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Karsilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Balci</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2014.00248</idno>
		<ptr target="https://doi.org/10.3389/fnins.2014.00248" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overcoming indecision by changing the decision boundary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J H</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="776" to="805" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/xge0000286</idno>
		<ptr target="https://doi.org/10.1037/xge0000286" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">SHOULD I SAMPLE OR SHOULD I GO</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Time-varying decision boundaries: insights from optimality analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J H</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="971" to="996" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13423-017-1340-6</idno>
		<ptr target="https://doi.org/10.3758/s13423-017-1340-6" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mulder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Boekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.4156-11.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.4156-11.2012" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2335" to="2343" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">DEoptim: An R Package for Global Optimization by Differential Evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mullen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ardia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Windover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<idno type="DOI">10.18637/jss.v040.i06</idno>
		<ptr target="https://doi.org/10.18637/jss.v040.i06" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Global gain modulation generates timedependent urgency during perceptual choice in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boonstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nieuwenhuis</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms13526</idno>
		<ptr target="https://doi.org/10.1038/ncomms13526" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">PsychoPy2: Experiments in behavior made easy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peirce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Macaskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>HÃ¶chenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kastman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>LindelÃ¸v</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-018-01193-y</idno>
		<ptr target="https://doi.org/10.3758/s13428-018-01193-y" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="195" to="203" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing (4.1.2). R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Models for Deferred Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rapoport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Burkheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="508" to="538" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A theory of memory retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.85.2.59</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.85.2.59" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="108" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Speed and accuracy of same and different responses in perceptual SHOULD I SAMPLE OR SHOULD I GO 30 matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Hacker</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03214286</idno>
		<ptr target="https://doi.org/10.3758/BF03214286" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="303" to="307" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Diffusion Decision Model: Current Issues and History</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2016.01.007</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2016.01.007" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="260" to="281" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Controllability boosts neural and cognitive signatures of changes-of-mind in uncertain environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rouault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.75038</idno>
		<ptr target="https://doi.org/10.7554/eLife.75038" />
	</analytic>
	<monogr>
		<title level="j">ELife</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Reward Rate Optimization in Two-Alternative Decision Making: Empirical Tests of Theoretical Predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Contreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1865" to="1897" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0016926</idno>
		<ptr target="https://doi.org/10.1037/a0016926" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<title level="m">Reinforcement Learning: An Introduction</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Human optional stopping in a heteroscedastic world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tickle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tsetsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000315</idno>
		<ptr target="https://doi.org/10.1037/rev0000315" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Sequential analysis. In Sequential analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1947" />
			<publisher>John Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Welcome to the tidyverse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Averick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Mcgowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>FranÃ§ois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grolemund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Bache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ooms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Spinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yutani</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.01686</idno>
		<ptr target="https://doi.org/10.21105/joss.01686" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">43</biblScope>
			<biblScope unit="page">1686</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
