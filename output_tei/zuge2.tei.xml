<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Uncertainty in learning, choice and visual fixation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-12-27">December 27, 2019.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrvoje</forename><surname>Stojić</surname></persName>
							<email>h.stojic@ucl.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Max Planck UCL Centre for Computational Psychiatry and Ageing Research</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>10-12 Russell Square</addrLine>
									<postCode>WC1B 5EH</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">L</forename><surname>Orquin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Management / MAPP</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<addrLine>Fuglesangs Alle 4</addrLine>
									<postCode>8210</postCode>
									<settlement>Aarhus</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Centre for Research in Marketing and Consumer Psychology</orgName>
								<orgName type="institution">Reykjavik University</orgName>
								<address>
									<addrLine>Menntavegur 1</addrLine>
									<postCode>101</postCode>
									<settlement>Reykjavik</settlement>
									<country key="IS">Iceland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Computational Neuroscience</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<addrLine>Max-Planck-Ring 8-14</addrLine>
									<postCode>72076</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck UCL Centre for Computational Psychiatry and Ageing Research</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>10-12 Russell Square</addrLine>
									<postCode>WC1B 5EH</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Speekenbrink</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>26 Bedford Way</addrLine>
									<postCode>WC1H 0AP</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Uncertainty in learning, choice and visual fixation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-27">December 27, 2019.</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>reinforcement learning | decision making | uncertainty | visual fixation | exploration-exploitation H.S., J.L.O., P.D., and M.S. designed research</term>
					<term>H.S. and J.L.O. performed research</term>
					<term>H.S. analyzed data</term>
					<term>H.S., J.L.O., P.D., and M.S. interpreted the results</term>
					<term>H.S. drafted the paper, and H.S., J.L.O., P.D., R.J.D., and M.S. wrote the paper</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Uncertainty plays a critical role in reinforcement learning and decision making. However, exactly how it influences behaviour remains unclear. Multi-armed bandit tasks offer an ideal test-bed, since computational tools such as approximate Kalman filters can closely characterize the interplay between trial-by-trial values, uncertainty, learning, and choice. To gain additional insight into learning and choice processes we obtained data from subjects&apos; overt allocation of gaze. The estimated value and estimation uncertainty of options influenced what subjects looked at before choosing; these same quantities also influenced choice, as additionally did fixation itself. A momentary measure of uncertainty in the form of absolute prediction errors determined how long participants looked at the obtained outcomes. These findings affirm the importance of uncertainty in multiple facets of behaviour, and help delineate its effects on decision making.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>W e often need to decide between alternative courses of action about whose outcome we are uncertain. Common examples include choosing a dish in a restaurant, a holiday trip, or financial investment. Uncertainty, which derives from initial ignorance and sometimes ongoing change, has two characteristic statistical and computational facets. One is straightforward: if we try an option, then the amount of learning, i.e., the extent to which we should update our beliefs, depends on our current uncertainty relative to the noise in the observation <ref type="bibr">(1)</ref>. The greater our uncertainty, the greater the impact an observation inconsistent with our current beliefs should have on our subsequent beliefs. There is good evidence that humans and other animals adapt their rate of learning to various factors in the environment which increase, or reduce, uncertainty <ref type="bibr">(2)</ref><ref type="bibr">(3)</ref><ref type="bibr">(4)</ref><ref type="bibr">(5)</ref><ref type="bibr">(6)</ref>.</p><p>The second facet concerns choice. Here, it is the options that we are uncertain about and that we need to learn about through sampling. This is more complicated, as our ignorance about their beneficial or malign consequences implies that we need to take a sampling risk. This is the notorious exploration/exploitation dilemma. Although there are elegant computational solutions for important special cases (Gittins indices; 7), a general solution is intractable. There is evidence that when choosing options, people explore in a directed manner, by integrating values with uncertainty about these values <ref type="bibr">(8)</ref><ref type="bibr">(9)</ref><ref type="bibr">(10)</ref><ref type="bibr">(11)</ref><ref type="bibr">(12)</ref>, particularly when these are carefully dissociated <ref type="bibr">(9,</ref><ref type="bibr">10)</ref>. However, there is also evidence for a simpler form of random, undirected, exploration, which is sensitive to value but not to its uncertainty <ref type="bibr">(5,</ref><ref type="bibr">13)</ref>. Integration of value and the uncertainty in its estimation is sensible. Estimation uncertainty serves as a proxy for how informative a choice is, or what the potential for improvement in value is <ref type="bibr">(14,</ref><ref type="bibr">15)</ref>. The distinction from irreducible uncertainty is important. Irreducible uncertainty stems from the inherent stochastic nature of the environment that generates rewards and can not be reduced through learning.</p><p>Most studies only admit indirect inferences about the processes of learning and decision-making, exploiting the trajectory of choices alone. However, when options are presented visually and are spatially distinct, we have an opportunity to gain a window onto these processes by examining what people choose to look at, that is, their visual fixations <ref type="bibr">(16)</ref><ref type="bibr">(17)</ref><ref type="bibr">(18)</ref><ref type="bibr">(19)</ref><ref type="bibr">(20)</ref><ref type="bibr">(21)</ref><ref type="bibr">(22)</ref><ref type="bibr">(23)</ref><ref type="bibr">(24)</ref><ref type="bibr" target="#b24">(25)</ref>. In typical tasks, including the one we employ in our experiment, we can expect two sorts of revealing fixation behaviour; namely, the relative time spent on each option when deciding (which bears on choice); and the absolute fixation time when receiving feedback about the consequences of choices (which bears on learning).</p><p>Fixation time might be correlated not only with subjects' internal states relevant to learning and choice, but might actually affect those states directly <ref type="bibr">(18,</ref><ref type="bibr">21)</ref>. This also allows factors other than value and estimation uncertainty, including stimulus salience, momentary lapses of attention, or unrelated cognitive processes to influence fixation <ref type="bibr" target="#b25">(26)</ref><ref type="bibr" target="#b26">(27)</ref><ref type="bibr" target="#b27">(28)</ref>, and exert statistically untoward effects on behaviour.</p><p>In the case of choice, a prominent view is that the process leading up to a decision involves accumulating information about the options until one is judged to be sufficiently good or sufficiently better than the alternatives <ref type="bibr" target="#b28">(29,</ref><ref type="bibr" target="#b29">30)</ref>. Under this framework, looking at an option facilitates accumulating information specifically about that option <ref type="bibr">(18,</ref><ref type="bibr">21)</ref>. This would provide a mechanism through which relative fixation time before making a choice can have a direct influence on the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Significance Statement</head><p>Humans cannot help but turn their gaze to objects that catch their attention. Our knowledge of the factors that govern this seizure, or of its effects in the context of learned decisionmaking, is currently rather incomplete. We therefore monitored the gaze of human subjects as they learned to choose between multiple options whose value was initially unknown. We found evidence that attention was influenced by uncertainty; and that the use of, and reduction in, uncertainty were in turn influenced by attention. Our findings provide evidence for approximately optimal models of learning and choice and uncover an intricate interplay between learning, choice and attentional processes. decision itself. In this case, for choices to be approximately optimal <ref type="bibr">(7,</ref><ref type="bibr">8,</ref><ref type="bibr">10,</ref><ref type="bibr">11)</ref>, the relative fixation time before a choice would have to reflect the learning history, with respect to both the value and estimation uncertainty. Our focus on directed exploration and estimation uncertainty distinguishes the present study from previous ones on reinforcement learning and attention, which focused on effects of value <ref type="bibr">(22)</ref> and irreducible uncertainty <ref type="bibr">(24)</ref>, or did not in any case involve exploration <ref type="bibr" target="#b24">(25)</ref>.</p><p>In the case of learning, absolute fixation time might have a direct influence on the magnitude of belief change in response to a prediction error, which amounts to the learning rate. For instance, visual fixations facilitate working memory and memory retrieval operations <ref type="bibr" target="#b30">(31)</ref><ref type="bibr" target="#b31">(32)</ref><ref type="bibr" target="#b32">(33)</ref><ref type="bibr" target="#b33">(34)</ref><ref type="bibr" target="#b34">(35)</ref>. Based on this evidence, fixation time might influence how well a newly observed outcome is integrated with an old value retrieved from memory. Thus, to follow the precepts of Bayesian statistical learning, fixation should be related to an option's estimation uncertainty <ref type="bibr">(3)</ref>, allowing the latter to be observable from the former. While this prediction was made almost two decades ago, empirical evidence has been lacking <ref type="bibr">(16)</ref>.</p><p>To examine the role of estimation uncertainty and complex interactions between visual fixation, learning, and choice, we administered a multi-armed bandit task in which we also tracked subjects' gaze as they chose repeatedly between six, initially unknown, options. We varied the mean and variance of options' outcomes to motivate exploration and to ensure ample variability in value and estimation uncertainty. When ignoring fixation behaviour, we found that both value and estimation uncertainty play a role in learning and choice. As predicted, we found that over the course of decision making, estimation uncertainty and value jointly influenced relative fixation times. During feedback, when subjects could update their beliefs, uncertainty, in the form of the unsigned reward prediction error, guided the total fixation time on the chosen option. Even though relative fixation time during choice carried information about value and estimation uncertainty, fixation exerted a much stronger independent influence on choices than was warranted by that information. This indicates that an important fixation-specific component influenced choice. Finally, we show that a model including value, estimation uncertainty, and relative fixation time before choice, best explained actual choices. This suggests that the influence of the first two of these quantities is not completely mediated by their effect on the third, and that capturing an internal valuation process is therefore still important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Participants completed two games. In each game they repeatedly chose between six options, for a total of 60 trials <ref type="figure" target="#fig_0">(Fig. 1A</ref>, Materials and Methods and SI Appendix, Methods). Each game was a multi-armed bandit task in which rewards for each option were drawn from different Gaussian distributions <ref type="figure" target="#fig_0">(Fig. 1C</ref>). Participants were instructed to maximize the cumulative sum of rewards in each game. To attain this goal they needed to explore the options in the choice set in order to learn which option had the highest average reward, and subsequently exploit this knowledge.</p><p>To facilitate detecting whether estimation uncertainty guided participants' exploration, the variances of the reward distributions differed between each of the options. The ratio- Each box denotes a stage in a trial, with duration displayed above the boxes. For visual fixation analyses the main stages of interest were Choice stage, where participants considered which option to choose, and Outcome stage, where they observed a choice outcome (the inset displays reward outcome overlaid over the option). Two stages were gaze contingent (GC), where participants trigger an onset by fixating on a fixation cross. (C) To facilitate detecting whether estimation uncertainty guided participants' exploration, the variances of the reward distributions differed between each of the options. In Decreasing variances game distributions get narrower (more certain, easier to learn) going from the best (rank 1) to the worst (rank 6) option, while for V-shaped variances game they are the narrowest for the middle ranking and broader (more uncertain, taking more trials to learn) for the better and worse ranking options respectively.</p><p>nale behind this manipulation is that choices that are guided by value alone would be less directly affected by such differences in variances. In a Decreasing variances game, variance decreased as the mean reward of the option decreased, so that, for instance, the option with the highest mean had the highest variance <ref type="figure" target="#fig_0">(Fig. 1C, left)</ref>. In a V-shaped variances game, the variance was largest for the options with the highest and smallest means, and smaller for the middle options <ref type="figure" target="#fig_0">(Fig. 1C, right)</ref>. Different games allow for better generalization of results and can serve as a further check for directed exploration, as again choices guided by value alone would be less sensitive to such differences. Options' expected rewards were constant throughout the bandit task. In such a task any reasonable reinforcement learning agent that maximizes cumulative rewards would gradually allocate more and more choices to high value options as its estimates of options' rewards improve with experience. Indeed, choices improved from the first to the last block of 15 trials ( <ref type="figure" target="#fig_2">Fig. 2A)</ref> ; see "Mixed effect regressions" in Materials and Methods). There was no strong difference in choice performance between the games, indicating that low ranking options did not attract more choices in the V-shaped game. While this could be due to choices not being guided by estimation uncertainty, an alternative explanation is that participants learned to ignore the low ranking options very quickly. This would resulting in weak difference between the games since it was mainly these that distinguished the distributions between games. In most cases, choice performance did not reach ceiling by the last block of 15 trials (mean of 2.08, SE = 0.10), suggesting that the games were not trivial and participants were still exploring by the end of the task.</p><p>In the following section, we outline a computational model built to determine the extent to which estimation uncertainty influenced choice. We then use this model to examine the multi-way relationships between the visual fixation during the period preceding each choice, the values and uncertainties of all the options estimated by the model, and the actual decision made by participants. We repeat this analysis for the relationships among fixation statistics at the time of reward feedback, the prediction error and estimation uncertainty that the model estimated participants entertain about the chosen option, and the ensuing learning.</p><p>Estimation uncertainty and choice. To identify learning and choice processes underlying participants' behaviour, we fitted computational models to their decisions. These models consisted of a learning component, in which participants learn or estimate properties of each option, and a choice component where they rely on these estimates to decide between the options.</p><p>Along with four control models often used to capture learning and choice in these types of tasks (SI Appendix, "Modeling learning and choices -control models" in Results), we considered two more sophisticated learning models, each coupled with two forms of choice. The learning models were either a Kalman filter <ref type="bibr">(8,</ref><ref type="bibr">13,</ref><ref type="bibr" target="#b35">36)</ref>, or a "lazy" Kalman filter, both of which use a variant of the delta rule to update estimated values from a reward prediction error (Materials and Methods, Eq. 1 and 2). The Kalman filter is a Bayesian model that tracks the expected values of options, as well as the uncertainties in those expectations (i.e. estimation uncertainty). Moreover, it dynamically adjusts the learning rate according to its current estimation uncertainty and the relative noise in the observed rewards. At each point in time, the Kalman filter provides an estimate of the value of an option as a Normal distribution, whose mean reflects the expected value, and whose variance reflects estimation uncertainty (in the remainder of the text we will use the term uncertainty to refer to estimation uncertainty). These means and variances are the key quantities we subsequently use to examine the role of value and uncertainty in visual fixations. The lazy Kalman filter is similar to the regular Kalman filter but with one crucial difference: it uses a learning rate which is a fraction of that of the regular Kalman filter (hence its moniker). Both models take into account differences in variances of options' rewards in each game (i.e. irreducible uncertainty), leading to different learning rates for each option.</p><p>The choice component in the models consisted of either a softmax (SM; Eq. 3; 37) or an upper confidence bound (UCB; Eq. 4; 14) rule. The softmax choice rule only uses estimated value to determine choice. As such, exploration is not guided by uncertainty. By contrast, the UCB choice rule implements a form of directed exploration. It uses the uncertainty to approximate the information gained by choosing an option, and adds this as an "uncertainty bonus" to the estimated value <ref type="bibr" target="#b37">(38)</ref>, implying that exploration is driven by a form of expected information gain.</p><p>We used a Bayesian hierarchical approach to estimate the parameters of the models. This assumes the parameters at the individual participant level are drawn from common grouplevel distributions <ref type="bibr" target="#b38">(39)</ref>. Model evidence shows that models with the UCB choice rule fit the data better than models using the softmax choice rule that ignores uncertainty <ref type="figure" target="#fig_2">(Fig. 2B)</ref>. The lazy Kalman filter model with a UCB choice rule described participants' choices best (KFL-UCB), with a posterior probability of approximately 0.99. Lazy versions of Kalman filter learning also outperformed the standard ones for the softmax choice rule. The Kalman filter models with the UCB choice rule convincingly outperformed all four control models (SI Appendix, Results). The probability of accurately predicting participants' choices with the KFL-UCB model increased steadily over the course of a game, reaching a mean of 0.46 (SE = 0.08) by trial 60 <ref type="figure" target="#fig_2">(Fig. 2C</ref>), well above the chance level (1/6 = 0.17) and above a simple non-learning model in which we estimate fixed probabilities of choosing each option (mean choice probability of 0.21). The overwhelming evidence in favour of the UCB choice rule shows that estimation uncertainty plays a clear role in choice. This shows that our model-based analysis is more sensitive than the model-free analysis predicated on the different variance patterns. The lack of a between-game effect in performance was likely due to participants quickly learning to ignore the low value options.</p><p>Since the only difference between the best fitting KFL-UCB model and its softmax counterpart (KFL-SM) is the β parameter that acts as a weight on uncertainty in the UCB choice rule, the strong evidence favouring the KFL-UCB model over the KFL-SM model indicates that the β parameter is reliably positive. Indeed, the posterior distribution of the β parameter of the KFL-UCB model has a mean of 0.37, and the 95% credible interval (CI) is [0.16, 0.61] (Eq. 4; <ref type="figure" target="#fig_2">Fig. 2D</ref>). This "inflation of value" is a sizeable uncertainty bonus, given that the expected values of options ranged between 2.5 and 6 and their variances between 0.75 and 2.75. As a final check, we also fitted a variant of the KFL-UCB model where the β parameter is not constrained to be non-negative. The KFL-UCB model with the non-negative β parameter outperformed the unconstrained KFL-UCB model with a posterior probability of approximately 0.99 (see "KFL-UCB model with unconstrained β parameter" in SI Appendix, Results). This result further affirms that the β parameter is positive and that uncertainty guides choice together with value.</p><p>We can also examine the usefulness of the "laziness" parameter (η) that biases the learning rate in the KFL-UCB model. A value of η = 1 would make the lazy Kalman filter equivalent to the regular Kalman filter. The bias seems to be rather small, as evidenced by the group-level posterior mean (0.93, 95% CI [0.80, 0.99]; Eq. 1). However, the individual variability is substantial: for a sizeable number of games (and individuals) parameter values were much lower and closer to 0 <ref type="figure">(Fig. S5C</ref>). This suggests the laziness parameter captures significant variation in behaviour. Values of the remaining parameters are depicted in <ref type="figure">Fig. S5</ref>.</p><p>Interactions between choice and fixation process. We next sought to assess three-way interactions between fixation during the choice epoch, the choice itself, and the combination of value and uncertainty. We first report basic properties of -2900 Proportions of choices allocated to options with the highest expected value (i.e. options with a rank equal to 1) increased from the first to the fourth block in a game. Relative fixation in the choice stage tracked the expected value of each option as well, but to a lesser extent, and shows learning effects. Error bars are SEM. (B) Model evidence (bars) and model comparison (numbers below bars) show that lazy Kalman filter learning with an upper confidence bound choice rule (KFL-UCB), captures participants' choices best. Error bars are interquartile ranges of bridge sampling repetitions (for some models too small to be visible; SI Appendix, Methods). (C) Mean probability with which each model accurately predicts participants' choices are well above chance level (dashed black line) and above a non-learning model that estimates fixed probabilities of choosing each option (dotted black line). The probability is highest for the KFL-UCB model (blue line). Means are computed over a rolling window of five trials. (D) Posterior of the group-level parameter for the KFL-UCB model that acts as a weight on uncertainty in the UCB choice rule (β). The posterior mean (vertical line) and 95% credible interval (black bar on the x-axis) shows the magnitude of uncertainty influence. Dots are posterior means of individual game level parameters.</p><formula xml:id="formula_0">K F -S M K F L -S M K F -U C B K F L -U C B Model</formula><p>fixation during the choice epoch. We then look at how value and uncertainty influence fixation. Finally, we ask whether and how fixation influences choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Properties of the fixation process in the choice stage.</head><p>To analyse interactions between choice and fixation, we focus on the choice stage of a trial <ref type="figure" target="#fig_0">(Fig. 1B)</ref>. Here participants had five seconds to consider which option to choose, before continuing to the next stage where they had to execute their choice, quickly. The fixation measure of interest in this section is the proportion of time spent fixating on each of the options. We computed the sum of the fixation durations received by each option, and divided this quantity by the sum total of fixation durations over all options. We refer to this measure of visual fixation as relative fixation.</p><p>Relative fixation resembled the allocation of choice, with increased allocation to high ranking options as learning progressed ( <ref type="figure" target="#fig_2">Fig. 2A</ref>). This close correspondence to the choice distribution, including the gradual shift of fixation distribution toward high value options over time, is a first indication that relative fixation might be affected by the same learning process that is guiding choices, as we originally hypothesized. Importantly, relative fixation followed the expected value of each option (i.e. option rank) to a lesser extent than choice proportions ( <ref type="figure" target="#fig_2">Fig. 2A</ref>). This could be due to a greater role of uncertainty in the trial-by-trial fixation dynamics, but could also be attributable to external, potentially independent, factors. Also as expected, and consistent with a reduction in uncertainty, the total time spent fixating on any of the options decreased over the course of learning <ref type="bibr">(</ref>  <ref type="figure" target="#fig_3">Fig. 3A</ref>). As for choice performance, there was no clear difference between the games. For analysis of other measures of the depth and breadth of the visual search process in the choice stage, see SI Appendix, "Additional properties of visual fixation" in Results.</p><p>Visual fixations in the choice stage are guided by both value and uncertainty. Given these suggestive results, we considered the conjoint influence of value and uncertainty on fixation in more detail. Previous studies that examined the relationship between choice and fixation <ref type="bibr">(18,</ref><ref type="bibr">21,</ref><ref type="bibr" target="#b39">40)</ref> could not do this, since they used one-shot choices which precluded modeling of learning and thereby examining the role of uncertainty. To examine such influences, we regressed estimates of value and uncertainty from the KFL-UCB model fitting choices best on relative fixation in each trial (see "Modeling relative fixation in the choice stage" in Materials and Methods). Importantly, it was beliefs about values and uncertainty that were established at the end of the one trial that were used to explain variation in relative fixation in the next trial. We assumed that relative fixation followed a Dirichlet distribution whose shape was influenced by value, uncertainty and a game type indicator as a control variable, and whose scale was set by a separate parameter (Eq. 6 and 7).</p><p>As predicted, the results of Bayesian hierarchical estimation show a clear positive contribution of both value and uncertainty in explaining variability in relative fixation. The whole of the measurable posterior distribution of the value parameter (Val; Eq. 7) was on the positive side of zero (mean of 0.17, 95% CI [0.12, 0.22]; <ref type="figure" target="#fig_3">Fig. 3B</ref>) and the same holds for the uncertainty parameter (Unc; Eq. 7; mean of 0.12, 95% CI [0.06, 0.17]; <ref type="figure" target="#fig_3">Fig. 3C</ref>). Estimated game-type effects were negligible (mean of −0.002, 95% CI [−9.66, 9.64]; Eq. 7), while the estimated scale parameter mostly acted to flatten the predicted relative fixation further (mean κ parameter was 0.60, 95% CI [0.50, 0.70]; Eq. 6). We verified these results by additionally comparing the full model to two simpler models where we either regressed uncertainty alone or value alone on relative fixation, keeping the game type indicator as a control variable <ref type="figure" target="#fig_3">(Fig. 3D)</ref>. The results of model comparison show that the model with both value and uncertainty clearly explains the relative fixation best (posterior probability of approximately 1), with simpler models lagging far behind. Hence, options with larger value and estimation uncertainty learned from previous trials attracted more relative fixation in the current trial. Thus, the same value and estimation uncertainty quantities that underlie block-wise changes in choice underlie block-wise changes in fixation allocation. for the full model and simpler models that regressed either value or uncertainty alone. The full model fits the data best. Error bars are interquartile ranges of bridge sampling repetitions (too small to be fully visible; SI Appendix, Methods). (E) Choice model modulated by relative fixation (KFL-aUCB) outperforms the model that regressed relative fixation directly on choices. This indicates that modeling learning and the choice process is important even when relative fixation is taken into account. The KFL-aUCB model also outperforms the model where learning process is modulated as well (aKFL-aUCB), the KFL-UCB model was included for comparison. (F) The KFL-aUCB model predicts participants' choices with the highest mean probability. All three are well above the chance level (dashed line) and a non-learning model that estimates fixed probabilities of choosing options (dotted line). Means are computed in a rolling window of five trials. (G) The group-level parameter in the KFL-aUCB, which determines a pseudo relative fixation for options that were not fixated, is small and closer to zero, indicating that relative fixation was useful as is. (H) The group-level β parameter from the UCB choice rule in the KFL-aUCB model shows a decrease in the magnitude of the weight placed on uncertainty after accounting for relative fixation, but the weight is still substantial.</p><p>Visual fixations in the choice stage influence choice. Having established that value and uncertainty affect the fixation process in the choice stage, we next examined whether visual fixation influenced choices. Such an influence has been shown in oneshot value-based choices (18, 40), but not yet for choices in a learning setting.</p><p>We first examined the effect of visual fixations on choices by regressing relative fixations in the choice stage directly on choices, using a simple multinomial logistic regression model (see "Modeling choices with visual fixations alone" in Materials and Methods). The results of Bayesian hierarchical estimation show that this simple model has a posterior probability of approximately 1 in comparison to the KFL-UCB model that fit choices best previously. What is surprising is the margin by which this simple model outperforms the KFL-UCB model, as shown clearly when examining the probability of accurately predicting participants' choices ( <ref type="figure" target="#fig_3">Fig. 3F</ref>). Here it is evident that the ability of the simple regression model to predict choice is almost twice that of KFL-UCB, reaching a mean of 0.63 (SE = 0.08) by trial 60. This result establishes a strong effect of visual fixation on choice, suggesting the presence of a large choice-related but value-and uncertainty-independent component in visual fixations, which is not captured in our KFL-UCB model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Values and uncertainty are not completely reflected in visual fixa-</head><p>tions. The excellent fit of choice using purely visual fixations prompts the question as to whether the effect of value and uncertainty on choice (KFL-UCB model; <ref type="figure" target="#fig_2">Fig. 2B</ref>) is mediated by their modest effect on fixation ( <ref type="figure" target="#fig_3">Fig. 3D</ref>), or whether a part of the valuation process that enters choice is not reflected in visual fixation. To test this, we incorporated relative fixation into the best fitting KFL-UCB model (KFL-aUCB model -"a" prefix marks "attention-modulated"; see "Modeling learning and choices modulated by visual fixations" in Materials and Methods) and examined whether this variant describes choice better than a simple model regressing relative fixation on choice. There are various ways in which relative fixation might be included; here, we assumed that values and uncertainty of options are warped in proportion to the relative fixation that options capture (Eq. 12).</p><p>Bayesian hierarchical estimation showed that the KFL-aUCB model outperformed the simple regression model, describing participants' choices best with a posterior probability of approximately 0.77 ( <ref type="figure" target="#fig_3">Fig. 3E</ref>; we included the KFL-UCB base model as well for comparison). The aKFL-aUCB model, in which learning process was modulated as well, followed suit with a posterior probability of approximately 0.23. Examining the models' probability of accurately predicting participants' choices again, we see a clear improvement over the simple regression model, with a constant advantage for the KFL-aUCB model throughout the game, reaching a mean of 0.73 (SE = 0.07) by trial 60 <ref type="figure" target="#fig_3">(Fig. 3F</ref>). This provides evidence that value and uncertainty are not completely reflected in visual fixation, and that explicitly modeling learning and choice processes provides additional predictive power. As a robustness check, we fitted additional attention-modulated models with a Softmax choice rule instead of UCB and a Kalman filter lacking the "laziness" parameter (SI Appendix, "Comparison of learn-ing and choice models modulated by visual fixation"in Results and <ref type="figure">Fig. S6</ref>). The results showed that the UCB component is important, as all models with it substantially outperform Softmax based models. The laziness parameter is important as well, but it has comparatively smaller impact.</p><p>We can compare the β parameter governing the strength of uncertainty-guidance in the UCB choice rule between the KFL-aUCB and KFL-UCB models. The posterior of β in KFL-aUCB is still clearly positive, but its magnitude was less once relative fixation is taken into account (posterior mean of 0.29, 95% CI [0.12, 0.49]; Eq. 4; <ref type="figure" target="#fig_3">Fig. 3H</ref>) -about 80% of the value for β in the KFL-UCB model without fixation modulation ( <ref type="figure" target="#fig_2">Fig. 2D)</ref>. Thus, some of the effect through which more uncertain options are more likely to be selected is sublimated when relative fixation is also taken into account.</p><p>In the KFL-aUCB model, the attention distribution over options was generated by squashing the relative fixation statistics according to a parameter (Eq. 11). The inferred value of this parameter can inform us about the importance of relative fixation. If is near 1, the distribution would be near uniform, independent of the relative fixation. If is near 0, then the distribution is dominated by the allocation of looking time. Consistent with the other analyses, the posterior distribution of parameter was small, with a mean value of 0.18 and 95% CI [0.01, 0.35] ( <ref type="figure" target="#fig_3">Fig. 3G</ref>).</p><p>Interactions between learning and fixation process. For analysing interactions between learning and fixation process we focus on the outcome stage of a trial <ref type="figure" target="#fig_0">(Fig. 1B)</ref>, the threesecond period during which participants could observe the reward outcome of their choice. The fixation measure of interest in this section is the total time fixating on the reward feedback in each trial. We will refer to this measure as absolute fixation. As for choice, we first examine the statistics of this measure, and then consider successively the effect of value and uncertainty on it and finally its potentially additional effect on learning.</p><p>Properties of the fixation process in the outcome stage. We first considered trial-by-trial variability in absolute fixation. Mean absolute fixation decreased over the course of learning and there are some, albeit weak, differences between the games (mixed effects regression estimates: intercept = 2. . The negative effect of the block is circumstantial evidence that uncertainty, which also decreases over the course of learning, is related to absolute fixation ( <ref type="figure" target="#fig_5">Fig. 4B</ref>). There was a ceiling effect due to the three-second outcome presentation time and this led to a left skewed distribution of absolute fixation ( <ref type="figure" target="#fig_5">Fig. 4A</ref>), but a mean of 2.36 s indicates that the effect was not particularly strong. Participants often continued looking at the feedback location for a few seconds more during the inter-trial interval <ref type="figure" target="#fig_5">(Fig. 4A</ref>). We assumed that these fixations were also associated with processing the reward feedback and included last fixations that ended within two seconds of the inter-trial interval. Most importantly for our subsequent considerations, when we repeat the same analysis on the standard deviations of absolute fixation, we observe considerable variability in absolute fixation (mixed effects regression estimates: intercept = 0.85, 95% CI [0.74, 0.96]; block = 0.07, 95% CI [0.02, 0.07]; game = 0.03, 95% CI [−0.08, 0.14]; block×game = −0.02, 95% CI [−0.06, 0.03]), as evidenced by the intercept estimate. For analysis of other measures of the visual search process, see SI Appendix, "Additional properties of visual fixation" in Results.</p><p>Unsigned reward prediction error guides fixation in the outcome stage. We next examined interactions between learning and fixation, focusing first on the theory-driven expectation that time spent looking at the reward feedback is guided by uncertainty, as is the case for the learning rate (3). There are two measures of uncertainty of interest here. One is the estimation uncertainty derived from the Kalman filter learning model (S variable, Eq. 2), the same quantity used in the UCB choice rule. The other is based on the prediction error and reflects both estimation and irreducible uncertainty <ref type="bibr" target="#b40">(41)</ref>. As predictions improve and estimation uncertainty decreases, unsigned (i.e. absolute) prediction error should generally decrease as well. However, because unsigned prediction error contains irreducible uncertainty (i.e. the variance of options' reward distributions), it will have continuing fluctuations as well, giving it a momentary character. Prediction errors play no role in uncertainty computations in the Kalman filter (Eq. 2), so these two measures should be largely decoupled. Indeed, the correlation between the two measures is negligible, with an average correlation across participants of 0.02 (SE = 0.11).</p><p>We regressed trial-by-trial uncertainty, prediction error, unsigned prediction error and value obtained from the KFL-UCB model on absolute fixation (see "Modeling absolute fixation in the outcome stage" in Materials and Methods, Eq. 8 and 9). We assumed absolute fixation follows a skew normal distribution constrained to the (0, 5) interval ( <ref type="figure" target="#fig_5">Fig. 4A</ref>) and we included a game type indicator as a control variable (Eq. 9). We compared the full model with all four predictors to simpler models that excluded particular predictors (Materials and Methods). The results of these model comparisons ( <ref type="figure">Fig. S7</ref>), which naturally take into account model complexity, show that a model including only unsigned prediction error (uPE model) explained absolute fixation best (P = 0.58), with a model including unsigned prediction error and value (uPE, Unc model) following suit (P = 0.28). In the uPE model, the effect of unsigned prediction error was clearly positive <ref type="figure" target="#fig_5">(Fig. 4C)</ref>, with almost the entire posterior distribution on the positive side (mean of 0.05; 95% CI [0.02, 0.07]). This means that reward outcomes accompanied with large unsigned prediction error tended to attract longer absolute fixation.</p><p>These results suggest that unsigned prediction error could in principle be a more important form of uncertainty, than estimation uncertainty, for guiding choice. On this basis we re-examined whether a class of models that uses unsigned prediction error, instead of estimation uncertainty, in the UCB choice rule might explain choices better than the KFL-UCB model. We implemented two models. The KFL-UPE model used a simple delta-rule to learn slow-moving estimates of unsigned prediction errors coming from the lazy Kalman filter learning model. These estimates were then used in the UCB rule. The K2-UPE model uses instead the K2 learning model which computes estimates of unsigned prediction errors in a more principled manner, following <ref type="bibr" target="#b40">(41)</ref>. However, the KFL-UCB model outperformed both models with a posterior probability of approximately 1 (SI Appendix, "Choice models with unsigned prediction errors" in Results and <ref type="figure" target="#fig_5">Fig. S4</ref>). Evidently estimation uncertainty is more relevant for guiding The group-level slope parameter (η1) that biases the learning rate in the aKFL-UCB model has a positive mean, suggesting a reduced bias for longer fixation on the feedback; however, the CI includes zero.</p><p>choice than unsigned prediction errors.</p><p>Fixation in the outcome stage influences the learning rate. Given our finding that learning influences visual fixations in the outcome stage we next considered whether there was a relation in the other direction, i.e., whether fixations affected the course of learning. As for choice, we tested this by comparing the KFL-UCB model that fitted choices best to a similar model in which we allowed absolute fixation at the outcome stage to modulate the learning rate, now referred to as aKFL-UCB (Materials and Methods, Eq. 13, 2 and 4). We decomposed the laziness parameter η of the lazy Kalman filter into an intercept η0 and a slope η1 that multiplies the absolute fixation in the outcome stage. The slope η1 is the main parameter of interest in the aKFL-UCB model. While the larger portion of its posterior is positive, with a mean of 0.03, the 95% CI [−0.17, 0.33] includes zero, suggesting the overall effect is weak (Eq. 13; <ref type="figure" target="#fig_5">Fig. 4E</ref>). To further assess its significance, we compared the aKFL-UCB model to the KFL-UCB model where learning is not modulated by absolute fixation. The KFL-UCB model outperformed the aKFL-UCB model, with a posterior probability of approximately 0.98, suggesting that absolute fixation does not modulate the learning rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>This study enriches our understanding of human reinforcement learning behaviour by looking at the four-way interaction between uncertainty, choice, learning and visual fixation. Our results offer evidence that people learn and choose in partial accordance with normative models, leveraging estimation uncertainty for both choice and learning. We show novel influences of fixation in reinforcement learning. Signatures of directed exploration can be seen in relative fixation at choice, which goes beyond previous findings on the effects of value and irreducible uncertainty on fixation at choice. Lastly, we provide novel evidence for the theoretical prediction that fixation at outcome is modulated by estimation uncertainty.</p><p>Examining choices alone supports a model where exploration is guided by both value and estimation uncertainty. The winning KFL-UCB model adds an "exploration bonus" to options' expected rewards <ref type="bibr">(14,</ref><ref type="bibr" target="#b37">38)</ref>. This model can be viewed as an approximation to the optimal solution for multi-armed bandit problems <ref type="bibr">(7,</ref><ref type="bibr" target="#b41">42)</ref> and adds to a growing body of evidence that people use uncertainty-guided choice strategies <ref type="bibr">(8)</ref><ref type="bibr">(9)</ref><ref type="bibr">(10)</ref><ref type="bibr">(11)</ref><ref type="bibr">(12)</ref>. The KFL-UCB also includes a Bayesian learning component (Kalman filter) which adapts its learning rate according to uncertainty. This dovetails with previous studies demonstrating a dynamic modulation of learning rate by uncertainty (4, 6). Our results imply that people track uncertainty about estimated value and incorporate it in their choices. This aligns with evidence from perceptual decision making that people have well-calibrated confidence in their choices <ref type="bibr" target="#b42">(43)</ref>, and from bandit tasks that they have accurate sense of confidence in their value estimates <ref type="bibr">(10,</ref><ref type="bibr" target="#b43">44)</ref>. Indeed, neuroimaging studies show that the brain tracks both mean and variance <ref type="bibr" target="#b44">(45,</ref><ref type="bibr" target="#b45">46)</ref>, while studies of neuronal population activity support a coding scheme where both mean and variance are represented <ref type="bibr" target="#b46">(47,</ref><ref type="bibr" target="#b47">48)</ref>.</p><p>Our analyses of visual fixation during choice provide novel evidence on the role of estimation uncertainty in choice. During the choice stage where participants considered which option to choose, we found that both value and estimation uncertainty, derived from estimation based on all previous trials, guided visual fixation in the current trial. Hence, directed exploration principles guide both choice and fixation. Examining choices alone do not always reveal the role of estimation uncertainty in exploration <ref type="bibr">(5,</ref><ref type="bibr">13)</ref>, but including fixation may provide a more reliable method to decode its role. Previous studies <ref type="bibr">(18,</ref><ref type="bibr">21,</ref><ref type="bibr" target="#b39">40</ref>) mostly focused on one-shot choices and hence could not examine whether and how visual fixation during choice is influenced by learning history, neither value nor estimation uncertainty. There are several exceptions. Perhaps the closest to the present study is recent work by Leong and colleagues <ref type="bibr">(22)</ref>, who show that fixation during choice is influenced by value learned from previous trials. However, the authors did not consider models that track uncertainty about value. Another recent study by Walker and colleagues <ref type="bibr">(24)</ref> showed that irreducible uncertainty increases exploration in both choice and attention, i.e. less focus on best options. However, their study used a between-subjects design and cannot explain what components of learning drive fixation on a trial-by-trial basis. Consequently, their results are inconclusive about the role of estimation uncertainty. Several other studies that examined relation between choice and attention in reinforcement learning eliminated the exploration aspect of the task and hence did not examine the role of estimation uncertainty <ref type="bibr" target="#b24">(25,</ref><ref type="bibr" target="#b48">49)</ref>.</p><p>We found that unsigned prediction errors guide visual fixation on the reward feedback during learning. Because estimation uncertainty modulates the learning rate, we expected it would guide fixation (3). Our additional prediction was that reward prediction errors might also influence fixation, as these indirectly incorporate both estimation and irreducible uncertainty. As learning progresses, estimated value becomes more accurate and prediction errors correspondingly decrease, thus mimicking the decrease in estimation uncertainty over time. Because prediction errors are influenced by irreducible uncertainty, they track both fast-moving momentary uncertainty and slow-moving estimation uncertainty. Looking at relative fixations to aversive stimuli in a conditioning task, (16) also found evidence for the influence of momentary uncertainty during the outcome stage. Results of both studies jointly provide supportive evidence for a prediction based on (3) that fixation should be related to option uncertainty, following the precepts of Bayesian statistical learning. Interestingly, we did not find that performance of a model where we allowed absolute fixation at the outcome stage to modulate the learning process (aKFL-UCB) improved over a model without fixation modulation (KFL-UCB). This result suggests fixation reflects the update process rather than having an influence on it. By contrast, <ref type="bibr">(16)</ref> and <ref type="bibr">(22)</ref> found evidence for such modulation. In <ref type="bibr">(16)</ref> learning process was directly observed and in (22) fixation measure was more detailed, tracking various features of options. These differences likely resulted in a greater sensitivity for detecting the fixation modulation in these studies.</p><p>Relative fixation in the choice stage exerted a stronger influence on choice than warranted by the information about value and estimation uncertainty contained in it. In fact, choices were better predicted from relative fixation alone than by the KFL-UCB model. This suggests that fixation carries additional choice relevant factors which are potentially unrelated to value and estimation uncertainty. For example, low level features of the symbols denoting individual options may have attracted gaze and biased choice toward those options <ref type="bibr" target="#b27">(28)</ref>. Such effects are anticipated by an attention modulated sequential sampling model <ref type="bibr">(18)</ref>. Here, we identify the magnitude of this modulation in a learning setting: our ability to predict choice nearly doubles, even for early trials that are usually difficult to predict by reinforcement learning models <ref type="figure" target="#fig_3">(Fig. 3F</ref>). This indicates that much can be gained by taking into account the visual search process in modeling learning and choices. The KFL-aUCB model, an example of how fixations can be incorporated into reinforcement learning models, explained choice better than relative fixation alone. This suggests that value and estimation uncertainty influenced choices both directly, through an internal valuation process, and indirectly, via fixation. This result invites an interesting conjecture about directed and random exploration <ref type="bibr">(9)</ref>. The source of directed exploration might be an internal choice process, while that of random exploration might lie in fixation specific factors unrelated to decision variables.</p><p>In tasks where people learn about options' values from reward feedback, looking at the options in the choice stage does not convey new information per se. In learning tasks, quantities such as estimated value and associated uncertainty must be represented in memory rather than externally. This raises the question of why participants' fixations in the choice stage were informative of their choices. To make an informed choice between the options, participants will likely retrieve experienced rewards or other indicators of options' value from memory. Looking at the stimuli, even though not informative per se, can facilitate memory retrieval and working memory operations <ref type="bibr" target="#b30">(31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51)</ref>. This is akin to the rationale behind sequential sampling mechanisms in one-shot value based decision making. <ref type="bibr">(18)</ref> hypothesized that the brain accumulates evidence by extracting the features of choice options, retrieving their learned values from the memory, and integrating these for each option. Similar assumptions underlie integrated reinforcement learning and sequential sampling models <ref type="bibr">(20,</ref><ref type="bibr" target="#b51">(52)</ref><ref type="bibr" target="#b52">(53)</ref><ref type="bibr" target="#b53">(54)</ref>. A negative side effect is that fixations can introduce bias, as suggested by <ref type="bibr">(18)</ref>. Our findings provide insight into the nature of this bias. Being shaped by the learning history the bias is partly adaptive, as a subset of fixations reflect cognitive processes behind directed exploration.</p><p>The attentional drift diffusion model by Krajbich and colleagues (18) is an appealing account of the within-trial choice process and how this may be influenced by fixation. Recent models combining reinforcement learning and sequential sampling have added across-trial learning dynamics <ref type="bibr" target="#b51">(52)</ref><ref type="bibr" target="#b52">(53)</ref><ref type="bibr" target="#b53">(54)</ref>. These models are not applicable in our task as the choice stage was fixed to 5 seconds and separated from the execution <ref type="figure" target="#fig_0">(Fig. 1B)</ref>. Therefore, response times are not informative about the evidence accumulation process. When we allowed for self-selected choice times in pilot experiments, we discovered that participants plan their next choice immediately after the feedback and during the inter-trial interval, making the collection of useful eye-movement data difficult. While such separation seems artificial in a laboratory task, it arguably brings the task closer to real-world situations. For instance, purchasing a certain type of product in a supermarket might happen every few days, effectively separating the choice opportunities and forcing the consumer to make a final choice once they are in front of the shelf. Applying sequential sampling models would require experimental designs that solve the issue of deciding in non-choice time in a different way. One potential solution would be to use several bandit problems simultaneously and on each trial randomly assign one of these, thereby reducing the usefulness of planning a choice before choice options are presented. Another is to use a contextual bandit problem, where new options can be presented on every trial, while learning would allow making useful predictions about the value of these new options <ref type="bibr">(10,</ref><ref type="bibr">22,</ref><ref type="bibr" target="#b54">55)</ref>.</p><p>One pertinent question is how our results regarding visual fixations relate to the role of attention in reinforcement learning. In theoretical work on associative learning in nonhuman animals, the Mackintosh model <ref type="bibr" target="#b55">(56)</ref> predicts that stimuli with high predictive value should attract attention, while the Pearce-Hall model <ref type="bibr">(2)</ref> predicts that uncertainty has a primary role. These seemingly contradictory accounts of attention have both received empirical support (57). (3) reconciled the two accounts, proposing that both are correct, but at different stages: during choice, attention is guided by predictive value, whilst during learning it is guided by uncertainty. Our results are consistent with this latter account. Fixations during the outcome stage were mainly driven by unsigned prediction errors, the measure of surprise in the Pearce-Hall model (2). Our results for relative fixations in the choice stage support an extension of the (56) account based on approximately optimal solutions to the exploration-exploitation trade-off <ref type="bibr">(14,</ref><ref type="bibr" target="#b37">38)</ref>. In this extension, both value and estimation uncertainty play a role in the choice stage.</p><p>Although imperfect, eye movements provide trial-by-trial empirical measures of attention. By recording fixations, attention need not be inferred solely from a computational model <ref type="bibr" target="#b57">(58)</ref><ref type="bibr" target="#b58">(59)</ref><ref type="bibr" target="#b59">(60)</ref>. But there is scope for further integrating measured attention into our models. Rather than using fixations as exogenous modulators of learning and choice, as we have done here (see also 22), a more satisfying treatment would endogenise fixations in a model that learns to direct attention and choose both within and across trials. Research in vision science has suggested that in tasks such as scene viewing <ref type="bibr" target="#b60">(61)</ref> and visual search <ref type="bibr" target="#b61">(62)</ref>, eye movements are guided by visual information gain. Sprague and Ballard <ref type="bibr" target="#b62">(63)</ref> proposed a reinforcement learning model of eye movements where uncertainty guides eye movements. In their model, eye movements to visually uncertain stimuli are reinforced because learning about the identity or state of the stimuli result in decisions that maximize the amount of reward. Previous studies have provided qualitative support for the model, albeit not in a reinforcement learning context (64). Manohar and Husain (65) modelled fixations in one-shot choices between monetary gambles where the authors argued that visual attention aims to minimize uncertainty about the expected value of gambles.</p><p>In the latter study, as well as those concerning visual scene detection, fixation directly provides novel information. This contrasts with our study, where fixating on an option can benefit memory retrieval, which in turn may serve a similar aim of information gain. This then paves the way to extending previous efforts to endogenise fixations to the current setting, a focus of future research that we plan.</p><p>In summary, we provide a detailed window on the interplay between learning, choice, and visual fixation, that allow us to trace the path through which uncertainty affects behaviour. Our study has theoretical and practical implications. First, it shows that attention and reinforcement learning processes might be more intertwined than previously thought, prompting a need for closer integration of the two in the future studies. It also raises new questions, such as whether the source of random exploration can be traced to the learning-independent properties of the fixation process. Second, it illustrates the utility of monitoring eye movements during learning and choice. The ability of reinforcement learning models to predict individual choice substantially improves when fixations are taken into account. Third, since fixations are shaped by learned values and associated uncertainties the potential for fixation to bias choice is smaller. Finally, the same result could explain everyday phenomena such as what shelf space in supermarkets people pay attention to and how companies can leverage this to induce exploration of new products. Task. The experiment was comprised of two separate multi-armed bandit (MAB) tasks (games) with 60 trials each. In each task, participants made repeated choices between the same six options, represented by different symbols <ref type="figure" target="#fig_0">(Fig. 1A)</ref> and shown in the same location on each trial. Key stages of a trial were the choice stage and outcome stage. In the choice stage options were presented for a fixed duration of 5 s, during which participants considered which option to choose. They registered their choice in the execution stage that followed the choice stage. In the outcome stage participants were shown reward feedback overlaid over the chosen option for 3 s. Participants were instructed to maximize the cumulative sum of the rewards during each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Methods</head><p>The main difference between the games was in the variance of the rewards. In the Decreasing variances game, the variance of each option decreased from the best option to the worst (according to expected reward). In the V-shaped variances game the variance decreased from the best option to the third best, and then increased again from the fourth best to the worst option. To minimize carryover effects between the games, we used a different set of letters from Gljagolica alphabet <ref type="figure" target="#fig_0">(Fig. 1A)</ref> and rescaled rewards differently for each game. The alphabet letters, options' locations, the order of the games, and the currencies and scaling factors associated with each game were randomized. At the end of each game participants received feedback about the experimental points they accumulated and corresponding earnings. After participants finished both games, we informed them which game was randomly selected for the payout, debriefed them, and paid their earnings. A detailed description of the time course of each trial, stimuli construction in each game and procedure is provided in SI Appendix, Methods.</p><p>Eye tracking. Participants sat in front of a screen with resolution of 1650 × 1050 pixels and physical size of 475 × 297 mm (widths and heights, respectively). They used a chinrest at approximately 60 cm distance from the screen. We recorded eye movements and pupillary responses using a desk-mounted EyeLink 1000 eye tracker (SR Research, https://www.sr-research.com/) with a monocular sampling rate of 500 Hz. We performed a 13-point calibration with the dominant eye, followed by a 13-point drift validation test. We accepted calibrations with offset less than 1°of visual angle. In gaze contingent stages of the trial -triggering the onset of the choice and execution stage -90% of gaze locations within a 1 s window needed to be in a circular area with a 3 cm radius around the fixation cross. To make a response in the execution stage participants had to press a key and an eye data sample had to be recorded at the same time within a circle representing an option. We used the default algorithm provided by SR Research to detect fixations. In data analysis we drew an area of interest (AOI) with radius of 3 cm around the centre of every option and assigned all fixations falling into these AOI to the corresponding options. See SI Appendix, Methods for further details on the eye-tracking setup.</p><p>Data analysis. We present here an abbreviated overview of analyses and models. More detailed descriptions, together with model fitting and comparison procedures, are given in SI Appendix, Methods.</p><p>Mixed effect regressions. We examined learning effects in games and differences between game types using Bayesian mixed effect regressions. We computed averages across blocks and regressed an intercept, a block indicator (coded as [−1.5, −0.5, 0.5, 1.5] for blocks 1 to 4) and a game type indicator (coded as −1 for Decreasing variances and 1 for V-shaped variances game), as well as their interaction on choice performance (chosen option rank) and fixation measures in the choice and outcome stage (total fixation duration, number fixations and number of options fixated). Intercept and blocks were entered as game-specific random effects while game type was entered as a fixed effect. Credible intervals were computed as highest posterior density intervals. . The Kalman filter model assumes participants update their estimates E j (t + 1) of the expected reward of choosing option j on trial t + 1 from the observed reward R j (t) on trial t as</p><formula xml:id="formula_1">E j (t + 1) = E j (t) + I j (t)K j (t)[R j (t) − E j (t)]</formula><p>. <ref type="bibr">[1]</ref> where the so-called "Kalman gain" term K j (t) acts as a learning rate. Term I j (t) is a simple indicator variable, with value of 1 if option j is chosen on trial t and 0 otherwise. The Kalman gain is updated on every trial and depends on current level of uncertainty</p><formula xml:id="formula_2">K j (t) = η S j (t) + σ 2 ζ S j (t) + σ 2 ζ + σ 2 ,j ,<label>[2]</label></formula><p>where S j (t) is the variance of the posterior distribution of the mean reward, updated in every trial as S</p><formula xml:id="formula_3">j (t + 1) = [1 − I j (t)K j (t)][S j (t) + σ 2 ζ ]; σ 2</formula><p>ζ is the innovation variance and σ 2 ,j the reward variance parameter which modulate the learning rate. Parameter η ∈ (0, 1) determines a bias in the Kalman gain, allowing the filter to learn at slower pace (hence the term "lazy"). In the standard Kalman filter we fixed this parameter to η = 1, while in lazy versions it is an estimated parameter. In both variants we initialized estimate of the expected value to E j (0) = 0. Initial variance was a free parameter σ <ref type="bibr">2</ref> i such that S j (0) = σ 2 i . We take into account differences between variances of options by setting the σ <ref type="bibr">2</ref> , In the softmax choice rule participants choose probabilistically according to relative estimated value</p><formula xml:id="formula_4">P (C(t) = j) = exp[θE j (t)] 6 k=1 exp[θE k (t)]</formula><p>, <ref type="bibr">[3]</ref> where P (C(t) = j) is probability of choosing option j at trial t and the inverse temperature parameter θ &gt; 0 determines the sensitivity to differences in estimated values, and with it the amount of exploration. The upper confidence bound choice rule combines estimated value and estimation uncertainty</p><formula xml:id="formula_5">P (C(t) = j) = exp{θ(E j (t) + β S j (t))} 6 k=1 exp{θ(E k (t) + β S k (t))} ,<label>[4]</label></formula><p>where β &gt; 0 is the weight a participant places on estimation uncertainty. While the original UCB rule chooses the option with the highest resulting value deterministically, we implemented a stochastic version by using a softmax transformation.</p><p>Modeling relative fixation in the choice stage. We used trial-by-trial subjective estimates of value and uncertainty from the KFL-UCB model fitting choices best, and regressed them on relative fixations in the choice stage. We controlled for potential differences between games by including a game-type indicator. Relative fixations were operationalised as the summed duration of fixations on each of the options divided by the sum of these quantities across all options. We assume that relative fixations in the choice stage (RF) follow a Dirichlet distribution RF(t) ∼ D(α(t), κ), <ref type="bibr">[5]</ref> with the probability density function defined as</p><formula xml:id="formula_6">1 B(α(t)κ) 6 j=1 RF α j (t)κ−1 j ,<label>[6]</label></formula><p>where B(α(t)κ) is a multinomial beta function that acts as a normalising constant. The vector of concentration parameters α(t) for each trial is obtained by passing values (E j (t)) and estimation uncertainty (S j (t)) of each option j obtained from the KFL-UCB model, as well as game type indicator as a control variable (G), through a softmax function</p><formula xml:id="formula_7">α(t) = exp{βvE j (t) + βu log S j (t) + βgtG} 6 k=1 exp{βvE k (t) + βu log S k (t) + βgtG} ,<label>[7]</label></formula><p>where βv and βu are weights on value and uncertainty, while βgt is the effect of game type. We log-transformed estimation uncertainty to linearise it. Games were coded as G = −1 for Decreasing variances and G = 1 for V-shaped variances game and this effect was included at a group level only. We assumed an additional precision parameter κ that multiplies the concentration parameters, governing how much probability mass is near the expected value.</p><p>Modeling absolute fixation in the outcome stage. We used trial-bytrial uncertainty, reward prediction errors, and value from the KFL-UCB model that fitted the choices the best and regressed them on absolute fixations in the outcome stage. We controlled for potential differences between games by including a game type variable. Absolute fixation measure was operationalised as a sum of durations of all fixations on the reward feedback. We assumed fixation durations during outcome stage (F ) follow a Skew Normal distribution</p><formula xml:id="formula_8">F (t) ∼ N (ξ(t), ω, α),<label>[8]</label></formula><p>truncated to interval F (t) ∈ [0, 5]. In the full model the location parameter ξ(t) for each trial is a linear combination of intercept, uncertainty (S j (t)), prediction error (PE), unsigned prediction error (uPE), and value (E j (t)) of chosen option j obtained from the KFL-UCB model and game type indicator variable (G)</p><formula xml:id="formula_9">ξ(t) = β i +βu log S j (t)+β PE PE j (t)+β uPE |PE| j (t)+βvE j (t)+βgtG,<label>[9]</label></formula><p>where βu, β PE , β uPE and βv are weights on uncertainty, signed prediction errors, unsigned prediction errors and value, β i is the intercept, and βgt the effect of game type. We computed unsigned prediction errors as absolute value of the prediction error and we log-transformed estimation uncertainty to linearise it. Games were coded as G = −1 for Decreasing variances and G = 1 for V-shaped variances game and this effect was included at a group level only. We assumed an additional scale parameter ω and shape parameter α, modelled at an individual game level, without a group-wise parameter.</p><p>Modeling choices with visual fixations alone. We also regressed relative fixation in the choice stage alone on choices, without explicitly modeling the learning and choice process. We used a simple multinomial logistic regression model where relative fixation for option j in trial t, RF j (t), is passed through a softmax function to obtain the probability P (C(t) = j) of choosing option j at trial t</p><formula xml:id="formula_10">P (C(t) = j) = exp[τ RF j (t)] 6 k=1 exp[τ RF k (t)]</formula><p>, <ref type="bibr">[10]</ref> where the inverse temperature parameter τ &gt; 0 determines the sensitivity to differences in relative fixations.</p><p>To avoid the measure of relative fixation taking the value of zero for options that were not fixated on at all in certain trials, we assigned each option a minimum value of which was treated as a free parameter:</p><formula xml:id="formula_11">RF j (t) = /6 + (1 − ) F j (t) 6 k=1 F k (t)</formula><p>.</p><p>[11]</p><p>Modeling learning and choices modulated by visual fixations. We assumed visual fixations can modulate the choice or learning component of the KFL-UCB model. We mark the learning and choice component with an "a" prefix to indicate which aspect is modulated by fixations. For example, in the aKFL-UCB model, visual fixations modulate the learning process, while in the KFL-aUCB they modulate the choice process. We assumed visual fixations in the choice stage enter the choice process by re-weighting the choice probabilities produced by the models based on options' estimated values and estimation uncertainty (Eq. 4). The relative fixation measure defined in Eq. 11 enters the UCB rule in an additive way:</p><formula xml:id="formula_12">P (C(t) = j) = exp{τ RF j (t) + θ(E j (t) + β S j (t))} 6 k=1 exp{τ RF k (t) + θ(E k (t) + β S k (t))} .</formula><p>[12] We assumed visual fixations in the outcome stage influence the learning process by making the bias in the Kalman gain update dependent on how long the reward feedback was fixated on in total in the outcome stage of the trial. We implemented this by replacing the η parameter in Eq. 2 with a baseline parameter η 0 and a slope parameter η 1 that depends on F , the absolute fixation duration in outcome stage:</p><formula xml:id="formula_13">η(t) = Φ(η 0 + η 1 F (t))</formula><p>, <ref type="bibr">[13]</ref> where Φ is the standard normal cumulative distribution function, used to constrain the resulting η parameter to the (0, 1) range.</p><p>Data and code availability. The data, code used for our analyses, as well as other project-related files are publicly available at the Open Science Framework website: https://osf.io/539ps/ (66). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS. We would like to thank</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supporting Information Text</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SI Methods</head><p>Exclusions. We recruited 34 participants (18 female, Mage = 26.8 and SDage = 8.1) in total. We removed data from two participants before processing, one due to problems with eye tracker calibration throughout the experiment, and one due to constant movement during the experiment. We applied two a priori exclusion criteria separately to each game played by each participant. The first criterion was failing to respond in time in more than 10 trials in a game. We excluded one participant who had more than 10 such trials in both games, most likely due to issues with calibration, as the choices were gaze contingent. The second criterion was failing to exceed chance performance (mean choice rank of 3.5) in the last 15 trials of a game. Specifically, we excluded games in which there was not at least weak evidence of above chance performance, as evidenced by the Bayes factor. In particular, we excluded games for which BF01 &gt; 1 (more evidence for the null hypothesis of chance performance). Based on these two criteria we excluded 28 games, 13 Decreasing variances games and 15 V-shaped variances games. After these exclusions, we were left with 23 participants (12 female, Mage = 26.9 and SDage = 8.4), 36 games in total, 19 Decreasing variances and 17 V-shaped variances games.</p><p>Trial time course. The trial structure was as follows. The inter-trial interval (ITI), indicated by a fixation cross, was randomly drawn from a uniform distribution, U (5, 5.5). After this interval, the fixation cross would rotate, indicating to participants that they should fixate on the cross in order to trigger the presentation of the stimuli. They had to maintain their fixation on the cross for 1 s for this to happen. Six options faded in over the course of 0.5 s and were presented for a total of 5 s fixed time, during which participants would consider which option to choose. Stimuli would then smoothly fade away over the course of 0.5 s, and the fixation cross would reappear, this time with a normal (unrotated) orientation. Participants would again have to fixate on the cross for 1 s to trigger the onset of the execution stage, in which they would make their choice. All six options appeared at their own location, smoothly fading in over 0.5 s. To register their choice, participants had to fixate on the option they wanted to choose and simultaneously press the SPACE key on the keyboard. They had at most 1.5 s to make a choice. Unchosen options would smoothly fade away over 0.5 s while the chosen option would remain on screen for a random duration drawn from a uniform distribution, U (2, 2.5). In the following outcome stage, the chosen option was made slightly transparent and reward feedback was overlaid on top of it for a fixed duration of 3 s. This was followed by the random inter-trial interval, and then the start of the next trial.</p><p>Stimuli construction in games. Rewards were drawn from a Gaussian distribution with an option specific mean and variance, µ k and σ 2 k . Means and variances differed between the options in each game. The best option in both games had a mean reward of 6. The main difference between the games was in the variance of the rewards. In both games the variance of the best option was set to 2.75. In the Decreasing variances game, the variance of each option decreased from the best option to the worst (according to the mean value) by 0.4. In the V-shaped variances game the variance decreased from the best option to the third best by 0.4, and then increased again from the fourth best to the worst option by 0.4. To make the difficulty of both games approximately equal, we set d = 0.4 between option pairs adjacent in their rank, and then determined exact means of the second best to the worst option according to µj = µj−1 − 0.4 × (σ 2 j−1 + σj)/2, where j is the rank of the option starting from 1.</p><p>To minimize carry-over effects between the games, we used a different set of letters from Gljagolica alphabet (1, letter area and color was adapted) and presented rewards using two different currencies (kuna and lek), with exchange rates of either 10 or 40, determined so that average earnings in both games are approximately equal. Rewards were scaled through multiplication with these exchange rates. Before each game began we informed participants about the exchange rate that would be used in the game and according to which we converted the points earned to money at the end of the experiment. The letters used in the games, options' locations, the order of the games, and the currencies and scaling factors associated with each game were fully randomized.</p><p>Procedure. Upon entering the laboratory, participants completed an informed consent form and provided basic sociodemographic data. Next we tested participants for eye dominance and seated them in front of the eye tracker. We then presented them with instructions about the task and earnings on-screen. We explained they would play two games and in each game they had to repeatedly (60 times) choose between six options, receiving a reward after each choice, with the goal to maximize the sum of rewards earned. We also explained that while the rewards were noisy, the average reward of the options would not change over time. We also indicated that the locations were chosen randomly and that nothing in the spatial arrangement was predictive of the options' values. Finally, we explained in detail how their earnings in the experiment were related to their choices in the games.</p><p>Participants completed seven practice trials before starting the games, in order to familiarize themselves with the interface, timings, and how to make gaze contingent transitions between the stages and choices. In the first two trials we showed brief instructions at the different stages, explaining what to do and how to perform actions. We increased the duration of each stage in these trials, to allow for sufficient time for reading the instructions. We used a different set Gljagolica letters in these practice trials.</p><p>Throughout the games, including the practice trials as well, if participants failed to respond in time (1.5 s), the trial was repeated. To provide an incentive to respond in time we deducted a significant number of experimental points when they failed to respond in time, in the amount of the expected value of the highest ranking option.</p><p>On finishing each game we provided feedback to participants how many experimental points they accumulated and to what earnings would that correspond if the game were to be selected to be paid out. After participants finished both games, we informed them about the game randomly selected for the payout and their final earnings, debriefed them, and paid out their earnings.</p><p>For the sake of full transparency, we recorded the following variables in our experiment: participants' choices, response times, eye gaze locations, and pupillary responses in the MAB tasks, and basic socio-demographic data (age and gender).</p><p>Eye tracking. Eye movements and pupillary responses were recorded using a desk-mounted EyeLink 1000 eye tracker (SR Research, https://www.sr-research.com/) with a monocular sampling rate of 500 Hz, a screen resolution of 1650 × 1050 pixels and physical size of 475 × 297 mm (widths and heights, respectively). We recorded pupil area using the centroid fit algorithm and CR tracking mode. The screen subtended a visual angle of 46.5°horizontally and 30.1°vertically. Participants used a chin-rest at approximately 60 cm viewing distance from the screen. We recorded exact physical layout of the equipment following <ref type="bibr">(2)</ref>.</p><p>Before beginning with the practice trials and each of the games, we performed calibration with the dominant eye using a 13-point calibration procedure, followed by a 13-point drift validation test. Background color and calibration point colors were adjusted according to the rest of the experiment. We considered acceptable a calibration offset less than 1.0°of visual angle. Pupil tracking parameters were determined through EyeLink's automatic method. We repeated the calibration procedure within the game if participants reported difficulties in gaze contingent stages of the trial.</p><p>We presented the experimental stimuli using the PsychoPy library (3). In the MAB task each option was represented by a circle with a radius of 3 cm and a letter with 2 × 2 cm size centered in it. To prevent participants from foveating more than one option at a time, they were placed in a circle separated horizontally and vertically by at least 3°of visual angle, 9 cm from the center of the screen. In gaze contingent stages of the trial -triggering the onset of the choice and execution stageparticipants had to have 90% of gaze locations within a 1 s window in a circle area with a 3 cm radius around the fixation cross. To make a response in the execution stage participants had to press a key and an eye data sample had to be recorded at the same time within a circle representing an option. Reward feedback was presented overlaid over the chosen option as text, with letters of 1 cm in height. Several aspects of the task implementation were concerned with collecting good quality pupillary data. We presented everything on the screen using two isoluminant colors -#457CA9 as a background color and #A4694F for text and stimuli (HTML color code). We chose letters from the alphabet that have approximately the same area. We used a longer inter-trial interval (5.25 s on average) to allow for pupil size to return to the baseline. Before each game we collected the game pupil baseline in a 40 s long stage with a fixation cross only where we instructed participants to look at the fixation cross during that time. They had another 40 s long stage where they looked directly at a camera, to be able to compute the pupil area in non-arbitrary physical units <ref type="bibr">(2)</ref>. Finally, the experiment was conducted in a darkly lit room, with constant lighting conditions across participants.</p><p>We used the default velocity, acceleration and motion-based algorithm provided by SR Research to detect fixations <ref type="bibr">(4)</ref>. In data analysis we drew an area of interest (AOI) with a radius of 3 cm around the center of every option and assigned all fixations falling into these AOIs to the corresponding option.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis.</head><p>Mixed effect regressions. We examined learning effects within games and differences between game types using Bayesian mixed effect regressions, implemented in the brms package in R <ref type="bibr">(5,</ref><ref type="bibr">6)</ref>. We computed averages across blocks and regressed the intercept, a block indicator variable (coded as [−1.5, −0.5, 0.5, 1.5] for blocks 1 to 4) and a game type indicator variable (coded as −1 for Decreasing variances game and 1 for V-shaped variances game), as well as their interaction, on choice performance (chosen option rank) and various fixation statistics in the choice and outcome stage (total fixation duration, number fixations and number of options fixated). We modeled choice ranks as a normal distribution truncated to the <ref type="bibr">[1,</ref><ref type="bibr">6]</ref> interval. The total number of fixations and the number of options fixated on were also modeled as normal distributions, truncated to the [0, ∞) interval. Total fixation duration was modeled as a skew normal distribution, truncated to the [0, ∞) interval. Intercept and blocks were entered as game-specific random effects, while game type was entered as a fixed effect. brms package uses the No-U-Turn-Sampling MCMC algorithm implemented in Stan (7) to fit the models (see "Fitting using MCMC" in SI Methods). We used default brms (version 2.8.0) priors and a centered parametrization of group-level parameters.</p><p>Modeling learning and choices. We fitted four main computational models to participants' choices. All four consisted of a learning component and a choice component. The learning component was either a Kalman filter (KF) (8-10) or a "lazy" Kalman filter (KFL) model. Both use a form of the delta rule <ref type="bibr">(11)</ref> to update estimated value based on a reward prediction error. What makes Kalman filter models different is that they track the (posterior) variance of the estimated value of each option (i.e. estimation uncertainty) and use this to dynamically adjust the learning rate. The lazy Kalman filter introduces a bias to the learning rate, allowing for slower learning. For the choice component the models used either a Softmax (SM; 12), or an upper confidence bound choice rule (UCB; 13). In the Softmax model exploration happens randomly -participants choose options with probability roughly proportional to the differences in estimated value between the options. By contrast, the UCB choice rule uses estimation uncertainty to approximate the information gained by choosing an option, and adds this as an "uncertainty bonus" to the estimated values <ref type="bibr">(14)</ref>, making exploration driven by information gain. We use a probabilistic form of the UCB rule where values are passed through a Softmax function, in contrast to the original deterministic form <ref type="bibr">(13)</ref>.</p><p>In the Kalman filter model we assumed participants update their estimates Ej(t + 1) of the expected reward of choosing option j on trial t + 1 from the observed reward Rj(t) on trial t as</p><formula xml:id="formula_14">Ej(t + 1) = Ej(t) + Ij(t)Kj(t)[Rj(t) − Ej(t)]</formula><p>. <ref type="bibr">[1]</ref> where the so-called "Kalman gain" term Kj(t) acts as a learning rate. Term Ij(t) is a simple indicator variable, with a value of 1 if option j is chosen on trial t and 0 otherwise. The Kalman gain is updated on every trial and depends on current level of uncertainty. This makes it a dynamic learning rate</p><formula xml:id="formula_15">Kj(t) = η Sj(t) + σ 2 ζ Sj(t) + σ 2 ζ + σ 2 ,j ,<label>[2]</label></formula><p>where Sj(t) is the variance of the posterior distribution of the mean reward, updated in every trial as</p><formula xml:id="formula_16">Sj(t + 1) = [1 − Ij(t)Kj(t)][Sj(t) + σ 2 ζ ]</formula><p>. Parameters σ 2 ζ and σ 2 ,j are the innovation variance and option's reward variance respectively, which modulate the learning rate. Parameter η ∈ (0, 1) determines the bias in updates of the Kalman gain, causing it to potentially learn at slower pace (hence the term "lazy"). In the standard Kalman filter we fixed this parameter to η = 1, while in lazy versions it is a free parameter, thus allowing for imperfect updates. In both variants we initialized estimate of the expected value to Ej(0) = 0. Initial variance was a free parameter σ <ref type="bibr">2</ref> i such that Sj(0) = σ 2 i . We take into account differences between variances of options by setting the σ <ref type="bibr">2</ref> ,j parameter to option's objective variance that we used to draw rewards from: ζ , σ 2 and σ 2 i ) needs to be fixed and we found that fixing σ 2 results in more stable estimations with better convergence properties (see "Hierarchical Bayesian parameter estimation" in SI Methods).</p><formula xml:id="formula_17">[2.</formula><p>We consider two choice rules that describe how the estimated values are used to make a choice C(t) between the options. In the Softmax choice rule (12) exploration occurs by chance -participants choose probabilistically according to relative estimated value</p><formula xml:id="formula_18">P (C(t) = j) = exp[θEj(t)] 6 k=1 exp[θE k (t)]</formula><p>, <ref type="bibr">[3]</ref> where P (C(t) = j) is the probability of choosing option j on trial t and the inverse temperature parameter θ &gt; 0 determines the sensitivity to differences in estimated values, and with it the amount of exploration. The upper confidence bound choice rule (13) uses estimation uncertainty to approximate an option's informativeness, or how much value estimates can be improved by trying an option. A multiple of the estimation uncertainty, defined as the standard deviation of the posterior distribution of the mean reward, is added to the posterior mean reward as an "exploration bonus". While the original UCB rule chooses the option with the highest resulting value deterministically, we implemented a stochastic version of the UCB rule by using a softmax transformation. In the Kalman filter the estimation uncertainty is explicitly modeled (posterior variance S in Eq. 2), resulting in the following form of the UCB choice rule</p><formula xml:id="formula_19">P (C(t) = j) = exp{θ(Ej(t) + β Sj(t))} 6 k=1 exp{θ(E k (t) + β S k (t))} ,<label>[4]</label></formula><p>where β &gt; 0 is the weight a participant places on estimation uncertainty. We fitted all models using hierarchical Bayesian parameter estimation (see "Hierarchical Bayesian parameter estimation" in SI Methods).</p><p>Modeling visual fixation in the choice stage. We used trial-by-trial subjective estimates of value and uncertainty from the KFL-UCB model fitting choices best and regressed them on relative fixations in the choice stage. We controlled for potential differences between the games by including a game type indicator. Relative fixations were operationalized as a sum of durations of fixations on each of the options in the choice stage, normalized by dividing by the sum of these quantities across all options. We assume that relative fixations in the choice stage (RF) follow a Dirichlet distribution RF(t) ∼ D(α(t), κ), <ref type="bibr">[5]</ref> with the probability density function defined as</p><formula xml:id="formula_20">1 B(α(t)κ) 6 j=1 RF α j (t)κ−1 j ,<label>[6]</label></formula><p>where B(α(t)κ) is a multinomial beta function that acts as a normalizing constant. The vector of concentration parameters α(t) for each trial is obtained by passing values (Ej(t)) and estimation uncertainty (Sj(t)) of each option j obtained from the KFL-UCB model, as well as the game-type indicator (G) as a control variable, through a Softmax function</p><formula xml:id="formula_21">α(t) = exp{βvEj(t) + βu log Sj(t) + βgG} 6 k=1 exp{βvE k (t) + βu log S k (t) + βgtG} ,<label>[7]</label></formula><p>where βv and βu are weights on value and uncertainty, while βgt is the effect of game type. We log-transformed estimation uncertainty to linearize it. Games were coded as G = −1 for the Decreasing variances and G = 1 for the V-shaped variances game and this effect was included at a group level only. We assumed an additional precision parameter κ that multiplies the concentration parameters, governing how much probability mass is near the expected value. We tested also several reduced models where either uncertainty or value was left out. We fitted all models using hierarchical Bayesian parameter estimation (see "Hierarchical Bayesian parameter estimation" in SI Methods).</p><p>Modeling visual fixation in the outcome stage. We used trial-by-trial uncertainty, reward prediction errors, and value from the KFL-UCB model fitting choices best and regressed them on absolute fixations in the outcome stage. We controlled for potential differences between games by including a game-type indicator. Absolute fixation was operationalized as the sum of durations of all fixations on the reward feedback. We assumed fixation durations during outcome stage (F ) follow a Skew Normal distribution <ref type="figure">N (ξ(t)</ref>, ω, α), <ref type="bibr">[8]</ref> truncated to the interval F (t) ∈ [0, 5]. In the full model the location parameter ξ(t) for each trial is a linear combination of intercept, uncertainty (Sj(t)), reward prediction error (PE), unsigned reward prediction error (uPE), and value (Ej(t)) of chosen option j obtained from the KFL-UCB model and the game-type indicator variable (G)</p><formula xml:id="formula_22">F (t) ∼</formula><formula xml:id="formula_23">ξ(t) = βi + βu log Sj(t) + β PE PEj(t) + β uPE |PE|j(t) + βvEj(t) + βgtG,<label>[9]</label></formula><p>where βu, β PE , β uPE and βv are weights on uncertainty, prediction errors, unsigned prediction errors and value, while βi is the intercept parameter and βgt the game-type effect. The intercept parameter is the baseline or mean absolute fixation across the whole experiment, while other parameters act as deviations from the baseline. We computed unsigned prediction errors as absolute value of prediction errors (this worked better than squaring the prediction error) and log-transformed estimation uncertainty to linearize it. Games were coded as G = −1 for the Decreasing variances and G = 1 for the V-shaped variances game and this effect was included at a group level only. We assumed an additional scale parameter ω and shape parameter α, modeled at an individual game level, without a group-wise parameter. We tested several reduced models where uncertainty, one of the reward prediction errors, or value are left out. We fitted all models using hierarchical Bayesian parameter estimation (see "Hierarchical Bayesian parameter estimation" in SI Methods).</p><p>Modeling choices with visual fixations alone. We can model choices by relative fixations in the choice stage alone by regressing the latter onto the former, without explicitly modeling the learning and choice process. We used a simple multinomial logistic regression model where relative fixation for option j in trial t, RFj(t), is passed through a Softmax function to obtain the probability P (C(t) = j) of choosing option j at trial t</p><formula xml:id="formula_24">P (C(t) = j) = exp[τ RFj(t)] 6 k=1 exp[τ RF k (t)]</formula><p>, <ref type="bibr">[10]</ref> where the inverse temperature parameter τ &gt; 0 determines the sensitivity to differences in relative fixations. To avoid our relative fixation measure taking the value 0 for options that were not fixated on at all in certain trials, we assigned each option a minimum value which was treated as a free parameter:</p><formula xml:id="formula_25">RFj(t) = /6 + (1 − ) Fj(t) 6 k=1 F k (t)</formula><p>. <ref type="bibr">[11]</ref> Estimating the parameter can tell us how useful the fixation data is. Overall, this regression model has two parameters: θ and . We fitted the model using hierarchical Bayesian parameter estimation (see "Hierarchical bayesian parameter estimation" in SI Methods).</p><p>Modeling learning and choices modulated by visual fixations. We assumed visual fixations can modulate the choice or learning component of the KFL-UCB model. We mark the learning and choice component with an "a" prefix to indicate which aspect is modulated by fixations. For example, in the aKFL-UCB model, visual fixations modulate the learning process, while in the KFL-aUCB they modulate the choice process.</p><p>We assumed visual fixations in the choice stage enter the choice process by re-weighting the choice probabilities produced by the models based on options' estimated values and estimation uncertainty (Eq. 4). The relative fixation measure defined in Eq. 11 enters the UCB rule in an additive way:</p><formula xml:id="formula_26">P (C(t) = j) = exp{τ RFj(t) + θ(Ej(t) + β Sj(t))} 6 k=1 exp{τ RF k (t) + θ(E k (t) + β S k (t))}</formula><p>. <ref type="bibr">[12]</ref> This has the effect of increasing the choice probabilities for options that received relatively more fixation time and diminishing them for the options that received relatively little fixation time. We assumed visual fixations in the outcome stage influence the learning process by making the bias in the Kalman gain update dependent on how long the reward feedback was fixated on during the outcome stage of a trial. We implemented this by replacing the η parameter in Eq. 2 with a baseline parameter η0 and a slope parameter η1 that depends on F , the absolute fixation duration in outcome stage: η(t) = Φ(η0 + η1F (t)), <ref type="bibr">[13]</ref> where Φ is the standard normal cumulative distribution function, which we use to constrain the resulting η parameter to the (0, 1) range. Overall, there are three model variants with attention modulation: The aKFL-UCB model has all the parameters that the KFL-UCB model has and an additional η1 parameter. The KFL-aUCB model instead has additional parameter, while the aKFL-aUCB has both additional parameters. We fitted all models using hierarchical Bayesian parameter estimation (see "Hierarchical bayesian parameter estimation" in SI Methods).</p><p>Hierarchical bayesian parameter estimation. We used a Bayesian hierarchical estimation procedure to estimate the parameters of each model <ref type="bibr">(15)</ref>. The unit of analysis was a game, rather than a participant, as games differed in their design and some participants had only one game left in the dataset after exclusions were performed. We used hierarchical models which treat each game as drawn from a common group-level distribution, where parameters at the game level are assumed to be generated by the same group-level prior distribution. We used this approach for all parameters in our models unless explicitly stated otherwise (e.g. game type variable). Parameters at the game level and so-called hyperparameters at the group level mutually constrain each other and we estimate them jointly using a Markov Chain Monte Carlo (MCMC) sampling procedure. We formulated all game-level parameters using a non-centered (probit) parametrization which facilitates MCMC sampling with hierarchical models <ref type="bibr">(16)</ref>.</p><p>We sample hyperparameters from hyperprior distributions, for which we used moderately informative distributions but broad enough to allow data to shift them. We show priors and hyperpriors for each parameter in <ref type="table">Table S1 and Table S2</ref>. We use superscript g on each parameter to refer to the dependence of parameters on game. For example, we assume that the uncertainty guidance parameter from UCB choice rule, β g , is sampled from a prior which is a linear combination of three hyperparameters: µ β determines the mean of the prior, while ζ β and ν β together determine deviations from the mean (this is the non-centered parametrization). This particular parameter should be non-negative and we use an exponential transformation to ensure that. The hyperparameters are in turn sampled from their hyperpriors: µ β from a Normal distribution with mean 0 and standard deviation 1, ζ β from a Half-Normal distribution with mean 0 and standard deviation 1 (half refers to truncation to the [0, ∞) interval), and ν β from a Normal distribution with mean 0 and standard deviation 1. Credible intervals were computed as highest posterior density intervals.</p><p>Fitting using MCMC. We fitted the models to the data using the No-U-Turn-Sampling MCMC algorithm implemented in Stan <ref type="bibr">(7)</ref>. This algorithm approximates the posterior distribution of parameters by generating samples from this posterior distribution given the observed behavioral data. We initialized five independent chains with randomly generated starting values and collected 5000 samples of each chain at a thin rate of 1, after discarding the first 5000 of burn-in samples of each chain. We confirmed that all chains successfully converged by visually inspecting the traceplots of the chains and examining the number of efficient samples andR statistic.</p><p>Model comparison with bridge sampling. We performed model comparison by estimating the model evidence through bridge sampling <ref type="bibr">(17,</ref><ref type="bibr">18)</ref>, using the bridgesampling package in R <ref type="bibr">(19)</ref>. Bridge sampling uses samples from MCMC chains to estimate the log marginal likelihood of a model, which can then be used to compute posterior probabilities of a model being the true one among a set of models <ref type="bibr">(18)</ref>. Following recommendations in (19) we used the "warp3" method and repeated the estimation multiple times (N = 50) to obtain an empirical estimate of error in estimated model evidence (the interquartile range of the estimates). In the figures that illustrate model evidence we report median log marginal likelihoods and posterior probabilities across the repetitions for each model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SI Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional properties of visual fixation.</head><p>In the choice stage, we examined several other measures of visual fixation: number of fixations made across all options and number of distinct options that were fixated. Mean number of fixations decreased over time and there was no difference between games (mixed effects regression estimates: intercept = 9.26, 95% CI <ref type="bibr">[8.57, 9.</ref> In the outcome stage, besides assessing trial-by-trial variability in absolute fixation we also examined variability in the number of fixations. The mean number of fixations decreased over time, same as for absolute fixation, but here there was no difference between games (mixed effects regression estimates: intercept = 4.76, 95% CI As an additional check of differences between games in terms of visual fixations, we regressed out expected values of options in each game from relative fixation time in the choice stage using Dirichlet regressions. Residuals from such regressions should reveal potential differences between games due to differences in the pattern of variances. The results however show no difference between standardized residuals of the two games <ref type="figure" target="#fig_0">(Fig. S1</ref>). This provides additional evidence that the differences between the games, relating to the variance of the lower ranking options only, were too subtle to result in large differences.</p><p>Finally, we investigated some relations between aspects of the fixation process and choices. In particular, we were interested in checking the predictions of how visual fixations influence choice made by <ref type="bibr">(20)</ref>, based on their attentional drift diffusion modeling approach. Even though we could not directly apply this approach to our paradigm because we fixed the duration of the choice stage, we examined to what extent their predictions are born out by our data. First, one assumption <ref type="bibr">(20)</ref> made was that first fixation is unbiased by options' values. In our learning task, participants learn the value of options over time and since the locations of options do not change across the trials we expected this assumption to be violated. Indeed, we found a larger probability of first fixating the best option than expected by chance (mean of 0.31, SE = 0.04; <ref type="figure" target="#fig_2">Fig. S2B</ref>). Another of (20) predictions was that final fixations would be shorter than middle fixations, as fixations are interrupted when the evidence accumulation process hits the bound. In our task there was no free response and we did not expect to see that pattern. Indeed, examining fixation duration by fixation type -first, one of the middle, or last fixation -shows the opposite pattern, where the last fixation duration is longer than the middle ones <ref type="figure" target="#fig_2">(Fig. S2A)</ref>. A final prediction made by (20) which we assessed is that participants should choose the option they looked at last, unless the option is much worse. This prediction did hold in our data as well. Participants indeed increasingly chose the option fixated the last, unless the option was low ranking one ( <ref type="figure" target="#fig_3">Fig. S3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling learning and choices -control models.</head><p>Rescorla-Wagner and Choice kernel based models. We fitted four additional control models to the choices. These models also consisted of a learning component and a choice component. We used three types of learning models: a Choice kernel (CK) model (21), a Rescorla-Wagner (RW) model <ref type="bibr">(11)</ref>, and a combination of both <ref type="bibr">(21)</ref>. These models do not explicitly track estimation uncertainty, but have been often successfully used to model learning in tasks like ours. With these learning models we used two choice models: a Softmax choice model (SM; 12) that we used with all three types of the learning models, and a nonparametric version of an upper confidence bound choice model (UCB; 13) that we used only with the RW model.</p><p>The CK model assumes that participants estimate a so-called choice kernel, CKj(t), which keeps track of how frequently they have chosen option j in the recent past. This choice kernel is updated as CKj(t + 1) = CKj(t) + γ[Ij(t) − CKj(t)], <ref type="bibr">[14]</ref> where γ ∈ (0, 1) is a fixed learning rate parameter and Ij(t) = 1 if option j was chosen on trial t, and 0 otherwise. We initialized estimates of the choice kernel to CKj(0) = 0. The RW model assumes participants update their estimates Ej(t + 1) of the expected value of choosing option j on trial t + 1 from the reward Rj(t) on trial t</p><formula xml:id="formula_27">Ej(t + 1) = Ej(t) + Ij(t)α[Rj(t) − Ej(t)]</formula><p>, <ref type="bibr">[15]</ref> where α ∈ (0, 1) is a fixed learning rate parameter. We initialized estimates of mean values to Ej(0) = 0. The Softmax choice rule uses the estimated kernels or values to make a choice C(t) between the options. In this choice rule exploration occurs by chance -participants choose probabilistically according to relative estimated kernel or value. The CK-SM model used</p><formula xml:id="formula_28">P (C(t) = j) = exp[τ CKj(t)] 6 k=1 exp[τ CK k (t)]</formula><p>, <ref type="bibr">[16]</ref> where the parameter τ &gt; 0 determines the sensitivity to differences in estimated kernels, and with it amount of exploration. The model thus had two parameters: τ and γ. The RW-SM model used</p><formula xml:id="formula_29">P (C(t) = j) = exp[θEj(t)] 6 k=1 exp[θE k (t)]</formula><p>, <ref type="bibr">[17]</ref> with an inverse temperature parameter θ &gt; 0 in addition to α. Finally, the RWCK-SM model used</p><formula xml:id="formula_30">P (C(t) = j) = exp[θEj(t) + τ CKj(t)] 6 k=1 exp[θE k (t) + τ CKj(t)]</formula><p>, <ref type="bibr">[18]</ref> with all four parameters from CK-SM and RW-SM model. The last model was the RW-UCB model. The UCB choice rule uses estimation uncertainty to approximate an option's informativeness, or how much value estimates can be improved by trying an option. While Kalman filter models explicitly track estimation uncertainty, the RW model does not. Therefore we use a nonparametric form of the UCB, using current trial t and number of times the options were chosen Nj as proxies P (C(t) = j) = exp{θ(Ej(t) + β log(t)/Nj)} 6 k=1 exp{θ(E k (t) + β log(t)/Nj)} , <ref type="bibr">[19]</ref> where β &gt; 0 is the weight a participant places on estimation uncertainty. We fitted these models to the choice data using hierarchical Bayesian model estimation (see "Modeling choices with visual fixations alone" in SI Methods). Model evidence shows that the models consisting of Kalman filter learning and UCB choice rule fit the data better than those based on Rescorla-Wagner, choice kernel learning, or both <ref type="figure" target="#fig_5">(Fig. S4)</ref>. The lazy Kalman filter model with a UCB choice rule described participants' choices best (KFL-UCB), with a posterior probability of approximately 0.99. All other models have a posterior probability of approximately zero. The Rescorla-Wagner UCB model (RW-UCB) performed particularly poorly, indicating that a nonparametric form of the UCB choice rule based on the number of times an option has been chosen does not describe behavior well. KFL-UCB model with unconstrained β parameter. The only difference between the KFL-UCB model that fitted the choices the best and its Softmax counterpart, KFL-SM, is the β parameter, that acts as a weight on uncertainty in the UCB choice rule. The strong evidence favoring the KFL-UCB model over the KFL-SM model indicates that the β parameter is reliably different from zero. In estimating the β parameter in the KFL-UCB model, we assumed that it can not be negative. As an additional check, we here also estimate an unconstrained model where β can be positive or negative. While the notion of directed exploration rests on a positive value of β, it is possible that participants are averse to irreducible uncertainty and negative values of the β parameter can capture such uncertainty or risk aversion <ref type="bibr">(22)</ref>. This makes interpretation of a negative value of β complicated, as the parameter may be negative when there is both directed exploration and risk aversion.</p><p>We fitted the unconstrained KFL-UCB model using hierarchical Bayesian parameter estimation (see "Hierarchical bayesian parameter estimation" in SI Methods). Comparing only the two models of interest, the KFL-UCB model with the non-negative β parameter outperformed the unconstrained KFL-UCB model with a posterior probability of approximately 0.99. Moreover, the β parameter of the unconstrained model was overwhelmingly positive (posterior mean of 0.48, 95% CI [0.21, 0.76]). This result further affirms that the β parameter is positive. In addition, we also compared the model to all other choice models (KFL-UCB unc; <ref type="figure" target="#fig_5">Fig. S4</ref>). The unconstrained KFL-UCB model is a second best model, after the constrained KFL-UCB model. These two models, together with KF-UCB, outperformed all others by a large margin.</p><p>Choice models with unsigned prediction errors. The analyses of interactions between the learning and fixation process showed that unsigned prediction error was the strongest predictor of absolute fixations in the outcome stage of the trial. This provided evidence for a theory-driven expectation that time spent looking at the reward feedback is guided by uncertainty <ref type="bibr">(23)</ref>. This result also suggests that unsigned prediction errors could reflect a more important form of uncertainty for guiding choices than estimation uncertainty. Hence, a model that uses unsigned prediction errors instead of estimation uncertainty in the UCB choice rule could potentially explain choices better than the currently best-fitting KFL-UCB model. Here we investigate this further.</p><p>In the analysis of fixation data we regressed unsigned prediction error from the current trial on the total fixation duration in the outcome stage of the trial. For predicting choices, the prediction error from the previous trial would not be sensible as uncertainty would not be defined for those options which were not chosen on the previous trial. Instead, it is reasonable to maintain estimates of uncertainty based on unsigned prediction errors that are updated from trial to trial.</p><p>Based on this idea we implemented two models. The first model is a KFL-UPE model that uses a simple delta-rule to learn slow-moving estimates of unsigned prediction errors coming from the lazy Kalman filter learning model. Hence, besides the usual lazy Kalman filter learning (Eq. 1 and 2), the KFL-UPE model assumes participants update their estimates of unsigned prediction errors Uj(t + 1) based on chosen option j on trial t + 1 from the reward Rj(t) on trial t and estimated value Ej(t) (from Eq. 1)</p><formula xml:id="formula_31">Uj(t + 1) = Uj(t) + Ij(t)ζ|Rj(t) − Ej(t)|,<label>[20]</label></formula><p>where ζ ∈ (0, 1) is a fixed learning rate parameter. We initialized estimates to Uj(0) = 100. Term Ij(t) is an indicator variable, with value of 1 if option j is chosen on trial t and 0 otherwise. These estimates were then used in a UCB-like choice rule where instead of estimation uncertainty we used estimates of unsigned prediction errors, Uj(t). The probability of choosing option j at trial t is given by</p><formula xml:id="formula_32">P (C(t) = j) = exp{θ(Ej(t) + β Uj(t))} 6 k=1 exp{θ(E k (t) + β U k (t))} ,<label>[21]</label></formula><p>where β &gt; 0 is the weight a participant places on uncertainty and the inverse temperature parameter θ &gt; 0 determines the sensitivity to differences in the values. The second model is a K2-UPE model that uses the K2 learning model which computes estimates of unsigned prediction errors in a more principled manner, following <ref type="bibr">(24)</ref>. In the K2 model these uncertainty estimates are used to dynamically modulate the learning rate, making the K2 model an alternative to the Kalman learning. The K2 model assumes participants update their estimates Ej(t + 1) of the expected reward of choosing option j on trial t + 1 from the observed reward Rj(t) on trial t as</p><formula xml:id="formula_33">Ej(t + 1) = Ej(t) + Ij(t)Kj(t)[Rj(t) − Ej(t)]</formula><p>. <ref type="bibr">[22]</ref> where term Kj(t) is a dynamic learning rate, similar to the Kalman filter learning model. Term Ij(t) is an indicator variable, with value of 1 if option j is chosen on trial t and 0 otherwise. The learning rate is updated on each trial as</p><formula xml:id="formula_34">Kj(t) = Sj(t) Sj(t) +Rj ,<label>[23]</label></formula><p>where Sj(t) is the uncertainty estimate. The K2 algorithm adapts S(t) by performing gradient descent in a corresponding set of parameters b(t), where the two are related by Sj(t) = exp{bj(t + 1)}. <ref type="bibr">[24]</ref> The parameters b(t) are updated as</p><formula xml:id="formula_35">bj(t + 1) = bj(t) + νIj(t)[(Rj(t) − Ej(t)) 2 −Rj − 6 k=1 S k (t)]</formula><p>, <ref type="bibr" target="#b24">[25]</ref> where ν &gt; 0 is a step-size parameter and b(t) parameters are initialized as bj(0) = logRj. <ref type="bibr" target="#b25">[26]</ref> Finally We combined the K2 learning model with a UCB-like choice rule where instead of estimation uncertainty we used uncertainty estimates (Sj(t)) from the K2 learning model. The probability of choosing option j at trial t is given by</p><formula xml:id="formula_36">P (C(t) = j) = exp{θ(Ej(t) + β Sj(t))} 6 k=1 exp{θ(E k (t) + β S k (t))}</formula><p>, <ref type="bibr" target="#b26">[27]</ref> where β &gt; 0 is the weight a participant places on uncertainty and the inverse temperature parameter θ &gt; 0 determines the sensitivity to differences in the values.</p><p>We fitted the new model using hierarchical Bayesian parameter estimation (see "Hierarchical Bayesian parameter estimation" in SI Methods). The KFL-UCB model outperformed both the K2-UPE and KFL-UPE model with a posterior probability of approximately 1. This result affirms that for explaining choices it is estimation uncertainty that matters the most, not unsigned prediction error. In addition, we also compared the new models to all other choice models <ref type="figure" target="#fig_5">(Fig. S4</ref>). Even though in simulations the K2 algorithm seems like a good competitor to the Kalman filter algorithm <ref type="bibr">(24)</ref>, the K2-UPE model does not fit the behavior of our participants well. It outperforms only the RW-UCB and CK-SM model by a convincing margin, and fits choices similar to the KF-SM model. The KFL-UCb model fits the behavior somewhat better than the K2-UPE, but is still substantially worse than Kalman filter models combined with the UCB choice rule, as well as RWCK-SM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison of learning and choice models modulated by visual fixation.</head><p>In our original analysis we assumed visual fixations can modulate the choice or learning component of the KFL-UCB model that best fitted the behavior (see "Modeling learning and choices modulated by visual fixations" in SI Methods). However, it is possible that certain components of the winning KFL-UCB model may become unnecessary once fixation information is taken into account. For example, the Softmax choice rule might outperform the UCB rule or the "laziness" parameter in the Kalman filter may become unnecessary once we include the fixation information. Hence, as a robustness check, we fitted additional attention-modulated models.</p><p>To assess the robustness of our finding that the UCB choice rule is relevant, we considered the Softmax choice rule combined with the same KFL learning component. As in the attention-modulated UCB rule, we here use the relative fixation measure defined in Eq. 11 to re-weight the values in the Softmax (Eq. 3)</p><formula xml:id="formula_37">P (C(t) = j) = exp{τ RFj(t) + θEj(t)} 6 k=1 exp{τ RF k (t) + θE k (t)}</formula><p>. <ref type="bibr" target="#b27">[28]</ref> This re-weighting again has the effect of increasing the choice probabilities for options that received relatively more fixation time and diminishing them for the options that received relatively little fixation time. The learning process in the KFL component is modulated in the same way as in Eq. 13. Overall, we have three additional KFL-SM model variants where either learning (aKFL-SM), the choice process (KFL-aSM), or both (aKFL-aSM) are modulated by attention.</p><p>To confirm the usefulness of the laziness parameter we also considered the non-lazy Kalman filter model (KF), combined with either an attention-modulated Softmax choice rule (KF-aSM; as in Eq. 28) or an attention-modulated UCB choice rule (KF-aUCB; as in Eq. 12). As we could not modulate the learning process of the KF component without effectively making it a "lazy" version, we only modulate the choice process.</p><p>We fitted all five models using hierarchical Bayesian parameter estimation (see "Hierarchical Bayesian parameter estimation" in SI Methods). The results of all five models, together with the three original models (aKFL-UCB, KFL-aUCB and aKFL-aUCB), are illustrated in <ref type="figure">Fig. S6</ref>. The results show that the KFL-aUCB is still the best fitting model, with a posterior probability of approximately 0.77. The aKFL-aUCB model, in which learning is also modulated by fixation at the outcome stage, obtained the remaining posterior probability of approximately 0.23. All other attention modulated models received negligible evidence. What is clearly visible from the ordering of the model performances is that the UCB component is needed <ref type="figure">(Fig. S6</ref>). All models with the UCB component clearly outperformed models with the SM component. Next, attention modulation of the choice process has a large impact on explaining choices. The aKFL-SM and aKFL-UCB model without it performed poorly, coming last in the ordering. The "laziness" parameter is important as well, all models with the "laziness" parameter outperform models without it. Modeling learning and choices -Control models CK learning rate, γ g Φ(µγ + ζγνγ) µγ ∼ Normal(−1, 1), ζγ ∼ Half-Normal(0, 1), νγ ∼ Normal(0, 1) RW learning rate, α g Φ(µα + ζανα) µα ∼ Normal(−1, 1), ζα ∼ Half-Normal(0, 1), να ∼ Normal(0, 1) K2 learning rate, ν g exp(µν + ζν νν ) µν ∼ Normal(−1, 1), ζν ∼ Half-Normal(0, 1), νν ∼ Normal(0, 1) K2 reward variance, σ <ref type="bibr">2,g</ref> exp(µ σ 2 + ζ σ 2 ν σ 2 ) µ σ 2 ∼ Normal(0, 1), ζ σ 2 ∼ Half-Normal(0, 1), ν σ 2 ∼ Normal(0, 1) UPE learning rate, ζ g Φ(µ ζ + ζ ζ ν ζ ) µ ζ ∼ Normal(0, 1), ζ ζ ∼ Half-Normal(0, 1), ν ζ ∼ Normal(0, 1) CK sensitivity, τ g exp(µτ + ζτ ντ ) µτ ∼ Normal(0, 1), ζτ ∼ Half-Normal(0, 1), ντ ∼ Normal(0, 1) Inverse temperature, θ g exp(µ θ + ζ θ ν θ ) µ θ ∼ Normal(0, 1), ζ θ ∼ Half-Normal(0, 1), ν θ ∼ Normal(0, 1) Uncertainty guidance, β g exp(µ β + ζ β ν β ) µ β ∼ Normal(0, 3), ζ β ∼ Half-Normal(0, 1), ν β ∼ Normal(0, 1)</p><p>Note. All models use non-centered reparametrization as indicated in Prior column, often transformed to constrain the parameters to be non-negative (exp) or to a certain range (Probit function, Φ). In addition to the parameter specification listed in Modeling learning and choices modulated by visual fixations panel, these models have the same parameters and associated priors as models in Modeling learning and choices panel. RF = relative fixation, CK = Choice kernel model, RW = Rescorla-Wagner model, UPE = unsigned prediction error, K2 = learning model from <ref type="bibr">(24)</ref>. Half-Normal(0, 1) -Shape, α g Normal(−2, 1) -Note. All models use non-centered reparametrization as indicated in Prior column, often transformed to constrain the parameters to be non-negative (exp). Game type parameter in both groups of models was assumed to be fixed effect and hence only prior was necessary. We used same assumption for scale and shape parameter in models of absolute fixation in the outcome stage. PE = Prediction error parameter, uPE = unsigned prediction error parameter. . Standardized residuals after regressing out expected values of options from relative fixations in choice stage do not differ between the games. We fitted a Dirichlet regression model to each game, similar to models of relative fixation in choice stage (see "Modeling choices with visual fixations alone" in SI Methods). Expected values were passed through a softmax function to produce concentration parameters in Dirichlet distributed relative fixation data. We fitted the models to the first block of 15 trials where we expected the differences between the games to be the strongest. Fixated option rank P(last fixation to chosen) <ref type="figure" target="#fig_3">Fig. S3</ref>. Participants increasingly chose the option fixated the last, unless the option was low ranking one, as learning went by. This is evidenced by increase in probability that last fixation is to the chosen option for higher ranking options and decrease for lower ranking options, from first block of 15 trials to fourth block of 15 trials in the game. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Illustration of the six-armed bandit task. (A) Participants chose between six options on each of 60 trials. Each option was represented by a letter from the Gljagoljica alphabet. Options were displayed in a circle around the centre of the screen, always at the same location. (B) Time course of a single trial.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>(A)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Interactions between choice and relative fixation in the choice stage. (A) Density of total fixation duration for all games. Options disappear after 5 s, but participants sometimes kept fixating on the same location before triggering the execution stage. (B) Posteriors of the group-level value (Val) and (C) uncertainty parameter (Unc) in the full model regressing value and uncertainty on relative fixation. Both parameters are clearly positive, as evident from the mean (vertical line) and 95% credible intervals entirely above zero (CI, black bar on the x-axis). Dots are posterior means of individual game level parameters. (D) Model evidence (bars) and model comparison (numbers above bars)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>36, 95% CI [2.20, 2.52]; block = −0.10, 95% CI [−0.14, −0.05]; game = −0.06, 95% CI [−0.22, 0.10]; block×game = 0.06, 95% CI [0.01, 0.11])</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Interactions between learning and fixation processes at outcome stage. (A) Density of absolute fixation in the outcome stage. Even though the option and feedback disappear after 3 s participants often kept fixating on the same location during the inter-trial interval (ITI). Fixations that extended 2 s into the ITI (i.e. 5 s in total) were also used in the analysis. (B) Like uncertainty and unsigned reward prediction errors, absolute fixation decreased over the course of learning. (C) Posterior of the group-level slope parameter in the model regressing unsigned reward prediction error (βuPE) on absolute fixations in the outcome stage. Almost complete posterior is positive, including the 95% credible interval (CI, black bar on the x-axis), indicating a clearly positive relationship. (D)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Participants.</head><label></label><figDesc>We recruited 34 participants (18 female, Mage = 26.8 and SDage = 8.1) from the Aarhus University subject pool. After applying a priori exclusion criteria separately to each game played by each participant, 23 participants remained (12 female, Mage = 26.9 and SDage = 8.4), 36 games in total, 19 Decreasing variances and 17 V-shaped variances game (see SI Appendix, Methods for details). The experimental sessions were conducted individually in the Cognition and Behavior Lab at Aarhus University and lasted for 75 minutes on average. Participants had normal or corrected to normal vision. The study was approved by the Aarhus University Research Ethics Committee and all participants provided written informed consent. Participants received a show-up fee of 100 Danish krone and an additional performance-contingent bonus (100 Danish krone on average).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Modeling learning and choices. We fitted four main computational models to participants' choices. Each model consists of a learning and a choice component. The learning component is either a Kalman filter (KF) (8, 13, 36) or a "lazy" Kalman filter (KFL) model. For the choice component the models used either a softmax (SM; 37), or an upper confidence bound choice rule (UCB; 14)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Toby Wise, Eran Eldar, Nitzan Shahar and Rani Moran for their feedback on the project. We thank Anna Nason for help with collecting the data. H.S., J.L.O., and R.D. were funded by Lundbeckfonden, Grant number: R281-2018-27. H.S. and R.D. were funded by the Max Planck Society, Munich, Germany, https://www.mpg.de/en, Grant number: 647070403019. R.D. was also funded by the Wellcome Trust, https://wellcome.ac.uk/home, Grant number/reference: 098362/Z/12/Z. P.D. was funded by the Gatsby Charitable Foundation and the Max Planck Society.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>95]; block = −0.52, 95% CI [−0.78, −0.26]; game = 0.10, 95% CI [−0.60, 0.80]; block×game = −0.24, 95% CI [−0.51, 0.02]). Mean number of unique option fixations decreased over time and there was a weak difference between games (mixed effects regression estimates: intercept = 2.99, 95% CI [2.67, 3.31]; block = −0.15, 95% CI [−0.25, −0.04]; game = 0.06, 95% CI [−0.26, 0.38]; block×game = −0.14, 95% CI [−0.25, −0.04]), as evidenced by block and block-game interaction estimates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>[4.40, 5.11]; block = −0.17, 95% CI [−0.30, −0.05]; game = −0.12, 95% CI [−0.49, 0.23]; block×game = 0.08, 95% CI [−0.05, 0.20]). The negative effect of block suggests that the decrease in number of fixations, but not fixation durations, is likely driving the decrease in absolute fixation. The standard deviation of number of fixations is sizable (mixed effects regression estimates: intercept = 1.97, 95% CI [1.87, 2.08]; block = 0.04, 95% CI [−0.02, 0.10]; game = 0, 95% CI [−0.10, 0.10]; block×game = −0.01, 95% CI [−0.07, 0.05]), as evidenced by intercept estimate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Table S1 .σ 2 i+ ζ σ 2 i ν σ 2 i) µ σ 2 i∼ Normal( 2 , 1 ), ζ σ 2 i∼ 2 i∼ 2 ζ+ ζ σ 2 ζ ν σ 2 ζ) µ σ 2 ζ∼ 2 ζ∼ 2 ζ∼ 1 )</head><label>S1222221222222221</label><figDesc>Parameters, priors and hyperpriors for choice models. Each panel denotes parameters for a group of models as described in Materials and Methods and SI Methods.Half-Normal(0, 1), ν σ Normal(0, 1) Innovation variance, σ 2,g ζ exp(µ σ Normal(0, 1), ζ σ Half-Normal(0, 1), ν σ Normal(0, 1) Inverse temperature, θ g exp(µ θ + ζ θ ν θ ) µ θ ∼ Normal(0, 1), ζ θ ∼ Half-Normal(0, 1), ν θ ∼ Normal(0, 1) Uncertainty guidance, β g exp(µ β + ζ β ν β ) µ β ∼ Normal(0, 1), ζ β ∼ Half-Normal(0, 1), ν β ∼ Normal(0, 1) Laziness, η g Φ(µη + ζηνη) µη ∼ Normal(1, 1), ζη ∼ Half-Normal(0, 1), νη ∼ Normal(0, 1)Modeling learning and choices modulated by visual fixation RF sensitivity, τ g exp(µτ + ζτ ντ )µτ ∼ Normal(0, 2), ζτ ∼ Half-Normal(0, 1), ντ ∼ Normal(0, 1) RF min attention, g Φ(µ + ζ ν ) µ ∼ Normal(−1, 1), ζ ∼ Half-Normal(0, 1), ν ∼ Normal(0, 1) Laziness intercept, η g 0 µη 0 + ζη 0 νη 0 µη 0 ∼ Normal(1, 1), ζη 0 ∼ Half-Normal(0, 1), νη 0 ∼ Normal(0, 1) Laziness slope, η g 0 µη 0 + ζη 0 νη 0 µη 0 ∼ Normal(0, 1), ζη 0 ∼ Half-Normal(0, 1), νη 0 ∼ Normal(0,Modeling choices with visual fixation alone RF min attention, g Φ(µ + ζ ν ) µ ∼ Normal(−1, 1), ζ ∼ Half-Normal(0, 1), ν ∼ Normal(0, 1) RF sensitivity, τ g exp(µτ + ζτ ντ ) µτ ∼ Normal(0, 2), ζτ ∼ Half-Normal(0, 1), ντ ∼ Normal(0, 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>1 )</head><label>1</label><figDesc>Table S2. Parameters, priors and hyperpriors for modeling relative fixation in the choice stage and for modeling absolute fixation in the outcome stage. Each panel denotes parameters for a group of models as described in Materials and Methods and SI Methods.ParameterPrior HyperpriorsModeling relative fixation in the choice stageValue, β g v µ βv + ζ βv ν βv µ βv ∼ Normal(0, 2), ζ βv ∼ Half-Normal(0, 1), ν βv ∼ Normal(0, 1) Uncertainty, β g u µ βu + ζ βu ν βu µ βu ∼ Normal(0, 2), ζ βu ∼ Half-Normal(0, 1), ν βu ∼ Normal(0, 1) Game type, βgt Normal(0, 5) -Precision, κ g exp(µκ + ζκνκ) µκ ∼ Normal(0, 1), ζκ ∼ Half-Normal(0, 1), νκ ∼ Normal(0,Modeling absolute fixation in the outcome stageIntercept, β g i µ β i + ζ β i ν β i µ β i ∼ Normal(2, 0.5), ζ β i ∼ Half-Normal(0, 0.5), ν β i ∼ Normal(0, 0.5) Value, β g v µ βv + ζ βv ν βv µ βv ∼ Normal(0, 0.2), ζ βv ∼ Half-Normal(0, 0.2), ν βv ∼ Normal(0, 0.2) Uncertainty, β g u µ βu + ζ βu ν βu µ βu ∼ Normal(0, 0.2), ζ βu ∼ Half-Normal(0, 0.2), ν βu ∼ Normal(0, 0.2) PE, β g PE µ β PE + ζ β PE ν β PE µ β PE ∼ Normal(0, 0.2), ζ β PE ∼ Half-Normal(0, 0.2), ν β PE ∼ Normal(0, 0.2) uPE, β g uPE µ β uPE + ζ β uPE ν β uPE µ βuPE ∼ Normal(0, 0.2), ζ β uPE ∼ Half-Normal(0, 0.2), ν β uPE ∼ Normal(0, 0.2) Game type, βgt Normal(0, 0.2) -Scale, ω g</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Fig. S1. Standardized residuals after regressing out expected values of options from relative fixations in choice stage do not differ between the games. We fitted a Dirichlet regression model to each game, similar to models of relative fixation in choice stage (see "Modeling choices with visual fixations alone" in SI Methods). Expected values were passed through a softmax function to produce concentration parameters in Dirichlet distributed relative fixation data. We fitted the models to the first block of 15 trials where we expected the differences between the games to be the strongest.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. S4 .Fig. S5 .Fig. S6 .Fig. S7 .</head><label>S4S5S6S7</label><figDesc>Model evidence for all choice models. Bars show the median log marginal likelihoods and numbers below the bars show the median posterior probabilities from model comparisons. The lazy Kalman filter learning component combined with the upper confidence bound choice rule (KFL-UCB) describes the participants' choices best. Error bars reflect interquartile ranges of values across repetitions; for most models, these are too small to be visible. Posterior distributions of the estimated group-level parameters for the KFL-UCB model not illustrated in the main text. (A) Innovation variance parameter in the Kalman filter learning model (σ 2 ζ ). The posterior mean (vertical line) and 95% credible interval (black bar on the x-axis) illustrate the magnitude of the effect. Dots are means of posteriors of individual game level parameters; the vertical jitter is arbitrary. (B) Initial variance parameter in the Kalman filter learning model (σ 2 i ). (C) Laziness parameter in the Kalman filter learning model (η). (D) Temperature parameter in the Upper confidence bound rule (θ). Model evidence for all attention modulated models. Bars show the median log marginal likelihoods and numbers below the bars show the median posterior probabilities from model comparisons. The lazy Kalman filter learning component combined with the attention-modulated upper confidence bound choice rule (KFL-aUCB) describes the participants' choices best. Error bars reflect interquartile ranges of values across repetitions; for most models, these are too small to be visible. Interactions between learning and fixation processes at outcome stage. Model evidence (bars) and model comparison (numbers below bars) for the full modelregressing uncertainty (Unc), reward prediction error (PE), unsigned reward prediction error (uPE) and value (Val) on absolute fixations in the outcome stage, and simpler model variants where we excluded some of the predictors. The model with unsigned prediction errors alone explains absolute fixations the best among the compared models. Error bars are interquartile ranges of bridge sampling repetitions (modeling details in SI Methods).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>75, 2.35, 1.95, 1.55, 1.15, 0.75] in Decreasing variances and [2.75, 2.35, 1.95, 1.95, 2.35, 2.75] in V-shaped variances game. This imposes different learning rates for each option, influenced by its objective reward distribution variance. To estimate the Kalman filter learning model one of the three parameters (σ 2</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>,R is an estimate of irreducible uncertainty. Here we used the objective reward variances, [2.75, 2.35, 1.95, 1.55, 1.15, 0.75] in the Decreasing variances and [2.75, 2.35, 1.95, 1.95, 2.35, 2.75] in the V-shaped variances game, rescaled by a free parameter σ 2 .</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">| Stojic et al.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Stojic et al.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">H. Stojić, J.L. Orquin, P. Dayan, R.J. Dolan and M. Speekenbrink</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information Appendix for</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Optimal filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bd Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Courier Corporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A model for pavlovian learning: variations in the effectiveness of conditioned but not of unconditioned stimuli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jm Pearce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page">532</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning and selective attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1218</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning the value of information in an uncertain world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Te</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woolrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rushworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1214</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Payzan-Lenestour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1001048</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An approximately bayesian delta-rule model explains the dynamics of belief updating in a changing environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mr Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Heasly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="12366" to="12378" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multi-armed bandit allocation indices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gittins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glazebrook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Uncertainty and Exploration in a Restless Bandit Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Konstantinidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Top. Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="351" to="367" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Humans use directed and random exploration to solve the explore-exploit dilemma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rc Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Gen</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="2074" to="2081" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">It&apos;s new, but is it good? how generalization and uncertainty guide the exploration of novel options</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pp Analytis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Speekenbrink</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deconstructing the human algorithms for exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sj Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="34" to="42" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The nature of belief-directed exploratory choice in human decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wb Knox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">398</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cortical substrates for exploratory decisions in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Nd Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">441</biblScope>
			<biblScope unit="page" from="876" to="879" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wr Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="285" to="294" />
			<date type="published" when="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A computational account of threat-related attentional bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Michely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1007341</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Eyes on the prize? evidence of diminishing attention to experienced and foregone outcomes in repeated experiential choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nj Ashby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rakow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Behav. Decis. Mak</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="183" to="193" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visual fixations and the computation and comparison of value in simple choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Armel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1292" to="1298" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gaze data reveal distinct choice processes underlying model-based and model-free reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Konovalov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krajbich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12438</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Eye tracking and pupillometry are indicators of dissociable latent decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jf Cavanagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kochar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Gen</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">1476</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gaze bias both reflects and influences preference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scheier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1317</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dynamic interaction between reinforcement learning and attention in multidimensional environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yc Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radulescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dewoskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="451" to="463" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Forward inference in risky choice: Mapping gaze and decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schoemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schulte-Mecklenbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renkewitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scherbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Behav. Decis. Mak</title>
		<imprint>
			<biblScope unit="issue">0</biblScope>
		</imprint>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The role of uncertainty in attentional and choice exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Me Le Pelley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beesley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon. Bull. &amp; Rev</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nonparametric learning rules from bandit experiments: The eyes have it! Games Econ</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kayaba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="215" to="231" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhaoping</surname></persName>
		</author>
		<title level="m">Understanding Vision: Theory, Models, and Data</title>
		<meeting><address><addrLine>Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Effects of salience are both short-and long-lived</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jl Orquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lagerkvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychol</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="69" to="76" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attention and choice: A review on eye movements in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jl Orquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychol</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="190" to="206" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The time course of perceptual choice: the leaky, competing accumulator model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">550</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The diffusion decision model: theory and data for two-choice decision tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="873" to="922" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Overlapping mechanisms of attention and spatial working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Awh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jonides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="119" to="126" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Interactions between attention and working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Awh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="201" to="208" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Look here, eye movements play a functional role in memory retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="236" to="242" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Memory for scenes: Refixations reflect retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Holm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mäntylä</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mem. &amp; Cogn</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1664" to="1674" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The role of locus coeruleus in the regulation of cognitive performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Servan-Schreiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rajkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aston-Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="page" from="549" to="554" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A causal role for right frontopolar cortex in directed, but not random, exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wk Zajkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kossut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">27430</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rs Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dopamine: Generalization and bonuses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>S Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="549" to="559" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Doing Bayesian data analysis: A tutorial with</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jk Kruschke</surname></persName>
		</author>
		<editor>R, JAGS, and Stan.</editor>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Biasing simple choices by manipulating relative visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kc Armel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beaumel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgm. Decis. making</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="396" to="403" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rs Sutton</surname></persName>
		</author>
		<title level="m">Gain adaptation beats least squares in Proceedings of the 7th Yale workshop on adaptive and learning systems</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="161" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multi-Armed Bandits and the Gittins Index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Whittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Stat. Soc. Ser. B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="143" to="149" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Post choice information integration as a causal determinant of confidence: Novel data and a computational account</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Usher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="99" to="147" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Confidence modulates exploration and exploitation in value-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B De</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurosci. Conscious</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deconstructing risk: Separable encoding of variance and skewness in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Symmonds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1139" to="1149" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Neural activity in the human brain relating to uncertainty and arousal during anticipation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hd Critchley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="537" to="545" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Neural coding of uncertainty and probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wj Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jazayeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="205" to="220" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Bayesian inference with probabilistic population codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wj Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1432</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Uncertainty and predictiveness determine attention to cues during human associative learning. The Q</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Beesley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Me</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pelley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="2175" to="2199" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Interactions between working memory, attention and eye movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Theeuwes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belopolsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Olivers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychol</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="106" to="114" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Working memory as internal attention: toward an integrative account of internal and external selection processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kiyonaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Egner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon. Bull. &amp; Rev</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="228" to="242" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Reinforcement-based decision making in corticostriatal circuits: mutual constraints by neurocomputational and diffusion models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1186" to="1229" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The drift diffusion model as the choice rule in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ml Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon. Bull. &amp; review</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1234" to="1251" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">fmri and eeg predictors of dynamic decision parameters during human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mj Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="485" to="494" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Putting bandits into context: How function learning supports decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Learn. Mem. Cogn</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="927" to="943" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A theory of attention: variations in the associability of stimuli with reinforcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nj Mackintosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">276</biblScope>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Two theories of attention: A review and a possible integration in Attention and associative learning: From brain to behaviour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jm Pearce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mackintosh</surname></persName>
		</author>
		<editor>C Mitchell, M LePelley.</editor>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="11" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Uncertainty, neuromodulation, and attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aj Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="681" to="692" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Reinforcement learning in multidimensional environments relies on attention mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8145" to="8157" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Modeling the evolution of beliefs using an attentional focus mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gläscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bossaerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1004558</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Saliency, attention, and visual search: An information theoretic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ndb Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsotsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jm Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="346" to="349" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Eye movements for reward maximization in Advances in neural information processing systems. (Neural Information Processing Systems Foundation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sprague</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ballard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1467" to="1474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The role of uncertainty and reward on eye movements in a virtual driving task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bt Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ca Rothkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hayhoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Attention as foraging for information and value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Husain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Hum. Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">711</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Uncertainty in learning, choice and visual fixation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Orquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Speekenbrink</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019-12-10" />
		</imprint>
	</monogr>
	<note>Available at https: //osf.io/539ps</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">file:glagolitic rtsi.svg, file:glagolitic shta.svg, file:glagolitic tverdo.svg, file:glagolitic yerj.svg, file:glagolitic vedi.svg, file:glagolitic az.svg -wikimedia commons, the free media repository</title>
		<ptr target="https://commons.wikimedia.org/w/index.php?title=File:Glagolitic_az.svg" />
	</analytic>
	<monogr>
		<title level="m">MacedonianBoy, File:glagolitic zhivete.svg, file:glagolitic zemlja.svg, file:glagolitic slovo.svg, file:glagolitic ljudi.svg, file:glagolitic fita.svg, file:glagolitic izhe.svg, file:glagolitic iota.svg, file:glagolitic kako.svg, file:glagolitic mislete.svg, file:glagolitic on.svg, file:glagolitic ot.svg, file:glagolitic pokoi.svg</title>
		<imprint>
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
	<note>?title=File:Glagolitic_mislete.svg. CC BY-SA 3.0 Licence; Online, accessed 14</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Mapping and correcting the influence of gaze position on pupil size measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tr Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav. Res. Methods</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="510" to="527" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">PsychoPy -Psychophysics software in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jw Peirce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci. Methods</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="8" to="13" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Eye tracking: A comprehensive guide to methods and measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Holmqvist</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>OUP</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<title level="m">R: A Language and Environment for Statistical Computing (R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">brms: An R package for Bayesian multilevel models using Stan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bürkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Softw</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Development Team</surname></persName>
		</author>
		<title level="m">RStan: the R interface to Stan</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>R package version 2.18.2</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Uncertainty and Exploration in a Restless Bandit Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Konstantinidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Top. Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="351" to="367" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Cortical substrates for exploratory decisions in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Nd Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">441</biblScope>
			<biblScope unit="page" from="876" to="879" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">A causal role for right frontopolar cortex in directed, but not random, exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wk Zajkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kossut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">27430</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement in Classical conditioning II: Current research and theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ra Rescorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wagner</surname></persName>
		</author>
		<editor>AH Black, WF Prokasy.</editor>
		<imprint>
			<date type="published" when="1972" />
			<publisher>Appleton-Century-Crofts</publisher>
			<biblScope unit="page" from="64" to="99" />
			<pubPlace>New York, NY, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rs Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Dopamine: Generalization and bonuses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>S Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="549" to="559" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Doing Bayesian data analysis: A tutorial with</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jk Kruschke</surname></persName>
		</author>
		<editor>R, JAGS, and Stan.</editor>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Hamiltonian Monte Carlo for hierarchical models. Curr. trends Bayesian methodology with applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Girolami</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="79" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Simulating ratios of normalizing constants via a simple identity: a theoretical exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xl Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sinica</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="831" to="860" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A tutorial on bridge sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qf Gronau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Psychol</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="80" to="97" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">bridgesampling: Bridge Sampling for Marginal Likelihoods and Bayes Factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qf Gronau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>R package version 0.6-0</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Visual fixations and the computation and comparison of value in simple choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Armel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1292" to="1298" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Ten simple rules for the computational modeling of behavioral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rc Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">49547</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Under pressure: The influence of time limits on human exploration in Proceedings of the 41st annual conference of the cognitive science society</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gerbaulet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tj Pleskac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive Science Society)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1219" to="1225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Learning and selective attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1218</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rs Sutton</surname></persName>
		</author>
		<title level="m">Gain adaptation beats least squares in Proceedings of the 7th Yale workshop on adaptive and learning systems</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="161" to="166" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
