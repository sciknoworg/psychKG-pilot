<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Effects of Sensorimotor and Linguistic Information on the Basic-Level Advantage</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rens</forename><surname>Van Hoef</surname></persName>
							<email>r.vanhoef@lancaster.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Lancaster University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louise</forename><surname>Connell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Lancaster University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Maynooth University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dermot</forename><surname>Lynott</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Maynooth University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology, Fylde College</orgName>
								<orgName type="institution">Lancaster University</orgName>
								<address>
									<postCode>LA1 4YF</postCode>
									<settlement>Bailrigg, Lancaster</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Effects of Sensorimotor and Linguistic Information on the Basic-Level Advantage</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>sensorimotor simulation</term>
					<term>linguistic distributional knowledge</term>
					<term>conceptual processing</term>
					<term>embodied cognition</term>
					<term>basic-level advantage</term>
					<term>categorisation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The basic-level advantage is one of the best-known effects in human categorisation. Traditional accounts argue that basic-level categories present a maximally informative or entry level into a taxonomic organisation of concepts in semantic memory. However, these explanations are not fully compatible with most recent views on the structure of the conceptual system such as linguistic-simulation accounts, which emphasise the dual role of sensorimotor (i.e., perception-action experience of the world) and linguistic distributional information (i.e., statistical distribution of words in language) in conceptual processing. In four preregistered word→picture categorisation studies, we examined whether novel measures of sensorimotor and linguistic distance contribute to the basic level-advantage in categorical decision-making. Results showed that overlap in sensorimotor experience between category concept and member concept (e.g., animal→dog) predicted RT and accuracy at least as well as a traditional division into discrete subordinate, basic, and superordinate taxonomic levels. Furthermore, linguistic distributional information contributed to capturing effects of graded category structure where typicality ratings did not. Finally, when image label production frequency was taken into account (i.e., how often people actually produced specific labels for images), linguistic distributional information predicted RT and accuracy above and beyond sensorimotor information. These findings add to our understanding of how sensorimotor-linguistic theories of the conceptual system can explain categorisation behaviour.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Effects of Sensorimotor and Linguistic Information on the Basic-Level Advantage</head><p>Categorisation is critical to our everyday cognitive functioning. Representative categories and concepts 1 allow us to adequately perceive, think about, perform actions with and speak about our day-to-day experience <ref type="bibr" target="#b50">(Lakoff, 1987)</ref>. Without categories, we would have to treat every object, action or event as a unique instance, rendering us overwhelmed and low on cognitive resources <ref type="bibr" target="#b89">(Smith &amp; Medin, 1981)</ref>. Instead, the use of categories allows us to organise the environment and the objects encountered within it into groups we judge to be meaningfully similar, thus enabling us to infer knowledge and potential actions, even if we have never encountered a particular instance before. While the fundamental importance of categorisation to our cognitive abilities is evident, the precise definition of categories and how categorical information is cognitively structured remains under debate.</p><p>In traditional, feature-based accounts of categorisation and conceptual structure, natural categories are classes that group entities together according to their shared features or properties. While feature-based theories differ in their details, they generally agree that concepts comprise discrete, binary features (e.g., a concept either has, or has not, the feature can fly), and that categorisation is possible because certain features occur together more frequently than others (e.g., if it has wings, lays eggs and can fly, it is likely a member of the category bird; <ref type="bibr" target="#b31">(Cree &amp; McRae, 2003;</ref><ref type="bibr" target="#b40">Hampton, 1993;</ref><ref type="bibr" target="#b58">Malt &amp; Smith, 1984;</ref><ref type="bibr" target="#b74">Posner &amp; Keele, 1968;</ref><ref type="bibr" target="#b79">Rosch, 1973;</ref><ref type="bibr" target="#b90">Smith et al., 1974;</ref><ref type="bibr" target="#b94">Tyler et al., 2000)</ref>. In one popular view, categories are stored in semantic memory through an abstracted summary of how features are shared by category members (prototype theory; <ref type="bibr" target="#b74">Posner &amp; Keele, 1968;</ref><ref type="bibr" target="#b81">Rosch &amp; Mervis, 1975)</ref>. Any given concept may be categorised at multiple, inclusive levels of abstraction (e.g., that small brown creature may simultaneously be categorised as house sparrow, sparrow, bird, and animal), reflecting a taxonomy-like hierarchy from very specific lower levels to very abstract higher levels. Crucially, while any given concept may be categorised at any taxonomic level, the basic level (e.g., bird) is generally privileged <ref type="bibr" target="#b82">(Rosch, Mervis, et al., 1976;</ref><ref type="bibr" target="#b80">Rosch, 1978)</ref>.</p><p>First demonstrated in an extensive series of experiments by , the basiclevel advantage describes a set of behavioural effects in object recognition, categorisation and naming which show a processing advantage for categories of intermediate abstraction. The most prominent example is the finding that people are faster and more accurate at categorising objects when these are preceded by their name at the basic level (e.g., dog; bird), compared to superordinate (e.g., animal) or subordinate (e.g., Labrador, sparrow) level names. This finding is one of the most fundamental effects in categorisation research, and has repeatedly been replicated in later work on potential moderating factors, such as object typicality <ref type="bibr" target="#b47">(Jolicoeur et al., 1984;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985)</ref>, context <ref type="bibr" target="#b68">(Murphy &amp; Wisniewski, 1989)</ref>, subject expertise <ref type="bibr" target="#b46">(Johnson &amp; Mervis, 1997;</ref><ref type="bibr" target="#b93">Tanaka &amp; Taylor, 1991)</ref> and neurological disorders <ref type="bibr" target="#b78">(Rogers &amp; Patterson, 2007)</ref>.</p><p>While the basic-level advantage in object categorisation is a robust effect, the mechanisms underlying it have not been conclusively explained. Feature-based hierarchical accounts argue that taxonomic structure is integral to how categorical knowledge is represented in semantic memory, where feature information is stored only once, at the highest possible level, and generalised to all subordinate levels <ref type="bibr" target="#b20">(Collins &amp; Loftus, 1975)</ref>, thus avoiding redundancy (e.g., the feature lays eggs is true for all birds). Following this, <ref type="bibr" target="#b47">Jolicoeur et al. (1984)</ref> argue that objects are most easily categorised at the basic level because it is the usual level at which the taxonomic structure is entered, and so categorisation at a level different to the entry level incurs a cost in response time and/or accuracy. Other featurebased accounts do not assume that semantic memory is structured hierarchically, but rather that a taxonomy is implicit in how features are interrelated. For instance, the differentiation SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION account <ref type="bibr" target="#b59">(Markman &amp; Wisniewski, 1997;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985;</ref><ref type="bibr" target="#b65">Murphy &amp; Lassaline, 1997;</ref><ref type="bibr" target="#b66">Murphy &amp; Smith, 1982)</ref>, argues that basic-level categories are quite distinct from contrasting categories, (e.g., dogs and birds share few features) while also being quite informative in how they group concepts together (e.g., Labradors and collies share many features). Consequently, these accounts argue that an object may be categorised most quickly and accurately at the basic level because it provides the maximally distinctive and informative match to the object's features, whereas other taxonomic levels are disadvantaged because they match few features of the object (i.e., superordinate categories are distinctive without being informative) or there are several competitors that match some of the object's features (i.e., subordinate categories are informative without being distinct). That is, the basic level is implicitly advantaged in how it best matches features of the object to be categorised (see also <ref type="bibr" target="#b78">Rogers &amp; Patterson, 2007)</ref>.</p><p>More recently however, an alternative view of the conceptual system has emerged that may offer a different explanation for the processing advantages in categorisation. Linguisticsimulation accounts of the conceptual system emphasise the importance of both sensorimotor and language experience in conceptual processing <ref type="bibr" target="#b8">(Barsalou et al., 2008;</ref><ref type="bibr" target="#b21">Connell, 2018;</ref><ref type="bibr" target="#b27">Connell &amp; Lynott, 2014;</ref><ref type="bibr" target="#b53">Louwerse, 2011)</ref>. Both simulated and linguistic distributional information are essential to the operation of the conceptual system, but they interact flexibly to allow reliance on one form of information over another, depending on the exact context or cognitive task <ref type="bibr" target="#b21">(Connell, 2018)</ref>. Simulated representations emerge from sensorimotor experience with our environment, whereby the neural activations across brain areas involved in processing this experience are represented as partial replays upon retrieval <ref type="bibr" target="#b7">(Barsalou, 1999)</ref>. These comprise perceptual, motor, affective and other information in direct and vicarious experience (e.g., the concept dog might be represented by its smell, the sound it makes when it barks, the touch of its fur etc.), though the precise information simulated in a SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 7 particular instance depends on situational context, task goals, available resources, and participant motivations (e.g., <ref type="bibr" target="#b27">Connell &amp; Lynott, 2014)</ref>. Evidence for the role of simulated representations comes from neuroimaging studies, showing shared activation between areas involved in perceptual experience and their equivalent in conceptual processing <ref type="bibr" target="#b3">(Aziz-Zadeh et al., 2006;</ref><ref type="bibr" target="#b19">Carota et al., 2012;</ref><ref type="bibr" target="#b36">Goldberg et al., 2006;</ref><ref type="bibr" target="#b42">Hauk et al., 2004)</ref>, as well as from behavioural studies that reveal intricate relationships between perceptual and conceptual processing <ref type="bibr" target="#b23">(Connell &amp; Lynott, 2010;</ref><ref type="bibr" target="#b33">Dils &amp; Boroditsky, 2010;</ref><ref type="bibr" target="#b105">Zwaan &amp; Taylor, 2006)</ref>.</p><p>Linguistic distributional knowledge, meanwhile, reflects our vast experience with language, where our sensitivity to statistical properties <ref type="bibr" target="#b2">(Aslin &amp; Newport, 2012;</ref><ref type="bibr" target="#b51">Landauer &amp; Dumais, 1997;</ref><ref type="bibr" target="#b54">Lund &amp; Burgess, 1996)</ref> has allowed us to develop knowledge of how words and phrases have specific patterns in their distribution relative to each other (see <ref type="bibr">Wingfield &amp;</ref> Connell, 2022a for a review). Certain words occur in the same or similar contexts more often than others (e.g., the contexts in which people mention dog and animal are more alike than those of dog and cup), and such linguistic distributional information has been shown to be powerful enough to predict conceptual processing in a wide range of tasks <ref type="bibr" target="#b21">(Connell, 2018;</ref><ref type="bibr" target="#b25">Connell &amp; Lynott, 2013;</ref><ref type="bibr" target="#b38">Goodhew et al., 2014;</ref><ref type="bibr" target="#b53">Louwerse, 2011)</ref>.</p><p>If concepts are indeed represented as a combination of sensorimotor simulation and linguistic distributional knowledge, it follows that such sensorimotor and/or linguistic information may also underlie categorisation. Rather than depending on featural similarity between an object and an abstracted feature summary of its class, category membership may be a product of sensorimotor and linguistic distributional similarity between a category concept (e.g., dog) and a potential member concept (e.g., Labrador), based on sensorimotor experience of the referent concepts and linguistic experience of the concept labels across language. In sensorimotor terms, many feature-based theories emphasise that categorical distinctions emerge at least in part from commonalities in the way we perceive and interact with the world around us <ref type="bibr" target="#b31">(Cree &amp; McRae, 2003;</ref><ref type="bibr" target="#b94">Tyler et al., 2000)</ref>. However, sensorimotor experience may also be considered as the extent to which a concept is experienced via each perceptual modality or action effector (i.e., sensorimotor strength: <ref type="bibr" target="#b56">Lynott et al., 2020)</ref>, where the overlap in sensorimotor experience between a category concept (e.g., dog) and a member concept (e.g., Labrador) predicts how readily people name the member as an example of that category <ref type="bibr" target="#b6">(Banks et al., 2021)</ref>. In linguistic distributional terms, the relationship between member-concept labels and category-concept labels in corpus-derived linguistic space is also an effective predictor of category membership <ref type="bibr" target="#b6">(Banks et al., 2021;</ref><ref type="bibr" target="#b29">Connell &amp; Ramscar, 2001;</ref><ref type="bibr" target="#b75">Riordan &amp; Jones, 2011;</ref><ref type="bibr" target="#b102">Wingfield &amp; Connell, 2022a)</ref>. When a category label (e.g., dog) appears in very similar context to a member concept label (e.g., Labrador), people tend to judge the member concept as an excellent example of its category (i.e., graded structure of concepts: <ref type="bibr" target="#b29">Connell &amp; Ramscar, 2001</ref>).</p><p>Compared to traditional, hierarchical, accounts of categories and concepts that rely on discrete features to compute and explain advantage effects in categorisation, linguisticsimulation theories take a very different approach in some key respects. Firstly, while hierarchical views assume that semantic memory is structured into discrete taxonomic levels, with the basic level accorded a preferential status (e.g., <ref type="bibr" target="#b47">Jolicoeur et al., 1984)</ref>, linguisticsimulation accounts do not share that assumption. Rather, although linguistic-simulation accounts have not yet addressed the basic-level advantage directly, they treat all category concepts (i.e., Labrador, dog and animal) with equal status, with no assumption of hierarchy nor preference for the basic level, and assume that task goals and available resources will determine which concept is activated first <ref type="bibr" target="#b27">(Connell &amp; Lynott, 2014)</ref>. In lacking an explicit a priori basic-level preference, linguistic-simulation views are similar to feature-based differentiation accounts (e.g., <ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985;</ref><ref type="bibr" target="#b78">Rogers &amp; Patterson, 2007)</ref> but differ in that they do not assume the basic level is implicitly advantaged by optimally distinct SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 9 and informative binary features. Secondly, where feature-based views draw a distinction between concepts and features, linguistic-simulation views do not. In these views, there is no a priori difference between tail, barks, and dog. They may be related, in that a sensorimotor simulation of dog involves the activation of the concepts tail and barks, or that the word label dog occurs frequently in the same or similar linguistic contexts as tail and barks (which enables the extraction of semantic relations; <ref type="bibr" target="#b102">(Wingfield &amp; Connell, 2022a)</ref>, but featureconcepts are not qualitatively different or subsidiary representations to object-concepts.</p><p>Finally, the linguistic-simulation account does not assume that category membership is dependent on similarity to a central tendency or feature abstraction. That is, the category animal is not represented through an abstracted feature-summary (i.e., prototype) or salient exemplars, but through the same sensorimotor and linguistic distributional information that other concepts (e.g., poodle, spaniel) are. Consequently, poodles are not categorised as animals because they share sufficient features with a prototype, or with familiar poodle exemplars, but because the sensorimotor and linguistic distributional information they activate is similar to that representing the concept animal.</p><p>The aim of this work is to test whether overlaps in sensorimotor and linguistic distributional experience between member concepts and category concepts can indeed contribute to the basic-level advantage, without a fixed taxonomy or subsidiary features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The current study</head><p>In this paper, we report four preregistered experiments (1a, 1b, 2a, 3), and one exploratory study (2b). All studies used a label → picture categorisation task similar to that used by , where participants judged (yes/no) whether the pictured item belonged to the category named in the preceding label. We investigated whether categorisation performance (response time, accuracy) can be predicted by sensorimotor (i.e., perception-action experience of the world) and linguistic distributional information (i.e., statistical distribution of words in language) more effectively than by discrete taxonomic levels. Critically, we used a novel measure of sensorimotor information that was fully grounded in perceptual and action experience alone (i.e., without the use of abstracted features), based on multidimensional ratings of sensorimotor strength from Lynott and colleagues (2020). 2 Our measure of linguistic distributional information was derived from cooccurrence frequencies in a large corpus of English. Together, these measures allowed us to distinguish whether representational similarity between a category and member concept was due to overlap in sensorimotor information (e.g., the concepts animal and dog both involve similar perception and action experience) or linguistic distributional information (e.g., the words animal and dog both appear in similar contexts across language).</p><p>We expected that sensorimotor and linguistic information would contribute to categorical decision making, and that linguistic information in particular would contribute to the basic level advantage in categorisation. That is, we expected people to categorise pictured objects more quickly and accurately when the member concept (e.g., dog) was close to the category concept (e.g., animal) in both sensorimotor experience and linguistic distributional knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1a: The Basic-Level Advantage</head><p>In our first study (preregistration, data, analysis code and results available at https://osf.io/8cjrm, we examined the basic-level advantage in a classic label → picture category verification task. Participants first saw a category name at one of various levels of specificity (e.g., general animal, basic dog, or specific Labrador), followed by a picture (e.g., photograph of a Labrador), and their task was to decide yes/no whether the pictured item belonged to the specified category. We expected responses to be faster and more accurate for basic-level category labels (i.e., the basic-level advantage), and aimed to contrast two competing explanations.</p><p>If traditional accounts of the basic-level advantage are correct, then the effect emerges from explicit or implicit levels of categorical representations in a taxonomic hierarchy (i.e., subordinate, basic, superordinate). Within this hierarchy, the basic level of dog is either the usual point of entry into the taxonomic structure of semantic memory (where accessing other levels of Labrador or animal incurs a processing cost: <ref type="bibr" target="#b35">Glass &amp; Holyoak, 1974;</ref><ref type="bibr" target="#b47">Jolicoeur et al., 1984)</ref> or is the category best differentiated by the pictured object's features (where animal matches few features and Labrador has too many competitors that match many features: <ref type="bibr" target="#b59">Markman &amp; Wisniewski, 1997;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985;</ref><ref type="bibr" target="#b78">Rogers &amp; Patterson, 2007)</ref>. As a result, categorical decisions are easier to make at the basic level.</p><p>By contrast, we hypothesised that the basic-level advantage emerges from representational overlap of linguistic and sensorimotor information between a category and member concept. Extensive research on picture naming has shown that when participants see a picture of a dog (e.g., a Labrador, poodle or collie), they label it with the most frequent and earliest-acquired name: dog (e.g., <ref type="bibr" target="#b12">Bates et al., 2003;</ref><ref type="bibr" target="#b13">Belke et al., 2005)</ref>. Since the most frequent, earliest-acquired name tends to be the basic-level label <ref type="bibr" target="#b82">(Rosch, Mervis, et al., 1976)</ref>, we therefore expected categorisation performance to be fastest and most accurate when the basic-level category label was presented before the picture (e.g., dog → [picture of a dog]). That is, the match between the presented category label (dog) and the common name automatically activated for the pictured object (dog) facilitates fast and accurate category verification. Simultaneously, the overlap between the sensorimotor representation of the category referent (dog) and the pictured object (dog) also facilitates responding, but likely to a lesser extent because linguistic activation tends to operate faster than sensorimotor activation <ref type="bibr" target="#b8">(Barsalou et al., 2008;</ref><ref type="bibr" target="#b21">Connell, 2018)</ref>. Any basic-level advantage would then depend on the extent of overlap in sensorimotor and linguistic distributional experience between the alternative category labels and the picture name.</p><p>For example, when a category label such as Labrador is presented, it automatically activates a sensorimotor simulation of the referent (e.g., perceptual and action experience of a Labrador) and linguistic distributional neighbours of the label (e.g., words that appear in similar contexts to "Labrador"). Next, the picture is presented and is automatically labelled as dog, which activates the linguistic distributional neighbours of dog and a more detailed sensorimotor simulation of the pictured dog. The more similar the sensorimotor experience and linguistic contexts are between Labrador and dog, the more they facilitate fast and accurate category verification, and the closer their response latency and accuracy will be to the basic-level case (e.g., label dog → [picture of a dog]). On the other hand, the more distant the category label and picture are in sensorimotor and linguistic distributional experience (e.g., animal → [picture of a dog]), the slower and more error-prone category verification will be.</p><p>Specifically, we predicted that both sensorimotor and linguistic distributional information would inform categorisation, and that linguistic distributional information would contribute above and beyond sensorimotor information alone. We also predicted that continuous sensorimotor and/or linguistic distributional variables would explain categorisation performance (RT and accuracy) better than traditional accounts of the basiclevel advantage, which are based on discrete levels in a taxonomic hierarchy (i.e., subordinate, basic, superordinate).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Thirty native speakers of English (23 female; Mage = 22 years, SD = 3.69) were recruited from Lancaster University in return for partial course credits or a sum of money (£3.50). We determined sample size via sequential hypothesis testing using Bayes SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 13 Factors <ref type="bibr" target="#b86">(Schönbrodt et al., 2017)</ref>, which allows evidence for/against the hypothesis to accumulate until a pre-specified threshold of evidence is reached, and thus enables flexible sampling without increasing Type 1 error. We stopped sampling at the minimum bound of Nmin = 30, when analysis A for RT (see Data Analysis) cleared the specified grade of evidence BF10 ≥ 3 (actual BF10 = 2043.09). This threshold indicated that a basic-level advantage could be detected in our data (i.e., categorical decisions were made faster when the displayed word label was at the basic level compared to the superordinate and subordinate levels).</p><p>The preregistered accuracy threshold of 80% correct answers on fillers, that we established based on pilot testing, proved to be too strict and would have led to the exclusion of 12 participants. As a result, we decided to deviate from the preregistration and lower this threshold to 70%; one participant did not pass this new threshold and was replaced.</p><p>Materials. Test items consisted of 216 label → picture items, comprising 72 target pictures (depicting natural objects and artefacts), each of which was paired with three labels that correctly described it at the subordinate, basic and superordinate level (e.g., the picture of a Labrador was paired with labels animal, dog and Labrador, respectively). We sourced all pictures through online image search, ensuring they were labelled for reuse with modification and had a minimum size of 1024x768 pixels. We then edited all pictures to display only target objects on a white background. All 72 subordinate labels were uniquely paired with pictures (e.g., label Labrador → picture Labrador), and 24 basic-level categories were paired with three different images (e.g., label dog → pictures Labrador, collie, and poodle). Finally, these 24 basic-level categories were grouped into superordinate categories at 2-7 members apiece, meaning that nine superordinate labels were paired with each between 6-21 different pictures (e.g., label animal → pictures Labrador, collie, poodle, chimpanzee, gorilla, orangutan, etc.).</p><p>We ensured that all labels were present in Lynott et al.'s (2020) sensorimotor norms to allow for the calculation of sensorimotor distances (see Design and Analysis). Finally, we divided all 216 test items into three stimulus lists of 72 items, where each list featured 24 subordinate, 24 basic and 24 superordinate labels and included each picture only once.</p><p>Filler items consisted of 116 label → picture pairs, containing similar object pictures and labels to test items. Of these, 71 false fillers were seen by all participants, and featured 23 superordinate (e.g., label "publication" → picture eggplant), 24 basic-level (e.g., label "horse" → picture zebra) and 24 subordinate (e.g., label "anchovy" → picture sunglasses)</p><p>labels. Forty-one of these fillers were easily recognisable as false (i.e., pictured object clearly unrelated to the label e.g., label "frog" → picture shamrock) and thirty were more challenging (i.e., pictured object belonged to the same superordinate category as the label, e.g., label "cow" → picture buffalo). A further 11 unique filler items were added to each stimulus list, featuring labels that appeared once among the items of that list, to ensure that repeated labels amongst test items could not cue participants to respond "yes" to category membership (e.g., the label "animal" appears in multiple true test items). Of these fillers, five were superordinate (3 true; 2 false) and six were basic-level (3 true; 3 false). Finally, to balance the true/false proportion per category type, we added 12 fillers that were the same for all lists, with unique subordinate labels (6 true; 6 false). As a result, the final stimulus lists each contained 166 label → picture pairs, divided evenly between true and false (72 true test items, 11 true fillers and 83 false fillers).</p><p>Procedure. Trials were presented on a white background, using PsychoPy (version 1.84.1; <ref type="bibr" target="#b73">Peirce, 2007)</ref>. Each trial began with a blank screen displayed for 200 ms followed by a fixation cross for 300 ms, the label (centred, black lowercase Arial, 52 px) for 1000 ms, another blank screen for 200 ms, a fixation cross for 300 ms, and finally the picture which remained onscreen until a response key was pressed. Participants sat in front of a computer with a keyboard. They were told they would see a series of word-picture pairs where the SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 15 word represented a category and the picture a potential member of that category. They were asked to press YES (z-key on the keyboard) when the picture showed a valid category member and NO (m-key) when it did not. Response times were measured from the onset of the picture to the onset of a valid keypress, and accuracy of each decision was also recorded.</p><p>Participants were randomly assigned to a stimulus list. Test and filler items appeared in random order with a self-paced break every 60 trials. Testing took approximately 20 minutes, including informed consent and debriefing.</p><p>Ethics and consent. The study received ethical approval from the Lancaster University Faculty of Science and Technology Research Ethics Committee (ethics code: FST17003). All participants read information detailing the purpose and expectations of the study before giving informed consent to take part. Consent included agreement to share publicly all alphanumeric data in anonymised form.</p><p>Critical predictors. As well as a specified taxonomic level (subordinate, basic, superordinate), each label → picture test item had an associated value in two critical predictors that captured the overlap in sensorimotor and linguistic distributional experience between category concept and member concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linguistic distance. Using a subtitle corpus consisting of 200 million words in British</head><p>English (see van Heuven et al., 2014), we calculated log co-occurrence frequencies around each word with a context radius of five. Each word in the corpus was represented as a vector of log co-occurrence frequencies 3 , allowing us to compare two words by calculating the cosine distance between their vectors (i.e., <ref type="bibr">1 -cos (θ (u,v)</ref>). For example, the words dog and animal generally appear in relatively similar contexts across language, therefore distance between their vectors in linguistic space is smaller (distance = .23) than that between two words that appear in very different contexts, such as dog and spaghetti (distance = .46).</p><p>Previous research suggests that pictures tend to be implicitly named with the most frequent, earliest-acquired word (e.g., <ref type="bibr" target="#b12">Bates et al., 2003;</ref><ref type="bibr" target="#b13">Belke et al., 2005)</ref>, which is usually the basic level (e.g., <ref type="bibr" target="#b82">Rosch, Mervis, et al., 1976)</ref>. In this experiment, we based our calculations on this assumption (i.e., we used the basic label dog as the name for all three pictures of dogs, regardless of whether it contained a Labrador, collie, or poodle). As a result, the corresponding linguistic distance for basic-level label → picture items was always zero (e.g., dog → dog distance = 0), and the ability of linguistic distance to predict categorisation performance depended on the presence of a systematic relationship between our dependent variables (i.e., RT, accuracy) and the linguistic distances of superordinate (e.g., animal → dog) and subordinate items (e.g., Labrador → dog). While this approach assumes which word label will be implicitly activated by a picture, it ensured fair comparison with the taxonomic category predictors, in which the basic-level category took the reference level of 0 in the dummy coding of sub-and superordinate categories (see data analysis). The final linguistic distance measure for each label → picture pair ranged in theory from -1 to +1 (actual range = [.00, .83], M = .25, SD = .21), with higher values indicating greater distance in linguistic space (i.e., less overlap in the linguistic distributional experience of each word).</p><p>Sensorimotor distance. To compare how two concepts overlapped in terms of sensorimotor experience, we took the novel approach of calculating sensorimotor distance based on multidimensional ratings of sensorimotor strength. We used <ref type="bibr">Lynott et al.'s (2020)</ref> sensorimotor norms for 40,000 concepts, in which people rated the extent to which they experienced a particular concept via six perceptual modalities (auditory, gustatory, haptic, interoceptive, olfactory, visual) and by performing an action with five action effectors (foot, hand, head, mouth, torso), where each dimension was separately rated on a scale from 0 (not at all) to 5 (greatly). Each concept was therefore represented by an 11-dimensional vector of grounded sensorimotor experience, allowing us to compare two words by calculating the cosine distance between their vectors (as for linguistic distance); see <ref type="bibr" target="#b104">Wingfield &amp; Connell (2022b)</ref>. For example, sensorimotor experience of dog and animal is more similar than sensorimotor experience of dog and spaghetti, which is captured by a smaller cosine distance between vectors of sensorimotor experience in the former (0.01) compared to the latter (0.24) example. As for linguistic distance (see above), we calculated sensorimotor distance between sensorimotor vectors for the category label at various taxonomic levels (e.g., <ref type="bibr">Labrador, dog, animal)</ref> and the name we assumed would be implicitly associated with the image (e.g., basiclevel dog).</p><p>The final sensorimotor distance measure for each label → picture pair ranged in theory from -1 to +1 (actual range [.00, .29], M = .03, SD = .05), with higher values indicating greater distance in sensorimotor space (i.e., less overlap in the sensorimotor experience of each concept). Linguistic and sensorimotor distance measures were moderately correlated, r = .38 (14.4% shared variance).</p><p>Data analysis. We planned three sets of analyses to test our hypotheses. All analyses were run in R (version 4.1.0: R Core Team, 2021) with main packages lme4 (version 1.1-27.1; D. <ref type="bibr" target="#b10">Bates et al., 2015)</ref>, lmertest (version 3.1-3; <ref type="bibr" target="#b48">Kuznetsova et al., 2017)</ref> MuMIn (version 1.43.17; <ref type="bibr" target="#b9">Bartoń, 2020)</ref> and emmeans (version 1.7.0; van Lenth, 2021). A full list of packages used is included in the supplemental materials on OSF.</p><p>Analysis A tested whether a classic basic-level advantage could be distinguished in the data. We ran a mixed effects linear regression of RT (correct trials only) with crossed random effects of participants and items, and fixed effects of taxonomic level (dummy coded as superordinate and subordinate variables with basic as the reference level). We also ran a mixed effects logistic regression (binomial, logit link) of accuracy (incorrect = 0, correct =1; all trials included), with crossed random effects of participants and items, and fixed effects of taxonomic level (coded as above). For both analyses, we used Bayesian model comparisons (Bayes Factors calculated from BIC; <ref type="bibr" target="#b100">Wagenmakers, 2007)</ref> to test whether the data favoured a model containing the above fixed effects over a null model containing only random effects.</p><p>Analysis B tested whether variance in RT and accuracy could be explained by sensorimotor and linguistic distance. Model comparisons tested whether the data favoured a model containing both sensorimotor and linguistic fixed effects over a model containing only a sensorimotor fixed effect. Although not specified in the preregistered analysis plan due to an error of omission, we also tested whether the data favoured a model with only sensorimotor distance over a null model containing only random effects (i.e., reflecting our preregistered hypothesis that sensorimotor distance contributes to categorical decision making).</p><p>Finally, Analysis C tested whether RT and accuracy were best explained by traditional taxonomic levels or by sensorimotor-linguistic information. In non-nested model comparisons, we tested whether the data favoured the best-fitting sensorimotor-linguistic model from Analysis B over the taxonomic model from Analysis A. Linear models of RT and logistic models of accuracy were compared separately.</p><p>For each analysis, we report the coefficients and null hypothesis significance testing (NHST) statistics of fixed effects in the best-fitting model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>We removed as outliers 55 trials from the RT analysis (2.81 % of 1960 correct responses) and 63 trials from the accuracy analysis (2.92% of 2160 responses) that had RTs more than 2.5SD from the participant's mean. <ref type="table" target="#tab_0">Table 1</ref> shows results of all model comparisons. In accuracy, there was positive evidence for the effect of sensorimotor distance alone (BF10 = 12.66), but also very strong evidence for the inclusion of linguistic distance alongside sensorimotor distance (BF10 = 300.29). Hence, the best sensorimotor-linguistic model of accuracy included both sensorimotor and linguistic distance. Coefficients showed that participants were more likely to respond incorrectly as sensorimotor distance increased (unstandardised b = -3.51, 95% CI = ±3.21, z =-2.15, p = .031) and as linguistic distance increased (b = -1.63, 95% CI = ±0.82, z = -3.87, p &lt;.001) between categories and member concepts. That is, participants were 2.77 times more prone to error for items at the greatest sensorimotor distance (.29) than for items at the smallest sensorimotor distance (zero).</p><p>Simultaneously, for items at the greatest linguistic distance (0.83) participants were 4.66 times 3 more prone to error than for items at the smallest linguistic distance (zero).</p><p>As predicted, sensorimotor and linguistic distributional information contribute to categorical decision making. Overlap in sensorimotor experience between category concept and member concept (e.g., between animal and Labrador) facilitates categorisation RT and accuracy. Similarly, overlap in linguistic experience between the distributional patterns of category and member label also facilitates categorisation accuracy; however, categorisation RT was not influenced by linguistic distance.</p><p>Best model. Analysis C showed mixed results as to whether the taxonomic or sensorimotor-linguistic model best explained the data. As predicted, Bayesian model comparisons found positive evidence that sensorimotor distance was BF10 = 4.66 times better than taxonomic levels in predicting RT. By contrast, and contrary to predictions, there was strong evidence that taxonomic levels were BF01= 164.70 times better than sensorimotor and linguistic distance at predicting accuracy. <ref type="figure" target="#fig_0">Figure 1</ref> shows comparisons for each experiment. Summary. Overall, while both sensorimotor and linguistic distributional information contribute to categorical decision making, they did not systematically do better than a taxonomic hierarchy of subordinate, basic, and superordinate levels. That is, sensorimotor information did predict response times best, but taxonomic level predicted accuracy best. We address a possible cause in the next experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1b: Modelling Categorical Gradedness in the Basic-Level advantage</head><p>In experiment 1, we assumed all pictures to be implicitly named at the basic level.</p><p>However, categories can be graded in terms of the "goodness" of membership -that is, how members range in typicality of their respective categories -and such categorical gradedness affects category processing and production <ref type="bibr" target="#b1">(Armstrong et al., 1983;</ref><ref type="bibr" target="#b76">Rips et al., 1973;</ref><ref type="bibr" target="#b79">Rosch, 1973;</ref><ref type="bibr" target="#b82">Rosch, Mervis, et al., 1976;</ref><ref type="bibr" target="#b84">Rosch, Simpson, et al., 1976;</ref><ref type="bibr" target="#b81">Rosch &amp; Mervis, 1975;</ref><ref type="bibr" target="#b90">Smith et al., 1974)</ref>. That is, categorising typical items that are representative of their category (e.g., sparrow, for the category bird) tends to be faster than categorising atypical items that are less representative of their category (e.g., penguin). However, atypical members tend to be named at the specific, subordinate level rather than at the more general basic level (e.g., a picture of a penguin is more likely to be named as a penguin rather than a bird: <ref type="bibr" target="#b82">Rosch, Mervis, et al., 1976;</ref><ref type="bibr" target="#b91">Snodgrass &amp; Vanderwart, 1980)</ref>. <ref type="bibr" target="#b47">Jolicoeur et al. (1984)</ref> interpreted this finding to mean that the subordinate level, rather than the basic level, acts as the entry point into the taxonomic hierarchy of semantic memory for atypical category members.</p><p>Alternatively, differentiation accounts proposed that a picture of an atypical bird, like a penguin, is more easily categorised at the subordinate level of penguin because its features are better matched at this specific level (i.e., the subordinate level is maximally informative and distinctive) compared to more general levels like bird or animal <ref type="bibr" target="#b63">(Murphy &amp; Brownell, 1985</ref> Hence, in this study (data, analysis code, results, and preregistration available at https://osf.io/8cjrm, we collected traditional typicality ratings for each of our subordinatelevel stimuli as a member of its basic-level category (e.g., typicality of sailfish as a fish) and examined its influence on categorical decision making using the dataset from Experiment 1.</p><p>In line with previous research on the role of object typicality in categorisation (e.g., <ref type="bibr" target="#b47">Jolicoeur et al., 1984;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985)</ref>, we expected typicality to enhance the ability of Traditional typicality ratings. We collected typicality ratings from naïve participants (all native speakers of English) for each of the 72 test items that comprised a basicsubordinate concept pair (e.g., fish-salmon). These ratings were collected as part of a larger study collecting typicality ratings for 2280 category-member items, where items were divided into lists of 120 items each <ref type="bibr" target="#b5">(Banks &amp; Connell, 2022)</ref>; the present 72 category-member items were randomly spread across these lists. Participants were asked to rate how good an example of the basic-level category (e.g., fish) they thought each subordinate category member (e.g., salmon) to be, on a scale from 1 (very poor) to 5 (very good); alternatively, they could select a "don't know" option if they were not familiar with the category or member concept in question. Consequently, if a participant gave a rating, they were indicating that they were sufficiently familiar with the concept to do so. Data collection stopped when every item had 12 valid ratings. We then calculated the average typicality rating per category member and used this typicality rating on every label → picture trial where it was presented (e.g., all trials with a salmon picture used the typicality rating for salmon as a kind of fish). Mean typicality rating across all items was 4.53 (SD = .36, range = [3.42, 5.00]).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 27</head><p>Gradedness-adjusted linguistic and sensorimotor distance. For our original calculation of linguistic distance in Experiment 1, we assumed that all pictured objects were implicitly named at the basic level (i.e., we used the basic label fish as the name for all three pictures of fish). To incorporate categorical gradedness into linguistic and sensorimotor distance, where pictures of less-representative category members would instead be implicitly named at the subordinate level (e.g., using the specific label sailfish as the name for the picture of a sailfish), we used the data to determine the tipping point of linguistic distance that distinguished good from less-representative category members. We first examined the distribution of linguistic distance between all 72 subordinate member concepts and their basic-level category concept (e.g., fish → sailfish, fish → salmon) and visually established 10 potential thresholds beyond which we assumed member concepts to be less representative of their category. We then replaced the linguistic distances of all items that fell beyond each threshold with those calculated using the subordinate name as the picture label. For instance, if the linguistic distance for fish → sailfish exceeded the threshold, we replaced all linguistic distances of sailfish trials (originally calculated as animal → fish, fish → fish, sailfish → fish)</p><p>with their gradedness-adjusted linguistic distances (i.e., animal → sailfish, fish → sailfish, sailfish → sailfish). For these same items, we likewise replaced the original sensorimotor distances with their gradedness-adjusted sensorimotor distance.</p><p>Finally, we examined which threshold was best supported by the data by running mixed effect regressions of RT per candidate threshold, with random effects of participant and item and fixed effects of gradedness-adjusted sensorimotor and linguistic distances.</p><p>Model comparisons showed that the best-fitting model was based on a gradedness-adjusted linguistic distance threshold of .33, and that the data favoured this model BF10 = 1908.20 times more strongly than the original model used in Experiment 1. In short, a linguistic distance of .33 acted as a tipping point between highly representative category members (N = 23) that were implicitly named at the basic level and less-representative category members (N = 49) that were implicitly named as the specific, subordinate level. We therefore used these optimal gradedness-adjusted linguistic and sensorimotor distances in subsequent analyses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gradedness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>Outlier trials were already removed from the dataset in Experiment 1. In addition, we removed one item (gavel) from both the RT (21 out of 1905 trials, 1.10%) and accuracy (28 out of 2097 trials, 1.33%) data because it had an exceptionally low typicality rating (2.2 on a 1-5 scale) that made it an outlier more than five standard deviations below the mean item typicality (M = 4.53, SD =.45). While removing this item deviated from the preregistered analysis plan, we felt it was necessary to avoid compromising the robustness of our analyses.   data, contrary to predictions of some traditional accounts (e.g., <ref type="bibr" target="#b79">Rosch, 1973;</ref><ref type="bibr" target="#b84">Rosch, Simpson, et al., 1976;</ref><ref type="bibr" target="#b81">Rosch &amp; Mervis, 1975</ref> Contrary to taxonomic accounts that hold typicality affects the basic-level advantage <ref type="bibr" target="#b47">(Jolicoeur et al., 1984;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985)</ref>, we found no evidence that atypical items were preferentially categorised at the specific, subordinate level. Rather, all category members showed the traditional basic-level advantage where the basic level was faster and more accurate than subordinate and superordinate levels (but see general discussion). In accuracy analysis, we again found very strong evidence for the effect of gradedness-adjusted sensorimotor distance over a null model, BF10 = 752.52. However -and</p><p>unlike Experiment 1a-we also found evidence against the inclusion of gradedness-adjusted linguistic distance, whereby the data favoured the model containing sensorimotor distance alone (BF01 = 5.65). Hence, as for RT, the best gradedness-adjusted sensorimotor-linguistic model of accuracy was sensorimotor distance alone, where the greatest distance made errors up to 6.90 times more likely than the shortest distance [b =-6.66, 95% CI = ±2.70, z = -4.82, p</p><formula xml:id="formula_0">&lt;.001].</formula><p>Best model. In analysis E, results followed the mixed pattern of Experiment 1aregarding whether the data were more likely under a model using traditional taxonomic levels with typicality ratings or sensorimotor/linguistic distance (see <ref type="figure" target="#fig_0">Figure 1)</ref>. As predicted,</p><p>Bayesian model comparisons between the best-performing models from analyses B and D found very strong evidence that gradedness-adjusted sensorimotor distance was BF10 = 118155.82 times better at predicting RT than a model containing taxonomic levels and traditional typicality. However, against predictions but consistent with Experiment 1, there was evidence that the taxonomic-typicality model was BF01 = 9.69 times better (i.e., BF10 = 0.10) at predicting accuracy than a model containing gradedness-adjusted sensorimotor distance 6 .</p><p>Summary. In this study, we examined whether accounting for categorical gradedness affected the ability of sensorimotor and linguistic distributional information to contribute to categorical decision making, relative to traditional taxonomic levels. In contrast to our predictions, linguistic distributional information did not decisively capture the graded structure of categories reflected in typicality ratings. While atypical member concepts were slightly more linguistically distant from their category concept (e.g., sweatpants and trousers overlap little in linguistic experience) than member concepts that were good examples of their category (e.g., jeans and trousers overlap a lot in linguistic experience), the evidence for a systematic relationship was equivocal.</p><p>Nevertheless, adjusting for categorical gradedness improved the predictive ability of sensorimotor and linguistic distance measures compared to the unadjusted measures of Experiment 1. Gradedness-adjusted sensorimotor information contributed to categorical decision making, and outperformed traditional predictors of taxonomic levels and typicality in fitting RT (but not accuracy). Against our predictions, however, gradedness-adjusted linguistic distributional information was not an effective predictor of either RT or accuracy.</p><p>That is, even though linguistic distance formed the basis for adjusting categorical gradedness, when these gradedness-adjusted measures are used, it appears that sensorimotor distance between the category and member concepts is more relevant to the time course and decision <ref type="bibr">6</ref> As an exploratory analysis, since typicality performed so poorly as a predictor, we opted to compare the gradedness-adjusted sensorimotor distance model against the taxonomic-only model (i.e., without typicality ratings). Results remained unchanged: sensorimotor distance was the best model of RT (BF10 = 2932.49 times better than the taxonomic model) and taxonomic levels were the best model of accuracy (BF01 = 109.43 times better than the sensorimotor model).</p><p>outcome than the linguistic distributional relationship between the category and member labels. That is, pictures of good, highly representative category members were implicitly named and processed at the basic level (e.g., fish → salmon processed as fish → fish) while pictures of less-representative category members were implicitly named and processed at the specific, subordinate level (e.g., fish → sailfish processed as fish → sailfish), and in each case the sensorimotor overlap between the retrieved category and member concept affected latency and accuracy of performance.</p><p>In addition, the analysis with typicality produced some unexpected results. Contrary to previous findings in the literature <ref type="bibr" target="#b84">(Rosch, Simpson, et al., 1976;</ref><ref type="bibr" target="#b81">Rosch &amp; Mervis, 1975)</ref>, a traditional measure of categorical gradedness, typicality ratings, did not affect categorical decisions, nor did it impact on the basic-level advantage as predicted by the entry-level <ref type="bibr" target="#b47">(Jolicoeur et al., 1984)</ref> and differentiation <ref type="bibr" target="#b63">(Murphy &amp; Brownell, 1985)</ref> accounts. That is, many of the least typical items in our dataset tended to be categorised at the basic rather than subordinate level (e.g., a picture of a fir was categorised as a tree more quickly and accurately than as a fir); a picture of a chalice was categorised as a cup more quickly and accurately than as a chalice) and many of the most typical items tended to be categorised at the subordinate level rather than basic (e.g., a picture of an eagle was categorised as an eagle more quickly and accurately than as a bird; a picture of a rose was categorised as a rose more quickly and accurately than as a flower). One possible explanation for the absence of typicality effects is that our items did not span a wide enough range of typicality ratings (i.e., range [3.42, 5.00] on a 1-5 scale), and hence were not sufficiently atypical to trigger the mechanisms that should cause less-representative category members to be categorised at the subordinate rather than basic level. However, this explanation cannot account for the fact that categorical gradedness did affect categorisation when it was modelled via linguistic distance: gradedness-adjusted measures of sensorimotor and linguistic distributional information outperformed the unadjusted measures used in Experiment 1, and gradedness-adjusted sensorimotor distance outperformed taxonomic-typical models in predicting RT. Such a pattern of findings suggests that subjective typicality ratings may not be the best measure of the graded structure of categories, and that the goodness-of-membership may be better captured by an implicit measure derived from distributional patterns in language use. In the next experiments, we examine this possibility, and the robustness of our reported findings, via replication studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2a: Replication of Experiment 1a</head><p>To replicate the effects found in Experiment 1a (i.e., sensorimotor and linguistic distance predicted the basic level advantage in categorisation, and outperformed taxonomic level as a predictor in RT but not accuracy), we set out to investigate the same hypotheses in a replication study run online (i.e., via a web-based experimental platform) rather than in the lab. Our predictions remained the same: we expected that sensorimotor and linguistic distributional information would inform categorisation, that linguistic distributional information would contribute above and beyond sensorimotor information alone, and that a combination of sensorimotor and/or linguistic distributional information would explain categorisation performance better than traditional taxonomic levels (i.e., subordinate, basic, superordinate). Preregistration, data, analysis code, and results are available at https://osf.io/8cjrm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The method was identical to Experiment 1a with the following exceptions.</p><p>Participants. 25 participants (21 female, Mage, 37.76, SD = 10.86) were recruited through Prolific.co (formerly Prolific.ac), an online crowdsourcing platform, for the sum of £1.75 (i.e., approx. £7 /hour pro rata for an assumed duration of 15 minutes). On average, participants took 12 minutes and 44 seconds to complete the task (SD = 6 minutes and 18 seconds). Through Prolific's recruitment filter settings, we ensured that all participants were native speakers of English, had no dyslexia, and had a minimum number of 10 submissions with a Prolific approval rating of &gt;95%. Participants were required to achieve an accuracy threshold of 70% accuracy on filler items; no participants were removed for failing to reach this threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sample size was determined through sequential hypothesis testing of analysis A as per</head><p>Experiment 1a. Since we stopped sampling at our lower bound of N = 30 in Experiment 1a, we used sequential analysis of Experiment 1a's data to determine the number of lab-based participants at which evidence for the basic-level advantage in RT began to consistently exceed our evidence threshold of BF10 ≥ 3, which occurred at N = 14 (BF10 = 71.88). Several studies <ref type="bibr" target="#b32">(Crump et al., 2013;</ref><ref type="bibr" target="#b44">Hilbig, 2016;</ref><ref type="bibr" target="#b87">Semmelmann &amp; Weigelt, 2017)</ref> suggest web-based data collection yields comparable results to lab-based testing, but may still be subject to noise. To allow for a higher level of noise in our dataset, we therefore set our present lower bound to be 50% higher at Nmin = 21 and raised our threshold of evidence to a more conservative BF10 ≥ 10. Due to a technical error, an additional 4 participants above Nmin were tested before online recruitment automatically closed; we opted to include all tested participants in data analysis rather than arbitrarily exclude the final four. At 25 participants, the specified grade of evidence for the presence of a basic-level advantage in our data was comfortably cleared at BF10 = 14847327.02. Data analysis. We repeated analyses A through C as specified in Experiment 1a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>One participant had a very long tail of slow RTs, which indicated inattention, but was not otherwise excluded by the preregistered criteria for outlier removal. As a result, we decided to remove all trials with RT &gt; 10,000 ms: 7 trials from the accuracy analysis and 2 trials from the RT analysis. We removed an additional 49 trials from the RT analysis and 57 trials from the accuracy analysis for having RTs that were more than 2.5 SD from the participant's mean. No responses were removed due to motor error. In total we thus removed 51 outliers from the RT analysis (3.07% of 1663 correct responses) and 64 outliers from the accuracy analysis (3.55% of all 1800 responses). <ref type="table" target="#tab_8">Table 3</ref> shows model comparisons for all analyses.  <ref type="figure" target="#fig_0">Figure 1)</ref>. The data favoured the model with sensorimotor distance BF10 = 6.23 times more than the model including taxonomic levels, which was below the specified threshold for this experiment (BF ≥ 10), and thus constitutes equivocal evidence. Model comparisons for accuracy showed overwhelming evidence that taxonomic levels were BF01 = 7902660.94 times better at fitting the data than sensorimotor distance, against predictions but replicating Experiment 1a.</p><p>Summary. These results are similar but not identical to the findings of Experiment 1a. Nevertheless, they provide further evidence for the effects of sensorimotor and linguistic distributional information on picture categorisation. When it comes to the time course of categorical decision making, the overlap in sensorimotor experience between the category and member concepts was at least as good as discrete taxonomic levels (i.e., subordinate vs.</p><p>basic vs. superordinate) in predicting performance. Linguistic distributional information might have a small effect on RT but the evidence is equivocal. When it comes to the accuracy of categorical decisions, however, taxonomic levels outperform the ability of sensorimotor information to predict performance. Crucially, the datasets for Experiments 1a and 2a yielded slightly different results (see <ref type="figure" target="#fig_0">Figure 1)</ref>. Specifically, contrasting the findings in Experiment 1a, linguistic distributional distance did not predict accuracy over sensorimotor distance.</p><p>Moreover, the higher Bayes Factor threshold used in Experiment 2a meant that, while the overall pattern was similar to that observed in Experiment 1a (i.e., strongest evidence for the sensorimotor-only model) evidence for the sensorimotor over taxonomic model was in the equivocal zone (BF10 &lt; 10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2b: Exploratory Replication of Experiment 1b.</head><p>In Experiment 1b, we found that adjusting measures of sensorimotor and linguistic distance to reflect the graded structure of categories considerably increased their ability to predict categorisation performance. Unexpectedly, however, typicality ratings (i.e., the traditional measure of categorical gradedness) did not alter the ability of taxonomic levels to predict categorisation. That is, while there was no evidence that atypical member concepts (e.g., relatively poor examples of their category) were categorised at the subordinate (rather than basic) level, there was indeed evidence that less-representative category members (i.e., that appear in quite dissimilar linguistic contexts to their category concept) were categorised at the specific, subordinate level.</p><p>We therefore opted to run an exploratory (i.e., not preregistered) 7 replication of Experiment 1b, using the new dataset collected in Experiment 2a. That is, we investigated the same hypotheses as Experiment 1b, based on analysis of the RT and accuracy data collected as part of Experiment 2a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>All materials, critical predictors, and data analyses were identical to Experiment 1b, with the omission of analysis C (i.e., correlation between typicality ratings and linguistic distance) as it involved no new data in this experiment. That is, for gradedness-adjusted sensorimotor and linguistic distance, we retained the tipping point whereby all items beyond linguistic distance of .33 were assumed to have their pictures implicitly named at the specific (subordinate) level and all other items were assumed to be named at the basic level.</p><p>Dependent measures of RT and accuracy were taken from Experiment 2a, as well as its threshold for inferencing of BF ≥ 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>With outliers already removed in Experiment 2a, we further removed all trials corresponding to the item gavel as per Experiment 1b, which excluded 24 trials from the accuracy dataset (1.38% of 1736 trials) and 17 trials from the RT dataset (1.05% of 1611 trials).</p><p>With this item excluded, the pattern of basic-level advantage remained the same as in    <ref type="bibr" target="#b84">Rosch, Simpson, et al., 1976</ref>) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interaction of typicality with taxonomic level. Analysis B model comparisons again</head><p>showed strong evidence against including an interaction between subordinate taxonomic level and typicality. In the analysis of RT, the interaction had little effect [b = 52.37, 95% CI = ±71.91, t(1521.83) = 1.42, p = .15], and the data were BF01 = 14.55 times more likely under the model without an interaction. In the analysis of accuracy, we again found evidence against adding the interaction between subordinate taxonomic level and typicality [b =1.03, 95% CI = ±, z = 1.38, p = .17] to a model including only taxonomic level and typicality (BF01 = 16.29). The best taxonomic-typicality model in this analysis therefore contained both taxonomic levels and typicality, but no interaction. These results replicate the findings from Experiment 1b, and run contrary to predictions of taxonomic accounts that hold typicality affects the basic-level advantage <ref type="bibr" target="#b47">(Jolicoeur et al., 1984;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985)</ref>.We therefore found no evidence that atypical items were preferentially categorised at the subordinate level. Instead, regardless of typicality, category members tended to show a traditional basic-level advantage in terms of processing speed (where the basic level was faster than subordinate and superordinate levels), and a partial basic-level advantage in terms of accuracy, where the basic-level was more accurate than the superordinate level but not the subordinate level.</p><p>Gradedness-adjusted sensorimotor and linguistic distance. In RT, Analysis D model comparisons showed very strong evidence for the effect of gradedness-adjusted sensorimotor distance over a null model (BF10 = 280449.99). However, as in Experiment 1b, we found strong evidence against adding gradedness-adjusted linguistic distance to a model containing sensorimotor distance alone: the data were BF01 = 33.16 times more likely under a model containing only sensorimotor distance compared to a model containing both linguistic and sensorimotor distance. In accuracy analysis, we again found very strong evidence for the effect of gradedness-adjusted sensorimotor distance over a null model (BF10 &gt; 1.93 billion), and evidence against the inclusion of gradedness-adjusted linguistic distance, whereby the data strongly favoured the model containing sensorimotor distance alone (BF01 = 32.27). This latter result again contrasted with our findings from the unadjusted measures of sensorimotor and linguistic distance in Experiment 1a but was consistent with those of Experiment 2a.</p><p>Hence, the best gradedness-adjusted sensorimotor-linguistic model of both RT and accuracy was one containing the fixed effect of sensorimotor distance alone, where higher distance Best Model. In RT, model comparisons between the best-performing models from analyses B and D showed equivalent performance between a taxonomic-typicality model (BF01 = 1.25) and a model containing gradedness-adjusted sensorimotor distance, contrasting with our findings in Experiment 1b (see <ref type="figure" target="#fig_0">Figure 1)</ref>. As an exploratory analysis, since typicality had little effect on performance, we opted to compare the gradedness-adjusted sensorimotor distance model against the model containing only taxonomic levels (i.e., the best model from Analysis A). Here, unlike a similar exploration in Experiment 1b, we found that the taxonomic-only model performed BF01 = 49.97 times better than the sensorimotor model (full details in supplementals).</p><p>In accuracy, model comparisons between the best-performing models from analyses B and D showed a weak reversal of the effects found in Experiment 1b, with evidence trending in favour of gradedness-adjusted sensorimotor distance (BF10 = 8.07). However, this level of evidence is below the threshold for this study (BF≥10), and thus constitutes equivocal evidence (i.e., both gradedness-adjusted sensorimotor distance and taxonomic-typicality models performed approximately equally well). Again, since typicality had little effect on accuracy, we explored a comparison with the best model from Analysis A (i.e., taxonomic levels only), and found little change: taxonomic levels and gradedness-adjusted sensorimotor distance performed equally well (BF10= 0.39).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary.</head><p>Results of this exploratory replication were similar but not identical to the findings of Experiment 1b. As predicted, gradedness-adjusted sensorimotor distance contributed to both RT and accuracy. Sensorimotor overlap between a category and member concept was a very strong predictor of categorical decision for "good" category members whose pictures were implicitly processed with high-frequency basic labels (e.g., fish → salmon processed as fish → fish) and less-representative category members whose pictures were implicitly processed with specific labels (e.g., fish → sailfish processed as fish → sailfish). However, counter to our predictions, linguistic distance did not affect performance once sensorimotor distance had been taken into account. In addition, and contrary to previous findings in the literature, typicality ratings also did not affect categorical decisions (e.g., <ref type="bibr" target="#b84">Rosch, Simpson, et al., 1976)</ref> nor impact on the level of categorisation (i.e., where atypical members are categorised at the subordinate level: <ref type="bibr" target="#b47">Jolicoeur et al., 1984;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985)</ref>. These findings are all consistent with Experiment 1b and show that categorical gradedness -as modelled by linguistic distance but not typicality ratings -mediates the basic level advantage in categorical decision making.</p><p>Different to Experiment 1b, however, was the finding that sensorimotor and taxonomic-typicality models performed equally well in explaining both accuracy and RT (see <ref type="figure">Figure 3</ref>). That is, sensorimotor distance between a category and member concept explains the latency and accuracy of picture categorisation at least as well as the traditional combination of taxonomic levels and typicality. While this result does not support our prediction that sensorimotor distance would outperform taxonomic levels and typicality, it also does not reject it (i.e., equivalent performance). Finally, we note that our exploratory analysis of taxonomic level alone versus sensorimotor distance also differed from a similar SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 47 exploratory analysis in Experiment 1b: accuracy was explained equally well by taxonomic levels and sensorimotor distance (as opposed to taxonomic levels alone in Experiment 1b), while RT was best explained by taxonomic levels (as opposed to sensorimotor distance in Experiment 1b). Taken together, these results suggest that sensorimotor-linguistic information (i.e., sensorimotor distance categorically graded by linguistic distance) predicts the basic level advantage about as well as discrete taxonomic levels, with the apparent primacy of one model over another varying by participant sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3: Categorical Gradedness from Normed Object Names</head><p>Experiments 1a and 2a were built on the assumption that images of objects would implicitly activate a basic-level name in participants, following research showing that participants most frequently use labels of intermediate abstraction when asked to name objects <ref type="bibr" target="#b82">(Rosch, Mervis, et al., 1976</ref>; see also <ref type="bibr" target="#b66">Murphy &amp; Smith, 1982)</ref>. However, as Experiment 1b and 2b show, participants' categorisation behaviour may be better predicted by models that do not rigidly assume the implicit image name is always at a basic level of abstraction, and adjustment for categorical gradedness is required to capture the fact that some images are named at a more specific, subordinate level. In addition, picture naming research suggests that perfect name agreement (i.e., a single name given to an image by all participants) is rarely observed (e.g., only 24 out of 1468 items in the BOSS norms; <ref type="bibr" target="#b16">Brodeur et al., 2010</ref><ref type="bibr" target="#b17">Brodeur et al., , 2014</ref> and the most frequently-given name for an object might not be the one assumed by experimenters (e.g., Brodeur and colleagues found that most participants labelled an image of an alligator as a crocodile). In short, people do not always label objects as one might expect, which may explain some of the variability in linguistic distributional versus sensorimotor effect sizes in previous experiments.</p><p>In this Experiment, therefore, we set out to investigate the effects of sensorimotor and/or linguistic distributional information on category verification using a set of pictures for which the range of associated names was known. Specifically, we derived category and object names from a recent set of picture-naming norms that provided both the list of names participants used to label each image, and the frequency with which each name was produced <ref type="bibr" target="#b98">(van Hoef et al., 2022)</ref>. Rather than assuming a single basic-or subordinate-level image label when calculating sensorimotor and linguistic distributional distances for a word → picture pair, we were instead able to incorporate all labels people are likely to give an image by averaging their distances, weighted by production frequency. For example, rather than assuming the item dog → [picture of a poodle] should be treated as dog → dog (Experiment 1a and 2a) or dog → poodle (Experiment 1b and 2b), we treated it according to the normed labels for that poodle image: a weighted average of 67% dog → dog and 33% dog → poodle.</p><p>In this way, the graded structure of categories was inherently reflected in the production frequency used to weight the distance calculations, as some member concepts were named at the basic level more often than others (e.g., an image of a Labrador was named as a dog more often than was an image of a poodle).</p><p>As before, we hypothesised that both sensorimotor and linguistic distributional information would inform categorisation, and that the basic-level advantage would emerge from representational overlap of linguistic and sensorimotor information between a category and member concept. However, we updated our specific predictions based on our findings in previous experiments. That is, we predicted that weighted average sensorimotor distance would independently predict RT and accuracy, and that weighted average linguistic distributional distance would predict accuracy (but not RT) above and beyond sensorimotor information and do so at least as well as sensorimotor distance. Furthermore, in line with the previous experiments, we predicted that sensorimotor distance alone would predict the basic- As before, we determined sample size via sequential hypothesis testing using Bayes</p><p>Factors <ref type="bibr" target="#b86">(Schönbrodt et al., 2017)</ref>, with Nmin set at 30 participants, and Nmax set at 90. We stopped sampling at 43 participants, when hierarchical effects of both sensorimotor distance and linguistic distributional distance in Analysis B cleared the specified grade of evidence of BF &gt; 10 (or reciprocal 1/10) for three successive participants for both accuracy and RT (see Results section for actual BFs).</p><p>Materials. Test items consisted of 396 label → picture items, comprising 132 target pictures, each of which was paired with three labels that described it at the subordinate, basic and superordinate level. All images were retrieved from the van Hoef et al., (2022) picture naming norms, and their basic-and subordinate-level names were derived from participants' naming responses in these norms. First, we determined basic-level category names, by selecting only those items from the norms for which the modal response occurred for the majority of object images as well as for more than one object (e.g., dog as the modal name for most Labrador and Spaniel images). Crucially, we ensured that every image had at least one alternative name that was more specific than the modal response (e.g., Labrador for Labrador images). Where more than one alternative name was produced for an item, we used the most frequent as the subordinate-level label in our task. Since abstracted, superordinatelevel labels were produced only occasionally in the picture-naming norms, we retrieved superordinate-level category names from WordNet (https://wordnet.princeton.edu), a lexical database that includes a hypernymic (i.e., type-of) taxonomy for each sense of a word. For each basic-level name, we determined the set of WordNet hypernyms for the relevant word sense (e.g., for the canine sense of dog rather than a figurative meaning), and selected the most easily-comprehensible abstracted hypernym as the superordinate-level label (e.g., for dog, we selected the hypernym animal rather than more technical alternatives like mammal or chordate). To create label → picture items, each subordinate-level label was then paired with three images (e.g., Labrador → three different images of a Labrador), each basic-level label was paired with between 6 and 27 images (e.g., dog → three images of a Labrador, three images of a Spaniel, three images of a collie, etc.) and each superordinate-level label was paired with between 27 and 39 images (e.g., animal → three images of a Labrador, three images of a Spaniel, three images of a Lynx etc.  Data analysis. We ran analyses A and B as specified in Experiment 1a, except we used weighted average sensorimotor distance and weighted average linguistic distributional distance in place of the original distance measures. Analysis C tested whether RT and accuracy were best explained by traditional taxonomic levels or by sensorimotor <ref type="bibr">(-linguistic)</ref> information. In non-nested model comparisons, we tested whether the RT data favoured the sensorimotor-only model from Analysis B over the taxonomic model from Analysis A, and whether the accuracy data favoured the sensorimotor-linguistic model from Analysis B over the taxonomic model from Analysis A.</p><p>For each analysis, we report the coefficients and null hypothesis significance testing (NHST) statistics of fixed effects in the best-fitting model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>In total, we collected data for 5938 trials. We removed 6 trials due to motor error (RT &lt; 200ms) and 21 trials due to inattention (RT &gt; 5000 ms); no participants had a mean RT further than 3 SD away from the overall mean. We removed 188 trials from the analysis of accuracy (3.18% from 5911 observations), and 158 trials from the analysis of RT (2.93 % of 5397 correct observations) for having an RT further than 2.5SD away from the participant mean. The final accuracy dataset consisted of 5723 correct and incorrect trials; the final RT dataset consisted of 5239 correct trials. (predicted probability of a correct answer = 91.8%). This data thus replicates the classic basic-level advantage, with best categorisation accuracy at the basic level and worst at the superordinate level, in line with Experiments 1a. <ref type="table" target="#tab_15">Table 5</ref> shows all model comparisons. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Taxonomic levels. Bayesian model comparisons in Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B</head><p>Step 1 (Sensorimotor) vs. step 0 (Null model) .014 1.60x10 10 .116 2.62x10 29</p><p>Step 2 (Sensorimotor-linguistic) vs step 1. and 2a that linguistic distance would affect RT, the results of these studies led us to update our hypotheses and predict a null linguistic effect in the present experiment. However, the linguistic effect on RT did indeed emerge, against our preregistered hypothesis, and instead consistent with the joint sensorimotor-linguistic effects we had expected to find in Experiments 1a and 2a. In other words, participants were up to 132.97 ms slower at the greatest average sensorimotor distance (.16), and up to 95.99 ms slower at the greatest average linguistic distributional distance (.91) between the category label and image name(s).</p><p>In accuracy, there was overwhelming evidence for the effect of sensorimotor distance alone (BF10 = 2.62x10 29 ), and positive evidence for the inclusion of linguistic distance alongside sensorimotor distance (BF10 = 10.99). Hence, the best sensorimotor-linguistic model of accuracy included both sensorimotor and linguistic distance. Coefficients showed that participants were more likely to respond incorrectly as sensorimotor distance increased (b = -24.55, 95% CI = ±5.27, z =-9.12, p &lt;.001) and as linguistic distance increased (b = -1.85, 95% CI = ±0.96, z = -3.77, p &lt;.001) between categories and member concepts. That is, participants were 50.80 times more prone to error for items at the greatest average sensorimotor distance (.16) than for items at the smallest sensorimotor distance (zero).</p><p>Simultaneously, for items at the greatest linguistic distance (.91) participants were 5.38 times more prone to error than for items at the smallest linguistic distance (zero).</p><p>As predicted, overlap in sensorimotor experience between category and member concepts (e.g., between animal and dog concept or animal and Labrador concept, depending on how an individual participant implicitly names an image of a Labrador) facilitates categorisation RT and accuracy. Similarly, as predicted, overlap in linguistic experience between the distributional patterns of category and member labels also facilitates categorisation accuracy. Indeed, more than we expected in this study, overlap in linguistic distributional experience also facilitates categorisation RT; an effect that failed to emerge as predicted in Experiments 1a and 2a.</p><p>Best model. Analysis C tested whether taxonomic or sensorimotor information best predicted RT, and whether taxonomic or sensorimotor-linguistic best predicted accuracy. As SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 57 predicted, Bayesian model comparisons found very strong evidence that sensorimotor distance was BF10 = 831.87 times better than taxonomic levels in predicting RT. As a model including linguistic distributional distance on top of sensorimotor distance outperformed a sensorimotor-only model in predicting RT, we ran an exploratory (i.e., not preregistered)</p><p>comparison between this sensorimotor-linguistic model and taxonomic levels, and found overwhelming evidence that sensorimotor and linguistic distance were BF10 = 36317.40 times better than taxonomic levels in predicting RT. Moreover, Bayesian model comparisons found overwhelming evidence that sensorimotor and linguistic distance were BF10 = 3.24x10 11 times better than taxonomic level at predicting accuracy. That is, sensorimotor-linguistic models outperformed taxonomic models in predicting the basic level advantage on both latency and accuracy (see <ref type="figure" target="#fig_0">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary.</head><p>In conclusion, these results provide further, stronger evidence that sensorimotor and linguistic distributional information contribute to categorical decision making. Critically, even though the classic basic-level advantage was present in our data, results also demonstrate that such sensorimotor-linguistic information was systematically better at explaining category verification performance than a taxonomic hierarchy of subordinate, basic, and superordinate levels. The grade of evidence for this superiority effect was generally much stronger in the present experiment than in previous experiments, suggesting that some of the variable effects in previous experiments may have been due to suboptimal assumptions about how participants implicitly labelled pictured objects. That is, when we incorporated included the normed range of object names that are likely to be activated when people see a particular picture, our weighted measures of sensorimotor and linguistic distributional information offered the best explanation for variation in categorisation performance. People categorised objects more quickly and accurately when the member concept was close to the category concept in both sensorimotor experience and linguistic distributional knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>The basic-level advantage effect in object categorisation is intrinsically tied to longstanding feature-and/or network-based theories on the nature of categorisation itself and that of conceptual representation (e.g., <ref type="bibr" target="#b30">Corter &amp; Gluck, 1992;</ref><ref type="bibr" target="#b47">Jolicoeur et al., 1984;</ref><ref type="bibr" target="#b59">Markman &amp; Wisniewski, 1997;</ref><ref type="bibr" target="#b63">Murphy &amp; Brownell, 1985;</ref><ref type="bibr" target="#b78">Rogers &amp; Patterson, 2007;</ref>. In the present work, we have used state-of-the-art measures to show that it is possible to express the taxonomic relationships between concepts, that are thought to underly categorisation, in terms of distance in sensorimotor experience and/or linguistic distributional knowledge between category and member concepts, without referring to discrete, binary features (e.g., has wings, can fly) or featural dimensions (e.g., size, weight). Specifically, we found that the distance in sensorimotor experience between a given category concept (e.g., DOG) and a member concept (e.g., Labrador) may predict the speed of categorisation at least as well as a division into discrete taxonomic levels (i.e., the basic-level advantage) might (e.g., Experiments 1 and 2a). We also found that adjusting our measure of sensorimotor distance -via linguistic distributional information -to reflect the graded structure of categories enhanced its ability to predict RT (e.g., Experiment 1b) and accuracy (e.g., Experiment 2b) at least as well the taxonomic level of the category label. Finally, we found that weighting our measures of sensorimotor and linguistic distributional distance to reflect the range of names typically produced for a pictured object improved their ability to predict both RT and accuracy well beyond that of discrete taxonomic levels (Experiment 3). That is, the present findings show that the latency and accuracy of categorisation can be predicted by sensorimotor (i.e., perception-action experience of the world) and linguistic distributional information (i.e., statistical distribution of words in language) more effectively than by explaining the basic-level advantage in terms of discrete taxonomic levels. These findings are in line with recent linguistic-simulation views on the nature of concepts (e.g., <ref type="bibr" target="#b8">Barsalou et al., 2008;</ref><ref type="bibr" target="#b21">Connell, 2018;</ref><ref type="bibr" target="#b27">Connell &amp; Lynott, 2014;</ref><ref type="bibr" target="#b53">Louwerse, 2011)</ref> as well as recent categorisation research showing similar effects (e.g., <ref type="bibr" target="#b6">Banks et al., 2021)</ref>.</p><p>There are many reasons why it might be desirable to specify categorical structure and behaviour without assuming feature-based representations of concepts. While various traditional accounts differ in their interpretation of the nature of the similarity processes underlying categorisation (e.g., <ref type="bibr" target="#b18">Brooks, 1978;</ref><ref type="bibr" target="#b39">Hampton, 1979;</ref><ref type="bibr" target="#b61">Medin &amp; Schaffer, 1978;</ref><ref type="bibr" target="#b70">Nosofsky, 1986;</ref><ref type="bibr" target="#b74">Posner &amp; Keele, 1968;</ref><ref type="bibr" target="#b81">Rosch &amp; Mervis, 1975)</ref>, they generally share the assumption that concepts comprise indivisible, static and binary features (e.g., a given concept may or may not possess the features has wings, can fly). In categorisation research, such features are frequently derived from participant responses in feature-listing tasks (e.g., <ref type="bibr" target="#b60">McRae et al., 2005)</ref>, which are assumed to be sufficiently reflective of the correlational structure of the perceived world <ref type="bibr" target="#b80">(Rosch, 1978)</ref>, in that participants are unlikely to list features for objects that do not possess them. However, therein lie several limitations of a featurebased approach to concepts and categories. Firstly, features generated from feature-listing tasks are necessarily verbalised expressions of people's experience with selected concepts.</p><p>Consequently, they are typically much better suited to describe concrete concepts (e.g., dog, cup) than abstract concepts (e.g., hunger, peace; although see <ref type="bibr" target="#b41">Harpaintner et al., 2018)</ref>. This asymmetry greatly limits the applicability of features as a basis for conceptual representation.</p><p>If all concepts are represented through features, then why would they be harder to determine for one type of concept compared to the next? Secondly, many listed features are not inherent to the concept they are listed for. For example, in addition to perceptual and functional features, participants may list taxonomic (e.g., eagle → is a bird), affective (e.g., wasp → is annoying) and other thematic associations (e.g., bird → builds nests, knife → used with fork;</p><p>see <ref type="bibr" target="#b60">McRae et al., 2005)</ref>. As a result, it is not clear what exactly is being compared when considering feature overlap between two concepts. Indeed, research shows that measures of feature overlap are among the weaker predictors of concept similarity <ref type="bibr" target="#b104">(Wingfield and Connell, 2022b)</ref>. Thirdly, features generated in feature-listing tasks are not always uniformly interpretable away from the category or concept they are generated for (e.g., has a seat requires knowledge of chairs to be meaningful; <ref type="bibr" target="#b80">Rosch, 1978)</ref>, and is large means something different for metal compared to wooden spoons <ref type="bibr" target="#b62">(Medin &amp; Shoben, 1988</ref> mechanism supports this division, and previous arguments that it is warranted on purely operational grounds (e.g., it is useful to assign a feature-status to has wings if it allows us to distinguish between the concepts bird and mouse: <ref type="bibr" target="#b89">Smith &amp; Medin, 1981)</ref> are unpersuasive when alternative approaches render it unnecessary. Taken together, these weaknesses suggest that while features may be a useful way to describe certain aspects of conceptual structure, they may not be the static, indivisible building blocks of concepts traditional accounts of categorisation assume.</p><p>In a label → picture category verification task such as the one we employed here, the category label may activate linguistic distributional knowledge as well as sensorimotor representations, which facilitate the categorisation of the subsequent image <ref type="bibr" target="#b14">(Boutonnet &amp; Lupyan, 2015;</ref><ref type="bibr" target="#b55">Lupyan &amp; Thompson-Schill, 2012)</ref>. As a process model of category verification, a sensorimotor-linguistic account is therefore similar to the preparation model SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 61 proposed by <ref type="bibr" target="#b66">Murphy and Smith (1982)</ref>, but substitutes functional and perceptual features by simulated modality-and effector-specific sensorimotor experience and/or linguistic distributional knowledge. Importantly, like the original preparation model, the sensorimotorlinguistic preparation model does not assume any taxonomic level is privileged, but rather that performance is solely driven by the degree of overlap in sensorimotor experience and/or linguistic distributional knowledge between category and member concepts. The sensorimotor-linguistic preparation model thus proposes that when participants see a label (e.g., dog), it activates a sensorimotor representation of the referent concept, as well as linguistic distributional knowledge about the contexts it may appear in. When the participant sees the subsequent image, they may verify whether the image matches this activated representation. The greater the overlap between the perceived image and the pre-activated perceptual simulation, the less additional activation is required and the faster and more accurate the response.</p><p>Of note is that, across Experiments 1b and 2b, we found no evidence that typicality mediated the basic-level advantage; that is, lower subjective typicality ratings did not lead to objects being categorised at the subordinate level. Nonetheless, categorical gradedness did affect categorisation when it was modelled via linguistic distance: gradedness-adjusted measures of sensorimotor distance in Experiments 1b and 2b outperformed the unadjusted measures used in Experiments 1a and 2a, respectively. Furthermore, Experiment 3 incorporated the graded structure of categories via production-frequency weighting on sensorimotor and linguistic distributional distance and showed strong effects of both on categorical decision. These results illustrate the ways in which sensorimotor and linguistic distributional information may capture the graded structure of categories. For instance, the gradedness-adjusted measures of Experiments 1b and 2b incorporated the idea that pictures of "good", highly representative, category members are recognised as their basic category concepts (e.g., picture of jeans recognised as trousers) while pictures of less-representative category members are recognised as the specific, subordinate member concept (e.g., picture of sweatpants recognised as sweatpants, and not trousers). As a result, "good" member concepts are judged more quickly and accurately when preceded by their basic-level label (e.g., trousers → [picture of jeans]), while less-representative member concepts are judged more quickly and accurately when preceded by their specific, subordinate label (e.g., sweatpants → [picture of sweatpants]), and all other judgements are slower and less accurate according to the sensorimotor distance between the category and member concepts. These findings indicate that categorical gradedness itself -that is, the notion that less-representative category members are implicitly named with a specific (subordinate) label rather than with a more generic (basic level) label -is valid. The design of Experiment 3 did not permit us to explore items that were predominantly named at the subordinate level, but nevertheless, we showed that measures of sensorimotor and linguistic distributional distance that incorporate weightings of categorical gradedness predict behaviour in a labelàpicture categorisation task well beyond the division into three discrete taxonomic levels. Finally, since the typicality rating for an object in its basic-level category proved ineffective at detecting how categorical gradedness affects object categorisation, our findings also suggest that typicality ratings may not actually be the best measure of categorical gradedness. Rather -particularly given the fact that our measure of linguistic distance did not meaningfully correlate with the typicality ratings in Experiment 1b -it appears that linguistic distributional information captures aspects of the graded structure of categories that are not captured by subjective ratings of object typicality.</p><p>In summary, our measures of sensorimotor and linguistic distributional information successfully captured aspects of the relationship between categories and their members: we have demonstrated that overlap in sensorimotor experience predicts RT and accuracy at least SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 63 as well as division into discrete taxonomic levels. Moreover, we have shown that sensorimotor experience and linguistic distributional information may capture the graded structure of categories. These findings add to our understanding of sensorimotor-linguistic concepts and categories and provide an alternative to feature-and/or network-accounts of the basic-level advantage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Log (ln) Bayes Factors for the best sensorimotor-linguistic model versus taxonomic levels for each experiment and dependent variable (Panel A), and relative contribution of sensorimotor and linguistic distributional information to the best-fitting sensorimotor-linguistic model, calculated from standardised regression coefficients (Panel B). Note: Red dotted line indicates Bayes Factor threshold set for each experiment; evidence falling between dotted lines is equivocal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>-adjusted linguistic distance (M = .30, SD = .25, range = [0, .83]) and sensorimotor distance (M = .04, SD = .05, range = [0, .29]) were moderately correlated at r = .53 (i.e., 28.30% shared variance).Data analysis. Five sets of analyses were planned to test our hypotheses: two to test the predictions of traditional taxonomic accounts of the basic-level advantage, and three to test the sensorimotor-linguistic account. Analysis A tested whether including traditional item typicality would predict categorical decision RT and accuracy better than taxonomic information alone. RT (correct trials only) and Accuracy (all trials) were analysed using the model specifications of Analysis A in Experiment 1, with an additional fixed effect of typicality (variable centred). Bayesian model comparisons tested whether the data favoured random effects only, taxonomic level, or taxonomic level and typicality. Analysis B tested whether categorisation at the subordinate versus basic level differed for typical and atypical category members. RT and accuracy were analysed as per Analysis A, with the additional fixed effect of interaction between typicality and subordinate taxonomic level (i.e., where basic level is coded as the reference level). Model comparisons tested whether the data favoured this interaction model over the final model of Analysis A.To test our sensorimotor-linguistic predictions, Analysis C investigated if linguistic distance and typicality ratings were correlated, using a Bayesian correlation analysis in JASP (version 0.9.2: JASP Team, 2019) with default beta prior width =1 and a directional hypothesis of negative correlation (i.e., higher distance = less typical). Analysis D examined whether variance in RT and accuracy could be explained by gradedness-adjusted sensorimotor and linguistic distance. Model comparisons tested whether the data favoured a SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 29 model containing sensorimotor distance alone, or a model containing the additional fixed effect of linguistic distance. Finally, in Analysis E, we investigated whether RT and accuracy were best explained by traditional taxonomic-typicality information or by sensorimotorlinguistic information. Therefore, in analysis E, Bayesian model comparisons determined whether our data favoured the best-performing taxonomic-typicality model from analysis B or the best-performing sensorimotor-linguistic model from analysis D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Procedure.</head><label></label><figDesc>The experiment ran on web-based platform Gorilla.sc<ref type="bibr" target="#b0">(Anwyl-Irvine et al., 2020)</ref>, which handled both collection of informed consent and experimental data collection. Trial presentation was identical to Experiment 1a, except the font used to display labels was lowercase Open Sans.Ethics and consent. The study received ethical approval from the Lancaster University Faculty of Science and Technology Research Ethics Committee (ethics code: FST18006). As well as the terms specified in Experiment 1a, participants consented to take part on condition that they passed a series of attention checks (i.e., 70% accuracy on filler items as per Experiment 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>slowed down categorisation by up to 216.80 ms [b = 747.58, 95% CI = ±255.32, t(1424.47) = 5.74, p &lt;.001] and made errors up to 31.90 times more likely [b =-11.94, 95% CI = ±3.37, z = -6.94, p &lt;.001].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Procedure.</head><label></label><figDesc>The experiment ran on web-based platform Gorilla.sc<ref type="bibr" target="#b0">(Anwyl-Irvine et al., 2020)</ref>, handling both collection of informed consent and experimental data collection.Trial presentation and instructions were identical to Experiment 2a, with the exception that the font used to display labels was 36-point lowercase Arial. Participants were randomly assigned to a stimulus list. Test and filler items appeared in random order with a self-paced break after 160 trials.Ethics and consent. The study received ethical approval from the Lancaster University Faculty of Science and Technology Research Ethics Committee (ethics code: FST18006). All participants read information detailing the purpose and expectations of the study before giving informed consent to take part, which included consent to take part on condition that they passed a series of attention checks (i.e., 70% accuracy on filler items as per Experiment 1), as well as agreement to share publicly all alphanumeric data in anonymised form.Critical predictors. As well as a specified taxonomic level (subordinate, basic, superordinate), each label → picture test item had an associated value in two critical predictors that captured the overlap in sensorimotor and linguistic distributional experience between category concept and member concept.Weighted average linguistic distance. For each image in the item set, we retrieved the set of names produced by participants in the van Hoef et al. (2022) picture naming norms, as well as the associated frequency of production for each name. We then calculated the cosine distance between each category label and each image name, using the same corpus-based measure of linguistic distance as per Experiment 1a. Finally, for every label → picture item, we calculated its weighted average linguistic distance by multiplying each label → name distance by the relevant production frequency of that name for that picture and calculated the mean of these weighted distances. For example, the weighted average linguistic distance for the item dog → [Labrador image 1] was calculated as the dog-dog distance (0) multiplied by its production frequency weight (81.0%) plus the dog-Labrador distance (.519) multiplied by its production frequency weight (19%), giving a weighted average distance of .071. The final weighted average linguistic distance measure for each label → picture pair ranged in theory from -1 to +1 (actual range = [.00, .91], M = .30., SD = .15), with higher values indicating greater distance in linguistic space (i.e., less overlap in the linguistic distributional experience of each word).Weighted average sensorimotor distance. As for linguistic distance (see above), we calculated the weighted average sensorimotor distance for each item based on the different names produced in the van Hoef et al. (2022) picture naming norms, weighted by their production frequencies. The final weighted average sensorimotor distance measure for each label → picture pair ranged in theory from -1 to +1 (actual range [.00, .16], M = .03, SD = .03), with higher values indicating greater distance in sensorimotor space (i.e., less overlap in the sensorimotor experience of each concept). Linguistic and sensorimotor distance measures were weakly-to-moderately correlated, r = .311 (9.67% shared variance).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Model comparisons for linear mixed effect regressions of RT and logistic mixed effects regressions of accuracy in Experiment 1a showing change in R2 for nested comparisons andBayes Factors for all comparisons.±0.44, z = -5.83, p &lt; .001] (predicted probability of a correct answer = 91.8%) than at the basic level. Our data thus replicate the classic basic-level advantage in categorisation. In RT, Analysis B model comparisons showed very strong evidence for the effect of sensorimotor distance over a null model containing only random effects (BF10 = 9521.33). While a model containing both sensorimotor and linguistic distance was also better than the null (BF10 = 391.87), model comparisons indicated strong evidence against the inclusion of linguistic distance in RT models (i.e., the data were BF01 = 24.30 times more likely under a model containing only sensorimotor distance compared to a</figDesc><table><row><cell>Analysis</cell><cell>Model comparison</cell><cell>RT</cell><cell></cell><cell>Accuracy</cell><cell></cell></row><row><cell></cell><cell></cell><cell>ΔR 2</cell><cell>BF10</cell><cell>ΔR 2</cell><cell>BF10</cell></row><row><cell></cell><cell>Null model (random effects)</cell><cell>.264</cell><cell>-</cell><cell>.270</cell><cell>-</cell></row><row><cell>A</cell><cell>Taxonomic levels vs. null</cell><cell>.012</cell><cell>2043.09</cell><cell>.065</cell><cell>49457.64</cell></row><row><cell>B</cell><cell>Sensorimotor distance vs. null</cell><cell>.011</cell><cell>9521.33</cell><cell>.016</cell><cell>12.66</cell></row><row><cell></cell><cell>Sensorimotor + Linguistic distance vs. null</cell><cell>.012</cell><cell>391.87</cell><cell>.041</cell><cell>300.29</cell></row><row><cell></cell><cell>Sensorimotor + Linguistic distance vs. Sensorimotor-only</cell><cell>.001</cell><cell>0.04</cell><cell>.025</cell><cell>23.72</cell></row><row><cell>C</cell><cell cols="2">Best Sensorimotor-Linguistic model vs. taxonomic levels. -</cell><cell>4.66</cell><cell>-</cell><cell>0.01</cell></row></table><note>Note: We report conditional model R 2 for the null model. For all other models, we report marginal (fixed effects only) model R 2 (see, Nakagawa &amp; Schielzeth, 2013). Note that marginal R 2 values are estimates reported only for information and are not used for inferencing. Taxonomic levels. Bayesian model comparisons in Analysis A showed very strong evidence for models containing taxonomic levels over a null model containing only random effects of participant and item on participants' RT (BF10 = 2043.09) and accuracy (BF10 = 49457.64). In RT, categorisation decisions made at the subordinate level were 37 ms slower than at the basic level [unstandardised b = 36.99, 95% CI = ±29.41, t(1822.17) = 2.46, p = .014]. Furthermore, categorisation decisions at the superordinate level were 84 ms slower than at the basic level [b = 83.81, 95% CI = ±29.68, t(1828.05) = 5.53, p &lt;.001]. Accuracy was overall high. Participants were most likely to answer correctly when an image was preceded by a label at the basic level (predicted probability of a correct answer = 97.7%). Compared to the basic level, participants were 2.74 times more likely to respond incorrectly when an image was labelled at the subordinate level, [b =-1.01, 95% CI = ±0.45, z = -4.37, p &lt; .001] (predicted probability of a correct answer = 93.9%). Finally, participants were up to 3.71 times more likely to respond incorrectly at the superordinate level [b = -1.31, 95% CI =Sensorimotor-linguistic predictors.model containing both sensorimotor and linguistic distances). Hence, the best sensorimotor- linguistic model of RT was sensorimotor distance alone, where RT increased with sensorimotor distance (unstandardised b = 722.97, 95% CI = ±277.49, t(1690.37) = 5.11, p &lt;.001), by up to 210 ms. 4</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>). In both accounts, categorisation of typical category members would therefore show the traditional basic-level advantage (i.e., basic level faster and more accurate than subordinate and superordinate levels), but categorisation of atypical members would show a different pattern (i.e., subordinate level faster and more accurate than basic level, followed by superordinate level).If it is indeed the case that less-representative category members are implicitly named at the specific, subordinate level, then it also affects how sensorimotor and linguistic information should be operationalized. In the previous experiment, we calculated sensorimotor and linguistic distance from the category name to the basic-level label of the pictured object. For example, in the item animal → picture of poodle, we assumed the picture would be implicitly labelled as the basic-level dog, hence sensorimotor and linguistic distance was calculated from animal → dog. However, for less-representative category members, sensorimotor and linguistic distance should instead be calculated from the category name to the subordinate label. If a poodle is a less-representative type of dog, then its picture would be implicitly labelled as poodle, and the item animal → picture of poodle should have its sensorimotor and linguistic distance calculated from animal → poodle. Since previous work has shown a close relationship between typicality and overlap of linguistic distributional experience (e.g.,<ref type="bibr" target="#b29">Connell &amp; Ramscar, 2001</ref>), we opted to implement an internally-consistent adjustment for categorical gradedness by using linguistic distance to determine whether a member concept should be considered a good or poor example of its category. Member concepts that were close to their category concept (e.g., salmon and fish appear in very similar linguistic contexts, and have a cosine distance of .28) were considered good, highly-representative category members whose pictures would activate basic-level labels and corresponding sensorimotor information, whereas member concepts that were distant from their category concept (e.g., sailfish and fish appear in rather different linguistic contexts, with a cosine distance of .67) were considered poor/less-representative members SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 25 that would activate subordinate labels and corresponding sensorimotor information. With this adjustment for categorical gradedness in place, we could characterise as before the representational overlap of linguistic and sensorimotor information between a category and member concept.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>traditional taxonomic accounts to explain the basic-level advantage in categorisation, and to interact with subordinate taxonomic level so that typical items would show a basic-level advantage but atypical items would show a subordinate-level advantage. From the sensorimotor-linguistic perspective, we also hypothesised that linguistic distributional information would capture the graded structure of categories, whereby linguistic distance would correlate negatively with traditional typicality ratings (i.e., less typical = greater linguistic distance between category and member concept). Using gradedness-adjusted measures of sensorimotor and linguistic distance, we predicted -as before -that linguistic distance would predict categorisation performance above and beyond sensorimotor distance (i.e., greater category-member distance results in slower RT and poorer accuracy in categorical decision) and that the best sensorimotor/linguistic model would outperform the taxonomic-typicality model. As well as a specified taxonomic level (subordinate, basic, superordinate), each label → picture test item had an associated traditional typicality rating of the pictured object as a member of its basic-level category. In addition, each label → picture test item had a gradedness-adjusted measure that captured the overlap in sensorimotor and linguistic distributional experience between category concept and member concept (see below for details).</figDesc><table /><note>Method Materials &amp; dependent measures. We used the categorical decision dataset from Experiment 1a, with new predictors as outlined below. Critical predictors.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note>shows model comparisons for analyses A, B, D and E.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc>Model comparisons for linear mixed effect regressions of RT and logistic mixed effects regressions of accuracy in Experiment 1b showing change in conditional and marginal R 2 for nested comparisons and Bayes Factors for all comparisons. In Analysis A, model comparisons showed evidence against adding typicality ratings to a model containing taxonomic levels. In RT analysis, the data strongly favoured the taxonomic-only model (BF01 = 40.20) and typicality had very little effect [b = 9.48, 95% CI = ±47.36, t (75.05) = 0.39, p = .700]. In accuracy analysis, the data again favoured the taxonomic-only model (BF01 = 11.29), with typicality weakly trending in the predicted direction [b =0.59, 95% CI = ±0.66, z = 1.76, p</figDesc><table><row><cell>Analysis</cell><cell>Model comparison</cell></row></table><note>Note: We report conditional model R 2 for the null model. For all other models, we report change in marginal (fixed effects only) model R 2 (see Nakagawa &amp; Schielzeth, 2013). Note that marginal R 2 values are estimates reported only for information and are not used for inferencing. Taxonomic levels and traditional typicality.= .080]. In short, typicality ratings did not affect overall categorisation performance in our SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 31</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Analysis B model comparisons showed strong evidence against an interaction between typicality and subordinate taxonomic level. In analysis of RT, the interaction had little effect [unstandardised b = 46.16, 95% CI = ±75.71, t(1812.60) = 1.19, p = .230], and data were BF01 = 21.26 times more likely under the model without an interaction. In analysis of accuracy, we also found strong evidence against adding the interaction between subordinate</figDesc><table /><note>). Interaction of traditional typicality with taxonomic level.taxonomic level and typicality (BF01 = 39.24), where it had little effect on categorical decision [b =0.25, 95% CI = ±0.88, z = 0.56, p = .570]. The best taxonomic-typicality model in this analysis therefore contained taxonomic levels and typicality ratings, but no interaction.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>., between subordinate items and their basic-level label) and average typicality ratings, with BF10= 0.79 representing only an equivocal level of evidence. That is, linguistic distance did not decisively capture the graded structure of categories normally reflected in typicality ratings, where more atypical examples of a category were only weakly associated with greater linguistic distance (i.e., less overlap in linguistic contexts) between category and member concept. In RT, Analysis D model comparisons showed very strong evidence for the effect of gradedness-adjusted sensorimotor distance over a null model of random effects, BF10 = 31398739.40. However, we found strong evidence against adding gradedness-adjusted linguistic distance to a model containing sensorimotor distance alone. That is, as we found for unadjusted distance measures in Experiment 1, the data were BF01 = 15.13 times more likely under a model containing only sensorimotor distance compared to a model containing both linguistic and sensorimotor distance. In the best-fitting sensorimotor-only model, categorisation took up to</figDesc><table /><note>Linguistic distance and traditional typicality. Analysis C found a negative correlation of r =-.176 between our original measure of linguistic distance (i.eGradedness-adjusted sensorimotor and linguistic distance.244.38 ms longer at the greatest gradedness-adjusted sensorimotor distance (0.29, reflecting the least overlap in sensorimotor experience) than for items at the smallest sensorimotor distance (zero), [unstandardised b = 842.68, 95% CI = ±235.21, t(1532.40) = 6.52, p &lt;.001].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3</head><label>3</label><figDesc>Model comparisons for linear mixed effect regressions of RT and logistic mixed effects regressions of accuracy in Experiment 2a showing change in R 2 for nested comparisons andBayes Factors for all comparisons. &lt;.001] levels was slower than at the basic level. In contrast to the findings from Experiment 1, the basic-level advantage did not appear in accuracy. Compared to the basic level, participants were 4.57 times more likely to respond incorrectly at the superordinate level [b = -1.52, 95% CI = ±.53, z = -5.67, p &lt; .001], as expected. However, people were 1.49 times more likely to respond correctly at the subordinate level than at the basic level (i.e., in 6%, followed by SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 39 basic-level (97.9%) and finally the superordinate-level (91.2%). In other words, accuracy was approximately equal at the subordinate and basic levels, and worse at the superordinate level.The present study therefore largely but not completely replicates the classic basic level advantage. Overlap in sensorimotor experience between category and member concept facilitates categorisation RT and accuracy. However, contrary to what we predicted, and not replicating the results from lab-based testing, we found no positive evidence for the effect of linguistic distributional information. Analysis C again showed mixed results as to which model best explained the data. Unlike Experiment 1a, where sensorimotor distance outperformed taxonomic levels in explaining RT, model comparisons in the present analysis showed they performed approximately equivalently (see</figDesc><table><row><cell>Analysis</cell><cell>Model comparison</cell><cell>RT</cell><cell></cell><cell cols="2">Accuracy</cell></row><row><cell></cell><cell></cell><cell>ΔR 2</cell><cell>BF10</cell><cell>ΔR 2</cell><cell>BF10</cell></row><row><cell></cell><cell>Null model (random effects)</cell><cell>.197</cell><cell>-</cell><cell>.262</cell><cell>-</cell></row><row><cell>A</cell><cell>Taxonomic levels vs. null</cell><cell cols="2">.024 14847327.02</cell><cell>.129</cell><cell>9.81x10 10</cell></row><row><cell>B</cell><cell>Sensorimotor distance vs. null</cell><cell cols="2">.022 92484998.15</cell><cell>.048</cell><cell>12408.53</cell></row><row><cell></cell><cell>Sensorimotor + Linguistic distance vs. null</cell><cell cols="2">.024 26398821.53</cell><cell>.049</cell><cell>314.23</cell></row><row><cell></cell><cell>Sensorimotor + Linguistic distance vs. Sensorimotor-</cell><cell>.002</cell><cell>0.28</cell><cell>.001</cell><cell>0.02</cell></row><row><cell></cell><cell>only</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>C</cell><cell>Best Sensorimotor-Linguistic model vs. taxonomic</cell><cell>-</cell><cell>6.23</cell><cell>-</cell><cell>&lt;0.01</cell></row><row><cell></cell><cell>levels.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Taxonomic levels. Bayesian model comparisons for Analysis A showed very strong</cell></row><row><cell cols="5">evidence for models containing taxonomic levels over models containing only random</cell><cell></cell></row><row><cell cols="6">effects. In RT, categorisation at the subordinate [unstandardized b = 35.91, 95% CI = ±28.94,</cell></row><row><cell cols="6">t(1528.67) = 2.43, p = .015] and superordinate [b = 105.85, 95% CI = ±30.09, t(1538.60) =</cell></row><row><cell>6.89, p</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Note: We report conditional model R 2 for the null model. For all other models, we report change in marginal (fixed effects only) model R 2 (see, Nakagawa &amp; Schielzeth, 2013). Note that marginal R 2 values are estimates reported only for information and are not used for inferencing.the opposite direction to the predicted basic-level advantage), but with a small effect that in NHST terms was not significant [b = 0.41, 95% CI = ±.69, z = 1.16, p = .245]. Predicted probabilities of a correct answer were highest at the subordinate-level at 98.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>shows all model comparisons.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 4</head><label>4</label><figDesc>Model comparisons for linear mixed effects regressions of RT and logistic mixed effects regressions of accuracy Experiment 2b, showing change in R 2 for nested comparisons andBayes Factors for all comparisons. We report conditional model R 2 for the null model. For all other models, we report change in marginal (fixed effects only) model R 2 (see,<ref type="bibr" target="#b69">Nakagawa &amp; Schielzeth, 2013)</ref>. Note that marginal R 2 values are estimates reported only for information and are not used for inferencing.</figDesc><table><row><cell>Analysis Model comparison</cell></row></table><note>accounts of categorical graded structure based on typicality (e.g.,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION 49 level advantage in RT at least as well as taxonomic levels, whereas sensorimotor and linguistic distributional information would not predict accuracy as well as taxonomic levels.Preregistration, data, analysis code, stimuli and results are available at https://osf.io/8cjrm.</figDesc><table><row><cell>Method</cell></row><row><cell>Participants. Forty-three native speakers of English (30 female; Mage = 34.58 years,</cell></row><row><cell>SD = 11.62) were recruited through web-based crowdsourcing platform Prolific.co, for the</cell></row><row><cell>sum of £3.55 (i.e., approx. £8.50/ hour pro rata for an assumed duration of 25 minutes). On</cell></row><row><cell>average, participants took 18 minutes and 44 seconds to complete the task (SD = 4 minutes</cell></row><row><cell>and 20 seconds), which included giving informed consent and reading a debriefing. Through</cell></row><row><cell>Prolific's recruitment filter settings, we ensured that all participants were native speakers of</cell></row><row><cell>English, had corrected-to-normal vision, and had not participated in any of our previous web-</cell></row><row><cell>based experiments. One participant was replaced based on the 70% accuracy threshold</cell></row><row><cell>specified in the preregistration.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>labels not featured in test items: 27 superordinate (e.g., label building → picture ashtray), 27 basic (e.g., label fish → image frog), and 51 subordinate (e.g., label duck → image cockatoo) labels. All false fillers ranged from easy to difficult to reject. Finally, to balance out the true and false items per stimulus list, we included 21 fillers that were true and</figDesc><table><row><cell>SENSORIMOTOR AND LINGUISTIC PICTURE CATEGORISATION</cell><cell>51</cell></row><row><cell>and used category did not repeat test-item category labels: 7 basic (e.g., label saw → image jigsaw), 7</cell><cell></cell></row><row><cell>subordinate (e.g., label kingfisher → image kingfisher), and 7 superordinate (e.g., label device</cell><cell></cell></row><row><cell>→ image keyboard) labels. As a result, the final stimulus lists each contained 306 label →</cell><cell></cell></row><row><cell>picture pairs, divided evenly between true and false (132 true test items, 21 true fillers and</cell><cell></cell></row><row><cell>153 false fillers). All stimuli may be found in the supplemental materials on OSF.</cell><cell></cell></row><row><cell>). Finally, we divided all 396 test items into</cell><cell></cell></row><row><cell>three stimulus lists of 132 items, where each list featured 44 subordinate, 9 basic and 4</cell><cell></cell></row><row><cell>superordinate labels and included each picture only once.</cell><cell></cell></row><row><cell>Filler items consisted of 174 label → picture pairs, comprising similar object pictures</cell><cell></cell></row><row><cell>and labels to test items, and were seen by all participants. Of these, 48 fillers were false and</cell><cell></cell></row><row><cell>used category labels featured in test-items, to ensure that repeated labels could not cue</cell><cell></cell></row><row><cell>participants to respond 'yes' to category membership: 24 basic level (e.g., label dog → image</cell><cell></cell></row><row><cell>cow) and 24 superordinate (e.g., label vehicle → image clock). A further 105 fillers were false</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>A showed very strong evidence for models containing taxonomic levels over a null model containing only random effects on participants' RT (BF10 =19262614.75) and accuracy (BF10 = 8.88x10 18 ). In RT, categorisation decisions made at the subordinate level were 32.18 ms slower than at the basic level [unstandardized b = 32.18, 95% CI = ±14.60, t(5086.31) = 4.32, p &lt;.001]. Furthermore, categorisation decisions at the superordinate level were 53.37 ms slower than at the basic level [b = 53.37, 95% CI = ±14.82, t(5088.95) = 7.06, p &lt;.001].Accuracy was overall high and comparable to previous experiments, suggesting the new stimulus set in the present study was of equivalent difficulty. Participants responded most accurately when the category label preceding an image was at the basic level (predicted</figDesc><table><row><cell>probability of a correct answer = 97.6%). Compared to this basic level, participants were 1.71</cell></row><row><cell>times more likely to respond incorrectly when an image was labelled at the subordinate level,</cell></row><row><cell>[b =-.54, 95% CI = ±0.28, z = -3.69, p &lt; .001] (predicted probability of a correct answer =</cell></row><row><cell>96.0%). Finally, participants were up to 3.69 times more likely to respond incorrectly at the</cell></row><row><cell>superordinate level than at the basic level [b = -1.30, 95% CI = ±0.26, z = -9.67, p &lt; .001]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 5</head><label>5</label><figDesc>Model comparisons for linear mixed effect regressions of RT and logistic mixed effects regressions of accuracy in Experiment 3, showing change in conditional R 2 for nested comparisons and Bayes Factors for all comparisons.</figDesc><table><row><cell>Analysis</cell><cell>Model comparison</cell><cell></cell><cell>RT</cell><cell></cell><cell>Accuracy</cell></row><row><cell></cell><cell></cell><cell>ΔR 2</cell><cell>BF10</cell><cell>ΔR 2</cell><cell>BF10</cell></row><row><cell></cell><cell>Null model (random effects)</cell><cell>.332</cell><cell>-</cell><cell>.295</cell><cell>-</cell></row><row><cell>A</cell><cell>Taxonomic levels vs. null</cell><cell>.006</cell><cell>19242414.80</cell><cell>.057</cell><cell>8.88x10 18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Note: We report conditional model R 2 for the null model. For all other models, we report change in marginal (fixed effects only) model R 2 . Note that marginal R 2 values are estimates reported only for information and are not used for inferencing, as marginal R 2 values may go down as well as up with additional parameters (see,<ref type="bibr" target="#b69">Nakagawa &amp; Schielzeth, 2013)</ref>.</figDesc><table><row><cell></cell><cell></cell><cell>-.001</cell><cell>43.78</cell><cell>.121</cell><cell>10.99</cell></row><row><cell>C</cell><cell>Sensorimotor versus taxonomic levels.</cell><cell>-</cell><cell>831.86</cell><cell>-</cell><cell>2.95x10 10</cell></row><row><cell></cell><cell>Sensorimotor-linguistic versus taxonomic levels</cell><cell>-</cell><cell>36416.55</cell><cell>-</cell><cell>3.24x10 11</cell></row><row><cell></cell><cell cols="5">Sensorimotor-linguistic predictors. Confirming our hypotheses, in RT, Analysis B</cell></row><row><cell cols="5">model comparisons showed very strong evidence for the effect of weighted average</cell><cell></cell></row><row><cell cols="4">sensorimotor distance over a null model containing only random effects (BF10 =</cell><cell></cell><cell></cell></row><row><cell cols="5">16023718859.37). However, contrasting our hypotheses, model comparisons also showed</cell><cell></cell></row><row><cell cols="5">strong evidence for the inclusion of weighted average linguistic distributional on top of</cell><cell></cell></row><row><cell cols="5">sensorimotor distance (BF10 = 43.78). Inspection of the coefficients revealed that RT</cell><cell></cell></row><row><cell cols="5">increased with sensorimotor distance [unstandardised b = 831.05, 95% CI = ±364.55, t</cell><cell></cell></row><row><cell cols="6">(1158.64) = 4.47, p &lt;.001] as well as with linguistic distance [b = 105.49, 95% CI = ±51.43, t</cell></row><row><cell cols="6">(3363.21) = 4.02, p &lt;.001]. That is, although we originally hypothesised in Experiments 1a</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head></head><label></label><figDesc>). In other words, some listed features (e.g., is large for lions, limousines, and mugs; McRae et al., 2005) may only become meaningful after the category has been established. It is not clear by what mechanism the meaning of such features is compared between concepts when determining their similarity. Finally, feature-based accounts of categorisation are typically agnostic with regards to the representation of features themselves (e.g., if bird is represented by has wings, what represents the latter?) and draw a line between features and concepts. It is unclear what</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In the present paper, we use the term concept to refer to an aggregated, canonical aspect of experience that can be mentally represented offline (i.e., in the absence of its referent:<ref type="bibr" target="#b27">Connell &amp; Lynott, 2014)</ref>, and the term category to refer to a class that groups entities together.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The present experiments were developed in parallel with a separate investigation using the same measure of sensorimotor overlap between concepts<ref type="bibr" target="#b6">(Banks et al., 2021)</ref>; since both studies used this new measure at the same time, both reports can legitimately describe its use as novel.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">For modelling performance in tasks of high conceptual complexity, the use of count-vector (e.g., log co-occurrence) models trained on high-quality corpora is recommended over the use of more complex predict models (e.g., skip-gram) or simpler n-gram models: see<ref type="bibr" target="#b102">Wingfield and Connell (2022a)</ref> for a systematic review and analysis.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This value reflects the change in the dependent variable at the maximum sensorimotor (.29) or linguistic (.83) distance between categories and members in our dataset, calculated as a proportion of the beta coefficient (e.g., .29*722.97 = 209.66).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Full coefficient statistics for all models including and excluding the gavel item are included in supplementals (see also Appendix A). In brief, analysis including this outlier item did not affect inferences based on Bayesian model comparisons, but it did create a weak but significant coefficient effect of typicality in Analysis B that disappeared when the item was excluded, which suggested we were correct to remove it.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Since there were no new data to collect to run this replication, we opted not to preregister it and instead included it as an exploratory study.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>Model statistics for taxonomic-typicality models of accuracy and RT for lab-based datasets excluding and including the item 'gavel'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Excluding </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gorilla in our midst: An online behavioral experiment builder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Anwyl-Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Massonnié</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Flitton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kirkham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Evershed</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-019-01237-x</idno>
		<ptr target="https://doi.org/10.3758/s13428-019-01237-x" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="388" to="407" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">What some concepts might not be</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Gleitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gleitman</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0277(83)90012-4</idno>
		<ptr target="https://doi.org/10.1016/0010-0277(83)90012-4" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="308" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Statistical Learning: From Acquiring Specific Items to Forming General Rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Newport</surname></persName>
		</author>
		<idno type="DOI">10.1177/0963721412436806</idno>
		<ptr target="https://doi.org/10.1177/0963721412436806" />
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="170" to="176" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Congruent Embodied Representations for Visually Presented Actions and Linguistic Phrases Describing Actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Aziz-Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iacoboni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="1818" to="1823" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cub.2006.07.060</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2006.07.060" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Category production norms for 117 concrete and abstract categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-021-01787-z</idno>
		<ptr target="https://doi.org/10.3758/s13428-021-01787-z" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Linguistic Distributional Knowledge and Sensorimotor Grounding both Contribute to Semantic Category Production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wingfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.13055</idno>
		<ptr target="https://doi.org/10.1111/cogs.13055" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Perceptual symbol systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Barsalou</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X99002149</idno>
		<ptr target="https://doi.org/10.1017/S0140525X99002149" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="577" to="660" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Language and Simulation in Conceptual Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Barsalou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symbols, Embodiment and meaning</title>
		<editor>M. de Vega, A. M. Glenberg, &amp; A. Graesser</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="245" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">MuMIn: Multi-Model Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bartoń</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 1.43.17. (1.43.17</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fitting Linear Mixed-Effects Models Using lme4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<idno type="DOI">10.18637/jss.v067.i01</idno>
		<ptr target="https://doi.org/doi:10.18637/jss.v067.i01" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Timed picture naming in seven languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>D'amico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Székely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Andonova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Devescovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Herron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ching Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pechmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pléh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wicha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Federmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gerdjikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kohnert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mehotcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tzeng</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03196494</idno>
		<ptr target="https://doi.org/10.3758/BF03196494" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="344" to="380" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Age of acquisition effects in picture naming: Evidence for a lexical-semantic competition hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Belke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brysbaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghyselinck</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2004.11.006</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2004.11.006" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="45" to="54" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Words Jump-Start Vision: A Label Advantage in Object Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boutonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page" from="9329" to="9335" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.5111-14.2015</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.5111-14.2015" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Bank of Standardized Stimuli (BOSS), a new set of 480 normative photos of objects to be used as visual stimuli in cognitive research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Brodeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dionne-Dostie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Montreuil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lepage</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0010773</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0010773" />
	</analytic>
	<monogr>
		<title level="j">PloS One</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Brodeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guérard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bouras</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0106953</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0106953" />
		<title level="m">Bank of Standardized Stimuli (BOSS) Phase II: 930 New Normative Photos. PLOS ONE</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Nonanalytic concept formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognition and categorization</title>
		<editor>E. Rosch &amp; B. Lloyd</editor>
		<imprint>
			<publisher>Lawrence Erlbaum Associates, Publishers</publisher>
			<date type="published" when="1978" />
			<biblScope unit="page" from="169" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Body-part-specific Representations of Semantic Noun Categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Carota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moseley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pulvermüller</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_00219</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_00219" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1492" to="1509" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A spreading-activation theory of semantic processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Loftus</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.82.6.407</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.82.6.407" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="407" to="428" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">What have labels ever done for us? The linguistic shortcut in conceptual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language, Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1308" to="1318" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/23273798.2018.1471512</idno>
		<ptr target="https://doi.org/10.1080/23273798.2018.1471512" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Look but don&apos;t touch: Tactile disadvantage in processing modality-specific words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lynott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2009.10.005</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2009.10.005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Flexible and fast: Linguistic shortcut affects both shallow and deep conceptual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lynott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="542" to="550" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13423-012-0368-x</idno>
		<ptr target="https://doi.org/10.3758/s13423-012-0368-x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Principles of Representation: Why You Can&apos;t Represent the Same Concept Twice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lynott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="390" to="406" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/tops.12097</idno>
		<ptr target="https://doi.org/10.1111/tops.12097" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Using Distributional Measures to Model Typicality in Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ramscar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Twenty-Third Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Explaining basic categories: Feature predictability and information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Corter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.111.2.291</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.111.2.291" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="291" to="303" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Analyzing the factors underlying the structure and computation of the meaning of chipmunk, cherry, chisel, cheese, and cello (and many other such concrete nouns)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Cree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcrae</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.132.2.163</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.132.2.163" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="163" to="201" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluating Amazon&apos;s Mechanical Turk as a tool for experimental behavioral research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J C</forename><surname>Crump</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0057410</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0057410" />
	</analytic>
	<monogr>
		<title level="j">PloS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Processing unrelated language can change what you see</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Dils</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boroditsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="882" to="888" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/PBR.17.6.882</idno>
		<ptr target="https://doi.org/10.3758/PBR.17.6.882" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Alternative conceptions of semantic theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Holyoak</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0277(74)90002-X</idno>
		<ptr target="https://doi.org/10.1016/0010-0277(74)90002-X" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="313" to="339" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Perceptual Knowledge Retrieval Activates Sensory Brain Regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Perfetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="4917" to="4921" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.5389-05.2006</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.5389-05.2006" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Why is the sunny side always up? Explaining the spatial mapping of concepts by language use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Goodhew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcgaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kidd</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-014-0593-6</idno>
		<ptr target="https://doi.org/10.3758/s13423-014-0593-6" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1287" to="1293" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Polymorphous concepts in semantic memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hampton</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0022-5371</idno>
		<ptr target="https://doi.org/10.1016/S0022-5371" />
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="90246" to="90255" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Prototype models of concept representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hampton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Categories and concepts: Theoretical views and inductive data analysis</title>
		<editor>I. van Mechelen, J. Hampton, R. Michalski, &amp; P. Theuns</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="67" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The Semantic Content of Abstract Concepts: A Property Listing Study of 296 Abstract Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harpaintner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Trumpp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kiefer</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2018.01748</idno>
		<ptr target="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01748" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Somatotopic Representation of Action Words in Human Motor and Premotor Cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hauk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Johnsrude</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pulvermüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="307" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/S0896-6273</idno>
		<ptr target="https://doi.org/10.1016/S0896-6273" />
		<imprint>
			<biblScope unit="page" from="838" to="847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Reaction time effects in lab-versus Web-based research: Experimental evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Hilbig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1718" to="1724" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13428-015-0678-9</idno>
		<ptr target="https://doi.org/10.3758/s13428-015-0678-9" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Effects of varying levels of expertise on the basic level of categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Mervis</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.126.3.248</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.126.3.248" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="248" to="277" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pictures and names: Making the connection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jolicoeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gluck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kosslyn</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(84)90009-4</idno>
		<ptr target="https://doi.org/10.1016/0010-0285(84)90009-4" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="275" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">lmerTest Package: Tests in Linear Mixed Effects Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H B</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<idno type="DOI">10.18637/jss.v082.i13</idno>
		<ptr target="https://doi.org/10.18637/jss.v082.i13" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Women, Fire and Dangerous Things: What categories reveal about the mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lakoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>The University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">A solution to Plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sensorimotor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linguistic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Categorisation</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.104.2.211</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.104.2.211" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Symbol Interdependency in Symbolic and Embodied Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Louwerse</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1756-8765.2010.01106.x</idno>
		<ptr target="https://doi.org/10.1111/j.1756-8765.2010.01106.x" />
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="302" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Producing high-dimensional semantic spaces from lexical co-occurrence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03204766</idno>
		<ptr target="https://doi.org/10.3758/BF03204766" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="208" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The evocative power of words: Activation of concepts by verbal and nonverbal means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Thompson-Schill</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0024904</idno>
		<ptr target="https://doi.org/10.1037/a0024904" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="170" to="186" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The Lancaster Sensorimotor Norms: Multidimensional measures of perceptual and action strength for 40,000 English words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lynott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brysbaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1271" to="1291" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13428-019-01316-z</idno>
		<ptr target="https://doi.org/10.3758/s13428-019-01316-z" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Correlated properties in natural categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Malt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0022-5371</idno>
		<ptr target="https://doi.org/10.1016/S0022-5371" />
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="90170" to="90171" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Similar and different: The differentiation of basic-level categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Markman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wisniewski</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.23.1.54</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.23.1.54" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="70" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Semantic feature production norms for a large set of living and nonliving things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcrae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Cree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Seidenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mcnorgan</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03192726</idno>
		<ptr target="https://doi.org/10.3758/BF03192726" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="547" to="559" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Context theory of classification learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Medin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Schaffer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.85.3.207</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.85.3.207" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Context and structure in conceptual combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Medin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Shoben</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(88</idno>
		<ptr target="https://doi.org/10.1016/0010-0285(88" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="90018" to="90025" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Category differentiation in object recognition: Typicality constraints on the basic category advantage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Brownell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="84" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0278-7393.11.1.70</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.11.1.70" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Hierarchical Structure in Concepts and the Basic Level of Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Lassaline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge, Concepts and Categories</title>
		<editor>K. Lamberts &amp; D. Shanks</editor>
		<imprint>
			<publisher>Psychology Press -Taylor &amp; Francis</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="93" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Basic-level superiority in picture categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/S0022-5371</idno>
		<ptr target="https://doi.org/10.1016/S0022-5371" />
		<imprint>
			<biblScope unit="page" from="90412" to="90413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Categorizing objects in isolation and in scenes: What a superordinate is good for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wisniewski</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.15.4.572</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.15.4.572" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="572" to="586" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A general and simple method for obtaining R 2 from generalized linear mixed-effects models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schielzeth</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2041-210x.2012.00261.x</idno>
		<ptr target="https://doi.org/10.1111/j.2041-210x.2012.00261.x" />
	</analytic>
	<monogr>
		<title level="j">Methods in Ecology and Evolution</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="142" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Attention, similarity, and the identification-categorization relationship</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="57" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0096-3445.115.1.39</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.115.1.39" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sensorimotor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linguistic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Categorisation</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">PsychoPy-Psychophysics software in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Peirce</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jneumeth.2006.11.017</idno>
		<ptr target="https://doi.org/10.1016/j.jneumeth.2006.11.017" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience Methods</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="13" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">On the genesis of abstract ideas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Posner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Keele</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0025953</idno>
		<ptr target="https://doi.org/10.1037/h0025953" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Redundancy in Perceptual and Linguistic Experience: Comparing Feature-Based and Distributional Models of Semantic Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Riordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1756-8765.2010.01111.x</idno>
		<ptr target="https://doi.org/10.1111/j.1756-8765.2010.01111.x" />
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="345" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Semantic distance and the verification of semantic relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Rips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shoben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/S0022-5371</idno>
		<ptr target="https://doi.org/10.1016/S0022-5371" />
		<imprint>
			<biblScope unit="page" from="80056" to="80064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Object categorization: Reversals and explanations of the basic-level advantage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Patterson</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.136.3.451</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.136.3.451" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="451" to="469" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Natural categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(73)90017-0</idno>
		<ptr target="https://doi.org/10.1016/0010-0285(73)90017-0" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="350" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Principles of Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognition &amp; Categorization</title>
		<editor>E. Rosch &amp; B. Lloyd</editor>
		<imprint>
			<publisher>Lawrence Erlbaum Associates, Publishers</publisher>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Family resemblances: Studies in the internal structure of categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Mervis</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285</idno>
		<ptr target="https://doi.org/10.1016/0010-0285" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="90024" to="90033" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Basic objects in natural categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mervis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boyes-Braem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="382" to="439" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/0010-0285</idno>
		<ptr target="https://doi.org/10.1016/0010-0285" />
		<imprint>
			<biblScope unit="page">90013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Structural bases of typicality effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="491" to="502" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0096-1523.2.4.491</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.2.4.491" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Sequential hypothesis testing with Bayes factors: Efficiently testing mean differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Schönbrodt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zehetleitner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perugini</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000061</idno>
		<ptr target="https://doi.org/10.1037/met0000061" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="322" to="339" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Online psychophysics: Reaction time effects in cognitive experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Semmelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weigelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1241" to="1260" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13428-016-0783-4</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0783-4" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Categories and Concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Medin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Structure and process in semantic memory: A featural model for semantic decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shoben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Rips</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0036351</idno>
		<ptr target="https://doi.org/10.1037/h0036351" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="214" to="241" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">A standardized set of 260 pictures: Norms for name agreement, image agreement, familiarity, and visual complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snodgrass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vanderwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Learning and Memory</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="174" to="215" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0278-7393.6.2.174</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.6.2.174" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Object categories and expertise: Is the basic level in the eye of the beholder?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1016/0010-0285(91</idno>
		<ptr target="https://doi.org/10.1016/0010-0285(91" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">90016</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Conceptual Structure and the Structure of Concepts: A Distributed Account of Category-Specific Deficits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Durrant-Peatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and Language</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="231" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title/>
		<idno type="DOI">10.1006/brln.2000.2353</idno>
		<ptr target="https://doi.org/10.1006/brln.2000.2353" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Subtlex-UK: A New and Improved Word Frequency Database for British English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sensorimotor And</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J B</forename><surname>Picture Categorisation Van Heuven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mandera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keuleers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brysbaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1176" to="1190" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/17470218.2013.850521</idno>
		<ptr target="https://doi.org/10.1080/17470218.2013.850521" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Timed Picture Naming Norms for 800 Photographs of 200 Objects in English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Hoef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lynott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/2h6q7</idno>
		<ptr target="https://doi.org/10.31234/osf.io/2h6q7" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Lenth</surname></persName>
		</author>
		<title level="m">emmeans: Estimated Marginal Means, aka Least-Squares Means (1.7.0)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A practical solution to the pervasive problems of p values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="779" to="804" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/BF03194105</idno>
		<ptr target="https://doi.org/10.3758/BF03194105" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Understanding the role of linguistic distributional knowledge in cognition. Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wingfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="1" to="51" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/23273798.2022.2069278</idno>
		<ptr target="https://doi.org/10.1080/23273798.2022.2069278" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Sensorimotor distance: A grounded measure of semantic similarity for 800 million concept pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wingfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Connell</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-022-01965-7</idno>
		<ptr target="https://doi.org/10.3758/s13428-022-01965-7" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Seeing, acting, understanding: Motor resonance in language comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.135.1.1</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.135.1.1" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sensorimotor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linguistic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Categorisation</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
