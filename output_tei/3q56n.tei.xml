<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding the Decline in Cooperation: The Role of Confusion and Social Preferences in Public Goods Games, Investigated Through Manipulation of Other Players&apos; Behavior and Decision-Making Model Comparisons</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiko</forename><surname>Mizuno</surname></persName>
							<email>k.mizuno@kwansei.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Kwansei Gakuin University</orgName>
								<address>
									<addrLine>1-155 Uegahara 1-bancho</addrLine>
									<postCode>662-8501</postCode>
									<settlement>Nishinomiya City, Hyogo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Kwansei Gakuin University</orgName>
								<address>
									<addrLine>1-155 Uegahara 1-bancho</addrLine>
									<postCode>662-8501</postCode>
									<settlement>Nishinomiya City, Hyogo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Shimizu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kwansei Gakuin University</orgName>
								<address>
									<addrLine>1-155 Uegahara 1-bancho</addrLine>
									<postCode>662-8501</postCode>
									<settlement>Nishinomiya City, Hyogo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding the Decline in Cooperation: The Role of Confusion and Social Preferences in Public Goods Games, Investigated Through Manipulation of Other Players&apos; Behavior and Decision-Making Model Comparisons</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In repeated public goods games, a robustly observed phenomenon is the gradual decline in cooperation that initially appears. Two main explanations for this decline have been proposed: the Social Preferences Hypothesis (SPH), which posits that individuals adjust their behavior based on altruism or equality toward others, and the Confusion Learning Hypothesis (CLH), which suggests that participants are simply trying to maximize their own benefit and learn the optimal behavior over time. This study aims to investigate which hypothesis is more valid through two approaches: (1) deriving a unified mathematical decision-making model and fitting the data and explains both hypotheses, and (2) conducting experimental manipulations by adjusting the feedback participants receive about others&apos; behavior. The results of Study 1 weakly supported CLH, while Study 2 provided strong evidence in favor of SPH. This study discusses the dual approach of combining decision-making models and experimental manipulation to explore both the decline and maintenance of cooperation in public goods games. An individual&apos;s pursuit of self-interest can lead to undesirable collective outcomes, as Hardin (1968) illustrated with the parable of the tragedy of the commons. In this scenario, when villagers graze their sheep freely on common pasture for personal gain, the pasture becomes depleted, leading to negative consequences for all. A social dilemma is a theoretical concept used to describe situations where individual rationality results in collective irrationality. It is defined as a situation where (1) individuals must choose between cooperation and non-cooperation, (2) cooperation is more beneficial for each individual, but (3) if everyone chooses non-cooperation, the group as a whole benefits less than if everyone had cooperated (Dawes, 1980). Social dilemmas are a common structure underlying many problems, from everyday issues to major social challenges (Dawes, 1980; Kollock, 1998). For example, consider the management of a local community. Running a community naturally incurs costs, such as money and effort. If every member shares these costs, the community can function well, benefiting everyone. However, it&apos;s tempting for</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>individuals to free ride, avoiding costs while still benefiting from the community. If everyone thinks this way, the community may struggle to function, as no one is willing to contribute. Other examples of social dilemmas include knowledge sharing in organizations <ref type="bibr">(Razmerita, Kirchner, &amp; Nielsen, 2016)</ref>, cooperation on COVID-19 prevention measures <ref type="bibr">(Johnson, Dawes, Fowler, &amp; Smirnov, 2020;</ref><ref type="bibr">Van Hulsen, Rohde, &amp; Van Exel, 2022)</ref>, and environmental issues <ref type="bibr">(Lee, Prendergast, Yim, &amp; Choi, 2019)</ref>.</p><p>Over time, cooperation in social dilemmas often declines. Many people have observed how activities that start with high participation gradually lose members and eventually fade away. This can happen in various situations, such as when fewer people speak up in meetings, when more people avoid paying for joint group purchases, or when only a few take on the responsibility of managing shared spaces. Why does cooperation in social dilemmas initially emerge but then gradually decline?</p><p>To find ways to sustain cooperation, this question must be addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Public Good Games (PGGs)</head><p>Numerous studies have examined behavior in social dilemmas using public goods games <ref type="bibr">(PGGs)</ref> in experimental settings. In a PGG, each participant decides how much of their initial endowment to contribute to a public good. The total contributions are then multiplied by a factor and distributed equally among all participants. For example, suppose each participant is given 100 points and chooses how much to invest. The total investment is multiplied by 1.6 and equally divided among four participants. The most efficient outcome is for everyone to invest the full 100 points, yielding 160 points per person and a 60-point profit.</p><p>However, in PGGs, the dominant strategy for each participant is to keep their entire endowment (non-cooperate), regardless of the contributions of others. For instance, if a player invests 100 points while the other three participants do not, the player will receive only 25 points, resulting in a 75-point loss, while the others gain 125 points each. In this scenario, the Nash equilibrium is for no one to contribute. Therefore, a rational, self-interested participant will prioritize maximizing their own benefit and choose not to cooperate. Thus, a rational participant seeking to maximize their personal gain need not consider whether others will cooperate or not; the best strategy is simply not to cooperate.</p><p>The expected return from cooperation in PGGs is influenced by the set value of the marginal per capita return <ref type="bibr">(MPCR)</ref>. MPCR refers to the marginal rate of return per player, and the higher this value, the more cooperation becomes a better option compared to non-cooperation. In the example above, the MPCR is 1.6/4, or 0.4, indicating that non-cooperation yields a higher payoff than cooperation.</p><p>When the &lt; 1, PGGs represent a social dilemma, as participants are incentivized to act in their self-interest rather than cooperate. Conversely, if the &gt; 1 ,, cooperation becomes more advantageous.</p><p>The tendency of initial cooperation followed by a gradual decline has been commonly observed in public goods game experiments. From an economic perspective, cooperation itself presents a puzzle, as rational, self-interested individuals would have no incentive to cooperate in the first place. Therefore, the emergence of cooperation in the early stages of these experiments, raises important questions.</p><p>Additionally, understanding why cooperation declines over time, even when some mutual cooperation is initially observed, may provide insights into how cooperation can be sustained. <ref type="bibr">For example, Isaac &amp; Walker (1988)</ref> examined the relationship between cooperation rates and group size in repeated PGGs and found that, regardless of group size, cooperation was initially high but decreased over time as the proportion of free riders increased. Similar trends have been reported in meta-analyses by Sally <ref type="bibr">(1995)</ref> and <ref type="bibr">Ledyard (1995)</ref>, indicating a general pattern of declining cooperation in repeated public goods games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confusion Learning hypothesis and Social Preference hypothesis</head><p>The initial pattern of high cooperation followed by a decline in PGGs was first theorized to be explained by confusion and learning <ref type="bibr">(Confusion Learning Hypothesis;</ref><ref type="bibr">CLH;</ref><ref type="bibr">Gale, Binmore, &amp; Samuelson, 1995;</ref><ref type="bibr">Palfrey &amp; Prisbrey, 1997)</ref>. In the early stages, participants may not fully understand the payoff structure of the social dilemma and cooperate out of confusion. As the game progresses, they learn that it is more beneficial not to cooperate. This explanation assumes that participants are purely self-interested and consider only their own individual gain.</p><p>A social preference explanation later emerged for the cooperation observed in PGGs, suggesting that participants behave rationally but not selfishly (Social Preference; SPH). This explanation assumes that individuals tend to consider not only their own payoffs but also the payoffs of others, a tendency referred to as social preferences <ref type="bibr">(Fehr &amp; Smidt, 1999;</ref><ref type="bibr">Bolton &amp; Ockenfels, 2002)</ref>, social motives <ref type="bibr">(Messick &amp; McClintock, 1968;</ref><ref type="bibr">McClintock,1972)</ref>, or social value orientation <ref type="bibr">(McClintock &amp; Liebrand, 1988;</ref><ref type="bibr">Murphy &amp; Ackerman, 2011)</ref>. As previously mentioned, participants who aim to maximize their own interests in PGGs do not need to adjust their behavior based on others and have no incentive to cooperate. However, conditional cooperation-where participants adjust their behavior to match that of others-has been consistently observed (e.g., <ref type="bibr">Andreoni, 1995;</ref><ref type="bibr">Fischbacher, Gächter &amp; Fehr, 2001;</ref><ref type="bibr">Fischbacher &amp; Gächter, 2010)</ref>. In both studies, using the strategy method, where participants indicated how much they would contribute based on the average contribution of others, <ref type="bibr">Fischbacher et al. (2001)</ref> found that 50% were conditional cooperators and 30% were free riders, while</p><p>Fischbacher &amp; Gächter (2010) reported 55% conditional cooperators and 23% free riders.</p><p>Social preferences have been used to explain not only the emergence of cooperation but also its decline <ref type="bibr">(Dannenberg, Riechmann, Sturm, &amp; Vogt, 2007;</ref><ref type="bibr">Fischbacher, Gächter &amp; Fehr, 2001;</ref><ref type="bibr">Kurzban, McCabe, Smith, &amp; Wilson, 2001</ref>). Many conditional cooperators exhibit a self-interest bias, where they cooperate in proportion to others but contribute slightly less <ref type="bibr">(Fischbacher, Gächter &amp; Fehr, 2001</ref>).</p><p>As a result of free riders and this self-interest bias, overall cooperation rates gradually decline. In contributions while monitoring others' contributions in real time, one where they could both increase and decrease their contributions, and one where neither change was possible. Cooperation was maintained only in the condition where players could only increase their contributions. This result suggests that people avoid cooperating more than others in social dilemma games. Similarly, <ref type="bibr">Dannenberg et al. (2007)</ref> showed that people tend to contribute more when others are cooperative and reduce their contributions when others are not. This suggests that inequality aversion-an aversion to differences in gains between oneself and others <ref type="bibr">(Fehr &amp; Schmidt, 1999</ref>)-motivates conditional cooperation and influences changes in behavior based on others' actions.</p><p>Debate continues on the complex issue of validating and disentangling the disruption and conditional cooperation hypotheses. In an early attempt to address this, Houser &amp; Kurzban <ref type="formula">2002</ref>conducted an experiment with two conditions: the standard PGG and a condition where participants played against a computer instead of a human. Since social preferences are excluded in the computer condition, comparing cooperation between these conditions helps assess whether cooperation is driven by disruption. The results showed that about half of the cooperation, particularly in the early rounds, was due to disruption. It was also concluded that the decline in cooperation could be explained by a reduction in disruption.</p><p>Evidence that cooperation in PGGs is due to confusion, and that the decline in cooperation is driven by the resolution of this confusion, has been presented multiple times in the past decade 'black box' condition (a completely non-social setting where participants were told they were contributing to a 'black box' rather than a group project), alongside standard PGG conditions. They found that cooperation was motivated by the desire to maximize personal interests rather than by social preferences, but participants lacked understanding of how to do so effectively. In their re-analysis, Burton-Chellew et al. (2015) compared three models: one based on self-interest, one accounting for group members' earnings, and one adjusting behavior based on the contributions of others. They found that the model where participants learned to maximize their own earnings was the most plausible, suggesting that the decline in cooperation was driven by learning to optimize personal profit rather than by others' behavior. In a subsequent study using the same group's strategy method <ref type="bibr">(Burton-Chellew, Mouden, &amp; West, 2016)</ref>, conditional cooperators adjusted their behavior in response to a computer opponent as if it were a human. The study also found that participants' behavior changed based on others' choices to maximize personal gain, with no difference in motivation between conditional cooperators and free-riders. This suggests that many conditional cooperators are confused in the sense that, despite the fact that in PGG non-cooperation is the best strategy for maximizing selfinterest regardless of others' actions, they fail to realize this.</p><p>Additionally, the CLH explains the decline in cooperation as the result of participants learning the payoff structure-specifically, that non-cooperation yields higher returns than cooperation. Burton-Chellew and West (2022) analyzed data from 237 public goods games and found that the decline in cooperation was most prominent in situations where the payoff structure was easier to understand.</p><p>Their findings suggest that cooperation decreases as confusion about the payoff structure is resolved, with participants learning that maximizing their own self-interest requires non-cooperation.</p><p>Furthermore, the authors noted that alternative hypotheses did not align with the data, supporting the view that the reduction in cooperation is driven by the resolution of confusion and learning based on payoffs to maximize personal gain.</p><p>Contrasting evidence has recently been presented against the CLH <ref type="bibr">(Wang, Li, Wang, Niu, &amp; Wang, 2024)</ref>. Cooperation was observed even when participants were given a standard 10-question test, provided with the correct answers, and appeared to understand how to maximize their gains in PGGs.</p><p>Additionally, cooperation was significantly higher when participants interacted with a human compared to a computer, both in the strategy method and direct responses. Wang et al. <ref type="formula">2024</ref>concluded that these findings support the view that social preferences, rather than confusion, are the primary drivers of human cooperation. Contrasting evidence has recently been presented against the CLH <ref type="bibr">(Wang, Li, Wang, Niu, &amp; Wang, 2024)</ref>. Cooperation was observed even when participants were given a standard 10-question test, provided with the correct answers, and appeared to understand how to maximize their gains in PGGs. Additionally, cooperation was significantly higher when participants interacted with a human compared to a computer, both in the strategy method and direct responses. Wang et al. (2024) concluded that these findings support the view that social preferences, rather than confusion, are the primary drivers of human cooperation. However, there remains a counterargument from the CLH, suggesting that people may still engage in conditional cooperation even with computers, as they mistakenly perceive the situation as interdependent <ref type="bibr">(Strømland, Koppel, Johannesson, &amp; Tinghög, 2024;</ref><ref type="bibr">Fosgaard, &amp; Wengström, 2024)</ref>.</p><p>Isolating whether confusion or social preferences explain cooperation and its changes in PGGs, and determining the extent to which each contributes, is a crucial question. Participants' behavior in PGGs could inform discussions on policies to sustain cooperation. If confusion is a plausible explanation and individuals are solely self-interested, interventions such as incentives or sanctions might effectively maintain cooperation. However, if social preferences play a role, messages highlighting others' cooperation could be effective-though if the CLH holds, such messages could even have the opposite effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Understanding the CLH and SPH through Payoff Structure Transformation</head><p>To further understand cooperation in social dilemmas, it is helpful to consider the subjective transformation of payoff structures. This approach is rooted in <ref type="bibr">Kelley &amp; Thibaut's (1978)</ref> interdependence theory, which argues that individuals perceive interpersonal interaction situations not through the objective 'given matrix' of payoffs, but rather through a 'subjective matrix.</p><p>They also highlight individual differences in how people transform payoff structures. Building on this idea, <ref type="bibr">Messick &amp; McClintock (1968)</ref> and <ref type="bibr">McClintock (1972)</ref> applied the concept of payoff structure transformation to explain cooperation in social dilemmas. They theorized different patterns of transformation as 'social motivations.' These motivations include prosocial motivation, where individuals prioritize others' payoffs and cooperate; individualistic motivation, where personal gains are prioritized; and competitive motivation, where one aims to reduce others' gains to increase their own. These social motivations later became known as social value orientation (SVO). If individuals subjectively transform the payoff structure by placing weight on others' payoffs, a game that objectively represents a social dilemma-where mutual non-cooperation is the equilibrium-can subjectively be perceived as a game where mutual cooperation is optimal <ref type="bibr">(Van Lange, 1999;</ref><ref type="bibr">Simpson, 2004</ref>).</p><p>The two main hypotheses regarding cooperation and its decline in PGGs-the social preferences hypothesis and the CLH-can be organized and understood through the lens of payoff structure transformation. Both hypotheses explore how individuals transform the objective structure of the PGG into a subjective one, which influences their decisions to cooperate or not.</p><p>The social preferences hypothesis suggests that individuals subjectively transform the payoff structure specifically when interacting with humans, uniquely perceiving interdependence in such interactions. In this view, cooperation arises because individuals place weight on others' outcomes,</p><p>transforming what is objectively a non-cooperative game into one where mutual cooperation is seen as beneficial. This transformation occurs because of social preferences, such as altruistic motivations or concern for equality (Mizuno &amp; Shimizu, 2023), which lead individuals to view their payoffs in relation to others' outcomes only in human interactions.</p><p>In contrast, the CLH posits that this subjective transformation can occur regardless of whether the interaction is with a human or a computer. According to this view, individuals may mistakenly perceive the PGG as an interdependent situation in both human and non-human conditions, leading to cooperation based on a misunderstanding of how to best achieve personal gains.</p><p>To model the subjective transformation of the payoff structure in PGGs, we consider a scenario where players participate in a PGG, and player can choose either to fully contribute their initial endowment (cooperation, ) or to contribute nothing (defection, ). The choice between cooperation and defection is determined by the expected utility, with the player selecting the option that offers the higher expected utility. The expected utility is defined as the probability of receiving a particular payoff multiplied by the magnitude of that payoff. Let represent the expected utility of cooperation and represent the expected utility of defection.</p><p>If utility were determined solely by objective payoffs, the utility for player , when they cooperate ( ) or defect ( ), would be expressed as follows:</p><formula xml:id="formula_0">= ( ) = ( + 1) − (1) = ( ) = (2)</formula><p>Here, represents the MPCR for each player, is the cost of cooperating (the player's initial endowment), and denotes the number of other players ∈ {1, − 1} who choose to cooperate</p><formula xml:id="formula_1">( ∈ {0,1, … , − 1}).</formula><p>The subjective transformation based on interdependence is represented by transforming the PGG payoff structure using the utility function of social value orientation (SVO). To express this transformation, we use the model proposed by Muto <ref type="formula">2006) 1 (Equation 3</ref>, which is defined as:</p><formula xml:id="formula_2">� , � = (1 − ) + − � − � (3)</formula><p>This model incorporates two parameters: altruism ( ), which increases an individual's utility as others' payoffs increase, and equality ( ), which decreases an individual's utility as the difference between their own payoff and others' payoffs grows. The former represents the tendency to prioritize others' outcomes, as suggested by previous SVO research (Ackermann, Fleiß, &amp; Murphy, 2016;</p><p>Mizuno &amp; Shimizu, 2023), while the latter is thought to motivate conditional cooperation <ref type="bibr">(Dannenberg et al., 2007</ref>).</p><p>Here's how you can incorporate the content you want into your writing: To extend the <ref type="bibr">Mutou (2006)</ref> SVO model, which is originally designed for two-player distribution scenarios, to an -player distribution, we express the utility function as:</p><formula xml:id="formula_3">� , � = (1 − ) + 1 − 1 � ≠ − 1 − 1 �� − � ≠<label>(4)</label></formula><p>In this equation, the altruism parameter ( ) and the equality parameter ( ) are applied to the average payoffs of all other players. Substituting the payoffs for cooperation ( ) and defection ( ) into</p><p>1 This model is mathematically equivalent to the well-known social preferences model by <ref type="bibr">Fehr &amp; Schmidt (1999</ref><ref type="bibr">) (Muto, 2009</ref> and is also the basis for the primary SVO measurement tool used to capture individual differences in social preferences <ref type="bibr">(Murphy &amp; Ackerman, 2011;</ref><ref type="bibr">Mizuno &amp; Shimizu, 2023)</ref>. Therefore, it is appropriate to consider that subjective transformations based on interdependence can be represented by this utility function.</p><p>equation <ref type="formula" target="#formula_3">4</ref>, we obtain the utility for cooperation ( ) and defection ( ) as:</p><formula xml:id="formula_4">= (1 − ) ( ) + 1 − 1 � ≠ ( ) − 1 − 1 �� ( ) − ( )� ≠ , = (1 − ) ( ) + 1 − 1 � ≠ ( ) − 1 − 1 �� ( ) − ( )� ≠<label>(7)</label></formula><p>Let ( | ) represent the predicted probability of the number of cooperators from player 's perspective, where ∈ [0,1] is the player's belief in others' likelihood of cooperation. For example, if player estimates others' cooperation probability at 40%, then = 0.4. Assuming independent cooperation, ℎ follows a Bernoulli distribution, and thus:</p><formula xml:id="formula_5">ℎ~B ernoulli( ) i. i. d. , ℎ ∈ {0,1}<label>(8)</label></formula><p>The number of cooperators follows a binomial distribution:</p><formula xml:id="formula_6">~Binomial( − 1, )<label>(9)</label></formula><p>Thus, the expected utilities for cooperation and defection, and , are calculated as:</p><formula xml:id="formula_7">= � ( | ) �(1 − ) ( ) + 1 − 1 � ≠ ( ) − 1 − 1 �� ( ) − ( )� ≠ � ∈{0,1,…, −1} , = � ( | ) �(1 − ) ( ) + 1 − 1 � ≠ ( ) − 1 − 1 �� ( ) − ( )� ≠ � ∈{0,1,…, −1} (10)</formula><p>Next, we apply these expected utilities into the softmax action selection model, which links utility differences to probabilities of choosing cooperation ( ) or defection ( ). In the softmax model, the player's probability of selecting cooperation, ( = ) is given by:</p><formula xml:id="formula_8">( = ) = exp� � exp� � + exp( )<label>(11)</label></formula><p>Where ( ∈ {0,1, … , }) represents the utility of each choice, and is the rationality parameter 2 .</p><p>When there are two options ( ∈ {0,1}), this formula reduces to the sigmoid function:</p><formula xml:id="formula_9">( = ) = 1 1 + exp �− � − �� (12)</formula><p>Thus, the probability of choosing cooperation over defection is based on the difference in expected utilities 3 , and . Substituting for the utility differences:</p><formula xml:id="formula_10">− = � ( | ) ⎣ ⎢ ⎢ ⎢ ⎢ ⎡(1 − ) � ( ) − ( )� + 1 − 1 � � ( ) − ( )� − 1 − 1 �� ( ) − ( )� − � ( ) − ( )� ≠ ⎦ ⎥ ⎥ ⎥ ⎥ ⎤ = � ( | ) ⎣ ⎢ ⎢ ⎢ ⎢ ⎢ ⎡ (1 − ) � ( ) − ( )� + 1 − 1 �� ( ) − � ( ) � − 1 − 1 ��( − 1) ( ) − � ( )� − �( − 1) ( ) − � ( )�� ⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎤<label>(13)</label></formula><p>Finally, using the binomial distribution properties 4 , the expected utility difference simplifies to:</p><formula xml:id="formula_11">− = {( − 1) + − (1 − 2 )} = {( − 1) + + 2 ( − 0.5)} .<label>(14)</label></formula><p>This equation 5 represents the degree to which an individual chooses cooperation over defection.</p><p>Both the MPCR ( ) and altruism ( ) have a positive linear effect on cooperation, while equality ( ) and belief ( ) interact to influence cooperation. Since is a probability between 0 and 1, when a player estimates the probability of others cooperating to be greater than 50%, equality exerts a positive <ref type="bibr">2</ref> The rationality parameter ( ) represents the extent to which choices are made based on utility.</p><p>When = ∞, choices are made entirely according to utility, while = 0 indicates completely random choices.</p><p>3 The sum of the payoffs when player cooperates is given by ∑ ( ) = ( − 1) ( + 1) −</p><p>, and when player defects, it is given by ( ) = ( − 1) − . <ref type="bibr">4</ref> Here, ( | ) is assumed to follow a binomial distribution, Binomial <ref type="figure" target="#fig_1">( | − 1, )</ref>. From the properties of the binomial distribution, ∑ ( | ) = 1, ∑ ( | ) = ( − 1) . 5 Since is a constant, it will not be included in subsequent expressions. effect on cooperation. Conversely, when the estimate is below 50%, equality exerts a negative effect.</p><p>In other words, this model illustrates that: (1) higher MPCR increases the likelihood of cooperation,</p><p>(2) individuals with higher altruism are more likely to cooperate, and (3) individuals with higher equality are more likely to cooperate when they estimate others' cooperation to be above 50%, but less likely to cooperate when the estimate is below 50%.</p><p>Next, the transition (decline) of cooperation is explained by incorporating the mechanism of a reinforcement learning model into the above framework. While there are various types of reinforcement learning models, this study utilizes the basic Q-learning model. By integrating the parameter update mechanism of the Q-learning model into the model expressed in Equation <ref type="formula" target="#formula_11">14</ref>, we can capture how players gradually learn the true value of MPCR through repeated PGGs. Since individual subjective MPCRs may vary, the model for learning r, and its update over time (where is the game period), is expressed.</p><formula xml:id="formula_12">( +1) = + ( − )<label>(15)</label></formula><p>where is the learning rate parameter for the MPCR.</p><p>Additionally, the model incorporates a mechanism to update the player's belief about how many others cooperated based on observed behavior over repeated PGGs. The belief at period + 1 is updated based on the proportion of cooperating players ( ) and the belief from the previous period, expressed as:</p><formula xml:id="formula_13">, +1 = + � − 1 − , �<label>(16)</label></formula><p>where is the learning rate parameter for belief. Thus, the final model derived is:</p><formula xml:id="formula_14">− = �( − 1) + + 2 � , − 0.5�� , +1 = + ( − ), , +1 = + � − 1 − , �<label>(17)</label></formula><p>In this study, we use two methods to examine the roles of altruism, equality, learning about expectations of others' cooperation, and the learning of the payoff structure in both the initial cooperation and the decline of cooperation in public goods games. The first method involves fitting the models to the data and conducting model comparisons across conditions. By applying mathematical models, we aim to capture how subjective transformations of the payoff structure change over time and to distinguish whether altruism and equality influence both human and computer conditions, or just human interactions. In the model comparisons, if the CLH is valid, the model where all estimated parameters are equal across conditions should fit the data better than a model where parameter values differ between conditions. Conversely, if the SPH is valid, the model where parameter values differ between the human and computer conditions should provide a better fit.</p><p>Second, we manipulate the feedback participants receive about others' behavior using a direct response method. In both human and computer conditions, participants receive identical feedback where cooperation gradually declines, isolating the nature of the opponent (human versus computer)</p><p>as the only variable (Experiment 1). In Experiment 2, participants first experience declining cooperation, followed by increasing cooperation. If social preferences play a role, conditional cooperation should only reappear in the human condition. If confusion about the method for maximizing payoffs and its resolution through learning are involved, conditional cooperation would be expected in both conditions.</p><p>In summary, based on the previous discussion, the hypotheses and their predicted outcomes are organized as follows <ref type="table" target="#tab_0">(Table 1)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were 120 students enrolled in a social psychology course at a private university in Japan.</p><p>Of the participants, 34 were male, with a mean age of 19.33 years (SD = 1.72).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>The experiment employed a 2-level between-subjects design with one factor, opponent type (human or computer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questionnaire 1</head><p>Participants completed the General Trust Scale <ref type="bibr">(Yamagishi, 1986)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task to Measure SVO Parameters</head><p>To measure individual altruism and equality parameters, we used the method outlined by Mizuno &amp; Shimizu (2023). Participants chose their preferred option from two choices regarding the distribution of rewards between themselves and others. Based on their responses, individual values for altruism and equality were calculated. After completing the task, one item was randomly selected, and the amount indicated by the participant's choice (converted to one-thousandth of its value) was distributed as a reward to both the participant and another participant in the next experimental session. For participants in the first session, the reward distribution was conducted with participants from the final session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Public Goods Game (PGG)</head><p>Participants were instructed differently based on the condition. In the human condition, participants were told they would be interacting with other participants, whereas in the computer condition, they were told they would be interacting with a computer. The game consisted of 20 periods, but participants were not informed of the exact number of repetitions and were instructed to repeat the game until the task ended. Additionally, the current period number was not displayed.</p><p>In the human condition, participants chose whether to contribute their initial endowment of 20 tokens (virtual currency) to a group or keep it. The total contribution from all four players (including the participant) was multiplied by 1.6 and then distributed equally among the four participants. In the computer condition, participants played a game alone and decided whether to contribute their tokens (Option A) or keep them (Option B), while simultaneously observing three computer-generated slots.</p><p>Participants were told that the total amount contributed by the player and the three slots would be multiplied by 1.6 and divided by four.</p><p>At the end of each period, participants received feedback. In the human condition, the feedback displayed each player's choice, the amount they kept, the amount earned from the distribution, and their total. In the computer condition, the feedback displayed the participant's choice and the outcome of the slots.</p><p>Deception was used in this experiment. In both conditions, the behavior of other participants or the slot outcomes was predetermined, and the same information was shown to all participants. Over time, it appeared to participants that the number of cooperators (or the number of slots showing Option A) was gradually decreasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Four participants were invited to the lab at a time. Human and computer condition sessions were conducted alternately. Sessions without four participants (due to absences) were run under the computer condition. The experimenter left the lab after explaining the tasks and left participants to complete the tasks on their own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-Experiment Explanation</head><p>Participants were seated in partitioned booths in the order they arrived. Each booth contained a computer and a mouse. After participants were seated, the experimenter explained the study and asked participants to sign the consent form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questionnaire 1</head><p>After the explanation, participants answered the General Trust Scale (Yamagishi, 1986) on the computer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task to Measure SVO Parameters</head><p>Once all participants completed the questionnaire, the experimenter explained the next task, displaying instructions on participants' screens and providing verbal explanations. After confirming that participants had no questions, they proceeded with the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Public Goods Game (PGG)</head><p>After confirming that all participants completed the SVO task, the experimenter explained the next task. Instructions varied depending on the condition. In the human condition, participants were asked to estimate the likelihood that other participants would cooperate (0%-100%) using a slider. In the computer condition, participants were asked to estimate the probability that the slot would choose Option A (0%-100%). After all participants completed the estimation, they began the PGG. Unlike Study 3, the PGG was repeated for 20 periods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questionnaire 2</head><p>After the PGG, participants were asked to provide feedback on their experience with the PGG and answer demographic questions (age, gender). They were also asked to estimate how often other participants cooperated (human condition) or how often the slot produced Option A (computer condition) using a slider (0%-100%). Additionally, they were asked to select which scenario they imagined while playing the PGG (cooperation, competition, or interacting with a computer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Debriefing and Compensation</head><p>At the end of the experiment, participants were debriefed, and the deception regarding the PGG was explained. They were asked for consent to use their data after being informed about the deception.</p><p>Participants' rewards from the SVO task and PGG were calculated (1 point = 1 yen) and sent as an Amazon gift card via email.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Histogram of Cooperation in the PGGs</head><p>When examining the histogram of cooperation in the PGGs <ref type="figure" target="#fig_1">(Figure 1</ref>), there is a peak in the distribution at 20 rounds of cooperation. This distribution suggests that among the participants who chose to cooperate in all 20 rounds, there are two distinct patterns: some participants are following the expected model and others are cooperating through a different mechanism. Therefore, to model the probability ( = 1) that player cooperates at time in a PGG with = 20 trials, we assume the following probability model:</p><formula xml:id="formula_15">( = 1) = (1 − ) + Bernoulli( | ) if � =1 = 20 ( = 1) = Bernoulli( | ) if � =1 ≠ 20</formula><p>Here, represents the number of cooperative choices, and (1 − ) represents the proportion of participants who always choose cooperation regardless of the model's predictions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Comparison</head><p>For the analysis, we fitted both a Fix model, where parameter values were assumed to be the same across conditions (human and computer), and a Free model, where parameter values were allowed to differ between conditions. The parameter was set to 1 for both models. MCMC estimation was conducted using Stan for each condition. The MCMC settings were as follows: 10,000 samples, a burn-in period of 1,000, and 4 Markov chains. The prior distributions for each parameter were as follows. No individual differences were assumed for any of the parameters.  for the Free model. We calculated the Bayes factor for the Fix and Free models. The result, , = 0.07, indicated that the Fix model provided a better fit ( &lt; 0.1). The parameters for the models are shown in <ref type="table">Table 2 and Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 2</head><p>In Study 2, participants will engage in a 40-period repeated PGG, with different feedback provided in the first and second halves. For the first 20 periods, as in Study 1, participants will receive feedback indicating that the cooperation rates of other players are gradually decreasing. In the subsequent 20 periods, the feedback will show that cooperation rates are gradually increasing.</p><p>The experimental conditions will mirror those of Study 1, with a human condition and a computer condition. In both conditions, we will analyze the changes in cooperation rates over time and perform model comparisons using information criteria to evaluate the fit of the different models across conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>A total of 137 participants were recruited from a social psychology course. For the analysis, 120</p><p>participants were included, after excluding 15 participants who reported technical difficulties or confusion during the experiment, and 1 participant who did not consent to the use of their data. Of the 120 participants, 34 were male, with a mean age of 19.29 years (SD = 1.03).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>The study employed a between-subjects design with one factor, opponent type (human versus computer), across two conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task to Measure SVO Parameters</head><p>The task for measuring SVO parameters was identical to the one used in Study 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Public Goods Game (PGG)</head><p>The task and display screens were the same as in Study 1, with one key difference in feedback. For the first 20 periods, feedback identical to that in Study 1 was provided. From the 21st period onward, however, feedback was manipulated to show a gradual increase in the cooperation rate (or the number of slots producing Option A in the computer condition).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>As in Study 1, four participants were called into the laboratory at a time. The human and computer condition sessions were conducted in alternating order. In cases where fewer than four participants were present due to absences, the computer condition was used. This procedure was consistent with that of Study 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-Experiment Explanation</head><p>Before the experiment, each participant was individually invited into a private Zoom chat room, and their name was anonymized by the experimenter to prevent others from seeing it. Participants were instructed to turn off their microphone and video during the experiment. For those with profile pictures containing human faces or animals (i.e., eyes), a request was made to temporarily change their image to a neutral one, to prevent any potential influence of being "watched" <ref type="bibr">(Haley &amp; Fessler, 2005)</ref>. After this, all participants were brought into the main Zoom room, where the experimenter explained the procedure and asked them to fill out an online consent form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questionnaire 1</head><p>Participants first answered the General Trust Scale <ref type="bibr">(Yamagishi, 1986)</ref> and the Personal and Social</p><p>Orientation Scale (Ito, 1993) via the computer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task to Measure SVO Parameters</head><p>Once all participants completed the questionnaire, the experimenter provided instructions for the SVO task. The procedure for this task was identical to that used in Study 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Public Goods Game (PGG)</head><p>After confirming that all participants had completed the SVO task, the experimenter explained the PGG task. The instructions varied by condition. After the explanation, participants were asked to estimate how likely others would be to cooperate (human condition) or how likely the slots would produce Option A (computer condition), using a slider ranging from 0% to 100%. Once all participants completed their estimates, they proceeded to the PGG, which, unlike Study 1, was repeated for 40 periods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questionnaire 2</head><p>After the PGG task, participants were asked for their impressions of the game, along with demographic information (age and gender). They also used a slider to estimate how likely others were to have cooperated (human condition) or how often the slots produced Option A (computer condition) during the PGG. Additionally, they were asked which scenario they imagined while playing the PGG (cooperation, business, or competition). These procedures were the same as in Study 2.</p><p>At the end of the experiment, participants were debriefed on the purpose of the study, and the deception used in the PGG task was explained. Participants were asked for their consent to use the data after learning about the deception, and they were asked to fill out an online consent form. The payment was calculated based on the points earned in the SVO and PGG tasks (1 point = 0.5 yen) and was sent to participants as an Amazon gift card via email.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As in Study 1, we assumed that among the participants who chose to cooperate in every period, some followed the expected model, while others cooperated based on a different mechanism. The MCMC settings and prior distributions for the parameters were identical to those used in Study 1.  <ref type="table">Table 2 and Table 3</ref>. <ref type="table">Table 2</ref> Parameters of the free model (Study 2) <ref type="table">Table 3</ref> Parameters of the free model (Study 2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this study, we examined the decline in cooperation in public goods games (PGGs) from the initial stages of cooperation. Our goal was to explore the ongoing debate between the Social Preferences Hypothesis (SPH) and the Confusion Learning Hypothesis (CLH) by deriving decision-making models based on the subjective transformation of the payoff structure in PGGs. The SPH posits that individuals transform their payoffs based on social preferences, such as altruism and equality, which results in cooperation specifically when interacting with humans. On the other hand, the CLH suggests that individuals misunderstand the game's payoff structure, resulting in confusion, which could explain cooperation and its decline irrespective of whether they are interacting with humans or computers. To investigate this, we employed two complementary approaches. First, we derived decision-making models that encapsulate how individuals decide whether to cooperate or defect in PGGs and tested their fit with empirical data. Second, we manipulated the feedback participants received about the behavior of others (or the outcomes of a slot machine in the computer condition) to determine which hypothesis better explains both initial cooperation and the eventual decline. This feedback manipulation followed a design similar to that employed in earlier studies (e.g., <ref type="bibr">Burton-Chellew &amp; West, 2013;</ref><ref type="bibr">Burton-Chellew, Mouden, &amp; West, 2016)</ref>, but with added rigor in distinguishing between human and computer interactions. In Study 1, we found moderate evidence supporting the CLH. Specifically, the Fix model, which assumes that parameter values are equivalent across both the human and computer conditions, provided a significantly better fit to the data compared to models that allowed for different parameter estimates in each condition. This finding suggests that participants were similarly confused about the payoff structure in both conditions, leading to comparable patterns of behavior regardless of whether they interacted with humans or computers. However, Study 2 produced a contrasting result. In this study, participants first experienced declining cooperation from others (or from the slot machine in the computer condition) before receiving feedback indicating that cooperation rates were rising.</p><p>Interestingly, under these circumstances, conditional cooperation re-emerged-but only in the human condition. Participants showed no such response in the computer condition, strongly supporting the SPH. The Free model, which assumes different parameter values between conditions, provided a better fit in this case. This divergence between Studies 1 and 2 highlights a critical point: natural human behavior may obscure differences between models unless an experimental manipulation, such as the recovery of cooperation, is introduced, allowing for the detection of latent differences in behavior between human and non-human conditions.</p><p>A key contribution of this study lies in how it reframes the debate between SPH and CLH through the common framework of subjective transformations of the payoff structure. Prior studies have not provided a formal mathematical foundation for either hypothesis, leaving key differences between them somewhat vague. In contrast, this study explicitly formalized the subjective transformation of objective payoffs into an interdependent structure using a utility function that incorporates concern for others' outcomes. This allows for a more precise comparison of the two hypotheses by focusing on whether social preferences are activated specifically in human interactions (SPH) or whether confusion about the payoff structure affects behavior equally in both human and computer conditions (CLH). By organizing the debate around this central question-whether interdependence is specific to human interactions or applies more broadly-this study provides a clearer framework for testing the validity of these competing hypotheses using model comparisons.</p><p>In addition to introducing this mathematical formalization, this study also employed a novel experimental approach by manipulating the feedback participants received about the behavior of others. This manipulation was crucial in distinguishing between SPH and CLH because it allowed us to directly observe how participants' expectations and behaviors changed in response to identical feedback across both human and computer conditions. This feedback manipulation, combined with the nature of the opponent (human vs. computer), created a unique experimental design not commonly found in previous research. As a result, this study offers new insights into the mechanisms that underlie cooperation in social dilemmas. For instance, the results from Study 2, in which conditional cooperation re-emerged only in the human condition, cast doubt on the validity of CLH. However, the mixed results from Study 1, where the Fix model performed better, suggest that further investigation is needed to fully disentangle the roles of confusion and social preferences in shaping cooperative behavior.</p><p>One limitation of this study is the possibility that the feedback showing a recovery in cooperation may have seemed somewhat artificial to participants, especially in the computer condition. While this feedback was necessary to create the experimental manipulation, it may not have fully reflected natural human interactions. However, it is worth noting that previous research on related social dilemma games, such as the repeated Prisoner's Dilemma, has documented similar patterns of cooperation recovery after prolonged rounds of defection. For example, <ref type="bibr">Rapoport and Chammah (1965)</ref> found that cooperation increased between rounds 30 and 60 in a repeated Prisoner's Dilemma game, suggesting that such a recovery in cooperation is not entirely unrealistic. This provides some reassurance that the feedback manipulation used in this study, while somewhat artificial, is grounded in established experimental findings.</p><p>Beyond its theoretical contributions, this study also proposes a decision-making model that captures how individuals make cooperation choices in PGGs. One of the key implications of this model is that individuals' expectations about others' cooperation play a crucial role in shaping their own behavior.</p><p>Specifically, when individuals believe that more than 50% of others will cooperate, their aversion to inequality promotes cooperation; however, when their expectations fall below 50%, this aversion works against cooperation, leading them to defect. Moreover, Study 2 showed that even when participants had learned that non-cooperation maximizes self-interest (as in the CLH), they continued to cooperate if they believed others would also cooperate. This suggests that fostering confidence in others' cooperation may be a critical mechanism for sustaining cooperation, even in the face of conflicting incentives.</p><p>While this study goes beyond merely evaluating the validity of SPH and CLH, the decision-making model it proposes also provides a valuable tool for understanding decision-making mechanisms in social dilemmas and sustaining cooperation. The model represents individual decision-making mechanisms in repeated social dilemma games in a mathematically rigorous and theoretically interpretable manner. This makes it a useful foundation for future research. Previous studies have</p><p>shown that mechanisms such as punishment systems for non-cooperators <ref type="bibr">(Fehr &amp; Gächter, 2000;</ref><ref type="bibr">Yamagishi, 1986)</ref> and opportunities for communication <ref type="bibr">(Kerr &amp; Kaufman-Gilliland, 1994</ref>) can promote mutual cooperation. By combining experimental manipulations with model-based analyses of parameter changes, future research can investigate which specific elements of these mechanisms are most effective in maintaining cooperation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>Burton-Chellew &amp; D'Amico, 2021; Burton-Chellew, Nax, &amp; West, 2015; Burton-Chellew &amp; West, 2013, 2021; Burton-Chellew, Mouden, &amp; West, 2016). Burton-Chellew &amp; West (2013) introduced a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Histogram of the number of cooperations (Study 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>shows the cooperation rate transitions for each condition, as well as the posterior predictive checks for the model. The light gray dashed line in the figure represents the average cooperation rate (or the average rate of Option A appearing) of the three other players (or three slots), as fed back to the participants during the experiment. The black dashed line represents the actual data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Trends in cooperation rates for each condition and post-prediction checks of the modesThe negative log marginal likelihoods of each model were 1443.27 for the Fix model and 1445.90</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3</head><label>3</label><figDesc>shows the cooperation rate transitions for each condition, as well as the posterior predictive checks for the model. The light gray dashed line in the figure represents the average cooperation rate (or the average rate of Option A appearing) of the three other players (or three slots), as fed back to the participants during the experiment. The black dashed line represents the actual data. The negative log marginal likelihoods of each model were 2948.08 for the Fix model and 2874.94 for the Free model. As in Study 1, we calculated the Bayes factor for the Fix and Free models. The result, , = 5.84 * 10 31 , indicated that the Free model provided a better fit ( &gt; 10). The parameters for the models are shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 Predicted Model Fit and Response to Others' Actions Based on Hypotheses Study 1</head><label>1</label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
