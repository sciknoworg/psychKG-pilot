<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Flexibility of Evidence-Accumulation Models under Practical Constraints</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Jones</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Colorado Boulder</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology and Neuroscience</orgName>
								<orgName type="institution">University of Colorado</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Flexibility of Evidence-Accumulation Models under Practical Constraints</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Choice response time</term>
					<term>evidence-accumulation models</term>
					<term>diffusion model</term>
					<term>model complexity</term>
					<term>model mimicry</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Evidence-accumulation models, including the diffusion model (DM) and linear ballistic accumulator (LBA), have been highly influential in modeling speeded decision making. Recent mathematical results prove these models become unfalsifiable when one removes technical assumptions about the distributions governing intertrial variability in growth rates (Jones &amp; Dzhafarov, 2014a). These results also require removal of a particular selective influence assumption (termed SI2), which holds that growth-rate distributions are unaffected by manipulations of preparatory processes such as speed-accuracy tradeoff. The result for the DM also requires that the contribution of diffusion can be arbitrarily small. Although these two allowances are logically and theoretically defensible-SI2 has weak theoretical motivation and has been abandoned in several recent applications to empirical data, and the DM has never specified a lower bound on the contribution of diffusion-it is nonetheless useful to determine how flexible the models are with SI2 retained and with a lower bound on the contribution of diffusion, as well as with qualitative restrictions on the complexity of the growth-rate distributions. The present paper addresses this question by focusing on startpoint variability, a theoretical assumption that has been held as essential to fitting data. It reports three results demonstrating that growth-rate variability is flexible enough to mimic the effects of startpoint variability, even under the constraints of SI2, a lower bound on diffusion, and unimodal growth-rate distributions. First, analytical derivations show that the standard LBA is formally equivalent to a generalized LBA with no startpoint variability, using unimodal growth-rate distributions that adhere to SI2. Second, the same is shown to hold for the DM in the limit of negligible diffusion. Third, simulations with real data that this mimicry problem arises even with large levels of diffusion: The standard DM can be closely mimicked by a generalized DM with no startpoint variability, unimodal growth-rate distributions obeying SI2, and diffusion as strong as in the original model. In conclusion, these three restrictions still leave the models excessively flexible, in that the theoretical question of startpoint variability remains unidentifiable.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Mathematical models based on evidence accumulation have had enormous empirical success in explaining data from human decision making, including response probabilities, response times (RTs), and numerous experimental and individual-difference variables that influence these two measures (e.g., <ref type="bibr" target="#b24">Ratcliff &amp; Smith, 2004)</ref>. This paper focuses on the two currently most influential members of this model family, the diffusion model (DM; <ref type="bibr" target="#b20">Ratcliff, 1978)</ref> and the linear ballistic accumulator (LBA; <ref type="bibr" target="#b1">Brown &amp; Heathcote, 2008)</ref>. The DM assumes a single accumulation process evolving stochastically between upper and lower decision boundaries, whereas the LBA assumes a separate process for each response, which grows linearly and deterministically. The response is determined by which threshold is crossed first or which process crosses its threshold first, and the RT is determined by the time to reach that threshold, plus some nondecision time (see below for formal model specifications).</p><p>The explanatory value of these models has recently been called into question, by mathematical results showing that their theoretical underpinnings are excessively flexible <ref type="bibr" target="#b11">(Jones &amp; Dzhafarov, 2014a)</ref>. In order to fit data (specifically, the relative average speeds of correct and error responses), the LBA and DM assume random variability across trials both in the growth rates of the accumulation processes and in their starting points. This intertrial variability turns out to make the models unfalsifiable (i.e., they can fit any possible pattern of data) if two assumptions are removed. The first assumption is a purely technical one that has traditionally been made for mathematical convenience, that the distribution of growth rates across trials is Gaussian. The second assumption is one of selective influence, termed SI2 because it is the second of three selective influence assumptions made by the models. SI2 holds that growth-rate distributions are unaffected by manipulations of the subject's cognitive state prior to stimulus onset, such as speed-accuracy instructions or base rates, which are assumed to affect only preparatory processes of setting thresholds and starting points. Jones and Dzhafarov defined generalized versions of the models (gDM and gLBA) that are identical to the original models except for removal of these two assumptions, and proved mathematically that the generalized models are unfalsifiable. Therefore the empirical success of the standard DM and LBA is fully dependent on the Gaussian growth and SI2 assumptions, and the remainder of the models' architectural and processing assumptions-generally regarded as embodying a rich framework of theoretical commitments-taken together make no behavioral predictions whatsoever.</p><p>Although the mathematical correctness of Jones and Dzhafarov's (2014a) results has not been challenged, <ref type="bibr" target="#b27">Smith, Ratcliff, and McKoon (2014)</ref> have argued that the proof relies on versions (i.e., parameterizations) of the DM that are unlike those that have arisen in applications to empirical data. In particular, they argue that diffusion is integral to the model, whereas the unfalsifiability proof relies on allowing diffusion to be negligible (e.g., allowing the diffusion rate to be arbitrarily close to zero). They also argue that SI2 is a valuable default assumption, even if it does not always hold, and that growth-rate distributions should not be allowed be too complicated, even if they are not constrained to be Gaussian. Jones and Dzhafarov (2014b) provided detailed responses to these arguments, including theoretical and empirical challenges to SI2, difficulty with objectively defining simplicity requirements because of their dependence on how one chooses to parameterize the model, and the logical incoherence of declaring a successful fit of a model with one of its components (viz., diffusion) nullified to be a failure of the model as a whole. Nevertheless, it is an interesting and potentially important question whether the excessive flexibility identified by Jones and Dzhafarov (2014a) remains if the LBA and DM retain SI2 and assume some qualitative restrictions on the forms of growth-rate distributions, and if the DM is constrained to have some (to be specified) minimal contribution of diffusion. <ref type="bibr" target="#b0">1</ref> That is the general question addressed in the present paper.</p><p>It is easy to show that SI2 makes both models falsifiable, as does a lower bound on diffusion for the DM. Thus the strong version of the previous results would not hold under these constraints. Still, it is quite possible for a model that is in principle falsifiable to be so flexible that it is of little use when applied to real data. For example, if one is interested in some theoretical question, and the model can fit data in one way that yields an affirmative answer to that question and in another way that yields a negative answer, then the model's flexibility is impeding its diagnostic value.</p><p>This paper pursues this line of reasoning for the theoretical question of startpoint variability. This assumption has been held as theoretically essential to the DM and LBA, based on claims that the models cannot fit certain empirically observed patterns without it (Rouder &amp; <ref type="bibr" target="#b22">Ratcliff, 1998;</ref><ref type="bibr" target="#b25">Ratcliff, Van Zandt, &amp; McKoon, 1999</ref>).</p><p>This may be true for the conventional versions of the models, but the unfalsifiability theorems show that it is not true if the Gaussian-growth and SI2 assumptions are removed. That is, the generalized models (gDM and gLBA) can fit any data perfectly without startpoint variability. The question addressed in the present paper concerns the intermediate case, where growth-rate distributions are not completely free but are not held to being Gaussian. Specifically, this paper considers the case where the technical Gaussian growth assumption is relaxed to one of unimodality, SI2 is retained, and (for the DM) diffusion is bounded from below. If the generalized models can still fit data without startpoint variability under these three constraints, then these constraints are insufficient to rescue the models from the problems of excessive flexibility.</p><p>Thus the specific question of this paper is this: Does growth-rate variability contribute so much flexibility that it can mimic the effects of other mechanisms, specifically startpoint variability, even with the constraints of unimodal growth-rate distributions, SI2, and bounded diffusion? This paper reports three results support-</p><p>ing an affirmative answer. First, the standard LBA (with startpoint variability) is analytically translated into an exactly equivalent gLBA model with no startpoint variability by changing the growth-rate distributions. The new growth-rate distributions are provably unimodal under any parameter values of the original model, and if the original model obeys SI2 then the new model will also. Therefore the gLBA with SI2 and unimodal growth-rate distributions can fit any data without startpoint variability as well as the standard model can with startpoint variability. Second, the same result is found with the diffusion model in the limit of negligible diffusion:</p><p>For any standard DM obeying SI2 and having a diffusion rate close to zero, there is an equivalent gDM that also obeys SI2, has unimodal growth-rate distributions, and has no startpoint variability. Both of these first two results are predicated on the assumption that the range of startpoint variability in the standard models varies across experimental conditions in proportion to the threshold, an assumption that has fit empirical data as well as have variants of the models in which the range is constant. Third, it is demonstrated by example with a real dataset (from Wagenmakers et al., 2008) that the identifiability problem persists when a lower bound is imposed on the diffusion rate. Specifically, the standard DM as fit to these data can be closely mimicked by a gDM that has no startpoint variability, obeys SI2, has unimodal growth-rate distributions, and has just as strong a contribution of diffusion as in the original model. The Wagenmakers et al. dataset exhibits the distinctive "crossover" pattern between correct and error RTs (defined below), which has been held as the definitive evidence for startpoint variability, and thus the present results demonstrate how this evidence is undermined once one recognizes the arbitrariness of the Gaussian growth assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>Before reporting the new results of this paper, this section introduces notation for the tasks and data structures under consideration, formally defines the standard LBA and DM as well as the gLBA and gDM, and summarizes the unfalsifiability theorems of Jones and Dzhafarov (2014a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II.1. Tasks and Data</head><p>The tasks considered in this paper involve speeded choices between two response options. As some examples, the subject could be asked to report whether a visual stimulus is in either of two locations, whether an auditory stimulus is present or not, whether a letter string is a word or a nonword, or whether an item was or was not on a previously studied list. The results reported here for the LBA apply also to tasks with any number of response options, but the DM's architecture limits it to binary choices. The possible responses on each trial are denoted by r ∈ {1, 2}, and values of RT by t. Variations in the stimulus, including properties that determine the correct answer and those that do not (e.g., brightness, lexical frequency) are indexed by s. Other experimental factors that are manipulated prior to stimulus onset (e.g., Assuming that G s,c (r, t) is differentiable in t, one can also define the (joint) R&amp;T density function,</p><formula xml:id="formula_0">g s,c (r, t) = dG s,c (r, t) dt .<label>(2)</label></formula><p>The family of R&amp;T distributions (or densities) as indexed by stimulus and condition constitutes the data for any subject in any binary speeded decision task, and likewise the predictions for any model. If two models predict exactly the same R&amp;T distributions then they are equivalent and indistinguishable, at least insofar as behavior data are concerned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II.2. Models</head><p>The LBA model is defined by a set of linear ballistic accumulators, one for each response, racing to a common threshold <ref type="bibr" target="#b1">(Brown &amp; Heathcote, 2008</ref> </p><formula xml:id="formula_1">R s,c r (t) = z c r + k s r t.<label>(3)</label></formula><p>Here z c r = R s,c r (0) is the starting point and k s r is the slope or growth rate. As the superscripts indicate, the starting point can depend on condition but not on stimulus, and the growth rate can depend on the stimulus but not on condition, embodying the selective-influence assumptions explained below. The threshold for all responses is denoted b c , which can depend on condition but not on the stimulus.</p><p>Stochasticity in the LBA arises from intertrial variability in the growth rates and starting points. The growth rate for any response for any stimulus is assumed to vary randomly according to a Gaussian distribution,</p><formula xml:id="formula_2">k s r ∼ N v s r , η 2 ,<label>(4)</label></formula><p>where v s r is the mean growth rate (responses with greater values of v s r are more likely to occur, and to occur with shorter RTs) and η governs the variability in growth rates for all responses, stimuli, and conditions. The starting point for any response in any condition is assumed to vary randomly according to a uniform distribution,</p><formula xml:id="formula_3">z c r ∼ U (0, A c )<label>(5)</label></formula><p>with 0 ≤ A c ≤ b c . On each trial, the growth rates and starting points for all responses are sampled independently from the above distributions.</p><p>As a race model, the LBA's predictions are based on how long it takes each accumulator to reach the threshold. Therefore, define the completion time (or firstpassage time) of each accumulator by</p><formula xml:id="formula_4">T s,c r = arg min t (R s,c r (t) ≥ b c ) = b c − z c r k s r .<label>(6)</label></formula><p>Note that, on any trial, the first-passage times for the different responses are mutually independent random variables, because their sources of stochasticity (starting points and growth rates) are assumed to be sampled independently. The model's response Nondecision time corresponds to the winning accumulator (i.e., with the shortest completion time), response = arg min</p><formula xml:id="formula_5">r (T s,c r ) ,<label>(7)</label></formula><p>and the RT equals the winning completion time plus a nondecision time, t 0 :</p><formula xml:id="formula_6">RT = min r (T s,c r ) + t 0 = T s,c response + t 0 .<label>(8)</label></formula><p>Note that the LBA's predictions depend entirely on the distributions of first-passage times, together with the nondecision time. Any other model based on a race of stochastically independent processes for which the first-passage distributions and the nondecision time are the same as the LBA's will generate identical predictions. <ref type="table" target="#tab_0">Table I</ref> summarizes the LBA's parameters.</p><p>The DM is defined by a single accumulation process, bounded by upper and lower thresholds corresponding to the two possible responses <ref type="bibr" target="#b20">(Ratcliff, 1978</ref>; see also <ref type="bibr" target="#b15">Laming, 1968;</ref><ref type="bibr" target="#b31">Stone, 1960)</ref>. In the Wiener diffusion model, the process evolves according to a stochastic differential equation that defines a Wiener drift-diffusion process:</p><formula xml:id="formula_7">dR s,c (t) = k s dt + σdB(t).<label>(9)</label></formula><p>Here k s is the drift (or growth) rate, σ is the diffusion rate, and B(t) represents a Brownian motion process. Closely related to the Wiener DM is the Ornstein-Uhlenbeck model, which assumes an additional decay component to the drift (Busemeyer &amp; <ref type="bibr" target="#b2">Townsend, 1993)</ref>. Following <ref type="bibr" target="#b24">Ratcliff and Smith (2004)</ref>, the Ornstein-Uhlenbeck model is treated here as a generalization of the Wiener model, with decay toward the process's starting point, z c = R s,c (0), governed by a decay parameter</p><formula xml:id="formula_8">β &gt; 0: dR s,c (t) = (k s + β (z c − R s,c (t))) dt + σdB(t).<label>(10)</label></formula><p>In what follows, DM refers to both the Wiener model (i.e., with β = 0) and the Ornstein-Uhlenbeck model, unless otherwise specified. The thresholds for responses 1 and 2 are respectively defined as 0 and a c . Whichever threshold is crossed first determines the response, and the RT equals the associated first-passage time plus a nondecision time (t 0 ).</p><p>Like the LBA, the DM assumes the growth rate for each stimulus varies randomly across trials according to a Gaussian distribution,</p><formula xml:id="formula_9">k s ∼ N v s , η 2 ,<label>(11)</label></formula><p>and the starting point varies according to a uniform distribution:</p><formula xml:id="formula_10">z c ∼ U z c − 1 2 δ c z ,z c + 1 2 δ c z .<label>(12)</label></formula><p>The mean of the latter distribution determines the response bias (e.g.,z c &lt; a c /2 implies bias toward response 1) and is constrained to satisfy 0 &lt;z c &lt; a c , and the range is constrained to satisfy δ c z ≤ min {2z c , 2 (a c −z c )}. Additionally, the DM assumes random variability in the nondecision time, following a uniform distribution  </p><formula xml:id="formula_11">t 0 ∼ U T er − 1 2 δ t , T er + 1 2 δ t .<label>(13)</label></formula><p>Table II summarizes the parameters of the DM.  For a DM with no growth-rate or startpoint variability (η = δ c z = 0) and no response bias (z c = a c /2), the predicted conditional RT distributions (and hence any summary statistics thereof, such as the mean) are provably identical for both responses (Laming, 1968). Introducing response bias can speed one response over another (e.g., so that mean "word" responses are faster than mean "nonword" responses), but it cannot account for empirical patterns wherein mean error RTs are faster than mean correct RTs (or vice versa) regardless of which response is correct.</p><p>Intertrial variability in growth rate breaks the symmetry between correct and error RT distributions, because errors are more likely on trials with lower growth rates, and lower growth rates make RT slower for both responses. The combination of these two effects produces an analogue of Simpson's paradox: Even though any single growth rate yields correct and error responses of equal mean duration, once growth rate is marginalized out (i.e., by averaging over all trials), errors show longer mean RT than correct responses <ref type="bibr" target="#b20">(Ratcliff, 1978)</ref>. Intertrial variability in the starting point produces an opposite effect: Errors are more likely on trials for which the starting point is closer to the incorrect response's threshold, and on such trials the mean error RT is faster than the mean correct RT <ref type="bibr" target="#b15">(Laming, 1968)</ref>. Therefore startpoint variability produces a pattern in which mean error RT is faster than mean correct RT. The same reasoning applies for the LBA; additionally, intertrial variability is the only source of stochasticity in that model (without it, the model would produce the same response and RT every time the same stimulus was presented). <ref type="bibr" target="#b1">2</ref> Thus intertrial variability in growth rates and in starting points produces opposite effects on the difference in mean RT between correct and error responses. Moreover, the relative contribution of these two mechanisms depends on speed-accuracy tradeoff. In conditions emphasizing speed, the models assume the thresholds will be lower, which leads to a greater influence of startpoint variability and hence relatively fast errors. In conditions emphasizing accuracy, the models assume thresholds will be larger, leading to a greater influence of growth-rate variability and hence relatively slow errors. This interaction-faster errors under speed conditions and faster correct responses under accuracy conditions-has been termed the crossover effect and has been observed in numerous experiments (e.g., <ref type="bibr" target="#b16">Luce, 1986;</ref><ref type="bibr" target="#b22">Ratcliff &amp; Rouder, 1998</ref><ref type="bibr" target="#b25">Ratcliff et al., 1999;</ref><ref type="bibr" target="#b28">Smith &amp; Vickers, 1988;</ref><ref type="bibr" target="#b32">Swensson, 1972;</ref><ref type="bibr" target="#b40">Wagenmakers et al., 2008</ref>).</p><p>The crossover effect has been held up as the primary evidence for the necessity of both growth-rate and startpoint variability. Indeed, <ref type="bibr" target="#b24">Ratcliff and Smith (2004, p.</ref> 338) claim that "The [diffusion] model cannot predict a crossover pattern such that errors are slower than correct responses in high-accuracy conditions and faster in low- <ref type="bibr" target="#b1">2</ref> Intertrial variability in nondecision time was introduced to the DM to fit the leading edge of empirical RT distributions (i.e., the shortest time at which appreciable numbers of responses are observed). <ref type="bibr">Ratcliff and Tuerlinckx (2002)</ref> found that the shape of the DM's RT distribution is mostly unaffected by nondecision variability, except at the leading edge: nondecision variability increases differences in the leading edge across conditions, and it makes the leading edge less abrupt than it would otherwise be. The latter property was argued to be important for fitting lexical decision data in <ref type="bibr">Ratcliff, Gómez, and McKoon (2004)</ref>. Nondecision variability is inessential to the present work, because if a gDM without nondecision variability is equivalent to (or closely mimics) a DM without nondecision variability, then adding an equal amount of nondecision variability to both models will preserve their equivalence.</p><p>accuracy conditions with only drift rate varying." This statement might be correct for the standard models, with Gaussian growth-rate distributions, but the unfalsifiability theorems summarized next imply it does not hold when growth-rate variability is unconstrained. Moreover, the mathematical forms of the intertrial distributions   </p><formula xml:id="formula_12">, A c , v</formula><formula xml:id="formula_13">p T s,c r (t) = 1 A c v s r Φ b c − tv s r tη − v s r Φ b c − A c − tv s r tη −ηφ b c − tv s r tη + ηφ b c − A c − tv s r tη .<label>(14)</label></formula><p>Here p T s,c r (t) for t &gt; 0 indicates the probability density function for T s,c r , and Φ and φ respectively denote the cumulative distribution and density functions of the standard Gaussian.</p><p>For the equivalent gLBA with no startpoint variability, the first-passage time is related to the growth rate by T s,c r = b c /k s,c r . Therefore the density for the growth-rate distribution that reproduces Equation 14 is given by  Growth Rate . Within each set, the ratio of the range of startpoint variability to the value of the threshold (A c /b c ) in the LBA varies from 0 to 1 in increments of .25. When this ratio equals zero, the gLBA's growth-rate distribution is the same as the original LBA's (most peaked curve in each set). As startpoint variability in the LBA increases, the gLBA's growth-rate distributions become progressively broader and more skewed. All curves assume the standard deviation of growth rates in the LBA (η) equals unity; changing this value would have no effect on the graph except on the scaling of the abscissa. The resulting probability density function is</p><formula xml:id="formula_14">p k s,c r (k) = dT s,c r dk s,c r k s,c r =k • p T s,c r b c k = b c A c k 2 v s r Φ k − v s r η − v s r Φ k − v s r η − A c k b c η −ηφ k − v s r η + ηφ k − v s r η − A c k b c η .<label>(15)</label></formula><formula xml:id="formula_15">Density v/η = 0 v/η = 2 v/η = 4 v/η = 6</formula><formula xml:id="formula_16">p k s,c (k) = a c 2δ c z k 2 v s Φ a c k + δ c z k − a c v s a c η − v s Φ a c k − δ c z k − a c v s a c η +ηφ a c k − δ c z k − a c v s a c η − ηφ a c k + δ c z k − a c v s a c η .<label>(16)</label></formula><p>Remarkably, this growth-rate distribution is independent of the decay rate, β, and therefore is the same for the Wiener and Ornstein-Uhlenbeck models. In fact, Appendix B proves that this same growth-rate distribution results regardless of the shape of the accumulation process (e.g., linear for the Wiener model, exponential for  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III.3. Eliminating Startpoint Variability with Nonzero Diffusion</head><p>The results presented thus far, as well as the unfalsifiability proofs in Jones and Dzhafarov (2014a), rely on a one-to-one correspondence between growth rates in the Within each set, the ratio of the range of startpoint variability to threshold separation in the DM (δ c z /a c ) varies from 0 to 1 in increments of .25. When this ratio equals zero, the gDM's growth-rate distribution is the same as the original DM's (most peaked curve in each set). The graph assumes the standard deviation of growth rates in the DM (η) equals unity; changing this value would have no effect except to rescale the abscissa.</p><p>generalized models and predictions for response and RT. This correspondence enables one to start with any R&amp;T distribution (or first-passage distribution) and to directly derive a growth-rate distribution that will generate it. However, a model with a positive diffusion rate cannot be inverted in this way, because a given growth rate can result in an infinity of outcomes via the within-trial variability of the diffusion process.</p><p>In fact, Ratcliff (2013) claims the diffusion process "washes out" any influence of the shapes of the growth-rate and startpoint distributions, so that choices of shape  <ref type="table" target="#tab_0">Table III</ref>).</p><p>Fitting the gDM to match the predictions of the DM proceeded as follows (see Appendix C for further details). First, for each response, stimulus category, and instruction condition, the DM's predictions were derived for the response probability, the first five moments of the conditional RT distribution (E [RT m |response = r] for m = 1 . . . 5), and the .1, .3, .5, .7, and .9 RT quantiles. The parameters of the gDM were then fit to minimize the sum of squared deviations between models for the moments and for the cumulative probabilities of the quantiles (i.e., G (r, t) where t is any of the DM's quantiles). Following <ref type="bibr" target="#b24">Ratcliff and Smith (2004)</ref> and <ref type="bibr" target="#b40">Wagenmakers et al. (2008)</ref>, the gDM's a c andz c parameters were allowed to vary between instruction conditions (but with δ c z = 0), holding all other parameters equal between conditions. For simplicity, T er and δ t were held equal to their values in the DM. Critically, the   <ref type="bibr" target="#b24">Ratcliff and Smith (2004)</ref>. General diffusion model (gDM) was fit to predictions of DM, with σ, T er , and δ t held at values from the DM and δ z held at zero. Both were Wiener models (β = 0). Speed, speed instructions; acc, accuracy instructions; HF, high frequency;</p><p>LF, low frequency; VLF, very low frequency; NW, nonword.</p><p>root mean squared deviation between gDM and DM predictions is 8.4 ms, compared to 23.5 ms between the DM and the data.  Note also the sharp vertex in the error RT distribution (which is not evident when one looks at the data). This is an artifact of the DM's uniform distribution of nondecision times, another example of how the shape of intertrial parameter distributions can have significant (sometimes unintended) impacts on model predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DISCUSSION AND CONCLUSIONS</head><p>Despite the extensive empirical success of evidence-accumulation models of decision making, and the intuitive and normative appeal of the basic sequential-sampling framework, there is reason for significant doubt about these models' ability to provide substantive explanations of human behavior. The DM has had to adopt assumptions of intertrial variability to account for differences in correct and error RT distributions, which it would otherwise predict to be identical, and the LBA relies entirely on intertrial variability to explain why behavior varies at all. However, without theoretically grounded constraints on the form it takes, intertrial variability confers so much flexibility as to make the models effectively useless. The counterargument to this position is that the formal unfalsifiability theorems rely on allowing growth rates to be fully unrestricted and on allowing diffusion to be negligible in the DM <ref type="bibr" target="#b11">(Jones &amp; Dzhafarov, 2014a)</ref>. It has been suggested that these allowances are too strong, that the models might yield usefully constrained predictions if growth-rate distributions were held to some qualitative simplicity requirements, if these distributions were held invariant across block-level experimental conditions (SI2), and if diffusion were required to have some minimal impact on within-trial dynamics <ref type="bibr" target="#b27">(Smith et al., 2014</ref>). The present results demonstrate this is not the case.</p><p>Although the goal of the present work was to investigate the consequences of these three assumptions, it should be stressed that none of them has strong a priori support.</p><p>First, the logical argument for SI2 is weak, because evidence accumulation could well be affected by block-level manipulations that occur prior to stimulus presentation, and there are models (e.g., <ref type="bibr" target="#b18">Nosofsky &amp; Palmeri, 1997)</ref>  One might also argue that the gDM growth-rate distributions in Section III.3 are more complicated than Gaussians because of the jagged shoulder seen in two of the four stimulus conditions <ref type="figure" target="#fig_15">(Figure 3</ref>). The goal undertaken here was to enforce unimodality. Certainly other qualitative restrictions could be imposed (e.g., a maximum of two inflection points), and their consequences explored. However, such an approach risks becoming increasingly subjective and arbitrary, and could carry on ad infinitum unless one had some principled reasons for the restrictions being imposed.</p><p>Furthermore, model complexity is not the only consideration. The gDM of Section III.3 is a proof by example that startpoint variability can be eliminated from the DM even when diffusion is nonzero. Previous arguments about the necessity of startpoint variability (e.g., <ref type="bibr" target="#b22">Ratcliff &amp; Rouder, 1998)</ref>  one could assume endogenous variability in perception <ref type="bibr" target="#b35">(Thurstone, 1927)</ref>, but this approach would just beg the question unless there were some theory to determine what form this perceptual variability should take. Also, stimulus variability would not help to explain startpoint variability.</p><p>Another possible explanation for intertrial variability is sequential effects. Recent trial history accounts for a great deal of variance in choice and RT (e.g., <ref type="bibr" target="#b16">Luce, 1986)</ref>. </p><formula xml:id="formula_17">p (k) = 1 αk 2 vΦ k−v η − vΦ m−v η − ηφ k−v η + ηφ m−v η .<label>(A1)</label></formula><p>This expression is undefined at k = 0, but it is continuously differentiable there and can be completed by continuity:</p><formula xml:id="formula_18">p (0) = d 2 dk 2 vΦ k−v η − vΦ m−v η − ηφ k−v η + ηφ m−v η k=0 d 2 dk 2 (αk 2 ) k=0 = 1 2α η 2 +vk−k 2 η 3 φ k−v η − (1−α) 2 η 2 +vm−m 2 η 3 φ m−v η k=0 = 1 2α 1 η φ v η − (1−α) 2 η φ v η = 2−α 2η φ v η .<label>(A2)</label></formula><p>The first derivative of the function p (k) is</p><formula xml:id="formula_19">d dk p (k) = − 2 αk 3 vΦ k−v η − vΦ m−v η − ηφ k−v η + ηφ m−v η + 1 αk 2 v η φ k−v η − (1−α)v η φ m−v η + k−v η φ k−v η − (1 − α) m−v η φ m−v η = − 1 αk 3 2vΦ k−v η − 2vΦ m−v η − 2η + k 2 η φ k−v η + 2η + m 2 η φ m−v η .<label>(A3)</label></formula><p>For k = 0, this first derivative is zero if and only if</p><formula xml:id="formula_20">2vΦ k−v η − 2vΦ m−v η = 2η + k 2 η φ k−v η − 2η + m 2 η φ m−v η .<label>(A4)</label></formula><p>For k = 0, Equation A4 can be seen to necessarily hold, but the final expression for the first derivative in Equation A3 is undefined. As above, that expression can be completed by continuity:</p><formula xml:id="formula_21">d dk p (k) k=0 = − d 3 dk 3 2vΦ k−v η − 2vΦ m−v η − 2η + k 2 η φ k−v η + 2η + m 2 η φ m−v η k=0 d 3 dk 3 (αk 3 ) k=0 = − 1 6α × k 5 −3vk 4 + 3v 2 −7η 2 k 3 + 11η 2 v−v 3 k 2 + 6η 4 −4η 2 v 2 k−2η 4 v η 7 φ k−v η − m 5 −3vm 4 + 3v 2 −7η 2 m 3 + 11η 2 v−v 3 m 2 + 6η 4 −4η 2 v 2 m−2η 4 v (1−α) 3 η 7 φ m−v η k=0 = − 1 6α × − 2v η 3 φ v η + 2v(1−α) 3 η 3 φ v η = v 3−3α+α 2 3η 3 φ v η .<label>(A5)</label></formula><p>This last expression equals zero if and only if v = 0.</p><p>Equation A4 can also be written aŝ </p><formula xml:id="formula_22">k−v m−v 2v η φ ζ η dζ =ˆk −v m−v d dζ 2η + (ζ+v) 2 η φ ζ η dζ =ˆk −v m−v 2ζ+2v η φ ζ η − 2ζ η + ζ(ζ+v) 2 η 3 φ ζ η dζ =ˆk −v m−v</formula><formula xml:id="formula_23">satisfy k = v = 0, 0 ≤ m &lt; v &lt; k, or k &lt; v &lt; m ≤ 0.</formula><p>The final step in the proof requires calculation of the second derivative of p (k):</p><formula xml:id="formula_24">d 2 dk 2 p (k) = d dk − 1 αk 3 2vΦ k−v η − 2vΦ m−v η − 2η + k 2 η φ k−v η + 2η + m 2 η φ m−v η = 3 αk 4 2vΦ k−v η − 2vΦ m−v η − 2η + k 2 η φ k−v η + 2η + m 2 η φ m−v η − 1 αk 3 k 2 (k−v) η 3 φ k−v η − m 2 (m−v) η 3 (1 − α) φ m−v η = − 1 αk 4 −6vΦ k−v η + 6vΦ m−v η + k 4 −vk 3 +3η 2 k 2 +6η 4 η 3 φ k−v η − m 4 −vm 3 +3η 2 m 2 +6η 4 η 3 φ m−v η .<label>(A7)</label></formula><p>When the first derivative is zero, Equation A4 can be used to substitute within Equation A7, yielding</p><formula xml:id="formula_25">d 2 dk 2 p (k) = − 1 αk 4 − 6η + 3k 2 η φ k−v η + 6η + 3m 2 η φ m−v η + k 4 −vk 3 +3η 2 k 2 +6η 4 η 3 φ k−v η − m 4 −vm 3 +3η 2 m 2 +6η 4 η 3 φ m−v η = − 1 αη 3 k 4 k 3 (k − v) φ k−v η − m 3 (m − v) φ m−v η .<label>(A8)</label></formula><p>The final argument can now be given that p (k) is always unimodal: Consider first the Wiener model, defined by β = 0. The assumptions just given imply the trajectory of the accumulation process on any trial is given by</p><formula xml:id="formula_26">If v = 0,</formula><formula xml:id="formula_27">R(t) = z + kt.</formula><p>The model's joint R&amp;T density can then be calculated as</p><formula xml:id="formula_28">g(1, t) = d dt Pr [z + kt ≤ 0] =ˆ∞ −∞ d dt Pr [z ≤ −kt] 1 η φ k−v η dk = − 1 δzˆ− a−δz 2t − a+δz 2t k η φ k−v η dk = − 1 δz vΦ k−v η − ηφ k−v η k=− a−δz 2t k=− a+δz 2t = v δz Φ a−δz+2tv 2tη − v δz Φ a+δz+2tv 2tη + η δz φ a−δz+2tv 2tη − η δz φ a+δz+2tv 2tη (B1)</formula><p>and likewise</p><formula xml:id="formula_29">g(2, t) = d dt Pr [z + kt ≥ a] = v δz Φ a+δz−2tv 2tη − v δz Φ a−δz−2tv 2tη − η δz φ a+δz−2tv 2tη + η δz φ a−δz−2tv 2tη . (B2)</formula><p>For the mimicking gDM, the trajectory of the accumulation process on any trial For the gDM to reproduce the distribution in Equations B1 and B2, the probability density function for k, denoted p k , is given for k &lt; 0 by</p><formula xml:id="formula_30">p k (k) = d dk RT • g 1, − a 2k = a 2k 2 v δz Φ −ak+δzk+av aη − v δz Φ −ak−δzk+av aη + η δz φ −ak+δzk+av aη − η δz φ −ak−δzk+av aη .<label>(B3)</label></formula><p>For k &gt; 0, the gDM's growth-rate density is given by</p><formula xml:id="formula_31">p k (k) = d dk RT • g 2, a 2k = a 2k 2 v δz Φ ak+δzk−av aη − v δz Φ ak−δzk−av aη − η δz φ ak+δzk−av aη + η δz φ ak−δzk−av aη ,<label>(B4)</label></formula><p>which is equivalent to the expression in Equation B3.</p><p>Now consider the Ornstein-Uhlenbeck model, for any β = 0. (Traditionally β is assumed to be positive, but the following analysis applies to β &lt; 0 as well.) The trajectory of the response process on each trial is given by</p><formula xml:id="formula_32">R(t) = z + k β 1 − e −βt .</formula><p>The model's joint R&amp;T density can thus be calculated as There is also a positive probability that RT = ∞, corresponding to cases where the accumulator asymptotes between the thresholds, 0 ≤ z + k β ≤ a.</p><formula xml:id="formula_33">g(1, t) = d dt Pr z + k β 1 − e −βt ≤ 0 =ˆ∞ −∞ d dt Pr z ≤ − k β 1 − e −βt 1 η φ k−v η dk = − e −βt</formula><p>For the gDM with the same value of β, the trajectory of the accumulation process on any trial is given by</p><formula xml:id="formula_34">R(t) = a 2 + k β 1 − e −βt</formula><p>and thus the response and RT are given by</p><formula xml:id="formula_35">response =            1 k &lt; − βa 2 2 k &gt; βa 2 undefined |k| ≤ βa 2<label>(B7)</label></formula><p>and</p><formula xml:id="formula_36">RT =      − 1 β log 1 − βa 2|k| |k| &gt; βa 2 ∞ |k| ≤ βa 2 .<label>(B8)</label></formula><p>The response is undefined for |k| ≤ βa 2 because in that case the accumulator asymptotes without reaching a threshold. For the gDM to reproduce the distribution in Equations B5 and B6, the probability density function for k &lt; − βa 2 is given by </p><formula xml:id="formula_37">p k (k) = d dk RT • g 1, − 1 β log 1 + βa 2k = a 2k 2 1 + βa 2k −1 • 1 + βa 2k δ z vΦ − β (a − δ z ) − 2v βa 2k 2η βa 2k − vΦ − β (a + δ z ) − 2v βa 2k 2η βa 2k +ηφ − β (a − δ z ) − 2v βa 2k 2η βa 2k − ηφ − β (a + δ z ) − 2v</formula><p>which is equivalent to the expression in Equations B3 and B4 for the gDM that mimics the Wiener model. For k &gt; βa 2 , the gDM's growth-rate density is given by</p><formula xml:id="formula_39">p k (k) = d dk RT • g 2, − 1 β log 1 − βa 2k ,<label>(B10)</label></formula><p>which again yields the same result. The remaining probability needing to be assigned to the interval − βa 2 ≤ k ≤ βa 2 is equal to</p><formula xml:id="formula_40">Pr |k| ≤ βa 2 = 1 −ˆ− βa 2 −∞ p k (k) dk −ˆ∞ βa 2 p k (k) dk = 1 −ˆ− βa 2 −∞ d dk RT g (1, RT ) dk −ˆ∞ βa 2 − d dk RT g (2, RT ) dk = 1 −ˆ∞ 0 g (1, RT ) dRT −ˆ∞ 0 g (2, RT ) dRT = Pr [RT = ∞] ,<label>(B11)</label></formula><p>and thus the gDM's probability of the accumulator's never terminating matches that of the original model. The distribution of this remaining probability mass in the region − βa 2 ≤ k ≤ βa 2 is arbitrary, because all such growth rates lead to the same outcome (i.e., no response), but extending Equation B9 across this range is a natural option. The resulting growth-rate distribution for mimicking the Ornstein-Uhlenbeck model is then independent of β and identical to that derived above for the Wiener model.</p><p>In fact, it can be shown that this analysis yields the same growth-rate distribution for any model where the growth rate acts multiplicatively on a strictly increasing deterministic accumulation process, regardless of the shape of that process (linear, exponential, etc.). Specifically, let f (t) be a strictly increasing function, with continuous derivative f , supremum F = lim t→∞ f (t) (possibly F = ∞), and f (0) = 0. As shown above with the Ornstein-Uhlenbeck model, the remaining probability mass equals Pr [RT = ∞], and it can be assigned to the interval k ∈ − a 2F , a 2F arbitrarily, including by extending the above expression across the whole real line. Therefore 53 the common result in Equations B3, B4, B9, B19, and B20 describes the growth-rate distribution that mimics any model described by Equations B12-B14, with startpoint variability eliminated.</p><p>Finally, observe that the growth-rate distribution derived here for the gDM is closely related to that derived in Equation 15 for the gLBA. Defining κ = a+δz a k, the density function p κ for κ is </p><formula xml:id="formula_41">= a+δz 2δzκ 2 vΦ κ−v η − vΦ κ−v η − 2δzκ η(a+δz) + ηφ κ−v η − 2δzκ η(a+δz) − ηφ κ−v η ,<label>(B21)</label></formula><p>which is equivalent to the distribution in Equation 15 under the identifications A = δ z and b = a+δz 2 . Note that under these identifications the DM's requirement δ z ≤ a is equivalent to the LBA's requirement A ≤ b. Therefore by the proof in Appendix A, p κ is unimodal under any parameterization of the DM, and thus so is p k since k and κ are linearly related.</p><p>There exist closed-form expressions for the predictions of the Wiener DM for any fixed values of drift rate k, starting point z, and nondecision time t 0 (e.g., <ref type="bibr" target="#b20">Ratcliff, 1978</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 )</head><label>1</label><figDesc>speed-accuracy instructions, prior expectancies) are indexed by c. Under this notation, for all values of s and c there is a joint distribution for the response and RT, referred to here as a response-and-time (R&amp;T) distribution: G s,c (r, t) = Pr [response = r and RT ≤ t|stimulus = s and condition = c] . (The marginal distribution G s,c (r, •) gives the response probabilities Pr [response = r|s, c], and the marginal G s,c (•, t) gives the overall (cumulative) RT distribution Pr [response ≤ t|s, c].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>; Donkin, Averell, Brown, &amp; Heathcote, 2009; Donkin, Brown, Heathcote, &amp; Wagenmakers, 2011; Heathcote &amp; Love, 2012). The value of the accumulator for response r following stimulus s in condition c is denoted here by R s,c r and is defined as a function of time (t) by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>}</head><label></label><figDesc>Uniform for nondecision time t 0 δ t Range of nondecision distribution with mean T er and range δ t ≤ 2T er :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>The</head><label></label><figDesc>LBA and DM both make three selective-influence assumptions, which are reflected in the notation introduced above for the model parameters. First, thresholds and starting points are assumed to be unaffected by the stimulus, as indicated by the indexing of the parameters b c , A c and a c ,z c , δ c z (likewise the random variables z c r and z c ) by c but not by s. The standard motivation is that thresholds and starting points are determined before stimulus onset, and thus cannot depend on the stimulus identity. Second, growth rates are assumed to be unaffected by block-level manipulations (e.g., speed-accuracy instructions or base rates), as indicated by the indexing of the parameters v s r and v s (likewise the random variables k s r and k s ) by s but not by c. The standard motivation for this assumption, referred to here as SI2, is that such manipulations occur before stimulus onset, whereas growth rates reflect stimulus processing. This reasoning lacks the rigor of that underlying the first selective-influence assumption, because manipulations occurring prior to stimulus processing could well affect that processing. As detailed in Jones and Dzhafarov (2014a, 2014b), models of decision making that incorporate attention shifting among stimulus attributes (Diederich, 1997; Nosofsky &amp; Palmeri, 1997; Roe, Busemeyer, &amp; Townsend, 2001) produce systematic and principled violations of SI2, and recent empirical applications of the standard LBA and DM have found violations of this assumption (Rae, Heathcote, Donkin, &amp; Brown, 2014; Starns, Ratcliff, &amp; McKoon, 2012; Starns, Ratcliff, &amp; White, 2012). The third selective-influence assumption is that non-decision time is unaffected by stimulus identity and by experimental condition, as indicated by the lack of indexing of t 0 , T er , and δ t by s or c.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Finally</head><label></label><figDesc>, it is important to understand the historical development and motivation of the intertrial variability assumptions. Intertrial variability was introduced into the DM to account for differences in RT distributions for correct and error responses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>Gaussian for growth rates, uniform for starting points) have always been considered arbitrary and based on convenience. That is, they are implementation decisions that do not represent theoretical commitments. Therefore it is important to understand what the models can and cannot predict with these implementational assumptions removed. Recent work has begun to consider the implications of choosing other distributional families (Heathcote &amp; Love, 2012; Ratcliff, 2013; Terry, Marley, Barnwal, Wagenmakers, Heathcote, &amp; Brown, in press), offering an important complement to the approach taken here. II.3. Unfalsifiability To understand the flexibility afforded by the LBA's and DM's assumption of intertrial variability in growth rates, Jones and Dzhafarov (2014a) defined generalized versions of these models, the gLBA and gDM, in which the growth-rate distributions are fully unconstrained. Formally, these models are derived from the standard models by removing the Gaussian-growth and SI2 assumptions. Thus, rather than Gaussian growth-rate distributions that are unaffected by experimental condition, the generalized models have fully free growth-rate distributions that can vary by condition (as well as by stimulus). Accordingly, the growth rates are rewritten as k s,c r (gLBA) and k s,c (gDM) to index by condition in addition to stimulus. The principal result of Jones and Dzhafarov (2014a), for present purposes, is that the gLBA and gDM are provably unfalsifiable. That is, for any possible pattern of data in a binary choice task, formalized as a family of R&amp;T distributions G s,c (r, t), there exist instances of the gLBA and the gDM generating predictions that perfectly match these distributions. For the gLBA, the intuition behind the proof is that freedom of the growth-rate distribution for each combination of r, s, and c implies freedom in the corresponding first-passage distribution: For any desired completion time T s,c r &gt; t 0 (including T s,c r = ∞), there is a growth rate k s,c r that will yield that completion time. An established theorem regarding independent-process race models states that, if the first-passage distributions are unconstrained (and allowed to include infinity), then such a model can produce any possible R&amp;T distribution (Dzhafarov, 1993; Jones &amp; Dzhafarov, 2014a; Marley &amp; Colonius, 1976; Townsend, 1972</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>s r , η, and t 0 . The mimicking gLBA is assumed to use the same thresholds and nondecision time (b c and t 0 ), to have starting points always equal to zero (z c r = 0), and to have growth rates defined by a family of random variables k s,c r . Thus the only aspect of the gLBA needing to be derived is the set of growth-rate distributions defining k s,c r . These distributions are derived here by first finding the first-passage distributions of the standard LBA and then finding the growth-rate distributions for the gLBA that will reproduce those first-passage distributions. As noted above, mimicking the LBA's first-passage distributions leads to mimicking its predicted R&amp;T distribution. The first-passage time, T s,c r , for each accumulator in the LBA is given by Equation 6. Integration over uniform startpoint and Gaussian growth-rate distributions yields the following expression for the LBA's first-passage distribution (Brown &amp; Heathcote, 2008):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>An important property of this distribution is that it depends on the ratio of the LBA's startpoint variability to the response threshold (A c /b c ) but not on either parameter (A c or b c ) alone. Therefore, if A c /b c were constrained to be constant across experimental conditions in the LBA, SI2 would be maintained in the gLBA: the growth-rate distributions for each stimulus s would be the same in all conditions c. Indeed, Brown and Heathcote (2008, p. 167) note that they fit the LBA under this constraint and found the fit was equally acceptable (only marginally poorer, with one less free parameter). The first selective-influence assumption, that starting points and thresholds are unaffected by stimulus, is trivially maintained in the gLBA, because starting points are assumed all to be zero and the thresholds b c are unchanged from the LBA. Likewise, the third selective-influence assumption, that nondecision time is unaffected by stimulus and condition, is maintained because t 0 is constant (unchanged from the LBA). Equation 15 therefore shows that flexibility in the growth-rate distributions allows startpoint variability to be eliminated from the LBA while maintaining selective influence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 1</head><label>1</label><figDesc>shows the growth-rate distributions for the gLBA that result from Equation 15.<ref type="bibr" target="#b2">3</ref> The graph takes advantage of the LBA's scaling degeneracy, which implies that joint rescaling of A c , b c , v s r , and η has no effect on the LBA's first-passage distributions. The only effect of such a rescaling on the corresponding gLBA is a multiplicative transformation of k s,c r , which amounts to nothing more than a rescaling of the abscissa in the graph. Thus η is fixed at unity, and the gLBA's growth-ratedistributions are indexed by two values derived from the LBA's parameters: A c /b c , ranging from zero (no startpoint variability) to unity (maximal startpoint variability); and the LBA's mean growth rate v s r (equivalently, the ratio v s r /η). Because Equation 15 is unchanged under (k, v s r ) → (−k, −v s r ), the distribution for any negative value of v s r is a reflection about zero of the distribution for the corresponding positive value of v s r , and therefore results are plotted only for v s r ≥ 0. 4 Taking into account these symmetries, Figure 1 shows a representative sampling of the full family of gLBA growth-rate distributions that will exactly mimic the LBA under any parameter values. Each set of curves corresponds to a different value of v s r in the LBA, ranging from weak evidence for the response in question (v s r = 0) to strong evidence (v s r = 6η); larger values of v s r yield the same qualitative pattern as those shown here. The most peaked curve in each set is the growth-rate distribution in the original LBA; when A c = 0, the gLBA adopts these distributions as well and the two models are identical. As A c /b c increases in the LBA, the growth-rate distributions in the gLBA develop heavier tails and positive skew (progressively flatter curves within each set). The increased probability of a large growth rate plays the same role as startpoint variability, in allowing the accumulator to terminate quickly on some trials. In addition to satisfying selective influence, the gLBA growth-rate distributions obtained from Equation 15 are quite simple. They are smooth, are provably unimodal under all parameter values (see Appendix A), and require the same number</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 1 .</head><label>1</label><figDesc>Elimination of startpoint variability from the linear ballistic accumulator (LBA) model. Each curve shows the growth-rate distribution for an accumulator in the general LBA (gLBA), without startpoint variability, that exactly matches the first-passage distribution of an accumulator in the standard LBA. Each set of curves shows results for a different value of v s r , the mean growth rate in the LBA (abbreviated as v in the figure)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>of free parameters as does the standard LBA (because they are analytically derived from that model's parameters). It is difficult to see a basis for claiming these distributions are any less psychologically plausible or interpretable than the LBA's Gaussian distributions. Thus, maintaining selective influence and requiring simple (unimodal) growth-rate distributions does not rescue the LBA from the problems of excess flexi-bility from intertrial growth-rate variability: Even under these constraints, the model can fit any possible data exactly as well without startpoint variability as it can with startpoint variability. This unidentifiability between models is a direct consequence of the flexibility provided by stochastic variation in growth rates, which makes it difficult to determine what other model components are theoretically necessary for an adequate account of human behavior.III.2. Eliminating Startpoint Variability from the Diffusion ModelThis section presents an analysis of the DM that parallels the analysis of the LBA in the previous section, again translating startpoint variability into growth-rate variability and deriving the resulting growth-rate distribution for the gDM. We begin with the limiting case of no diffusion as well as assuming no response bias, tackling the full model in the next section. The standard DM is taken as defined in Section II.2,with parameters β, a c , σ, v s , η,z c , δ cz , T er , and δ t , with σ = 0 andz c = a c /2. The mimicking gDM is assumed to use the same decay rate, threshold separation, and nondecision parameters (β, a c , T er , δ t ), to have starting points always equal toz c (δ c z = 0), and to have growth rates defined by a family of random variables k s,c . The growth-rate distribution for the gDM is derived in Appendix B, by directly calculating the R&amp;T distribution predicted by the DM (for each s and c) and then deriving the growth-rate distribution in the gDM that matches that R&amp;T distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>the</head><label></label><figDesc>Ornstein-Uhlenbeck model), provided the process is strictly monotonic and diffusion is negligible: A model with Gaussian growth rates and uniformly distributed starting points is always equivalent to a model with growth rates distributed according to Equation 16 and no startpoint variability. This result is also unaffected by nondecision time or nondecision variability (T er and δ t ). Most importantly for the present investigation, the boundary separation, a c , and the startpoint variability, δ c z , affect the distribution only through the value of their ratio, δ c z /a c . In other words, if startpoint variability is conceived as a proportion of total boundary separation, there is a direct translation between startpoint variability and growth-rate distribution that is independent of all other model parameters.Although the form of the DM that has appeared recently in the literature treats startpoint variability as independent of boundary separation (e.g.,Ratcliff, 2013; Ratcliff &amp; Smith, 2004), previous applications have linked these parameters. In particular, in a paper widely cited as demonstrating the necessity of startpoint variability, Ratcliff and Rouder (1998) assumed δ c z /a c to be constant across conditions. I know of no empirical evidence in subsequent research that is inconsistent with this assumption. With this assumption in place for the DM, Equation 16 shows that SI2 holds for the resulting gDM. This conclusion parallels the conclusion for the LBA (Equation 15): Even though the unfalsifiability theorems of Jones and Dzhafarov (2014a) do not guarantee SI2, it turns out to be automatically maintained when startpoint variability is eliminated from the model (in the special case of no diffusion or response bias). The gDM derived here also automatically satisfies the first and third selective-influence assumptions, because the threshold and nondecision parameters are unchanged from the original model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 2</head><label>2</label><figDesc>shows the growth-rate distributions for the gDM that result from Equation 15, using the same conventions as inFigure 1. The gDM's possible growth-rate distributions are indexed by two values derived from the DM's parameters: δ c z /a c (ranging from 0 to 1) and v s /η. Using the DM's scaling degeneracy, η is held at unity, and changing η would merely change the scale of the abscissa. The graph also takes advantage of the symmetry of Equation 15 under (k, v s ) → (−k, −v s ), so that the growth-rate distribution for any negative value of v s is a reflection about zero of the distribution for the corresponding positive value of v s . In this way, Figure 2 shows a representative sampling of the full family of gDM growth-rate distributions that will exactly mimic the DM under any parameterization. Each set of curves corresponds to a different value of v s in the DM, ranging from v s = 0 (no discriminability) to v s = 6η (high discriminability). The most peaked curve in each set is the growth-rate distribution in the original DM and is also the distribution adopted by the gDM when the DM has no startpoint variability (δ c z = 0). As δ c z /a c increases in the DM, the gDM's growth-rate distributions become broader and more skewed, paralleling the results found above with the gLBA. As with the gLBA, the gDM's growth-rate distributions are quite simple, requiring the same number of free parameters as does the standard DM, and being provably unimodal under all parameter values (see Appendix B). Therefore, maintaining selective influence and requiring unimodal growth-rate distributions does not resolve the problem of excessive flexibility in the DM, at least for the special case of negligible diffusion and no response bias, because startpoint variability remains unidentifiable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 2 .</head><label>2</label><figDesc>Elimination of startpoint variability from the diffusion model (DM). Shown are the distributions of growth rates for the generalized DM (gDM) without startpoint variability that exactly matches the predictions of the standard DM. Each set of curves shows results for a different value of the DM's mean growth rate, v s (abbreviated as v in the figure).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>(</head><label></label><figDesc>Gaussian, uniform, etc.)  have little effect on model predictions. If this claim were correct, then introducing some sort of lower bound on the contribution of diffusion might offer a remedy to the unfalsifiability theorem for the DM, because under such a constraint flexibility in the shape of the growth-rate distributions might contribute little flexibility to the model's predictions.To explore this possibility, I investigated whether the DM could be mimicked by a gDM without startpoint variability, this time with nonzero diffusion. Rather than undertaking to produce an exact equivalence between models, the goal was to make the models' predictions match as closely as possible, starting with a DM fit to real data. Using real data is useful because it provides a practical perspective for evaluating the degree of mimicry: If the gDM can match the DM at least as well as the DM matches the data, then one can conclude that startpoint variability is unidentifiable in practice. The starting point was<ref type="bibr" target="#b24">Ratcliff and Smith's (2004)</ref> fit of the DM to the data from Experiment 1 of Wagenmakers et al. (2008). 5 Because of the computational cost of numerically fitting an Ornstein-Uhlenbeck model with nonparametric growth-rate distributions, the analysis used Ratcliff and Smith's fit of the Wiener model. Thus the goal was to match the predictions of Ratcliff and Smith's model using a gDM with unimodal growth-rate distributions obeying SI2 and a comparably large contribution of diffusion. The Wagenmakers et al. (2008) experiment used a lexical decision task, with four stimulus levels (words of high, low, and very low frequency, and nonwords) and two instruction conditions emphasizing speed or accuracy. The results of this experiment provide a particularly strong challenge to the goal of eliminating startpoint variability from the diffusion model, because they exhibit the critical crossover pattern thatis often given as decisive evidence for the necessity of this mechanism. Specifically, median RT in the accuracy condition was slower for errors than for correct responses, but in the speed condition this pattern was reversed, with median error RT faster than median correct RT. It has been claimed that variability in growth rate alone cannot explain fast errors, and that explaining the crossover between fast and slow errors within one experiment is a particularly stringent test of any RT model<ref type="bibr" target="#b25">(Ratcliff et al., 1999;</ref><ref type="bibr" target="#b22">Ratcliff &amp; Rouder, 1998;</ref><ref type="bibr" target="#b24">Ratcliff &amp; Smith, 2004;</ref><ref type="bibr" target="#b39">Van Zandt, Colonius, &amp; Proctor, 2000)</ref>. The DM fit by<ref type="bibr" target="#b24">Ratcliff and Smith (2004)</ref>, with startpoint variability included, reproduces this crossover pattern (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 3</head><label>3</label><figDesc>shows that the gDM matches the DM's full R&amp;T distributions very closely, certainly more closely than the precision offered by data from typical experiments.Figure 3also shows this match was achieved with simple, unimodal growth-rate distributions. Finally, the values of a c andz c are very close between models, implying the gDM is not taking advantage of the scaling degeneracy discussed above to reduce the effective diffusion rate (by using large threshold separations). In fact, threshold separation is slightly smaller in the gDM, meaning diffusion actually plays a greater role than it does in the DM. In sum, the gDM reported here shows that the predictions of the DM can be matched without startpoint variability, using unimodal growth-rate distributions that obey SI2, and without reducing the contributions of diffusion-even for data that have been offered as strong support for the necessity of startpoint variability. Together with the formal unfalsifiability theorems<ref type="bibr" target="#b11">(Jones &amp; Dzhafarov, 2014a)</ref> and the analytical results in the previous sections, these results support the conclusion that startpoint variability is unnecessary in the presence of growth-rate variability. More generally, they demonstrate that the flexibility afforded by the assumption of variability in growth rates makes it very difficult to determine the mechanisms needed to explain speeded choice behavior.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 3 .</head><label>3</label><figDesc>Model fits to Experiment 1 of<ref type="bibr" target="#b40">Wagenmakers et al. (2008)</ref>. Dashed curves represent fits by<ref type="bibr" target="#b24">Ratcliff and Smith (2004)</ref> of the standard diffusion model (DM) to the data. Solid curves represent general diffusion model (gDM), with no startpoint variability, fit to match the predictions of the DM. Rows correspond to the different stimulus types. Left column shows the growth-rate distributions, which are constrained to be Gaussian in the DM but are free in the gDM. Middle and right columns show joint response-and-time (R&amp;T) distributions for speed and accuracy conditions, respectively. Upper and lower curves correspond to correct and incorrect responses, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>and the weak influence of distributional assumptions (Ratcliff, 2013; Smith et al., 2014) claim this is not possible at all, regardless of how flexible the growth-rate distribution is. More generally, a model's contribution to psychological theory is not evaluated solely in terms of how mathematically flexible its predictions are. The contribution lies in the structure attributed to psychological processes and representations: how many components there are, what they do or encode, and how they interact. A central conclusion from the present work is that, when variables from one component of a model are given stochastic variation with no theoretical constraints on the form of that variation, it becomes difficult to decide the core theoretical question of what other components are present.The translation approach advanced here is very general. Whenever some component of a modeling framework is flexible enough to make that framework unfalsifiable, any other model component can be translated into that one. That is, the former component can be modified to accommodate any change in (including complete elimination of) the latter, while exactly preserving the model's predictions. The present work focused on translating startpoint variability into the growth-rate distributions, but one can for example do the same with nondecision variability or diffusion, deriving the growth-rate distributions for a model without either of these components that exactly mimics a model with them. In addition to the insights it offers regarding model flexibility, this translation strategy offers a potentially useful way to simplify model comparison. For example, one could take any set of models and translate them into gLBA models without startpoint variability, so that the models are now all expressed in the same framework and differ only quantitatively, namely in their choices of growth-rate distributions. Jones and Dzhafarov (2014a,Figure 4) performed this particular translation starting from the standard DM, using parameter values typical of real data fits, including significant diffusion. The resulting gLBA growth-rate distributions were quite similar to the ones derived here for translating away startpoint variability from the standard LBA (Figure 1). Thus at a qualitative level, diffusion (with the single-process dual-threshold architecture) and startpoint variability are both equivalent to skewing the gLBA's growth-rate distributions. It is intriguing that these skewed distributions are also similar-though not identical-to the lognormal distributions that Heathcote and Love(2012)found to be empirically successful in their LBA variant without startpoint variability (more precisely, with lognormal variability in threshold-startpoint separation that is intentionally unidentifiable from the lognormal growth-rate variability). Thus the translation approach offers a new perspective on the relationship among these four models: the standard LBA (with startpoint variability and Gaussian growth-rate distributions), the exactly equivalent gLBA with no startpoint variability and growth-rate distributions defined by Equation 15, Heathcote and Love's lognormal LBA, and the standard DM (with startpoint variability, Gaussian growth-rate distributions, and within-trial diffusion). When translated to the gLBA framework (without startpoint variability), these models all have quite similar growth-rate distributions, suggesting they would be difficult to distinguish empirically. This approach of comparing a set of models that are all expressed in the same framework and differ only in their growth-rate distributions is similar to the recent work of Terry et al. (in press), although those authors reach very different conclusions. Terry et al. show that, with a fixed (uniform) startpoint distribution, gLBA models with different forms of growth-rate variability (normal, lognormal, gamma, and Fréchet) behave quite differently and cannot mimic each other well. They conclude that gLBA variants can be empirically distinguished, and they claim, counter to Jones and Dzhafarov (2014a), that one can evaluate the consequences of different growth-rate assumptions separately from questions about model architecture. What this argument overlooks is the point that has been emphasized here, that a model's architectural assumptions can trade off with or compensate for changes in the growth-rate distribution. This reflects a critical difference between the present analyses and Terry et al.'s: Rather than keeping the startpoint distribution fixed, the present paper investigated the consequences of removing startpoint variability from models that include that mechanism, and how the growth-rate distributions can accommodate that change. The results show that one cannot determine the form of the best-fitting growth-rate distributions without independently fixing the form of the startpoint variability, and, vice versa, one cannot determine the necessity of startpoint variability without first fixing the form of the growth-rate distributions. Thus the present effort and that of Terry et al. (in press; see also Heathcote, Wagenmakers, &amp; Brown, 2014) are aimed at different questions, perhaps stemming from different perspectives on the goals of building cognitive models. If one wants to consider models as unitary entities (i.e., inseparable sets of assumptions), and to give structural assumptions and assumptions about shapes of distributions the same theoretical status, then certainly one can evaluate the predictions of these models and use standard methods to compare their abilities to fit data. Under this philosophy, the fact that extant models-taken as wholes-make constrained predictions that match data remarkably well (e.g., Ratcliff &amp; Smith, 2004) should be taken as a great success. On the other hand, the work of Jones and Dzhafarov (2014a) has shown that the basis for these predictive constraints, and the principles of cognition they reflect, are poorly understood. I believe a different approach is necessary if one wants to view models as embodying explanations, and moreover if one's goal is to discover explanatory principles that generalize to other domains separately from the particular models in which they are embedded. Under this latter philosophy, it is important to know what predictions necessarily follow from a given principle or set of principles, regardless of the choices of implementational assumptions that are made in defining a full working model. If it turns out that no predictions follow at all-as is the case for the architectures of the LBA and the DM-or that different sets of principles make the same predictions-as is the case for those architectures combined with SI2, unimodal growth-rate distributions, and lower-bounded diffusion, with and without startpoint variability-then this is a serious problem for the goal of explaining human behavior. A possibly fruitful way forward is to develop a positive theory of intertrial variability. Current models assume this variability exists while providing little to no detail regarding the mechanisms from which it arises. Consequently there is no basis for theoretical constraints on the form of the variability, leading to the excess flexibility problems that are the topic of this article. If instead there were a model for how the variability is generated, that model might make specific predictions for the form it takes (including the shapes of the associated distributions), at which point the flexibility problem might be resolved. Heathcote and Love (2012) offer one such model, extending Ulrich and Miller's (1993) cascading partial outputs system, as a basis for lognormal growth-rate distributions. Another obvious candidate foundation for a theory of intertrial variability is real variability in the stimuli. Such variability is certainly present in some paradigms, for example lexical decision or recognition memory, although one would need to define quantitative measures of stimulus variability in these paradigms and determine how those measures translate to values of the growth rate. For simple perceptual tasks with no physical stimulus variability,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>These effects are often well explained by incremental learning models, in which the subject's expectancy for each upcoming trial varies due to learning from prediction error on recent trials (e.g.,Jones, Curran, Mozer, &amp; Wilder, 2013). Jones (in prepa-ration) shows how this type of learning offers a promising theoretical foundation for intertrial variability in the DM. Specifically, a Bayesian interpretation of the DM architecture implies three task parameters that a decision-maker needs to learn in order to perform optimally: the base rate for the correct response, the midpoint between the drift rates associated with the two stimulus categories (known as the drift criterion), and the signal-to-noise ratio (the difference in drift rates for the two categories, divided by the squared diffusion rate). Learning rules can be derived for each of these parameters and incorporated into the DM, and these produce sequential dependencies in the starting point, net drift rate (i.e., after subtracting the drift criterion), and threshold separation, respectively. These dependencies in turn have two consequences: intertrial variability in these three variables, and three signature sequential effects in the model's choice and RT that all have prior empirical support(e.g., Jesteadt, Luce, &amp; Green, 1977; Jones, Love, &amp; Maddox, 2006; Jones, Mozer, &amp; Kinoshita, 2009; Taylor &amp; Lupker, 2001; Treisman &amp; Williams, 1984). Most remarkably, the model's predictions for these two sets of effects (i.e., intertrial variability in internal variables, and sequential effects in choice and RT) are tightly linked, in a way that predicts data quite well. When the model is fit to the sequential effects that are present in the Wagenmakers et al. (2008) dataset, by estimating the relevant learning-rate parameters, it produces just the right amount of intertrial variability in these parameters to match the marginal R&amp;T distributions (i.e., ignoring trial order). In fact, the resulting variances for growth rates and starting points are nearly identical to those in Ratcliff and Smith's (2004) fit of the DM to these data, although the shapes of the distributions are different because they are determined by the learning dynamics. The reverse result holds as well: When the model is fit to the R&amp;T distributions, it predicts sequential effects that quantitatively match those in the data. Thus, incremental learning from prediction error, together with a Bayesian interpretation of the DM, yields a mechanistic theory of intertrial variability that makes constrained predictions that are well-supported by the data. Regardless of the merits of this particular model, efforts of this kind have the potential to theoretically ground intertrial variability of evidence-accumulation models will eventually result in constrained, principled models and resolve the problems of excess flexibility currently facing the field. 0 &lt; α ≤ 1, as well as m = (1 − α) k. Letting p (k) denote the probability density function for the gLBA's growth-rate distribution, Equation 15 can be rewritten as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>understanding that´b a f (x) dx = −´a b f (x) dx if b &lt; a), which implieŝ positive, as is (ζ + v) 2 except at the single point ζ = −v, and η 3 is a constant with respect to the integral. Therefore Equation A6 can hold only if (1) k = m or (2) ζ changes sign in the interval (m − v, k − v). The first of these conditions implies k = 0, which by Equation A5 can only be a local extremum if v = 0. The second condition is equivalent to m &lt; v &lt; k when v &gt; 0, and to k &lt; v &lt; m when v &lt; 0; the condition cannot be satisfied if v = 0 because k and m cannot have opposite signs. Therefore, all local extrema of the function p (k) must</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>then there is at most one local extremum, at k = 0. Equation A2 implies p (0) &gt; 0, and it is easy to see from Equation A1 that lim k→−∞ = lim k→∞ = 0. Thus k = 0 must be a maximum, not a minimum or an inflection point.If v &gt; 0, any local extremum satisfies 0 ≤ m &lt; v &lt; k, whence k 3 (k − v) φ (k − v) &gt; 0 and m 3 (m − v) φ (m − v) ≤ 0,implying that the second derivative of p (k) at that extremum is negative and thus the point is a local maximum. If v &lt; 0, any local extremum satisfies k &lt; v &lt; m ≤ 0, whence the second derivative is again negative by the same reasoning. In all three cases, p (k) is a continuously differentiable, non-constant function with finite and equal limits at ±∞ and no local minima, which taken together imply that it must have a single (local and global) maximum, thus making it a unimodal distribution. make identical predictions for response and RT. To simplify notation, the indexing for stimulus (s) and condition (c) is dropped.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>e −βt = e −βt δz vΦ β(a−δz)+2v 1−e −βt 2η 1−e −βt − vΦ β(a+δz)+2v 1−e −βt 2η 1−e −βt +ηφ β(a−δz)+2v 1−e −βt 2η 1−e −βt − ηφ β(a+δz)+2v 1−e −βt 2η 1−e −βt (B5) and likewise g(2, t) = d dt Pr z + k β 1 − e −βt ≥ a = e −βt δz vΦ β(a+δz)−2v 1−e −βt 2η 1−e −βt − vΦ β(a−δz)−2v 1−e −βt 2η 1−e −βt +ηφ β(a−δz)−2v 1−e −βt 2η 1−e −βt − ηφ β(a+δz)−2v 1−e −βt 2η 1−e −βt . (B6)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>βa 2k 2η βa 2k = a 2δzk 2</head><label>2</label><figDesc>vΦ ak+δzk−av aη − vΦ ak−δzk−av aη + ηφ ak−δzk−av aη − ηφ ak+δzk−av aη ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>Define a two-sided accumulator model by R (t) = z + kf (t) and a. Note that the Wiener and Ornstein-Uhlenbeck models both fit this definition, in the case of negligible diffusion and no response bias. The joint R&amp;T density predicted by such a model is given byg (1, t) = d dt Pr [z + kf (t) ≤ 0] =ˆ∞ −∞ d dt Pr [z ≤ −kf (t)] 1 η φ t) = d dt Pr [z + kf (t) ≥ a] = f (t) δz g vΦ a+δz−2vf (t) 2ηf (t) − vΦ a−δz−2vf (t) 2ηf (t) +ηφ a−δz−2vf (t) 2ηf (t) − ηφ a+δz−2vf (t) 2ηf (t) .(B16)Now consider a generalized model with accumulation process still given by Equation B12 but with unconstrained growth-rate distribution and with no startpoint variability (z fixed at a 2 ). The model's response and RT are given by 2F interpreted as zero if F = ∞. For this generalized model to reproduce the R&amp;T distribution in Equations B15 and B16, the growth-rate density for k &lt; − a2Fisp k (k) = d dk RT • g 1, f −1 − a 2k = a 2k 2 f f −1 − a 2k • f f −1 − a 2k δz vΦ − a − δ z − 2v a 2k 2η a 2k − vΦ − a + δ z − 2v a 2k 2η a 2k +ηφ − a − δ z − 2v a 2k 2η a 2k − ηφ − a + δ z − 2v a2k k &gt; a 2F the result is the same:p k (k) = d dk RT • g 2, f −1 a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>− 2ka σ 2 − e − 2kz σ 2 e − 2ka σ 2 − 1 G ( 2 ,− 1 . 2 ∞ n=1 2na 2 σ 2 k 2 −t k 2 a 2 +n 2 π 2 σ 4 2a 2 σ 2 G 2 ∞ n=1 2na 2 σ 2 k 2 a 2 +n 2 π 2 σ 4 −t k 2 a 2 +n 2 π 2 σ 4 2a 2 σ 2 ( 2 ∞ n=1 n sin nπz a e −t k 2 a 2 +n 2 π 2 σ 4 2a 2 σ 2 g ( 2 , t) = πσ 2 a 2 −t k 2 a 2 +n 2 π 2 σ 4 2a 2 σ 2 .−t k 2 a 2 +n 2 π 2 σ 4 2a 2 σ 2 dt= m!πσ 2 a 2 e − kz σ 2 ∞ n=1 n sin nπz a k 2 a 2 +n 2 π 2 σ 4 2a 2 σ 2 −2 a 2 +n 2 π 2 σ 4 2a 2 σ 2 −m− 1 .</head><label>2212122242224422422242422221</label><figDesc>. The marginal response probabilities are given by G(1, •) = lim t→∞ G(1, t) = e •) = lim t→∞ G (2, t) = e − 2kz σ 2 − 1 e − 2ka σ 2 is given by G (1, t + t 0 ) = G (1, •) − πσ 2 a 2 e − kz σ a 2 +n 2 π 2 σ 4 sin nπz a e (2, t + t 0 ) = G (2, •) − πσ 2 a 2 e k(a−z) σ sin nπ(a−z) a e C2) and the associated R&amp;T density is given by g (1, t) = πσ 2 a 2 e − kz σ (C3) Predictions for the full DM (for any given stimulus and condition) can be obtained by numerically integrating Equations C1-C3 over the distributions of t 0 , z, and k. Three sets of measures were computed summarizing the DM's predictions, separately for each combination of stimulus type and instruction condition. The first measure was the DM's overall response probability, p (word) = G (2, •). The second set was based on the .1, .3, .5, .7, and .9 quantiles of the DM's marginal RT distribution for each response. For each quantile value t under each response r, the DM's joint cumulative probability G (r, t) was computed, which is equal to the marginal response probability G (r, •) times the quantile probability defining t (i.e., .1, .3, .5, .7, or .9). These first two sets of measures constitute the empirical statistics commonly used in fitting the DM to data (including by Ratcliff &amp; Smith, 2004, and Wagenmakers et al., 2008, in fitting the DM of Section III.3). The third set of measures were the first five joint moments of the DM's R&amp;T distribution for each response. The m th joint moment for response r is defined here as the m th moment of the conditional RT distribution multiplied by the response probability: M m r = E [RT m |response = r] • G(r, •). (C4) The moments conditioned on any fixed values of k and z can be calculated from Equation C3 as follows: numerically integrated over the DM's intertrial distributions for z and k to obtain the joint moments for the full DM for each combination of stimulus and condition. Thus there were a total of 42 measures per stimulus type: 2 response probabilities (1 per condition), 20 joint cumulative probabilities evaluated at the quantiles of the DM (5 per response and condition), and 20 joint moments (5 per response and condition). The gDM was fit to match these 168 target measures by weighted</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table I .</head><label>I</label><figDesc>LBA model parameters</figDesc><table><row><cell cols="2">Parameter Meaning</cell><cell>Associated Distribution</cell></row><row><cell>b c</cell><cell>Common threshold for all accumulators</cell><cell></cell></row><row><cell>A c v s r η 2</cell><cell>Upper limit on range of starting points Mean growth rate of accumulator r Variance in growth rate for all accumulators</cell><cell>Uniform for starting point z c r } Gaussian for growth rate k s r</cell></row><row><cell>t 0</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table II .</head><label>II</label><figDesc>Diffusion model parameters</figDesc><table><row><cell cols="2">Parameter Meaning</cell><cell>Associated Distribution</cell></row><row><cell>β</cell><cell>Decay rate; set to 0 for Wiener model</cell><cell></cell></row><row><cell>a c</cell><cell>Threshold separation</cell><cell></cell></row><row><cell>σ</cell><cell>(Square root of) diffusion rate</cell><cell></cell></row><row><cell>v s η</cell><cell cols="2">Mean growth rate Standard deviation of growth-rate distribution } Gaussian for growth rate k s</cell></row><row><cell>z c δ c z</cell><cell>Mean starting point Range of startpoint distribution</cell><cell>} Uniform for starting point z c</cell></row><row><cell>T er</cell><cell>Mean nondecision time</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>In particular, one might want to require diffusion to have some minimal contribution to the DM's predictions, for example by placing some lower bound on the diffusion rate. Third, one might also want to impose some qualitative constraints on the form of the growth-rate distributions. Even though the choice of a Gaussian function is essentially arbitrary, one might want to disallow distributions that are overly complex in some sense, requiring certain properties such as symmetry or unimodality. The results reported next demonstrate that none of these considerations avoids the practical consequences of the unfalsifiability theorems: The models remain excessively flexible even under the restrictions of SI2, unimodal growth-rate distributions, and a strong lower bound on the diffusion rate. .1. Eliminating Startpoint Variability from the LBA This section explicitly derives the gLBA without startpoint variability that mimics the standard LBA, demonstrating that this gLBA naturally satisfies the selectiveinfluence assumptions and has simple, unimodal growth-rate distributions. The LBA is defined as in Section II.2, with parameters b c</figDesc><table /><note>). For the gDM, the proof relies on the limiting case in which the diffusion rate approaches zero (or the threshold separation grows very large; see Footnote 1), in which case for every joint assignment of response and RT, (r, t), there is a growth rate k s,c that will produce that outcome. Thus any R&amp;T distribution can be directly translated into a distribution on growth rates. The universality theorems imply that the intertrial variability introduced into the models in order to fit data (including the crossover effect) makes them exces- sively flexible. Unfalsifiability of the generalized models implies that the predictive constraints of the standard models depend fully on the arbitrary implementation assumption of Gaussian growth rates and the theoretically and empirically suspect SI2 assumption. Nevertheless, there are a number of considerations that might be argued to limit the importance of these results. First, one might want to retain SI2, for example as a default assumption to hold onto unless forced to abandon it (Smith et al., 2014). Second, one might argue, as Smith et al. (2014) have, that the unfal- sifiability theorems require consideration of instances of the models that-in some subjective sense-are very different from the instances that have been obtained from parameter estimation in actual empirical applications.III. REDUNDANCY OF STARTPOINT VARIABILITY One consequence of the fact that unconstrained growth-rate variability makes the LBA and DM unfalsifiable is that other mechanisms in the model become unneces- sary, including startpoint variability, nondecision variability, diffusion in the DM, and decay in the Ornstein-Uhlenbeck model. The models' predictions under any choice of parameter values can be perfectly matched by a model without any of these mech- anisms, under a different choice of growth-rate distributions. This property seriously undermines the models' theoretical value, because these mechanisms that have been argued to be necessary for explaining behavior and that have been given detailed psychological interpretations become unidentifiable. The present paper focuses on the mechanism of startpoint variability, demonstrating that this situation of uniden- tifiability holds even if SI2 is retained, growth-rate distributions are constrained to be unimodal, and diffusion in the DM is required to have a significant impact on the accumulation process.III</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table III .</head><label>III</label><figDesc>Median reaction times from Wagenmakers et al. (2008) Experiment 1 Finally, the best-fitting gDM's predicted R&amp;T distributions were derived for all stimuli in both conditions, and these were compared to the predictions of the DM. Tables III and IV report the predicted median RTs and the parameters of the DM and gDM. The gDM does quite well at reproducing the predictions of the DM, including the critical crossover pattern of median RTs. Indeed, the gDM matches the DM better than the DM matches the human data: Across the 16 median RTs, the</figDesc><table><row><cell></cell><cell></cell><cell>Speed</cell><cell cols="2">Accuracy</cell></row><row><cell></cell><cell cols="4">Correct Incorrect Correct Incorrect</cell></row><row><cell></cell><cell></cell><cell cols="2">High Frequency</cell><cell></cell></row><row><cell>Human Data</cell><cell>471</cell><cell>441</cell><cell>564</cell><cell>563</cell></row><row><cell cols="2">Standard diffusion model (DM) 491</cell><cell>467</cell><cell>578</cell><cell>602</cell></row><row><cell cols="2">General diffusion model (gDM) 488</cell><cell>480</cell><cell>594</cell><cell>607</cell></row><row><cell></cell><cell></cell><cell cols="2">Low Frequency</cell><cell></cell></row><row><cell>Human Data</cell><cell>510</cell><cell>480</cell><cell>636</cell><cell>653</cell></row><row><cell cols="2">Standard diffusion model (DM) 508</cell><cell>488</cell><cell>644</cell><cell>712</cell></row><row><cell cols="2">General diffusion model (gDM) 502</cell><cell>492</cell><cell>652</cell><cell>711</cell></row><row><cell></cell><cell></cell><cell cols="2">Very Low Frequency</cell><cell></cell></row><row><cell>Human Data</cell><cell>525</cell><cell>498</cell><cell>674</cell><cell>760</cell></row><row><cell cols="2">Standard diffusion model (DM) 518</cell><cell>501</cell><cell>700</cell><cell>770</cell></row><row><cell cols="2">General diffusion model (gDM) 510</cell><cell>499</cell><cell>702</cell><cell>762</cell></row><row><cell></cell><cell></cell><cell cols="2">Nonword</cell><cell></cell></row><row><cell>Human Data</cell><cell>508</cell><cell>488</cell><cell>655</cell><cell>718</cell></row><row><cell cols="2">Standard diffusion model (DM) 502</cell><cell>501</cell><cell>640</cell><cell>754</cell></row><row><cell cols="2">General diffusion model (gDM) 493</cell><cell>516</cell><cell>646</cell><cell>762</cell></row><row><cell cols="5">Note: DM was fit to data (by Ratcliff &amp; Smith, 2004), and gDM was fit to</cell></row><row><cell></cell><cell cols="2">predictions of the DM.</cell><cell></cell><cell></cell></row></table><note>diffusion rate was held equal to its value in the DM (σ = .1), and the growth-rate distributions were held equal between conditions, reflecting SI2. The growth-rate distribution for each stimulus was fit nonparametrically (using a discrete set of uni- formly spaced growth rates), under a strict requirement for unimodality as well as an L2 penalty that encouraged smoothness.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table IV .</head><label>IV</label><figDesc>Model parameters from fits to Wagenmakers et al. (2008) Experiment 1Modela speed a acc σ v HF v LF v VLF v NW ηz speedzacc δ z T er δ t DM.0855 .1593 .1 .4316 .2749 .1818 -.2566 .1135 .0410 .0774 .0531 .</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>4082 .1430</cell></row><row><cell>gDM .0744 .1584 .1 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-.0324 .0695 0 .4082 .1430</cell></row><row><cell cols="5">Note: Fits of standard diffusion model (DM) are taken from</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>and empirical applications (e.g.,<ref type="bibr" target="#b19">Rae et al., 2014)</ref> that have assumed just such a dependence. Second, no lower bound has ever been proposed on the DM's diffusion rate, and it is incoherent to treat the claim that diffusion is necessary for fitting data as an assumption of the model itself. Moreover, the proposal that within-trial variability is negligible is a theoretically defensible one and indeed was the primary justification for the LBA<ref type="bibr" target="#b0">(Brown &amp; Heathcote, 2005</ref>. Third, the proposal for simple growth-rate distributions is not necessarily a well-founded idea, because one could always reparameterize a model to use a transformation of the growth rate (e.g., define a new parameter equal to ln k or k 2 ). There is no obvious basis for holding that one parameterization is in any sense more psychologically fundamental than another. Notwithstanding these concerns, all three assumptions are amenable to formal definition within the LBA or DM frameworks, and researchers in the field have advocated for them (e.g., Smith et al., 2014), so it is worthwhile exploring their consequences.Under these additional constraints, the models are no longer falsifiable, but it turns out they are still overly flexible to the point of losing theoretical and explanatory value. In particular, the present results show that the theoretically important mechanism of startpoint variability becomes unidentifiable when the Gaussian growth-rate assumption is relaxed to one of unimodality, even when retaining SI2 and adding a lower bound on the DM's diffusion rate. For the standard DM and LBA, with Gaussian growth-rate distributions, startpoint variability is needed to match data, in particular the crossover effect. In contrast, startpoint variability becomes unnecessary under different growth-rate distributions. Thus different distributional assumptions lead to qualitatively different conclusions about the mechanisms necessary for modeling speeded choice behavior.One possible objection to this argument would be to claim that the generalized models derived here are more complex than the standard models. If this claim were correct, then one might have a basis for preferring the latter, and in turn concluding that startpoint variability is essential to modeling data. However, there is in fact no increase in complexity, because the degrees of freedom have not changed between models. The derivations used here constitute a direct translation procedure, in which any instance of a standard model is converted, one for one, to a corresponding instance of the generalized model. Therefore the new model is indexed by the same parameters as is the original model, which is immediately apparent in Equations 15 and 16. Moreover, for both of the generalized models derived in Sections III.1 and III.2, the space of possible predictions is identical to that of the original model (because the models are exactly equivalent). Thus there is no increased flexibility.</figDesc><table><row><cell>Even in the case of Section III.3, where the growth-rate distributions were nonpara-</cell></row><row><cell>metrically estimated (over a lattice of 267 growth rates per stimulus type), the result</cell></row></table><note>depended on the data only via the DM's predictions, and hence only via that model's parameters. Thus the dimensionality of the gDM under the procedure used here is equal to the dimensionality of the DM. Another way to see this is that one could specify the DM-gDM translation in advance of seeing the data, by predetermining the best mimicking gDM (by any desired criterion) for any possible instance of the DM. The space of gDM models generated in this way would necessarily have the same dimensionality as the space of DM models.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">There is a well-known degeneracy of both models' parameterizations, due to the arbitrary scaling of the internal evidence dimension. Consequently the contribution of diffusion in the DM is determined not by the diffusion rate (σ) but by the ratio θ = σ 2 /a 2 , where a is the threshold separation<ref type="bibr" target="#b11">(Jones &amp; Dzhafarov, 2014a)</ref>. For brevity, this paper often refers to constraints on the diffusion rate when the intended meaning is constraints on this ratio.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Note that the forms of the growth-rate distributions below zero are arbitrary; any modification that preserves Pr [k s r ≤ 0] will leave model predictions unchanged, because the accumulator never terminates when its slope is not positive (corresponding to T s,c r = ∞). For simplicity, the distributions are plotted according to the natural analytic extension from the positive domain into the negative domain; that is, according to Equation 15 for all real values of k. This approach also allows the graph to indicate the growth-rate distributions for cases of v s r &lt; 0, under the symmetry explained in the main text.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Negative v s r is allowable for the LBA; it just implies that, on more than half of trials, the accumulator in question will never reach threshold.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5"><ref type="bibr" target="#b24">Ratcliff and Smith (2004)</ref> report this experiment as Experiment 2 in their paper, although the full methodological details appear in Wagenmakers et al. (2008). Wagenmakers et al. fit the same model as Ratcliff and Smith and reported slightly different parameter estimates, and Ratcliff and Smith's fit was arbitrarily chosen as the target for the present analysis. I thank Roger Ratcliff for providing the data.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This appendix derives the growth-rate distributions for the gDM without startpoint variability that exactly mimics the standard DM, for the special case of no diffusion and no response bias (σ = 0,z c = a c /2). Nondecision time is ignored (implicitly treating T er and δ t as zero), because it does not affect equivalence between the models, provided it is distributed identically in both models. That is, if the models make identical predictions for response and first-passage time then they will The latter were approximated by probability weights for a discrete set of 267 equally spaced growth rates ranging v s ± 20η (the parameters from the DM). Because all 42 target measures for each stimulus type are linear with respect to mixtures of the growth-rate distribution, the probability weights for the growth rates could be directly estimated using convex linear regression. This regression step also enforced unimodality, by requiring the weights to be nondecreasing on the left shoulder of the distribution and nonincreasing on the right shoulder, and it encouraged continuity of the distribution by including an L2 penalty (i.e., ridge regression, which discouraged all of the probability going to a few growth rates). Optimization over the four a and z parameters was performed in an outer loop by a generic search routine.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A ballistic model of choice response time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The simplest complete model of choice response time: Linear ballistic accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="153" to="178" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Decision field theory: A dynamic-cognitive approach to decision making in an uncertain environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Townsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="432" to="459" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dynamic stochastic models for decision making under time constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diederich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="260" to="274" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Getting more from accuracy and response time data: Methods for fitting the Linear Ballistic Accumulator model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Averell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1095" to="1110" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Diffusion versus linear ballistic accumulation: Different models for response time, same conclusions about psychological mechanisms?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="140" to="151" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grice-representability of response time distribution families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">N</forename><surname>Dzhafarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="281" to="314" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Linear deterministic accumulator models of simple choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">292</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The falsifiability of actual decision-making models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sequential effects in judgments of loudness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jesteadt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="92" to="104" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modeling sequential effects in decision making via incremental learning in diffusion models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science Society and the Society for Mathematical Psychology</title>
		<imprint/>
	</monogr>
	<note>in preparation. Research presented at the 2014 meetings of the</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unfalsifiability and mutual translatability of major modeling schemes for choice reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">N</forename><surname>Dzhafarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analyzability, ad-hoc restrictions, and excessive flexibility of evidence-accumulation models: Reply to two critical commentaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dzhafarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="689" to="695" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recency effects as a window to generalization: Separating decisional and perceptual sequential effects in category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Maddox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="316" to="332" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimal response initiation: Why recent experience matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kinoshita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. Koller, D. Schuurmans, Y. Bengio, &amp; L. Bottou</editor>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="785" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Information Theory of Choice Reaction Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R J</forename><surname>Laming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Response Times: Their Role in Inferring Elementary Mental Organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The &quot;horse race&quot; random utility model for choice probabilities and reaction times, and its competing risk interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A J</forename><surname>Marley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Colonius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An exemplar-based random walk model of speeded classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="266" to="300" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Hare and the Tortoise: Emphasizing speed can change the evidence used to make decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Averell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1226" to="1243" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A theory of memory retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="59" to="108" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Parameter variability and distributional assumptions in the diffusion model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="281" to="292" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modeling response times for two-choice decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="347" to="356" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A comparison of sequential sampling models for two-choice reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="333" to="367" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Connectionist and diffusion models of reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Zandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="261" to="300" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multialternative decision field theory: A dynamic artificial neural network model of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Roe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Townsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="370" to="392" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The diffusion model is not a deterministic growth model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comment on Jones and Dzhafarov</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The accumulator model of two-choice discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vickers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="135" to="168" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evaluating the unequal-variability and dual-process explanations of zROC slopes with response time data and the diffusion model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Starns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Diffusion model drift rates can be influenced by decision processes: An analysis of the strength-based mirror effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Starns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1137" to="1151" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Models for choice reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="251" to="260" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The elusive tradeoff: Speed versus accuracy in visual discrimination tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Swensson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="16" to="32" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sequential effects in naming: A time-criterion account</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Lupker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="117" to="138" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Generalising the drift rate distribution for linear ballistic accumulators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A J</forename><surname>Marley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barnwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A law of comparative judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Thurstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="273" to="287" />
			<date type="published" when="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Serial and within-stage independent parallel model equivalence on the minimum completion time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Townsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="219" to="238" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A theory of criterion setting with an application to sequential dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="68" to="111" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Information processing models generating lognormally distributed reaction times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="513" to="525" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A comparison of two response time models applied to perceptual matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Zandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Colonius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Proctor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="208" to="256" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A diffusion model account of criterion shifts in the lexical decision task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="140" to="159" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
