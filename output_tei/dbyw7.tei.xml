<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MoralNet: A Benchmarking Protocol for Evaluating Morality in AI Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">MoralNet: A Benchmarking Protocol for Evaluating Morality in AI Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T12:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Artificial intelligence has prompted unprecedented concerns regarding ethical decision-making in autonomous systems. Here, we introduce MoralNet, a proof of concept database and benchmarking platform akin to ImageNet, designed to assess, evaluate, and iteratively refine any instance of ethical decision-making in machines. Inspired by the lessons of moral psychology and moral philosophy, MoralNet is a call to action to take the first step towards a computational ethics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>AI is increasingly embedded in our society's fabric-from healthcare and finance to transportation and security. It is therefore increasingly necessary to talk about machine ethics or computational ethics <ref type="bibr" target="#b1">(Awad et al. 2022)</ref>. Machine ethics or computational ethics is the attempt to implement ethical decision-making capabilities in machines. If machines are present in multiple areas of our lives and different machine learning models and algorithms make decisions that affect people -because we delegate this decision-making to them-it is peremptory that these decisions are made from the point of view of human ethics <ref type="bibr" target="#b0">1</ref> . Although machine ethics or computational ethics is a sub-branch of AI ethics and the latter has been articulated in various programmes and projects for more than a decade, there is still no ambitious attempt to take the "bull by the horns", sort of speak. That is, in addition to defining, clarifying the conceptual space and methods, how do we begin to implement morality in machines? We need to have a clear roadmap and stop offering only conceptual clarifications and definitions of this new area called AI ethics.</p><p>As AI is becoming an ever-more pervasive element in daily existence, leading to an expanding array of interactions between humans and AI entities, AI ethics exist to deal with all conundrums which will arise. One of these conundrums is what to expect of 'hybrid societies,' a milieu where both human and algorithmic actors co-exist and engage. In this article, taking inspiration from the successful ImageNet competition <ref type="bibr">(Deng et al. 2009</ref>)-that has enabled a qualitative leap in computational vision-or the biannual competition-called "Critical Assessment for Structure Prediction (CASP)" (Lattman 1995)-we propose a similar competition, but for the implementation of ethical decision-making in machines that we call MoralNet.</p><p>With MoralNet we aim to legitimize one of the great challenges of science: how to assess whether a machine learning system understand human ethical judgement or even makes moral judgements for itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Background</head><p>Substantial effort has taken place in philosophy to engage with the notion of ethical machine learning, machine ethics or computational ethics. Since Alan Turing proposed the Turing Test as a metric to assess a machine's ability to emulate human-like behavior, many others capitalizing on this idea have proposed the moral Turing test (MTT) as a framework for evaluating the moral performance of autonomous systems <ref type="bibr" target="#b12">(Wallach and Allen 2008)</ref>. Before that, Asimov put forth the triad of robotic laws to serve as a foundational guideline for machine conduct (1941). Furthermore, Bostrom contends that an exclusive focus on problem-solving capabilities in machines could yield unintended and disastrous outcomes, such as the hypothetical paperclip maximizer scenario <ref type="bibr" target="#b4">(Bostrom 2014)</ref>. Alongside these seminal works, various other scholarly inquiries in the realm of philosophy, moral psychology, etc.</p><p>have delved into the ethical conundrums posed by AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">The Importance of morality in AI</head><p>The ethical performance of autonomous systems is not a fringe academic concern, but a core dimension of functionality that is critical to societal acceptance and responsible deployment of AI systems. While mathematical optimization and data-driven decision-making lie at the heart of AI, these systems are increasingly taking on roles that demand more than just accuracy and efficiency; they require moral insight-a nuanced understanding and integration of ethical principles in the decision-making process.</p><p>As artificial intelligence systems become more advanced and integrated into our lives, it is crucial that they be aligned with human values and morals. AI has the potential to greatly benefit society, but without an ethical framework, it also runs the risk of causing unintentional harm. A key reason morality matters in AI is because these systems are optimized to achieve goals. An AI that is highly competent but lacks morality could lead to disastrous consequences if its objectives are unintentionally misaligned with human values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Objectives</head><p>In this work, we offer a theoretical exposition of MoralNet. By MoralNet, we mean the grand scientific challenge to crack the moral code problem in machines. The one who provides a viable AI technique-be it a deep generative neural network or any other AI method-for implementing morality into artificial systems shall claim the prize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Organization</head><p>The rest of the paper is organized as follows: Related work section reviews related works across disciplines that have shaped the discourse on moral cognition in both humans and AI. MoralNet  But what sets MoralNet apart from these two proposals is that MoralNet wants to become morality's ImageNet moment and cracks one of the grand challenges of science and philosophy that have vexed humanity for millennia.</p><p>To this end, MoralNet proposes a series of protocols for adversarial teams to collaborate in establishing the criteria to be met to assess whether an algorithm, neural network or any other AI technique overcomes a series of moral dilemmas and is capable of making a moral judgement similar to that of a human being.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Moral psychology and human decision-making</head><p>Moral psychology studies the basic psychological processes behind moral behaviour and moral decision-making (Gray and Graham 2019). Although the study of the psychological mechanisms of moral behaviour is still in its infancy, empirical and theoretical studies are pointing to the fact that we need to distinguish between different types of emotional, intuitive, reflective and rational processes that underlie human moral cognition. Additionally, moral decision-making can be impacted by individual preferences for moral strategies, relationships with others, and even unconscious biases. Overall, the research in moral psychology and human decision-making suggest that ethical judgments arise from a multifaceted integration of internal values, situational norms, social considerations, and both conscious and unconscious thinking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Theories in moral philosophy</head><p>Moral philosophy has been around for millennia, certainly much longer than moral psychology, having as its object of study the question of why we act the way we do. During all this time, it has generated different ethical theories that many consider describing human anthropology in its entirety.</p><p>There are three moral philosophical theories par excellence: virtue ethics, deontologism and utilitarianism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">AI ethics and machine learning systems</head><p>AI ethics (the umbrella term where we include computational ethics or machine ethics) cannot be reduced to a checklist or a static set of guidelines; it is a dynamic discourse involving technologists, ethicists, policymakers, and the broader public. To think about AI ethics is to engage in a continuous dialogue that reflects the evolving complexity of both technology and human values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Limitations in current approaches</head><p>We mentioned above some attempts to offer ways forward in computational ethics. They are valuable contributions and attempts but the field, say, computational ethics, needs a larger-scale, multimodal dataset that provides fine-grained, nuanced morality annotations across diverse situations and moral foundations and all of this carried out by teams of adversaries collaborating on the basis of a set of rules and criteria that produce performance metrics.</p><p>This could inspire bold new models and benchmarks to significantly advance research into computational ethics or AI ethics broadly speaking, much like ImageNet did for computer vision. But it will require a concerted community effort, and this is what MoralNet stands for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MoralNet conceptual framework</head><p>The MoralNet conceptual framework should not remain confined merely to the plane of normative ethics, which tells us how we ought to act. Instead, it should possess a meta-ethical layer that scrutinizes the semantic, epistemic, and ontological dimensions of moral judgments. This is essential because machines, unlike humans, do not possess moral intuitions that implicitly navigate this complex landscape</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Philosophical underpinnings</head><p>The philosophical framework should be infused with insights from cognitive science, social psychology, and even neuroscience. For instance, aspects of social cognition can offer insights into the dynamics of collective moral reasoning, an area scarcely covered in AI ethics. AI trained on this enriched data could perform a more nuanced "social moral calculus", incorporating elements like group dynamics, emotional contagion, and even societal structures like power relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Psychological foundations</head><p>The psychological principles that underpin the MoralNet competition are essential for understanding how machine ethics or computational ethics could ever approximate human-like moral competence.</p><p>We need the algorithms, models that participate in MoralNet to be based on theories <ref type="bibr">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Design Principles</head><p>MoralNet could be designed around key ethical principles from moral philosophy to provide a foundational taxonomy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MoralNet database</head><p>MoralNet dataset could be organized into broad virtue ethics categories like wisdom, courage, humanity, justice, temperance, and transcendence. Each virtue can have sub-categories covering more specific morally relevant concepts like honesty, loyalty, greed, deceit, patience, etc. Or it can be organised in terms of utility or consequences of our actions or rules.</p><p>In the MoralNet Competition, a multimodal database could serve as an invaluable resource for assessing and improving machine ethical decision-making across different sensory modalities and communicative formats. This database would stand apart from conventional text-only or image-only datasets by encompassing a more holistic array of data types, including text, images, audio clips, video footage, and perhaps even sensorimotor data like haptic feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data sources</head><p>This dataset will comprise various case studies and moral dilemmas that span the domains of justice theory, deontological ethics, virtue ethics, utilitarian perspectives, and common sense morality and as we say it could have a multimodal format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data annotation</head><p>Given the heterogeneity of moral judgments, the annotation process should aim for granularity.</p><p>Trained annotators could assess situations based on their reflection or violation of particular values, virtues, rules, etc., rating them on a continuous scale. The data itself could be richly multi-modal, spanning images, videos, texts, dialogues, and more to ensure a holistic understanding of complex ethical situations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Benchmarking protocols</head><p>Benchmarking protocols for MoralNet presents an academic and technical challenge unprecedented in scale and complexity. This is why we invite a biannual competition similar to ImageNet and CASP for teams of adversaries who previously agree on a set of rules and criteria to try to implement moral decision-making capabilities in machines.</p><p>While traditional machine learning benchmarks like ImageNet primarily deal with quantitative measures, MoralNet involves variables that are both quantitative and qualitative, often resistive to easy parameterization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Protocol A: Basic moral competence</head><p>Experiments in machine learning for moral reasoning necessitate a balanced performance metric.</p><p>Classical metrics such as accuracy, precision, and recall could be complemented by measures of philosophical rigor-perhaps a 'Morality Score' that assesses the depth of ethical engagement of machines. When we speak of 'basic moral competence' in machines, the criteria and metrics of assessment necessitate an interplay between computational rigour and philosophical depth.</p><p>We need to build a multi-metric assessment framework aims to provide a nuanced yet robust evaluation, laying the groundwork for subsequent, more complex moral reasoning tasks. MoralNet could be the platform to get this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Protocol B: Real-world decision-making</head><p>One of the defining challenges in machine morality, particularly for MoralNet, is the extrapolation of laboratory-calibrated algorithms to real-world situations. The dynamic complexity of these scenarios demands an evaluation protocol far beyond traditional machine learning benchmarks. Protocol B aims to be this evaluative mechanism, facilitating a complex, multi-layered, and contextually grounded assessment of models competing on MoralNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Challenges and a call to action</head><p>MoralNet can combine both philosophical rigour and technical accuracy in order to advance computational ethics. Metrics that adequately capture moral reasoning pose a unique challenge. MoralNet can combine both philosophical rigor and technical accuracy in its performance metrics and achieve an "ImageNet moment for ethics". The conception of MoralNet that we present here finds its inspirational parallel in ImageNet, the vast dataset that revolutionized computer vision through its robust taxonomy and scale.</p><p>MoralNet database has to be multimodal, and the annotation process is much more complicated than in other benchmarking attempts or protocols (e.g. ImageNet) However, if the teams or researchers participating in MoralNet are able to build their models or algorithms on the basis of the psychological substrates of moral reasoning within a machine learning framework we can be confident and optimistic that we will succeed in cracking the moral code in machines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>conceptual frameworkdelves into the conceptual framework of MoralNet, discussing its philosophical underpinnings and psychological foundations. MoralNet database section outlines the specifics of the MoralNet database, from data sources to annotation processes. Benchmarking protocols section details the benchmarking protocols designed to assess ethical decision-making in machines. Finally, Challenges and future work section looks at challenges and future directions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2</head><label>2</label><figDesc>Related workTo be honest, there are several attempts to create a moral benchmarking protocol that seek to recreatemoral decision-making in machines. For example, Jeong et al. (2022) trained a model to predict textual immorality using the ETHICS dataset, then applied a novel zero-shot visual immorality prediction method using CLIP image-text embedding. Ziems et al. (2022) introduced the Moral Integrity Corpus (MIC), a new dataset for evaluating the social and moral reasoning of conversational AI systems.Both proposals aimed to advance research into developing AI systems with ethical reasoning abilities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>The research in moral psychology and human decision-making implies that making moral choices involves both internal cognitive processes, like emotionally-driven moral identity formation, as well as external contextual factors, such as flexible moral principles and social elements (Young and Saxe 2008; Baar, Chang and Sanfey 2019).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>or research programs and/or facts) such as Dual-Process Theory (Kahneman 2011), empathy research (Baron-Cohen 2012), heuristic and biases (Tversky and Kahneman 1974), Moral Foundations Theory (Graham et al. 2013), theory of mind (Premack, and Woodruff 1978), etc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>While</head><label></label><figDesc>ImageNet relies on simpler annotation schemes-usually bounding boxes around objects and categorical labels-MoralNet's annotation layer is intrinsically more complex. It must capture not just what is depicted, but also the moral weight of the situation. A continuous scale, handled by expert annotators grounded in moral philosophy, moral psychology and cognitive sciences, provides nuanced labelling that accommodates the complex subjectivity inherent in ethical judgments.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Let us not forget that it is also possible that in addition to one day being able to implement ethical decisionmaking in machines aligned with our values, it is also possible that in the not too distant future a complete ex novo human-machine ethic will emerge.Submitted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023). Do not distribute.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We cordially invite scholars and researchers in moral psychology, moral philosophy, and cognitive science to engage and promote the birth of the MoralNet competition-an endeavor aimed at implementing ethical reasoning capabilities into artificial intelligence systems.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Three laws of robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Asimov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1941" />
		</imprint>
	</monogr>
	<note>Runaround</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Computational ethics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Awad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="388" to="405" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The computational and neural substrates of moral strategies in social decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanfey</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-019-09161-6</idno>
		<ptr target="https://doi.org/10.1038/s41467-019-09161-6" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The science of evil: On Empathy and the Origins of Cruelty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baron-Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Basic books</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bostrom</surname></persName>
		</author>
		<title level="m">Superintelligence: Paths, Dangers, Strategies. Oxford</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Moral foundations theory: The pragmatic validity of moral pluralism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Experimental Social Psychology</title>
		<editor>Patricia Devine and Ashby Plant</editor>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="55" to="130" />
			<date type="published" when="2013" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Atlas of Moral Psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename></persName>
		</author>
		<editor>J.</editor>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Guilford Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jeong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.05521</idno>
		<title level="m">Zero-shot Visual Commonsense Immorality Prediction</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Thinking, Fast and Slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Farrar, Straus and Giroux</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Judgment under uncertainty: Heuristics and biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">4157</biblScope>
			<biblScope unit="page" from="1124" to="1131" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Protein structure prediction: A special issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lattman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PROTEINS: Structure, Function, and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<title level="m">Moral machines: Teaching robots Right from Wrong</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The neural basis of belief encoding and integration in moral judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saxe</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1912" to="1920" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ziems</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.030216</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
