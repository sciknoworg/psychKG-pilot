<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Social Decision Making with Humans and Robots: Trust and Approachability Mediate Economic Decision Making</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Tulk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">George Mason University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Wiese</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">George Mason University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Social Decision Making with Humans and Robots: Trust and Approachability Mediate Economic Decision Making</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>As humanoid robots become more advanced and commonplace, the average user may find themselves in the position of wondering if their robotic companion truly possesses a mind. It is important for scientists and designers to consider how this will likely affect our interactions with social robots. The current paper explores how social decision making with humanoid robots changes as the degree of their human-likeness changes. For that purpose, we created a spectrum of human-like agents via morphing that ranged from very robot-like to very human-like in physical appearance (in increments of 20%) and measured how this change in physical humanness affected decision-making in two economic games: Ultimatum Game (Experiment 1) and Trust Game (Experiment 2). We expected increases in human-like appearance to lead to a higher rate of punishment for unfair offers in the Ultimatum Game, and to a higher rate of trust in the Trust Game. While physical humanness did not have an impact on economic decisions in either of the experiments, follow-up analyses showed that both subjective ratings of trust and agent approachability mediated the effect of agent appearance on decision-making in both experiments. Possible consequences of these findings for human-robot interactions are discussed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>While some still believe that a world filled with robots is still a distant science fiction dream, social robots are already becoming incorporated in our society <ref type="bibr" target="#b7">(Fortunati et al., 2015)</ref>. Aside from entertainment purposes, social robots are desirable for their ability to assist clinicians in providing specialized care <ref type="bibr" target="#b16">(Rabbitt et al., 2015;</ref><ref type="bibr" target="#b2">Costa et al., 2015)</ref>, as well as constant care within individual users' homes <ref type="bibr" target="#b20">(Zaga et al., 2017)</ref>. Social robots could also be used as teachers and personal assistants at home and work, or public assistants in environments such as stores or airports. However, not all people view these potential expansions positively <ref type="bibr" target="#b6">(Flandorfer, 2012;</ref><ref type="bibr" target="#b1">Bartneck &amp; Reichenbach, 2005;</ref><ref type="bibr" target="#b17">Scopelliti et al., 2005)</ref>. It is possible that some users are not ready to accept social robots as proxies for human interaction partners in certain domains. However, just as humans have developed relationships with computers and smart phones which have become commonplace in most aspects of life, it is possible that humans will adjust to our new counterparts as they become further embedded into our world. The way we adjust to social robots, and the relationships we develop with them will likely be affected by a robot's perceived capacity as a social agents and how likely it is that people perceive them as being capable of having a mind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mind perception and Rationality</head><p>What does it mean to possess a mind? To reach a verdict of whether or not we believe an entity possesses a mind, there are two dimensions these entities are judged on: experience (awareness and the capacity to feel), and agency (the capacity to think and choose for oneself) <ref type="bibr" target="#b8">(Gray et al., 2007)</ref>. Where adult humans are seen as possessing high experience and agency, suggesting that they are naturally perceived as possessing a mind, typical robots are seen as having some agency and low experience. One way for non-humans to gain perceived experience would be to design them to emulate humanlikeness (in appearance or behavior) in order to increase the likelihood that people attribute human-like characteristics and intentions to these non-human agents through anthropomorphism, and are therefore more likely to perceive them as rational social agents who are capable of having and carrying out intentions as a human can. It has been shown that perception of a robot as a social agent is facilitated by humanlike appearance <ref type="bibr" target="#b10">(Kiesler et al., 2008;</ref><ref type="bibr" target="#b11">Looser and Wheatley, 2010;</ref><ref type="bibr" target="#b0">Admoni et al., 2011;</ref><ref type="bibr" target="#b14">Martini, Gonzalez &amp; Wiese, 2016)</ref>, and/or behavior <ref type="bibr">(Morewedge, 2009;</ref><ref type="bibr" target="#b18">Waytz et al., 2010;</ref><ref type="bibr" target="#b18">Short, Hart, Vu &amp; Scassellati, 2010;</ref>; see <ref type="bibr" target="#b20">Wiese et al. (2017)</ref>; for a review. Importantly, perceiving a social agent as humanlike can cause them to be seen as entities that deserve to be treated respectfully and fairly <ref type="bibr" target="#b5">(Epley et al., 2007)</ref>, therefore perception of human-likeness may also affect social decision making with social robots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Economic Games and Decision-Making</head><p>Behavioral Economics has adapted iconic 2-person interaction models from Game Theory (frequently called "economic games") in order to study social decision making in the presence of external motivation. A typical implementation leads individuals to try to maximize personal gains while coordinating with another player. In the Ultimatum Game (UG), Player 1 first decides how to split up some amount of money with a partner and making an offer to Player 2. Player 2 then decides to either accept the offer (each player ends up with the split Player 1 proposed), or reject the offer (each player ends up with nothing). A truly "rational" decision would be for player 2 to always accept any offer above $0, since any amount above $0 is still a gain. However, people will often reject offers they perceive as unfair as a means of punishing Player 1 for this unfairness <ref type="bibr" target="#b13">(Luce &amp; Raiffa, 2012)</ref>. A neuroimaging study <ref type="bibr" target="#b16">(Sanfey et al., 2003)</ref> had participants play the UG where they responded to offers made by players who they believed to be either a human or a computer. Unfair offers from the computer were rejected less than unfair offers from the human partners, and unfair offers from the human partners resulted in stronger activation in the bilateral anterior insula, a region associated with the feeling of disgust, than did the unfair offers from the computer. This suggests that a violation in fairness from a non-human results in less negative emotions as well as less impulse to punish this unfairness. It is possible that since the computer is not seen as having a mind, unfair offers from the computer occur randomly without any inten-tion to present something unfair, which doesn't produce strong emotions. A follow up study incorporated facial expressions of a social avatar, which was assumed to be controlled either by a human or a computer, in order to manipulate the belief of emotions and intent with regard to fairness in economic games <ref type="bibr">(DeMelo, 2015)</ref>. While people responded in the same way to emotional displays from humans and computers, humanness has a stronger impact on social perceptions and decisionmaking. That raises the possibility that robots are treated as human like social agents, but ones whose feelings are less compelling than those of other humans.</p><p>When engaging in a social decision making task with a robot, it is possible that people adopt the same trust model as with human-human interactions, but that different qualities are used to judge trustworthiness or fairness in robots than those used to judge humans. Given this uncertainty, when playing the Trust Game with robots, some chose to interact with robots in order to better understand how to treat them <ref type="bibr">(Mota et al., 2016)</ref>. This suggests that while the human trust model may be adopted as a default, people might seek information about robots in order to update their model. It is important for researchers and designers to investigate how users form their human-robot trust models and how this impacts social perception and treatment of robotic agents.</p><p>This study attempts to understand how the degree of humanlike appearance affects social perception of agents and strategies for interacting with agents in social decision tasks, specifically repeated Ultimatum Games and Trust Games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS &amp; MATERIALS Experiment 1: Ultimatum Game (UG)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were recruited and participated via Amazon's Mechanical Turk (MTurk) website and were paid $0.30 for approximately 30 minutes of participation. The only qualification for participation was that participants be at least 18 years old and currently residing in the United States. There were 52 individuals that had participated in Experiment 1 (29 women, mean age: 37 years old). 10 participants were excluded from Experiment 1 for responding with the same answer for at least 63 of 64 trials (4 practice and 60 real).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Apparatus</head><p>This experiment was conducted online through MTurk. The experiment was programmed in javascript via an open source plugin to the Qualtrics survey site, called the QRTEngine <ref type="bibr" target="#b1">(Barnhoorn et al., 2015)</ref>. The QRTEngine allowed for precise timing of stimuli presentation, RT recording and also provided a speed test for individual computers to ensure that timing was accurate and reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>The stimuli for this experiment were a series of 6 images of faces that were robotic, human, or somewhere in between. The robot face that was used came from a Meka humanoid robot head. The human face was obtained with full permission from a 35 year-old female volunteer. Morphing software was used to create the spectrum from 100% robotic (i.e., 0% human) to 100% human with 20% increments. These faces constituted 6 agents whom participants interacted with throughout the experiment.</p><p>For each trial in experiments 1 and 2, an agent would make an offer of how to divide a sum of $10 between them-selves and the participant. The offers made by each agent were fixed (consistent with Sanfey paper) such that each agent made an offer of $5 five times (i.e., totally fair: "I get $5, you get $5"), $3 (somewhat fair) one time, $2 (somewhat unfair) two times and $1 (totally unfair) two times, for a total of 10 offers from each of the 6 agents. All subjects saw a random presentation of all 60 trials (within subjects design).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Upon navigating to our experiment from the MTurk site, an Internet connectivity test was conducted to verify that the participant's computer had adequate signal to ensure accurate results. Once this verification was complete, participants gave informed consent and completed a basic demographic questionnaire (including age, native language and education). Participants were then instructed to ensure that they were in a quiet room without distraction, and to maximize the browser window to fill their entire screen.</p><p>Participants first completed 4 practice rounds with only the 100% human and 100% robot images, each presenting the totally fair ($5, $5) offers twice. For the practice trials, participants first saw the expression "New Game" in the center of the screen for 2 sec, followed by the words "Player 1:" in red text (which they were informed would only be present during the practice trials) for 2 sec. Next, the image of the agent was presented in the center of the screen for 5 sec. After this, the words "Player 1 says" in red text (also only present during the practice trials) was presented above the offer that was made by the agent for that trial (presented in black text in in center screen) for 4 sec. Next, the words "Player 2:" was presented in red (only for the practice blocks) for 2 sec. On the next screen, the participant saw the text "Press "a" to accept, or press "l" to reject"; participants would only proceed to the next screen after responding, and the Reaction Time (RT) and response were recorded. Finally, participants were shown the outcome for 1.5 sec: either the same offer shown to them previously in the trial if they chose to accept the offer, or, "I get $0, you get $0", if they chose to reject the offer, and the next trial would begin. Once the practice block was completed, participants had a second chance to review the instructions before beginning the experimental block. The experimental block consisted of a random presentation of all agents and offers with the same trial sequence as the practice block, except that the red text was removed in order to simplify the display once the rules had been learned. After the experimental block, participants explicitly rated each of the 6 agents (from 1 -7) on how trustworthy they believed the agents to be (Trust) and how readily they would approach each agent (Approachability). Every trial begins with the presentation of the words "New Game" for 2 sec, followed by the image of the agent for 5 sec. Next, the offer is presented as a statement coming from the agent, displayed for 4 sec. Participants then respond with "A" to accept or "L" to reject. After the response, the result (either the same proposed amounts or $0, $0) is displayed for 1.5 sec. This sequence is repeated 60 times over the experimental block. Presentation of agents and offers are random.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2: Trust Game (TG)</head><p>Participants 46 individuals participated in Experiment 2 (29 women, mean age: 40 years old). As with experiment 1, participants were recruited and participated via MTurk and were paid $0.30 for approximately 30 minutes of participation. The only qualification for participation was to be at least 18 years old and currently residing in the United States. 8 participants were removed for responding with the default answer on more than 90% of trials. <ref type="figure">Figure 2</ref>. Trial Sequence in the TG: Every trial begins with the presentation of the words "New Game" for 2 sec, followed by the image of the agent for 5 sec. Next, the offer is presented as a statement coming from the agent, displayed for 4 sec. Participants then see the tripled offer and indicate how much they wish to return by dragging the slide rule and pressing the space key. This sequence is repeated 60 times over the experimental block. Presentation of agents and offers are random.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Experiment 2 had the same agents, offers and trail format except that they played the Trust Game, where instead of simply accepting or rejecting the offer that player 1 made, participants chose an amount of money to return to player 1 after that offer was tripled (as is a typical setup with the trust game). Participants can then choose to return any integer amount from $0 -3 x Player 1's offer, knowing that they kept the remainder of what they did not return to player 1 (i.e., if Player 1 offered $3, the participant can offer to return anything from $0-$9. If they offer $1, they keep $8). This response screen showed the tripled offer with the text "Please indicate how much to return:", above a horizontal slider scale which the participant could move right or left to indicate how much of the endowment to keep and to return to player 1. The relative amounts to keep and to return were displayed above the slider and were automatically adjusted as the slider was moved left or right. Participants would press space once they indicated the desired response via the slider, and begin the next trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANALYSIS Ultimatum Game</head><p>For the decisions to accept or reject offers made by the 6 agents, two way ANOVAs were used to investigate the relationship between agent appearance, fairness of the offer and the mean number of trials that were accepted. Two way repeated measures ANOVAs were also used to determine the relationship between RT, appearance and offers. T-tests were used to compare explicit ratings of trust and approachability for each of the agents. As a follow-up analysis, a Sobel test using regression was conducted to determine if trust and approachability mediated the relationship between appearance and response or RT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trust Game</head><p>Two-way repeated measures ANOVAs were used to analyze the effect of appearance and fairness on the amount of the tripled offer participants decided to return to P1. For RT data, all trials where participants returned $0 were excluded (mouse task was avoided thus the RT was much shorter), and repeated measures ANOVAs were again used to determine the impact of appearance and fairness on RT. Again, t-tests were used to compare explicit ratings of trust and approachability for each of the agents and mediation analyses were conducted to determine if trust and approachability mediated the effect of appearance on response or RT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ultimatum Game (UG)</head><p>Data was filtered by RT, where trials that were more than 2 standard deviations above the mean RT, or faster than 100 ms were pairwise deleted. This was done to remove trials where participants may not have been paying attention, since they were at home and not in a lab setting. This brought the number of total observations from 2520 to 2406. For responses, offer significantly affected the mean number of offers that were accepted (F(1,976) = 946.44, p &lt; .001) but agent appearance did not (F(1,976) = 0.15, p = 0.979). Appearance affected explicit ratings of trust (t(251) = -3.7, p = .002) and approachability (t(251) = -2.11, p = .036), and on further analysis, approachability significantly affected the mean acceptance of offers (F(1,248) = 6.16, p = .014), though trust did not (F(1, 248) = 0.23, p = .635). While ratings of trust and approachability seem to have similar trend with visual inspection (see <ref type="figure" target="#fig_1">Figure 3</ref>), they are only marginally correlated (t(251) = -1.76, p = .079). A Sobel mediation test indicated that approachability mediated the effect of appearance on mean offer acceptance (z' = 2.36, p = .018).</p><p>RT for each response was not significantly affected by agent (F(1,2398) = 0.76, p = .383) or offer (F(1,2398) = 2.25, p = .134). Approachability had a significant effect on RT (F(1,2398) = 7.66, p = .006) and was determined to mediate the relationship between appearance and RT (z' = 2.84, p = .005). Each dot represents a rating of approachability given to 1 of the 6 agents and the average % of offers from the agent that were accepted. The red line is the linear best fit line, which has a positive slope. (B) Explicit ratings of trust and approachability over the percent of humanlikeness for the 6 agents in the UG. While the overall trends are similar, there is only a marginal correlation between trust and approachability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trust Game (TG)</head><p>Data was filtered by the total overall amount of money that was returned to Player 1. Participants who chose to return $0 on a significant amount of trials were excluded from analysis, or those whose overall returns were outside the 1st quartile. A total of 8 participants were removed, bringing the number of participants to 35. Again, RT was log transformed to normalize the data. The amount of money returned to P2 was significantly correlated with offer (F(1,2092) = 474.81, p &lt; .001) but not agent appearance (F(1,2092) = 1.42, p = .234). Again, trust (t(209) = 19.80, p &lt; .001) and approachability (t(209) = 19.90, p &lt; .001) were significantly correlated with agent appearance. Trust and approachability were significantly correlated (t(209) = 2.53, p = .012). Trust significantly impacted the amount returned to P2 (F(1,2092) = 19.47, p &lt; .001), but approachability did not (F(1,2092) = .04, p &lt; .847). A Sobel test did not show that trust mediated the effect of appearance on amount returned (z' = 1.16, p = .245). A boxplot is overlaid on each rating level. Each dot represents a rating of trust given to 1 of the 6 agents and the average dollar amount of the tripled offer from the agent that was returned. The red line is the linear best fit line, which has a positive slope. (B) Explicit ratings of trust and approachability over the percent of humanlikeness for the 6 agents in the TG. While the overall trends are similar, there is only a marginal correlation between trust and approachability.</p><p>Offer impacted RT (F(1,2092) = 4.44, p = .035), but agent did not (F(1,2092) = 0.12, p = .734). When all returns of $0 were excluded (significantly faster responses since there was no need to use the mouse), offer (F(1,1214) = 3.25, p = .021), still significantly impacted RT but agent did not (F(1, 1214) = 1.51, p = .219). Trust significantly impacted RT (F(1, 1214) = 4.84, p = .028), but approach did not (F(1,1214) = 4.84, p = .028). There was a significant interaction between trust and approachability (F(1,1214) = 3.90, p = .049). A Sobel mediation test indicated that trust mediated the effect of appearance on RT (z' = 2.25, p = 0.024).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>The goal of this study was to investigate how humanlike appearance affected people's treatment of agents in social decision making tasks. We hypothesized that increased humanlikeness would result in a greater expectation of fairness and more punishments for unfair offers (i.e., rejecting unfair offers in the UG or offering unfair returns in the TG), but the results show that the story is not so straightforward. In both games, participants made the distinction between fair and unfair offers from Player 1, but degree of human-like appearance did not uniformly impact participants' decisions or the time it took to make these decisions. Instead, after having the same exposure and overall experience with each agent in the experimental block, participants' explicit levels of trust and approachability were rated significantly differently for each agent, on average increasing with humanlikeness. In a follow up analysis, it was determined that the more approachable an agent was perceived to be, the more offers were accepted in the UG and the less time it took to respond, and the more participants trusted the agent, the higher their overall returns were in the TG, and the more time it took to respond. This suggests that treatment of agents in social decisions (either in the decision or how much time it takes to make the decision) varies by how much individuals perceive that they can trust different agents and how approachable they perceive agents to be, and humanlikeness is one factor that affects these perceptions. Demonstrable evidence of mediation was found in both games.</p><p>In this study, measurements of trust and approachability were taken after participants had experiences with each agent to draw from. It is possible that the negative experience of being presented with unfair offers is more salient for agents who are on the perceptual threshold of being sufficiently human, and that these experiences are closely attended to in order to understand how to treat the agent in future interactions, which potentially affected explicit ratings after the experimental block. It is also possible that paying more attention to unfair offers caused participants to make judgements about these agents early on, which could have impacted their performance more strongly over the block. This could be further explored by asking for pre and post ratings of trust and approachability and determining if these ratings change after playing some economic game.</p><p>It is possibly meaningful that approachability mediated response and RT in the UG while trust mediated the RT in the TG. While the overall trends of trust and approachability for the 6 agents are similar in both games, the concept of approachability is more superficial than trust. Since making decisions in the UG (accept fair offers and reject unfair ones) is simpler than deciding a fair amount to return in the TG, it's possible that the TG required more consideration of the agent since participants were required to consider if and how fairly they should act towards the agents, possibly even considering that Player 1's perception of fairness from the participant could affect what offers they would receive in the future. In this case, feeling like the agent was trustworthy might inspire empathy that resulted in more consideration of true fairness.</p><p>Overall, it is important to consider how human-robot trust models develop as people have more experiences with robots to draw from. If users begin to have more experience to draw from, it is unclear how the resulting model will differ from the human-human trust model. If the human-robot model is generalized to all interactions a person has with robots, the overall success of social robotics as a mainstream technology might be impacted by the initial experiences users have. Furthermore, while individual humans have developed tendencies towards fairness and honesty in order to exist harmoniously within society, a robot will not necessarily have the same motivations. Since robotic interfaces are intentionally developed by humans, the designer has the power to make honest robots to benefit others, or deceptive ones that can take advantage of other people, for instance, by spreading misinformation or attempting to trick users into giving away private information. To address this concern, future work will attempt to address how well people can detect deception and other untrustworthy qualities from agents as humanlikeness varies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Trial Sequence in the UG:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>(A) Average amount of offers accepted by participant over approachability ratings in the UG. A boxplot is overlaid on each rating level.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>(A) Average amount returned to Player 1 by participant over trust ratings in the TG.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robot gaze does not reflexively cue human attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Admoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scassellati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual Conference of the Cognitive Science Society</title>
		<editor>L. Carlson, C. Hölscher, and T. Shipley</editor>
		<meeting>the 33rd Annual Conference of the Cognitive Science Society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1983" to="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">QRTEngine: An easy solution for running online reaction time experiments using</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Barnhoorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Haasnoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Bocanegra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Van Steenbergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bartneck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reichenbach</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhcs.2004.11.006</idno>
		<ptr target="doi:10.1016/j.ijhcs.2004.11.006" />
	</analytic>
	<monogr>
		<title level="j">Qualtrics. Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="179" to="192" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Int. J. Hum. Comput. Stud.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using a humanoid robot to elicit body awareness and appropriate physical interaction in children with autism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of social robotics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="265" to="278" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Importance of Cognition and Affect for Artificially Intelligent Decision Makers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Carnevale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="336" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Humans versus Computers: Impact of Emotion Expressions on People&apos;s Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Carnevale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="136" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On seeing human: a three-factor theory of anthropomorphism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Epley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Waytz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Cacioppo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">864</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Population ageing and socially assistive robots for elderly persons: the importance of sociodemographic factors for user acceptance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Flandorfer</surname></persName>
		</author>
		<idno type="DOI">10.1155/2012/829835</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Popul. Res</title>
		<imprint>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Introduction to the special issue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fortunati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lugano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Beyond industrial robotics: Social robots entering public and domestic spheres</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dimensions of mind perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Wegner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5812</biblScope>
			<biblScope unit="page" from="619" to="619" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cooperative and competitive behavior in mixed-motive games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Gallo</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Mcclintock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Conflict Resolution</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="78" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Anthropomorphic interactions with a robot and robot-like agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kiesler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Fussell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torrey</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<idno type="DOI">10.1521/soco.2008.26.2.169</idno>
	</analytic>
	<monogr>
		<title level="j">Soc. Cogn</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="169" to="181" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The tipping point of animacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Looser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wheatley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">How, when, and where we perceive life in a face</title>
		<idno type="DOI">10.1177/0956797610388044</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1854" to="1862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Games and decisions: Introduction and critical survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Raiffa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Courier Corporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Seeing Minds in Others-Can Agents with Robotic Appearance Have Human-Like Preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Martini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0016796</idno>
	</analytic>
	<monogr>
		<title level="m">PloS one</title>
		<editor>e0146310. Morewedge, C. K.</editor>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="535" to="545" />
		</imprint>
	</monogr>
	<note>Negativity bias in attribution of external agency</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C R</forename><surname>Mota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Le Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sharlin</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Integrating socially assistive robotics into mental healthcare interventions: Applications and recommendations for expanded use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ieee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Rabbitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kazdin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scassellati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Sanfey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Rilling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Nystrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot and Human Interactive Communication (RO-MAN)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1755" to="1758" />
		</imprint>
	</monogr>
	<note>Science</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Robots in a domestic setting: a psychological approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scopelliti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Giuliani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fornara</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10209-005-0118-1</idno>
	</analytic>
	<monogr>
		<title level="j">Univers. Access Inf. Soc</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="146" to="155" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Making sense by making sentient: effectance motivation increases anthropomorphism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Short</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scassellati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ieee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Waytz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Morewedge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Epley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monteleone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Cacioppo</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0020240</idno>
	</analytic>
	<monogr>
		<title level="m">Human-Robot Interaction (HRI), 2010 5th ACM/IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2010-03" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="410" to="435" />
		</imprint>
	</monogr>
	<note>No fair!! an interaction with a cheating robot</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What we observe is biased by what other people tell us: beliefs about the reliability of gaze behavior modulate attentional orienting to gaze cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zwickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Müller</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0094529</idno>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>PLoS ONE</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Simple Nod of the Head: The Effect of Minimal Robot Movements on Children&apos;s Perception of a Low-Anthropomorphic Robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prosser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Evers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2017 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1663" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="336" to="341" />
		</imprint>
	</monogr>
	<note>Robots as intentional agents: Using neuroscientific methods to make robots appear more social</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
