<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THIS IS A PROVISIONAL VERSION OF THE MANUSCRIPT Value Projection. Humans perception of a humanoid robot in moral contexts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Marchesi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Social Cognition in Human-Robot Interaction</orgName>
								<orgName type="institution" key="instit2">Italian Institute of Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Developmental and Social Psychology</orgName>
								<orgName type="institution">University of Padua</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kinga</forename><surname>Ciupińska</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Social Cognition in Human-Robot Interaction</orgName>
								<orgName type="institution" key="instit2">Italian Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>De Tommaso</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Social Cognition in Human-Robot Interaction</orgName>
								<orgName type="institution" key="instit2">Italian Institute of Technology</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Wykowska</surname></persName>
							<email>agnieszka.wykowska@iit.it</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Social Cognition in Human-Robot Interaction</orgName>
								<orgName type="institution" key="instit2">Italian Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">THIS IS A PROVISIONAL VERSION OF THE MANUSCRIPT Value Projection. Humans perception of a humanoid robot in moral contexts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>As robots become collaborators in various domains, understanding human perception of them as moral and intentional agents is pivotal. This study addresses different strategies to promote humans&apos; perception of social robots as value-aware collaborators, focusing on the alignment of values between humans and the humanoid robot iCub. Employing three different strategies of describing the iCub robot abilities of moral-decision making, we found that regardless of the strategy used, participants tended to attribute moral agency to iCub, likely influenced by its humanoid appearance. Interestingly, the absence of prior indication of iCub&apos;s ability to make moral decisions led to a lower adoption of intentional stance. These results suggest a nuanced relationship between perceived intentionality and morality in human-robot interactions. Moreover, our findings advance our understanding of how humans perceive different agents in terms of value-awareness, bridging subjective and objective measures through behavioural and self-report indicators.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sharing our social environments with social robots is becoming increasingly common <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2</ref> . Therefore, understanding how we integrate these artificial agents into our societies and the ethical implications of this integration is crucial. This understanding should be grounded not only in the examination of individual human interactions <ref type="bibr" target="#b2">3</ref> . Artificial agents are often considered technologically opaque <ref type="bibr" target="#b3">4</ref> , meaning their technological complexity, encompassing both hardware and software, positions them as in-between entities. They are clearly human-made artifacts, yet they can potentially be perceived as social actors. Some authors suggest that the dual nature of social robots could even constitute a new ontological category (NOC) <ref type="bibr" target="#b4">5</ref> . Consequently, investigating people's relationships with these entities is of significant interest to social and cognitive scientists.</p><p>Given that the definition of moral agency implies responsibility and awareness of action consequences, should we attribute such moral status to artificial agents? Various authors have proposed differing views on this matter <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7</ref> . Some authors argue for the creation of a computational model of human ethics to enable artificial systems to reason autonomously, by passing emotional involvement <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9</ref> . Others contend that the lack of consciousness, mental states, and intentions precludes artificial systems from being considered moral agents <ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11</ref> . A more flexible approach suggests that while artificial systems may not meet all the criteria for full moral agency, they could still fall within the spectrum of moral agency (for a review see <ref type="bibr" target="#b5">6</ref> .</p><p>The debate on whether artificial systems are capable of possessing internal states such as beliefs and desires or could ever achieve consciousness is ongoing. However, literature shows that people often attribute such states to artificial systems, adopting an intentional stance towards them <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> . This stance may lead to the attribution of moral agency, as humans tend to correlate perceived intentionality with moral responsibility <ref type="bibr" target="#b14">15</ref> . Research in human-robot interaction supports that people assign moral status to artificial systems, expecting them to exhibit certain behaviours and attitudes, that may be perceived as attuned with some moral values <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17</ref> .</p><p>Integrating an anthropocentric approach to ethics in technology, focusing on human perceptions of artificial agents, is crucial <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b17">18</ref> . Some researches argue that artificial agents do not need mental states or personhood to qualify as moral agents. This "mindless morality" approach suggests that systems meeting these criteria can be considered moral agents without actually possessing intentionality or awareness.</p><p>Coeckelbergh <ref type="bibr" target="#b5">6</ref> in particular, introduced a significant shift towards an anthropocentric approach, emphasizing that technology is inherently linked to human contexts. He argues that we should evaluate artificial systems based on human experiences and interactions with them, rather than their internal states. This perspective aligns with the literature on the intentional stance <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14</ref> , where observers interpret robot behavior as if the robots possessed mental states, regardless of the robots' actual capabilities.</p><p>Indeed, previous works <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref> have revealed that successful collaboration between humans and robots relies on the development of shared values, goals, and tasks. The success of human-robot collaboration is marked by bidirectional value alignment, wherein robots accurately infer human values and provide effective explanations of their behavior to humans. Failure to meet these prerequisites may lead to unforeseen difficulties in collaboration due to misguided expectations among teammates <ref type="bibr" target="#b21">22</ref> . Consequently, for robots to become valuable collaborators in human society, they must act properly during interactions with their human counterparts. If the goal is to have non-human agents capable of engaging with-and supporting humans and other agents in complex and risky tasks, it becomes crucial for humans to verify that these agents' policies align with expected and desired outcomes. This alignment, commonly referred to as value alignment, is defined in the Asilomar AI Principles, stating that "highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation". The challenge lies in determining an efficient method to test whether a robot is aligned with human values. Existing approaches to value alignment often centre around qualitative evaluations of trust <ref type="bibr" target="#b22">23</ref> or the alignment of an agent's performance through interactions and active learning <ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25</ref> . In contrast, our work addresses the challenge of searching for effective tests to verify the alignment. In particular, we are interested in investigating the best strategies under which people attribute moral agency to artificial agents. Most existing work on value alignment focuses primarily on iteratively training a learning agent to ensure that its final behavior is consistent with the user's intentions <ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27</ref> . However, we focus on verifying the compatibility of human and robot values. Building on these premises, we designed an experiment to investigate the behavioral aspects of a social robot that influence its perception as a moral and intentional agent. Namely, whether it is best to explicitly inform users about the robot's abilities of moral reasoning, or they should infer this autonomously from robot behaviour or, finally, whether no previous information is needed for participants to attribute moral reasoning abilities to the robot. Moreover, we examined the impact of humanoid behavior on participants' adoption of the intentional stance and the subsequent moral stance. In the preset study, we adopted an anthropocentric approach, in line with the "mindless morality" approach. By means of collecting measures (self report questionnaires and choices) from humans, we investigate the ascription of value awareness to an artificial system. By following this approach, we leave the human at the centre of the social relationship with the robot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Aim and Experimental Manipulation</head><p>The main aim of the present paper is to explore which are the best strategies that support humans' perception of an artificial system as a moral agent. To do so, we created a between groups design, where participants were assigned to three different groups, each group differed in the strategy used to evoke the perception (or not) of the robot as a moral agent. Group 1 received explicit information about the robot's abilities to morally reason make decisions accordingly. as previously mentioned, Group 3 did not receive any explicit information about the robot's moral reasoning abilities, but they were exposed to an interaction with the robot before the experiment proper. during this time, they experienced the robot's behaviour as human-like and resonating emotionally with events in the environment (a manipulation first described in Marchesi et al. <ref type="bibr" target="#b13">14</ref> . In the present experiment, the iCub would contingently react to the peak event in the video. More in detail, as in <ref type="bibr" target="#b13">14</ref> the experimenter played the greeting sentences at the beginning and the end of the shared experience session with the robot, via a Wizard-of-Oz technique (WoOz; <ref type="bibr" target="#b27">28</ref> ). Briefly, the WoOz manipulation consists of an experimenter completely (or partially) remotely controlling a robot's actions (for a review, see <ref type="bibr" target="#b28">29 )</ref>. To frame the social interaction in the context of moral decision-making situation, we modified the video: instead of presenting documentaries scenes like in <ref type="bibr" target="#b13">14</ref> , we presented scene from three movies/television shows (see XXX link to OSF repository) In addition, the robot was programmed to look in the direction of participants' and recognize their face to simulate mutual gaze. This procedure was implemented because literature shows that mutual gaze in human-robot interaction is a pivotal mechanism that influences human social cognition <ref type="bibr" target="#b29">30</ref> . The gaze behavior was implemented using the 6-DoF iKinGazeCtrl <ref type="bibr" target="#b30">31</ref> , using inverse kinematics to produce eye and neck trajectories. Facial expressions on the robot were controlled via the YARP emotion interface module. Finally, Group 2 was a control group, and thus was not expose to any manipulation about the robot's moral abilities, not verbally nor phenomenologically.</p><p>3 Methods, Procedure, and Participants</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participants</head><p>We recruited N= 121 participants (M age = 25.08, SD age = 5.66, min= 18; max= 48; F= 69, M= 47, 1 trans person (MtF)). Participants were assigned to one of three groups, and 4 participants were excluded due to technical issues, for a total of G1 n = 39; G2 n = 38; G3 n = 40 (see <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table">Table 2</ref> for the descriptives of all the three groups). All participants had normal or corrected-to normal vision, had no neurological disorders, and were naïve to the purpose of the experiment. The study was approved by the local ethical committee (Comitato Etico Regione Liguria) and conducted in accordance with the ethical standards (Declaration of Helsinki, 2013). Before the experiment, all participants gave written informed consent. At the end of each experimental session, participants were all debriefed about the purpose of the study. They all received an honorarium of 15 euros for their participation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Stimuli and Apparatus</head><p>As showed in <ref type="figure" target="#fig_0">Fig. 1</ref>, the experimental set-up required participants to be seated beside the iCub robot <ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33</ref> . Both participants and the robot had one screen each, on which the description of the moral dilemma and the subsequent two options were appearing. Importantly, participants were not able to see which button the robot was pressing, but could hear the sound of the button press. Only for Group 3 participants were exposed to a social experience with the robot before the actual task. This shared experience was taken from Marchesi et al. (2022), see <ref type="figure" target="#fig_1">Fig. 2</ref> for the set-up representation. More details about the experimental manipulation will be described in the next paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">The iCub Robot</head><p>The iCub robot is a humanoid robotic platform with 53 degrees of freedom (DoF). Recent research showed that such robot can be perceived as a potential social partner <ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34</ref> . In our experiment, the robot button pressing behaviors were implemented via the middleware Yet Another Robot Platform (YARP, <ref type="bibr" target="#b34">35</ref> ) using the position controller following a minimum jerk profile for head and hands movements to realize the key presses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">The dilemma scenarios</head><p>We created 20 scenarios in the form of a moral dilemma by asking ChatGPT 3.5 to report 20 topics with relevant moral choices involved (prompt: "can you list 20 relevant scenarios in which there are moral choices involved?"). Once we obtained the topics, we created the final structure presented to the robots and the participants as follows:</p><p>You are responsible for collecting surveillance data in a public area. There is a balance to strike between individual privacy rights and public safety concerns. Collect data within legal and ethical bounds, respecting individual privacy rights. Collect extensive data, potentially infringing on privacy rights, to enhance public safety and security.</p><p>Thus, both the robot and the participants were presented with 1) only the text describing the scenario; 2) after 10s, the two options would appear below the scenario; 3) after the robot key press, participants were presented with two questions:</p><p>• which option do you think the robot chose?</p><p>• which option do you choose Participants were instructed to press the left button to choose the first option and the right button to choose the second option. The presentation of the two questions was randomized on a trial-by-trial, to reduce the influence of the previous question on the subsequent. Experimental set up for the moral decision-making. On the left side of the figure we show the complete set-up with the robot on the left of the participants, divided by two panels, so that participants were unable to see which button the robot pressed. On the right side of the figure, we can see a detail of the participants' station with the scenarios and the two options displayed on the screen and the two corresponding buttons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Questionnaires and Test administered before and after the experimental session</head><p>During the experimental session, each of the participants completed a list of questionnaires and test evaluating different factors that could contribute to the attribution of the status of moral agent to the robot. Specifically, the set of questionnaires were divided in Pre-and Post-interaction questionnaires:</p><p>The Pre-questionnaires and test were:</p><p>• the first part of the Instance Test (IST), from 13 :</p><p>• this test is a tool used in HRI to assess the adoption of the intentional stance (i.e., attributing intentionality) towards a humanoid robot. See <ref type="figure">figure 3</ref> for an example. To complete the IST, participants are asked to observe 34 scenarios (divided in two groups (A and B) of 17 for pre-and post-interaction completion as in <ref type="bibr" target="#b13">14</ref> ). These scenarios depict the iCub robot performing some actions, and participants are asked to drag a slider toward the description of the scenario that they found fitting best to what is displayed in the pictures. One sentence is explaining the behavior with reference to mental state (i.e., representing the adoption of the intentional stance), on the other hand, the other sentence is explaining the behavior with reference to a mechanistic explanation (i.e., representing the design stance). Presentation of the two sentences is counterbalanced, and the order of completion of part A and B as pre-and post-interaction test is counterbalanced as well.</p><p>The Post-questionnaires were:</p><p>• the modified version of the Moral Character Questionnaire (MCQ), from <ref type="bibr" target="#b35">36</ref> : this questionnaire assesses core components of personality dispositions in moral identifications, including behavior, motivation, cognition, and identity (Honesty, Compassion, Fairness, Loyalty, Respect, and Purity). In this context, we asked participants to rate the iCub on the MCQ scales to explore their perception of the robot as a possible moral agent. In particular, in our case the Honesty subscale assesses the extent to which individuals think that the iCub values telling the truth, avoid deception, and are straightforward in their dealings with others. The Loyalty subscale assesses the extent to which individuals think that the iCub values adhere to moral and ethical principles, even when faced with difficult situations or potential negative consequences. The Fairness subscale assesses the extent to which individuals think that the iCub values making fair decisions, considers others' rights and needs, and treats everyone equitably. The Compassion subscale assesses the extent to which individuals think that the iCub values others' emotional states, showing compassion, and offers support. The Respect subscale assesses the extent to which individuals think that the iCub values behaviors that reflect esteem and appreciation for others' rights, opinions, and dignity. The Purity subscale assesses the extent to which individuals think that the iCub values behaviors and beliefs related to moral integrity and avoiding actions considered impure or morally tainted. Finally, the Global Morality subscale assesses the extent to which individuals think that the iCub values how consistently individuals uphold broad moral values such as justice, human rights, and the common good, across various situations and contexts. Examples of items are: iCub is honest; iCub is loyal; iCub wants to be honest even when it's difficult. The questionnaire is completed on a 5-point Likert scale. • the second part of the IST, from 13 ;</p><p>• the Moral Foundation Questionnaire (MFQ), from <ref type="bibr" target="#b36">37</ref> (Italian validated version, <ref type="bibr" target="#b37">38</ref> : this questionnaire investigates both the relevance of and the judgments about the five morally relevant dimensions: Harm, Fairness, Ingroup, Authority, and Purity. In particular, The Harm subscale assesses sensitivity to suffering and harm, and the desire to protect and care for others. The Fairness subscale assesses the importance placed on justice, rights, and equality, the concerns about unfair treatment, cheating, and dishonesty. The Ingroup subscale assesses the value individuals place on loyalty, patriotism, and group solidarity. It measures the importance of standing by one's group and the negative response to betrayal or disloyalty. The Authority subscale assesses the respect for tradition, authority, and social order. It assesses how much individuals value obedience, respect for authority figures, and the maintenance of social hierarchies and structures. Finally, the Purity subscale assesses the importance placed on purity, sanctity, and the avoidance of contamination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>All analyses were run with R (v. 2022.07.1) with reader, ggplot2, and dplyr packages <ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40</ref> and JASP (v.0.18.3.0). In our analyses, we focused on the alignment (dependent variable) between participants' responses and what they thought was the iCub's response and whether this differs between Groups (independent variable) as a measure of perception of moral alignment. Next, we wanted to verify whether we can observe differences in questionnaires' results (i.e., IST pre and post, LOC, SoA, MCQ, MFQ; dependent variables) between experimental conditions (i.e., Groups; independent variable). This was done to understand whether our experimental conditions (verbal instruction, WoOz shared experience, no manipulation) can influence the above-mentioned results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Results on value alignment</head><p>In order to understand which of the three strategies used as a manipulation to support humans' perception of moral alignment, we compared the frequencies of alignment (or misalignment) perceived by participants during the task. This means that for each participant, we counted the times that they chose (or not) the same option for themselves and the robot. We fitted a Generalized Linear Mixed Model (GLLM), with frequency of alignment as dependent variable, group as fixed factor and participants as random factor. Results from this model reported no significant difference [p &gt; 0.1] among the three groups. A Chi-square test <ref type="figure">Figure 3</ref>. Example of the IST items with the scenario and the two sentences using either a mentalistic or a mechanistic explanation <ref type="bibr" target="#b12">13</ref> .</p><p>of independence was conducted to examine the differences in alignment frequencies within each group. The results indicated significant differences in alignment frequencies for all groups (with all p &lt; 0.001). We also explored the frequencies of alignment of each group in each scenario, observing that there are some scenarios that seem to elicit more alignment than others (see <ref type="figure" target="#fig_2">figure 4)</ref>.</p><p>For example, scenarios related to healthcare seem to elicit a strong alignment compared to scenarios related to urban planning or space exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Results from Questionnaires</head><p>Intentional Stance Test. The IST was run Pre-and Post-Interaction with the robot to check whether among the three groups there was a change in the attribution of intentionality to the robot. We run a Mixed RM-ANOVA, with the IST scores Preand Post-as repeated measures and Group as a fixed factor. Results reported a close to significance main effect for IST, no statistical significance for the interaction between the IST and the Group and a significant effect for between the groups (see <ref type="table" target="#tab_1">Table 3</ref> for all statics about the within effects and <ref type="table">Table 4</ref> for the between effect). Post-Hoc test, performed with Holm correction, revealed that the difference between the groups is driven by Group 2, which did not receive any manipulation. Curiously, this groups presents also the lower IST mean at the Pre session as well, indicating a general lower tendency in this group to adopt the intentional stance by default, compared to Group 1 and 3. The MCQ questionnaire was run as a Post-questionnaire. We run a One-Way ANOVA that revealed no significant differences in the general mean scores among the three groups in the attribution of moral characteristics to the robot [F(2, 1.98), p= 0.14, η 2 = 0.03].    To further explore the differences in the subscales, we analyzed the mean scores per topic among the subscales. Thus, we run two MANOVAs, one for Relevence and one for Judgment. The first MANOVA for the Relevance subscales reveled no internal differences in the evaluation of the topics [F(2, 0.63), p= 0.79, Wilks ′ λ = 0.14]. Similarly, participants did not differently evaluate the topics in the Judgment subscale [F(2, 1.07), p= 0.38, Trace Pillai = 0.09].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Explorative correlations</head><p>Alignment Score and MCQ We decided to investigate correlations between the moral questionnaires (MFQ and MCQ) with the Alignment Score (AS) calculated as the difference between the misalignment frequency and the alignment frequency  MCQ and MFQ Finally, we decided to explore the relationship between MCQ and MFQ. We first looked at the relationship between the general MCQ and the MFQ Relevance subscale, which highlighted a close to significance positive correlation [Pearsons' r= 0.17, p= 0.07]. Secondly, we looked at the relationship between the general MCQ and the MFQ Judgment subscale, which did not emerge as statistically significant [Pearsons' r= -0.02, p= 0.77].</p><p>To further explore the close to significance relationship between the MCQ subscales and the MFQ Relevance subscale, we correlated the MCQ with the MFQ Relevance topics. We found a positive correlation between MCQ Honesty subscale and MFQ Ingroup [Pearsons' r= 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In the present study, we aimed at exploring whether humans can perceive social robots as potential actors that can align to them, especially in terms of moral judment. Misalignment of moral choices that participants made for themselves, compared to what they believed the robot chose.</p><p>Among the three groups (i.e. with explicit instructions about the robot's abilities to understand moral dilemmas (change also in the abstract) and make decisions accordingly; with no information; and with with social interaction before the experiment), we found no differences. However, our results showed that in most cases (see <ref type="figure" target="#fig_0">Figure 10</ref>) people aligned with iCub. In our study, we also used a set of different questionnaires evaluating factors that could contribute to moral alignment. The results from the MFQ and MCQ questionnaires also showed no differences between the three groups. Only in the case of the Intentional Stance Test we did observe a significantly lower attribution of intentional stance toward the iCub in the group without any manipulation (Group 2). However, this difference was observed already pre-experiment, and therefore is not informative with respect to our experimental manipulation, but highlights the possibility that more contributing factors can lead to pre-existing biases towards humanoid robots. Moreover, the results of the correlation between the morality attribution tests (MFQ -evaluating participants' own morality and MCQ -attribution of moral characteristics to the robot) showed their significant positive relationship. Specifically, the more people rated themselves as moral, the more they rated iCub as a moral agent. Interestingly, the results of the correlation between alignment scores and the MCQ rating revealed a positive link -i.e. the more participants perceived themselves as moral the more they were aligned with iCub. Similarly to results from MCQ -MFQ correlation, this may suggest that people want to perceive iCub as a moral agent as much as they perceive themselves.</p><p>Given these results, we argue that people perceive the humanois robot iCub as a possible agent on to which they can project and assign a moral decision-making capability to, regardless of how the robot itself and its abilities were introduced. This may indicate that people perceive the iCub as a moral agent in the same way they see themselves. Indeed, it is a kind of projection of one's own attitude onto the attitude of a social robot. This projection is influenced by the iCub's morphology itself (i.e., very humanoid appearance) that causes people to anthropomorphize it and, as a consequence, to attribute value-awareness and morality. O'Reilly et al., (submitted) conducted three experiments using vignettes that described scenarios involving either a humanoid robot or a human as the main character. Given a certain outcome of the protagonist's actions (that could affect others positively or negatively), participants were asked to rate, on a 7-point Likert scale, 1) how much intentionality they attributed to the main character and 2) how much moral responsibility the main character deserves. The authors report that moral responsibility ratings were in general higher for actions leading to negative consequences than for those leading to positive consequences, for both agents. Moreover, intentionality ratings were not influenced by the valence of the consequences for the robotic agent, while for humans, intentionality ratings were higher for negative consequences compared to positive ones. The authors argue that this dissociation suggests that humans might view robots' actions as morally accountable even in the absence of intentional agency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Limitation and Future Research</head><p>Our study showed that people tend to "project" their moral stance to a robot agent. However, some limitations of the study need to be mentioned.</p><p>Mainly, the use of self-report questionnaires such as the IST, MFQ, MCQ, LoC, and SoA, while informative, may be subject to social desirability bias and thus may not accurately reflect participants' true perceptions or attitudes. Objective measures such as neural indicators, as proposed for future research, would provide more objective data.</p><p>Another significant limitation is the reliance on the specific humanoid robot platform, namely the iCub, which has a very human-like appearance. This could inherently bias participants towards attributing moral and intentional qualities to it due to the activation of the "human model" and anthropomorphic attributions <ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref> . Future research should include a variety of robot morphologies, including non-humanoid robots, to determine if these attributions are consistent across different forms.</p><p>Finally, while our study focused on value alignment and intentionality attribution, it did not account for other factors that might influence these perceptions, such as the individual differences in anthropomorphic attribution, personality differences or cultural/individual background <ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref> . Future studies should explore these variables, both using explicit and implicit measure, to provide a more comprehensive understanding of how humans perceive robots as moral and intentional agents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Experimental set up for the moral decision-making. On the left side of the figure we show the complete set-up with the robot on the left of the participants, divided by two panels, so that participants were unable to see which button the robot pressed. On the right side of the figure, we can see a detail of the participants' station with the scenarios and the two options displayed on the screen and the two corresponding buttons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Experimental set up of the shared experience of Group 3. On the left side, there is the experimenter controlling the robot via WoOZ. On the right side, there is the participant watching video clips together with the robot. The robot's reactions to the video clips are human-like and emotionally resonating with the content of the movies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Bar plot showing the frequencies of value alignment and misalignment among the three groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Bar plot showing the frequencies of value alignment and misalignment trial by trial among the three groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Bar plot showing the general mean scores at the MCQ questionnaire by group.8/14to further explore this factor, we compared the MCQ subscales among the three groups with a MANOVA. Results revealed no significant difference [F(2, 1.2), p= 0.26, Trace Pillai = 0.14].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Bar plot showing the mean scores per subscales at the MCQ questionnaire by group. Moral Foundation Questionnaire. The MFQ questionnaire was run as a Post-questionnaire. We run a Mixed RM-ANOVA comparing the two general subscales (Relevance and Judgment) among the three groups. Results revealed a significant main effect of the subscales [F(1,8.15), p= 0.005, η 2 p = 0.06]. Post-ho test with Holm correction revealed a sifnificant difference in the way the two scales were rated [t= 2.85, p Holm = 0.005] No other significant differences emerged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Bar plot showing the general mean scores at the MFQ questionnaire by group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Bar plot showing the mean scores per subscales at the MFQ questionnaire by group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(misalignment -alignment). Results reported a positive correlation between the AS x MCQ general mean [Pearsons' r= 0.23, p= 0.01].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Correlation plot between AS and general MCQ.We then proceeded to look for correlations between the AS and the MCQ subscales.Three positive correlations resulted significant: 1-AS x MCQ fairness subscale [Pearsons' r= 0.26, p= 0.04], 2-AS x MCQ loyalty subscale [Pearsons' r= 0.23, p= 0.01] and AS x MCQ global morality subscale [Pearsons' r= 0.21, p= 0.02]. Alignment Score and MFQ We then proceeded to explore the relationship between AS and MFQ. No significant correlation emerged between the AS and the MFQ Relevance subscale [Pearsons' r= 0.14, p= 0.14] or AS and MFQ Judgment [Pearsons' r= -0.03, p= 0.78].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Descriptive Statistics</figDesc><table><row><cell></cell><cell></cell><cell>Age</cell><cell></cell></row><row><cell></cell><cell cols="3">Group1 Group2 Group3</cell></row><row><cell>Mean</cell><cell>24.64</cell><cell>23.89</cell><cell>26.8</cell></row><row><cell>Std. Deviation</cell><cell>5.69</cell><cell>4.05</cell><cell>6.73</cell></row><row><cell>Minimum</cell><cell>18</cell><cell>18</cell><cell>20</cell></row><row><cell>Maximum</cell><cell>44</cell><cell>39</cell><cell>48</cell></row><row><cell cols="4">Table 2. Frequencies for Sex</cell></row><row><cell>Group</cell><cell cols="3">Sex Frequency Percent</cell></row><row><cell>Group1</cell><cell>F</cell><cell>21</cell><cell>53.85</cell></row><row><cell></cell><cell>M</cell><cell>18</cell><cell>46.15</cell></row><row><cell>Group2</cell><cell>F</cell><cell>27</cell><cell>71.05</cell></row><row><cell></cell><cell>M</cell><cell>11</cell><cell>28.95</cell></row><row><cell>Group3</cell><cell>F</cell><cell>21</cell><cell>52.5</cell></row><row><cell></cell><cell>F*</cell><cell>1</cell><cell>2.5</cell></row><row><cell></cell><cell>M</cell><cell>18</cell><cell>45</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Within Subjects Effects</figDesc><table><row><cell>Cases</cell><cell>Sum of Squares</cell><cell cols="2">df Mean Square</cell><cell>F</cell><cell>p</cell><cell>η 2</cell><cell>p</cell></row><row><cell>IST</cell><cell>359.144</cell><cell>1</cell><cell cols="5">359.144 3.457 0.066 0.029</cell></row><row><cell>IST * Manipulation</cell><cell>80.587</cell><cell>2</cell><cell cols="5">40.294 0.388 0.679 0.007</cell></row><row><cell>Residuals</cell><cell cols="2">11842.372 114</cell><cell>103.880</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Note. Type III Sum of Squares</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .Table 6 .</head><label>46</label><figDesc>Between Subjects Effects Note. Results are averaged over the levels of: IST IST Means Pre-and Post-for reach Group</figDesc><table><row><cell>Cases</cell><cell></cell><cell>Sum of Squares</cell><cell cols="3">df Mean Square</cell><cell>F</cell><cell>p</cell><cell>η 2</cell><cell>p</cell></row><row><cell cols="2">Manipulation</cell><cell>7641.255</cell><cell>2</cell><cell></cell><cell cols="3">3820.627 5.686 0.004 0.091</cell></row><row><cell>Residuals</cell><cell></cell><cell cols="2">76596.809 114</cell><cell></cell><cell>671.902</cell><cell></cell></row><row><cell cols="3">Note. Type III Sum of Squares</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">Table 5. Post Hoc Comparisons -Manipulation</cell></row><row><cell></cell><cell></cell><cell cols="3">Mean Difference</cell><cell>SE</cell><cell cols="2">t p holm</cell></row><row><cell cols="2">None</cell><cell>Verbal</cell><cell cols="5">−11.030 4.178 −2.640 0.019</cell></row><row><cell></cell><cell></cell><cell>Video</cell><cell cols="5">−13.083 4.152 −3.151 0.006</cell></row><row><cell cols="3">Verbal Video</cell><cell cols="5">−2.053 4.125 −0.498 0.620</cell></row><row><cell cols="6">Note. P-value adjusted for comparing a family of 3</cell><cell></cell></row><row><cell cols="4">IST Manipulation N Mean</cell><cell>SD</cell><cell cols="3">SE Coefficient of variation</cell></row><row><cell>Pre</cell><cell cols="5">None (G2) 38 33.58 20.05 3.25</cell><cell></cell><cell>0.59</cell></row><row><cell></cell><cell cols="5">Verbal (G1) 39 43.17 19.62 3.14</cell><cell></cell><cell>0.45</cell></row><row><cell></cell><cell cols="5">Video (G3 40 46.08 14.86 2.35</cell><cell></cell><cell>0.32</cell></row><row><cell>Post</cell><cell cols="5">None (G2) 38 34.71 24.63 3.99</cell><cell></cell><cell>0.71</cell></row><row><cell></cell><cell cols="5">Verbal (G1) 39 47.18 21.92 3.51</cell><cell></cell><cell>0.46</cell></row><row><cell></cell><cell cols="5">Video (G3) 40 48.37 15.69 2.48</cell><cell></cell><cell>0.32</cell></row></table><note>Moral Character Questionnaire.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>2, p= 0.03], MCQ compassion and MFQ authority [Pearsons' r= 0.24, p= 0.007], MCQ fairness and MFQ authority [Pearsons' r= 0.25, p= 0.007], MCQ respect and MFQ authority [Pearsons' r= 0.2, p= 0.02], and MCQ honesty and MFQ purity [Pearsons' r= 0.24, p= 0.008], MCQ compassion and MFQ purity [Pearsons' r= 0.2, p= 0.04], and finally MCQ fairness and MFQ purity [Pearsons' r= 0.28, p= 0.003].</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has received support from the European Union under the European Innovation Council (EIC) research and innovation programme, Project "VaLue-aware AI (VALAWAI)", Grant Agreement number 101070930. Moreover, the authors would like to acknowledge Silvia Moretti and Federico Rospo for their help in data collection.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional information</head><p>To include, in this order: Accession codes (where applicable); Competing interests (mandatory statement).</p><p>The corresponding author is responsible for submitting a competing interests statement on behalf of all authors of the paper. This statement must be included in the submitted article file.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Socially intelligent robots: dimensions of human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos. transactions royal society B: Biol. sciences</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="page" from="679" to="704" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Are friends electric? the benefits and risks of human-robot relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Prescott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Robillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robots as mirrors of the human mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Dir. Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="34" to="40" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Technological opacity, predictability, and self-driving cars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Surden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cardozo L. Rev</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Noc noc, who&apos;s there? a new ontological category (noc) for social robots. New perspectives on human development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Kahn</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="106" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Robot ethics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Coeckelbergh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">How do we approach robots: anthropomorphism, the intentional stance, cultural norms and values, and societal implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<idno type="DOI">file://localhost/opt/grobid/grobid-home/tmp/10.31234/osf.io/gn2za</idno>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robot minds and human ethics: the need for a comprehensive model of moral decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wallach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ethics Inf. Technol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A conceptual and computational model of moral decision making in human and artificial agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Top. cognitive science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="454" to="485" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Artificial agency, consciousness, and the criteria for moral agency: What properties must an artificial agent have to be a moral agent?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Himma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ethics Inf. Technol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Moral responsibility of robots and hybrid agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hakli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mäkelä</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Monist</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="259" to="275" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Dennett</surname></persName>
		</author>
		<title level="m">The intentional stance</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Do we adopt the intentional stance toward humanoid robots? Front</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">psychology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">450</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Belief in Sharing the Same Phenomenological Experience Increases the Likelihood of Adopting the Intentional Stance Toward a Humanoid Robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Tommaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perez-Osorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<ptr target="Https://tmb.apaopen.org/pub/56dkj53d" />
	</analytic>
	<monogr>
		<title level="j">Technol. Mind, Behav</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vallor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos. &amp; Technol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="107" to="124" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Does the correspondence bias apply to social robots?: Dispositional and situational attributions of human versus robot behavior. Front</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics AI</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">788242</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The fundamental attribution error in human-robot interaction: An experimental investigation on attributing responsibility to a social robot for its pre-programmed behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Horstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Krämer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Soc. Robotics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1137" to="1153" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Personal robots, appearance, and human good: a methodological reflection on roboethics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Coeckelbergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Soc. Robotics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="217" to="221" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Can robots be teammates?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Groom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Benchmarks in human-robot teams. Interact. studies</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="483" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The role of mental models in team performance in complex systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Rouse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Cannon-Bowers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Salas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1296" to="1308" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
	<note>man, cybernetics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Advances in experimental social psychology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1" to="65" />
			<date type="published" when="1992" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Implicit coordination strategies for effective team communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Butchibabu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sparano-Huiban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sonenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. factors</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="595" to="610" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Establishing appropriate trust via critical states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Dragan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3929" to="3936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning from human preferences. Adv. neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Christiano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Active preference-based learning of reward functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sadigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Dragan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06565</idno>
		<title level="m">Concrete problems in ai safety</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Research priorities for robust and beneficial artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dewey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tegmark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="105" to="114" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An empirical methodology for writing user-friendly natural language computer applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kelley</surname></persName>
		</author>
		<idno type="DOI">file://localhost/opt/grobid/grobid-home/tmp/10.1145/800045.801609</idno>
	</analytic>
	<monogr>
		<title level="m">Conf. on Hum. Factors Comput. Syst. -Proc. 193-196</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Wizard of awwws: Exploring psychological impact on the researchers in social hri experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Geiskkovitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction</title>
		<meeting>the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">To follow or not to follow your gaze: The interplay between strategic control and the eye contact effect on gaze-induced attention orienting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kompatsiari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ciardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Gen</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A cartesian 6-DoF gaze controller for humanoid robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roncone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pattacini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Natale</surname></persName>
		</author>
		<idno type="DOI">file://localhost/opt/grobid/grobid-home/tmp/10.15607/rss.2016.xii.022</idno>
	</analytic>
	<monogr>
		<title level="j">Robotics: Sci. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The icub humanoid robot: An open-systems platform for research in cognitive development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1125" to="1134" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The not-yet-finished story of building a robot child</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Natale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bartolozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Icub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Robotics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1026</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Tools and methods to study and replicate experiments addressing human social cognition in interactive scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>De Tommaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kompatsiari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Yarp: yet another robot platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Natale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adv. Robotic Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Development and validation of the moral character questionnaire</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Furr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prentice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Parham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jayawickreme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Res. Pers</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">104228</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Moral foundations questionnaire</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Pers. Soc. Psychol</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Il moral foundation questionnaire: Analisi della struttura fattoriale della versione italiana [the moral foundation questionnaire: Analysis of the factorial structure of the italian version</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bobbio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nencini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sarrica</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="7" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">dplyr: A grammar of data manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hadley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Romain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lionel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kirill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<title level="m">Elegant graphics for data analysis</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robots as intentional agents: using neuroscientific methods to make robots appear more social</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Metta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1663</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The phenotypes of anthropomorphism and the link to personality traits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Spatola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Soc. Robotics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cognitive load affects early processes involved in mentalizing robot behaviour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Spatola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">14924</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The mediating role of anthropomorphism in adopting the intentional stance towards humanoid robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Spatola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Theta synchronization as a neural marker of flexible (re-)use of socio-cognitive mechanisms for a new category of (artificial) interaction partners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Parenti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">P</forename><surname>Navare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
		<idno type="DOI">file://localhost/opt/grobid/grobid-home/tmp/10.31219/osf.io/5uw68</idno>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The role of prior exposure in the likelihood of adopting the intentional stance toward a humanoid robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>De Tommaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Paladyn, J. Behav. Robotics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">20220103</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A study on social inclusion of humanoid robots: A novel embodied adaptation of the cyberball paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Russi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>De Tommaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wykowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Soc. Robotics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="671" to="686" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">For data citations of datasets uploaded to e.g. figshare, please use the howpublished option in the bib entry to specify the platform and the link</title>
		<imprint/>
	</monogr>
	<note>as in the Hao:gidmaps:2014 example in the sample bibliography file</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
