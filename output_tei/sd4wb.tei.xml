<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Embodied Crossmodal Self Forms Language and Interaction: A Computational Cognitive Review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-08-16">16 August 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">Alexander</forename><surname>Verschoor</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felice</forename><surname>Cimatti</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Macwhinney</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Röder</surname></persName>
							<email>frank.roeder@uni-hamburg.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Özdemir</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phuong</forename><forename type="middle">D H</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wermter</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Eppe</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Leiden University</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Calabria</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<settlement>Hamburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Embodied Crossmodal Self Forms Language and Interaction: A Computational Cognitive Review</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-08-16">16 August 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3389/fpsyg.2021.716671</idno>
					<note type="submission">Received: 29 May 2021 Accepted: 16 July 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>embodiment cognition</term>
					<term>grounding language</term>
					<term>dialog</term>
					<term>minimal self</term>
					<term>reinforcement learning</term>
					<term>developmental psychology</term>
					<term>developmental robotics</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Human language is inherently embodied and grounded in sensorimotor representations of the self and the world around it. This suggests that the body schema and ideomotor action-effect associations play an important role in language understanding, language generation, and verbal/physical interaction with others. There are computational models that focus purely on non-verbal interaction between humans and robots, and there are computational models for dialog systems that focus only on verbal interaction. However, there is a lack of research that integrates these approaches. We hypothesize that the development of computational models of the self is very appropriate for considering joint verbal and physical interaction. Therefore, they provide the substantial potential to foster the psychological and cognitive understanding of language grounding, and they have significant potential to improve human-robot interaction methods and applications. This review is a first step toward developing models of the self that integrate verbal and non-verbal communication. To this end, we first analyze the relevant findings and mechanisms for language grounding in the psychological and cognitive literature on ideomotor theory. Second, we identify the existing computational methods that implement physical decision-making and verbal interaction. As a result, we outline how the current computational methods can be used to create advanced computational interaction models that integrate language grounding with body schemas and self-representations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The human species has a unique communication system that involves verbal (e.g., speech) and non-verbal (e.g., gestures, facial expressions, body language) interaction with others. Despite cultural and social differences, participants in a conversation need to share a common conceptual view of the world and their embodied self. This is essential to have a common understanding, avoid misunderstandings, interpret metaphors <ref type="bibr" target="#b33">(Feldman and Narayanan, 2004</ref>) (see <ref type="figure" target="#fig_0">Figure 1A)</ref>, and for self-other distinction <ref type="bibr" target="#b88">(Schillaci et al., 2013)</ref>. A common conceptual view of the world is a consequence of the shared commonalities in how conversation partners ground language in their embodied interaction with the world <ref type="bibr" target="#b6">(Barsalou, 2008;</ref><ref type="bibr" target="#b63">Madden et al., 2010)</ref>. For example, the common conceptual view implies a self-representation that enables humans to solve tasks involving intrinsic spatial reference frames, like the one in <ref type="figure" target="#fig_0">Figure 1B</ref>. But how can humans learn appropriate representations of their body and, consequently, their self? Is the self a unifying principle that combines all the needed ingredients to solve both mentioned examples?</p><p>In this review, we will address these questions from an interdisciplinary perspective. Therefore, we will first discuss the cognitive and psychological background for self-representation and embodied language learning. Second, we will align this background with contemporary research in reinforcement learning. Herein, we focus on the cognitive mechanistic aspects of representation learning and behavior. We also appreciate insights from neuroscientific literature <ref type="bibr" target="#b84">(Rizzolatti and Arbib, 1998;</ref><ref type="bibr" target="#b56">Kaplan, 2007;</ref><ref type="bibr" target="#b63">Madden et al., 2010</ref>), but we draw only occasional links to maintain a feasible scope for this article, we draw only occasional links to particularly relevant neuroscience background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Embodied Language Learning</head><p>Human-robot interaction (HRI) is an active field of research where communication via natural language is an essential but also a very challenging component. In the past years, methods utilized machine learning to improve natural language processing (NLP), enabling decent interactions with virtual agents like Siri, Alexa, Cortana, and Google. These improvements are mainly due to utilizing large neural network-based language models <ref type="bibr" target="#b107">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b28">Devlin et al., 2019)</ref>. However, these systems are limited to disembodied language processing, and therefore, cannot understand how natural language is situated in the physical world. For example, properties such as "heavy" or "hot" cannot be experienced without sensors, and they are important for robots interacting with humans. A robot should understand that hot things can hurt living beings and that not every person can lift heavy objects. There exists research on how robots can technically acquire and understand language through sensorimotor grounding <ref type="bibr" target="#b96">Spranger et al., 2014)</ref>. However, in practice, this is still challenging for current computational models on robots as sensory inputs are imperfect, and natural language is full of ambiguities (see <ref type="figure" target="#fig_0">Figure 1A)</ref>. For example, <ref type="bibr" target="#b98">Steels and Loetzsch (2012)</ref> present research on how robots can establish new names for objects they see in an environment. They play a grounded naming game with a hardcoded cognitive system and vision, speech recognition, and pointing mechanisms. This is consistent with the concept of decoupling skill learning and language language grounding <ref type="bibr" target="#b1">(Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref> that we consider in this article.</p><p>To address the problem of imperfect sensors and noisy perception, researchers and engineers often use crossmodal inputs following the notion of the duck test for deductive reasoning: "If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck." <ref type="bibr" target="#b49">(Hill et al., 2020;</ref><ref type="bibr" target="#b67">McClelland et al., 2020)</ref>. Language models, even if showcased as extremely powerful like GPT-3 <ref type="bibr" target="#b13">(Brown et al., 2020)</ref>, are limited as they cannot make sense of swimming or what a quaking duck would sound or even look like. To fully understand what swimming and quacking are, an agent requires embodied and situated experiences to ground these concepts. This includes physical interaction with water and, preferably, cross-modal visual and acoustic sensory input to perceive the quacking. In other words, many of the existing language models like GPT-3 perform Natural Language Processing (NLP), but they lack the embodied grounding processes required for Natural Language Understanding (NLU). As a consequence, to understand language in the context of a dialog and to be able to interact physically with the world via actuators, it is critical to receive embodied multisensory inputs, such as vision, sound, and touch. <ref type="figure">Figure 2</ref> illustrates a possible association between the language modality and other modalities (right side) compared to a model that cannot use such grounded connections. Understanding grounded language is critical for acting robots <ref type="bibr" target="#b103">(Tellex et al., 2020)</ref> to perform dialog <ref type="bibr" target="#b10">(Bordes et al., 2017)</ref> and HRI in general.</p><p>Many human skills can be acquired by explanation through language only. However, learning physical skills like a backflip is hard and costly to learn by verbal explanations only because it also benefits from the athletic experience. For example, <ref type="bibr" target="#b19">Christiano et al. (2017)</ref> were able to teach an agent to do a backflip via simple feedback akin to basic language only, describing how good the agent is currently performing or what to improve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIGURE 2 |</head><p>We illustrate an example using a neural text-processing model that integrates text only (left) and text in combination with vision and sound (right). Possible associations or groundings are highlighted.</p><p>The key point is that learning skills through language require embodied concepts that recall motions and postures in context. For example, "While jumping as high as you can, pull your legs towardz your body and throw yourself to the back; after a full rotation, land on your feet" presupposes that the skill "jumping" is already known. Without such concepts, explaining the execution of a backflip, similarly to the example of <ref type="bibr" target="#b19">Christiano et al. (2017)</ref>, requires a vast amount of feedback or very detailed guidance to compensate for the lack of knowledge.</p><p>In summary, humans leverage embodied concepts built up during their lifetime, with language understanding always tightly connected to knowledge and experiences of the motor system <ref type="bibr" target="#b35">(Fischer and Zwaan, 2008)</ref>. Specifically, verbal descriptions like "throwing a ball" or "jumping in the air" excite the relevant parts of the motor cortex that are active for both hearing and executing. Therefore, language acquisition is strongly influenced by embodied experiences and the current context <ref type="bibr" target="#b67">(McClelland et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Reinforcement Learning and Computational Language Understanding Methods</head><p>Reinforcement learning (RL) <ref type="bibr" target="#b100">(Sutton and Barto, 2018</ref>) is a cognitively plausible and valuable framework to emulate infantlike learning, exploring the world with a trial-and-error approach based on rewards. RL-based agents are sometimes intrinsically motivated <ref type="bibr" target="#b36">(Forestier et al., 2017;</ref><ref type="bibr" target="#b21">Colas et al., 2020;</ref><ref type="bibr" target="#b1">Akakzia et al., 2021;</ref><ref type="bibr" target="#b50">Hill et al., 2021)</ref>. They imitate behaviors <ref type="bibr" target="#b18">(Chevalier-Boisvert et al., 2019;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref>, use hierarchical abstractions to decompose a complex task into simpler tasks <ref type="bibr" target="#b75">(Oh et al., 2017;</ref><ref type="bibr" target="#b31">Eppe et al., 2019)</ref>, and some of them can be trained with language to follow instructions <ref type="bibr" target="#b47">(Hermann et al., 2017;</ref><ref type="bibr" target="#b75">Oh et al., 2017;</ref><ref type="bibr" target="#b17">Chaplot et al., 2018;</ref><ref type="bibr" target="#b71">Narasimhan et al., 2018;</ref><ref type="bibr" target="#b18">Chevalier-Boisvert et al., 2019;</ref><ref type="bibr" target="#b48">Hill et al., 2019</ref><ref type="bibr" target="#b49">Hill et al., , 2020</ref><ref type="bibr" target="#b50">Hill et al., , 2021</ref><ref type="bibr" target="#b54">Jiang et al., 2019;</ref><ref type="bibr" target="#b21">Colas et al., 2020)</ref>.</p><p>Reinforcement learning is also a promising method to implement dialog systems <ref type="bibr" target="#b91">(Shi and Yu, 2018;</ref><ref type="bibr" target="#b86">Saleh et al., 2020</ref>) and language-driven interactive RL <ref type="bibr" target="#b26">(Cruz et al., 2015;</ref><ref type="bibr" target="#b18">Chevalier-Boisvert et al., 2019)</ref>. Commonly, language in RL <ref type="bibr" target="#b60">(Luketina et al., 2019)</ref> is either used to provide an instruction (what to do) or to assist the learning of the agent with hints and descriptions <ref type="bibr" target="#b71">(Narasimhan et al., 2018)</ref>. Other methods describe the agent's environment purely in textual form, e.g., the agent's state in a dialog or text-based game <ref type="bibr" target="#b25">(Côté et al., 2019;</ref><ref type="bibr" target="#b64">Madureira and Schlangen, 2020)</ref>, which is a common setup for most conversational settings. For example, the simulator ALFWorld <ref type="bibr" target="#b94">(Shridhar et al., 2021)</ref> was published with the goal to provide a learning environment where they combine the textbased knowledge obtained in TextWorld <ref type="bibr" target="#b25">(Côté et al., 2019)</ref> is combined with visual inputs from ALFRED <ref type="bibr" target="#b93">(Shridhar et al., 2020)</ref>. <ref type="bibr" target="#b86">Saleh et al. (2020)</ref> use hierarchical reinforcement learning (HRL) ( <ref type="bibr" target="#b7">Barto and Mahadevan, 2003)</ref> in an open-domain dialog, providing results that are comparable with the current stateof-the-art language models <ref type="bibr" target="#b107">(Vaswani et al., 2017)</ref>. As another example for language-driven RL, consider the research by <ref type="bibr" target="#b54">Jiang et al. (2019)</ref>, who use simplified language to communicate between a lower and higher layer of a hierarchical RL agent following language instructions.</p><p>The recent review by <ref type="bibr" target="#b106">Uc-Cetina et al. (2021)</ref> illustrates the applicability of RL in NLP to some extent, such as machine translation, language understanding, and text generation. The authors also suggest considering embodiment <ref type="bibr" target="#b46">(Heinrich et al., 2020)</ref>, textual domain knowledge, and conversational settings. <ref type="bibr" target="#b9">Bisk et al. (2020)</ref> focus further on embodiment and highlight the importance of physical and social context, more precisely, multimodal sensory experiences, to apprehend the coherency of words and actions. In an embodied dialog, the notion of technically combining the world state, i.e., the sensory inputs, with a linguistic state of a dialog, e.g., the context of the last n utterances, is crucial. We also see advances in multimodal reinforcement learning <ref type="bibr" target="#b88">(Schillaci et al., 2013;</ref><ref type="bibr" target="#b17">Chaplot et al., 2018;</ref><ref type="bibr" target="#b48">Hill et al., 2019</ref><ref type="bibr" target="#b49">Hill et al., , 2020</ref><ref type="bibr" target="#b50">Hill et al., , 2021</ref>, integrating multisensory experience for explainability and improved training performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Scientific Rationale and Contribution of This Review</head><p>The work of <ref type="bibr" target="#b29">Eppe et al. (2020)</ref> provides a thorough review of the hierarchical concepts for embodied problem-solving, but the authors do not consider language. Another related review about computational models of the self and body schemas has recently been presented by <ref type="bibr" target="#b74">Nguyen et al. (2021)</ref>. However, the authors do not consider language either. We address this gap by examining the challenges of embodied dialogs <ref type="bibr" target="#b44">(Hahn et al., 2020)</ref> in the context of the self, combining the presence of language with other input modalities to learn appropriate hierarchical representations.</p><p>For our review, we hypothesize that a disembodied combination of the latest insights in multimodal data processing and language processing is not sufficient to enable full language understanding in dialogs between humans and embodied computational agents like robots. Instead, we hypothesize that an increased focus on the embodied self is important to enable computational agents with true language understanding capabilities beyond the mere computational processing of language. We investigate this hypothesis by addressing the following research questions:</p><p>What are the cognitive components of the self, and why are they important for communication and dialog? Which components have been realized computationally, and how? Which are still missing?</p><p>To address these questions, and as our main contribution, we look into recent articles defining the prerequisites of an artificial self <ref type="bibr" target="#b87">(Schillaci et al., 2016;</ref><ref type="bibr" target="#b42">Georgie et al., 2019;</ref><ref type="bibr" target="#b43">Hafner et al., 2020;</ref><ref type="bibr" target="#b74">Nguyen et al., 2021)</ref> and relate these prerequisites with verbal and non-verbal dialog methods for computational agents and reinforcement learning. In section 2, we survey the developmental processes of humans to ground language in embodied sensorimotor representations of the self and its surrounding world. In section 3, we summarize existing computational methods that use grounded language to train an agent. In section 4, we address our main hypothesis by summarizing and detailing why the self contains all the components that make robots better language learners and dialog partners. In addition, we provide a blueprint for combining the different existing computational techniques. These results are followed by a brief conclusion in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">COGNITIVE AND PSYCHOLOGICAL PERSPECTIVES OF THE COMMUNICATING SELF</head><p>The development of the human ability to perform bi-directional language-based dialog is a process over three interleaved stages. The first stage is sensorimotor development, where infants learn to align their perception with their motor skills <ref type="bibr" target="#b79">(Paul et al., 2018)</ref> to acquire an understanding of the physical dynamics of their environment. Based on such low-level sensorimotor knowledge acquisition, humans develop embodied mental concepts in a second developmental stage to model their environment in higher-level preverbal conceptual representations <ref type="bibr" target="#b34">(Feldman, 2006;</ref><ref type="bibr" target="#b6">Barsalou, 2008;</ref><ref type="bibr" target="#b37">Frankland and Greene, 2020)</ref>. Such higherlevel concepts are the foundation of language, which emerges with social interaction and communication during the third stage of development <ref type="bibr" target="#b34">(Feldman, 2006;</ref><ref type="bibr" target="#b58">Kiefer and Pulvermüller, 2012)</ref>. These three stages are not temporally distinct, but they co-develop. For example, verbal interaction demands additional low-level motor skills to produce phonemes using tongue, lips, and diaphragm. And social interaction leads to learning new conceptual representations that describe social interaction, e.g., in meta-communication. In the following, we will summarize the psychological and cognitive foundations of each of these stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Learning Sensorimotor Representations</head><p>From the very first month of birth, infants start developing a sense of their own body and its relation to other physical entities, such as objects and other living beings <ref type="bibr" target="#b74">(Nguyen et al., 2021)</ref>. The representation of their body in space that encodes positional and relational information is called the body schema <ref type="bibr" target="#b52">(Holmes and Spence, 2004;</ref><ref type="bibr" target="#b51">Hoffmann et al., 2010)</ref>. The body schema, or sense of body, is mainly shaped by proprioception, but visual information and other modalities <ref type="bibr" target="#b110">(Wermter et al., 2009)</ref>, including sound, vision, pain, and smell, also play a role <ref type="bibr" target="#b3">(Anderson, 1972)</ref>. The multimodality of the formation of lowlevel sensorimotor representations is very efficient for humans suffering from a lack of one or more senses. For example, visually impaired humans can build a rich conceptual understanding of words, objects, and the world, even without the visual sense <ref type="bibr" target="#b74">(Nguyen et al., 2021)</ref>. Generally, the absence of one or more modalities can be compensated by the other modalities, such as touch and sound. Therefore, multisensory integration is crucial for embodied cognition and learning concepts to represent the world.</p><p>Ideomotor theory postulates that the physical knowledge about multimodal sensorimotor contingencies is encoded as bidirectional action-effect associations <ref type="bibr" target="#b92">(Shin et al., 2010)</ref>. This implies that neural structures learn a mapping between actions and effects that enable humans to predict the outcome of actions and external events. The same structures enable humans to select an action based on a desired effect, i.e., a goal. The acquisition of ideomotor associations is enabled by observing and interacting with the world, learning principles such as occlusion, solidness, collision, gravity, and other physical events <ref type="bibr" target="#b5">(Baillargeon, 2001)</ref>.</p><p>Developmental psychology suggests that the acquisition of sensorimotor knowledge is guided by several forms of intrinsic motivation, including self-guided play <ref type="bibr" target="#b101">(Sutton-Smith, 2001</ref>), curiosity <ref type="bibr" target="#b76">(Oudeyer et al., 2007)</ref>, repetition, and imitation <ref type="bibr" target="#b112">(Wood et al., 1976;</ref><ref type="bibr" target="#b80">Paulus, 2014)</ref>. Self-guided play implies that infants conduct their own experiments, e.g., dropping toys to discover forces like gravity, to extend their knowledge about the world and their own capabilities <ref type="bibr" target="#b101">(Sutton-Smith, 2001</ref>). This behavior is closely tied to curiosity and active learning: infants often strive to encounter surprising and unpredictable situations to maximize their knowledge about the world <ref type="bibr" target="#b89">(Schwartenbeck et al., 2019)</ref>. More specifically, <ref type="bibr" target="#b89">Schwartenbeck et al. (2019)</ref> state that active learning builds on minimizing the unexpected uncertainty, which can be described as the uncertainty about uncertainty. The authors exemplify active learning with a two-armed bandit problem where the reward of using one arm is low, but the agent knows that the probability for the low reward is high. The other arm has a low but unknown probability for a high reward. In this case, an agent will first try to resolve the unexpected uncertainty about the unknown probability for a high reward of the second arm by trying it. In general, it will collect samples of state transitions with a high unexpected uncertainty until it has a good estimate of the uncertainty.</p><p>This explorative behavior, however, must be balanced with striving for predictable action-state transitions, as described by the free energy principle <ref type="bibr" target="#b39">(Friston, 2009)</ref>. This principle implies that humans and other acting systems perform an active inference behavior and seek to encounter predictable situations. It describes long-term surprise as an upper limit for free energy and states that biological agents strive to minimize the free energy. At first glance, active inference seems to contradict the active learning behavior where agents strive to encounter uncertain and unpredictable situations to maximize their knowledge gain.</p><p>However, since active learning seeks to encounter situations with a high unexpected uncertainty, i.e., uncertainty about uncertainty, this is in fact very compatible with active inference, which seeks to avoid situations with a high expected uncertainty. In other words, active learning is preliminary to active inference because it is required to learn a model about expected uncertainty.</p><p>Another form of intrinsic motivation is repetition: Biological agents exhibit behaviors that are not only goal-driven but exclusively conducted for the purpose of repetition to discover multiple possible ways of achieving a goal <ref type="bibr" target="#b16">(Burghardt, 2006)</ref>. For example, one can think about a child stacking blocks just for the sake of stacking rather than the goal of building a big tower. In the goal-driven case, repetition allows experiencing many ways of achieving the same desired outcome. 1 Acevedo-Valle et al. (2020) point out that intrinsically motivated sensorimotor exploration is also related to imitation. The authors' proposed architecture highlights imitation-based learning of an infant in the pre-linguistic phase, being supervised by an instructor. They consider the simulation of a vocal tract as a comparison to what young infants do to produce vocal sounds when acquiring speech. Most robots do not have a vocal tract, but there exists research on modeling goal-directed behavior where the goal is to produce a certain vowel or syllable <ref type="bibr" target="#b81">(Philippsen, 2021)</ref>. Here, the authors consider the case of speech acquisition, where goaldirected explorative behavior uses sounds to learn vowels and syllables via goal babbling <ref type="bibr" target="#b81">(Philippsen, 2021)</ref>.</p><p>In summary, explorative play and active learning are the main drivers for learning to "know the unknown" <ref type="bibr" target="#b108">(Vygotsky, 1967;</ref><ref type="bibr" target="#b8">Belsky and Most, 1981)</ref> and, more specifically, about the effects and uncertainties of actions <ref type="bibr" target="#b74">(Nguyen et al., 2021)</ref>. However, explorative behavior is balanced with the free energy principle, causing agents to strive for predictable situations. Other drivers of sensorimotor learning are imitation and repetition. Once enough knowledge is acquired, humans and other animals can use their rich conceptual knowledge for one-shot problem-solving <ref type="bibr" target="#b29">(Eppe et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Formation and Grounding of Preverbal and Abstract Conceptual Representations</head><p>Language allows humans to express thought. However, explicit verbal language is not a prerequisite for thought-there exists a preverbal hierarchical system of abstract mental concepts to enable thought (Frankland and Greene, 2020).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Representational Abstraction</head><p>The human mind constantly performs inference on multiple layers of representational abstraction <ref type="bibr" target="#b20">(Clark, 2016)</ref>. The theory of embodied cognition suggests that the higher levels of abstraction emerge from the sensorimotor interaction of the lower levels <ref type="bibr" target="#b6">(Barsalou, 2008;</ref><ref type="bibr" target="#b59">Lakoff and Johnson, 2010;</ref><ref type="bibr" target="#b102">Tani, 2016)</ref>. Already during the first year of a human's life, sensorimotor abstraction leads to higher-level preverbal concepts that enable problemsolving and the understanding of simple language <ref type="bibr" target="#b65">(Mandler, 2004)</ref>. These concepts are grounded in sensorimotor experiences and perception, being later on shaped by our acquired language. Cognitive sciences often refer to such preverbal general concepts as image schemas <ref type="bibr" target="#b59">(Lakoff and Johnson, 2010;</ref><ref type="bibr" target="#b105">Turner, 2015)</ref> or, in a more linguistic context, semantic frames <ref type="bibr" target="#b6">(Barsalou, 2008;</ref><ref type="bibr" target="#b40">Gamerschlag et al., 2014)</ref>.</p><p>How exactly such concepts are represented in biological neural structures remains largely unknown. In particular, there is a lack of research concerned with the semantic compositionality of mental concepts. There exists phenomenological research from the cognitive sciences community to model compositional high-level concept formation <ref type="bibr" target="#b59">(Lakoff and Johnson, 2010;</ref><ref type="bibr" target="#b105">Turner, 2015;</ref><ref type="bibr" target="#b30">Eppe et al., 2018)</ref>. On the other end of the spectrum, there also exists very low-level neuroscientific research showing the compositionality of distributed neural activation patterns via neuroimaging <ref type="bibr" target="#b45">(Haynes et al., 2015)</ref>. Between these extremes, there is some very interesting work related to binding neurons <ref type="bibr" target="#b90">(Shastri, 1999</ref>) that can potentially model semantic role-filler bindings known from cognitive linguistics. The event segmentation theory (EST) is a biologically plausible model to explain action abstraction based on prediction errors <ref type="bibr" target="#b114">(Zacks et al., 2007)</ref>. However, to the best of our knowledge, no computationally verified and functional unifying theory integrates the cognitive sciences and linguistics perspective on symbolic compositional mental representations with the neuroscientific perspective of representing mental concepts as distributed neural activation patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2.">Abstract Mental Concepts for Language and Creative Thought</head><p>Abstract preverbal concepts are not only critical for language acquisition, but they are also very important for creativity <ref type="bibr" target="#b105">(Turner, 2015)</ref>. For example, consider the metaphorical concepts of files and folders of a computer's operating system: the terminology for these concepts comes from the pre-digital age, originally from non-electronic paper-based files and folders. Blending this terminology with the tree-based algorithmic pointer concepts behind a computer's file system was a creative act that made it possible to align a human's pre-existing conceptual system with new technology and helped to improve the usability of early operating systems like Windows 95. <ref type="bibr" target="#b23">Confalonieri et al. (2015</ref><ref type="bibr" target="#b24">Confalonieri et al. ( , 2016</ref><ref type="bibr" target="#b22">Confalonieri et al. ( , 2018</ref> and <ref type="bibr" target="#b30">Eppe et al. (2018)</ref> demonstrate the importance of such concept blending with a functional computational model that allows an artificial agent to combine two known concepts to new concepts with emergent useful and aesthetic properties. The authors show how the new blended concepts lead to the creative and serendipitous discovery of lemmas required for mathematical proofs and the automated (re-)discovery of famous chord progressions in jazz music.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Embodied Language Acquisition</head><p>Preverbal and abstract semantic concepts are the basis for language. Since abstract concepts emerge from low-level sensorimotor interaction, the body and environment have a great impact on our thinking and language acquisition <ref type="bibr" target="#b33">(Feldman and Narayanan, 2004)</ref>. Several studies highlight that hearing or reading language about action and perception activates related areas of the brain, showing that there are neural representations reflecting an individual's way of performing actions when heard (see the overview by <ref type="bibr" target="#b111">Willems et al., 2010</ref> or the work about the mirror system by <ref type="bibr" target="#b84">Rizzolatti and Arbib, 1998)</ref>. This is compatible with ideomotor theory <ref type="bibr" target="#b92">(Shin et al., 2010)</ref> and mental simulation theory, which claims that humans simulate actions unconsciously within those areas of the brain responsible for motor planning. As a result, there exists an embodied mental semantics <ref type="bibr" target="#b33">(Feldman and Narayanan, 2004;</ref><ref type="bibr" target="#b97">Steels, 2007;</ref><ref type="bibr" target="#b111">Willems et al., 2010)</ref>, implying that living entities with different kinds of bodies simulate in different ways. For example, consider the difference between right-and left-handed people, using the contrary sides of the premotor cortex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Language Acquisition as Resolution of Mismatches</head><p>Mandler <ref type="formula">2004</ref>describes the preverbal phase in infants as dominated by general conceptual knowledge that is in a mismatch with the language we understand and start to use at the age of 9 months. General conceptual knowledge is required to execute goal-directed actions, understand spatial relationships and the difference between objects and animals. The conceptual knowledge is also important to derive non-trivial intentions of conversation partners <ref type="bibr" target="#b104">(Trott et al., 2016)</ref>. Consequently, when language becomes more important during a toddler's early life, there is a need to compensate for the mismatch between the rich self-acquired conceptual knowledge and the words used to describe the world. For example, toddlers would assign the word dog to a fox since they do not yet have the language to differentiate them more precisely <ref type="bibr" target="#b65">(Mandler, 2004)</ref>. Similar to machine learning models with the objective of classifying foxes, wolves, and specific breeds of dogs distinctively, a child would pay at some point closer attention to the details if the appearance is different, but the describing word stays the same <ref type="bibr" target="#b65">(Mandler, 2004)</ref>. One can also think about the attributes mentioned, like black cat, red car, or big dog, to accentuate a specific property, helping with the mapping of words to organize categories <ref type="bibr" target="#b109">(Waxman and Markow, 1995)</ref>. Mainly using a mixture of receptive language and producing words and simple sentences allows them to learn about things being said to and about them. Especially parents often explain to their children what they are doing, allowing them to learn word mappings to actions and objects nearly automatically, known as perceptual learning <ref type="bibr" target="#b65">(Mandler, 2004)</ref>. There is also a lot of imitation involved, e.g., replicating actions of social partners, repeating perceived utterances, or recalling sentences in a specific context.</p><p>There are still open questions at which point in time infants are capable of learning specific differences, especially those that are hard to grasp, like varieties between similar-looking plants that are not that frequently experienced in their daily life <ref type="bibr" target="#b65">(Mandler, 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Toward Narrative, Egocentric, and Goal-Directed Language</head><p>When the first form of language is learned, infants tend to use egocentric speech, where they narrate their own activities <ref type="bibr" target="#b82">(Piaget, 1926)</ref>. Even though they do not have fully learned fluent language like adults, they use their present concepts and actively reinforce their speech in their own doing. This is different from babbling from an earlier stage, where the overall learning goal is to explore and correct their internal motor model of speech production with respect to adult language heard (see section 2.1). Furthermore, after infants learn a first basic corpus of language, they start using it to describe their intrinsically motivated goals. This can happen by just saying the word "arm" to tell their caregiver that they want to be picked up or by issuing more complex multi-word sentences of the form "I want X, " where the "I" reflects an emerging concept of the self <ref type="bibr" target="#b42">(Georgie et al., 2019)</ref>. Such goal-directed utterances to caregivers are among the first language-based communication situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">The Self and Communication</head><p>Language is very effective when it comes to communicating with other humans. The efficiency stems from the compositional structure of natural language. Most natural languages build on a finite vocabulary in the order of magnitude of 100,000 to 200,000 actively used words that can be composed to express an intractable number of different sentences and meanings. Our acquired knowledge about grammar, syntax, and semantics enables us to understand most of these compositions, even if we have never heard them before. For example, you may never have heard the sentence "She sneezed the napkin off the table.", but your knowledge about English grammar enables you to correctly understand it. This demonstrates that language is an important cognitive tool to convey meaning <ref type="bibr" target="#b69">(Mirolli and Parisi, 2011;</ref><ref type="bibr" target="#b21">Colas et al., 2020;</ref><ref type="bibr" target="#b32">Eppe and Oudeyer, 2021)</ref>. However, the self described in recent literature <ref type="bibr" target="#b87">(Schillaci et al., 2016;</ref><ref type="bibr" target="#b43">Hafner et al., 2020;</ref><ref type="bibr" target="#b74">Nguyen et al., 2021)</ref> is also important for embodied dialog. The self builds upon the actor's capabilities to sense its own body and the environment. It is, therefore, characterized by the response to actions and predictions of the internal model <ref type="bibr" target="#b87">(Schillaci et al., 2016;</ref><ref type="bibr" target="#b43">Hafner et al., 2020)</ref>. Grounded language in the context of the self refers to the context of these senses. For example, the phrase "Hand me the box to your left." (see <ref type="figure" target="#fig_0">Figure 1B)</ref> requires the robot to classify and detect the desired object <ref type="bibr" target="#b66">(Matuszek et al., 2012)</ref> that is next to itself. Once the sentence is understood, a sequence of motor controls needs to be executed to fulfill the instruction. While the language already contains important contextual information, such that it is a box and not another object, which requires different balancing and grasping, the clue "next to you" suggests the object be in reachable distance, also described as peripersonal space <ref type="bibr" target="#b74">(Nguyen et al., 2021)</ref> with respect to the self. The executed actions are conditioned on the initial instruction of handing over the bottle. The theory about the mirror system by <ref type="bibr" target="#b84">Rizzolatti and Arbib (1998)</ref> hightlights the linkage between language and action representations <ref type="bibr" target="#b110">(Wermter et al., 2009)</ref>: Humans can merely recognize the intent of others by observing their behavior, e.g., if someone is approaching another person offensively. Intention recognition, however, plays a core role in communication and dialogs. We build on this neuroscientific perspective to underpin our claim that a self-and other-manifold is essential for embodied dialogs.</p><p>Current computational methods cannot effectively learn a theory of mind with the concepts of you and me. Therefore, they fail to learn robust and general behaviors. We suppose that this gap is due to a lack of understanding of "the self " <ref type="bibr" target="#b43">(Hafner et al., 2020)</ref>, and how it is defined in the context of "the other." Specifically, we suggest that a self-other projection model is critical for empathy and a theory of mind to map an observed other agent, along with its semantic properties and relations, to the self and its semantic properties and relations.</p><p>In the following section, we will address this gap by investigating the computational language acquisition models that exist and summarize how they relate to the cognitive, psychological, and neurological perspectives on the communicative self.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">COMPUTATIONAL METHODS</head><p>Current advances in neural language modeling accelerated the research progress in many NLP tasks <ref type="bibr" target="#b107">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b28">Devlin et al., 2019)</ref>. Successful pre-trained one-shot models like GPT-3 <ref type="bibr" target="#b13">(Brown et al., 2020</ref>) have many useful applications. Remarkable results were presented with the recently introduced successor version of GPT-3, named DALL-E <ref type="bibr" target="#b83">(Ramesh et al., 2021)</ref>, which learns visual-linguistic representations that align textual with image inputs to generate, based on text descriptions, samples of new pictures, showing up compositional conceptualization. For example, the sentence "a red table in shape of a pentagon" lets the model generate samples of red pentagon-shaped tables based on its learned multimodal representations. However, models like GPT-3 and DALL-E consider only disembodied language learning without any sensorimotor grounding because, unlike robots, they cannot physically interact with the world. Insights for grounded language learning in robotics <ref type="bibr" target="#b46">(Heinrich et al., 2020)</ref> with sequential decision-making settings <ref type="bibr" target="#b1">(Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref> and embodied cognition <ref type="bibr" target="#b33">(Feldman and Narayanan, 2004;</ref><ref type="bibr" target="#b35">Fischer and Zwaan, 2008)</ref> accentuate the need for embodied grounding. This includes physical interaction and multiple sensory modalities to develop systems that understand language more like humans <ref type="bibr" target="#b3">(Anderson, 1972;</ref><ref type="bibr" target="#b110">Wermter et al., 2009;</ref><ref type="bibr" target="#b67">McClelland et al., 2020)</ref>. Additional prerequisites for modeling a communicative self requires curiosity, body representations, and predictive processes <ref type="bibr" target="#b43">(Hafner et al., 2020;</ref><ref type="bibr" target="#b32">Eppe and Oudeyer, 2021)</ref>. In reinforcement learning, there is a body of research <ref type="bibr" target="#b78">(Pathak et al., 2017;</ref><ref type="bibr" target="#b27">Dean et al., 2020;</ref><ref type="bibr" target="#b73">Nguyen et al., 2020;</ref><ref type="bibr" target="#b85">Röder et al., 2020)</ref>, containing these components. However, to the best of our knowledge, these prerequisites have not yet been combined with language and the self in mind. Overall, there is a lack of research methods that regard the self in the area of RL, explicitly making use of language in embodied dialogs <ref type="bibr" target="#b44">(Hahn et al., 2020)</ref>. This section reviews methods that partly satisfy the requirements but still miss at least one of the desired components. Furthermore, we provide an outlook on what needs to be recombined or is missing to learn self-other representations in embodied dialogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Formal Background</head><p>Reinforcement learning <ref type="bibr" target="#b100">(Sutton and Barto, 2018</ref>) is based on a Markov decision process (MDP) defined by a tuple (S, A, T, R, γ ), where S is the space of all possible states, A the space of all possible actions, T : S×A×S → [0, ∞) the transition probability function, R : S×A → R the reward function, and γ ∈ [0, 1) is the discount factor. The transition function represents a probability density of transitioning to a following state s ′ ∈ S, when executing action a ∈ A, being in state s ∈ S. The reward function describes the immediate real-valued reward obtained when transitioning to the next state. The overall objective is to find a policy π that selects actions, π(a t |s t ), to maximize the expected discounted reward T t=1 E π γ t R(s t , a t ) for every time step t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">RL and Imitation Learning</head><p>The definition of the MDP, as mentioned earlier, also applies to the framework of imitation learning (IL) <ref type="bibr" target="#b4">(Atkeson and Schaal, 1997;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref>, where the learner only has access to a sequence of state-action pairs (s 1 : T , a 1 : T ) of an expert-hence the optimal or suboptimal policy-without knowing the reward function R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Language as Goal</head><p>In this review, we consider papers that also augment this setup with a set of goals G and condition the action-selection of the policy based on the present state and goal, π(a t |s t , g t ), also named as goal-conditioned RL <ref type="bibr" target="#b75">(Oh et al., 2017;</ref><ref type="bibr" target="#b17">Chaplot et al., 2018;</ref><ref type="bibr" target="#b18">Chevalier-Boisvert et al., 2019;</ref><ref type="bibr" target="#b54">Jiang et al., 2019;</ref><ref type="bibr" target="#b21">Colas et al., 2020;</ref><ref type="bibr" target="#b85">Röder et al., 2020;</ref><ref type="bibr" target="#b1">Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref>. One way of integrating language into the augmented MDP, is to learn a mapping from language to goal, m(l t ) → g t . Another approach is to provide extra input to the policy or concatenate and extend the dialog state as a combination of language and world state, s t = s world t , s dialog t . However, these are technical questions that we do not further consider within this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Recent Advances in Reinforcement Learning With Language</head><p>Modeling language occurrences in a simulated environment is not obvious to implement, and using human-annotated linguistic training data is usually inefficient and costly. It is also a very specific design decision, how complex the sentences and how limited the vocabulary of words used to train the agent are (see section 3.3).</p><p>The review of <ref type="bibr" target="#b60">Luketina et al. (2019)</ref> provides an overview of the recent progress of language-processing RL agents where researchers explore possibilities of integrating neuro-plausible principles, such as intrinsic motivation <ref type="bibr" target="#b36">(Forestier et al., 2017;</ref><ref type="bibr" target="#b21">Colas et al., 2020)</ref>, to foster language learning. Many approaches benefit from mapping instructions to action sequences <ref type="bibr" target="#b12">(Branavan et al., 2010;</ref><ref type="bibr" target="#b70">Misra et al., 2017)</ref>, latent plans <ref type="bibr" target="#b62">(Lynch and Sermanet, 2021)</ref>, semantic goals <ref type="bibr" target="#b1">(Akakzia et al., 2021)</ref>, and internal abstractions <ref type="bibr" target="#b54">(Jiang et al., 2019)</ref>. In section 3.3, we further examine the possibilities of providing language data to artificial agents that learn from sparse rewards as successfully presented by recent approaches <ref type="bibr" target="#b60">(Luketina et al., 2019;</ref><ref type="bibr" target="#b27">Dean et al., 2020;</ref><ref type="bibr" target="#b1">Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref>. We see a trend of detaching from the traditional MDP formulation and integration imitationbased <ref type="bibr" target="#b62">(Lynch and Sermanet, 2021)</ref> and self-supervised methods <ref type="bibr" target="#b1">(Akakzia et al., 2021)</ref> into a learning framework to autonomously acquire motor skills and language understanding with minimal human intervention. We draw inspiration from the intrinsically motivated learning of infants, like mentioned in section 2, based on a cognitive and developmental perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Dataset-Driven RL Methods</head><p>Generally, methods make use of sparse goal annotations <ref type="bibr" target="#b1">(Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref> or generate scenedependent descriptions <ref type="bibr" target="#b71">(Narasimhan et al., 2018;</ref><ref type="bibr" target="#b50">Hill et al., 2021)</ref> and instructions <ref type="bibr" target="#b47">(Hermann et al., 2017;</ref><ref type="bibr" target="#b75">Oh et al., 2017;</ref><ref type="bibr" target="#b17">Chaplot et al., 2018;</ref><ref type="bibr" target="#b18">Chevalier-Boisvert et al., 2019)</ref>. Such methods often build on a previously collected fixed dataset. Therefore, most language-conditioned and language-assisted agents are limited in these settings as they do not reveal behavioral diversity, sticking to a poor set of discovered solutions. This is a problem for embodied agents in dialogs and HRI, with potential uncertainties and inaccuracies coming with dynamics of the physical world. Furthermore, many do not consider all the available modalities to build rich and robust representations, including self-representation <ref type="bibr" target="#b73">(Nguyen et al., 2020)</ref>. Recent work shows that RL with language needs another type of benchmarking, similar to supervised learning, evaluating the agent on unseen tasks, objects, and instructions <ref type="bibr" target="#b49">(Hill et al., 2020)</ref>. Otherwise, one could not prove the generalizability of learned feature representations that encode concepts and meanings that are relevant. Especially for our case, we consider an embodied conversational setup with an agent and a human communicating, where having a self-other representation is beneficial if not crucial (see <ref type="figure" target="#fig_0">Figure 1B)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Adding Dynamic Data and Language Grounding</head><p>Using datasets only to train RL-based dialog agents creates limitations. However, datasets can be used for pre-training when a basic understanding of language is necessary to solve a certain task. They can also be augmented with other data, such as demonstrations and pre-trained word embeddings. This can also be combined with other learning methods, such as inverse RL.</p><p>Interesting perspectives in this direction are covered in the work of <ref type="bibr" target="#b60">Luketina et al. (2019)</ref>: The authors consider languageconditioned RL, where language processing is inevitable to fulfill a task because either the state space or action space contains language. A sequence of instructions needs to be followed, telling the agent what to do or which goal to accomplish. The authors argue that following high-level instructions has a strong connection to hierarchical RL (HRL) <ref type="bibr" target="#b75">(Oh et al., 2017;</ref><ref type="bibr" target="#b54">Jiang et al., 2019)</ref>, decomposing the overall dialog into a sequence of subtasks <ref type="bibr" target="#b85">(Röder et al., 2020)</ref>.</p><p>Another approach presented in the same study <ref type="bibr" target="#b60">(Luketina et al., 2019)</ref> is to infer the reward function from the present instructions, especially where no external reward is available, but a set of demonstrations is present. A suitable strategy in such a case is inverse RL <ref type="bibr" target="#b72">(Ng and Russell, 2000)</ref>. An optimal or suboptimal policy trajectory is used to reconstruct the underlying reward function R as the origin of the demonstration policy's behavior. Unlike behavior cloning, as the simplest form of imitation learning, a goal-achievement reward function could be learned <ref type="bibr" target="#b21">(Colas et al., 2020)</ref>, which could also be helpful for intrinsically motivated-and transfer learning.</p><p>Next, <ref type="bibr" target="#b60">Luketina et al. (2019)</ref> consider language-assisted RL, which is also partly related to language-conditioned RL, where language eases the learning and is not required to solve a task. Here, language is descriptive and contains assisting clues for the agent, e.g., "be careful with the delicate plates" (as additional hint before the agent tries to pick them up) or "to open a door, it needs to be unlocked with a key" (the agent is facing a door and is stuck or randomly tries to find a solution). This setting requires the agent to retrieve the relevant information for a given context, where a grounded language understanding is inevitable. <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> show that combining imitation learning with pre-trained word embeddings enables zero-shot learning. Approaching problems with pre-trained models like BERT from <ref type="bibr" target="#b28">Devlin et al. (2019)</ref> can circumvent the effort to train so-called "tabula rasa" RL agents <ref type="bibr" target="#b60">(Luketina et al., 2019)</ref>, that is, agents that need to learn language and sensorimotor control simultaneously from scratch. Conclusively, language is a vehicle for transfer learning, as it encodes world knowledge distilled from large text corpora <ref type="bibr" target="#b28">(Devlin et al., 2019;</ref><ref type="bibr" target="#b13">Brown et al., 2020)</ref>. We believe that language in RL <ref type="bibr" target="#b60">(Luketina et al., 2019)</ref> should focus on aligning its sensorimotor representations, learning from multisensory inputs <ref type="bibr" target="#b50">(Hill et al., 2021;</ref><ref type="bibr" target="#b83">Ramesh et al., 2021)</ref> that exploit and ground the present compositional and hierarchical linguistic concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Language Data for RL Agents</head><p>When infants interact with their caretakers and the world, they receive visual, auditory, and haptic feedback. In addition, they are also exposed to linguistic utterances and speech in the context of this interaction. In machine learning, this corresponds to interactive RL <ref type="bibr" target="#b26">(Cruz et al., 2015)</ref>. However, as opposed to human infants that can learn from a few examples very efficiently, RL agents require large amounts of interaction data to learn a reasonable behavior. Furthermore, the required presence of a human partner in the training process is still costly and timeconsuming. For this review, we consider approaches (1) that can efficiently collect language before training <ref type="bibr" target="#b17">(Chaplot et al., 2018;</ref><ref type="bibr" target="#b71">Narasimhan et al., 2018)</ref>, (2) that can automatically generate linguistic instructions at training and testing time <ref type="bibr" target="#b47">(Hermann et al., 2017;</ref><ref type="bibr" target="#b18">Chevalier-Boisvert et al., 2019;</ref><ref type="bibr" target="#b54">Jiang et al., 2019;</ref><ref type="bibr" target="#b49">Hill et al., 2020</ref><ref type="bibr" target="#b50">Hill et al., , 2021</ref>, and (3) that require only minimal linguistic input for an agent in the learning process <ref type="bibr" target="#b21">(Colas et al., 2020;</ref><ref type="bibr" target="#b1">Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Gathering Data in Advance</head><p>Approaches that fall into the first category, such as <ref type="bibr" target="#b71">Narasimhan et al. (2018)</ref> and <ref type="bibr" target="#b17">Chaplot et al. (2018)</ref>, gather language data in advance. <ref type="bibr" target="#b71">Narasimhan et al. (2018)</ref> utilize Amazon Mechanical Turk <ref type="bibr" target="#b14">(Buhrmester et al., 2011)</ref> to collect descriptions of entities (their roles or behaviors) in different game environments-Amazon Mechanical Turk offers a crowdsourcing website where researchers can hire so-called crowd workers to collect large amounts of data easily and rapidly for a particular task. For each game environment, annotators are shown videos of gameplay and asked to describe entities in terms of their role or behavior, whereby a set of descriptions are collected. It is important to note that the annotators are prompted to give descriptive information about the entities rather than instructive information, which may help the agent complete the given task. The agent, in turn, exploits the appropriate set of descriptions in an end-toend learning process to reach its goal for a given environment. <ref type="bibr" target="#b17">Chaplot et al. (2018)</ref>, on the other hand, manually create 70 instructions that prompt the agent to navigate in a 3D game environment and find the target object. Each instruction follows the template "Go to the X" where X is an object with its properties such as "green torch, " "tall blue object" etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Automated Generation of Verbal Instructions</head><p>The second category approaches, such as Chevalier-Boisvert et al. <ref type="formula">2019</ref>and <ref type="bibr" target="#b54">Jiang et al. (2019)</ref>, can automatically generate language input during training and testing. <ref type="bibr" target="#b54">Jiang et al. (2019)</ref> use the CLEVR language engine <ref type="bibr" target="#b55">(Johnson et al., 2017)</ref>, which programmatically generates scenes of objects and language descriptions/instructions. This also requires the agent to learn a language-conditioned policy in an end-to-end fashion (see section 3.2). In this sparse-reward setting, the authors use hindsight instruction relabeling <ref type="bibr" target="#b54">(Jiang et al., 2019)</ref> to improve sample efficiency. Chevalier-Boisvert et al. <ref type="formula">2019</ref>introduce a synthetic language, the Baby Language, which has a systematic definition with combinatorial properties. Albeit a proper subset of English, the Baby Language has 2.48 × 10 19 possible instructions. It has a special grammar based on which synthetic instructions with different actions (pick up, drop, move), colors, objects, and locations (e.g., "move the green ball next to the blue box") can be generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Training With Sparse Data</head><p>Lynch and Sermanet (2021) and <ref type="bibr" target="#b1">Akakzia et al. (2021)</ref> are considered in the third category because they require only very little language data for the agent during the learning process. <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> introduce multicontext imitation, which allows flexibility to use paired state-action language data for less than 1% of the examples to train the agent. They pair play data with human language, which they call hindsight instruction pairing. They randomly select a robot behavior from play and ask human annotators to describe it with the most suitable instruction, with the question "Which language instruction makes the trajectory optimal?" in their mind. From goal image examples, a paired goal image and language dataset is created that consists of short trajectories paired with unrestricted instructions collected from human annotators. <ref type="bibr" target="#b1">Akakzia et al. (2021)</ref> utilize a synthetic social partner that describes the actions of the robotic arm manipulating objects in a simulator.</p><p>The first two category methods that we review in this paper do not strictly follow the approach we propose in this work. Many of them integrate the language data directly into the simulation. For our approach, we consider two phases (see <ref type="figure">Figure 4)</ref> where data collection is important: skill learning and language grounding. As a first phase in the skill learning <ref type="bibr" target="#b1">(Akakzia et al., 2021)</ref>, the agent curiously collects data to learn goal-directed behaviors, similar to infants in their preverbal phase (see section 2), shaping their body schema <ref type="bibr" target="#b73">(Nguyen et al., 2020)</ref>. Subsequently, a social partner or caregiver provides the language to be grounded in the present goal-directed motor skills. Like infants, the agent should align and learn word meanings with the corresponding action effects. We consider a sparse annotation like applied in <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> with hindsight instructions of &lt; 1% of demonstrations-proposing the optimal instruction after the fact-or behavior annotations like <ref type="bibr" target="#b1">(Akakzia et al., 2021)</ref> with only 10% of episodes as plausible approaches in line with the sparse utterances an infant experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Decoupling Language Grounding From Skill Learning</head><p>We visually summarize our review of research with respect to different approaches used in language-driven RL in <ref type="figure">Figure 3</ref>. The figure illustrates the underlying techniques, showing the most overlaps with respect to the categories multitask, hierarchy, curiosity, and hindsight in RL. Based on this categorization, we identify two methods that we consider most appropriate to address the research question of this article, namely <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> and <ref type="bibr" target="#b1">Akakzia et al. (2021)</ref>. Among the approaches we discuss here, only these two consider the decoupling of learning skills and grounding language for an embodied robot in a 3D environment. This is important because in order to benefit from insights of preverbal goal-conditioned behavior in human infants <ref type="bibr" target="#b112">(Wood et al., 1976;</ref><ref type="bibr" target="#b65">Mandler, 2004)</ref>, artificial agents should be able to learn sensorimotor skills without the presence of language right at the beginning of the learning process. For our following discussion, we perform an indepth analysis of these two methods. Based on the insights from section 2, we split the overall learning into two phases, as shown in <ref type="figure">Figure 4</ref>: skill learning and language grounding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Skill Learning</head><p>The skill learning phase <ref type="figure">(Figures 4A,B)</ref> treats the sensorimotor skill learning as (a) learning those skills independently via imagined goals or concepts like self-play and intrinsic motivation or (b) emulating the behaviors of a caregiver via imitation or supervised learning. In the first case <ref type="figure">(Figure 4A)</ref>, the agent could learn via intrinsically motivated play or mental problem-solving (imagination) to explore possible block configurations <ref type="bibr" target="#b1">(Akakzia et al., 2021)</ref>. This is similar to how an infant learns by exploring the environment while interacting with the objects around.</p><p>In the second case <ref type="figure">(Figure 4B)</ref>, the agent could learn by imitating the caregiver <ref type="bibr" target="#b62">(Lynch and Sermanet, 2021)</ref>. <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> conducted imitation learning on a dataset of play data. One benefit of play data is the unrestricted setup without solving any particular tasks. In their setup <ref type="bibr" target="#b62">(Lynch and Sermanet, 2021)</ref> have a fixed robot arm in front of a desk with buttons, a cupboard, and other objects. The dataset is collected by recording the proprioceptive inputs, images from the camera, and executed motor control. Herein, the agent benefits from a knowledgeable human collecting the data. This yields a dataset of diverse and curious behaviors, including knowledge about object affordances. FIGURE 3 | A selection of reinforcement learning methods which we categorize according to their properties. Multitask RL involves methods that learn a policy to solve and transfer knowledge between different tasks. Hindsight learning allows to create and learn from imagined- <ref type="bibr" target="#b21">(Colas et al., 2020)</ref> and relabeled goals <ref type="bibr" target="#b1">(Akakzia et al., 2021)</ref>. Methods using a hierarchy of policies/models are employed for temporal abstractions <ref type="bibr" target="#b54">(Jiang et al., 2019;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref>. Curiosity serves as an intrinsic signal to utilize self-supervision and overcome sparse extrinsic feedback <ref type="bibr" target="#b21">(Colas et al., 2020;</ref><ref type="bibr" target="#b1">Akakzia et al., 2021;</ref><ref type="bibr" target="#b50">Hill et al., 2021)</ref>. The methods with the largest overlaps, namely <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> and <ref type="bibr" target="#b1">Akakzia et al. (2021)</ref>, integrate both essential and cognitive plausible mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Language Grounding</head><p>In the second phase ( <ref type="figure">Figures 4C,D)</ref>, learning a grounded language is achieved by providing feedback or instructions. In <ref type="bibr" target="#b1">Akakzia et al. (2021)</ref>, a social partner-in our case, a caregiver ( <ref type="figure">Figure 4C)</ref>-provides linguistic feedback, describing the behavior of the agent in hindsight. The social partner provides a description that considers a change in spatial relations between any two objects from the starting configuration to the final in the scene. Language grounding is achieved via a languageconditioned goal generator (LGG) which is implemented as a conditional variational autoencoder <ref type="bibr" target="#b95">(Sohn et al., 2015)</ref>: given an initial configuration and a description, LGG generates a corresponding final configuration, the goal for the agent to achieve. Resampling from the LGG allows the agent to solve the instruction in different ways, resulting in a diverse behavior (see section 2.1). Similar to <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref>, only a small fraction of the author's dataset is annotated with instructions. These are provided in hindsight: after observing a particular behavior of the agent, the human provides the optimal "hindsight instruction" that would evoke this behavior. <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> extend the learning from play (LfP) approach <ref type="bibr" target="#b61">(Lynch et al., 2020)</ref> by pairing experienced trajectories with natural language instructions, which they coin as LangLfP. They introduce multicontext imitation to train a single policy on both image and language goals. Multicontext imitation refers to training a single policy on shared latent representations of goal image and natural language datasets using image and language encoders. Multicontext imitation endows the approach with the flexibility to use paired state-action language data for less than 1% of the examples to train an agent. Having the ability to learn from sparsely annotated data corresponds with how infants learn in the real world with very little feedback from their caregivers. The trained agent can relate language to lowlevel perception, perform visual reasoning and solve a complex sequential decision problem. As a result, it can follow non-expert human instructions to perform object manipulation tasks in a row. <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> also exploit a large-scale pretrained language model <ref type="bibr" target="#b107">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b113">Yang et al., 2020)</ref> to encode linguistic input; before feeding the language input to the network, they transfer it to a semantic vector space by using the pre-trained language model as an encoder. In this manner, the approach can handle unseen linguistic inputs such as synonyms, as well as instructions in 16 different languages. We suppose that FIGURE 4 | We accentuate the learning phases of current methods <ref type="bibr" target="#b1">(Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref> that have a grounded language acquisition by first learning behaviors/skills (A,B)-be it via imitation learning or intrinsic motivation-and following this, ground language in actions by receiving instructions or feedback from a caregiver (C,D).</p><p>training instruction-following and training dialog are suitable tasks for fine-tuning a pre-trained agent <ref type="figure">(Figure 4D)</ref>. Moreover, continuing to learn a pre-trained mapping of new objects to concepts appears to be a promising future approach to consider <ref type="bibr" target="#b50">(Hill et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE SELF IN AN EMBODIED DIALOG</head><p>In this section, we propose the computational components of an embodied dialog agent, informed by the above analysis of skill learning and language grounding and inspired by the recent work about self-representations of <ref type="bibr" target="#b43">Hafner et al. (2020)</ref> and <ref type="bibr" target="#b74">Nguyen et al. (2021)</ref>.</p><p>Naively, testing the capabilities of a language-aware agent could already involve tasks and instructions that specifically strain grounded language knowledge and selfother distinction (see <ref type="figure" target="#fig_0">Figure 1B)</ref>. However, we assume that research progress can be accelerated by observing the problem from a perspective of the artificial self <ref type="bibr" target="#b43">(Hafner et al., 2020;</ref><ref type="bibr" target="#b74">Nguyen et al., 2021)</ref> rather than disregarding the emerging properties as a side effect. The recent methods introduced in section 3 provide important techniques that implement the required ingredients and are helpful in improving embodied dialogs and HRI applications. Still, we see a lack of methods that combine all of them jointly into one learning architecture.</p><p>Current RL methods without language representations can be extended with it (section 3.4.2), as they already include the skill learning phase (section 3.4.1). This is an important feature of RL because skill learning is a necessary prerequisite for language grounding. However, since language grounding is not a necessary prerequisite for skill learning, we conclude that RLdriven physical skill learning is more foundational for embodied dialog agents than disembodied language processing models like GPT-3 <ref type="bibr" target="#b13">(Brown et al., 2020)</ref>.</p><p>In the remainder of this section, we summarize the computational components that are important to develop embodied dialog agents based on self-representations. In addition, we provide references to successful implementations of these components. We subdivide these components into those that are related to predictive processes and those that are related to self-other distinction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Predictive Processes and Crossmodal Self-Representations</head><p>Many methods compute prediction errors with inverse-and forward models that implement action-effect associations [e.g., <ref type="bibr" target="#b87">Schillaci et al., 2016;</ref><ref type="bibr" target="#b85">Röder et al., 2020</ref> and also neurosciencerelated work like <ref type="bibr" target="#b56">(Kaplan, 2007;</ref><ref type="bibr" target="#b57">Kidd and Hayden, 2015)</ref>]. At training time, these errors yield a signal for intrinsic motivation, helping to shape and update the body schema and sense of agency (see section 2.1). We see plenty of methods that implement this as curiosity-driven learning <ref type="bibr" target="#b78">(Pathak et al., 2017;</ref><ref type="bibr" target="#b73">Nguyen et al., 2020;</ref><ref type="bibr" target="#b1">Akakzia et al., 2021;</ref><ref type="bibr" target="#b50">Hill et al., 2021)</ref>. Other researchers model the prediction error not only with the sensory state but based on language. For example, <ref type="bibr" target="#b47">Hermann et al. (2017)</ref> and <ref type="bibr" target="#b50">Hill et al. (2021)</ref> consider word predictions given the egocentric view of an agent in a 3D environment. <ref type="bibr" target="#b47">Hermann et al. (2017)</ref> predict a word at each time step, while a meaningful word of the current instruction serves as a target, e.g., the object "apple" given the instruction "Pick up the red apple." This auxiliary task helps to shape the agent's representation in learning instruction The longer the simulation horizon, the more uncertain the agent is about its predicted action-effects (illustrated with increasing color transparency).</p><p>to word mappings. <ref type="bibr" target="#b50">Hill et al. (2021)</ref> compute a surprise score for both vision and language. An episodic memory with a specific language to vision key-mapping, inspired by dual-coding theory <ref type="bibr" target="#b77">(Paivio, 1969)</ref>, is queried to calculate a language-and visionbased distance as an intrinsic reward. Although this seems to be a promising approach, it is essential to consider some sort of weighting <ref type="bibr" target="#b50">(Hill et al., 2021)</ref>.</p><p>The authors empirically show that the less frequently encountered language is more important than the more frequently changing visual information. However, they are not using an appropriate body representation <ref type="bibr" target="#b78">(Pathak et al., 2017;</ref><ref type="bibr" target="#b73">Nguyen et al., 2020)</ref> for the vision encoding to omit the Noisy-TV Problem <ref type="bibr" target="#b15">(Burda et al., 2019)</ref>, which might be the reason for the superior performance when using intrinsic rewards based on language only. <ref type="bibr" target="#b27">Dean et al. (2020)</ref> implement an audiovisual association model to employ curiosity-driven exploration by exploiting the associations of two modalities, namely audio and vision.</p><p>The approaches above combine crossmodal integration in curiosity-driven and goal-directed learning procedures crucial for intelligent explorative behaviors <ref type="bibr" target="#b42">(Georgie et al., 2019)</ref>. When evaluating a trained agent, the internal models disclose metrics of surprise where the agent encounters dynamics that are novel or uncertainties with understanding instructions.</p><p>Other important computational components for embodied dialog agents include hierarchical abstraction <ref type="bibr" target="#b29">(Eppe et al., 2020)</ref> and automatically generated subtasks <ref type="bibr" target="#b54">(Jiang et al., 2019)</ref> or latent plans <ref type="bibr" target="#b62">(Lynch and Sermanet, 2021)</ref> to abstract away from low-level motor execution, toward higher-level conceptual representations. Abstractions are important because they limit the horizon of predictive processes. For example, in <ref type="figure" target="#fig_1">Figure 5</ref>, we illustrate sensorimotor simulation, using the internal model to unroll a latent (abstract) plan consisting of four steps only. If the same plan was represented in more fine-grained lowerlevel motor actions, this would lead to many more consecutive simulation steps, resulting in a higher cumulative prediction errors. Also, since predictions become less accurate the farther they are in the future, regenerating plans and subtasks happen more frequently. For example, <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> use a hierarchy with a high-level module (plan encoder) to generate a latent plan at the frequency of 1 Hz, while a low-level action module (plan decoder) is executing motor controls at a frequency of 30 Hz. Similarly, the implementation of <ref type="bibr" target="#b54">(Jiang et al., 2019)</ref> employs a 2-layer hierarchy that effectively leverages the compositionality of language to solve a task by solving subtasks.</p><p>Finally, having access to the agents internal hierarchical predictive state also allows observing metrics such as surprise and uncertainty (e.g., by measuring the prediction error) that expose how strong the sense of body ownership and agency is <ref type="bibr" target="#b42">(Georgie et al., 2019;</ref><ref type="bibr" target="#b43">Hafner et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Self-Other Distinction</head><p>The scenario of <ref type="figure" target="#fig_0">Figure 1B</ref> requires the agent to understand the meaning of self-related words like you and other related words like me. <ref type="bibr" target="#b42">Georgie et al. (2019)</ref> propose that distinguishing selfgenerated from externally produced sensational actions-effects are inevitable for an artificial self. By dividing the training procedure into two phases (section 3.4), agents learn the required body representations as describe by <ref type="bibr" target="#b42">Georgie et al. (2019</ref><ref type="bibr" target="#b74">), Nguyen et al. (2021</ref>. The authors consider motor babbling as an active self-exploration process, starting with selftouch in prenatal development up to toddlerhood. Considering the progression from this early stage, the evolved body ownership and sense of agency define the minimal self <ref type="bibr" target="#b42">(Georgie et al., 2019)</ref>. We suppose that this stage is covered by our first phase <ref type="figure">(Figures 4A,B)</ref>, employing motor babbling to train the internal models and motor skills from scratch.</p><p>The language-grounding phase (section 3.4.2) exploits the learned behaviors and body representations. This can be performed with a social partner or hindsight instructions to annotate behaviors. With the sense of body ownership developed during the skill learning phase, through minimal prediction error or free energy of inverse-and forward models, the agent can align its motor skills with grounded language. Socialpsychological scientists like <ref type="bibr" target="#b68">Mead et al. (2000)</ref> postulate the emergence of a self requires a social process based on the social theory of symbolic interactionism. However, there are limitations and different perspectives <ref type="bibr" target="#b2">(Aksan et al., 2009)</ref> toward social RL <ref type="bibr" target="#b53">(Jaques et al., 2019)</ref> and grounded language in a social context <ref type="bibr" target="#b9">(Bisk et al., 2020)</ref>. We consider these as future work and out of the scope of this article. Nevertheless, according to symbolic interactionism, self-awareness is a kind of reflection and inference of the behavioral observation of others. In other words, the self develops as a generalization of others, putting perception and expectations into the perspective of the social partners or group <ref type="bibr" target="#b68">(Mead et al., 2000)</ref>. This process allows sharing the same common understanding and thus the same language.</p><p>Despite the potential importance of social interaction, our review in section 3 reveals that only Chevalier-Boisvert et al. (2019) contain some sort of interactive partner or teacher that provides linguistic and demonstrative feedback. The authors use a 2D environment and employ a synthetic simplified language (section 3.3). We suggest two possibilities to enhance the integration of a social partner to train a self-aware agent for communication.</p><p>The first possibility follows the approach of <ref type="bibr" target="#b18">Chevalier-Boisvert et al. (2019)</ref>, where the language grounding phase integrates a social partner, caretaker, or teacher. This agent supplies language annotations in hindsight <ref type="bibr" target="#b1">(Akakzia et al., 2021)</ref> and, in addition, serves as an embodied entity that provides perceptible demonstrations in combination with language. The second possibility to develop a self for embodied dialog agents is to introduce a third alignment phase (see section 3.4), similarly to the developmental process of section 2.3.3, that involves external crossmodal sensory inputs of a social partner and considers finetuning the present motor-linguistic skills of the previous phases (sections 3.4.1 and 3.4.2).</p><p>In both cases, the language must explicitly refer to the individuals. Sentences like "You put red on top of the blue" or "I put red on top of blue" are possible examples that allow observing self-and externally generated stimuli in the context of language <ref type="bibr" target="#b67">(McClelland et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>This review contributes to the development of artificial agents for embodied crossmodal dialog. Our main hypothesis is that an explicit self representation is a critical component to enable embodied language understanding, going beyond disembodied language processing as proposed in recent machine learning articles. Reinforcement learning seems particularly suitable, as it allows by definition to discover the environment in a selfexplorative manner, similar to an infant shaping its body schema within a self-conducted reinforcement process. Like <ref type="bibr" target="#b62">Lynch and Sermanet (2021)</ref> and <ref type="bibr" target="#b1">Akakzia et al. (2021)</ref>, we suggest splitting the training of an agent into two phases, namely skill learning and language grounding (section 3.4). These two methods are the only ones regarding an embodied robot in a 3D environment and integrate most of the plausible concepts (see section 2 and <ref type="figure">Figure 3)</ref> with state-of-the-art performance for complex instruction following. After the skill learning phase, language is grounded in sensorimotor-and body representations, hence in essential parts of the artificial self <ref type="bibr" target="#b43">(Hafner et al., 2020)</ref>.</p><p>As our main result and contribution, we propose and summarize computational components to implement and model an artificial embodied dialog agent in section 4. Here, we highlight self-related components and expand the decoupled two-phased learning to a setting with an embodied social partner.</p><p>This approach is underpinned in social-psychological science <ref type="bibr" target="#b68">(Mead et al., 2000)</ref> and by recent findings in neurorobotics <ref type="bibr" target="#b43">(Hafner et al., 2020;</ref><ref type="bibr" target="#b74">Nguyen et al., 2021)</ref> which emphasize the significance of learning socially with other agents. These benefits arise because self-awareness and natural communication are learned by distinguishing self-generated from external stimuli and being part of social interaction. We believe that explicit self-representations in artificial agents improve robustness, performance, and trust for conversational settings because the emergence of a self is a consequence of low-level interaction with its body and environment <ref type="bibr" target="#b87">(Schillaci et al., 2016;</ref><ref type="bibr" target="#b43">Hafner et al., 2020)</ref> and high-level verbal/non-verbal social interactions <ref type="bibr" target="#b68">(Mead et al., 2000)</ref>.</p><p>In this article, we focus primarily on mechanistic cognitive models, but we are also aware of the valuable neuroscientific research that examines the use of the RL framework <ref type="bibr" target="#b11">(Botvinick and Weinstein, 2014)</ref>, grounded language <ref type="bibr" target="#b38">(Friederici and Singer, 2015;</ref><ref type="bibr" target="#b41">Garagnani and Pulvermüller, 2016)</ref>, and curiosity <ref type="bibr" target="#b56">(Kaplan, 2007;</ref><ref type="bibr" target="#b57">Kidd and Hayden, 2015)</ref>. Considering the integration these neuroscientific theories would add a valuable additional dimension to our future research.</p><p>A simulation of the self with artificial agents is another beneficial future research direction. For example, we can potentially gain more insights from attention-based mechanisms <ref type="bibr" target="#b17">(Chaplot et al., 2018;</ref><ref type="bibr" target="#b48">Hill et al., 2019)</ref>, enabling us to visualize the agent's internal state as a kind of gaze following and eye tracking [see <ref type="bibr" target="#b48">Hill et al. (2019)</ref>, how they visualize the attention weights of different neural network layers when processing language and vision]. Such research paves the ground for measuring and defining neurologically inspired low-level metrics of an artificial agent's self in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR CONTRIBUTIONS</head><p>FR and ME authored and conceptualized the major parts of this article. OÖ mainly authored and contributed to section 3, revised the manuscript, and was involved in discussions with FR and ME. PN provided feedback for FR to conceptualize the initial outline. SW contributed through active feedback and revisions. All authors contributed to the article and approved the submitted version.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc>(A) Misunderstanding a metaphor, potentially due to the lack of a self-representation. (B) A robot using the self as point of reference to understand an instruction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 5 |</head><label>5</label><figDesc>Internal models are capable of mentally simulating possible action trajectories given the visual observation and instruction of stacking the blocks.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Frontiers in Psychology | www.frontiersin.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">August 2021 | Volume 12 | Article 716671</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This idea was recently used to learn robust and diverse behaviors in goal-directed RL<ref type="bibr" target="#b1">(Akakzia et al., 2021;</ref><ref type="bibr" target="#b62">Lynch and Sermanet, 2021)</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>FR, PN, SW, and ME acknowledge funding by the DFG through the IDEAS (402776968) and LeCAREbot (433323019) projects. OÖ and SW acknowledge support from the German Research Foundation DFG, project CML (TRR 169).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest:</head><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p><p>Publisher's Note: All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p><p>Copyright © 2021 Röder, Özdemir, Nguyen, Wermter and Eppe. This is an openaccess article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social reinforcement in artificial prelinguistic development: a study using intrinsically motivated exploration architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Acevedo-Valle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Angulo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TCDS.2018.2883249</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cogn. Dev. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="198" to="208" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Grounding language to autonomously-acquired skills via goal generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akakzia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Colas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Oudeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chetouani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sigaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Symbolic interaction theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aksan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kısac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aydın</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Demirbuken</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.sbspro.2009.01.160</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Soc. Behav. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="902" to="904" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">More is different</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.177.4047.393</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="393" to="396" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robot learning from demonstration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Atkeson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<editor>D. H. Fisher Jr.</editor>
		<meeting><address><addrLine>Nashville, TN</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="12" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Infants&apos; physical knowledge: of acquired expectations and core principles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baillargeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language, Brain, and Cognitive Development: Essays in Honor of Jacques Mehler</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="341" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grounded cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Barsalou</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.59.103006.093639</idno>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="617" to="645" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recent advances in hierarchical reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1022140919877</idno>
	</analytic>
	<monogr>
		<title level="j">Discrete Event Dyn. Syst. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="41" to="77" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From exploration to play: a crosssectional study of infant free play behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Belsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Most</surname></persName>
		</author>
		<idno type="DOI">10.1037/0012-1649.17.5.630</idno>
	</analytic>
	<monogr>
		<title level="j">Dev. Psychol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="630" to="639" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Experience grounds language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chai</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.703</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8718" to="8735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weston</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Model-based hierarchical reinforcement learning and human action control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weinstein</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2013.0480</idno>
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. R. Soc. B Biol. Sci</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<biblScope unit="page">1655</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reading between the lines: learning to map high-level instructions to commands</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<meeting><address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1268" to="1277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<meeting><address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Amazon&apos;s mechanical turk: a new source of inexpensive, yet high-quality, data?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Buhrmester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gosling</surname></persName>
		</author>
		<idno type="DOI">10.1177/1745691610393980</idno>
	</analytic>
	<monogr>
		<title level="j">Perspect. Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3" to="5" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large-scale study of curiosity-driven learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The Genesis of Animal Play: Testing the Limits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Burghardt</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/3229.001.0001</idno>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gated-attention architectures for task-oriented language grounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Chaplot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Sathyendra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Pasumarthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rajagopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Artificial Intelligence</title>
		<editor>S. A. McIlraith and K. Q. Weinberger</editor>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2819" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BabyAI: first steps towards grounded language learning with a human in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chevalier-Boisvert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lahlou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amodei</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03741</idno>
		<title level="m">Deep reinforcement learning from human preferences</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Surfing Uncertainty: Prediction, Action, and the Embodied Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780190217013.001.0001</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford; New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Language as a cognitive tool to imagine goals in curiosity driven exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Colas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Dussoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Moulin-Frier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dominey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3761" to="3774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Upward refinement operators for conceptual blending in the description logic EL ++</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Confalonieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schorlemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pe Naloza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10472-016-9524-8</idno>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="69" to="99" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Upward refinement for conceptual blending in description logic &quot;an ASP-based approach and case study in EL ++</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Confalonieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schorlemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Ontologies and Logic Programming for Query Answering</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conceptual blending in El++</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Confalonieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schorlemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Description Logics</title>
		<meeting><address><addrLine>Cape Town</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Textworld: a learning environment for text-based games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Á</forename><surname>Kádár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kybartas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fine</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-24337-1_3</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Games</title>
		<editor>T. Cazenave, A. Saffidine, and N. Sturtevant</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1017</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Interactive reinforcement learning through speech guidance in a domestic scenario</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Twiefel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Magg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN.2015.7280477</idno>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (Killarney)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">See, hear, explore: curiosity via audiovisual association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tulsiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="14961" to="14972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gumbsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kerzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Butz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<title level="m">Hierarchical principles of embodied reinforcement learning: a review</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A computational framework for conceptual blending</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Maclean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Confalonieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schorlemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2017.11.005</idno>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page" from="105" to="129" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">From semantics to execution: integrating action planning with reinforcement learning for robotic causal problem-solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<idno type="DOI">10.3389/frobt.2019.00123</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Robot. AI</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">123</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Intelligent behavior depends on the ecological niche: interview with Dr. Pierre-Yves Oudeyer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Oudeyer</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13218-020-00696-1</idno>
	</analytic>
	<monogr>
		<title level="j">Künstliche Intelligenz</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="103" to="108" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Embodied meaning in a neural theory of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0093-934X(03)00355-9</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Lang</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="385" to="392" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">From Molecule to Metaphor: A Neural Theory of Language. A Bradford Book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Feldman</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/3135.001.0001</idno>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Embodied language: a review of the role of the motor system in language comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210701623605</idno>
	</analytic>
	<monogr>
		<title level="j">Q. J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="825" to="850" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Intrinsically motivated goal exploration processes with automatic curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Forestier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Oudeyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Concepts and compositionality: in search of the brain&apos;s language of thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Frankland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Greene</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-122216-011829</idno>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="273" to="303" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Grounding language processing on basic neurophysiological principles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Friederici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Singer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2015.03.012</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="329" to="338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The free-energy principle: a rough guide to the brain?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2009.04.005</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="293" to="301" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Frames and Concept Types: Applications in Language and Philosophy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gamerschlag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gerland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Osswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Petersen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-01541-5</idno>
	</analytic>
	<monogr>
		<title level="j">Studies in Linguistics and Philosophy</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<date type="published" when="2014" />
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Conceptual grounding of language in action and perception: a neurocomputational model of the emergence of category specificity and semantic hubs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garagnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pulvermüller</surname></persName>
		</author>
		<idno type="DOI">10.1111/ejn.13145</idno>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="721" to="737" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An interdisciplinary overview of developmental indices and behavioral measures of the minimal self</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Georgie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schillaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<idno type="DOI">10.1109/DEVLRN.2019.8850703</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Development and Learning and Epigenetic Robotics</title>
		<meeting><address><addrLine>Oslo</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Prerequisites for an artificial self</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Loviken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pico Villalpando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schillaci</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnbot.2020.00005</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Neurorobot</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Where are you? Localization from embodied dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.59</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="806" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">fMRI decoding of intentions: compositionality, hierarchy and prospective memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wisniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gorgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Reverberi</surname></persName>
		</author>
		<idno type="DOI">10.1109/IWW-BCI.2015.7073031</idno>
	</analytic>
	<monogr>
		<title level="m">International Winter Conference on Brain-Computer Interface</title>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers Inc</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Crossmodal language grounding in an embodied neurocognitive model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kerzel</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnbot.2020.00052</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Neurorobot</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">52</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Faulkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Soyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06551</idno>
		<title level="m">Grounded language learning in a simulated 3D world</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Understanding early word learning in situated artificial agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09867</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Environmental drivers of systematicity and generalization in a situated agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<publisher>Addis Ababa</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Grounded language learning fast and slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Von Glehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Merzic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clark</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Body schema in robotics: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arieta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sumioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lungarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pfeifer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAMD.2010.2086454</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Auton. Mental Dev</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="304" to="324" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The body schema and multisensory representation(s) of peripersonal space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Spence</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10339-004-0013-3</idno>
	</analytic>
	<monogr>
		<title level="j">Cogn. Process</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="94" to="105" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Social influence as intrinsic motivation for multi-agent deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Strouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<editor>K. Chaudhuri and R. Salakhutdinov</editor>
		<meeting><address><addrLine>Long Beach, CA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3040" to="3049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Language as an abstraction for hierarchical deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R. Garnett</editor>
		<meeting><address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="9419" to="9431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">CLEVR: a diagnostic dataset for compositional language and elementary visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.215</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">In search of the neural circuits of intrinsic motivation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<idno type="DOI">10.3389/neuro.01.1.1.017.2007</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="225" to="236" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The psychology and neuroscience of curiosity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kidd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Y</forename><surname>Hayden</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2015.09.010</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="449" to="460" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Conceptual representations in mind and brain: theoretical developments, current evidence and future directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kiefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pulvermüller</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2011.04.006</idno>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="805" to="825" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Philosophy in the Flesh: The Embodied Mind and Its Challenge to Western Thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Basic Books</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A survey of reinforcement learning informed by natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luketina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nardelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foerster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/880</idno>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>Macao</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6309" to="6317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning latent plans from play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khansari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<editor>L. P. Kaelbling, D. Kragic, and K. Sugiura (PMLR</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1113" to="1132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Language Conditioned Imitation Learning Over Unstructured Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<idno type="DOI">10.15607/RSS.2021.XVII.047</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Robotics: Science and Systems</title>
		<meeting>Robotics: Science and Systems</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A cognitive neuroscience perspective on embodied language for human-robot cooperation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Dominey</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bandl.2009.07.001</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Lang</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="180" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">An overview of natural language state representation for reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Madureira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Thought before language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mandler</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2004.09.004</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="508" to="513" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A joint model of language and perception for grounded attribute learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<meeting><address><addrLine>Edinburgh</addrLine></address></meeting>
		<imprint>
			<publisher>Omni Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1435" to="1442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Extending machine language models toward human-level language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="DOI">10.5282/ubm/epub.72201</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Mind, Self, and Society: From the Standpoint of a Social Behaviorist</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Mead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Mead</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>University of Chicago Press</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>George Herbert Mead. Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Towards a vygotskyan cognitive robotics: the role of language as a cognitive tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parisi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.newideapsych.2009.07.001</idno>
	</analytic>
	<monogr>
		<title level="j">N. Ideas Psychol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="298" to="311" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Mapping instructions and visual observations to actions with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artzi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1106</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1004" to="1015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Grounding language for transfer in deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="DOI">10.1613/jair.1.11263</idno>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="849" to="874" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Algorithms for inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<meeting><address><addrLine>Stanford, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="663" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Robotic self-representation improves manipulation skills and transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Sensorimotor representation learning for an &quot;active self &quot; in robots: a model survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Georgie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kayhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13218-021-00703-z</idno>
	</analytic>
	<monogr>
		<title level="j">Künstliche Intelligenz</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="9" to="35" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Zero-shot task generalization with multi-task deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<editor>D. Precup and Y. W. Teh</editor>
		<meeting><address><addrLine>Sydney, NSW</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2661" to="2670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Intrinsic motivation systems for autonomous mental development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Oudeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<idno type="DOI">10.1109/TEVC.2006.890271</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="265" to="286" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Mental imagery in associative learning and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paivio</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0027272</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="241" to="263" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Curiosity-driven exploration by self-supervised prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<idno type="DOI">10.1109/CVPRW.2017.70</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<meeting><address><addrLine>Sydney, NSW</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2778" to="2787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Efficient grounding of abstract spatial concepts for natural language interaction with robot platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Arkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Aksaray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Howard</surname></persName>
		</author>
		<idno type="DOI">10.1177/0278364918777627</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Rob. Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1269" to="1299" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">How and why do infants imitate? An ideomotor approach to social and imitative learning in infancy (and beyond)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paulus</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-014-0598-1</idno>
	</analytic>
	<monogr>
		<title level="j">Psychon. Bull. Rev</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1139" to="1156" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Goal-directed exploration for learning vowels and syllables: a computational model of speech acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Philippsen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13218-021-00704-y</idno>
	</analytic>
	<monogr>
		<title level="j">Künstliche Intelligenz</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">The Language and Thought of the Child</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Piaget</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1926" />
			<publisher>Brace: Harcourt</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.12092</idno>
		<title level="m">Zero-shot text-to-image generation</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Language within our grasp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Arbib</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0166-2236(98)01260-0</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Neurosci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="188" to="194" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Curious hierarchical actor-critic reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Röder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-61616-8_33</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks (Bratislava)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="408" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Hierarchical reinforcement learning for open-domain dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghandeharioun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i05.6400</idno>
	</analytic>
	<monogr>
		<title level="j">Conf. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8741" to="8748" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Exploration behaviors, body representations, and simulation processes for the development of cognition in artificial agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schillaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lara</surname></persName>
		</author>
		<idno type="DOI">10.3389/frobt.2016.00039</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Robot. AI</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Is that me? Sensorimotor learning and self-other distinction in robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schillaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grosjean</surname></persName>
		</author>
		<idno type="DOI">10.1109/HRI.2013.6483582</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Human-Robot Interaction</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="223" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Computational mechanisms of curiosity and goal-directed exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schwartenbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Passecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">U</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kronbichler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.41703</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">41703</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Recruitment of binding and binding-error detector circuits via long-term potentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shastri</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0925-2312(98)00131-3</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">27</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Sentiment adaptive end-to-end dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1140</idno>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Melbourne, VIC</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1509" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">A review of contemporary ideomotor theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Capaldi</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0020541</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Bull</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="943" to="974" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">ALFRED: a benchmark for interpreting grounded instructions for everyday tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.01075</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">ALFWorld: aligning text and embodied environments for interactive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett</editor>
		<meeting><address><addrLine>Montréal, QC</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Grounding dynamic spatial relations for embodied (robot) interaction, &quot; in Pacific Rim International Conferences on Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spranger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suchan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-13560-1_83</idno>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="958" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">The Symbol Grounding Problem Has Been Solved. So What&apos;s Next? Symbols, Embodiment and Meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780199217274.003.0012</idno>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">The grounded naming game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loetzsch</surname></persName>
		</author>
		<idno type="DOI">10.1075/ais.3.04ste</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Interaction Studies</title>
		<editor>L. Steels</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>John Benjamins Publishing Company</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="41" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Emergent action language on real robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spranger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Trijp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Höfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hild</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4614-3064-3_13</idno>
	</analytic>
	<monogr>
		<title level="m">Language Grounding in Robots</title>
		<editor>L. Steels and M. Hild</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="255" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">The Ambiguity of Play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sutton-Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Exploring Robotic Minds: Actions, Symbols, and Consciousness as Self-Organizing Dynamic Phenomena</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tani</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780190281069.001.0001</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Robots that use language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kress-Gazit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Matuszek</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-control-101119-071628</idno>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Control Robot. Auton. Syst</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="25" to="55" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Recognizing intention from natural language: clarification dialog and construction grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Communicating Intentions in Human-Robot Interaction, International Symposium on Human and Robot Interactive Communication</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Turner</surname></persName>
		</author>
		<title level="m">The Origin of Ideas: Blending, Creativity, and the Human Spark</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Uc-Cetina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navarro-Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Martin-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05565</idno>
		<title level="m">Survey on reinforcement learning for language processing</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Play and its role in the mental development of the child</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vygotsky</surname></persName>
		</author>
		<idno type="DOI">10.2753/RPO1061-040505036</idno>
	</analytic>
	<monogr>
		<title level="j">J. Russ. East Eur. Psychol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="6" to="18" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Words as invitations to form categories: evidence from 12-to 13-month-old infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Waxman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Markow</surname></persName>
		</author>
		<idno type="DOI">10.1006/cogp.1995.1016</idno>
	</analytic>
	<monogr>
		<title level="j">Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="257" to="302" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Multimodal communication in animals, humans and robots: an introduction to perspectives in brain-inspired informatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gallese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pulvermüller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neunet.2009.01.004</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="111" to="115" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Body-specific representations of action verbs: neural evidence from right-and left-handers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hagoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Casasanto</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797609354072</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="67" to="74" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">The role of tutoring in problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bruner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-7610.1976.tb00381.x</idno>
	</analytic>
	<monogr>
		<title level="j">J. Child Psychol. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="89" to="100" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Multilingual universal sentence encoder for semantic retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.12</idno>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics, System Demonstrations</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Event perception: a mind-brain perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Swallow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Braver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Reynolds</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.133.2.273</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Bull</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="273" to="293" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
