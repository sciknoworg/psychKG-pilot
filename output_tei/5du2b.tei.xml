<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Björn</forename><surname>Meder</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computational Principles of Intelligence Lab</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<addrLine>Max-Planck-Ring 8</addrLine>
									<postCode>72076</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lion</forename><surname>Schulz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computational Principles of Intelligence Lab</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<addrLine>Max-Planck-Ring 8</addrLine>
									<postCode>72076</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Schween</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computational Principles of Intelligence Lab</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<addrLine>Max-Planck-Ring 8</addrLine>
									<postCode>72076</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Binz</surname></persName>
							<email>marcel.binz@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computational Principles of Intelligence Lab</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<addrLine>Max-Planck-Ring 8</addrLine>
									<postCode>72076</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>meta-learning</term>
					<term>resource rationality</term>
					<term>heuristics</term>
					<term>strategy selection</term>
					<term>strategy discovery</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Numerous researchers have put forward heuristics as models of human decision-making. However, where such heuristics come from is still a topic of ongoing debate. In this work, we propose a novel computational model that advances our understanding of heuristic decision-making by explaining how different heuristics are discovered and how they are selected. This model-called bounded meta-learned inference (BMI)-is based on the idea that people make environment-specific inferences about which strategies to use while being efficient in terms of how they use computational resources. We show that our approach discovers two previously suggested types of heuristics-one reason decision-making and equal weighting-in specific environments. Furthermore, the model provides clear and precise predictions about when each heuristic should be applied: knowing the correct ranking of attributes leads to one reason decision-making, knowing the directions of the attributes leads to equal weighting, and not knowing about either leads to strategies that use weighted combinations of multiple attributes. In three empirical paired comparison studies with continuous features, we verify predictions of our theory and show that it captures several characteristics of human decision-making not explained by alternative theories.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristics From Bounded Meta-Learned Inference</head><p>Imagine having to decide which of two movies you are going to watch tonight:</p><p>Movie A vs. Movie B. Movie A has a higher average rating on a website that you trust, while Movie B is directed by a known director and has previously won an Oscar for the best picture. From past experiences, you know that rating is the best indicator for a good movie. Whether the movie won an Oscar and who directed it is less important for how much you normally enjoy watching a movie. How do people make decisions like this?</p><p>The question of how people decide between two options is as fundamental as its answer is contentious. Indeed, even though we make countless such decisions every day, the underlying principles of these decisions are still debated in psychology <ref type="bibr" target="#b143">(Todd &amp; Gigerenzer, 2000)</ref>, behavioral economics <ref type="bibr" target="#b117">(Samuels et al., 2012)</ref>, and neuroscience <ref type="bibr" target="#b23">(Camerer et al., 2005)</ref>. Traditionally, researchers have approached this problem by looking at how rational agents decide. From this ideal observer perspective <ref type="bibr" target="#b35">(Geisler, 1989)</ref> it is assumed that people weigh different attributes of each option appropriately to combine information from all available sources. Psychologists were however quick to point out that rational decision-making can be too burdensome <ref type="bibr" target="#b130">(Simon, 1990b;</ref><ref type="bibr" target="#b146">Tversky &amp; Kahneman, 1974)</ref>.</p><p>Instead, they suggested that human decision-making may be based on a variety of heuristics, which are simple strategies that ignore part of the relevant information <ref type="bibr" target="#b47">(Gigerenzer &amp; Todd, 1999;</ref><ref type="bibr" target="#b126">Shah &amp; Oppenheimer, 2008;</ref><ref type="bibr" target="#b146">Tversky &amp; Kahneman, 1974)</ref>.</p><p>Two common classes of heuristics are one reason decision-making  and equal weighting <ref type="bibr" target="#b30">(Dawes &amp; Corrigan, 1974;</ref><ref type="bibr" target="#b32">Einhorn &amp; Hogarth, 1975)</ref>.</p><p>One reason decision-making heuristics are based on the idea that good reasoning often requires just a single piece of information <ref type="bibr" target="#b87">(Marewski et al., 2010)</ref>. Applying such a strategy to the initial example, you would only need to inspect the most important attribute: the movie rating. Based on this attribute, you decide to watch Movie A and ignore all other information about both movies. Equal weighting heuristics on the other hand completely abstain from differentiating between the attributes and instead tally all of them together to decide which option to choose. In our example, Movie B has two attributes in its favor, while Movie A only has one. Hence, you would decide to watch Movie B if your decision was based on an equal weighting heuristic.</p><p>Even though they are computationally simplistic strategies, heuristics can be surprisingly competitive in many real-world benchmarks <ref type="bibr" target="#b28">(Czerlinski et al., 1999;</ref><ref type="bibr" target="#b81">Lichtenberg &amp; Şimşek, 2017)</ref>. This observation led different researchers to consider heuristics as ecologically rational strategies <ref type="bibr" target="#b43">(Gigerenzer &amp; Gaissmaier, 2011;</ref><ref type="bibr" target="#b47">Gigerenzer &amp; Todd, 1999;</ref><ref type="bibr" target="#b108">Payne et al., 1993)</ref>, implying that heuristics are strategies that are particularly well-suited for our complex and dynamic world. The ecological rationality of heuristics also makes it appealing to view them as models of human decision-making. Empirical studies attempting to show that people apply heuristics have however produced mixed evidence <ref type="bibr" target="#b4">(Ayal &amp; Hochman, 2009;</ref><ref type="bibr" target="#b17">Bröder, 2000;</ref><ref type="bibr" target="#b19">Bröder &amp; Gaissmaier, 2007;</ref><ref type="bibr" target="#b48">Glöckner &amp; Betsch, 2008;</ref><ref type="bibr" target="#b57">Hilbig, 2010</ref>, see also our later discussion on empirical results).</p><p>In this work, we suggest bounded meta-learned inference (BMI) as a novel computational theory for explaining how people make decisions. BMI discovers decision-making strategies through a resource-rational algorithm <ref type="bibr" target="#b38">(Gershman et al., 2015;</ref><ref type="bibr" target="#b83">Lieder &amp; Griffiths, 2019;</ref><ref type="bibr" target="#b129">Simon, 1990a</ref>) that has been adapted to an environment over time via meta-learning <ref type="bibr" target="#b7">(Bengio et al., 1991;</ref><ref type="bibr" target="#b123">Schmidhuber et al., 1996;</ref><ref type="bibr" target="#b140">Thrun &amp; Pratt, 1998)</ref>.</p><p>Like ideal observer models, BMI attempts to infer optimal decision-making strategies but does so while taking computational resources into account. Like heuristics, strategies inferred through BMI are tailored to a specific environment. However, unlike heuristics, the inductive biases of such strategies have been meta-learned through previous interactions with the environment instead of building them in by design.</p><p>Through a series of model simulations, we demonstrate that BMI discovers several previously suggested heuristics. Specifically, our results reveal three important classes of environments that lead to three different strategies. First, if the model knows the correct ranking of attributes but not their weights, then it learns a strategy that makes decisions based only on the attribute with the highest ranking, a form of one reason decision-making.</p><p>Secondly, if the model knows that the direction of correlation between attributes and outcome is positive, then it learns a strategy that makes decisions based on equal weighting. Finally, if the model does not know either the ranking or the direction of attributes, it learns to use individual weights for each attribute. This analysis provides new insights into the mixed results of prior empirical work on heuristics because it makes precise predictions about if and when a specific heuristic should be used. We verify these predictions in three empirical paired comparison studies and show that the vast majority of participants apply heuristics whenever they are optimal strategies for the current environment after considering limited computational resources.</p><p>In summary, our work makes the following three main contributions:</p><p>1. We show that heuristics can emerge through BMI, thereby providing a normative justification for previously suggested heuristics.</p><p>2. We map out which features of an environment lead to which (heuristic) decision-making strategy, where knowing the correct ranking of attributes leads to one reason decision-making, knowing the directions of the attributes leads to equal weighting, and not knowing about either leads to strategies that use weighted combinations of multiple attributes.</p><p>3. We test these predictions empirically in three experiments and find strong evidence for our theory's predictions.</p><p>The remainder of the paper is organized as follows: we first summarize the relevant literature on heuristic decision-making and introduce its general terminology. Thereafter, we present formal models corresponding to different hypotheses considered in our work. By running simulations on different environments, we generate several predictions of our theory, which we empirically test in three new decision-making experiments. Finally, we discuss our results and connect our theory to related ideas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Past Research on Heuristic Decision-Making</head><p>There has been an extensive amount of past research on heuristic decision-making.</p><p>In this section, we describe common heuristics, summarize empirical and theoretical results regarding their performance, and review prior studies with a focus on the evidence they provide for heuristic decision-making in humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristics Toolbox</head><p>Even though a mathematically precise definition of what constitutes a heuristic is still a topic of ongoing debates <ref type="bibr" target="#b148">Van Rooij et al., 2012)</ref>, here we adopt the following definition put forward by <ref type="bibr" target="#b43">Gigerenzer and Gaissmaier (2011)</ref>: "A heuristic is a strategy that ignores part of the information, with the goal of making decisions more quickly, frugally, and/or accurately than more complex methods." The collection of different heuristics is often thought of as an adaptive toolbox from which appropriate decision-making strategies can be selected as required <ref type="bibr" target="#b46">(Gigerenzer &amp; Selten, 2002)</ref>. We are primarily interested in heuristics that can be applied to paired comparison tasks like the aforementioned movie example (e.g., <ref type="bibr" target="#b89">Martignon &amp; Hoffrage, 2002)</ref>. In such tasks, a decision-making agent is asked to judge which of two options is superior on an unobserved criterion. To aid the decision-making process, the agent observes multiple attributes of both options, also known as cues or features in the decision-making literature. Most heuristics developed for the paired comparison setting make use of binary features that indicate whether an attribute is present or not. 1</p><p>Many decision-making strategies are built around the concept of feature validity <ref type="bibr" target="#b142">(Todd &amp; Dieckmann, 2005)</ref>. The validity of a binary feature is the rate at which it allows the agent to make correct predictions given that the feature is present in one option but not the other <ref type="bibr" target="#b79">(Lee &amp; Cummins, 2004)</ref>. For example, the validity of being directed by a known director for predicting whether you like a movie could be 0.8, indicating that you would enjoy a movie that is directed by someone you know over someone you do not know in eighty percent of the cases. In general, decision-making strategies for paired comparison tasks can be divided into two classes: compensatory and non-compensatory strategies. A strategy is compensatory whenever it integrates information from multiple features, whereas it is non-compensatory when a feature cannot be outweighed by any combination of less important features <ref type="bibr" target="#b112">(Rieskamp &amp; Hoffrage, 1999)</ref>.</p><p>A prominent sub-class of compensatory strategies are linear-additive strategies.</p><p>These strategies compute a weighted sum of features for each option and decide on the option with the largest sum. They are typically considered the normative standard in the decision-making literature <ref type="bibr" target="#b107">(Payne et al., 1988)</ref>. This argument can be made precise if one weights features by the log-odds of their validities. The resulting strategy corresponds to an algorithm known as naive Bayes, which is optimal under the assumption that features are conditionally independent given the criterion <ref type="bibr" target="#b71">(Katsikopoulos &amp; Martignon, 2006;</ref><ref type="bibr" target="#b79">Lee &amp; Cummins, 2004)</ref>. The weighted additive (WADD) strategy is another popular example of a linear-additive strategy, which weights features directly by their validities. In contrast to naive Bayes, however, it is not possible to interpret WADD as an optimal strategy.</p><p>Heuristics are typically much simpler than WADD or naive Bayes. Equal weighting heuristics, for example, are compensatory, yet simple, decision-making strategies. They do not distinguish between how features are weighted and instead use an identical weighting for all features. The process itself can be realized by tallying features of both options together and selecting the one with the larger sum <ref type="bibr" target="#b30">(Dawes &amp; Corrigan, 1974;</ref><ref type="bibr" target="#b32">Einhorn &amp; Hogarth, 1975</ref>).</p><p>The prime example for a non-compensatory strategy is the take-the-best (TTB) heuristic <ref type="bibr" target="#b44">(Gigerenzer &amp; Goldstein, 1996)</ref>. TTB belongs to the family of one reason decision-making heuristics. It assumes a ranking of features based on their validities and inspects features in decreasing order until a feature that discriminates between both options is reached. The final decision is based on the validity of that feature alone, ignoring all other information. If a ranking of features is not a priori accessible, then it can either be estimated from observations or a random ranking can be used. A TTB strategy using a random ranking of features is referred to as the Minimalist heuristic <ref type="bibr" target="#b44">(Gigerenzer &amp; Goldstein, 1996)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ecological Rationality</head><p>To seriously consider heuristics as a model of human decision-making, they shouldat the very least -be able to solve the kind of decision-making problems that people typically encounter. Prior work demonstrated that heuristics do not only match the performance of more complex linear-additive models but even exceed them on such problems. This finding is also referred to as the less-is-more effect <ref type="bibr" target="#b47">(Gigerenzer &amp; Todd, 1999)</ref>. <ref type="bibr" target="#b28">Czerlinski et al. (1999)</ref>, for example, compared different heuristics against logistic regression on 20 real-world decision-making problems and found that averaged over all tasks TTB and logistic regression performed equally well.  extended this analysis to additionally include a feed-forward neural network, two exemplar-based models, and a decision-tree algorithm. They concluded that the less-is-more effect is most prevalent when only limited data is available. Later on, it was highlighted that, although earlier work fitted models on a limited training set, it evaluated them on the entire data-set (training and test set). It turned out that, when only out-of-sample predictions were considered, TTB even exceeded all competing models in terms of performance <ref type="bibr" target="#b15">(Brighton, 2006;</ref><ref type="bibr" target="#b42">Gigerenzer &amp; Brighton, 2009;</ref><ref type="bibr" target="#b72">Katsikopoulos et al., 2010)</ref>. More recently, <ref type="bibr" target="#b81">Lichtenberg and Şimşek (2017)</ref> have shown that the less-is-more effect also extends to situations in which one has to make predictions about a continuous outcome.</p><p>The discovery of the less-is-more effect caused researchers to ask themselves, why do heuristics perform so well? Eventually, this cumulated in several conditions that allow us to make claims about the performance of a heuristic based on the structure of the task it is applied to <ref type="bibr" target="#b70">(Katsikopoulos, 2011)</ref>. In the case of binary features, it has been shown that decisions made by TTB are identical to those of a linear-additive model if the true feature weights of the task are non-compensatory, i.e. when a more important feature cannot be overruled by any combination of less important features <ref type="bibr" target="#b89">(Martignon &amp; Hoffrage, 2002;</ref><ref type="bibr" target="#b91">Martignon et al., 1999)</ref>. A similar result was obtained by <ref type="bibr" target="#b71">Katsikopoulos and Martignon (2006)</ref> under the assumption that features are conditionally independent given the criterion. <ref type="bibr" target="#b6">Baucells et al. (2008)</ref> described a different task structure known as cumulative dominance that causes both TTB and equal weighting to achieve maximum performance across all strategies. An option cumulatively dominates another option -under the assumption that features are ordered according to their importance -if all of its cumulative sums of features are larger than the ones of the alternative option. Şimşek (2013) demonstrated that both non-compensatoriness and cumulative dominance are relatively common in many real-world decision-making problems and therefore provided a justification for the use of heuristics.</p><p>A related line of research has argued that heuristics work well because they involve fewer parameters, and are hence easier to learn based on limited or noisy observations. In this context, <ref type="bibr" target="#b61">Hogarth and Karelaia (2005</ref><ref type="bibr" target="#b15">, 2006</ref><ref type="bibr" target="#b11">, 2007</ref> derived several analytical conditions under which different heuristics -like TTB and equal weighting --achieve superior performance compared to a linear-additive model whose weights are estimated using maximum likelihood estimation. In particular, they found that both heuristics perform well when the number of observations used for estimation is small compared to the number of features. They additionally demonstrated that TTB tends to perform well when the variability of validities between features is high, while equal weighting performs well when the variability of validities is low. <ref type="bibr" target="#b42">Gigerenzer and Brighton (2009)</ref> approached the less-is-more effect from the perspective of the bias-variance trade-off, which states that the expected generalization error of a model can be decomposed into the sum of a bias and a variance component. A model with high bias fails to capture regularities in the data, while a model with high variance is sensitive to small fluctuations in the sample. <ref type="bibr" target="#b42">Gigerenzer and Brighton (2009)</ref> argued that if observations are sparse or noisy the variance component will typically dominate and that heuristics achieve superior performance in such conditions because they keep this component within acceptable limits. <ref type="bibr" target="#b133">Şimşek and Buckmann (2015)</ref> provided additional support for this theory by showing that building blocks of different heuristics can be learned efficiently with just a few training samples. Finally, <ref type="bibr" target="#b105">Parpart et al. (2018)</ref> argued that heuristics can also emerge from Bayesian inference in the limit of infinitely strong priors. Based on this insight, they identified priors that correspond to both TTB and equal weighting. Their work indicated that "heuristics perform well because they implement strong priors that approximate the actual structure of the environment."</p><p>Thus far, we have discussed environmental conditions that favor heuristic decision-making. There exists, however, a complementary justification for why people should use heuristics: they simply involve less complicated computations <ref type="bibr" target="#b107">(Payne et al., 1988;</ref><ref type="bibr" target="#b108">Payne et al., 1993)</ref>. <ref type="bibr" target="#b126">Shah and Oppenheimer (2008)</ref> have advocated for the study of heuristics in the light of the accuracy-effort trade-off. From their point of view, heuristics are interpreted as strategies that save effort at the cost of a potentially reduced accuracy.</p><p>Resource-rational theories of decision-making take this point of view one step further <ref type="bibr" target="#b10">(Bhui et al., 2021)</ref>. Instead of only asking how to save computational resources, resource-rational models identify how to spend a limited amount of resources optimally in order to maximize accuracy.  applied the framework of rational meta-reasoning to construct resource-rational decision-making strategies. They showed that TTB can be considered rational if execution time is limited. We currently know very little about whether common heuristics can be interpreted as strategies that make optimal use of limited computational resources beyond the results of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical Studies</head><p>The observation that heuristics are computationally efficient and ecologically rational strategies is often used to justify them as models of human decision-making <ref type="bibr" target="#b144">(Todd &amp; Gigerenzer, 2007)</ref>. However, to truly establish that people use heuristics, proving good performance in simulation and theory is not sufficient; it also requires empirical evidence.</p><p>Many studies have attempted to find such evidence, yet no consensus for or against heuristics has been reached. Here, we provide an overview of these studies and attempt to connect their findings. While we focus on studies in the paired comparison setting, we also included a few notable exceptions with more than two choice alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidence For Heuristics</head><p>Let us first consider studies that provided evidence for heuristics. The majority of such evidence comes from studies in which it was costly to access information about feature values. The Mouselab paradigm is a process-tracing approach to decision-making, which requires participants to click or hover over a specific feature to reveal its value. In studies making use of the paradigm, <ref type="bibr" target="#b113">Rieskamp and Otto (2006)</ref> showed that people's selection of strategies depended on the environment they interacted with. Participants in their study had initial preferences for linear-additive strategies, but then slowly adopted TTB in a non-compensatory environment and WADD in a compensatory environment. <ref type="bibr" target="#b92">Mata et al. (2007)</ref> confirmed this general result in a study with participants from different age groups.</p><p>They found that across all age groups, participants looked up less information in an environment with unequal validities compared to one with equal validities. They also concluded that older adults tend to select simpler strategies, like TTB, more frequently than their younger counterparts. <ref type="bibr" target="#b93">Mata et al. (2010)</ref> reinforced the hypothesis that older people tend to apply simpler strategies. In particular, they demonstrated that older people were more likely to apply equal weighting -instead of WADD -in a compensatory environment. In a similar paradigm, <ref type="bibr" target="#b153">Wichary et al. (2016)</ref> demonstrated that placing participants under emotional stress caused them to search for less information and to apply simpler strategies.</p><p>Another way to promote the use of heuristics is to require a monetary fee to reveal features. In several experiments with monetary fees, <ref type="bibr" target="#b17">Bröder (2000)</ref> produced evidence in favor of one reason decision-making heuristics. In his experiments, more participants were classified as TTB users in a high-cost condition compared to a low-cost condition. In another study, <ref type="bibr" target="#b18">Bröder (2003)</ref> manipulated the payoff structure of the environment while keeping the nominal cost for obtaining information constant, i.e., he considered environments in which it was advantageous to gather more information and those in which it was not. He found that most participants applied TTB in a non-compensatory environment, whereas they applied a linear-additive strategy when information was more valuable. In the latter condition, he also found that the percentage of non-TTB choices did not increase over time, suggesting that "a compensatory strategy may be something like a default strategy". <ref type="bibr" target="#b31">Dieckmann and Rieskamp (2007)</ref> also observed that TTB predicted more decisions in environments with monetary costs and furthermore demonstrated that participants applied TTB more often when the redundancy between features was high.</p><p>It has also been argued that people rely more on heuristic decision-making when feature values are not readily available but have to be retrieved from memory instead. In multiple experiments with memory-based retrieval, Bröder et al. demonstrated that participants became more consistent with TTB when features had to be retrieved from memory <ref type="bibr" target="#b19">(Bröder &amp; Gaissmaier, 2007;</ref><ref type="bibr" target="#b20">Bröder &amp; Schiffer, 2003</ref><ref type="bibr" target="#b15">, 2006</ref>. <ref type="bibr" target="#b20">Bröder and Schiffer (2003)</ref>, for example, classified 72% of participants as TTB users when they were under high working memory load, but only 56% when they were not. <ref type="bibr" target="#b109">Persson and Rieskamp (2009)</ref> used a similar paradigm but required participants to learn about the interaction between features and the criterion based on feedback. They found that most participants applied TTB when feedback indicated which option was better on the unobserved criterion.</p><p>However, when direct feedback about criterion values was provided, most people applied a linear-additive strategy instead. In addition, they also included an exemplar-based approach in their analysis but found little evidence for such a strategy.</p><p>What about situations in which information is freely available? There exists overall only limited evidence suggesting that people apply heuristics in such cases. <ref type="bibr" target="#b9">Bergert and Nosofsky (2007)</ref> were among the few who provided support for the idea that people rely on heuristics even when information is free. In their study, participants exhibited non-compensatory decision-making patterns, assigning over half of the total weight to a single feature. They further strengthened their claim using a novel reaction time method that allowed them to disentangle predictions of different strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidence Against Heuristics</head><p>In general, it seems that increasing the costs for utilizing information can make human decision-making more consistent with heuristics. However, even under such supposedly favorable conditions, it is still disputed whether people use heuristics or if they rely on more complex strategies instead. <ref type="bibr" target="#b100">Newell et al. (2003)</ref> demonstrated that even with large monetary costs and other conditions favoring one reason decision-making heuristics, not many participants acted fully in accordance with TTB. When reanalyzing the data of <ref type="bibr" target="#b113">Rieskamp and Otto (2006)</ref>, <ref type="bibr" target="#b121">Scheibehenne et al. (2013)</ref> found that people in non-compensatory environments were better described through a mixture of TTB and WADD, indicating a general preference for linear-additive strategies. Van Ravenzwaaij et al. (2014) showed that hierarchical models accounting for both search order and termination provided a better explanation for participants' choices than TTB and WADD alone. Similarly, <ref type="bibr" target="#b136">Söllner and Bröder (2016)</ref> found that people tend to adjust how long then search for information based on the evidence that they have accumulated so far. They concluded that this observation is in line with evidence accumulation models <ref type="bibr" target="#b79">(Lee &amp; Cummins, 2004)</ref>, but not with heuristics like TTB.</p><p>We also have to be cautious to not misinterpret evidence for heuristics in process tracing studies as a general inability to apply more complex strategies when information search is not constrained by the experimental paradigm. In this context, <ref type="bibr" target="#b48">Glöckner and Betsch (2008)</ref> argued that process-tracing studies are likely to underestimate the cognitive capacity of participants, as they hinder the activation of automatic decision-making processes. They verified this claim by demonstrating that participants were generally able to combine information from multiple features extremely quickly when the acquisition of information was not constrained. Further studies with freely accessible information provided similar results <ref type="bibr" target="#b17">(Bröder, 2000;</ref><ref type="bibr" target="#b56">Heck et al., 2017;</ref><ref type="bibr" target="#b79">Lee &amp; Cummins, 2004;</ref><ref type="bibr" target="#b105">Parpart et al., 2018)</ref>, always concluding that few participants made decisions consistent with TTB and that their choices were, in general, better described through linear-additive strategies.</p><p>Finally, <ref type="bibr" target="#b99">Newell and Lee (2011)</ref> highlighted large inter-individual differences and presented a sequential sampling model that provided better fits than TTB, WADD, and a strategy selection model across all participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristics in Related Research Areas</head><p>There are also a number of research areas that use experimental paradigms similar to paired comparison studies, which have produced mixed evidence on whether people rely on heuristic decision-making or not. In probabilistic category learning <ref type="bibr" target="#b2">(Ashby &amp; Maddox, 2005)</ref>, participants are asked to classify objects into one of usually two categories. Thus, similar to paired comparison tasks, participants learn a mapping between features and a binary outcome.  noted that the category learning literature emphasizes exemplar models, which is in contrast to the linear-additive models studied in the decision-making literature. Based on this observation, they investigated which factors modulate a shift from exemplar models to linear-additive cue-integration models. In a similar setting, Von Helversen et al. (2013) demonstrated that participants switched from an exemplar-based model to a linear-additive cue-integration model once information about the direction of features was available. However, both of these lines of work did not examine the role of heuristics in the context of category learning. In a later study, <ref type="bibr" target="#b67">Juslin, Jones, et al. (2003)</ref> did consider the possibility for one reason decision-making heuristics but found little evidence for such strategies, even after introducing additional time pressure.</p><p>Another closely connected paradigm with a long history on its own is multiple-cue probability learning (MCPL, <ref type="bibr" target="#b14">Brehmer, 1979;</ref><ref type="bibr" target="#b49">Gluck &amp; Bower, 1988;</ref><ref type="bibr" target="#b55">Hammond, 1955)</ref>. In MCPL, people have to learn about a probabilistic relationship between an object described by multiple features and an outcome. A popular instance of MCPL is given by the weather prediction task. Here, participants are presented with a multi-dimensional stimulus taking the form of tarot cards and learn based on feedback whether given patterns lead to sunny or rainy weather. <ref type="bibr" target="#b50">Gluck et al. (2002)</ref> conjectured that people approach this task using three different strategies: (1) an optimal strategy, which learns about all available features,</p><p>(2) a one reason decision-making heuristic, in which decisions are based on a single feature, and (3) a singleton heuristic, which learns only about the patterns that have a single feature present. In two studies, they found that a majority of participants (85% across both studies) was overall best fit by the singleton heuristic. However, as more data were observed participants either switched towards the one reason decision-making heuristic in a more challenging experiment or the optimal multi-cue strategy in an easier experiment. In contrast, <ref type="bibr" target="#b77">Lagnado et al. (2006)</ref> concluded that a vast majority of participants was best described by a strategy that integrated information from all features (86% across three studies). <ref type="bibr" target="#b98">Newell et al. (2007)</ref> reported similar results, with the additional observation that people switched towards a more simplistic singleton heuristic if they were put under working memory load. Finally, it is worth pointing out that equal weighting also received some attention in the MCPL literature: when participants were provided with directional information about features, they switched from a multi-cue strategy towards equal weighting <ref type="bibr" target="#b101">(Newell et al., 2009)</ref>. In the context of this article, this is an interesting observation, because -as we will show later on -it is exactly what our model predicts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>To summarize, many prior studies attempted to produce evidence for one reason decision-making strategies like TTB, while focusing less on other heuristics such as equal weighting. They concluded that such strategies were indeed more apparent when it was costly to access information about feature values, either in terms of time, money, or memory. However, when features were freely accessible, evidence for heuristics in human decision-making remained rare. Where does that leave us? We argue, following earlier work of , <ref type="bibr" target="#b108">Payne et al. (1993)</ref>, and <ref type="bibr" target="#b126">Shah and Oppenheimer (2008)</ref>, that examining which strategies are rational after taking limited computational resources into consideration can help us to understand why and when people use heuristics. In the next section, we formalize this idea and present a novel modeling framework that allows us to determine which strategy is resource-rational for a particular environment. We then showwith the help of this framework -that previously suggested heuristics can be interpreted as resource-rational solutions to paired comparison tasks when additional information about the ranking or the direction of features is available. In our experimental studies, we indeed find that people use their computational resources efficiently, and apply heuristics when such information is available. This result is amongst the first to show that people rely heavily on heuristics even in the absence of time, money, or memory constraints. However, when no side information is available, we find that it is resource-rational to make decisions using weighted combinations of features. We confirmed empirically that under such conditions, people do not rely on heuristics and instead apply linear-additive strategies.</p><p>This result is in agreement with the majority of reviewed studies with freely accessible feature values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational Models</head><p>In this section, we show how recent advances in meta-learning can be used to construct environment-specific decision-making algorithms that make optimal use of limited computational resources. Having access to such an algorithm does allow us to predict if and when people should rely on heuristic decision-making strategies, assuming that they use available computational resources efficiently. To test this conjecture, we also introduce several other computational models of decision-making in paired comparison tasks. First, we will outline the assumptions about the structure of the problem to be solved and define a corresponding ideal observer model. Then, we introduce probabilistic variants of two popular heuristics. Both heuristics are considerably simpler than an ideal observer model regarding their use of available information. Finally, we describe how we obtain resource-rational algorithms that are adapted to a particular environment.</p><p>The decision-making problems we focus on in this article are paired comparison tasks with continuous features. In a paired comparison task an agent -either human or machine -has to decide which of two options with feature vectors x A,B ∈ R d has the higher value on an unobserved criterion y A,B . In our movie example, the feature vector contains information about whether the movie has won an Oscar, its average rating on a reviewing website, and so on, while the unobserved criterion corresponds to your personal rating of the movie (i.e., how much you would like the movie if you watched it). We consider the setting where data arrive sequentially, i.e. one at a time, and with feedback that indicates which option has the higher criterion value. Let x A,t and x B,t denote the observed features at time-step t and let c t be a binary variable that takes the value of 1 if option A has the higher criterion value and 0 otherwise. For each time-step, the agent first observes both options, then makes a prediction about c t , and subsequently receives feedback about which option had the higher criterion value. Note that learning in this setting is always based on feedback in the form of c t , and that the criteria y A,t and y B,t are never observed directly.</p><p>In contrast to most prior work, we investigate paired comparison tasks with continuous features. In many real-world scenarios, features are naturally described through continuous values and thus we believe that the restriction to binary features oversimplifies a characteristic present in many of the problems people typically solve. Moving to continuous features also facilitates statistical analysis as fewer trials are needed to observe expected effects. For example, it would require over four times more trials to distinguish an ideal observer model from a single cue heuristic in environments with dichotomized features instead of continuous ones (see Appendix A for further details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ideal Observer</head><p>Ideal observer models (IO) are designed to provide a theoretical upper bound on performance in a specific task. In the following, we construct an ideal observer model for paired comparison tasks. For this, we assume that there exists an underlying linear relationship between features and the criterion:</p><formula xml:id="formula_0">y A = w T x A + A y B = w T x B + B<label>(1)</label></formula><p>with feature weights w ∈ R d and independent, additive noise A,B ∼ N (0, σ 2 ).</p><p>Based on this assumption, we can express the probability, that option A has a higher criterion value than option B as:</p><formula xml:id="formula_1">p(Y A,t &gt; Y B,t |x A,t , x B,t , w, m = IO) = p(C t = 1|x t , w, m = IO) = Φ w T x t √ 2σ (2)</formula><p>where Φ is the cumulative distribution function of a standard normal distribution.</p><p>For ease of notation, we have denoted the difference between feature vectors as</p><formula xml:id="formula_2">x t = x A,t − x B,t</formula><p>and used the binary variable C t to indicate which of the two options has a higher criterion value.</p><p>Equation 2 is known in the statistics and machine learning literature as the probit regression model. The probit regression model makes it clear that an ideal observer should represent the probability that one option is better than the other using a weighted sum of differences between features of the options. Hence, the ideal observer model is a compensatory decision-making strategy. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter Estimation</head><p>Equation 2 provides an ideal observer model under the assumption that the underlying feature weights w are known. However, we assume that the weights are not provided in advance to the decision-maker. Thus, the agent has to infer them based on past observations. An ideal observer should apply Bayesian inference to infer unobserved parameters from data in a normative manner. In our setting, we estimate unobserved parameters by applying Bayesian inference sequentially. Exact inference is not possible under the above assumptions and thus we resort to a variational approximation <ref type="bibr" target="#b66">(Jordan et al., 1999)</ref>. We approximate the true posterior with a normal distribution q(w; λ λ λ t ) = N (w; µ µ µ t , Ψ t ) and optimize its parameters λ λ λ t = (µ µ µ t , Ψ t ) through gradient ascent on the evidence lower bound:</p><formula xml:id="formula_3">L(λ λ λ t ) = E w∼q(w;λ λ λt) [log p(C t = c t |x t , w)] − KL [q(w; λ λ λ t )||q(w; λ λ λ t−1 )]<label>(3)</label></formula><p>where q(w; λ λ λ 0 ) corresponds to an initial prior distribution. This kind of approximation is equivalent to exact inference when the true posterior is within the considered variational family. We provide further details on how Equation 3 is optimized in Appendix B.</p><p>To make predictions, we average over all plausible parameter values given by the variational distribution. The resulting predictive distribution can be expressed in closed form:</p><formula xml:id="formula_4">p(C t+1 = 1|x t+1 , λ λ λ t ) = p(C t+1 = 1|x t+1 , w)q(w; λ λ λ t )dw = Φ   µ µ µ T t x t+1 2σ 2 + x T t+1 Ψ t x t+1   (4)</formula><p>We assume, throughout this article, that features weights are sampled from a standard normal distribution at the beginning of each task and held constant over its entire duration, which implies that an ideal observer should use a prior in form of a standard normal distribution, i.e. q(w; λ λ λ 0 ) = N (w; 0, I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heuristics</head><p>The two heuristics we consider in our analysis belong to the categories of one reason decision-making and equal weighting. In contrast to traditional heuristics, like TTB, they are probabilistic decision-making strategies for tasks with continuous features. Both are obtained through modification of the ideal observer model, such that either less information is required to make a decision or that information is combined in a simpler way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One Reason Decision-Making</head><p>In our implementation of one reason decision-making, we modify Equation 2 and</p><p>replace it with a model that only takes a single feature x * t into account:</p><formula xml:id="formula_5">p(C t = 1|x t , w, m = SC) = Φ w • x * t √ 2σ<label>(5)</label></formula><p>We refer to the resulting strategy as single cue heuristic (SC). If a ranking of features is available, decisions are based on the most predictive feature, otherwise, we select the feature that performed best on the data so far. In contrast to TTB, the single cue heuristic does not involve a sequential search over features. However, we assume that features take continuous values, and hence search is not required as a feature nearly always discriminates between options <ref type="bibr" target="#b86">(Luan et al., 2014)</ref>. We have also experimented with a semi-lexicographic heuristic that uses a threshold parameter for deciding whether to consider a feature, but have not found it to explain the empirical data better than the simpler single cue heuristic. Thus, we decided to focus our analysis on the simpler implementation that always uses the first or best feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Equal Weighting</head><p>In our probabilistic version of equal weighting, we replace Equation 2 with a model that has a single, tied weight for all features:</p><formula xml:id="formula_6">p(C t = 1|x t , w, m = EW) = Φ w • d i=1 x t,i √ 2σ<label>(6)</label></formula><p>For w &gt; 0, this equal weighting heuristic probabilistically selects the option with the larger sum of features. For w &lt; 0, it becomes more likely to select the option with the smaller sum (a negative weight is appropriate if most features have negative correlations with the criterion). Note that the ideal observer model contains as many free parameters as there are observed features, while both heuristics have only a single free parameter regardless of how many features are observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bounded Meta-Learned Inference</head><p>Finally, we present bounded meta-learned inference (BMI) as a novel theory for human decision-making. BMI combines two equally important ideas: meta-learning and resource rationality. We are going to introduce them one after the other. First, we describe how meta-learning can produce decision-making algorithms that infer the optimal strategy for a particular environment, resulting in a variant without resource limitations called meta-learned inference (MI). Then, we show how MI can be extended to BMI by additionally taking limited computational resources into account. BMI may therefore be described as a resource-rational decision-making algorithm that has been adapted to an environment over time via meta-learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-Learned Inference</head><p>Meta-learning <ref type="bibr" target="#b7">(Bengio et al., 1991;</ref><ref type="bibr" target="#b123">Schmidhuber et al., 1996;</ref><ref type="bibr" target="#b140">Thrun &amp; Pratt, 1998)</ref>, also known as learning to learn, is a machine learning approach to devise learning systems that can rapidly adapt to new problems. In our work, we will use meta-learning as a purely methodological tool for constructing resource-rational decision-making algorithms, i.e., we do not attempt to study the process of meta-learning itself but are only interested in its outcome.</p><p>The main idea of our approach is simple: instead of using Bayesian <ref type="bibr">(or variational)</ref> inference to infer posterior distributions over probit regression weights, we train a recurrent neural network to do this inference. In time-step t + 1, the network processes the previous feature vector x t together with its corresponding target c t , combines this information with its hidden state, and based on this estimates the parameters of the posterior distribution</p><formula xml:id="formula_7">λ λ λ t = {µ µ µ t , Ψ t }.</formula><p>Finally, it combines the estimated weights with the feature vector x t+1 as described in Equation 4 to obtain the predictive posterior distribution p(C t+1 = 1|x t+1 , λ λ λ t , Θ). <ref type="figure" target="#fig_0">Figure 1</ref> illustrates graphically how the network processes a sequence of observations. Initially, the recurrent network maps a sequence of previously observed feature-target pairs to a random posterior distribution over weights. During meta-learning, the system is then trained in an end-to-end manner to infer statistically optimal predictive posterior distributions for a distribution over tasks p(x 1:T , c 1:T ). We also refer to this distribution over tasks as the environment. In probabilistic terms, we can infer statistically optimal predictive posterior distributions by minimizing their negative log-probabilities on tasks sampled from the environment:</p><formula xml:id="formula_8">(x t , c t ) λ λ λ t = {µ µ µ t , Ψ t } x t+1 p(C t+1 = 1|x t+1 , λ λ λ t , Θ) = p(C t+1 = 1|x t+1 , w)q(w; λ λ λ t )dw</formula><formula xml:id="formula_9">L(Θ) = E p(x 1:T ,c 1:T ) T −1 t=0 − log p(C t+1 = c t+1 |x t+1 , λ λ λ t , Θ)<label>(7)</label></formula><p>where Θ are parameters of the recurrent network, which we refer to as meta-parameters in order to distinguish them from the probit regression weights of Equation 2.</p><p>Equation 7 is optimized until convergence using standard optimization techniques.</p><p>Through repeated encounters with the environment, the model is able to adapt to the properties of that specific environment. Once meta-learning has finished, the recurrent network acts as a free-standing decision-making algorithm without requiring any further optimization. Instead, adaptation to new tasks is simply implemented in form of forward passes through the network: we provide the network with a sequence of feature-target examples and an input that we want to query, and the network provides us with optimal predictive posterior distributions for that sequence of observations. We refer to the decision-making algorithm that is implemented by the forward dynamics of the recurrent network as meta-learned inference (MI). It has been shown in previous work that this meta-learning approach leads to the emergence of an algorithm that approximately simulates Bayesian inference <ref type="bibr" target="#b95">(Mikulik et al., 2020;</ref><ref type="bibr" target="#b104">Ortega et al., 2019;</ref><ref type="bibr" target="#b110">Rabinowitz, 2019)</ref>.</p><p>Thus, MI will implement an algorithm similar to our ideal observer model, assuming that both of them make identical assumptions about the environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resource Rationality</head><p>Bounded meta-learned inference (BMI) is an extension to MI that additionally takes limited computational resources into consideration. More specifically, BMI controls for how many bits are required to implement the emerging decision-making algorithm, which is also referred to as its description length. From a psychological perspective, this may be interpreted as a cost for storing the algorithm that infers what decision-making strategies to apply. We will examine how this type of computational cost relates to other costs commonly used in cognitive science in the General Discussion.</p><p>How can this be formalized mathematically? First, we have to recognize that controlling the description length of meta-parameters is equivalent to controlling the description length of the emerging decision-making algorithm. This is the case because the emerging decision-making algorithm is fully specified through the meta-parameters. If we then represent the meta-parameters using a distribution over their plausible values q(Θ; Λ), it is possible to interpret the Kullback-Leibler (KL) divergence between q(Θ; Λ) and a prior p(Θ) as a measure of the meta-parameters' description length <ref type="bibr" target="#b53">(Grünwald &amp; Grunwald, 2007;</ref><ref type="bibr" target="#b59">Hinton &amp; Van Camp, 1993)</ref>. <ref type="bibr">3</ref> In order to find the optimal balance between high performance with low computational complexity, BMI simply adds a β-weighted KL-term to the MI objective from Equation 7:</p><formula xml:id="formula_10">L(Λ) = E p(x 1:T ,c 1:T ) E q(Θ;Λ) T −1 t=0 − log p(C t+1 = c t+1 |x t+1 , λ λ λ t , Θ) performance +β KL [q(Θ; Λ)||p(Θ)] description length<label>(8)</label></formula><p>In our later model comparisons, we treat β as a free parameter that is fitted to empirical data. For β = 0, meta-learning with Equation 8 is equivalent to MI. For β &gt; 0, we get a family of decision-making algorithms that optimally trade-off performance for a shorter description length. In this article, we focus on the information-theoretic interpretation of Equation 8. For completeness, it should be noted that several authors have suggested an alternative interpretation that appeals to PAC-Bayesian theory <ref type="bibr" target="#b94">(McAllester, 2013)</ref>, both in the context of traditional supervised learning <ref type="bibr" target="#b0">(Achille &amp; Soatto, 2018</ref> and meta-learning <ref type="bibr" target="#b154">(Yin et al., 2020)</ref>.</p><p>We additionally use a sparsity-inducing prior <ref type="bibr" target="#b74">(Kingma et al., 2015;</ref><ref type="bibr" target="#b97">Molchanov et al., 2017;</ref><ref type="bibr" target="#b141">Tipping, 2001)</ref>, which means that under large resource limitations only networks with few non-zero meta-parameters remain. Thus, resulting algorithms are simple in terms of their description length and in terms of the number of remaining meta-parameters. <ref type="figure">Figure 2</ref> schematically contrasts two networks obtained from optimization with low and high resource limitations. In Appendix C we provide a full specification of the network architecture, meta-learning procedure, and choice of prior.  approximately simulates an ideal observer, and hence we expect it to infer strategies that use independent and non-zero weights for all features. However, as we decrease the description length of the emerging decision-making algorithm, we expect it to infer simpler strategies like the single cue or equal weighting heuristic. Importantly, which strategy BMI infers, and whether it corresponds to a particular heuristic or not, does not only depend on its complexity but also on the distribution over tasks that was used for meta-learning.</p><formula xml:id="formula_11">x t,1 x t,2 x t,3 x t,4 c t µ µ µ t,1 µ µ µ t,2 µ µ µ t,3 µ µ µ t,4 x t,1 x t,2 x t,3 x t,4 c t µ µ µ t,1 µ µ µ t,2 µ µ µ t,3 µ µ µ t,4</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Summary</head><p>Let us summarize all outlined models again and contrast the assumptions they make. The ideal observer model assumes that everything about the structure of the has acquired a resource-rational algorithm to infer decision-making strategies through repeated encounters with an environment. Thus, BMI can exploit characteristics present in that specific environment, while also being efficient in terms of computational resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Simulations</head><p>Next, we demonstrate through a series of model simulations that BMI recovers both single cue and equal weighting heuristics in specific environments. This result implies that both heuristics can be resource-rational strategies under certain conditions. However, we also identify circumstances where BMI does not discover any known heuristic and instead infers strategies that use weighted combinations of all features. Before running these simulations, we first have to specify the assumptions we make about the environment and introduce a method for analyzing the emerging strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Environments</head><p>For BMI it is necessary to specify a distribution over tasks p( 3. Randomly determine which option has the larger criterion by sampling from a Bernoulli distribution with a success probability given by Equation 2.</p><formula xml:id="formula_12">x 1:T , c 1:T ) that</formula><p>Features weights are held constant over a task but are resampled between tasks.</p><p>Importantly, we assume that the decision-making agent cannot access these weight vectors directly, but instead has to infer them based on observations.</p><p>Both redundancy and uncertainty are crucial factors in many real-world decision-making problems <ref type="bibr" target="#b43">(Gigerenzer &amp; Gaissmaier, 2011)</ref>. Thus, we want them to be present in our environments. Partially redundant features are ensured by drawing separate feature covariance matrices from a LKJ prior with η = 2 <ref type="bibr" target="#b80">(Lewandowski et al., 2009)</ref> for each task. To introduce uncertainty, we use a limited number of trials in each task (T = 10) and set the additive noise term σ such that an ideal observer is correct in 85% of the cases in the tenth trial.</p><p>We consider three variations of the previously outlined environments, that assume</p><p>(1) known rankings of features, (2) known directions of features or (3) neither. To provide agents with a ranking of features, we arrange them in decreasing order according to the magnitude of their weights. Known directions are ensured by inverting the sign of a feature if it has a negative correlation with the criterion, leading to features with only positive directions. 4 These environments are used during meta-learning, for the model simulation results presented next, and to generate the tasks for our empirical studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy Analysis</head><p>To characterize different decision-making strategies, we adopt a measure from the economics literature called the Gini coefficient <ref type="bibr" target="#b3">(Atkinson et al., 1970)</ref>. The Gini coefficient was originally intended to describe income and wealth distributions of countries. Its minimal value of zero corresponds to a country in which all residents are equally wealthy, while the maximal value of one corresponds to a country in which a single person possesses everything. 5</p><p>The extreme cases of the Gini coefficient also coincide with the two previously discussed heuristics: equal weighting heuristics have a Gini coefficient of zero, while single cue heuristics have a Gini coefficient close to one. Thus, we can employ the Gini coefficient to understand how similar estimated regression weights are compared to both heuristics. In practice, we compute Gini coefficients using absolute values of weight vectors.</p><p>Mathematically, the Gini coefficient of a weight vector w ∈ R d is defined as half of the relative mean absolute difference:</p><formula xml:id="formula_13">G(w) = d i=1 d j=1 |w i − w j | 2d d i=1 w i<label>(9)</label></formula><p>Throughout this section, we analyzed Gini coefficients for BMI (with β = 0.01), MI, and ideal observer models. If Gini coefficients were consistently close to zero or one, we deduced that the model has recovered one of the two heuristics. We additionally evaluated the average KL divergence from the posterior predictive distribution of both heuristics to the posterior predictive distribution of BMI. This KL divergence can be interpreted as a difference measure between two models. If it is significantly lower for one of the two heuristics, this would further strengthen our claim that BMI has discovered that particular heuristic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BMI Discovers Heuristics</head><p>First, we considered an environment with known feature rankings. For MI and BMI we optimized meta-parameters until convergence in an environment where features are ordered based on the magnitude for their associated weight. We then analyzed Gini coefficients of inferred regression weights after meta-learning is completed. Because MI and BMI are adapted to the environment, they could exploit the additional ranking information to adjust how they infer strategies.   with nearly maximum Gini coefficients, which correspond to weight vectors that only have a single non-zero component. Thus, we conclude that the single cue heuristic emerged as the resource-rational strategy for an environment with known feature rankings. Looking at MI in <ref type="figure" target="#fig_2">Figure 3</ref> (b), we find Gini coefficients that cover a much wider range of values. Even though there is an initial tendency towards single cue heuristics, many later decisions are based on compensatory rules. This indicates that being adapted to the environment alone is not a sufficient justification for heuristics. Instead, we need algorithms that are adapted to the environment and efficient in terms of their computational resources. Decisions in the ideal observer model are nearly always based on weighted combinations of multiple features, and hence its Gini coefficients in <ref type="figure" target="#fig_2">Figure 3</ref>   as more data is observed strategies with higher Gini coefficients emerge. The ideal observer model on the other hand does not exploit the additional directional information and hence we find no noticeable change in Gini coefficients compared to an environment with known rankings <ref type="figure" target="#fig_6">(Figure 4 (c)</ref>). Like before, our results are confirmed when looking at the KL divergence between both heuristics and BMI, which is now substantially smaller for the equal weighting heuristic as shown in <ref type="figure" target="#fig_6">Figure 4 (d)</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BMI Does Not Always Discover Heuristics</head><p>We have seen that BMI discovered different heuristics in two classes of environments. Next, we show that there are also environments where this is not the case.   For this, we optimized MI and BMI such that they adjust to problems without additional information in the form of ranking or direction. Gini coefficients obtained from BMI reveal that neither single cue nor equal weighting heuristics are resource-rational under such circumstances, as shown in <ref type="figure" target="#fig_11">Figure 5 (a)</ref>. Instead, the pattern now looks more similar to one observed in MI and the ideal observer models, shown in <ref type="figure" target="#fig_11">Figures 5 (b)</ref> and (c) respectively. In all cases, Gini coefficients cover the full range of possible values, indicating that inferred weight vectors integrate information from multiple features to different degrees. This time, we find no difference in the KL divergence between both heuristics and BMI (ref. <ref type="figure" target="#fig_11">Figure 5</ref> (d)), which confirms the earlier conclusion that BMI does not recover any of the two heuristics in an environment without additional information about ranking or direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Predictions</head><p>BMI discovered both single cue and equal weighting heuristics when information about ranking and direction was provided, respectively. However, resulting strategies diverged from known heuristics whenever such information was not present. Instead, our simulation results suggest that weighted combinations of multiple features should be used in such situations. Under the assumption that people make adaptive and computationally efficient inferences, our results enable us to make precise predictions about when to expect heuristics as part of human decision-making and when not: knowing the correct ranking of attributes leads to one reason decision-making, knowing the directions of the attributes leads to equal weighting, and not knowing about either leads to strategies that use weighted combinations of multiple attributes. Below, we present the results of three paired comparison studies that confirm the predictions made by BMI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1: Known Ranking</head><p>In our first study, participants made decisions in multiple paired comparison tasks while having access to a ranking of features, but not their underlying weights. Previously, we showed that in environments with known feature rankings, single cue heuristics are resource-rational strategies. Hence, we hypothesized that people are more likely to apply the single cue heuristic in this condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were students from the University of Marburg, taking part in the study for course credits. Besides course credits, they got a chance to win a e 10 voucher if they made more than 66.6% correct decisions. The experiment was approved by the local ethics board (AZ 2020-32k). In total, we collected data from 28 participants (23 female, average age: 22.36 ± 5.65). We decided on this number of participants based on previous studies <ref type="bibr" target="#b20">(Bröder &amp; Schiffer, 2003;</ref><ref type="bibr" target="#b100">Newell et al., 2003)</ref>. The median time to complete the experiment was 26.00 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Each participant performed 30 different paired comparison tasks that were randomly generated according to the previously described distribution. Each task consisted of ten trials. The underlying feature weights remained fixed within a task but varied between tasks. Participants were informed about transitions between tasks. Each participant encountered the same set of paired comparison tasks in a randomized order.</p><p>The problem itself was framed as an alien sports competition on an unknown planet (see <ref type="figure">Figure 6</ref>). Participants observed four numerical attributes for two aliens and indicated by a button press which alien they believed was more likely to win. The alien cover story was used to keep the meaning of features completely abstract from the participant's perspective. Participants did not have access to the underlying feature weights but instead had to learn about the importance of features based on experience. Feedback about the correct choice was provided directly after each decision. For this condition, features were displayed in descending order based on the magnitude of their weights. Participants were told that features are arranged from top to bottom according to how well they predict the winner. Being aware of this additional ranking information allowed them to apply strategies that are appropriate for this environment. All participants went through a short tutorial and did a comprehension check to confirm that they understood the instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Graphical illustration of a single trial in the experiment. "Alien X gewinnt" translates to "Alien X wins". <ref type="figure">Figure 7</ref> shows the percentage of correct decisions for participants in our study together with the accuracy of different models. Participant performance was within the range of the single cue heuristic but below the ideal observer model. On average, participants made 68.25 ± 7.55% correct choices. For each participant, we assessed whether or not they chose the better option more frequently than chance by using an exact binomial test with a base probability of p = 0.5 and classifying them as better than chance if the p-value of that test was smaller than 0.05. This analysis showed that 26 out of 28 participants chose the better option more frequently than what would be expected under chance level performance. We also fitted a mixed-effects logistic regression to investigate participants' learning over trials and tasks, using a variable indicating whether or not participants had chosen the better option on a given trial as the dependent variable, and adding trial number and task number as both fixed effects and random effects over participants. The results of this model showed a significant fixed effect of trial number (β = 0.12, z = 5.63, p &lt; .001) onto choosing the better option but not of task number (β = −0.02, z = −0.66, p = .51). This means that participants improved over trials within a given task but did not improve over tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Comparison</head><p>If people make efficient use of their available computational resources, we expect them to adopt the single cue heuristic in this experiment. To examine this hypothesis, we performed a Bayesian model comparison and computed posterior probabilities of different models given the decisions made by a participant. Appendix D provides a detailed description of the methods we used for statistical analysis. In addition to the previously described models, we also included a simple strategy selection model (ref <ref type="table">. Appendix E)</ref> and a feedforward network trained by gradient descent (ref. Appendix F) in our analysis.</p><p>Because the single cue heuristic and BMI make redundant predictions, we decided to split our analysis into two parts. First, we analyzed all models except BMI for individual participants. Then, we compared BMI against the other models on the data of all participants.</p><p>We found evidence for the application of the single cue heuristic in 23 out of 28 participants. For all but four of those participants, the model evidence decisively favored the single cue heuristic (p(m = SC|ĉ (i) , X (i) ) &gt; 0.99). <ref type="figure">Figure 8</ref> (a) summarizes posterior probabilities of different models for all participants. From the participants not best described by one reason decision-making, two were best described by guessing, one by the equal weighting heuristic, one by the ideal observer model, and one by the strategy selection model. The protected exceedance probability (PXP), which measures the probability that a particular model is more frequent in the population than all the other models under consideration <ref type="bibr" target="#b114">(Rigoux et al., 2014)</ref>, favored the single cue heuristic decisively (PXP &gt; 0.999).</p><p>While our model simulations predicted that participants should not change their strategy during a task, our analysis did not rule out this possibility so far. It might, for example, be possible that participants did not start a task with the single cue heuristic but only developed this preference during learning. We tested this specific model prediction by comparing differences in log-likelihoods of individual time-steps between different models. <ref type="figure">Figure 8 (b)</ref>, we can see that the single cue heuristic dominates both equal weighting and the ideal observer model across all time-steps. This makes it unlikely that participants only applied the single cue heuristic for a subset of trials, and also validates the hypothesis that strategies did not switch within a task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Looking at</head><p>Finally, we compared how well BMI fared against the other models on the  aggregated data. The resulting posterior probabilities indicated that across all participants BMI offered an even better explanation for the observed data than the other models (p(m = BMI|ĉ, X) ≈ 1). We hypothesized that this is the case because BMI was able to explain the behavior of participants that used a single feature (corresponding to higher β-values) and those who used two or more features (corresponding to lower β-values).</p><p>There were overall 12 participants who were better described by BMI than by the single cue heuristic. We found that the fitted β-values of these participants were significantly lower than those within the rest of the population (t(15.4) = −2.78, p = 0.007), meaning that these participants acted as if they had access to more resources and therefore applied more complex strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Most empirical evidence for one reason decision-making has been provided by studies that involved a cost for acquiring information about features <ref type="bibr" target="#b17">(Bröder, 2000;</ref><ref type="bibr" target="#b19">Bröder &amp; Gaissmaier, 2007;</ref><ref type="bibr" target="#b113">Rieskamp &amp; Otto, 2006)</ref>. However, even with an experimental protocol that favored few pieces of information, evidence for these strategies remained inconclusive <ref type="bibr" target="#b100">(Newell et al., 2003;</ref><ref type="bibr" target="#b121">Scheibehenne et al., 2013)</ref>. When information is freely available, people are often better described through compensatory strategies such as logistic regression <ref type="bibr" target="#b17">(Bröder, 2000;</ref><ref type="bibr" target="#b48">Glöckner &amp; Betsch, 2008;</ref><ref type="bibr" target="#b79">Lee &amp; Cummins, 2004;</ref><ref type="bibr" target="#b105">Parpart et al., 2018)</ref>. Our results are among the first to decisively show that people's choices can be based on a single piece of information, even when such strategies are not favored by the experimental protocol. This was possible because we precisely identified conditions under which one reason decision-making should appear. Nearly all participants in our study applied strategies that were efficient in terms of resources while also accounting for environmental characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2: Known Direction</head><p>In our second study, we provided no information about ranking and instead informed participants about feature directions; otherwise, it was identical to the first experiment. In our previous analysis, we have seen that this modification also caused a change in what strategy is resource rational. Now, resource-rational decision-making amounts to the application of equal weighting heuristics. We, therefore, hypothesized that participants would become more likely to use such strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were students from the University of Marburg, taking part in the study for course credits. Besides course credits, they got a chance to win a e 10 voucher if they made more than 66.6% correct decisions. The experiment was approved by the local ethics board (AZ 2020-32k). In total, we collected data from 24 participants (22 female, average age: 22.54 ± 3.28). The median time to complete the experiment was 29.69 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>The design was identical to the first experiment, except that participants were informed about the presence of positive feature directions instead of the feature ranking.</p><p>This was realized by telling them that higher feature values always made it more probable for an alien to win the competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance</head><p>Participants made on average 73.85 ± 4.53% correct choices, putting their performance within the range of all models, see <ref type="figure">Figure 9</ref>. The higher average performance indicates that participants found it overall easier to process information about direction than about ranking. We again assessed whether or not individual participants chose the better option more frequently than chance by using an exact binomial test with a base probability of p = 0.5 and classifying them as better than chance if the p-value of that test was smaller than 0.05. This analysis confirmed that all participants chose the better option more frequently than what would be expected under chance level performance. We also fitted a mixed-effects logistic regression to investigate participants' learning over trials and tasks as described in the analysis of the previous study. The results of this model showed a significant fixed effect of trial number (β = 0.08, z = 3.5, p &lt; .001) onto choosing the better option but not of task number (β = −0.01, z = −0.4, p = .69). Like in the previous study, this means that participants improved over trials within a given task but did not improve over tasks. Participants' performance in the initial step turned out to be substantially higher than the ideal observer model and both heuristics, indicating that directional information is useful even before making any observations. This characteristic is also captured in BMI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Comparison</head><p>In this condition, equal weighting and BMI made partially redundant predictions.</p><p>Thus, we again decided to split our analysis into two parts. First, we analyzed all models except BMI for individual participants. Then, we compared BMI against the other models on the data of all participants.</p><p>The posterior probabilities of different models, illustrated in <ref type="figure" target="#fig_0">Figure 10 (a)</ref>, confirmed the prediction of our earlier simulations. Participants indeed adhered to the resource-rational maxim and applied equal weighting heuristics. For all participants, equal weighting provided the best explanation for the observed data with decisive evidence (p(m = EW|ĉ (i) , X (i) ) &gt; 0.99). The probability that equal weighting was the most frequent model in the population (PXP &gt; 0.999) supported the conclusion that people, in general, applied equal weighting heuristics when directional information was available. We again inspected per-trial log-likelihoods to confirm that participants did not change their strategies within a task. <ref type="figure" target="#fig_0">Figure 10 (b)</ref> shows that equal weighting dominated the single cue heuristic and the ideal observer model across all time-steps, which again rules out the possibility that participants only applied equal weighting for a subset of trials.</p><p>When additionally comparing BMI against the other models on the aggregated data of all participants, we found that BMI again offered an even better explanation than all other models (p(m = BMI|ĉ, X) ≈ 1). Here, this was the case because BMI was able to capture participants' decisions in the initial step, while the equal weighting heuristic did not. This can be confirmed by inspecting the rightmost panel of <ref type="figure" target="#fig_0">Figure 10 (b)</ref>, which compares per-trial log-likelihoods between equal weighting and BMI. Here, we find a substantial difference between how well both strategies matched human choices in the initial trial, but no differences during later trials. Indeed, if we look at how well BMI  describes participants on an individual level, we find that it offers a better explanation than equal weighting for all but four participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Like in our first study, we found that people apply resource-rational strategies that are adequate for the given environment. Participants performed better compared to the first study, indicating that they found it easier to work with directions than with rankings.</p><p>We speculate that one explanation for this observation could be that positive correlations are more frequently encountered in the world. Perhaps somewhat surprisingly, there is only limited evidence from prior decision-making studies showing that people employ equal weighting heuristics. The present study is amongst the first to show that people rely heavily on such strategies under the appropriate conditions. However, there is a result from the MCPL literature that connects nicely to our result. In this context, <ref type="bibr" target="#b101">Newell et al. (2009)</ref> showed that people also switched to an equal weighting heuristic when provided with directional information about feature weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3: Unknown Ranking and Direction</head><p>In our final study, we investigated choice behavior in an environment that did not provide information about ranking or direction. In the previous model simulations, we have demonstrated that no heuristic emerges under such conditions. Instead, BMI discovered strategies with compensatory weights even under large resource constraints. Hence, we predicted that people in this condition should be less reliant on traditional heuristics and instead integrate information from multiple features properly. To test this hypothesis, we initially reiterated the experimental paradigm of our two earlier studies. However, we found that without the additional information about ranking or direction, cognitive limitations became a dominating factor. While some participants still performed well, a substantial number were at or close to chance level. Therefore, we subsequently decided to conduct a simpler version of our task which involved only two features. While we focus on the two-feature study in the main text, the results of the four-feature study are also reported in Appendix G for completeness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were students from the University of Marburg, taking part in the study for course credits. Besides course credits, they got a chance to win a e 10 voucher if they made more than 66.6% correct decisions. The experiment was approved by the local ethics board (AZ 2020-32k). In total, we collected data from 27 participants (22 female, average age: 21.74 ± 4.75). The median time to complete the experiment was 36.35 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>The general design was identical to both previous experiments, except for two adjustments: participants only observed two features for each alien, and they were not provided with information about the feature ranking and their directions anymore. We additionally probed participants' judgments about ranking and direction of features at the end of each task. In particular, we asked them for both attributes whether they believe a positive value is advantageous for winning the competition, and which of the two attributes they believe is more important for determining the winner. For all questions, we collected a binary response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance</head><p>The average performance of participants was 71.59 ± 5.68%, which places them somewhere between the single cue and equal weighting heuristics (see <ref type="figure" target="#fig_0">Figure 11)</ref>. Like in the two previous studies, we assessed whether or not individual participants chose the better option more frequently than chance by using an exact binomial test with a base probability of p = 0.5 and classifying them as better than chance if the p-value of that test was smaller than 0.05. This analysis indicated that 26 of 27 participants chose the better option more frequently than what would be expected under chance level performance. We also repeated the mixed-effects logistic regression used in the previous two studies to investigate participants' learning over trials and tasks. This analysis revealed a significant fixed effect of trial number (β = 0.2, z = 8.83, p &lt; .001) onto choosing the better option but not of task number (β = 0.05, z = 1.3, p = .19), again meaning that participants improved over trials within a given task but did not improve over tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Comparison</head><p>According to our model simulations, we should expect to find evidence for models using weighted combinations of multiple features in this condition. Because no known   <ref type="figure" target="#fig_0">Figure 12</ref> (a) confirmed that most participants combined information from multiple features instead of using heuristics like equal weighting or one reason decision-making. 22 out of 27 participants were best described by BMI; in sixteen of those we found decisive evidence (p(m = BMI|ĉ (i) , X (i) ) &gt; 0.99). Amongst the participants not best described by BMI, three were best described by the ideal observer model and two by the equal weighting heuristic. We again found that BMI fared favorably against all other models on the aggregated data (p(m = BMI|ĉ, X) ≈ 1). The protected exceedance probability (PXP &gt; 0.999) also supported the conclusion that BMI was the most frequent explanation for participants in our population. Looking at per-trial log-likelihoods in <ref type="figure" target="#fig_0">Figure   12</ref> (b), we see that BMI dominated all alternative hypotheses on nearly every time-step, which again confirms that participants did not change their strategies within a task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Judgements about Ranking and Direction</head><p>What made BMI a better model of human choices than other compensatory strategies like the ideal observer model? We speculated that this was the case because BMI better reflected human intuitions about the ranking and direction of features. To test this hypothesis, we analyzed participants' judgments about ranking and direction at the end of each task. For our analysis, we computed likelihood ratios of human judgments between the two competing models. The likelihood that model m ∈ {BMI, IO} assigns a positive direction to feature i is given by p(w i &gt; 0|x 1:T , c 1:T , m), which can be computed in closed form under our assumption of normal posterior distributions. The likelihood that model m ∈ {BMI, IO} evaluates the first feature as more important is given by p(|w 1 | &gt; |w 2 ||x 1:T , c 1:T , m), which we approximated using a sample-based estimate. While we found no substantial difference in terms of ranking (BF = 0.41), BMI offered a much better explanation for the human judgments of directions (BF = 1.4 × 10 24 ). This suggests that the main advantage of BMI stems from the fact that it is better at capturing human intuitions about feature directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In an environment that did not provide additional information about ranking or direction, participants' decision-making again followed the prediction made by BMI. The majority of participants applied strategies that involved weighted combinations of features, as was suggested by our model simulations. We observed an identical pattern in our initial study with four features, but there it was less pronounced due to the complexity of the task (see Appendix G). The general result that most people were able to quickly combine information from multiple sources if needed is also consistent with results of prior studies <ref type="bibr" target="#b17">(Bröder, 2000;</ref><ref type="bibr" target="#b48">Glöckner &amp; Betsch, 2008;</ref><ref type="bibr" target="#b105">Parpart et al., 2018)</ref>. Notably, BMI offered a superior account to alternative compensatory strategies like the ideal observer model. We believe that part of the explanation for this result is that BMI aligned better with the subjective judgments about feature directions than other compensatory strategies.</p><p>However, there might be additional factors at play, which our current form of analysis was not able to capture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>At the core of theories of ecological rationality, researchers have posited an interaction between cognition and the environment. <ref type="bibr" target="#b22">Brunswik (1956)</ref> argued that human perception cannot be understood in laboratory settings alone, but rather has to be interpreted in the light of real environments in which real objects are perceived and acted upon. <ref type="bibr" target="#b130">Simon (1990b)</ref> famously highlighted the interaction between cognition and the environment using an analogy of a pair of scissors, with one blade being the structure of the environment and the other blade the computational capabilities of the subject. This conceptualization of ecological rationality has strongly influenced theories of heuristic decision-making. The need to economize cognitive resources places pressure on the mind to employ heuristics that work well in specific environments. Nonetheless, how people pick a particular heuristic for a specific environment and where those heuristics come from in the first place has remained elusive. The theoretical picture becomes even more puzzling when looking at the empirical support for heuristic decision-making. Proponents of heuristic decision-making acknowledge these problems. For example, <ref type="bibr" target="#b41">Gigerenzer (2008)</ref> writes:</p><p>"Why do heuristics work? They exploit evolved capacities that come for free. In addition, they are tools that have been customized to solve diverse problems. By understanding the ecological rationality of a heuristic, we can predict when it fails and succeeds. The systematic study of the environments in which heuristics work is a fascinating topic and is still in its infancy." But what does a theory, which can explain how heuristics emerge and how they are selected, look like? We have put forward BMI as a theory that makes significant advances on these questions. Our simulation results show that BMI discovers previously suggested heuristics. Thus, it provides a normative justification for heuristic decision-making. Moreover, we find that different heuristics emerge depending on environmental assumptions. Thus, BMI also explains how decision-making strategies are selected.</p><p>Already early on, researchers working on heuristic decision-making levied the criticism that simply observing behavioral biases is not enough, and that "in place of plausible heuristics that explain everything and nothing -not even the conditions that trigger one heuristic rather than another -we need models that make surprising (and falsifiable) predictions" <ref type="bibr" target="#b39">(Gigerenzer, 1996)</ref>. However, the very fact that several heuristic components have been claimed to be part of a heuristic toolbox without fully specifying how they are selected and combined, has subjected heuristic theories to a similar line of criticism: ". . . if one cannot predict which heuristics will be used in which environments then determining the heuristic that will be selected from the toolbox for a particular environment becomes necessarily post hoc and thus the fast-and-frugal approach looks dangerously like becoming unfalsifiable." <ref type="bibr" target="#b100">(Newell et al., 2003)</ref>. In contrast to these arguments, BMI makes clear, falsifiable, and surprising predictions about when people should apply which heuristic. Specifically, our simulation results show that there are three important classes of environments triggering three decision-making strategies. If people know the correct ranking of attributes but not their weights, then they should exhibit one reason decision-making. If people know the direction of the attributes but not their ranking, then they should exhibit equal weighting strategies. Finally, if people do not know either the ranking or the direction of the attributes, then they should exhibit strategies that use weighted combinations of attributes.</p><p>We subjected these predictions to a rigorous test in three paired comparison experiments and found that the vast majority of participants applied decision-making strategies as predicted by BMI. Moreover, BMI captured elements of human decision-making that could not be explained by traditional heuristics in all three experiments: In the first study, it additionally accounted for the participants that employed more complex strategies. In the second study, it provided an explanation for the good initial performance of participants. In the third study, it predicted correctly that people make decision using a weighted combination of all features, and offered a superior account to alternative compensatory strategies like the ideal observer model. These results enrich our theoretical and empirical understanding of ecologically rational decision-making. <ref type="bibr" target="#b47">Gigerenzer and Todd (1999)</ref> argue that decision-making under limited resources cannot be expressed through models that perform optimization under constraints:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>"Optimization under constraints also limits search, but does so by computing the optimal stopping point, that is, when the costs of further search exceed the benefits." Computing this optimal stopping point can be at least as expensive as finding the optimal solution;</p><p>hence it defeats the initial intention of modeling decision-making under resource limitations <ref type="bibr" target="#b47">(Gigerenzer &amp; Todd, 1999;</ref><ref type="bibr" target="#b122">Scheibehenne &amp; Von Helversen, 2009)</ref>. BMI involves optimization under constraints but importantly does so at the meta-learning level, which happens on a much larger time scale (e.g. through evolutionary processes). Learning within an individual task, on the other hand, is fast as it does not involve any form of optimization. This perspective of learning at multiple scales is also at the core of recent theories of fast and slow reinforcement learning <ref type="bibr" target="#b13">(Botvinick et al., 2019)</ref>.</p><p>BMI assumes that meta-learning happened prior to the experiment, but it remains agnostic about the exact processes controlling the acquisition of strategies. BMI could, for example, be acquired through evolutionary processes, individual experiences, or both. If meta-learning indeed happened prior to the experiment, we should find no noticeable improvement in performance throughout our studies. We find support for this hypothesis when comparing human performance in the first and second half of our studies as shown in <ref type="figure" target="#fig_0">Figure 13</ref> (a) and (b). Furthermore, we evaluated posterior probabilities of different models for each task as opposed to for each participant, shown in <ref type="figure" target="#fig_0">Figure 13</ref> (c), and found that participants did not switch between different strategies during the experiment.</p><p>Nonetheless, a valid criticism of our current work is that it does not address the precise process of meta-learning and whether this process is rather shaped by ontogeny, phylogeny, or both. This is indeed an open problem for all theories of heuristic decision-making, which at various times have argued that heuristics emerge from evolutionary pressures <ref type="bibr" target="#b65">(Hutchinson &amp; Gigerenzer, 2005)</ref>, developmental processes <ref type="bibr" target="#b40">(Gigerenzer, 2003)</ref>, or task-specific adaptations <ref type="bibr" target="#b88">(Marewski &amp; Schooler, 2011)</ref>. The time scale of meta-learning, therefore, remains an open theoretical and empirical question.</p><p>We have used a particular model architecture to simulate behavior in our tasks. In particular, we applied a gated recurrent network and adapted the meta-parameters through gradient descent on a loss function that can trade-off between the accuracy of the network and the description length of its parameters. Thus, a naturally arising question is how much our results depend on the chosen architecture. For the sake of the resource-rational argument, we should have used the architecture that optimally solves the accuracy-effort trade-off. Because identifying this architecture is not possible, we settled for the next best option and used an architecture that is known to work well across a wide range of domains.   the corresponding strategy was applied with high probability in the given task.</p><p>Theoretically, a resource-rational algorithm should at least be able to recover optimal decision-making if there are no resource limitations. Infinitely wide recurrent neural networks are known to be Turing-complete and hence are in theory able to implement optimal decision-making <ref type="bibr" target="#b127">(Siegelmann &amp; Sontag, 1992)</ref>. Looking at <ref type="figure" target="#fig_0">Figure 11</ref>, we observe that our networks are wide enough to closely approximate the ideal observer model.</p><p>We have also used a particular distribution over tasks for training our meta-learning models. Even though we constructed this distribution to reflect real-world decision-making environments, it remains unclear whether our assumptions can be fully justified. This is a general criticism that rational accounts of decision-making must face <ref type="bibr" target="#b11">(Binmore, 2007;</ref><ref type="bibr" target="#b16">Brighton &amp; Gigerenzer, 2012;</ref><ref type="bibr" target="#b43">Gigerenzer &amp; Gaissmaier, 2011;</ref><ref type="bibr" target="#b138">Szollosi &amp; Newell, 2020)</ref>. For example, <ref type="bibr" target="#b138">Szollosi and Newell (2020)</ref>  we hope to address in future work. In this context, it would also be interesting to study how knowledge is transferred between other task formats, e.g., causal learning <ref type="bibr" target="#b76">(Lagnado et al., 2013;</ref><ref type="bibr" target="#b151">Waldmann &amp; Holyoak, 1992)</ref> or active learning <ref type="bibr" target="#b54">(Gureckis &amp; Markant, 2012;</ref><ref type="bibr" target="#b106">Parpart et al., 2017)</ref>.</p><p>Currently, our approach also does not directly offer a way to predict which method when neural network approaches are applied to psychological questions <ref type="bibr" target="#b115">(Ritter et al., 2017)</ref>. We believe that this possible weakness can also be a strength, because it forces researchers to truly study the properties of environments, as has been the core proposal of theories of ecological rationality for decades.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>To highlight what BMI adds to existing theories, we compare it to other ideas put forward in previous investigations. In the context of decision-making, we focus on methods that address how strategies are selected and how they are discovered. Beyond that, we discuss how meta-learning and resource rationality have been applied to understand other phenomena.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy Discovery</head><p>There have been some accounts that explain how strategies are discovered. <ref type="bibr" target="#b124">Schulz et al. (2016)</ref> proposed a method for learning decision-making strategies from small, probabilistic building blocks. Based on a self-reinforcing sampling scheme, they were able to build tree-like non-compensatory heuristics. Their approach can recover TTB on data sets that have been generated by the TTB heuristic. However, it is not able to learn about other, non-compensatory strategies or to make predictions about when participants would prefer which strategy.  suggested a model that composes strategies from atomic computations. According to their theory, an agent represents computations as costly actions in a meta-level Markov decision process. The agent's goal is to maximize the external payoff obtained from making correct decisions while accounting for the computational costs of actions. When they applied their theory to several decision-making problems, they found that it discovered two known heuristics -TTB and guessing -as well as a novel strategy that combined TTB with satisficing <ref type="bibr" target="#b128">(Simon, 1956)</ref>. <ref type="bibr" target="#b105">Parpart et al. (2018)</ref> showed that heuristics can emerge from Bayesian inference in the limit of infinitely strong priors. Using this idea, they identified priors corresponding to an equal weighting heuristic. Finding a prior that leads to TTB proved to be more challenging in the Bayesian framework and was only possible after introducing an additional decision rule. Instead of relying on the complexity argument as justification for heuristics, their analysis suggested that heuristics work well because they implement priors that reflect the actual structure of the environment.</p><p>Theories that build algorithms from simpler computations <ref type="bibr" target="#b124">Schulz et al., 2016)</ref> discover one reason decision-making heuristics without difficulties, but struggle to account for equal weighting heuristics. Theories based on Bayesian inference <ref type="bibr" target="#b105">(Parpart et al., 2018)</ref> on the other hand have no difficulties with discovering equal weighting heuristics, but require additional components to find heuristics that rely on a single piece of information. We have shown that people use both classes of strategies and provided a theory that can discover both of them in an appropriate context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy Selection</head><p>There have also been several theories explaining how strategies are selected. <ref type="bibr" target="#b113">Rieskamp and Otto (2006)</ref> proposed a theory of strategy selection learning that framed the strategy selection process as a model-free reinforcement learning problem. Their theory assumes that people slowly learn how to select the right strategy from a given repertoire of strategies based on repeated interactions. A key finding of their experiments was that over time participants learned to select the best-performing strategy for a particular environment. Their method requires learning from scratch whenever it encounters novel problems and hence it does not address how knowledge is transferred between different environments, and why participants are immediately able to select appropriate strategies in our experiments.</p><p>Lieder and Griffiths (2017) addressed the missing ability to transfer knowledge between environments through an approach based on rational meta-reasoning. Based on properties of the environment, they predicted speed and accuracy of different strategies.</p><p>They showed that participants selected the strategy that was best for solving the speed-accuracy trade-off in the current context. In contrast to their work, we used separate models for each environment. However, it would be possible to extend our modeling framework by conditioning the initial state of the recurrent network on features of an environment.</p><p>Marewski and Schooler (2011) postulated a probability landscape describing an individual's ability to apply a strategy as a function of cognitive capabilities and the environment. Their work referred to situations in which a strategy can be applied as a cognitive niche and showed that cognitive niches of different strategies are disjoint in many cases. This greatly simplified the strategy selection problem and was in line with participants' behavior across a number of experiments. We believe that cognitive niches could also be the result of meta-learning, where an algorithm adapts to a given characteristic of an environment until it cannot easily be applied to a vastly different environment anymore.</p><p>Previous theories of strategy selection require defining a set of potential strategies in advance, which can be problematic because it always comes along with the risk of missing out on the strategy that is appropriate for solving the problem at hand. In contrast, BMI</p><p>is not restricted to predefined sets and instead discovers useful strategies on the fly. While there exist prior approaches that address either the strategy selection problem or the strategy discovery problem independently, BMI is also the first to account for both problems jointly within a unified framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resource Rationality</head><p>The space of existing resource-rational models is large and such models have been applied to study human behavior across a wide range of contexts (for extended summaries on this topic see <ref type="bibr" target="#b10">Bhui et al., 2021;</ref><ref type="bibr" target="#b38">Gershman et al., 2015;</ref><ref type="bibr" target="#b83">Lieder &amp; Griffiths, 2019)</ref>. In this subsection, we provide a brief review of such models to highlight how our approach relates to the previous literature. There exist many conceptualizations of what constitutes a computational resource. Two of the most common ones are computation time, i.e., the number of steps necessary to solve a problem, and storage space, i.e., the amount of memory required for solving a problem.</p><p>Lieder et al. <ref type="bibr" target="#b85">Lieder et al., 2018)</ref> proposed to model limited computation time as a form of rational metareasoning <ref type="bibr" target="#b116">(Russell &amp; Wefald, 1991)</ref>. They defined the value of computation as the difference between the utility of a strategy and its execution time and argued that a resource-rational agent should maximize this quantity. This approach is extremely general and can also be applied to costs other than computation time. However, it requires designing an appropriate cost function for the specific problem at hand. Another way to restrict computation time is offered by sampling-based models <ref type="bibr" target="#b102">(Ortega et al., 2015;</ref><ref type="bibr" target="#b118">Sanborn et al., 2010;</ref><ref type="bibr" target="#b150">Vul et al., 2014)</ref>. In such models, ideal inference is approximated through Monte Carlo sampling, and decreasing the number of samples is interpreted as a reduction in computation time.</p><p>Limited storage space, on the other hand, is typically modeled through methods that appeal to rate-distortion theory <ref type="bibr" target="#b5">(Bates &amp; Jacobs, 2020;</ref><ref type="bibr" target="#b36">Genewein et al., 2015;</ref><ref type="bibr" target="#b37">Gershman, 2020;</ref><ref type="bibr" target="#b60">Ho et al., 2020;</ref><ref type="bibr" target="#b131">Sims, 2018;</ref><ref type="bibr" target="#b155">Zaslavsky et al., 2018)</ref>. In this framework, one attempts to maximize some measure of performance, while simultaneously placing an upper bound on the number of bits required to store an object of interest. What kind of performance measure is maximized and what kind of object is stored depends on the specific model instantiation. <ref type="bibr" target="#b157">Zenon et al. (2019)</ref> identified two major classes of cognitive costs that can be represented using rate-distortion theory: (1) a perceptual cost for storing a representation of stimuli, and (2) a cost for storing deviations from the default behavior. In our setting, these two costs translate to a cost for storing a representation of feature vectors and a cost for storing deviations from the default decision-making strategy, respectively.</p><p>BMI is similar to traditional rate-distortion theory-based approaches as it also places a cost on storage space. However, it neither implements a cost for storing feature vectors, nor a cost for storing deviations from the default strategy. Instead, it places a storage cost on the algorithm that infers which decision-making strategies to apply. In some sense, this is similar to the concept of Kolmogorov complexity <ref type="bibr" target="#b24">(Chaitin, 1969;</ref><ref type="bibr" target="#b75">Kolmogorov, 1965;</ref><ref type="bibr" target="#b137">Solomonoff, 1964)</ref>, which measures the size of the shortest computer program that produces an object of interest. Kolmogorov complexity has previously been applied to the study of cognition <ref type="bibr" target="#b26">(Chater &amp; Vitányi, 2003;</ref><ref type="bibr" target="#b33">Gauvrit et al., 2014;</ref><ref type="bibr" target="#b34">Gauvrit et al., 2017;</ref><ref type="bibr" target="#b52">Griffiths et al., 2018;</ref><ref type="bibr" target="#b156">Zenil et al., 2015)</ref>. However, because Kolmogorov complexity is based on universal programming languages, it comes with the downside of being incomputable in general. BMI relaxes the assumption of universal programming languages, and could therefore be viewed as a practical implementation of Kolmogorov complexity. <ref type="bibr" target="#b15">Brighton (2006)</ref> and  considered standard feed-forward networks trained with backpropagation as models of decision-making in paired comparison tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-Learning in the Context of Human Behavior</head><p>Their results indicated that, if only a few examples were used, such models tended to overfit and were outperformed by much simpler, more robust alternatives. <ref type="bibr" target="#b15">Brighton (2006)</ref> suggested meta-learning as a potential solution to this problem of overfitting but did not provide a concrete implementation of this conjecture. BMI is such an implementation that can be applied to paired comparison tasks with few examples and -cruciallywithout</p><p>showing signs of overfitting. The key to BMI's success is that learning happens solely in the fully-trained network's recurrent activations and not through traditional gradient-based training schemes.</p><p>When we look beyond decision-making and paired comparison tasks, meta-learning has recently received increased attention as an explanation for human behavior across a variety of cognitive and neuroscientific questions. For example, meta-learning has been shown to lead to human-like characteristics in the contexts of few-shot learning <ref type="bibr" target="#b119">(Santoro et al., 2016)</ref>, systematic compositionality <ref type="bibr" target="#b78">(Lake, 2019)</ref>, exploration <ref type="bibr" target="#b12">(Binz &amp; Endres, 2019)</ref> as well as one-shot navigation and model-based reasoning <ref type="bibr" target="#b152">(Wang et al., 2016)</ref>. Most relevant to our work is the approach of <ref type="bibr" target="#b29">Dasgupta et al. (2020)</ref>, who taught neural networks to approximate Bayesian inference, given some information about an inference problem's prior and likelihood. They are able to account for a large number of cognitive biases, including base rate neglect and conservatism, by restricting the size of the network. This approach shares its core principles with our theory: resource rationality and meta-learning.</p><p>However, BMI does not approximate Bayesian inference explicitly as done by <ref type="bibr" target="#b29">Dasgupta et al. (2020)</ref>. Instead, it attempts to infer distributions that are optimal for making predictions. In the limit of no resource limitations, this also leads to algorithms that approximate Bayesian inference <ref type="bibr" target="#b104">(Ortega et al., 2019)</ref>. However, when computational resources are limited, the two approaches will produce algorithms with distinctive characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Directions</head><p>Most computational models in psychology and cognitive science are confined to idealized settings. BMI on the other hand can -in principle -scale to much more complex domains <ref type="bibr" target="#b119">(Santoro et al., 2016;</ref><ref type="bibr" target="#b152">Wang et al., 2016)</ref>. Having access to such models allows us to study human behavior under more realistic conditions. In the context of decision-making, it becomes, for example, possible to investigate how and why different representational formats influence human strategies <ref type="bibr" target="#b21">(Bröder &amp; Schiffer, 2006)</ref> by learning models that directly process visual representations of the task.</p><p>The classical approach to computational modeling is to propose a model, test its predictions and finally revise the model if required. However, we can also envision an approach for the revision of theories that puts the study of environments first. In this framework, we would ask ourselves what environments can account for observed behavior assuming that people make ecologically and resource-rational decisions, instead of revising arbitrary parts of the model. That this is a promising research direction for building more human-like agents was shown for example by <ref type="bibr" target="#b58">Hill et al. (2020)</ref>, who demonstrated that systematic generalization can be an emergent property of an agent interacting with a rich environment.</p><p>Finally, our theory provides us with a set of predictions about what should happen when available computational resources are manipulated. It will be interesting to see whether people follow the behavioral trajectories stipulated by BMI when put under cognitive load or whether patients with attention or memory impairment are better described by models with lower complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The idea that theories of human cognition should consider both the structure of the environment and the computational capabilities of the subject has been a central theme in psychology <ref type="bibr" target="#b130">(Simon, 1990b;</ref><ref type="bibr" target="#b145">Todd &amp; Gigerenzer, 2012)</ref>. However, actual implementations of this principle have been lacking so far. BMI provides such an implementation by combining the ideas of resource rationality and meta-learning. BMI accounts for two open questions in the decision-making literature simultaneously, explaining why different strategies emerge and how appropriate strategies are selected. By mapping out environments that cause different strategies to be resource-rational, we obtained precise predictions about when previously suggested heuristics should be used and when not. We confirmed these predictions in three paired comparison experiments. Taken together, we believe that BMI offers a normative and empirically supported theory of human decision-making. Power analysis for environments with known feature ranking. The plot illustrates how many tasks are on average required to distinguish the ideal observer model from the single cue heuristic, assuming that decisions are made by the single cue heuristic. We show results for both dichotomized environments (dotted) and environments with continuous features (solid).</p><p>Meta-Learning. MI and BMI are obtained by minimizing Equation 8 with the AmsGrad optimizer <ref type="bibr" target="#b111">(Reddi et al., 2019)</ref>. During meta-learning, the expectation of the log-likelihood term is approximated through one sample from the encoding distribution q(Θ; Λ) and we obtain gradients with respect to Λ using the reparametrization trick <ref type="bibr" target="#b73">(Kingma &amp; Welling, 2013)</ref>. The following pseudocode describes the meta-learning procedure: Learning rates are set to 3 × 10 −4 and we train for 10 6 iterations with a batch size of 32; at the end of meta-learning, the loss function has converged. Each model is initialized from a pre-trained version without resource limitations and we increase β linearly over the first half of the training to the desired value.</p><formula xml:id="formula_14">Algorithm</formula><p>Evaluation. During evaluation the expectation of the log-likelihood term is approximated through K = 100 samples from the encoding distribution and we perform no further updates of meta-parameters:</p><p>Algorithm 2: Evaluation Input: a particular task x 1:T , c 1:T sample model parameters: Θ k ∼ q(Θ; Λ); for t ← 0 to T − 1 do for k ← 1 to K do compute λ λ λ t,k = {µ µ µ t,k , Ψ t,k } according to Equations 12 to 17;</p><p>compute p(C t+1 = 1|x t+1 , λ λ λ t,k , Θ k ) according to Equation 4; end compute predictive posterior distribution: 1 K K k=1 p(C t+1 = 1|x t+1 , λ λ λ t,k , Θ k ); end Prior. The prior over meta-parameters corresponds to a variational dropout prior <ref type="bibr" target="#b74">(Kingma et al., 2015)</ref>. In variational dropout, model parameters are corrupted by multiplicative normally distributed noise:</p><formula xml:id="formula_15">Θ i = µ µ µ i • ξ ξ ξ i (18) ξ ξ ξ i ∼ N (ξ ξ ξ i |1, α α α i ) (19) ⇒ q(Θ; Λ) = i N (Θ i |µ µ µ i , α α α i µ µ µ 2 i )<label>(20)</label></formula><p>Instead of parametrizing the encoding distribution by Λ = {µ µ µ i , α α α i }, Molchanov et al. (2017) suggested the following reparametrization to reduce the variance of stochastic gradients:</p><formula xml:id="formula_16">σ σ σ 2 i = α α α i • µ µ µ 2 i (21) ⇒ q(Θ; Λ) = i N (Θ i |µ µ µ i , σ σ σ 2 i )<label>(22)</label></formula><p>which is used together with an improper log-scale uniform prior over model parameters:</p><formula xml:id="formula_17">p(|Θ i |) ∝ 1 |Θ i |<label>(23)</label></formula><p>There is no analytical expression for the KL term (ref. Equation 8) under this prior and encoding distribution, however it can be approximated numerically. <ref type="bibr" target="#b97">Molchanov et al. (2017)</ref> suggested the following approximation:</p><formula xml:id="formula_18">KL [q(Θ i |Λ i )||p(Θ i )] ≈ −k 1 σ(k 2 + k 3 log α α α i ) + 0.5 log(1 + α α α −1 i ) − const.<label>(24)</label></formula><p>k 1 = 0.63576, k 2 = 1.87320, k 3 = 1.48695</p><p>Meta-learning models presented in this article use the parametrization from Equation 22 and approximate the KL term through Equation 24. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Comparison</head><p>Posterior probabilities obtained from a Bayesian model comparison in <ref type="figure" target="#fig_0">Figure G1</ref> (b) indicated a trend towards strategies that combine information from multiple features. Nine out of 23 participants were best described by BMI; in four of those we found decisive evidence (p(m = BMI|ĉ (i) , X (i) ) = 0.99). Amongst the participants not best described by BMI, six were best described by the equal weighting heuristic, two by guessing, two by the ideal observer model, two by the feedforward network, one by the single cue heuristic, and one by the strategy selection model. The protected exceedance probability provided moderate support for the hypothesis that BMI was the most frequent explanation for participants in our population (PXP = 0.57). The obtained evidence was however not decisive. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Graphical depiction of MI/BMI. The recurrent neural network sequentially processes examples from a given task. Through its recurrent activations it combines information from all previous feature-target pairs to compute a distribution over weights, which is then combined with the next input to obtain the predictive distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3</head><label>3</label><figDesc>(a)  visualizes Gini coefficients obtained from BMI. We observe strategies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) to (c) Gini coefficients for an environment with known rankings. High values indicate similarity to the single cue heuristic, while low values correspond to equal weighting heuristics. (a) BMI results in Gini coefficients that are close to the single cue heuristic. (b) MI shows tendencies towards the single cue heuristic, especially with few observations. (c) Gini coefficients of the ideal observer model cover the whole range of possible values, indicating that a weighted combination of multiple features is used. (d) Average KL divergence from the posterior predictive distribution of both heuristics to the posterior predictive distribution of BMI. The KL divergence is lower for the single cue heuristic, which confirms our results from the Gini coefficient analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(c) spread over an even wider range of values. Figure 3 (d) confirms our findings by showing that BMI infers posterior predictive distributions that are much more similar to the single cue heuristic than to equal weighting in terms of their KL divergence.Next, we looked at an environment where feature directions are known instead of their ranking. For this, we optimized MI and BMI in an environment with only positive feature directions. The result here looks very different compared to the ranking condition.Gini coefficients resulting from BMI, visualized inFigure 4 (a), are consistently close to zero. Low Gini coefficients correspond to uniform weight vectors and hence in this environment the equal weighting heuristic turned out to be the resource-rational strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4</head><label>4</label><figDesc>(b) confirms earlier results showing that MI only leads towards an initial tendency towards heuristics. Early strategies are somewhat similar to equal weighting, but especially</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4</head><label>4</label><figDesc>Figure 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a) to (c) Gini coefficients for an environment with positive directions. High values indicate similarity to the single cue heuristic, while low values correspond to equal weighting heuristics. (a) BMI results in Gini coefficients that are close to the equal weighting. (b) MI shows tendencies towards the equal weighting heuristic, especially with few observations. (c) Gini coefficients of the ideal observer model cover the whole range of possible values, indicating that a weighted combination of multiple features is used. (d) Average KL divergence from the posterior predictive distribution of both heuristics to the posterior predictive distribution of BMI. The KL divergence is lower for the equal weighting heuristic, which confirms our results from the Gini coefficient analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 5</head><label>5</label><figDesc>Figure 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(a) to (c) Gini coefficients for an environment without ranking or direction. High values indicate similarity to the single cue heuristic, while low values correspond to equal weighting heuristics. (a) BMI, (b) MI and (c) ideal observer models result in Gini coefficients that cover the whole range of possible values, indicating that a weighted combination of multiple features is used. (d) Average KL divergence from the posterior predictive distribution of both heuristics to the posterior predictive distribution of BMI. The KL divergence is roughly equal for both heuristics, indicating that neither of the two is particularly similar to BMI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Percentage of correct decisions (averaged over all tasks) in the ranking condition plotted over the number of trials within a task. For human performance shaded contours represent the standard error of the mean. The left panel shows the ideal observer model and both heuristics, while the right shows BMI for different values of β. For BMI, lower β-values correspond to a less restricted model. Performance plots for the strategy selection model and feedforward network can be found in Appendix E and F respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Figure 8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>(a) Posterior distributions for each participant over different strategies in the ranking condition. High values indicate that the participant was likely to use the corresponding strategy. (b) Log-likelihood differences for each time-step averaged across all tasks. The solid blue line shows the average across all participants, whereas transparent lines correspond to individual participants. The left panel compares the single cue heuristic to the ideal observer model, the middle panel compares the single cue heuristic to the equal weighting heuristic, the right panel compares the single cue heuristic to BMI. Positive values indicate evidence for the single cue heuristic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Percentage of correct decisions (averaged over all tasks) in the direction conditionplotted over the number of trials within a task. For human performance shaded contours represent the standard error of the mean. The left panel shows the ideal observer model and both heuristics, while the right shows BMI for different values of β. For BMI, lower β-values correspond to a less restricted model. Performance plots for the strategy selection model and feedforward network can be found in Appendix E and F respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Figure 10</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>(a) Posterior distributions for each participant over different strategies in the direction condition. High values indicate that the participant was likely to use the corresponding strategy. (b) Log-likelihood differences for each time-step averaged across all tasks. The solid blue line shows the average across all participants, whereas transparent lines correspond to individual participants. The left panel compares equal weighting to the ideal observer model, the middle panel compares equal weighting to the single cue heuristic, the right panel compares equal weighting to BMI. Positive values indicate evidence for the equal weighting heuristic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>Percentage of correct decisions (averaged over all tasks) in the unrestricted condition plotted over the number of trials within a task. For human performance shaded contours represent the standard error of the mean. The left panel shows the ideal observer model and both heuristics, while the right shows BMI for different values of β. For BMI, lower β-values correspond to a less restricted model. Performance plots for the strategy selection model and feedforward network can be found in Appendix E and F respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>Figure 12</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>(a) Posterior distributions for each participant over different strategies in the unrestricted condition. High values indicate that the participant was likely to use the corresponding strategy. (b) Log-likelihood differences for each time-step averaged across all tasks. The solid blue line shows the average across all participants, whereas transparent lines correspond to individual participants. The left panel compares BMI to the ideal observer model, the middle panel compares BMI to equal weighting, the right panel compares BMI to the single cue heuristic. Positive values indicate evidence for BMI. heuristic emerged in this environment, we did not split our analysis and already considered BMI on the level of individual participants. Posterior probabilities obtained from a Bayesian model comparison in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>(a) and (b) show that the performance of participants did not change over the experiment, indicating that meta-learning already happened prior to the experiment. Shaded contours represent the standard error. (c) and (d) confirm this observation by showing that the selection of strategies also did not change during the experiment. High values indicate that</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>properties of the environment will determine what type of decision-making strategies are ecologically rational. Instead, we have to train our meta-learning models in different environments and then analyze what decision strategies emerge, for example by analyzing the weights' Gini coefficient. Looking at a model's emerging properties is a common</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>Figure A1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>1 :</head><label>1</label><figDesc>Meta-Learning while not converged do sample a batch of tasks: x 1:T , c 1:T ∼ p(x 1:T , c 1:T ); sample model parameters: Θ ∼ q(Θ; Λ); initialize loss: L(Λ) ← βKL [q(Θ; Λ)||p(Θ)]; for t ← 0 to T − 1 do compute λ λ λ t = {µ µ µ t , Ψ t } according to Equations 12 to 17; compute p(C t+1 = 1|x t+1 , λ λ λ t , Θ) according to Equation 4; accumulate loss: L(Λ) ← L(Λ) − log p(C t+1 = c t+1 |x t+1 , λ λ λ t , Θ); end perform gradient step: Λ ← AmsGrad(L(Λ), Λ); end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head></head><label></label><figDesc>of correct decisions (left) and probability of selecting each strategy (right) in the strategy selection model plotted over number of trials. of correct decisions (left) and Gini coefficients (right) for the feedforward neural network plotted over number of trials. Gini coefficients are shown for an example model with learning rate of 2 −4 but are similar for other learning rates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>Percentage of correct decisions in the unrestricted condition plotted over the number of trials within a task. For human performance shaded contours represent the standard error of the mean. The left panel shows the ideal observer model and both heuristics, while the right shows BMI for different values of β. For BMI, lower β-values correspond to a less restricted model. (b) Posterior distributions for each participant over different strategies in the unrestricted condition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>It also seems sensible to ask: what decision-making strategies can BMI infer? Both the single cue heuristic and equal weighting are subsets of the space of all possible weight vectors that can be inferred. Equal weighting heuristics correspond to uniform vectors (e.g., [1, 1, 1, 1]), while single cue heuristics can be expressed through a vector with a single non-zero entry (e.g., [1, 0, 0, 0]). BMI could thus -in principle -discover the two heuristics and select between them whenever appropriate. MI (or equivalently BMI with β = 0)</figDesc><table><row><cell>Figure 2</cell></row><row><cell>Illustration of two optimized neural networks with a sparsity-inducing prior and different</cell></row><row><cell>resource limitations. For clarity, we omit recurrent connections and show only the means of</cell></row><row><cell>q(w; λ λ λ t ) as an output. (a) Network trained with low resource limitations uses all available</cell></row><row><cell>connections. (b) Network trained with high resource limitations uses only the set of</cell></row><row><cell>connections that are most useful for increasing performance. Network (b) is much simpler</cell></row><row><cell>than network (a).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>decision-making environment is known. In particular, it knows about the linear-Gaussian relationship. With this knowledge, it is able to compute the optimal solution by combining information from all features through weighted sums. Heuristics, like the single cue strategy and equal weighting, assume that computing weighted sums is too burdensome and instead bet on simpler ways for making decisions. The single cue heuristic only inspects a single feature, while the equal weighting heuristic sums up all features without weighting them.BMI does not know anything about the structure of the environment explicitly. Instead, it</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>is used for meta-learning. In general, this distribution should reflect a participant's prior experiences in the world and its expectations about what tasks might be encountered during the experiment. Here, we make the following assumptions. All tasks involve two options with four different features, and we concentrate on tasks with no costs to reveal information about features. In order to generate a single task, we proceed in three steps:</figDesc><table><row><cell>1. Randomly generate features weights (ref. Equation 1 or 2) by sampling from a</cell></row><row><cell>standard normal distribution.</cell></row></table><note>2. Randomly generate features x A,t and x B,t from a multivariate normal distribution with zero mean and covariance matrix Σ.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that non-binary features, like average movie ratings, can always be dichotomized at a loss of information. In past studies, this has been frequently done by setting values which were less than the median to 0 and otherwise to 1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that alternatively, it would have also been possible to assume that the noise term follows an extreme-value distribution, which would result in a logistic regression model. We have decided on the probit model instead because it allows us to compute predictive posterior distributions in closed-form.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot"><ref type="bibr" target="#b64">&amp; Valpola, 2004)</ref>, which allows us to interpret the KL term as the coding length of meta-parameters when encoded together with the data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">In our ideal observer implementation, we always assume the original standard normal prior over weights, i.e., the prior is not adjusted based on the additional information about ranking or direction. The fact that the prior does not reflect side information makes the resulting model slightly less ideal than a true ideal observer.5 The extreme value of one is only reached in the limit of an infinite number of residents, otherwise the maximum Gini coefficient for d residents is 1 − d −1 .</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Note</head><p>Appendix A</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Power Analysis</head><p>Environments with continuous features can facilitate statistical analysis as fewer trials are needed to observe expected effects. To verify this hypothesis, we conducted a power analysis for an environment with continuous features and one for an environment, where features are dichotomized based on their median. The results presented here are based on an environment with known feature rankings and T = 10 decisions per task.</p><p>In both settings, we computed how many tasks are on average required to distinguish the single cue heuristic from the ideal observer model, assuming that decisions are made by the single cue heuristic. In dichotomized environments, ties between features of two options are likely, and hence we modified the single cue heuristic to make decisions based on the first feature that discriminates between both options. We assumed that decisions are made by the single cue heuristic and measured the average support for the single cue heuristic over the ideal observer model on a single task by computing log-Bayes Factors <ref type="bibr" target="#b69">(Kass &amp; Raftery, 1995)</ref> between both strategies:</p><p>The expectation over tasks was approximated using 10 5 samples. Furthermore, we assumed that tasks are sampled independently from each other, meaning that we can multiply log BF by the total number of encountered tasks K to get expected log-Bayes</p><p>Factors for an experiment with K tasks. <ref type="figure">Figure A1</ref> shows this analysis for both continuous and dichotomized environments. We observed that it requires roughly four times more tasks to distinguish the single cue heuristic from an ideal observer model in environments with dichotomized features compared to one with continuous features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B Variational Inference Details</head><p>We update posterior distributions over weights after each observation using variational inference. The true posterior is approximated with a normal distribution q(w; λ λ λ t ) = N (w; µ µ µ t , Ψ t ) and its parameters λ λ λ t = (µ µ µ t , Ψ t ) are obtained through maximizing the evidence lower bound:</p><p>The initial prior is set to a standard normal distribution q(w; λ λ λ 0 ) = N (0, I). We furthermore employ a mean-field approximation, in which posterior covariance matrices Ψ t are restricted to be diagonal. To ensure positive semi-definite covariance matrices, we parametrize them with logarithms of their standard deviations.</p><p>Equation 3 is maximized through gradient-based optimization using AmsGrad <ref type="bibr" target="#b111">(Reddi et al., 2019</ref>) with a learning rate of 0.1. Training is stopped once the evidence lower bound function does not increase anymore over 10 steps or after 1000 total gradient steps.</p><p>The Kullback-Leibler divergence can be evaluated in closed-form assuming normal prior and posterior distributions. The expected log-likelihood term is approximated through 100 samples and we employ the reparametrization trick <ref type="bibr" target="#b73">(Kingma &amp; Welling, 2013)</ref> to obtain gradients with respect to the variational parameters λ λ λ t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-Learning Details</head><p>Architecture. The architecture of MI and BMI consists of a gated recurrent unit <ref type="bibr">(GRU, Cho et al., 2014</ref>) with a hidden size of 128 units, followed by two linear transformations projecting to µ µ µ t and log σ σ σ t respectively. The latter are used to construct diagonal posterior covariance matrices Ψ t as in the ideal observer model. The exact forward pass equations are given by:</p><p>where σ denotes the logistic sigmoid function and element-wise multiplication.</p><p>Together, we denote the set of all model parameters as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D Bayesian Model Comparison</head><p>We relied on Bayesian model comparisons <ref type="bibr">(Bishop, 2006)</ref> to test which hypothesis accounted best for human choices. For the most part, we performed separate comparisons for each participant in order to detect potential individual differences.</p><p>Let</p><p>x KT } denote the set of all observed features and</p><p>. . ,ĉ KT } the set of corresponding decisions from a single participant i, and let X andĉ denote the joint data for all participants. K corresponds to the total number of tasks and T to the number of trials per task. Note, that we useĉ to refer to decisions made by participants and c to refer to ground truth labels. We can then compute the probability that a participant used strategy m through Bayes' rule:</p><p>We assumed a uniform prior over hypothesis in all of our analyses. For models that include fitted parameters, we approximated the model evidence using the Bayesian information criterion (BIC, <ref type="bibr" target="#b125">Schwarz et al., 1978)</ref>:</p><p>where |θ| denotes the number of parameters and θ * a maximum likelihood estimate. For all models except BMI, the maximum likelihood estimate was obtained using Bayesian optimization <ref type="bibr" target="#b51">(GPyOpt, 2016;</ref><ref type="bibr" target="#b96">Močkus, 1975;</ref><ref type="bibr" target="#b134">Snoek et al., 2012)</ref>. For BMI, we instead adopted a simple grid-search procedure. Fitted parameters and their search domains were: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Equation 31 reveals that this strategy selection model amounts to selecting the model with the highest accumulated log evidence over all previous time-steps. The strategy selection model combines advantages of the ideal observer model with those of heuristics: if additional information is provided heuristics may outperform the ideal observer early on and hence they will be initially preferred. However, after a while, the ideal observer model surpasses both heuristics in terms of performance and hence it will be preferred during the later stages of a task. <ref type="figure">Figure E1</ref> shows the average performance of the strategy selection model and its probability for the selection of each strategy plotted over the number of trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F Feedforward Network</head><p>Our feedforward neural network models use the same architecture as MI and BMI, but without recurrent connections and the previous target as additional input. Parameter updating is performed through gradient descent on the negative log-likelihoods of targets. <ref type="figure">Figure F1</ref> shows the average performance of the feedforward neural network with different learning rates together with the Gini coefficients of its inferred weight vectors. In our model comparisons, we treated the learning rate α as a free parameter that is fitted to the empirical data. The exact forward pass equations are given by:</p><p>Ψ t = diag e log σ σ σt <ref type="bibr">(37)</ref> where σ denotes the logistic sigmoid function and element-wise multiplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix G Experiment 3b: Unknown Ranking and Direction, 4 Features</head><p>Here, we briefly summarize the results of our original study with four features and no information about ranking and direction. We have excluded this study from the main text because the performance of participants did not allow us to draw decisive conclusions about their use of strategies. The design was identical to experiment 3, except that participants observed four features per alien.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were students from the University of Marburg, taking part in the study for course credits. Besides course credits, they got a chance to win a e 10 voucher if they made more than 60% correct decisions. The experiment was approved by the local ethics board (AZ 2020-32k). In total, we collected data from 23 participants (16 female, average age: 23.09 ± 4.38). The median time to complete the experiment was 36.09 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance</head><p>Participants found this version much harder and performed substantially worse.</p><p>Without the additional information from the first two conditions, their cognitive resource limitations became a dominating factor. The average performance dropped to 57.14 ± 4.38%, ref. <ref type="figure">Figure G1 (a)</ref>. While some participants performed well, a substantial amount was at or close to chance level. We used an exact binomial test with a base probability of p = 0.5 to assess whether or not individual participants chose the better option more frequently than chance. In this study, only 14 out of 23 participants performed better chance. We then repeated the mixed-effects logistic regression analysis described in the main text to investigate participants' learning over trials and tasks. The results of this model showed no significant fixed effect of either trial number (β = −0.01, z = −0.27, p = .79) or task number (β = −0.01, z = −0.29, p = .77) onto choosing the better option.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Emergence of invariance and disentanglement in deep representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1947" to="1980" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.12213</idno>
		<title level="m">Where is the information in a deep neural network</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Human category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">G</forename><surname>Ashby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Maddox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="149" to="178" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the measurement of inequality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Atkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="244" to="263" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ignorance or integration: The cognitive processes underlying choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ayal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hochman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="455" to="474" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Efficient data compression in perception and perceptual memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">891</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cumulative dominance and heuristic performance in binary multiattribute choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baucells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Carrasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations research</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1289" to="1304" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Learning a synaptic learning rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cloutier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m">Seattle International Joint Conference on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">969</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A response-time approach to comparing generalized rational and take-the-best models of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Bergert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">107</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Resource-rational decision making. Current Opinion in Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="15" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rational decisions in large worlds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Binmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annales d&apos;Economie et de Statistique</title>
		<imprint>
			<biblScope unit="page" from="25" to="41" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Endres</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
	<note>Where do heuristics come from?</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reinforcement learning, fast and slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="408" to="422" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Preliminaries to a psychology of inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="210" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">AAAI spring symposium: Between a rock and a hard place: Cognitive science principles meet AI-hard problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="17" to="22" />
		</imprint>
	</monogr>
	<note>Robust inference with simple cognitive models</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Are rational actor models &quot;rational&quot; outside small worlds. Evolution and Rationality: Decisions, Co-operation, and Strategic Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="84" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Assessing the empirical validity of the&quot; take-the-best&quot; heuristic as a model of human probabilistic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1332</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decision making with the&quot; adaptive toolbox&quot;: Influence of environmental structure, intelligence, and working memory load</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">611</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequential processing of cues in memory-based multiattribute decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="895" to="900" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Take the best versus simultaneous feature matching: Probabilistic inferences from memory and effects of reprensentation format</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">277</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stimulus format and working memory in fast and frugal strategy selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="361" to="380" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Perception and the representative design of psychological experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brunswik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1956" />
			<publisher>Univ of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neuroeconomics: How neuroscience can inform economics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Loewenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prelec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic Literature</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="64" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the simplicity and speed of programs for computing infinite sets of natural numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Chaitin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="422" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Fast, frugal, and rational: How rational norms explain behavior. Organizational behavior and human decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oaksford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nakisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Redington</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="63" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simplicity: A unifying principle in cognitive science?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vitányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="22" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">How good are simple heuristics? Simple heuristics that make us smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Czerlinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="97" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A theory of learning to infer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">412</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Linear models in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Corrigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">95</biblScope>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The influence of information redundancy on probabilistic inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dieckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1801" to="1813" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unit weighting schemes for decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Einhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational behavior and human performance</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="192" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Algorithmic complexity for short binary strings applied to psychology: A primer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gauvrit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zenil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Delahaye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Soler-Toscano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Behavior research methods</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">The information-theoretic and algorithmic approach to human, animal, and artificial cognition. Representation and reality in humans, other living organisms and intelligent machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gauvrit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zenil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tegnér</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="117" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sequential ideal-observer analysis of visual discriminations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Geisler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">267</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bounded rationality, abstraction, and hierarchical decision-making: An information-theoretic optimality principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Leibfried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grau-Moya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers in Robotics and AI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Origin of perseveration in the trade-off between reward and complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Computational rationality: A converging paradigm for intelligence in brains, minds, and machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">6245</biblScope>
			<biblScope unit="page" from="273" to="278" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">On narrow norms and vague heuristics: A reply to kahneman and tversky</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The adaptive toolbox and lifespan development: Common questions? Understanding human development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="423" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Why heuristics work</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on psychological science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="29" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Homo heuristicus: Why biased minds make better inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in cognitive science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="143" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Heuristic decision making. Annual review of psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="451" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Reasoning the fast and frugal way: Models of bounded rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">650</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Betting on one good reason: The take the best heuristic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="75" to="95" />
		</imprint>
	</monogr>
	<note>Simple heuristics that make us smart</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Bounded rationality: The adaptive toolbox</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Selten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Simple heuristics that make us smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Journal of experimental psychology: Learning, memory, and cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glöckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Betsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">1055</biblScope>
		</imprint>
	</monogr>
	<note>Multiple-reason decision making based on automatic processing</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">From conditioning to category learning: An adaptive network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Bower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">227</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">How do people solve the &quot;weather prediction&quot; task?: Individual variability in strategies for probabilistic category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning &amp; Memory</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="408" to="418" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">GPyOpt: A bayesian optimization framework in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gpyopt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Subjective randomness as statistical inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Austerweil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="85" to="109" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">The minimum description length principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Grünwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grunwald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Self-directed learning: A cognitive and computational perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Markant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="464" to="481" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Probabilistic functioning and the clinical method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Hammond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">255</biblScope>
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">From information processing to decisions: Formalizing and comparing psychologically plausible choice models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Hilbig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moshagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="26" to="40" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Reconsidering &quot;evidence&quot; for fast-and-frugal heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Hilbig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="923" to="930" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Environmental drivers of systematicity and generalization in a situated agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SklGryBtwr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Keeping the neural networks simple by minimizing the description length of the weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Camp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth annual conference on Computational learning theory</title>
		<meeting>the sixth annual conference on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="5" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The efficiency of human cognition reflects planned information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 34th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Ignoring information in binary choice with continuous variables: When is less &quot;more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="124" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Take-the-best and other simple strategies: Why and when they work well with binary cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="205" to="249" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Heuristic and linear models of judgment: Matching rules and environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">733</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Variational learning and bits-back coding: An information-theoretic view to bayesian learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Honkela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="800" to="810" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Simple heuristics and rules of thumb: Where psychologists and behavioural biologists might meet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioural processes</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="124" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">An introduction to variational methods for graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="233" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Cue abstraction and exemplar memory in categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Winman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">924</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Exemplar effects in categorization and multiple-cue judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C</forename><surname>Olsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">133</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the american statistical association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">430</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Psychological heuristics for making inferences: Definition, performance, and the emerging theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Katsikopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="29" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Naive heuristics for paired comparisons: Some results on their relative accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Katsikopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martignon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="488" to="494" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The robust beauty of ordinary information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Katsikopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schooler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1259</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Variational dropout and the local reparameterization trick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2575" to="2583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Three approaches to the quantitative definition ofinformation&apos;. Problems of information transmission</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Kolmogorov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Causal responsibility and counterfactuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lagnado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gerstenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zultan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1036" to="1073" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Insight and strategy in multiple-cue learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lagnado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">162</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Compositional generalization through meta sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9788" to="9798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Evidence accumulation in decision making: Unifying the &quot;take the best&quot; and the &quot;rational</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">models. Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="343" to="352" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Generating random correlation matrices based on vines and extended onion method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kurowicka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Joe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of multivariate analysis</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1989" to="2001" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Simple regression models. Imperfect Decision Makers: Admitting Real-World Rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Lichtenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Şimşek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="13" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Strategy selection as rational metareasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">762</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="page" from="1" to="85" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">An automatic method for discovering rational heuristics for risky choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CogSci</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Rational metareasoning and the plasticity of cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musslick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1006043</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">From perception to preference and on to inference: An approach-avoidance analysis of thresholds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schooler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">501</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Good judgments do not require complex cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Marewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="121" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Cognitive niches: An ecological model of strategy selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Marewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schooler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">393</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Fast, frugal, and fit: Simple heuristics for paired comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="29" to="71" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title/>
		<idno type="DOI">10.1023/A:1015516217425</idno>
		<ptr target="https://doi.org/10.1023/A:1015516217425" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Why does one-reason decision making work. Simple heuristics that make us smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Group</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="119" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">The aging decision maker: Cognitive aging and the adaptive selection of decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schooler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology and aging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">796</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Learning to choose: Cognitive aging and strategy selection learning in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Helversen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology and aging</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">299</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1307.2118</idno>
		<title level="m">A pac-bayesian tutorial with a dropout bound</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Delétang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mcgrath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11223</idno>
		<title level="m">Meta-trained agents implement bayes-optimal agents</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">On bayesian methods for seeking the extremum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Močkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimization techniques IFIP technical conference</title>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="page" from="400" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Variational dropout sparsifies deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ashukha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2498" to="2507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Challenging the role of implicit processes in probabilistic category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lagnado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="505" to="511" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">The right tool for the job? comparing an evidence accumulation and a naive strategy selection model of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="456" to="481" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Empirical tests of a fast-and-frugal heuristic: Not everyone &quot;takes-the-best</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="96" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">The effectiveness of feedback in multiple-cue probability learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Tunney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="890" to="908" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<idno type="arXiv">arXiv:1512.06789</idno>
		<title level="m">Information-theoretic bounded rationality</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rowland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sprechmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.03030</idno>
		<title level="m">Meta-learning of sequential strategies</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Heuristics as bayesian inference under extreme priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Parpart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="127" to="144" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Active learning reveals underlying decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Parpart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
		<idno type="DOI">10.1101/239558</idno>
		<ptr target="https://doi.org/10.1101/239558" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Adaptive strategy selection in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">534</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">The adaptive decision maker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Inferences from memory: Strategy-and exemplar-based judgment models compared</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="37" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Meta-learners&apos; learning dynamics are unlike learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Rabinowitz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01320</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09237</idno>
		<title level="m">On the convergence of adam and beyond</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">When do people use simple heuristics, and how can we tell?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Ssl: A theory of how people learn to select strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Otto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">207</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Bayesian model selection for group studies-revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rigoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="971" to="985" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Cognitive psychology for deep neural networks: A shape bias case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2940" to="2949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Principles of metareasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wefald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="361" to="395" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Ending the rationality wars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Collected Papers</title>
		<editor>Knowledge, Rationality, and Morality</editor>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Rational approximations to rational models: Alternative algorithms for category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1144</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m">Meta-learning with memory-augmented neural networks. International conference on machine learning</title>
		<imprint>
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Testing adaptive toolbox models: A bayesian hierarchical approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scheibehenne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title level="m" type="main">Useful heuristics. Making essential choices with scant information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scheibehenne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Helversen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="195" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Simple principles of metalearning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report IDSIA</note>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">Simple trees in complex forests: Growing take the best by approximate bayesian computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Estimating the dimension of a model. The annals of statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Heuristics made easy: An effort-reduction framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Oppenheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">207</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">On the computational power of neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Siegelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth annual workshop on Computational learning theory</title>
		<meeting>the fifth annual workshop on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="440" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Rational choice and the structure of the environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">129</biblScope>
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<title level="m">Bounded rationality. Utility and probability</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="15" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">Invariants of human behavior. Annual review of psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Efficient coding explains the universal law of generalization in human perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Sims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="issue">6389</biblScope>
			<biblScope unit="page" from="652" to="656" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Linear decision rule as aspiration for simple decision heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Şimşek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2904" to="2912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Learning from small samples: An analysis of simple decision heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Şimşek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Buckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>K. Q. Weinberger</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Toolbox or adjustable spanner? a critical comparison of two metaphors for adaptive decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Söllner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">215</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">A formal theory of inductive inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Solomonoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
	<note>part i. Information and control</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">People as intuitive scientists: Reconsidering statistical explanations of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szollosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1008" to="1018" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.tics.2020.09.005</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.tics.2020.09.005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Learning to learn: Introduction and overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
	<note>Learning to learn</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Sparse bayesian learning and the relevance vector machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Tipping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="211" to="244" />
			<date type="published" when="2001-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Heuristics for ordering cue search in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dieckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1393" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Précis of simple heuristics that make us smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="727" to="741" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title level="m" type="main">Environments that make us smart: Ecological rationality. Current directions in psychological science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="167" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<title level="m" type="main">Ecological rationality: Intelligence in the world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Judgment under uncertainty: Heuristics and biases. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="1124" to="1131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">A hierarchical bayesian modeling approach to searching and stopping in multi-attribute judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Ravenzwaaij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1384" to="1405" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Intractability and the use of heuristics in psychological explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Van Rooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wareham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="471" to="487" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Why does cue polarity information provide benefits in inference problems? the role of strategy selection and knowledge of cue importance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Helversen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wilke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta psychologica</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="82" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">One and done? optimal decisions from very few samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="599" to="637" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Predictive and diagnostic learning within causal models: Asymmetries in cue competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Waldmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">222</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tirumala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05763</idno>
		<title level="m">Learning to reinforcement learn</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Probabilistic inferences under emotional stress: How arousal affects decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wichary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="525" to="538" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BklEFpEYwS" />
		<title level="m">Meta-learning without memorization. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Efficient compression in color naming and its evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zaslavsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Regier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page" from="7937" to="7942" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zenil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tegnér</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.06338</idno>
		<title level="m">Approximations of algorithmic and structural complexity validate cognitive-behavioural experimental results</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">An information-theoretic perspective on the costs of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zenon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Solopchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="5" to="18" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
