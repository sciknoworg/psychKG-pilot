<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">What label should be applied to content produced by generative AI?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Epstein</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">A</forename><surname>Arechar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">CATHY MENGYING FANG</orgName>
								<orgName type="institution" key="instit2">Massachusetts Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Center for Research and Teaching in Economics (CIDE)</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="laboratory">Accurate Infographic Human Bright/Contrast Computer Art Sound quality adjustments AI Art AI−Human Art Accurate Infographic Chatbot Magic Eraser Family Photo Caption Image of Event Misleading Infographic Human Photoshop Image of Event Video splicing AI Song AI−Generated Image of Event AI−Human Song AI−Human−Generated Image of Event Faceswap Magic Eraser Politican Misleading Infographic Chatbot Video AI−generated</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="laboratory">Accurate Infographic Human Bright/Contrast Computer Art Sound quality adjustments AI Art AI−Human Art Accurate Infographic Chatbot Magic Eraser Family Photo Caption Image of Event Misleading Infographic Human Photoshop Image of Event Video splicing AI Song AI−Generated Image of Event AI−Human Song AI−Human−Generated Image of Event Faceswap Magic Eraser Politican Misleading Infographic Chatbot Video AI−generated</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">What label should be applied to content produced by generative AI?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>generative AI</term>
					<term>disclosure</term>
					<term>misinformation</term>
					<term>cross-cultural study</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The rise of generative AI has created pressure for content labeling. This paper investigates the public&apos;s understanding of nine potential labels. Participants from the US (N=1056), Mexico (N=1060), Brazil (N=1065), India (N=1038), and China (N=1031) were shown twenty different types of content that varied in the extent to which they were AI-generated, and the extent to which they were misleading. Across countries and demographic subgroups, participants consistently associated &quot;AI Generated, &quot; &quot;Generated with an AI tool, &quot; and &quot;AI manipulated&quot; with AI-generated content, regardless of misleadingness; and associated &quot;Deepfake&quot; and &quot;Manipulated&quot; with misleading content, regardless of AI involvement. Interestingly, &quot;Artificial&quot; performed poorly in China due to translation nuances, but performed well on both alignment tasks in the other countries. Finally, we examined self-reported effects of the terms on belief in, and attitudes toward, labeled content. Our study underscores the need for deliberate decision-making regarding the objectives and implementation of generative AI disclosure. CCS Concepts: • Human-centered computing → Collaborative and social computing; Empirical studies in collaborative and social computing.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The recent proliferation of generative artificial intelligence (AI) has made it easier than ever before for almost anyone to create high-quality images and videos portraying whatever the creator desires. The rise of AI-generated media will surely have many complex impacts on society <ref type="bibr" target="#b6">[6]</ref>, transforming a wide variety of aspects of creative work and the information environment. In response to these widespread concerns, there has been significant attention and push directed towards developing methods for disclosing and governing content that has been produced by generative AI (e.g., on social media). These concerns have also sparked regulatory interest, such as the AI Disclosure Act of <ref type="bibr">2023 [35]</ref> that was recently introduced in the United States, which would require any output generated by AI to disclose "Disclaimer: this output has been generated by artificial intelligence. " Similarly, on July 21, 2023, President Biden announced that many large technology companies have made commitments to clearly label AI-generated content via watermarking <ref type="bibr" target="#b1">[2]</ref>.</p><p>Within this push to label AI-generated content, one facet that has received particular attention is the threat that AI-generated media play to the information environment <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b13">13]</ref>: by allowing a wide range of actors to easily create deceptive media (e.g., images or videos that depict events that did not occur), generative AI has the potential to scale up the threat of misinformation. For example, in Meta's announcement on generative AI, they mention labeling in reference of their approach to mitigating misinformation: "We're following industry best practices so it's harder for people to spread misinformation with our tools. Images created or edited by Meta AI, restyle, and backdrop will have visible markers so people know the content was created by AI.. <ref type="bibr" target="#b20">[20]</ref>" Furthermore, in his remarks when signing an executive order on AI, President Biden emphasized "it's already happening that AI devices <ref type="bibr">[sic]</ref> are being used to deceive people. Deep fakes use AI-generated audio and video to smear reputations, speak -spread fake news, and commit fraud. <ref type="bibr" target="#b0">[1]</ref>" As these quotes highlights, a prominent motivation for labeling AI generated content comes from its ability to mislead, and the resulting threat to both individuals and democratic institutions at large.</p><p>We begin by highlighting that this creates a core tension in the push to label AI-generated content. Policies like the AI Disclosure Act focus on the process through which the content is created, and thus propose to label all AI-generated content. Yet much of the motivation to label comes from AI-generated content's potential to be misleading and thus pose a threat to society -and only a (potentially small) subset of AI generated content is misleading.</p><p>Thus, there are two distinct goals that AI labeling might pursue. On the one hand, labels might focus on the process through which content is created, seeking to identify content that was generated by AI -regardless of what the content is, or what positive versus negative impacts that content might have. On the other hand, rather than focusing on the process through which the content was created, labels might instead attempt to identify content that has the potential to mislead. If the goal is to label potentially misleading content, the process through which the content was created is less important: A "cheapfake" created through deceptive editing of existing footage or incorrect captioning could be just as misleading -and thus just as worthy of a label -as artificial media created from scratch by an algorithm <ref type="bibr" target="#b23">[23]</ref>. (Of course, these two goals are not mutually exclusive -one might run separate labeling programs, one for AI-generated content and another for misleading content.)</p><p>Whichever of these goals a labeling policy decides to pursue, it remains unclear what term(s) would be widely understood by the public if used to label content. People have many different conceptions of what AI is, and how it operates <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b30">30]</ref>. Furthermore, there is a continuum of different types of content with varying levels of algorithmic intervention, making binary classification difficult. Finally, social media users (and the public more generally) vary widely in their level of familiarity with AI and AI-related terms. Not to mention that the meaning of the terms may vary in different languages. Together, these issues make it unclear how any given term will be understood by people observing a label that technology companies would apply. In this paper, we shed empirical light on this complex problem.</p><p>Specifically, we ask the following research questions:</p><p>(1) Which labels do participants most clearly understand as describing AI-generated content?</p><p>(2) Which labels do participants most clearly understand as describing misleading generated content?</p><p>(3) Which labels are predicted to have the biggest effect on reducing the belief in an event actually occurring? (4) How do the answers to 1-3 vary across cultures?</p><p>To address these questions, we ran a large-scale online study exploring how members of the general public in the United States, Brazil, Mexico, India and China understand a variety of AI-related terms that could potentially be used as labels. Specifically, we randomly assigned participants to see one of nine possible labeling terms, selected through consultation with academic researchers, technology company teams working on misinformation and generative AI labeling, and coalitions/initiatives working on provenance policy. We then show participants descriptions of 20 different kinds of content that vary in the extent to which they were generated by AI and the extent to which they are misleading, and ask the participants whether or not they think the label describes each piece of content. Importantly, we are not asking participants which label they prefer, or otherwise eliciting their attitudes or behaviors with respect to the terms. Instead, we are asking a more fundamental question: what kinds of content participants would consider to be described by a given term. That is, we are assessing their understanding of which types of content fall under the umbrella of each term. It is critical to know the answer to this question before developing any labeling policy, as it is imperative that the term used for the label is widely understood by the public to correspond to the types of content that the policy is seeking to label. For example, if participants considered both a misleading image created by AI and an image that was given a misleading caption by a human to be Manipulated, then Manipulated would not be a good term for labeling content generated by AI -but could be a viable term for labeling content that is misleading.</p><p>Our study results show that the best terms that describe either labeling goal are completely different. We find that the terms AI Generated, Generated with an AI Tool, and AI Manipulated -the three terms that explicitly mention AI -are most consistently associated with content that is generated using AI (regardless of whether that content is misleading). This suggests that respondents had a comparatively good understanding of what the term "AI" means in this context. Conversely, the terms Deepfake and Manipulated are most consistently associated with content that is misleading (regardless of whether it is generated using AI or other means). Thus, if a labeling policy's goal is to inform users regarding the process by which the content was created (with or without AI), then AI Generated, Generated with an AI Tool, or AI Manipulated could be appropriate. Conversely, if the goal is to alert users content that is potentially misleading, Manipulated could be appropriate (while Deepfake was understood by the general public as corresponding to misleading content regardless of generation process, the formal definition implies AI generation -thus this term does not seem optimal for labeling content that is misleading regardless of process). In addition, we found the terms perform largely consistently across cultures, with the exception of Artificial in Chinese speaking population due to the difference in its epistemology. Overall, our results show that labeling terms performed differently in terms of their accuracy of representing the two labeling goals. This cross-cultural variations also highlight the complex nature of creating labeling terms in different cultural contexts. We hope the insights from this paper can guide people to create the labels that best match the labeling goals and the public perception of the label.</p><p>In short, our contributions are as follows:</p><p>• A practical framework for labeling AI-generated content that makes it explicit that labeling based on process versus misleadingness are two fundamentally different goals</p><p>• A 5,130 participant cross-cultural study informed by this framework that illuminates the public's understanding of a variety of potential labeling terms</p><p>• An open-sourced study and participant response dataset</p><p>• A set of insights and design recommendations for labels that are appropriate for each labeling goal, so that whichever goal a policymaker or platform decides to pursue, they have guidance on which labels to use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>For mitigating misinformation more generally, there is evidence that warning labels can in many cases be effective. But however when it comes to labels for AI-generated content in particular, key questions about how people both perceive AI systems and understand content provenance become central.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Warning labels to mitigate misinformation</head><p>When presented with information on social media, users use a range of tactics for assessing the veracity of posts <ref type="bibr" target="#b9">[9]</ref>.</p><p>To support user judgements, there is growing work on the efficacy of warning labels for labeling misleading content on social media. This work has demonstrated that warning labels may reduce people's likelihood to believe <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b25">25]</ref> and share <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b37">38]</ref> misleading content on social media. This work has also identified factors that might influence the efficacy of warning labels, such as the label's source <ref type="bibr" target="#b35">[36]</ref>, the terminology used <ref type="bibr" target="#b33">[33]</ref>, the political alignment of the consumer <ref type="bibr" target="#b26">[26]</ref>, the relative absence of labels for other pieces of content <ref type="bibr" target="#b24">[24]</ref>, and the use of humor in the labels <ref type="bibr" target="#b11">[11]</ref>. In a series of qualitative interviews, <ref type="bibr" target="#b29">[29]</ref> find that warning labels can be perceived as paternalistic, biased, and punitive. A potential danger of labeling schemes, however, is that they might inadvertently induce users to believe that content that is not labeled is factual, referred to as "the implied truth effect" <ref type="bibr" target="#b24">[24]</ref>. This effect is particularly thorny for labelling AI-generated content via user-provided labels because bad actors could simply lie. In the context of AIgenerated warning labels, recent work has show that explaining how the label was created can increase the labels' efficacy <ref type="bibr" target="#b5">[5]</ref>. For their experiments on the human detection of political deepfakes, <ref type="bibr" target="#b15">[15]</ref> include a disclosure stating the content "contains AI-generated content" but do not test the efficacy of that particular disclosure statement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Perceptions of AI-generated media</head><p>The term AI itself is riddled with fallacies, ambiguities <ref type="bibr" target="#b21">[21]</ref> and divergent interpretations <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b30">30]</ref>. AI is a diffuse sociotechnical system <ref type="bibr" target="#b32">[32]</ref> which is subject to diverse perceptions, such as anthropomorphization <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b36">37]</ref> and conceptual drift <ref type="bibr" target="#b6">[6]</ref>, which can pose downstream problems for how people reason about these technologies <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b7">7]</ref>. These perceptions give rise to a constellation of different folk theories for how these systems operate <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b31">31]</ref>.</p><p>These perceptions and corresponding folk theories in turn impact how to design disclosures and terminology to contextualize their use, not only because different terms vary in the extent to which they implicate AI in the generative process, but also AI itself may be perceived in having forms of intent and agency. Langer et al. <ref type="bibr" target="#b19">[19]</ref> finds that terminological differences in how algorithmic decision-making systems are refereed (e.g AI vs algorithm vs computer program ) can impact people's perceptions of properties of the systems themselves (such as perceived complexity)</p><p>and their evaluation of the systems (such as trust). Scott et al. <ref type="bibr" target="#b30">[30]</ref> find that people perceive a degree of consciousness in generative AI systems. Epstein et al. <ref type="bibr" target="#b7">[7]</ref> find that anthropomorphizing the AI system can impact the perceived credit and responsibility to human artists involved in the creation of AI art. Khadpe et al. <ref type="bibr" target="#b17">[17]</ref> find that the conceptual metaphors used to describe an AI agent can impact not only users pre-use expectations but also their post-use evaluations of their interactions with that AI agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Provenance of AI-generated media</head><p>Any labeling scheme for AI-generated media requires determining what content is AI-generated or not in the first place.</p><p>One possible way warning labels for AI-generated content could be implemented is by asking users how their content was generated, and using their reports for labelling. However, this approach is vulnerable to both the implied truth effect (discussed above) and bad actors who can simply lie. Therefore, a much more promising approach is establishing frameworks for digital provenance across content types that can provide a cryptographically secure chain-of-custody for content from point-of-capture to being viewed on social media. The Coalition for Content Provenance and Authenticity (C2PA) <ref type="bibr" target="#b28">[28]</ref> has put forward specifications for i) what types of information are associated with various types of content, ii) how that information is displayed to users, and iii) methods for identifying if that information has been tampered with. Developing a chain of custody for digital content is critical as it spreads across social media. While promising, such frameworks are challenging because they require widespread adoption and coordination across the media ecosystem <ref type="bibr" target="#b6">[6]</ref>. A key feature for labelling AI-generated content in general and for surfacing content provenance in particular is that the process must be perceived to be legitimate <ref type="bibr" target="#b22">[22]</ref>.</p><p>In this paper, we attempt to connect these distinct workstreams by understanding what terms can be used for warnings labels for AI-generated content that might interact with provenance tooling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>The study was conducted in Qualtrics using participants from the United States (in English), Mexico (in Spanish), Brazil (in Portuguese), India (in English), and China (in Mandarin); and the research was deemed exempt by the local Institutional Review Board. Informed consent was obtained from all participants. The exact question wordings asked can be found in the Appendix. For Brazil, we recruited a translator from the website Upwork and asked them to translate the materials into Brazilian Portuguese; for Mexico, one of the authors who is a native speaker translated the documents;</p><p>for China, we recruited a translator from the website Upwork to translated the documents, which were then further revised by one of the authors who is a native speaker. We acknowledge that translation is a difficult process, but we tried our best to adhere to the principle of translating the "implied meaning" not "direct word for word" translation (or back translation). The main part of the study followed the individual difference measures. Participants were randomly assigned to be shown one of nine potential terms for describing AI-generated content, shown in <ref type="table">Table 1</ref>. That is, the study used a between-subjects design in which each participant saw only a single term, to avoid spillover effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participants</head><p>We note that another set of participants were not assigned a labeling term, and instead were asked: "How much was a human involved in the creation of this content?" (Likert scale: 1 -No human involvement whatsoever, to 7 -Completely human created) and "How much was AI involved in the creation of this content?" (1 -No AI involvement whatsoever, to 7 -Completely AI created). This data was collected as a robustness check to validate our ground truth labels for the extent to which each the 20 content types where AI generated. Specifically, we calculate a continuous AI-generated score for each content type by subtracting the average response to the human involvement question from the average response to the AI involvement score. As shown in Appendix <ref type="figure" target="#fig_14">Figure A1</ref>, there is good agreement between our choice of AI-generated ground truth labels and these continuous rating-based AI-generated scores.</p><p>To construct our set of nine terms, we consulted with academic researchers who study misinformation and/or the effects of generative AI on the media ecosystem; technology company teams working on misinformation and generative AI labeling; and coalitions/initiatives working on provenance policy. Thus, while the set of terms we investigate is not exhaustive, we aimed to capture a variety of terms that are in current consideration, use, or public conversation when it comes to labeling content that is AI-generated or misleading.  <ref type="table">Table 1</ref>. List of the nine terms that could be used to describe AI-generated content which we examine in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>English</head><p>Participants randomly assigned to a term were first asked "If you saw an image or video online that was labeled &lt;term&gt;, to what extent would the label make you less likely to think that the events shown in the image/video actually occurred?" (Likert scale: 1 -I would definitely NOT think the events occurred to 7 -No effect on what I think about whether the event occurred), where [term] was the term from <ref type="table">Table 1</ref> to which the participant was randomly assigned.</p><p>Next, participants were asked two questions about how that label would make them feel about the image/video and about the person/account posting the content (Likert scale: 1 -Very negative … 4 -Neutral … 7 -Very positive).</p><p>Finally, participants were presented with text descriptions of 20 different kinds of content (each on its own page and in random order), and asked whether they would consider each piece of content to be <ref type="bibr">[term]</ref>. To assess how accurately participants associated each term with content that is produced by generative AI and content that is misleading, we create variability by including types of content that both involved AI and content that did not involve AI (similar for misleadingness): the 20 content descriptions (exactly as they were shown to participants) along with our classification of whether each content type is AI-generated and is misleading, are shown in <ref type="table" target="#tab_2">Table 2</ref>. For maximum clarity, we used text descriptions rather than showing people actual pieces of audio or video, as the provenance of the content is often not obvious just from visual inspection (which is what necessitates labeling to begin with). We selected these content type examples to systematically span a wide range of AI involvement and misleadingness (see the Appendix Section A1 for more information on our motivation for this approach to content type curation. We solicited input on the set of content types from many of the same people/groups who provided suggestions of terms. An overview of our study design is presented in <ref type="figure" target="#fig_14">Figure 1</ref>.</p><p>When evaluating the classification performance of each term, we consider AI-generated content to be: images, video, and art generated from scratch by algorithms; face-swapping; songs that use AI to imitate the voice of a famous singer; chatbot generated infographics; and algorithmically removing content from images (in-painting). Conversely, we consider misleading content to be: images and videos appearing to show events that never actually happened, regardless of the process used to produce them; misleading infographics, regardless of whether they are produced by AI or humans; face-swapping; songs that use AI to imitate the voice of a famous singer; and algorithmically removing an unpopular politician for a political ad (but not strangers from the background of a family photo). The misleading classification is quite distinct from the classification of whether content is generated using AI, as it includes misleading content generated through other means, and does not include AI-generated content that is not misleading (e.g., AI art).</p><p>Our main analyses ask how well each term does from a classification perspective at being selectively associated with (i) content that is generated using AI ( <ref type="table" target="#tab_2">Table 2</ref>, column 2) or (ii) content that is misleading ( <ref type="table" target="#tab_2">Table 2</ref>, column 3).</p><p>For example, optimal performance for a given &lt;term&gt; using the "generated using AI" outcome would be the situation in which all participants selected "yes" when asked if they considered each of the content types that were generated by AI (images, video, and art generated from scratch by algorithms; face-swapping; songs that use AI to imitate the voice of a famous singer; chatbot generated infographics; and algorithmically removing content from images) to be &lt;term&gt;, and selected "no" for all other pieces of content. Put differently, a given participant's responses are turned into an alignment score by determining the fraction of responses that correspond with our specified "correct" responses (given in <ref type="table" target="#tab_2">Table 2</ref> columns 2 and 3 for the two different outcomes). We then calculate average alignment for each term by averaging across the alignment ratings for all participants assigned to that term. Finally, for interpretability, we z-score (standardize) alignment scores within each country -i.e., set mean 0 and standard deviation 1 within each country.</p><p>Content type AI-Generated? Misleading?</p><p>An accurate infographic produced by a person 0 An image that was edited by a photo editing app (like Google Photos or iPhone Photos) to adjust brightness and contrast to make the image look better 0</p><p>A piece of art that was generated by a person drawing on a touchscreen (eg an iPad) with a stylus and using computer software to color, shade, and add final touches to their artwork 0</p><p>A song sung by a famous singer that was edited to adjust the sound quality (e.g. equalization, compression, reverb) to make the recording sound better 0</p><p>A piece of digital art that was created from scratch by a computer algorithm (like Dall-E 2 or Midjourney) in response to a text prompt 0</p><p>A piece of digital art that was created from scratch by a computer algorithm (like Dall-E 2 or Midjourney) through a process in which a person carefully crafted text prompts, fed the prompts to the algorithm and repeatedly tweaked the prompts for several hours until the algorithm produced an image they liked. 0</p><p>An accurate infographic produced by an artificial intelligence (AI) chatbot 0 A image that was edited using an algorithm (like Magic Eraser in Google Photos) to remove strangers accidentally captured in the background of a family photo 0</p><p>An image appearing to show an event that never actually happened, that a person created from an existing image by adding a misleading caption or timestamp 1</p><p>A misleading infographic produced by a person 1 An image appearing to show an event that never actually happened, that a person created by modifying an existing image using a computer program (like Photoshop) 1</p><p>A video appearing to show an event that never actually happened, that a person created from existing footage by cutting/splicing out key piece(s) of the video (eg so that someone's comments appear out of context) 1</p><p>A song that sounds like it is being sung by a famous singer, but was actually written by a different person who then trained a computer algorithm to mimic the singer's voice 1</p><p>An image appearing to show an event that never actually happened, that was created from scratch by a computer algorithm (like Dall-E 2 or Midjourney) in response to a text prompt 1</p><p>A song that sounds like it is being sung by a famous singer, but was actually written by a computer algorithm that mimicked the singer's voice 1</p><p>An image appearing to show an event that never actually happened, that was created from scratch by a computer algorithm (like Dall-E 2 or Midjourney) through a process in which a person carefully crafted text prompts, fed the prompts to the algorithm and repeatedly tweaked the prompts for several hours until the algorithm produced an image they liked. 1</p><p>An image or video in which one person's face was replaced with another person's face using a computer algorithm (like the face swapping effect in Snapchat) 1</p><p>A image that was edited using an algorithm (like Magic Eraser in Google Photos) to remove a now-unpopular politician from a photo to be used for a political ad 1</p><p>A misleading infographic produced by an artificial intelligence (AI) chatbot 1 A video appearing to show an event that never actually happened, that was entirely generated by a computer algorithm (i.e. no original footage existed) 1 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>To compare how well participants' understanding of each term aligned with content that was AI-generated and/or misleading, we aggregate alignment at the term level, and use linear regression with robust standard errors to compute test statistics. We start by presenting the results of the two first research question combining all countries. Except where noted, the results were strikingly similar across the five countries, and thus our main analyses aggregated across countries for clarity and statistical power. We then compare how the aggregate results compared across each country individually. Finally, we look at the subjective perceptions of the labels across countries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Perception alignment</head><p>4.1.1 Alignment of terms with content that is generated using AI. First, to answer Research Question 1, we look at how well does each term perform in terms of alignment between participants' understanding of the term and whether the content was created using generative AI. <ref type="figure" target="#fig_2">Figure 2</ref> shows the mean alignment ratings for each term when identifying content generated using AI (alignment scored as 0 if the participant considered the term as applying to the content and the content was not AI-generated, or if the participant did not consider the term as applying to the content and the content was AI-generated; and scored as 1 if the participant considered the term as applying to the content and the content was AI-generated, or if the participant did not consider the term as applying to the content and the content was not AI-generated). We see substantial variation across terms, with AI Generated, Generated with an AI tool, and AI Manipulated performing much better than the other six terms. In particular, linear regression with robust standard errors predicting z-scored alignment at the participant level using dummies for each term finds that AI-generated, Generated with an AI tool, and AI manipulated were each significantly better than all of the other terms (p&lt;0.001 for all comparisons), and were not significantly different from each other (p&gt;0.4781 for all comparison). Similar results are observed when separately considering specificity versus sensitivity (see Appendix <ref type="figure" target="#fig_1">Figure A3</ref>), and when using a continuous groundtruth measure of the extent to AI vs humans were involved in the creation of the content (see Appendix <ref type="figure" target="#fig_2">Figure A2</ref>). Among other things, these results suggest that the term AI generated has become widely known in the general public, and is as good or better than any of the other terms we tested in terms of being associated with content that is created using generative AI.  <ref type="figure" target="#fig_2">Fig. 2</ref>. The terms AI Generated, Generated with an AI Tool, and AI Manipulated are most consistently associated with content types generated using AI (regardless of misleadingness). Shown is average alignment when identifying whether the content is created via a process involving generative AI, aggregated across all five countries. Perception alignment is calculated for each participant, alignment is z-scored across participant within each country, and mean values for each term are shown. Error bars indicate standard error of the mean. As a robustness check, see <ref type="figure" target="#fig_14">Figures A1</ref> and A2 for the extent to which different participants perceive different content types and terms to exhibit human (AI) involvement, respectively. In general, we observe a similar pattern of results,</p><p>with AI Generated, Generated with an AI tool, and AI Manipulated performing better than the other terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Alignment of terms with content that is misleading.</head><p>Next, to answer Research Question 2, we consider how well participants' understanding of each term aligns with whether each type of content would -if presented without any additional context -be misleading. <ref type="figure" target="#fig_1">Figure 3</ref> shows the mean alignment ratings for each term when identifying misleading content, using an analogous approach to the classification of content generated by AI in <ref type="figure" target="#fig_2">Figure 2</ref>. We once again see considerable variation across terms, but with a strikingly different pattern from Z−scored perception alignment with AI−generated content Z−scored perception alignment with misleading content <ref type="figure">Fig. 4</ref>. Different terms satisfy different labeling goals. Shown is the categorization alignment for each term when identifying content generated by AI (x-axis) versus identifying content that is misleading (y-axis), aggregated across all five countries. Pareto frontier shown in orange.</p><p>misleading content, the terms Deepfake and Manipulated perform substantially better than the other 7 terms. In particular, Deepfake, and Manipulated were significantly better than all of the other terms (p&lt;0.001 for all comparisons), and Deepfake and Manipulated did not significantly differ (p=0.067). Conversely, AI Generated is one of the worst performing terms. As when identifying content generated by AI, these results are equivalent when separately considering sensitivity versus specificity (see Appendix <ref type="figure" target="#fig_1">Figure A3</ref>). <ref type="figure" target="#fig_1">Figures 2 and 3</ref> highlight the fact that different terms are better suited to the two different classification tasks. This should not be surprising, as the 20 pieces of content used in the classification task span the spectrum of content that is AI-generated or not, and misleading or not. We visualize the trade-off across terms in identifying content that is generated using AI versus content that is misleading in <ref type="figure">Figure 4</ref>. While AI Generated performs well for identifying content that is generated using AI but poorly for content that misleading, the opposite is true for Manipulated and Deepfake. Conversely, Synthetic, Artificial, Edited and Not real are strictly dominated by other terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Alignment of terms against combined labeling goals. The divergent results in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Variation in perceptions across content types.</head><p>To dig more deeply into how people are understanding the best performing terms, <ref type="figure" target="#fig_4">Figure 5</ref> shows, for each of the terms near the Pareto frontier, the fraction of people who selected each piece of content (for equivalent plots for all nine terms, see Appendix). One feature that is immediately apparent is that there is a "noise floor" of roughly 20 to 30 percentage points: no piece of content is selected less than roughly 30 percent of the time on average, and no piece of content is selected more than roughly 20 percent of the time on average. These bounds likely reflect some combination of inattention on the part of the participants (which adds random noise but should not affect the relative ranking of the terms) and true confusion about the meaning of the various terms.</p><p>Some of the largest differences across the terms are that AI Generated, Generated with an AI tool, and AI Manipuluated are much more strongly associated with AI Art and the Accurate Infographic Chatbot than Deepfake or Manipulated, whereas the AI-related terms are less associated with videos and images that are misleading due to editing (rather   than being created from scratch by AI). Perhaps most surprisingly, the term Deepfake was associated with misleading content types produced by humans such as videos and images that are misleading due to (non-AI) editing processes.</p><p>Thus, it seems that many people are misunderstanding the term Deepfake and applying to content that a traditional definition would not include (i.e. "cheapfakes") -and this misunderstanding is in fact what makes Deepfake successful at identifying misleading content.</p><p>It is also interesting to note how in-painting (i.e. using magic eraser) scores as an intermediate case between non-AI-generated and clearly AI-generated content. For the terms that explicitly mention AI, the two in-painting content types lie roughly halfway between content that is created by humans without AI assistance and the content that fully AI-generated. These results highlight how the various content types we examine here exist along a continuum, and that ambiguity is reflected in the responses of our participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Moderation by individual differences</head><p>Next, we ask whether the relative performance of different terms varies based on participant characteristics. Specifically, we examine age, gender, education, digital literacy and familiarity with generative AI. For each of these characteristics, we conduct a separate multi-variate regression analysis interacting the z-scored characteristic with each of the label types predicting process <ref type="table">(Table A1</ref>) and misleading (A2) alignment, respectively.</p><p>Looking across the terms, we see many significant interactions between Digital Literacy (for process alignment) and</p><p>Familiarity with Generative AI (for misleading alignment and process alignment). However, examining the means <ref type="figure" target="#fig_7">(Figures A4-7)</ref> shows that the interactions do not lead to meaningful differences in the best aligned terms for each outcome, but rather correspond to overall increases or decreases in the spread in average alignment across terms. Specifically, for participants with high digital literacy, highly aligned terms are even more highly aligned and poorly aligned terms are more poorly aligned. Conversely, for participants with high familiarity with generative AI, highly aligned terms are relatively less aligned and poorly aligned terms are more aligned. Overall, however, the three terms explicitly mentioning AI are best aligned with process, and Deepfake and Manipulated are best aligned with misleadingness across demographic subgroups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Cross-cultural differences in the understandings of the term Artificial</head><p>Overall, in answer to Research Question 4, we saw strikingly similar results from aforementioned analysis across all five countries <ref type="figure" target="#fig_5">(Figures 6 and 7)</ref>. A salient exception as shown in <ref type="figure" target="#fig_5">Figures 6 and 7</ref>, the term Artificial does strikingly poorly in China for both classification tasks. When considering China separately <ref type="figure" target="#fig_8">(Figure 8</ref>), we find that Artificial lies along the Pareto frontier when aggregating across the other four countries. That is, when considering the tradeoff between the objectives of labeling content that is AI generated and misleading, the term Artificial stands out as performing fairly well on both classification tasks outside of China -but is by far the worst performing term in China.</p><p>It is important to note a substantial cross-cultural difference we observed regarding the term Artificial. In particular, Chinese-speaking participants responded to the word "Artificial" (人工) very differently from respondents in the other countries. We speculate that this difference may be due to a subtle but important aspect of the Chinese translation of the term Artificial. "Artificial" can be translated as 人工, or interchangeably 人造 depending on the context. We chose the former as it is used to describe "Artificial Intelligence" (人工智能). While indeed the word 人工 stands in contrast to natural (e.g., artificial sweetener), in China this connotation does not exhibit the same negative connotation of unnatural as in English, and it is much closer to "human-made" (人: human, 工: engineered). Therefore in contrast</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Edited</head><p>Not real Manipulated Deepfake Synthetic Artificial AI manipulated Generated with an AI tool AI generated</p><p>Perception alignment with content that is generated using AI by Country Z−scored Accuracy to terms that stand in for machine-generated, in China the term artificial connotes human involvement rather than automation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Subjective feelings towards and belief of the labels</head><p>Finally, to answer Research Question 3, we consider participants' subjective perception of each term when used as a label. In particular, we examine participants' self-report regarding how seeing a label with the given term applied to a piece of content would (i) affect their feelings towards the content and the person/account who shared and (ii) affect their belief that the events depicted actually occurred. Although these self-report measures may be subject to various   For these subjective measures, we find significant differences in the average response across countries (collapsing across terms, we find p&lt;.001 for both subjective measures varying across country using ANOVA). When visualizing responses to the subjective measures for each country separately <ref type="figure" target="#fig_9">(Figure 9)</ref>, we see striking level differences across the countries. In particular, response values for both items were substantially higher among participants from China Be that as it may, across all countries, the terms Deepfake, Manipulated, and Not real were (i) seen much more negatively than the other terms, and (ii) were expected to lead to much lower belief that the depicted events actually occurred. That is, the labels which lead to greater anticipated reduction in belief were also perceived more negatively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION, LIMITATIONS, AND FUTURE WORK</head><p>Here we have identified labels that are widely understood by the public across five countries as matching two different labeling goals. In answer to our first research question, we found that AI generated, Generated with an AI tool, and AI Manipulated are the terms that participants most consistently associated with content that was generated using AI. However, if the goal is to identify content that is misleading (e.g., our second research question), these terms perform quite poorly. Instead, Deepfake and Manipulated are the terms most consistently associated with content that is potentially misleading. The differences between AI Manipulated and Manipulated are quite striking: simply adding the "AI" qualifier dramatically changed which pieces of content participants understood the term as applying it. This demonstrates our participants' sensitivity to -and in general correct understanding of -the phrase "AI. "</p><p>In answer to our forth research question, it is important from a generalizability perspective, as well as a practical perspective, that our findings appeared to be fairly consistent across our samples recruited from the United States, Mexico, Brazil, India, and China. Given the global nature of technology companies (and the global impact of generative AI), it is imperative that any labeling scheme ensure that the label is interpreted in a consistent manner around the world. One interesting cross-cultural difference that did arise involved the term Artificial, which carried different connotations in China compared to the other four countries. Thus, while Artificial performed very poorly in China, it represented a promising compromise candidate that performed reasonably well at both classification tasks in the other four countries. Furthermore, the divergent interpretation of the term "artificial" within China may have important implications for the perceptions and governance of AI systems more broadly.</p><p>Interestingly, we observed that while the term Deepfake was quite effective at identifying misleading content, it performed poorly for identifying AI-generated content. This is surprising because the term is a portmanteau of "deep learning" and "fake, " and thus corresponds to fake content that is generated with AI methods. This suggests that the term Deepfake is not widely understood, and that people think it just means fake.</p><p>Should one choose an objective and select a term to use for labeling accordingly, numerous challenges still remain for labeling to be effective. First, there is the fundamental issue of determining what content to apply the label to.</p><p>Self-disclosure is one approach that is easy to implement but is vulnerable to bad actors. If one's concern is the use of generative AI for deceit, it seems exceedingly unlikely that people who are trying to deceive will opt in to selfdisclosure. Methods for detecting synthetic media via machine learning <ref type="bibr" target="#b14">[14]</ref>, crowdsourcing <ref type="bibr" target="#b14">[14]</ref>, and digital forensics <ref type="bibr" target="#b8">[8]</ref> offer possibilities for active classification, although as generative AI technology continues to advance, it will likely get harder and harder to detect generated content. More generally, the question of who gets to decide what content gets to count as AI-generated is central, and for labels to be effective, it is critical for the process to be percieved as legitmate <ref type="bibr" target="#b22">[22]</ref>.</p><p>Second, there is the question of what inferences users will draw regarding content that is not labeled. In the context of veracity labels on news articles, an "Implied Truth" effect has been identified, whereby applying false labels to some content increases belief in unlabeled content -an effect that is consistent with Bayesian reasoning, rather than being an irrational bias <ref type="bibr" target="#b24">[24]</ref>. It seems likely that an analogous "Implied Authenticity" effect may occur when labeling AIgenerated content, such unlabeled content is perceived as more authentic. It is important to bear this possibility in mind -and evaluate it empirically -when deciding what to label.</p><p>Finally, there is the user interface design question of how to visually present the labels. It is important for future work to examine different design approaches to how the labels look and interact with context to maximize their effectiveness.</p><p>Of course, it is important to note that we focused entirely on terms to describe AI-generated content in the context of images and video. While many of the terms we consider would likely generalize well to AI-generated text, some likely would not (e.g. Deepfake, as it refers to a very specific use case of generative AI). Future work should conduct a similar investigation to what we have done here in the context of AI-generated and/or misleading text. Future work should also conduct experiments in which participants are randomized to see a label versus no label on actual pieces of content, to determine the causal effect of any given label on belief in, attitudes regarding, and behaviors taken towards the depicted content. In addition, we acknowledge that there are many ways that these terms could be translated into different languages, and future work is needed to see how subtle differences in translations impact these results.</p><p>In sum, an essential first question that must be answered before developing labels for AI-generated content is what term(s) should be used for such labels. In this work, we provide a first step towards answering that question.  <ref type="figure" target="#fig_14">Fig. A1</ref>. Continuous user-based categorization of each content type being AI generated, computed based on the difference in average response to the questions "How much was AI involved in the creation of this content?" and "How much was a human involved in the creation of this content?" in the robustness check sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>Gen. w/ an AI tool AI generated AI manipulated Synthetic Artificial Not real Deepfake Manipulated Edited</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alignment with continuous AI-generated content score across terms by Country</head><p>Correlation between continuous AI-generated content score and fraction of participants who consider &lt;content type&gt; to be &lt;term&gt;  . Correlation between continuous AI-generated scores for each content type and the fraction of participants who considered that content type to be a given term. For each individual country, the correlation is computed within country separately. For overall, the correlation is computed across all countries. If you give us permission by completing the survey, we plan to discuss/publish the results in an academic forum. In any publication, information will be provided in such a way that you cannot be identified. Only members of the research team will have access to the original data set. Before the data is shared outside the research team, any potentially identifying information will be removed. Once identifying data has been removed, the data may be used by the research team, or shared with other researchers, for both related and unrelated research purposes in the future. Your anonymized data may also be made available in online data repositories such as the Open Science Framework, which allow other researchers and interested parties to use the data for further analysis. nfc I would rather do something that requires little thought than something that is sure to challenge my thinking abilities.</p><p>1 -Very untrue (1) 2 (2) 3 (3) 4 (4) 5 -Very true <ref type="bibr" target="#b5">(5)</ref> Edu Highest level of education completed?</p><p>None (1) Less than secondary school degree (2) Less than high school degree (3) High school diploma (4) Attended College (5) Bachelor's degree (6) Graduate degree <ref type="formula">7</ref>Income Think of this ladder as representing where people stand in your country. At the top of the ladder are the people who are the best offthose who have the most money, the most education and the most respected jobs. At the bottom are the people who are the worst offwho have the least money, least education, and the least respected jobs or no job. The higher up you are on this ladder, the closer you are to the people at the very top; the lower you are, the closer you are to the people at the very bottom.</p><p>Where would you place yourself on this ladder?</p><p>1 -Bottom <ref type="formula">1</ref> QRCode Which of the following best describes what a "QR Code" is?</p><p>A junk message sent to lots of people on the internet (1) An image made up of squares that can be scanned (2) A four number code that makes my device more secure (3) A website that can be edited by a group of people (4) A programming language for web pages (5) None of the above <ref type="bibr" target="#b6">(6)</ref> download Which of the following best describes what "download" means?</p><p>A way to change who can see the content I post online (1) A way to send something from my phone to somewhere else (2) A way to put or save new things on my phone (3) A way to search for information (like news) on the internet (4) A way to create something new from existing images (5) None of the above <ref type="bibr" target="#b6">(6)</ref> tag Which of the following best describes what "tag" means in the context of social media?</p><p>A piece of information that circulates rapidly on the internet (1) An image with text on it that describes a joke or idea (2) A way to mention a specific individual, business, or account (3) A sequence of instructions telling a computer what to do (4) A file that looks like a printed document or image (5) None of the above <ref type="bibr" target="#b6">(6)</ref> securepswd Which of the following four passwords is the most secure?</p><p>WTh@5Z (1) Boat1234 (2) intro*48 (3) 123456 (4) AID_Inst In the following section, you will be asked several questions about recent developments in artificial intelligence (AI).</p><p>genai_fam Recently, there have been major advances in using artificial intelligence (AI) across a wide range of important tasks. Some examples of these advancements are ChatGPT, which can produce text responses to human questions, and Stable Diffusion, which can generate images from prompts. How much, if anything, have you heard or read about recent advancements in AI such as ChatGPT and Stable Diffusion?</p><p>1 -Nothing at all (1) 2 (2) 3 (3) 4 -A little (4) 5 (5) 6 (6) 7 -A lot <ref type="bibr" target="#b7">(7)</ref> genai_use How often have you used recent AI tools and services such as ChatGPT and Stable Diffusion? Other examples are Midjourney, AlphaCode, GitHub Copilot, and Bard.</p><p>1 -I have never used any of these kinds of AI tools (1) 2 (2) 3 (3) 4 -I have used these AI tools a moderate amount (4) 5 (5) 6 (6) 7 -I use these kinds of AI tools every day <ref type="formula">7</ref>P1 Please continue to the next part of the study. AI_involvement [visible if term is 'calibration'] How much was AI involved in the creation of this content?</p><p>1 -No AI involvement whatsoever (1) 2 (2) 3 (3) 4 (4) 5 (5) 6 (6) 7 -Completely AI created <ref type="bibr" target="#b7">(7)</ref> screener1b People are very busy these days and many do not have time to follow what goes on in the government. We are testing whether people read questions. To show that you've read this much, answer both "extremely interested" and "very interested":</p><p>Not at all interested (1) Slightly interested (2) Moderately interested (3) Very interested (4) Extremely interested <ref type="bibr" target="#b5">(5)</ref> Comments Do you have any comments about our survey (optional)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. A9. Codebook</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>The terms Deepfake and Manipulated are most consistently associated with content types that are misleading (regardless of whether they were generated using AI). Shown in average alignment for identifying whether the content is misleading if presented without context, aggregated across all five countries. alignment alignment is calculated for each participant, z-scored across participants within each country, and mean values for each term are shown. Error bars indicate standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fraction of participants who consider &lt;content type&gt; to be &lt;term&gt;</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>For each content type (columns), fraction of participants who consider that content type to be a given term (rows). Aggregated across all five countries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Alignment for identifying whether the content is created via a process involving generative AI for each country. Perception alignment is calculated for each participant, z-scored across participant, and mean values for each term are shown. Error bars indicate standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Alignment for identifying whether the content is misleading for each country. Perception alignment is calculated for each participant, z-scored across participant, and mean values for each term are shown. Error bars indicate standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Trade-off in categorization alignment across terms for identifying content generated by AI versus content that is misleading, for USA/India/Mexico/Brazil (left) and China (right). Pareto frontier shown in orange.biases, and may not necessarily accurately reflect actual behavior, they provide some insight into how participants perceive the terms when used as labels (if not necessarily the actual effects of such labels).To measure negative versus positive feelings towards the content and its poster, we used two 7-point Likert scales (one asking about the content, the other about the poster) that had Very Negative as the low anchor, Neutral as the central anchor, and Very Positive as the high anchor. As the two measures were highly correlated with each other (r=0.801), we average them to create a single scale. Note that values below 4 indicate negative perception while values above 5 indicate positive perception. To measure the anticipated effect on belief in the depicted events, we used a single 7-point Likert scale that had "I would definitely NOT think the events occurred" as the low anchor and "No effect on what I think about whether the event occurred" as the high anchor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Subjective perception of the label's impact on belief that the depicted event occurred (x-axis) and subject perception of how the label would make the participant about the content and its poster (y-axis), separately for China, India, USA, Brazil &amp; Mexico. Note that y-axis values below 4 indicate negative perception while values above 5 indicate positive perception; and lower x-axis values indicate a greater expected decrease in perception as a result of seeing the label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. A2</head><label></label><figDesc>Fig. A2. Correlation between continuous AI-generated scores for each content type and the fraction of participants who considered that content type to be a given term. For each individual country, the correlation is computed within country separately. For overall, the correlation is computed across all countries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Clicking on the arrow at the bottom of this page indicates that you are at least 18 years of age and agree to complete this survey voluntarily. Filter1 [exclude if incorrect] Please enter the number you see in the image above (use numerical digits). SocialMedia What type of social media accounts do you use (if any)? Facebook (1) Twitter (2) Snapchat (3) Instagram (4) WhatsApp (5) Tiktok (6) Other (please specify) (98) None (99) SharingType Which of these types of content would you consider sharing on social media (if any)? Political news (1) Sports news (2) Celebrity news (3) Science/technology news (4) Business news (5) Other (please specify) (98) None (99) SocialMediaUse About how often do you access social media services (Facebook, Twitter, Instagram, Pinterest, YouTube, etc.)? Several times a day (1) About once a day (2) Several times a week (3) About once a week (4) A few times a month (5) Never (6) Filter2 [exclude if incorrect] Help us keep track of who is paying attention, please select -"Somewhat disagree" in the options below. Strongly agree (1) Agree (2) Somewhat agree (3) Neither agree nor disagree (4) Somewhat disagree (5) Disagree (6) Strongly disagree (7)grid When deciding whether to share a piece of content on social media, how important is it to you that the content is...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>2 (2) 3 (3) 4 (4) 5 (5) 6 (6) 7 (7) 8 (8) 9 (9) 10 -Top (10) fbDec How are the decisions about what stories to show people on Facebook made? At random (1) By editors and journalists that work for news outlets (2) By editors and journalists that work for Facebook (3) By computer analysis of what stories might interest you (4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>1 -</head><label>1</label><figDesc>events_occur [visible if term is not 'calibration'] If you saw an image or video online that was labeled[term]: * To what extent would the label make you less likely to think that the events shown in the image/video actually occurred?1 -I would definitely NOT think the events occurred(1) 2 (2)3 (3) 4 (4) 5 (5) 6 (6) 7 -No effect on what I think about whether the event occurred (7) feeling [visible if term is not 'calibration'] * How would it make you feel about the image/video? 1 -Very negative (1) 2 (2) 3 (3) 4 -Neutral (4) 5 (5) 6 (6) 7 -Very positive (7) feeling_post [visible if term is not 'calibration'] * How would it make you feel about the person/account who posted the image/video? 1 -Very negative (1) 2 (2) 3 (3) 4 -Neutral (4) 5 (5) 6 (6) 7 -Very positive (7) P2 [visible if term is not 'calibration'] For this final part, you will be presented with a list of different kinds of content you might see on social media. For each piece of content, we would like to know if you would consider it to be [term]. P2b [visible if term is 'calibration'] For this final part, you will be presented with a list of different kinds of content you might see on social media. For each piece of content, we would like to know how much a human / AI was involved in the creation of this content. F [term] T [visible if term is not 'calibration'] Would you consider this content to be [term]? No (0) Yes (1) human_involvement [visible if term is 'calibration'] How much was a human involved in the creation of this content? No human involvement whatsoever (1) 2 (2) 3 (3) 4 (4) 5 (5) 6 (6) 7 -Completely human created (7)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>continue; and 13 participants dropped out during the survey. This left us with an effective sample of 1,018 Chinese participants (mean age = 42.5, 48.2% female).</figDesc><table><row><cell cols="2">3.2 Materials &amp; Procedure</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Participants first completed two trivial attention screeners, demographics, and measures of digital literacy (five multiple</cell></row><row><cell cols="6">choice questions; scored as number of correct answers) [16, 34] and familiarity with generative AI (two seven-point</cell></row><row><cell cols="6">Likert scales asking about how much the participant has heard/read about, and used, generative AI). Participants who</cell></row><row><cell cols="6">failed either attention check were not permitted to continue with the survey. Participants were also shown a more</cell></row><row><cell cols="6">difficult attention check later in the study, and were allowed to proceed if they failed. To preserve representativeness,</cell></row><row><cell cols="6">Samples were recruited in August and September 2023 through Lucid Marketplace using country-specific representa-</cell></row><row><cell cols="6">tive quotas on age and gender (for the U.S. sample, the sample was also quota-matched on ethnicity and geographic</cell></row><row><cell cols="6">region). For the U.S sample, 1,310 unique participants entered the survey; 254 failed trivial attention checks at the study</cell></row><row><cell cols="6">outset and were not permitted to continue; and 32 dropped out prior to reaching the relevant section of the survey.</cell></row><row><cell cols="6">This left us with an effective sample of 1,024 U.S. participants (mean age = 47.3, 50.8% female). For the Brazil sample,</cell></row><row><cell cols="6">1,308 unique participants entered the survey; 243 failed trivial attention checks at the study outset and were not per-</cell></row><row><cell cols="6">mitted to continue; and 36 participants dropped out during the survey. This left us with an effective sample of 1,029</cell></row><row><cell cols="6">Brazilian participants (mean age = 42.3, 49.1% female). For the Mexico sample, 1,502 unique participants entered the</cell></row><row><cell cols="6">survey; 442 failed trivial attention checks at the study outset and were not permitted to continue; and 22 participants</cell></row><row><cell cols="6">dropped out during the survey. This left us with en effective sample of 1,038 Mexican participants (mean age = 39.1,</cell></row><row><cell cols="6">51.9% female). For the India sample, 1,514 unique participants entered the survey; 476 failed trivial attention checks</cell></row><row><cell cols="6">at the study outset and were not permitted to continue; and 17 participants dropped out during the survey. This left</cell></row><row><cell cols="6">us with an effective sample of 1,021 Indian participants (mean age = 37.7, 48.9% female). For the China sample, 1,149</cell></row><row><cell cols="6">unique participants entered the survey; 118 failed trivial attention checks at the study outset and were not permitted</cell></row><row><cell></cell><cell>AI generated</cell><cell></cell><cell></cell><cell>Would you consider...</cell><cell>x20</cell></row><row><cell>Participants N=1024 (USA) N=1029 (Brazil) N=1038 (Mexico) N=1021 (India) N=1018 (China)</cell><cell>Generated with an AI tool Artificial Synthetic Deepfake Manipulated Not Real AI Manipulated Edited Randomized conditions</cell><cell>Age Gender Education Digital Literacy Fam. w/ GenAI etc Pre-experiment Questionaire</cell><cell>Subjective questions about &lt;term&gt; Feeling towards content/poster Belief depicted events occured Initial Term Questionaire</cell><cell>An image or video in which one person's face was replaced with another person's face using a computer algorithm (like the face swapping effect in Snapchat) An image or video in which one person's face was replaced with another person's face using a computer algorithm (like the face swapping effect in Snapchat) ...to be &lt;term&gt;?</cell></row><row><cell></cell><cell>for 9 terms</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Alignment task (repeated for 20 content types)</cell></row><row><cell cols="6">Fig. 1. Survey flow. Participants are randomly assigned to a term, and asked if that term would be used to describe 20 different types</cell></row><row><cell>of content.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>toour analyses do not filter on this harder attention check, but the results are qualitatively similar when screening on attention.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>List of Content and Classification Scorings</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>and India, intermediate among participants from Brazil, and lowest among participants from the US and Mexico. It is unclear if this level difference across countries is due to different baseline attitudes towards AI/technology across cultures, different levels of overall response bias/scale use, or some other factor(s). Future work should investigate these differences more precisely.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Fig. A6. Identifying content that is generated by AI (left) and misleading (right) by education, aggregated across all five countries using regression coefficients from Tables A1 and A2.Fig. A8. Identifying content that is generated by AI (left) and misleading (right) by familiarity with generative AI, aggregated across all five countries using regression coefficients from Tables A1 and A2. Please only continue if you are interested in completing a 15 minute survey. Thanks! Consent This survey is part of a MIT scientific research project. Your decision to complete this survey is voluntary.</figDesc><table><row><cell></cell><cell></cell><cell cols="26">Moderator Moderator Classifying Content Generated Using AI by Gender Age Age Gender Education Digital Literacy Fam. w/ GenAI Gender Education Digital Literacy Fam. w/ GenAI Classifying Misleading Content by Gender</cell></row><row><cell></cell><cell>0.80 0.75</cell><cell cols="6">moderator AI Manipulated Artificial moderator 0.6 AI Manipulated Artificial Gen. w/ an AI tool AI generated AI manipulated AI manipulated Artificial Deepfake 0.3 Edited Gen. w/ an AI tool Manipulated Not real Synthetic AI Generated</cell><cell></cell><cell></cell><cell cols="12">-0.006 (0.006) -0.006 ( 0.009) -0.059  *  *  *  -0.054  *  *  *  -0.059  *  *  *  -0.014 0.003 (0.012) ( 0.006) 0.001 -0.007 (0.012) (0.009) -0.009 -0.003 0.016  *  *  0.6 (0.012) (0.006) (0.006) 0.011  *  0.02 0.019  *  (0.012) (0.009) (0.009) 0.054  *  *  *  0.045  *  *  *  0.055  *  *  *  0.001 ( 0.006) 0.02  *  ( 0.009) 0.055  *  *  *  AI manipulated 0.80 Artificial Deepfake Deepfake Gen. w/ an AI tool AI generated Edited Gen. w/ an AI tool Manipulated 0.75 Not real 0.3 Synthetic AI manipulated Manipulated AI Generated</cell><cell cols="4">0.062  *  *  *  ( 0.006) -0.010 ( 0.008) -0.060  *  *  *  0.013  *  (0.006 ) 0.021  *  (0.009 ) 0.056  *  *  *</cell><cell></cell><cell>-0.008 (0.006) -0.005 (0.009) -0.058  *  *  *  Manipulated Deepfake</cell></row><row><cell>Process alignment</cell><cell>0.55 0.60 0.70 0.65</cell><cell cols="6">Deepfake Edited Gen w/ AI Tool Manipulated Deepfake Edited Gen w/ AI Tool Manipulated Manipulated Not real −0.3 Deepfake Synthetic Artificial 0.0 Z−scored Accuracy</cell><cell></cell><cell></cell><cell cols="16">(0.009) -0.097  *  *  *  -0.099  *  *  *  -0.097  *  *  (0.012 ) (0.009) (0.101) 0.012 ) (0.008) -0.097  *  *  *  -0.134  *  *  *  -0.119  *  *  *  (0.064) (0.063) (0.009) -0.004 -0.008 -0.004 ( 0.009) (0.012) (0.009) -0.095  *  *  *  -0.108  *  *  *  -0.095  *  *  *  (0.013) (0.009) (0.009) 0.123  *  *  *  0.125  *  *  *  0.123  *  *  *  ( 0.009) 0.12  *  *  *  ( 0.009) (0.012) (0.009) (0.009) 0.043  *  *  *  0.043  *  *  0.042  *  *  *  0.041  *  *  *  ( 0.009) (0.013) (0.009) (0.009) 00.001 0 0.001 0 ( 0.009) (0.012) (0.009) (0.009) 0.104  *  *  *  0.089  *  *  *  0.104  *  *  *  0.103  *  *  *  Edited Deepfake AI generated 0.55 Gen. w/ an AI tool ( 0.008) -0.100  *  ( 0.008) -0.122  *  *  *  ( 0.008) -0.006 (0.008) -0.098  *  *  *  (0.009 ) 0.124  *  *  *  (0.009 ) 0.042  *  *  *  (0.009 ) (0.009 ) 0.106  *  *  *  −0.3 Not real AI manipulated 0.001 Manipulated Synthetic Artificial Edited Not real Synthetic Artificial 0.0 0.60 0.70 Z−scored Accuracy 0.65 Misleading alignment</cell><cell></cell><cell>(0.009) -0.098  *  *  *  (0.008) -0.120  *  *  *  (0.009) -0.004 (0.009) -0.095  *  *  *  Gen. w/ an AI tool AI generated Edited Not real Synthetic Artificial AI manipulated</cell></row><row><cell></cell><cell>0.50</cell><cell cols="8">Not Real Synthetic Edited −0.6 Not Real Synthetic Male −1.5 −1.0 −0.5 Digital Literacy (z−scored) 0.0 0.5</cell><cell cols="16">(0.009) -0.103  *  *  *  -0.108  *  *  *  -0.103  *  *  *  (0.012) (0.009) (0.008) (0.012) (0.008) -0.065  *  *  *  -0.060  *  *  *  -0.065  *  *  *  ( 0.008) (0.012) (0.008) (0.012) (0.009) (0.009) 0.067  *  *  *  0.063  *  *  *  0.067  *  *  *  ( 0.009) 0.066  *  *  *  ( 0.009) (0.012) (0.009) (0.009) −0.6 0.50 0.045  *  *  *  0.05  *  *  *  0.045  *  *  *  0.043  *  *  *  Female Male 1.0 1.5 −1.5 −1.0 −0.5 ( 0.009) (0.012) (0.009) (0.009) Gender Digital Literacy (z−scored) (0.008) -0.106  *  *  *  (0.008) -0.068  *  *  *  (0.008) (0.009 ) 0.067  *  *  *  (0.009 ) 0.0 0.5 0.045  *  *  *  (0.009 ) Gender</cell><cell>1.0</cell><cell>( 0.009 ) -0.104  *  *  *  (0.008) -0.065  *  *  *  (0.008) 1.5</cell><cell>Female</cell></row><row><cell cols="28">AI Manipulated × moderator Artificial × moderator AI Manipulated × moderator 0.002 ( 0.009) Fig. A5. Identifying content that is generated by AI (left) and misleading (right) by gender. 0.013 -0.016 -0.010 -0.015 . -0.012 ( 0.009) (0.017) ( 0.008) (0.008) (0.009) 0.014 . -0.006 -0.020  *  -0.033  *  *  *  0.001 0.018 -0.003 0.003 -0.024  *  *  (0.018) (0.009) (0.008) Fig. A7. Identifying content that is generated by AI (left) and misleading (right) by digital literacy, aggregated across all five countries (0.009 ) Artificial × moderator 0.018  *  0.019 -0.006 0.003 -0.034  *  *  *  using regression coefficients from Tables A1 and A2.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">( 0.009)</cell><cell cols="2">(0.008) (0.018)</cell><cell cols="3">(0.017) (0.009)</cell><cell cols="4">( 0.008) (0.009)</cell><cell cols="2">(0.008)</cell><cell cols="2">(0.009 )</cell><cell></cell><cell>(0.008)</cell></row><row><cell></cell><cell></cell><cell cols="8">Deepfake × moderator Deepfake × moderator</cell><cell cols="2">0.014</cell><cell></cell><cell cols="2">0.010 -0.004</cell><cell cols="2">0.003 0</cell><cell></cell><cell cols="4">-0.005 0.037  *  *  *</cell><cell cols="5">-0.054  *  *  *  -0.032  *  *  *</cell><cell>0.004</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">( 0.009)</cell><cell cols="2">(0.008) (0.018)</cell><cell cols="3">(0.017) (0.009)</cell><cell cols="4">( 0.008) (0.008)</cell><cell cols="2">( 0.008)</cell><cell cols="2">(0.009 )</cell><cell></cell><cell>(0.009)</cell></row><row><cell></cell><cell></cell><cell cols="7">Edited × moderator Edited × moderator</cell><cell></cell><cell cols="2">0.001</cell><cell></cell><cell cols="2">0.001 0.001</cell><cell cols="3">0.028 -0.006</cell><cell cols="3">-0.006 0.005</cell><cell></cell><cell cols="4">-0.064  *  *  *  -0.03  *  *</cell><cell></cell><cell>0.008</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">( 0.009)</cell><cell cols="2">(0.009) (0.018)</cell><cell cols="3">(0.017) (0.009)</cell><cell cols="4">(0.009) (0.009)</cell><cell cols="2">(0.008)</cell><cell cols="2">(0.009 )</cell><cell></cell><cell>(0.009)</cell></row><row><cell></cell><cell></cell><cell cols="13">Gen. w/ an AI tool × moderator 0.006 Gen. w/ an AI tool × moderator 0.002 0.001</cell><cell cols="3">0.009 -0.005</cell><cell cols="3">-0.007 -0.002</cell><cell></cell><cell cols="2">-0.017  *</cell><cell cols="2">-0.014</cell><cell></cell><cell>0.002</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">( 0.009)</cell><cell cols="2">( 0.009 ) (0.018)</cell><cell cols="3">(0.017) (0.009)</cell><cell cols="4">( 0.009) (0.009)</cell><cell cols="2">(0.008)</cell><cell cols="2">(0.009 )</cell><cell></cell><cell>(0.009 )</cell></row><row><cell>Process alignment</cell><cell>0.80 0.75 0.60 0.65 0.70</cell><cell cols="26">Manipulated × moderator Not real × moderator Synthetic × moderator Intercept Table A1. Regression analysis predicting process alignment from z-scored moderating variables and labels 0.014 0.027 -0.007 -0.052  *  *  *  -0.001 (0.008) (0.017) ( 0.009) (0.008) (0.009) 0.011 0.009 0.003 -0.040  *  *  *  0.003 (0.008) (0.017) ( 0.009) (0.008) (0.009) 0.022  *  *  -0.011 -0.001 -0.034  *  *  *  -0.003 (0.009) (0.017) ( 0.008) (0.008) (0.008) 0.663  *  *  *  0.669  *  *  *  0.662  *  *  *  0.665  *  *  *  0.663  *  *  *  (0.006) (0.008) (0.006) (0.0006) (0.006) Manipulated × moderator 0.001 0.032 . -0.007 0.033  *  *  *  -0.04  *  *  *  ( 0.009) (0.018) (0.009) (0.009) 0.80 AI manipulated Artificial 0.80 AI manipulated Artificial AI manipulated Artificial 0.80 AI manipulated Artificial (0.009 ) Not real × moderator 0.014 . 0.009 0.019 . 0.022  *  Deepfake Edited Deepfake Edited Deepfake Edited Deepfake Edited -0.034  *  *  *  ( 0.009) (0.018) (0.009) (0.009) (0.009 ) Synthetic × moderator 0.026  *  *  -0.011 0.003 0.016 . 0.75 Gen. w/ an AI tool Manipulated Not real Synthetic 0.75 Gen. w/ an AI tool Manipulated Not real Synthetic Gen. w/ an AI tool Manipulated Not real Synthetic Gen. w/ an AI tool Manipulated 0.75 Not real Synthetic -0.023  *  *  ( 0.009) (0.018) (0.009) (0.009) Intercept 0.562  *  *  *  0.566  *  *  *  0.562  *  *  *  0.563  *  *  *  0.562  *  *  *  ( 0.006) (0.009) (0.006) (0.006) (0.006 ) Table A2. Regression analysis predicting misleading alignment from z-scored moderating variables and labels 0.60 0.65 0.70 Process alignment 0.60 0.60 0.65 0.70 0.65 Misleading alignment Misleading alignment 0.70 (0.009 ) AI Generated AI Generated AI Generated AI Generated</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Process Term Identification</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Misleading Identification</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.55</cell><cell></cell><cell></cell><cell>0.55</cell><cell></cell><cell></cell><cell></cell><cell cols="4">Gen. w/ an AI tool</cell><cell></cell><cell></cell><cell></cell><cell>0.55</cell><cell></cell><cell></cell><cell>0.55</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Deepfake</cell></row><row><cell></cell><cell>0.80</cell><cell></cell><cell cols="2">AI manipulated Artificial</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">AI generated</cell><cell>0.80</cell><cell></cell><cell cols="3">0.7 AI manipulated Artificial</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Manipulated</cell></row><row><cell></cell><cell>0.50</cell><cell></cell><cell cols="2">Deepfake Edited 0.50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">AI manipulated</cell><cell>0.50</cell><cell></cell><cell cols="2">Deepfake Edited 0.50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.75</cell><cell>−1.5</cell><cell cols="2">0.55 Gen. w/ an AI tool Manipulated Not real −1.5 −1.0</cell><cell>−0.5</cell><cell>−1.0</cell><cell>0.0</cell><cell>−0.5</cell><cell>0.5</cell><cell>0.0</cell><cell>1.0</cell><cell>0.5</cell><cell>1.5</cell><cell>1.0</cell><cell>0.75 1.5</cell><cell>−1.5</cell><cell cols="3">Gen. w/ an AI tool Manipulated Not real −1.5 −1.0</cell><cell>−0.5</cell><cell>−1.0</cell><cell>0.0</cell><cell>−0.5</cell><cell>0.5</cell><cell>0.0</cell><cell>1.0</cell><cell>0.5</cell><cell>1.5</cell><cell>1.0</cell><cell>1.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Synthetic AI Generated</cell><cell cols="7">Education (z−scored) Fam. w GenAI (z−scored)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Synthetic AI Generated</cell><cell></cell><cell cols="7">Education (z−scored) Fam. w GenAI (z−scored)</cell></row><row><cell>Process alignment</cell><cell>0.60 0.70 0.65</cell><cell></cell><cell>True Negative Rate</cell><cell>0.50</cell><cell></cell><cell></cell><cell cols="4">Deepfake Synthetic Artificial</cell><cell></cell><cell></cell><cell></cell><cell>Misleading alignment</cell><cell cols="2">0.57 0.60 0.63 0.66 Accuracy 0.60 0.70 0.65</cell><cell>True Negative Rate</cell><cell>0.5 0.6</cell><cell></cell><cell></cell><cell cols="3">Edited Synthetic Artificial</cell><cell></cell><cell cols="2">Not real</cell><cell>Accuracy 0.60 0.64 0.68</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Manipulated</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.45</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.55</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Not real</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.55</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">AI manipulated</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.50</cell><cell></cell><cell></cell><cell>0.40</cell><cell>Edited</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.50</cell><cell></cell><cell></cell><cell>0.4</cell><cell cols="4">Gen. w/ an AI tool AI generated</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>−1.5</cell><cell></cell><cell>−1.0</cell><cell>−0.5</cell><cell></cell><cell>0.0</cell><cell></cell><cell>0.5</cell><cell></cell><cell>1.0</cell><cell></cell><cell>1.5</cell><cell></cell><cell></cell><cell>−1.5</cell><cell></cell><cell>−1.0</cell><cell></cell><cell>−0.5</cell><cell></cell><cell>0.0</cell><cell></cell><cell>0.5</cell><cell></cell><cell>1.0</cell><cell>1.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.600</cell><cell>0.625</cell><cell></cell><cell cols="2">0.650</cell><cell></cell><cell>0.675</cell><cell></cell><cell cols="2">0.700</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.60</cell><cell></cell><cell>0.65</cell><cell cols="2">0.70</cell><cell cols="2">0.75</cell><cell>0.80</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">True Positive Rate Age (z−scored)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">True Positive Rate Age (z−scored)</cell><cell></cell></row></table><note>Fig. A3. True positive and true negative rates for identifying content created through the process of AI generation term alignment (left) and for identifying content that is misleading (right).Fig. A4. Identifying content that is generated by AI (left) and misleading (right) by age, aggregated across all five countries using regression coefficients from Tables A1 and A2.warning This survey is expected to last 15 minutes.</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1 PARETO FRONTIERS BY CONTENT CATEGORY</head><p>The results we obtain are dependent on the curation of the 20 content types we used, and the corresponding ground truth labels for process and misleading for those content types. Because both accuracy and misleading alignment are computed from the same participant response ("Would you consider &lt;content_type&gt; to be &lt;term&gt;?"), one would expect to a priori find divergence between accuracy and misleading alignment for content with divergent ground- </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Remarks by President Biden and Vice President Harris on the Administration&apos;s Commitment to Advancing the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. The White House</title>
		<ptr target="https://www.whitehouse.gov/briefing-room/speeches-remarks/2023/10/30/remarks-by-president-biden-and-vice-president-harris-on-the-administrations-commitment-to-advancing-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Bartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krystal</forename><surname>Hu</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>n. d.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">others pledge to watermark AI content for safety, White House says. Reuters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Openai</surname></persName>
		</author>
		<ptr target="https://www.reuters.com/technology/openai-google-others-pledge-watermark-ai-content-safety-white-house-2023-07-21/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Real solutions for fake news? Measuring the effectiveness of general warnings and fact-check tags in reducing belief in false stories on social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spencer</forename><surname>Blair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">A</forename><surname>Busam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Forstner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Glance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Kawata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akhila</forename><surname>Kovvuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political behavior</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1073" to="1095" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Moral crumple zones: Cautionary tales in human-robot interaction (pre-print</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeleine</forename><forename type="middle">Clare</forename><surname>Elish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Engaging Science, Technology, and Society</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>pre-print</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Do explanations increase the effectiveness of AI-crowd generated fake news warnings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolo</forename><surname>Foppiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophie</forename><surname>Hilgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjana</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International AAAI Conference on Web and Social Media</title>
		<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="183" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Art and the science of generative AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Investigators Of Human</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Memo</forename><surname>Creativity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Akten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Farid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fjeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">380</biblScope>
			<biblScope unit="page" from="1110" to="1111" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Who gets credit for AI-generated art?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sydney</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iyad</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rahwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iscience</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Creating, using, misusing, and detecting deep fakes</title>
		<idno>Hany Farid. 2022</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Online Trust and Safety</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Falling for fake news: investigating the consumption of news via social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Flintham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Karner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khaled</forename><surname>Bachour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Creswick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neha</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Moran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI conference on human factors in computing systems</title>
		<meeting>the 2018 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What&apos;s the folk theory? Reasoning about cyber-social systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megan</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reasoning About Cyber-Social Systems</title>
		<imprint>
			<date type="published" when="2017-02-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Flagging Facebook falsehoods: Self-identified humor warnings outperform fact checker and peer warnings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shannon</forename><surname>Poulsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Mediated Communication</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="240" to="258" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Concepts and folk theories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristine</forename><forename type="middle">H</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Legare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of anthropology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="379" to="398" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Josh A Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renee</forename><surname>Musser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Diresta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Gentzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sedova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.04246</idno>
		<title level="m">Generative language models and automated influence operations: Emerging threats and potential mitigations</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deepfake detection by human crowds, machines, and machine-informed crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaz</forename><surname>Firestone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosalind</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">2110013119</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Human detection of political deepfakes across transcripts, audio, and video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aruna</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Lippman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosalind</forename><surname>Picard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12883</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Digital literacy and online political behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Guess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Munger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political science research and methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="110" to="128" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Conceptual metaphors impact perceptions of human-AI collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Khadpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Metaphors we live by</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>University of Chicago press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Look! It&apos;sa computer program! It&apos;s an algorithm! It&apos;s AI!&quot;: Does terminology affect human perceptions and evaluations of algorithmic decision-making systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Hunsicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Feldkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cornelius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grgić-Hlača</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2022 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Building Generative AI Features Responsibly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meta</forename></persName>
		</author>
		<ptr target="https://about.fb.com/news/2023/09/building-generative-ai-features-responsibly/" />
	</analytic>
	<monogr>
		<title level="j">Meta Newsroom</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.12871</idno>
		<title level="m">Why AI is harder than we think</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Comparing the perceived legitimacy of content moderation processes: Contractors, algorithms, expert panels, and digital juries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahil</forename><surname>Christina A Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yakhmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><forename type="middle">X</forename><surname>Strasnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deepfakes and cheap fakes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Britt</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Donovan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The implied truth effect: Attaching warnings to a subset of fake news headlines increases perceived accuracy of headlines without warnings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Bear</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Evan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David G</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management science</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="4944" to="4957" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Prior exposure increases perceived accuracy of fake news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyrone</forename><forename type="middle">D</forename><surname>Cannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David G</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology: general</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page">1865</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fighting misinformation on social media using crowdsourced judgments of news source quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="2521" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The media equation: How people treat computers, television, and new media like real people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byron</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clifford</forename><surname>Nass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">10</biblScope>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">C2PA: the world&apos;s first industry standard for content provenance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Rosenthol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Digital Image Processing XLV</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">12226</biblScope>
			<biblScope unit="page">122260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Encounters with visual misinformation and labels across platforms: An interview and diary study to inform ecosystem approaches to misinformation interventions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Saltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><forename type="middle">R</forename><surname>Leibowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Wardle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Do You Mind? User Perceptions of Machine Consciousness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ava</forename><forename type="middle">Elizabeth</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmin</forename><surname>Niess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paweł W</forename><surname>Woźniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2023 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
	<note>n. d.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Metaphor&apos;s role in the information behavior of humans interacting with computers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Sease</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information technology and libraries</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Algorithms as culture: Some tactics for the ethnography of algorithmic systems</title>
	</analytic>
	<monogr>
		<title level="j">Big data &amp; society</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">2053951717738104</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Designing indicators to combat fake media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Imani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elissa</forename><forename type="middle">M</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><forename type="middle">W</forename><surname>Redmiles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stokes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00544</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Digital literacy is associated with more discerning accuracy judgments but not sharing intentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Sirlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">A</forename><surname>Arechar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David G</forename><surname>Rand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Using expert sources to correct health misinformation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Emily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leticia</forename><surname>Vraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bode</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science communication</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="621" to="645" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The rhetoric and reality of anthropomorphism in artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Minds and Machines</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="417" to="440" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Effects of credibility indicators on social media news sharing intent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waheeb</forename><surname>Yaqub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otari</forename><surname>Kakhidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasir</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Memon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 chi conference on human factors in computing systems</title>
		<meeting>the 2020 chi conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">members of the Human Cooperation Lab, and Hope Schroeder helpful suggestions and useful feedback. truth labels (e.g. AI-generated but not misleading, or Misleading but not AI-generated), while one would expect to find convergence between accuracy and misleading for content with convergent ground-truth labels (e.g. Both AIgenerated and misleading, or Neither AI-generated nor misleading). Therefore, it is natural to ask if our findings of divergence between the two goals is an artifact on our particular curation of content types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C2pa</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">We thank Neha Gupta for her help developing the materials, and</title>
		<imprint/>
	</monogr>
	<note>rather than a insight</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">AI-generated but not misleading (n=4), misleading but not AI-generated (n=4), both AI-generated and misleading (n=8). If anything, the over-representation of the final category (both AI-generated and misleading) suggests that a priori one might expect to find convergence between the accuracy and misleading ratings, which is the opposite of what we found</title>
	</analytic>
	<monogr>
		<title level="m">However, across the 20 content types, we note representation of all four category types: Neither AI-generated nor misleading (n=4)</title>
		<imprint/>
	</monogr>
	<note>To make this concrete, Figure ⁇ shows the Pareto</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
