<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Running head: EXPOSURE EFFECTS IN SPEECH PERCEPTION 1 What we do (not) know about the mechanisms underlying adaptive speech perception: A computational framework and review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Language Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Brain and Cognitive Sciences</orgName>
								<orgName type="institution">University of Rochester</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Florian Jaeger</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Brain and Cognitive Sciences</orgName>
								<orgName type="institution">University of Rochester</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Rochester</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chigusa</forename><surname>Kurumada</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Brain and Cognitive Sciences</orgName>
								<orgName type="institution">University of Rochester</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Social Science Plaza B</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>3151, 92697-5100</postCode>
									<settlement>Irvine</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Running head: EXPOSURE EFFECTS IN SPEECH PERCEPTION 1 What we do (not) know about the mechanisms underlying adaptive speech perception: A computational framework and review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>speech perception</term>
					<term>computational model</term>
					<term>accent adaptation</term>
					<term>perceptual recalibration</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Speech from unfamiliar talkers can be difficult to comprehend initially. These difficulties tend to dissipate with exposure, sometimes within minutes or less. Adaptivity in response to unfamiliar input is now considered a fundamental property of speech perception, and research over the past two decades has made substantial progress in identifying its characteristics. The mechanisms underlying adaptive speech perception, however, remain unknown. Past work has attributed facilitatory effects of exposure to any one of three qualitatively different hypothesized mechanisms: (1) low-level, pre-linguistic, signal normalization, (2) changes in/selection of linguistic representations, or (3) changes in post-perceptual decision-making. Direct comparisons of these hypotheses, or combinations thereof, have been lacking. We describe a general computational framework that-for the first time-implements all three mechanisms. We demonstrate how the framework can be used to derive predictions for experiments on perception from the acoustic properties of the stimuli. Using this approach, we find that-at the level of data analysis presently employed by most studies in the field-the signature results of common experimental paradigms do not distinguish between the three mechanisms. This highlights the need for a change in research practices, so that future experiments provide more informative results. We recommend specific changes to experimental paradigms and data analysis. All data and code for this study are shared via OSF, including the R markdown document that this article is generated from, and an R library that implements the models we present.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>What we do (not) know about the mechanisms underlying adaptive speech perception: A computational framework and review</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>How human listeners are able to infer meaning from speech is a central question in cognitive and neurosciences. The computational complexity of spoken language understanding becomes most apparent when a talker's pronunciations-and thus the mapping of acoustic input to linguistic categories and meaning-strongly deviate from listeners' expectations. This might occur, for example, when listening to a talker with an unfamiliar regional or non-native accent, or a patient with apraxia or dysarthria. The same fundamental challenge is, however, present even during seemingly effortless comprehension. Even among talkers who share similar language backgrounds, the mapping between the acoustic input and linguistic categories can vary substantially between talkers due to both physiology (e.g., vocal tract size and shape) and socio-cultural factors (e.g., social identity and language background). As a consequence, one talker's pronunciation of, say, the sound category [s] (as in sip) can be acoustically more similar to another talker's production of <ref type="bibr">[ʃ]</ref> (as in ship, ). How we manage to understand each other despite such cross-talker differences has remained one of the perennial puzzles in research on speech perception (where it is known as part of the infamous lack of invariance problem, <ref type="bibr" target="#b144">Liberman et al., 1967)</ref>. This article presents a general computational framework-which we refer to as ASP for adaptive speech perception-that helps address this question. ASP grew out of our long-term goal to contribute to the development of stronger theories, affording decisive comparisons between alternative hypotheses about the mechanisms underlying speech perception (in the tradition of "strong inference" approaches to scientific inquiry, <ref type="bibr" target="#b207">Platt, 1964)</ref>. We identify the three most influential hypotheses about the mechanisms that allow listeners to overcome cross-talker variability <ref type="figure">(Figure 1</ref>). These three hypotheses-described below-entail fundamentally different cognitive abilities and neural architectures, with far-reaching consequences for theories of speech perception, linguistics, and the malleability of neural representations more generally. ASP is the first to formalize and implement all three of these mechanisms in a common computational framework. This responds to a need identified in recent reviews to better characterize the mechanisms of adaptive speech perception (e.g., <ref type="bibr" target="#b6">Baese-Berk et al., 2020;</ref><ref type="bibr" target="#b108">Johnson &amp; Sjerps, 2021;</ref><ref type="bibr" target="#b139">Kurumada &amp; Roettger, 2021;</ref><ref type="bibr" target="#b212">Quam &amp; Creel, 2021;</ref><ref type="bibr" target="#b259">Stilp, 2020;</ref>. <ref type="figure">Figure 1</ref>. Listeners' recognition of speech categories are typically assumed to involve at least three types of mechanisms: 1) the acoustic input is transformed by low-level normalization processes into the perceptual cues that form the input to categorization, 2) category representations describe the mapping between these perceptual and linguistic categories (here 1 and 2 ), and 3) decisionmaking mechanisms allow additional, stimulus-independent, biases to affect recognition. Any of these three mechanisms can in theory be affected by recent experience. It is unknown which (combination) of the three mechanisms underlie these changes and how the engagement of different mechanisms depends on, for instance, stimulus properties, task demands, and individual differences between listeners.</p><p>While the three hypotheses in <ref type="figure">Figure 1</ref> have largely been pursued in separate lines of research, they are not mutually exclusive. This raises questions as to whether adaptive speech perception is the result of combinations of these mechanisms, and (if so) how the relative engagement of these mechanisms depends on, for instance, stimulus properties, task demands, or individual differences between listeners. ASP can be used to address these questions. Researchers can, for example, use ASP to predict adaptive changes in speech perception while 'switching off' individual change mechanisms-making it possible to test whether any of the three mechanisms is sufficient to explain a given result-or to predict changes from weighted combinations of all three mechanisms. Future work could use ASP, for example, to investigate whether specific instances of impaired adaptation (as seen, e.g., in children with dyslexia, <ref type="bibr" target="#b69">Gabay &amp; Holt, 2021;</ref><ref type="bibr" target="#b198">Ozernov-Palchik et al., 2021)</ref> arise from auditory, linguistic, or cognitive sources-an important prerequisite for devising more effective interventions/treatments. For the present article, we have three more immediate goals. The first part of this article introduces the ASP framework, along with visual demonstrations and animations. We take a deliberately tutorial-like approach so to help researchers apply ASP to their own experiments. All data and code for this article can be downloaded from the Open Science Framework at https://osf.io/q7gjp/. The article is written in R markdown, allowing readers to replicate our analyses with the press of a button using freely available software (R Core <ref type="bibr" target="#b222">RStudio Team, 2020</ref>, see supplementary information for detailed software requirements). Readers can also revisit any of the assumptions we make-e.g., changing parameterizations of our models, or substituting alternative models (see also . We welcome questions about the code, including the accompanying R library.</p><p>Second, we demonstrate one way in which computational frameworks like ASP can advance theories of speech perception. We simulate human recognition for two influential experimental paradigms under each of the three hypothesized mechanisms. The first paradigm-perceptual recalibration (e.g., <ref type="bibr" target="#b216">Reinisch &amp; Holt, 2013;</ref><ref type="bibr" target="#b227">Samuel, 2016;</ref><ref type="bibr" target="#b288">Vroomen &amp; Baart, 2009</ref>)-tends to employ a small set of exposure and test stimuli that are phonetically manipulated to form a single perceptual continuum. This property makes such experiments comparatively easy to understand and model, and thus suitable as an initial case study. The second paradigm-adaptation to second language (L2) accents (e.g., <ref type="bibr" target="#b19">Bradlow &amp; Bent, 2008;</ref><ref type="bibr" target="#b83">Hernández et al., 2019;</ref><ref type="bibr" target="#b243">Sidaras et al., 2009;</ref><ref type="bibr" target="#b280">Tzeng et al., 2016;</ref><ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020</ref>)-introduces substantially more complexity for listeners and researchers alike. Stimuli for these experiments tend to exhibit the full range of naturally occurring phonetic variability, introducing listeners to novel phonetic cues, differences in cue weightings, and other complex changes in the mapping from acoustics to linguistic categories.</p><p>We find that, contrary to common assumptions, the signature findings of both paradigms are qualitatively compatible with any of the three hypothesized change mechanisms. Beyond the immediate consequences for research on perceptual recalibration and accent adaptation, this demonstrates how ASP can inform and revise intuitions about the mechanisms underlying adaptive speech perception. The R code for our case studies further serves as a template for experimenters interested in understanding the theoretical implications of their results while reducing the need for ad-hoc reasoning.</p><p>Finally, we discuss how computationally-guided behavioral and neuroimaging research can advance future work. We show that the empirical indeterminacy of many existing findings is due to the level of analysis chosen in those studies. We propose new standards of experimental design and data analysis that will more effectively distinguish between competing hypotheses about the relative engagement of different mechanisms. But first some background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The state of the field(s)</head><p>Research over the past decades has identified adaptive changes in speech perception to be a key component in listeners' ability to overcome cross-talker differences. Although speech perception can initially be slower and/or less accurate when listeners encounter an unfamiliar talker with unexpected pronunciations, these processing difficulties tend to reduce with exposure (e.g., <ref type="bibr" target="#b19">Bradlow &amp; Bent, 2008;</ref><ref type="bibr" target="#b196">Nygaard et al., 1994;</ref><ref type="bibr" target="#b200">Perrachione et al., 2016;</ref><ref type="bibr" target="#b243">Sidaras et al., 2009;</ref><ref type="bibr" target="#b292">Wade et al., 2007;</ref><ref type="bibr" target="#b299">Weil, 2001;</ref>. Remarkably, substantial improvements-such as reduced processing times or increased accuracy of recognition-can occur within minutes or less <ref type="bibr" target="#b35">(Clarke &amp; Garrett, 2004;</ref><ref type="bibr" target="#b179">Munro &amp; Derwing, 1995;</ref><ref type="bibr" target="#b314">Xie, Weatherholtz, et al., 2018)</ref>. Even a context as brief as a single utterance can be sufficient to change perception and segmentation of ambiguous speech, blurring the distinction between processing and adaptation (e.g., categorizing a Dutch ambiguous /m?t/ embedded in an utterance with fast or slow speech as either "mat" or "maat" <ref type="bibr" target="#b18">Bosker et al., 2017;</ref><ref type="bibr">see also 1988;</ref><ref type="bibr" target="#b71">1996;</ref>). Yet, adaptive changes after only a few words of exposure can sometimes last for days, if not longer <ref type="bibr" target="#b52">(Eisner &amp; McQueen, 2006;</ref><ref type="bibr" target="#b306">Xie et al., 2016</ref>; see also <ref type="bibr" target="#b71">Goldinger, 1996)</ref>.</p><p>In short, listeners' ability to adapt based on recent input is now considered a central part of human speech perception, and substantial progress has been made in identifying its empirical properties and constraints (for comprehensive reviews, see <ref type="bibr" target="#b6">Baese-Berk et al., 2020;</ref><ref type="bibr" target="#b108">Johnson &amp; Sjerps, 2021;</ref><ref type="bibr" target="#b212">Quam &amp; Creel, 2021;</ref><ref type="bibr" target="#b259">Stilp, 2020;</ref><ref type="bibr" target="#b282">Tzeng et al., 2021)</ref>. Despite these substantial advances, however, it remains unclear how-through what mechanisms-recent exposure comes to facilitate spoken language understanding. This is not due to a lack of theoretical proposals. Across cognitive sciences and neurosciences, there are now dozens of competing perspectives. However, contrastive comparisons between proposals have largely been lacking. Two inter-related factors seem to contribute to this: (1) many proposals-including some of our own past work-remain under-specified, constituting informal hypotheses rather than theories or models that lend themselves to strong contrastive tests; (2) there is a tendency, particularly in behavioral research, to focus on characterizing properties of adaptive speech perception rather than on identifying the underlying cognitive and neural architectures (but see <ref type="bibr" target="#b87">Hoffmann Bion &amp; Escudero, 2007;</ref><ref type="bibr" target="#b115">Kiefte &amp; Nearey, 2019;</ref>. As a consequence, different hypotheses are often assumed rather than tested, with different lines of research making different <ref type="bibr">(implicit)</ref> assumptions, sometimes co-existing for decades without targeted attempts to contrast the predictions that would follow from those assumptions.</p><p>Neuroimaging research has, on the whole, been more invested into contrastive comparisons (e.g., <ref type="bibr" target="#b17">Bonte et al., 2017;</ref><ref type="bibr" target="#b57">Erb et al., 2013b;</ref><ref type="bibr" target="#b76">Guediche et al., 2015;</ref><ref type="bibr" target="#b182">Myers &amp; Mesite, 2014)</ref>: questions about the involvement of different types of information processing-operationalized as differential activation of different brain areas and networks that are associated with different functionality-are the bread and butter of neuroimaging. This approach has identified a wide range of brain regions as involved in different aspects of adaptive speech perception, ranging from subcortical areas (e.g., <ref type="bibr" target="#b76">Guediche et al., 2015;</ref><ref type="bibr" target="#b248">Skoe et al., 2021)</ref> to networks associated with decision-making (e.g., <ref type="bibr" target="#b57">Erb et al., 2013b;</ref><ref type="bibr" target="#b182">Myers &amp; Mesite, 2014)</ref>. This leaves open, however, what types of computations underlie the observed differential activations, or why different types of exposure lead to different types of behavioral changes. In light of these gaps in our understanding, recent reviews continue to emphasize the need to better characterize the nature of the mechanisms underlying adaptive speech perception (from, e.g., <ref type="bibr" target="#b230">Samuel &amp; Kraljic, 2009;</ref><ref type="bibr" target="#b6">to Baese-Berk et al., 2020)</ref>. This includes questions about how the task demands of different types of experimental paradigms affect the engagement of different mechanisms <ref type="bibr" target="#b7">(Baese-Berk et al., 2018;</ref><ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020)</ref>, and thus also which paradigms are most likely to shed light on the mechanisms affording flexible perception in everyday life.</p><p>The ASP framework we present in Section is designed to help address these questions. We group existing proposals for adaptive speech perception into three types of theoretical perspectives <ref type="figure">(Figure 1</ref>). The three proposals share with each other, and with all major theories in speech perception, general assumptions about how the acoustic input supports perception of a speech category. The process begins with (A) the extraction and normalization of acoustic/phonetic cues.</p><p>These cues are (B) mapped onto, and activate, linguistic categories (such as phonemes, syllables, and/or words). Finally, (C) decision processes integrate the resulting category activations with contextual support (e.g., from lexical or sentential context) and/or meta-reasoning (e.g., about the task), and recognition takes place. Existing proposals differ, however, in which of (A)- <ref type="bibr">(C)</ref> explains changes in speech perception as a function of recent exposure. As we discuss next, it is these differences that entail fundamentally different cognitive and neural architectures.</p><p>The majority of recent behavioral research on talker adaptation has focused on the middle layer, changes in the mapping from acoustic or phonetic cues onto phonological categories (for brevity: changes in category representations). This includes proposals that attribute exposure effects to "boundary re-tuning/shift" (e.g., , "perceptual/category recalibration" (e.g., <ref type="bibr" target="#b216">Reinisch &amp; Holt, 2013;</ref><ref type="bibr" target="#b227">Samuel, 2016;</ref><ref type="bibr" target="#b288">Vroomen &amp; Baart, 2009)</ref>, "perceptual retuning" <ref type="bibr" target="#b102">(Jesse &amp; McQueen, 2011;</ref><ref type="bibr" target="#b169">McQueen et al., 2006;</ref>, "category shift" <ref type="bibr" target="#b145">(Lindsay et al., 2022;</ref><ref type="bibr" target="#b233">Sawusch &amp; Pisoni, 1976)</ref>; "category expansion" <ref type="bibr" target="#b238">(Schmale et al., 2012)</ref>, "dimension-based statistical learning" , or "criteria relaxation" <ref type="bibr" target="#b321">(Zheng &amp; Samuel, 2020)</ref>. While these proposals are often not further formally specified or modeled (for notable exceptions, see <ref type="bibr" target="#b141">Lancia &amp; Winter, 2013;</ref>, they all describe types of changes in representations. For example, "category shift" refers to a change in the mean of the cue distribution corresponding to a category, and "category expansion" refers to increases in the variance of that distribution.</p><p>One reason that the idea of representational changes has received so much attention is that it is of high theoretical relevance. Representational changes as a function of recent exposure are predicted by influential exemplar <ref type="bibr" target="#b105">Johnson, 2006)</ref>, episodic <ref type="bibr" target="#b72">(Goldinger, 1998)</ref>, Bayesian inference , and neural network models <ref type="bibr" target="#b141">(Lancia &amp; Winter, 2013)</ref>. All of these theories predict that listeners can learn and store talker-or accent-specific representations (see also <ref type="bibr" target="#b5">Baese-Berk et al., 2013;</ref><ref type="bibr" target="#b19">Bradlow &amp; Bent, 2008;</ref><ref type="bibr" target="#b280">Tzeng et al., 2016)</ref>. Perhaps unsurprisingly, this idea-continued implicit learning of new representations throughout their adult life-has been influential beyond speech perception. The possibility that listeners learn and maintain category representations for multiple types of talkers has influenced psycholinguistic research on lexical, sentence, and semantic/pragmatic processing <ref type="bibr" target="#b29">(Chang et al., 2012;</ref><ref type="bibr" target="#b112">Kaschak &amp; Glenberg, 2004;</ref><ref type="bibr" target="#b208">Pogue et al., 2016;</ref><ref type="bibr" target="#b224">Ryskin et al., 2019;</ref><ref type="bibr" target="#b240">Schuster &amp; Degen, 2020</ref>; for review, see <ref type="bibr" target="#b20">Brown-Schmidt et al., 2015)</ref> and research on second language learning (for reviews, see <ref type="bibr" target="#b110">Kaan &amp; Chun, 2018;</ref><ref type="bibr" target="#b199">Pajak et al., 2016)</ref>. It has shaped linguistic theories (e.g., <ref type="bibr" target="#b24">Bybee, 2001;</ref><ref type="bibr" target="#b73">Goldinger &amp; Azuma, 2004;</ref><ref type="bibr" target="#b81">Hay et al., 2019;</ref><ref type="bibr" target="#b156">Magnuson &amp; Nusbaum, 2007;</ref><ref type="bibr" target="#b204">Pierrehumbert, 2001)</ref> as well as theories about the interface between social and linguistic cognition (e.g., <ref type="bibr" target="#b4">Babel et al., 2019;</ref><ref type="bibr" target="#b41">Creel &amp; Bregman, 2011;</ref><ref type="bibr" target="#b66">Foulkes &amp; Hay, 2015;</ref><ref type="bibr" target="#b264">Sumner et al., 2014)</ref>. Further illustrating the influence of this idea, several recent reviews have gone as far as to discuss what types of representational changes underlie the effects of recent exposure (e.g., "category expansion" vs. "category shifts"), rather than whether representational changes are indeed necessary to explain adaptive speech perception (e.g., <ref type="bibr" target="#b6">Baese-Berk et al., 2020;</ref><ref type="bibr" target="#b10">Bent &amp; Baese-Berk, 2021;</ref>.</p><p>In the absence of contrastive tests, however, the same behavioral results that have been interpreted as arguing for representational changes could in principle be explained by computationally more parsimonious mechanisms that do not assume changes in category representations. For instance, proposals dating back to at least the 1970s hold that adaptive speech perception is due to low-level, automatic (involuntary) normalization during the early stages of auditory processing (bottom of <ref type="figure">Figure 1</ref>). These processes are thought to be pre-linguistic in that they do not refer to categories but rather apply to the acoustic or phonetic cues (for reviews, <ref type="bibr" target="#b108">Johnson &amp; Sjerps, 2021;</ref><ref type="bibr" target="#b259">Stilp, 2020)</ref>. In contrast to the assumption that cross-talker variability may be learned and stored, which is fundamental to all the theories of representational changes as described above, normalization proposals assume that listeners remove talker variability prior to mapping cues to linguistic categories. More recently, evidence from neuroimaging studies has lent support for low-level normalization mechanisms by showing engagement of subcortical structures in sensory adaptation (e.g., the brain stem, <ref type="bibr" target="#b248">Skoe et al., 2021;</ref><ref type="bibr"></ref> and cerebellum, <ref type="bibr" target="#b76">Guediche et al., 2015</ref>; for review, see <ref type="bibr" target="#b75">Guediche et al., 2014)</ref>. Studies using intracranial electrocorticography have found evidence of talker-normalized (spectral) cues in the auditory cortex before they are mapped onto categories (e.g., <ref type="bibr" target="#b244">Sjerps et al., 2019;</ref><ref type="bibr" target="#b270">Tang et al., 2017a)</ref>. This leaves open, however, whether normalization can indeed explain talker-specific adaptation that have been attributed to changes in representations. If it can, this would remove the necessity for the computational complexity and cognitive abilities implied by theories of representational changes. 1</p><p>Another explanation for adaptive speech perception that does not refer to changes in representations are post-perceptual-'cognitive'-mechanisms of decision-making (top of <ref type="figure">Figure   1</ref>). Just like normalization, this explanation is computationally more parsimonious than changes in representations. And just like normalization is broadly accepted to be part of speech perception, there is little doubt that changes in decision and response biases can affect listeners' interpretation of speech input, or at least the responses they give within experiments.</p><p>For instance, <ref type="bibr">Clarke-Davidson et al. (2008, p.605</ref>) define a response bias as "the increased likelihood to give a particular response-such as /s/-given any acoustic input, or the need for less evidence for a particular response" that "would help participants make faster word decisions in […] ambiguous cases". In behavioral research, such biases continue to be rarely considered when interpreting the effects of recent exposure. When response biases have been considered (e.g., as "response equilibration" in <ref type="bibr" target="#b288">Vroomen and Baart 2009)</ref>, this explanation tends to be dismissed. One reason for this might be that particular result patterns-such as boundary shifts in perceptual recalibration or improved categorization or transcription accuracy in accent adaptation-are taken to rule out changes in response biases (or normalization, for that matter). However, to anticipate 1 It would also indicate a need to revisit the interpretation of findings that speech perception can be affected by the (inferred) social identity of a talker (e.g., regional origin, <ref type="bibr" target="#b80">Hay &amp; Drager, 2010;</ref><ref type="bibr" target="#b189">Niedzielski, 1999;</ref><ref type="bibr">sex, Johnson et al., 1999;</ref><ref type="bibr" target="#b260">Strand, 1999;</ref><ref type="bibr">age, Walker &amp; Hay, 2011;</ref><ref type="bibr" target="#b295">Waller et al., 2015;</ref><ref type="bibr">and individual identity, Nygaard et al., 1994;</ref><ref type="bibr" target="#b218">Remez et al., 2018)</ref>. In sociophonetics and related fields, these findings are routinely attributed to talker-specific storage of category representations, without considering alternative explanations in terms of normalization. While early normalization accounts that were limited to correction for physiology were rather convincingly rejected by cross-linguistic comparisons <ref type="bibr" target="#b105">(Johnson, 2006)</ref>, modern theories of normalization like the ones we discuss in Section 2 are not subject to those arguments. one take-home point from the case studies we present below, we find that response biases can explain more complex changes in behavior than has previously been assumed, including the very signature results that are often assumed to be incompatible with changes in response bias.</p><p>In contrast to behavioral research, changes in decision-making have received substantial attention in neuroimaging research. Recent studies have investigated whether adaptive changes in speech perception primarily recruit areas associated with decision-making <ref type="bibr" target="#b57">(Erb et al., 2013b;</ref><ref type="bibr" target="#b182">Myers &amp; Mesite, 2014;</ref><ref type="bibr" target="#b251">Sohoglu &amp; Davis, 2016</ref>)-such as prefrontal areas (e.g., <ref type="bibr" target="#b14">Binder et al., 2004;</ref><ref type="bibr" target="#b276">Thompson-Schill et al., 1997)</ref> as well as the insula and parietal cortex (e.g., <ref type="bibr" target="#b68">Furl &amp; Averbeck, 2011;</ref><ref type="bibr" target="#b114">Keuken et al., 2014)</ref>-as opposed to cortical areas associated with phonetic representations <ref type="bibr" target="#b17">(Bonte et al., 2017;</ref><ref type="bibr" target="#b154">Luthra et al., 2020)</ref>. For instance, <ref type="bibr" target="#b182">Myers and Mesite (2014)</ref> found that sensitivity to category shifts between [s] and [ʃ] emerged in right frontal and middle temporal regions, implicating adjustments of decision-related or attentional criteria downstream from functions performed by primary auditory cortex.</p><p>In summary, different lines of research have focused on different types of explanations for adaptive speech perception observed in different types of paradigms. Comparisons between competing hypotheses about the types of computations that underlie adaptive speech perception-within or across paradigms-remain lacking. The upshot of this is that we often neither know whether the results of a given paradigm clearly argue for one over another mechanism, nor whether the results of different paradigms all point to the same (combination of) mechanisms. The computational framework that we introduce next provides a way for future work to address these questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Modeling adaptive changes in speech perception</head><p>We assume conceptual familiarity with reasoning about distributions and contemporary theories of speech perception-all of which expect that listeners have implicit representations of the mapping between phonetic cues and linguistic categories that encompass (in one form or other) knowledge of the distribution of cues that correspond to a linguistic category. This assumption is motivated by observations made as early as <ref type="bibr" target="#b0">Abramson and Lisker (1973)</ref> or <ref type="bibr" target="#b185">Nearey and Hogan (1986)</ref>, and illustrated in <ref type="figure">Figure 2</ref>: listeners' categorization responses for two phonetic categories (/d/ and /t/ in <ref type="figure">Figure 2B</ref>) can be predicted by considering the phonetic properties of the input relative to the distribution of phonetic cues that listeners have previously experienced <ref type="figure">(Figure 2A</ref>). Recent introductions to, and discussions of, this perspective are provided in <ref type="bibr" target="#b10">Bent and Baese-Berk (2021)</ref>, <ref type="bibr" target="#b139">Kurumada and Roettger (2021)</ref>, <ref type="bibr" target="#b212">Quam and Creel (2021)</ref>, and .  <ref type="figure">Figure 2</ref>. Speech production realizes phonetic categories as distributions in a multi-dimensional acoustic or phonetic cue space. Implicit knowledge of these distributions is known to mediate listeners' interpretation of speech inputs (for review, see . Panel A: voice onset time (VOT) and fundamental frequency (f0) of 6,518 word-initial /d/ and /t/ from 50 male L1 speakers of US English (data from . VOT and f0 were centered relative to their overall mean (see SI §2). Panel B: responses to a 2AFC ("da" vs. "ta") categorization task by 10 L1 listeners of US English, depending on VOT and f0 (data from Experiment 1 in .</p><p>ASP is not meant to be a new model of speech perception but rather a conceptual and computational framework that i) integrates the core insights shared by present-day models of speech perception, ii) extends these models to specify how recent exposure can come to affect any of the three mechanistic levels, and iii) stays as simple and conceptually transparent as possible.</p><p>Any of the components we present below can be exchanged and compared to alternatives: researchers might, for example, substitute a different approach to normalization or use exemplar models of category representations rather than the Bayesian model we employ in this study. The general conclusions and recommendations we arrive at in the present study are unlikely to be affected by these choices.</p><p>For the present purpose, we focus on modeling offline responses, which remain one of the most commonly employed measures in research on speech perception. This includes categorization/identification responses in two-forced-choice (2AFC) tasks that continue to be the standard approach used to assess the effects of recent exposure on subsequent speech perception (e.g., <ref type="bibr" target="#b162">Maye et al., 2008;</ref><ref type="bibr" target="#b216">Reinisch &amp; Holt, 2013;</ref><ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020)</ref>. The general framework we develop here can, however, be extended to offline and online tasks with two or more categorical outcomes, including discrimination (e.g., <ref type="bibr" target="#b59">Feldman et al., 2009;</ref>, transcription (e.g., <ref type="bibr" target="#b19">Bradlow &amp; Bent, 2008)</ref>, accuracy in cross-modal priming (e.g., <ref type="bibr" target="#b245">Sjerps &amp; McQueen, 2010)</ref>, spoken repetition (e.g., <ref type="bibr" target="#b13">Bieber &amp; Gordon-Salant, 2021)</ref>, or fixations in the visual world paradigm (e.g., . <ref type="figure">Figure 3</ref> provides an overview of how ASP can be used to model adaptive changes in speech perception. This is the approach we employ in the two case studies in Sections 4 and 5. ASP integrates a processing model with three different change models-one each to describe changes in normalization, representations, and decision-making, respectively. The processing model-for the present study, a categorization model-describes the mechanisms that allow listeners to infer 'what is being said'. 2 This model is closely related to psychometric models that are used for data analysis in many areas of the cognitive sciences (for an introduction, see <ref type="bibr" target="#b300">Wichmann &amp; Hill, 2001)</ref> but remain rare in research on speech perception-in particular, in research on the effects of recent experience (but see . It is also conceptually related to general process models of online perceptual decision-making (e.g., the drift diffusion model, <ref type="bibr" target="#b215">Ratcliff et al., 2011)</ref>. The change models describe listeners' inferences about 'how things are being said'. These change models extend existing models for normalization (adding inference of talker's means to <ref type="bibr">C-CuRE, McMurray &amp; Jongman, 2011)</ref> and representational <ref type="bibr">2</ref> The present study focuses on the recognition of phonetic categories-be it a phoneme, syllable, or word-out of context. We do not aim to model the well-documented effects of, a.o., phonotactic, prosodic, lexical/semantic, visual and sentential/discourse contexts (for a great concise review, see <ref type="bibr" target="#b301">Winn, 2018)</ref>. The results we present below are, however, expected to generalize to situations in which such context is taken into account (in ASP, context simply changes the overall response bias). Critically, models of spoken word recognition that capture contextual effects share the general assumptions encoded in ASP's processing model (DIANA, ten <ref type="bibr" target="#b272">Bosch et al., 2015;</ref><ref type="bibr">NAM, P. A. Luce &amp; Pisoni, 1998;</ref><ref type="bibr">TRACE, McClelland &amp; Elman, 1986;</ref><ref type="bibr">EARSHOT, Magnuson et al., 2020)</ref>.</p><p>changes (extending ideal adaptors to multivariate acoustic inputs, , and add a novel model for changes in decision-making. <ref type="figure">Figure 3</ref>. Overview of the approach for the present study. Experiments on the effect of recent exposure on subsequent speech perception tend to involve two phases. An exposure phase manipulates the statistics of the speech input, typically between participants. A test phase-typically identical across participants-assesses the effects of those manipulations on the subsequent interpretation of speech input. We seek to understand what type of exposure effects each of the three mechanisms in <ref type="figure">Figure 1</ref> can explain. To this end, we specify both a) a processing model-specifically, a categorization model-that describes the interpretation of speech input at any given moment (vertical information flow) and b) change models for all three mechanisms that describe how these parts of the categorization model change as a function of exposure (horizontal information flow). We then use the different change models to compare the predicted consequences of changes to normalization, representations, or response biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The categorization model ('processing')</head><p>For the present purpose, we can think of the mapping from acoustic inputs to categorization responses as involving at least the three processes illustrated in <ref type="figure">Figure 4</ref> (by presenting these processes as three different steps, we do not mean to imply that they are discrete, information encapsulated processes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">'Pre-linguistic' auditory processes: signal transformations and normalization</head><p>The first step in our categorization model maps the acoustic input onto perceptual features. These perceptual features are the outcome of low-level signal transformations and normalization <ref type="figure">Figure 4</ref>. Graphical model of a simplified general categorization model for -AFC alternative-choice tasks (e.g., vowel categorization, word transcription, etc.) over a -dimensional phonetic input. The left-hand side links the components and parameters in the model to the three mechanism introduced in <ref type="figure">Figure 1</ref>. Filled gray circles represent variables the researcher can observe. Empty circles represent latent variables that are not observable. Diamonds represent variable-free processes. Only variables that we consider as being potentially affected by recent exposure are shown (see text for additional detail). Parentheses describe the number of degrees of freedom (DF) introduced by each parameter. In practice, many of these DFs can be fixed based on phonetic databases and/or previous perception experiments (see text for details). Squares are annotated with the distributions resulting at that level of the model: (ormal), Multi(nomial), and ℳ(ixture) distributions. For 2AFC tasks, all multinomial distributions simplify to Bin(omial) distributions. processes. 3 Experiments on the perception of stimulus similarity suggest that the human brain represents frequency information logarithmically <ref type="bibr" target="#b74">(Greenwood, 1961)</ref>. This is captured by, for example, the Mel <ref type="bibr" target="#b258">(Stevens et al., 1937)</ref>, Bark <ref type="bibr" target="#b323">(Zwicker, 1961)</ref>, and ERB <ref type="bibr" target="#b178">(Moore &amp; Glasberg, 1983</ref>) transformations. Such logarithm-transformed spectral cues have been found to provide a better fit against human categorization responses than features based on raw frequencies <ref type="bibr" target="#b87">(Hoffmann Bion &amp; Escudero, 2007;</ref><ref type="bibr" target="#b121">Kleinschmidt, 2019;</ref>. The case studies we present below model perception for a phonological contrast that depends on both temporal and spectral cues. For the spectral cue, we use Mel-transformed frequencies.</p><p>Normalization refers to further transformation of acoustic inputs based on either other acoustic properties or the overall distribution of the acoustic input itself (for a review, see . For example, one of the most influential normalization procedures for the formant cues that affect vowel perception centers and standardizes these cues based on the talker-specific mean and standard deviation of the formant values . This and conceptually similar normalizations (e.g., <ref type="bibr" target="#b70">Gerstman, 1968)</ref> have been found to remove a substantial amount of cross-talker variability in the realization of vowels (e.g., Hoffmann Bion &amp; <ref type="bibr" target="#b87">Escudero, 2007;</ref><ref type="bibr" target="#b184">Nearey, 1989</ref>; for review, see <ref type="bibr" target="#b203">Persson &amp; Jaeger, 2022b)</ref> while maintaining phonemic contrasts and sociolinguistic information <ref type="bibr" target="#b1">(Adank et al., 2004)</ref>, providing a good fit against vowel categorization by human listeners (e.g., <ref type="bibr" target="#b202">Persson &amp; Jaeger, 2022a;</ref>.</p><p>The case studies we present below employ a general model of normalization that can be applied to any type of phonological contrast (C-CuRE, <ref type="bibr" target="#b40">Cole et al., 2010;</ref>). C-CuRE stands for "computing cues relative to expectations" and centers cues by subtracting the (expected) mean for that cue in the current context ( in <ref type="figure">Figure 4</ref>). C-CuRE has been found effective in accounting for cross-talker differences as well as effects of surrounding phonological context, improving the ability to predict human responses compared to a model without any normalization ; see also <ref type="bibr" target="#b43">Crinnion et al., 2020;</ref><ref type="bibr" target="#b124">Kleinschmidt, 2020;</ref><ref type="bibr" target="#b167">McMurray &amp; Jongman, 2016;</ref>. <ref type="figure">Figure 5</ref> visualizes the effects of C-CuRE normalization on the marginal distributions of f0 and VOT to word-initial stop voicing in US English (e.g., /b/ vs. /p/ in bin vs. pin). The specific procedure is described in the SI ( §2). We use these normalized data throughout the remainder of this study, including the two case studies. That is, all studies presented below assume that listeners' long-term expectations are based on talker-normalized cues, while leaving open how normalization affects perception during the initial exposure to an unfamiliar talker. The qualitative findings of our studies do not, however, depend on this assumption.</p><p>Beyond signal transformations and normalization, the stimulus observed by a listener is also affected by perceptual noise (not shown in <ref type="figure">Figure 5</ref>). This means that even the same exact </p><formula xml:id="formula_0">/b/−/p/ /d/−/t/ /g/−/k/<label>0</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B)</head><p>Figure 5. Effects of applying C-CuRE normalization to productions of word-initial stop voicing in US English (e.g., bin vs. pin). Panel A: unnormalized VOT and f0 of 40,459 stop productions from . VOT is the primary cue to this voicing contrast for L1 US English, and f0 is known to be a secondary cue. The data exhibit clear evidence of multimodality along both VOT and f0. Panel B: the same productions but after C-CuRE normalization has been applied to remove talker-specific variability. Compared to unnormalized data, the C-CuRE normalized data exhibits reduced variability and reduced evidence of multimodality (the remaining low-f0 outliers in the Panel B are the result of creaky voice and measurement errors like pitch-halving, see SI §2).</p><p>acoustic stimulus does not necessarily result in the same percept <ref type="bibr" target="#b59">(Feldman et al., 2009;</ref><ref type="bibr">Nearey &amp; Hogan, 1986, p. 148)</ref>. The integration of noise into models of speech perception has been shown to explain otherwise puzzling differences in the perception and recognition of different types of phonological contrasts (e.g., <ref type="bibr" target="#b136">Kronrod et al., 2016)</ref>. Although not critical for the present purpose, we incorporate perceptual noise into ASP also because it results in more human-like (less steep) categorization functions. This noise is held constant across all case studies presented below, set to the values obtained by <ref type="bibr">Kronrod and colleagues (2016, 2 ,</ref> = 80 2 , 2 , = 878 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Category representations: from perceptual features to linguistic categories</head><p>The output of normalization is the input to the mapping onto linguistic categories. All major theories of speech perception agree that this involves implicit knowledge of the distributional realization of linguistic categories-i.e., the distribution of acoustic or phonetic cues that are observed across instances of the category. In analytic models, this mapping is typically described by the category likelihood that is learned from previous inputs (e.g., in the neighborhood activation model, P. A. <ref type="bibr" target="#b152">Luce &amp; Pisoni, 1998;</ref><ref type="bibr">shortlist B, Norris &amp; McQueen, 2008;</ref><ref type="bibr">and other</ref> Bayesian inference models, <ref type="bibr" target="#b59">Feldman et al., 2009;</ref>. In exemplar models and related theories, the same mapping is achieved by storing previously experienced inputs as exemplars (e.g., <ref type="bibr" target="#b105">Johnson, 2006;</ref><ref type="bibr" target="#b204">Pierrehumbert, 2001;</ref><ref type="bibr" target="#b298">Wedel, 2006)</ref> or episodic traces <ref type="bibr" target="#b71">(Goldinger, 1996)</ref> that subsequent inputs are compared to during recognition (e.g., by means of -nearest neighbor algorithms, <ref type="bibr" target="#b63">Fix &amp; Hodges, 1989)</ref>. In connectionist and deep neural network models, the same probabilistic mapping is achieved through latent structure in the network that is learned from previous input <ref type="bibr" target="#b157">(Magnuson et al., 2020;</ref><ref type="bibr" target="#b164">McClelland &amp; Elman, 1986)</ref>. Although the specific nature of these representations continues to be a matter of debate, all of these theories share the assumption that there is a probabilistic mapping between perceptual cues and linguistic categories (see also <ref type="bibr" target="#b242">Shi et al., 2010</ref>, on the close computational relation between exemplar and Bayesian inference models) and that perception involves implicit knowledge of this probabilistic mapping.</p><p>Here we employ an analytic characterization of category likelihoods. Specifically, we adopt a simplifying assumption commonly made in research on speech perception <ref type="bibr" target="#b59">Feldman et al., 2009;</ref> and automatic speech recognition <ref type="bibr" target="#b109">(Jurafsky &amp; Martin, 2000)</ref> that the cue distributions for each category follow a multivariate Gaussian distribution. In <ref type="figure">Figure 4</ref>, this is indicated through the two parameters that are sufficient to specify each multivariate Gaussian (the category means and the category covariance matrices Σ ). 4 Bivariate Gaussian categories fit to the data from  are shown in <ref type="figure" target="#fig_2">Figure 6</ref>, along with the categorization functions of the f0-VOT space that would result from these categories prior to considering other effects on decision-making that we discuss in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Post-perceptual decision-making: incorporating priors, response biases, and attentional lapses</head><p>The third and final step in our categorization model takes the output of the second step and derives a decision/recognition. 5 This includes the integration of information about the prior probability of a category in the current context, ( | ). In Bayesian ideal observer models, this integration takes place according to Bayes theorem, yielding an estimate of each category's posterior probability (e.g., P. A. <ref type="bibr" target="#b152">Luce &amp; Pisoni, 1998;</ref>. Alternative computational approaches can introduce additional degrees of freedom, for example, by allowing non-optimal weighting of priors and category likelihoods. As our goal here is to arrive at the simplest possible model, we follow the approach taken in ideal observers:</p><p>4 This assumption strikes a compromise between two common alternatives. A representationally less complex proposal introduces an independence assumption and describes linguistic categories as a combination of independent univariate Gaussians for each cue dimension. The likelihoods from the univariate Gaussians is then combined through a cue integration model. This substantially reduces the degrees of freedom that need to be estimated-both for learners/listeners and the researcher (see <ref type="bibr" target="#b277">Toscano &amp; McMurray, 2010)</ref>. A representationally more complex alternative dispenses with the Gaussian assumption and instead assumes that listeners store all previously experienced exemplars (or some pruned set of exemplars, <ref type="bibr" target="#b204">Pierrehumbert, 2001</ref>). This allows for more accurate (non-parametric) representations of previous experience but also introduces many additional degrees of freedom-both for learners/listeners and the researcher (for discussion, see . We expect the big picture conclusions we draw below to be largely independent of the specific model of category representations.</p><p>5 This step can be split further into recognition of the category and post-recognition processes that affect the behavioral response. For the present purpose, we group these processes together. Similarly, some models of perceptual decision-making distinguish between decision thresholds (the amount of evidence necessary before a decision is being made) and decision biases (stimulus-independent effects on the activation or probability of a response option, <ref type="bibr" target="#b36">Clarke-Davidson et al., 2008;</ref><ref type="bibr" target="#b287">Venezia et al., 2012)</ref>. For the present purpose, these two have essentially identical effects.  <ref type="figure">Figure 5B</ref>. Ellipses show 95% probability mass. Bottom row: Categorization functions that would result from these category likelihoods prior to taking into account other effects on decision-making (see <ref type="figure" target="#fig_4">Figure 7</ref> in the next section).</p><formula xml:id="formula_1">( | ) = ( | ) ( ) Σ ( | ) ( ) = ( | , Σ ) ( ) Σ ( | , Σ ) ( )<label>(1)</label></formula><p>where the second row substitutes the Gaussian category likelihoods assumed in the previous section into the equation. In Bayesian models, ( ) is generally assumed to reflect a rational estimate based on either the relative frequency of the category in this type of context in listeners' longterm experience or an estimate based on the expectations about the present context. The latter allows for the integration of response biases that go beyond capturing the relative frequency of categories in previous experience. In an experiment with a 2AFC task, for example, participants might expect both response options to occur about equally often. This might lead participants to adjust response biases based on the sequence of most recently observed categories.</p><p>The simplified model in <ref type="figure">Figure 4</ref> captures these response biases-regardless of whether they reflect priors based on the relative frequency of categories, meta-reasoning about the structure of experiments, or other factors-through the parameters . For a -way categorical outcome, this</p><p>introduces − 1 degrees of freedom (since Σ = 1) that cannot be independently estimated from phonetically annotated databases. These parameters can, however, often be set based on assumptions about the current task as well as on the extent to which prior expectations about natural language transfer to this task. For example, standard experimental designs provide participants with ample evidence that prior expectations based on the relative frequency of lexical items in natural language use do not transfer to the experiment (cf. <ref type="bibr" target="#b99">Jaeger, 2010)</ref>. In such contexts, participants might quickly come to adjust their expectations and employ uniform response biases.</p><p>In addition to response biases, the categorization model in <ref type="figure">Figure 4</ref> includes the possibility that listeners sometimes respond independent of the stimulus. As we will show below, this is a critical addition that affects what types of behavioral changes can be explained by changes in decision biases. Stimulus-independent responses can occur, for example, because of attentional lapses. On such occasions, the response is only influenced by the response biases. Lapsing models without consideration of response biases have previously been used in some analyses of exposure effect on speech perception . For the present purpose, we further assume that these response biases on lapsing trials are identical to the response biases on non-lapsing trials. Assuming equal priors for all alternative categories, this yields the following simplified model of the joint effect of attentional lapses and response biases, where is lapse rate-the probability of lapsing: 6</p><p>6 Readers familiar with psychometric models might recognize the close relation between Equation (2) and the standard psychometric model in <ref type="bibr" target="#b300">Wichmann and Hill (2001)</ref>:</p><formula xml:id="formula_2">+ (1 − − ) ( | , ).</formula><p>In the Wichmann and Hill model, describes the floor and 1 − describes the ceiling probability. In Equation <ref type="formula">2</ref>, is the lapse rate and determines how the lapses (and non-lapses) are affected by response biases, resulting in a floor of and a ceiling of 1 − (1 − ). For the special case of two Gaussian categories with identical variance along a unidimensional cue continuum, Equation (2) can be described by <ref type="bibr">Wichmann and</ref> Hill's psychometric model if the</p><formula xml:id="formula_3">( | ) = (1 − ) ( | , Σ ) Σ ( | , Σ ) + Σ (2)</formula><p>In <ref type="figure">Figure 4</ref>, the fact that response bias affect listeners' responses in both lapsing and non-lapsing trials is indicated by the two arrows leaving from . <ref type="figure" target="#fig_4">Figure 7</ref> visualizes the effects of the two parameters and for a 2AFC categorization task.</p><p>The final part of ASP's categorization model is the decision rule that takes the posterior in Equation <ref type="formula">2</ref>as input and returns a response. Here, we follow a common assumption in research in speech perception and employ Luce's choice rule (R. D. <ref type="bibr" target="#b153">Luce, 1959</ref>; for a comparison of decision rules, see <ref type="bibr" target="#b160">Massaro &amp; Friedman, 1990)</ref>. Under this decision rule, the predicted distribution of responses is identical to the posterior in Equation (2). For example, in a 2AFC categorization task, a posterior probability of .3 for /d/ and .7 for /t/ would result in a /d/-response with .3 probability or a /t/-response with .7 probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The change models ('adaptation'/'learning')</head><p>This completes the description of the categorization model in <ref type="figure">Figure 4</ref>. For any parameterization of , , , Σ , and , this model takes acoustic stimuli as input and returns predictions about the expected response distribution (e.g., 30% /d/-responses and 70% /t/-responses). In practice, all but one of these parameters (the lapse rate ) can either be independently estimated from phonetically annotated databases ( , Σ , and ) or assumed to have certain values (e.g., uniform response biases ), leaving a single parameter that must be estimated from perceptual data.</p><p>Next, we extend this model to capture changes at any of the three mechanistic levels. That is, we specify change models that describe how , , Σ , and can change with exposure. It is these change models that make it possible to use ASP to derive predictions for human responses following exposure-for example, during the test phase of an experiment on perceptual recalibration or accent adaptation (see <ref type="figure">Figure 3)</ref>. Together, the three change models introduce a total of four new parameters that must be estimated from perceptual data, all of which can be perceptual model is set to be a logistic function with appropriate choice of its threshold and slope (cf. <ref type="bibr">Kleinschmidt &amp; Jaeger, 2015, p. 200)</ref>. For unequal variances and/or additional cue dimensions, additional s are required.  . Illustrating the effects of and on the posterior probability of /d/, using the two bivariate Gaussian categories of /d/ and /t/ shown in <ref type="figure" target="#fig_2">Figure 6b</ref>. The colored planes indicate the ceiling and flooring levels of posterior probability of /d/. Panel a) here is identical to Panel e) in <ref type="figure" target="#fig_2">Figure 6with</ref> = 0 and / / = .5. Top panel: Differences in lapse rate for a uniform bias of / / = .5. As the lapse rate increases, the ceiling and flooring responses at the end points change while the categorization slope remains the same. Bottom panel: Differences in bias / / when the lapse rate = .2. As the bias towards /d/ changes from 0.1 to 0.9, the categorization surface shifts upwards and to the right, resulting in more /d/ responses across the phonetic space. understood as related to learning rates.  here substitutes in <ref type="figure">Figure 4</ref> (removing those degrees of freedom from the categorization model). While we mark the prior cue mean 0 as a latent variable, it can be estimated from phonetic databases (as we do in Case Studies 1 and 2), leaving 0 as the only degree of freedom for this change model. C-CuRE and most other models of normalization assume that the theoretical quantities employed in normalization-for C-CuRE, the means of all cues-are known to the listeners (e.g., . However, listeners must somehow infer these quantities from the observed inputs (see also Section 3.3 in . For example, in the types of experiments we consider below, listeners need to infer the unfamiliar talker's cue means from the inputs observed during exposure. At the beginning of exposure, the best estimates of the cue means for the unfamiliar talker are the mean expected based on listeners' longterm experience with various different talkers ( 0 ). With increasing exposure to the unfamiliar talker, listeners can update their estimates of the talker's cue means based on the input. ASP thus expands C-CuRE with a linking hypothesis that describes how listeners update their estimates of the unknown mean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Modeling changes in normalization</head><p>Some proposals for such functions include moving-window algorithms that estimate the mean as the sample mean over a finite number of the most recent observations <ref type="bibr" target="#b142">(Lee et al., 2002;</ref><ref type="bibr"></ref> K. <ref type="bibr" target="#b317">Zhang &amp; Peng, 2021)</ref>. Here, we model listeners' estimate of the talker-specific cue mean after observations from that talker as simple linear interpolation between the cue mean observed in previous longterm experience ( 0 ) and the mean observed in the sample observed from the unfamiliar talker (). This approach has the advantage that listeners can draw on prior experience when they do not yet have much (or any) data from an unfamiliar talker. They can then update the inferred cue mean as they observe further data from the talker (see discussion of the flexibility-stability trade-off in <ref type="bibr">Kleinschmidt &amp; Jaeger, 2015, p. 178-182)</ref> <ref type="figure" target="#fig_6">Figure 8</ref> expresses Equation <ref type="formula">3</ref>as a graphical model. The two parameters describing the input from the unfamiliar talker, and, are determined by the exposure data used in the experiment (the estimation of the cue means,̄requires that the exposure stimuli are phonetically annotated). 0 can be estimated from sufficiently large phonetically annotated databases of speech, essentially assuming that listeners have learned the overall cue means across talkers from previously experienced speech input. This is what we did to create <ref type="figure">Figure 5</ref>, and it is what we assume in the remainder of this study. This leaves only one degree of freedom that is not independently determined: the relative weight of previous experience compared to the input received from the talker so far ( 0 ). This is the parameter we vary in the case studies presented below to illustrate the types of results that can be explained through changes in normalization due to recent exposure.</p><formula xml:id="formula_4">: = 1 0 + ( 0 0 +) = 0 0 + 0 + 0 +̄( 3)</formula><p>One important characteristic of normalization that we will return to in the general discussion is that it applies to cues regardless of the category they originate from/map into. On the one hand, this makes normalization potentially very efficient, by considering all available information about a cue, rather than just observations of a specific category . On the other hand, this limits what types of changes in the mapping from cues to categories normalization can account for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Modeling changes in category representations</head><p>Just like listeners need to infer an unfamiliar talker's overall cue mean for normalization, listeners who learn talker-specific representations need to infer the category means and covariance matrices of the unfamiliar talker. That is, changes in representations can be described as the process of inferring the talker's category likelihood. A theory of this inference process-the ideal adaptor-is introduced in . Bayesian belief-updating models based on this theory have been shown to provide a good qualitative and quantitative fit against human responses in experiments on perceptual recalibration <ref type="bibr" target="#b125">(Kleinschmidt &amp; Jaeger, 2011</ref>; for closely related models, see , selective adaptation , unsupervised or semi-supervised distributional learning (e.g., <ref type="bibr" target="#b118">Kim et al., 2020;</ref>; for closely related model, see <ref type="bibr" target="#b9">Bejjanki et al., 2011;</ref>, and accent adapation <ref type="bibr" target="#b86">(Hitczenko &amp; Feldman, 2016</ref>; for a closely related model, see . However, as outlined in the introduction, an explicit comparison with alternative models that change normalization or response biases has been lacking.</p><p>The belief-updating model describes the inference of category means and category variances in ways that are conceptually similar to the type of interpolation we described in Equation <ref type="formula">3</ref>, by combining knowledge based on previously experienced speech input with the observations made from the unfamiliar talker. The specific instance of the model we use here-belief-updating over a Normal-Inverse-Wishart ( −1 ) prior )-describes the uncertainty listeners have about the category means and category covariance matrices Σ prior to any observations from an unfamiliar talker as a function of four variables <ref type="bibr">(Murphy, 2012, p. 132-3)</ref>:</p><formula xml:id="formula_5">( , Σ | ) = −1 ( , Σ |m ,0 , ,0 , ,0 , S ,0 ) = ( |m ,0 , 1 ,0 Σ ) × −1 (Σ |S ,0 , ,0 )<label>(4)</label></formula><p>The Normal part of the −1 model describes the uncertainty about the category mean , the Inverse-Wishart part describes the uncertainty about the category covariance Σ . For the former, m ,0 is the mean of the normal distribution describing the uncertainty about the category mean , and ,0 indicates the extent to which listeners transfer their prior beliefs about the category mean to the present input. The larger ,0 is, the more certain listeners are about the category mean even prior to any observation, and the less their inferences about the talker's category mean will be influenced by observations from the talker. Put differently, larger ,0 predicts slower learning of changes in the category mean. Similarly, S ,0 is the scale matrix of the Inverse-Wishart-having a conceptually similar function to the mean m ,0 of the Normal distribution-and ,0 indicates extent to which listeners transfer their prior beliefs about the category covariance to the present input. Just as larger ,0 predicts slower learning of changes in the category mean, larger ,0 predicts slower learning of changes in the category covariances.</p><p>In practice, researchers can estimate the m ,0 s and the S ,0 s such that they yield the distribution of category means and covariances that would be expected given listeners' previous long-term experience (see SI, §3.1). This leaves two degrees of freedom to model changes in each category's likelihood, ,0 and ,0 . We further follow previous work to make the simplifying assumption that all categories have the same prior ,0 and ,0 , leaving just two degrees of freedom across all categories to model changes in representations. These are the two parameters we vary in the case studies presented below to illustrate the types of results that can be explained through changes in representations. <ref type="figure">Figure 9</ref> demonstrates how ,0 and ,0 affect the uncertainty about the category likelihoods for the simple case of univariate Gaussian categories along a single cue dimension (VOT). The case studies we present below employ bivariate Gaussian categories along f0 and VOT.</p><p>As listeners observe additional information from the unfamiliar talker, they update their beliefs (and thus uncertainty) about the distribution of that talker's category means and covariances by integrating their prior beliefs with the observed input from the unfamiliar talker.</p><p>The updating formula for each parameter is given in the SI ( §3.1) and visualized in <ref type="figure">Figure 35</ref>.</p><p>Figures 11 and 12 illustrate how speech input from a talker with unexpected pronunciations changes listeners' beliefs about the category likelihoods and, consequently, their categorization functions. We exposed the four models from <ref type="figure">Figure 9</ref>-each of which reflects the expected category means and variances derived from , but with different certainty-to input from a talker with unexpected pronunciations of /d/ and /t/. Specifically, the talker's /d/ and /t/ categories were shifted by +25 msecs VOT compared to a (C-CuRE normalized) talker in  data. Additionally, the talker's /t/-category exhibited half the variance found in <ref type="bibr">Chodroff and Wilson' data.</ref>   <ref type="figure">Figure 9</ref>. Illustrating the effects of ,0 and ,0 on the uncertainty about the category means and variances Σ for univariate /d/ and /t/ categories along VOT. The four priors have identical expected category means (E( / / ), E( / / )) and variances (E( / / ), E( / / ))-set to match the average of the C-CuRE normalized category means and covariance matrices obtained from the data in , and indicated by black points. The four priors differ, however, in their uncertainty about the category means and variances and thus in the changes they predict to occur when exposed to input from an unfamiliar talker. The more uncertain a listener is about the category means and variances of an unfamiliar talker (smaller ,0 and ,0 ), the quicker that listener will adjust their expectations based on the inputs observed from that talker (see <ref type="figure">Figures  11 and 12</ref>). Density lines are drawn at 10 −3 to 10 −10 at powers of 10.</p><p>talker. Models with weak prior beliefs about category means ( ,0 = 4) accommodate the unfamiliar speech input by changing beliefs about the category mean-shifting categories 'horizontally'. Models with weak prior beliefs about category variance ( ,0 = 4) accommodate the unfamiliar speech input by changing beliefs about the category variance-expanding the category. This is particularly apparent for the /d/ category. <ref type="figure">Figure 12</ref> demonstrates the consequences of these changes for the expected categorization function.</p><p>Unlike normalization, changes in category representations can capture category-specific changes in cue distributions. As we lay out in more detail in the general discussion, this makes representational changes computationally less parsimonious than normalization but also more expressive: there are ways in which talkers might differ from each other that can be better , and Σ , here substitutes and Σ in <ref type="figure">Figure 4</ref> (removing those degrees of freedom from the categorization model). While we mark the prior m ,0 and S ,0 as latent variables, they can be estimated from phonetic databases (as we do in Case Studies 1 and 2), leaving ,0 and ,0 as the only degrees of freedom for this change model. A more detailed graphical model is provided in the SI ( §3.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Modeling changes in decision-making</head><p>Finally, we specify a linking hypothesis for changes in response biases. To the best of our knowledge, this problem has not previously been formalized for speech perception. The change model we propose is, however, very similar to the conceptual proposal of <ref type="bibr" target="#b251">Sohoglu and Davis (2016)</ref>, who describe adaptation to degraded speech as changes in decision-making. These changes are assumed to be a function of the prediction error experienced during processing, when the category label is encountered or inferred from context (for discussion, see also . The proposed change model for decision-making is thus a form of error-based learning, as implemented for other learning problems in connectionist <ref type="bibr" target="#b28">(Chang et al., 2006;</ref><ref type="bibr" target="#b164">McClelland &amp; Elman, 1986;</ref><ref type="bibr" target="#b223">Rumelhart &amp; Mcclelland, 1986)</ref>, Bayesian , information theoretic <ref type="bibr" target="#b101">(Jaeger &amp; Snider, 2013)</ref>, and predictive coding models <ref type="bibr" target="#b214">(Rao &amp; Ballard, 1999;</ref><ref type="bibr" target="#b254">Sohoglu et al., 2012</ref>; for review, see <ref type="bibr" target="#b33">Clark, 2013)</ref>.</p><p>Consider a typical experiment on accent adaptation. A listener unfamiliar with the L2 <ref type="figure">Figure 11</ref>. Illustrating the effects of ,0 and ,0 on changes in the expected category likelihoods, assuming a binary phonetic contrast between two Gaussian categories (/d/-/t/) along a unidimensional continuum (VOT). Updating is shown for the data points in the rug along the x-axis: 20 observations each of /d/and/t/ from a talker who realized both categories with a shifted mean of 25 msec, and exhibits typical variance for /d/ but only half of the typical variance for /t/. We set the lapse rate = 0 and response biases to uniform ( ,0 = .5). Animation controls require Acrobat PDF reader. accent will initially miscategorize the L2-accented inputs. Typically, these errors will not be random but rather exhibit directionality. For example, in experiments on Mandarin-accented English, L1-English participants initially mishear voiced syllable-final stops as voiceless (e.g., hearing lid as lit, <ref type="bibr" target="#b64">Flege et al., 1992;</ref>. Critically, experiments of this type tend to employ exposure stimuli that effectively label the intended category of the stimulus (e.g., lemona_e). Participants thus receive an error signal, indicating how much their expectations based on the acoustic input mismatched the intended (labeled) category. Participants can use this prediction error-operationalized here as the surprisal ( | ) of the category label given the acoustic input-to adapt the biases for all categories. For the present example, participants would increase the bias for the labeled category (/d/ in this example) and decrease the bias for all other categories, thereby improving their recognition accuracy for the L2-accented speech. 7 With each exposure observation, the log-odds for the intended category increase by an amount jointly <ref type="bibr">7</ref> We thank Zach Burchill for bringing this possibility to our attention.  <ref type="figure">Figure 12</ref>. Changes in expected categorization functions resulting from the changes in the expected category likelihoods in <ref type="figure">Figure 11</ref>. We set the lapse rate = 0, the prior lapse biases to uniform ( ,0 = .5). Neither normalization, nor response biases changed as a function of the input. Animation controls require Acrobat PDF reader.</p><formula xml:id="formula_6">κ /d/ , 0 = κ /t/ , 0 = 4 κ /d/ , 0 = κ /t/ , 0 =</formula><p>determined by the prediction error and the change/learning rate ( ), with larger prediction errors and larger s resulting in larger changes (for details, see SI, §3.2). We note that this makes our change model for decision-making sensitive to the order of exposure, unlike the two change models presented so far. We return to this issue in our case studies.    <ref type="figure">Figure 13</ref>. Graphical representation of change model for decision-making. , here substitutes in <ref type="figure">Figure 4</ref> (removing those degrees of freedom from the categorization model). refers to the surprisal experienced when the acoustic input is recognized (from context) to be of category .</p><formula xml:id="formula_7">κ /d/ , 0 = κ /t/ , 0 = 4 κ /d/ , 0 = κ /t/ , 0 =</formula><p>non-additive changes in the posterior log-odds. This is illustrated in <ref type="figure" target="#fig_11">Figure 15</ref>. Once the possibility of non-zero lapse rates is considered, changes in the slope of the categorization function (even in log-odds) therefore do not rule out explanations in terms of changing response biases.</p><p>This does not mean that changes in decision-making can explain arbitrary types of adaptive behavior. In the general discussion, we demonstrate that even with non-zero lapse rates, there are strong constraints on the type of adaptive behavior that can be explained by changes in decision-making (for further visualization, see also SI §3.2.1). It does, however, mean that changes in decision-making can explain a wider range of behaviors than is typically considered, and we will see examples of that in our case studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Next in this theater: overview of case studies</head><p>Next, we present two case studies that illustrate the predictions of the three change models for two types of paradigms that have been particularly influential: perceptual recalibration (Case Study 1) and accent adaptation (Case Study 2). <ref type="figure" target="#fig_2">Figure 16</ref> summarizes how we will use ASP in these two case studies to derive predictions about listeners' behavior.</p><p>ASP can be used to predict changes in perception from weighted combinations of all three change mechanisms. In the general discussion, we outline why this ability to make predictions based on combinations of mechanisms will likely be critical in moving the field forward. In that context, we discuss how future work can use ASP to address more advanced questions about the factors that determine the relative engagement of the three mechanisms-by investigating how the ASP parameters ( 0 , ,0 , ,0 , and ) that best explain human behavior depend on factors such as stimulus properties, task demands, and individual differences between listeners. <ref type="figure" target="#fig_10">Figure 14</ref>. Illustrating the effects of on changes in the categorization function (Left: posterior probability, Right: posterior log-odds). The model has the same uncertain prior beliefs about category mean and variances as the model in <ref type="figure">Figure 9D</ref> ( ,0 = ,0 = 0). Neither normalization nor prior beliefs about the categories changes as a function of exposure. We set the lapse rate = 0, the prior lapse biases to uniform ( ,0 = .5). The input to this change model is identical to what was used in <ref type="figure">Figures 11 and 12</ref>. In the left panel, orange arrows indicate changes in the category boundary (point of subjective equality) for = 1. In the right panel, orange arrows indicate the distance between the posterior log-odds resulting from the two most extreme s. This highlights the fact that changes to response biases have additive effects on the log-odds of /d/ responses when = 0. Animation controls require Acrobat PDF reader.  <ref type="figure" target="#fig_2">Figure 16</ref>. The ASP framework can be used to derive predictions, or to fit to human behavior. ASP's change models describe how ASP's categorization model is predicted to change based on the inputs experienced during exposure. The updated categorization model can then be used to predict listeners' response distributions for any test token (as we do in Case Study 1), and/or to predict listeners' recognition accuracy (as we do in Case Study 2). As described in the text, researchers can choose to set some of ASP's parameters based on phonetic databases. By doing so, researchers commit to the assumptions (i) that listeners learn and store some statistics of previously experienced speech input, and (ii) that the database is a sufficiently good approximation of those statistics for an average listener in the experiment. Setting parameters based on phonetic databases reduces the degrees of freedom and functional flexibility of ASP's change models, leading to stronger (more easily falsifiable) predictions. This is the approach we employ in our case studies.</p><p>For our two case studies, however, we deliberately only consider ASP models that employ one of the three change mechanisms at a time. This allows us to assess which of the three mechanisms are sufficient, and which ones are insufficient, to explain the signature results of the two paradigms. Of particular theoretical interest is whether it is indeed the case that the computationally least parsimonious change model, changes in category representations, is the only model that can explain the signature results of both perceptual recalibration and accent adaptation paradigms (as seems to be often assumed).</p><p>Beyond this specific question, we use the two case studies to (i) illustrate how intuitions about the types of results each mechanism can(not) account for can be misleading, and (ii) to</p><p>show how ASP can be used to inform researchers' intuitions, by predicting the effects of recent exposure on subsequent speech perception. For these reasons, both case studies focus on qualitative comparison of ASP's predictions against the signature results from each paradigm, documented in previously published perception experiments (in the general discussion, we show how ASP can be used to compare change models in terms of their quantitative fit against listeners' behavior). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Case Study 1: perceptual recalibration</head><p>In a typical perceptual recalibration experiment, participants are randomly assigned to one of two exposure groups that subsequently perform the same test. During exposure, participants hear stimuli that contain a critical phonetic contrast (e.g., syllable-intial /d/ vs. /t/, as in crocodile or cafeteria, , mixed with many fillers that do not contain that phonetic contrast. Between participants, critical exposure stimuli are manipulated with the goal to shift the category boundary along the phonetic contrast into different directions. This is achieved by exposing listeners to typical pronunciations from one category and pronunciations of the other category that are acoustically shifted towards the point of maximal perceptual ambiguity between the two categories. Which of the two categories is shifted is manipulated between the two exposure groups. To ensure that the shifted stimuli are still recognized as instances of the intended category, exposure stimuli are typically lexically or visually labeled (e.g., hearing the shifted sound /?dt/ embedded in the lexical context of "croco_ile" would label the shifted sound as a /d/). In a subsequent test phase, both groups of participants then categorize the same test stimuli along an artificially generated acoustic continuum between the two categories. The goal of this test phase is to estimate participants' categorization function for the critical phonetic contrast, and so test stimuli are unlabeled. This is achieved by presenting the manipulated continuum in the contexts of a lexical minimal pair (e.g., dip-tip) or a nonce-word pair (e.g., idi-iti).</p><p>For example, an influential study by  exposed participants to either shifted /d/ and typical /t/ or shifted /t/ and typical /d/. Participants saw 20 typical and 20 shifted tokens (mixed with 160 fillers). Following exposure, participants in both conditions categorized non-word tokens (/ɪdɪ/-/ɪtɪ/) tokens along a six-step /d/-/t/ continuum. <ref type="figure" target="#fig_4">Figure 17</ref> shows the results obtained by . 8 Although relatively small, a significant perceptual recalibration effect was observed: participants in the /d/-shifted exposure condition were more likely to give "d"-responses, resulting a categorization function that is shifted rightwards relative to participants in the /t/-shifted condition. This shift in the category boundary is the signature of perceptual recalibration experiments.</p><p>Perceptual recalibration continues to be one of the most frequently used paradigm in research on adaptive speech perception. A recent review cites over 200 studies using variants of this paradigm <ref type="bibr" target="#b274">(Theodore, 2021)</ref>. Boundary shifts like those in <ref type="figure" target="#fig_4">Figure 17</ref> (though often larger) have been demonstrated for an increasing number of phonetic contrasts and languages (e.g., <ref type="bibr" target="#b262">Sumner, 2011a</ref>;   <ref type="bibr">replotted from Kraljic &amp; Samuel, 2007, Figure 1)</ref>. No error bars were provided in the original, and the original data are no longer available <ref type="bibr">(Samuel, p.c.)</ref>. . We now know that boundary shifts can occur for both isolated and connected speech (e.g., <ref type="bibr" target="#b51">Eisner &amp; McQueen, 2005;</ref><ref type="bibr" target="#b216">Reinisch &amp; Holt, 2013)</ref>, even after fewer shifted tokens (e.g., as few as four, L.  or under cognitive load <ref type="bibr" target="#b3">(Baart &amp; Vroomen, 2010;</ref><ref type="bibr" target="#b318">X. Zhang &amp; Samuel, 2014</ref>; but see <ref type="bibr" target="#b227">Samuel, 2016)</ref>, and that they can persist over hours and days <ref type="bibr" target="#b52">(Eisner &amp; McQueen, 2006;</ref><ref type="bibr" target="#b226">Saltzman &amp; Myers, 2021;</ref><ref type="bibr" target="#b288">Vroomen &amp; Baart, 2009)</ref> though they eventually decay . More recent work has begun to identify the brain regions involved in perceptual recalibration, which range from primary auditory cortex and superior temporal cortices <ref type="bibr" target="#b17">(Bonte et al., 2017;</ref><ref type="bibr" target="#b116">Kilian-Hütten et al., 2011;</ref><ref type="bibr" target="#b182">Myers &amp; Mesite, 2014;</ref><ref type="bibr" target="#b284">Ullas, 2020)</ref>, to more frontal and parietal areas <ref type="bibr" target="#b154">(Luthra et al., 2020;</ref><ref type="bibr" target="#b182">Myers &amp; Mesite, 2014;</ref><ref type="bibr"></ref> Ullas, 2020; for review, see <ref type="bibr" target="#b75">Guediche et al., 2014)</ref>.</p><p>While the signature boundary shift observed in perceptual recalibration experiments is often considered the consequence of representational changes, it is also possible that this finding is compatible with explanations in terms of either of the two alternative change mechanisms. We use ASP to assess this possibility. Specifically, we predict changes in categorization following the type of exposure employed in experiments on perceptual recalibration, while switching on and off the three different change models of ASP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>Most published experiments on perceptual recalibration do not measure and report the acoustic properties of their stimuli. We therefore generate data based on the same procedure that experimenters use to create and select the stimuli for perceptual recalibration experiments. The details of our stimulus generation approach, which closely follows the procedure described in , are described in the SI ( §4). These details do not affect the general results we present below. They are merely meant to provide a sufficiently concrete example.</p><p>Readers can revisit any of the assumptions we made by downloading the R markdown document that this article is generated from. Readers familiar with perceptual recalibration experiments might find <ref type="figure" target="#fig_6">Figure 18A</ref> puzzling at first glance: the conventional way of visualizing the results of perceptual recalibration experiments wrongly suggests that the targeted phonetic contrast falls along a single acoustic continuum (see, e.g., <ref type="figure" target="#fig_4">Figure 17</ref>). This is, however, rather unlikely to be the case: phonetic contrasts tend to vary along multiple phonetic dimensions (e.g., <ref type="bibr" target="#b64">Flege et al., 1992;</ref>; for a particular powerful demonstration, see . For the phonetic contrast at hand, VOT is known to be the primary cue to syllable-initial stop voicing in L1 US English, but f0 and other cues also affect listeners' categorization responses (e.g., <ref type="bibr" target="#b278">Toscano &amp; McMurray, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Exposure phase</head><p>Although not strikingly evident in <ref type="figure" target="#fig_6">Figure 18A</ref>, this also applies to the /d/-/t/ contrast: /d/ and /t/ vary along both VOT and f0 among other cues (e.g., <ref type="bibr" target="#b119">Kirby et al., 2020;</ref>.  <ref type="figure" target="#fig_6">Figure 18</ref>. Distribution of the exposure and test of the perceptual recalibration experiment. Panel A -Exposure: 20 tokens each of shifted and typical /d/ and /t/, respectively. Arrows indicate how the shifted tokens created by the experimenter differ from typical tokens of the same category (arrows originate from the mean of typical tokens and end at the mean of shifted tokens). As would be expected given the procedures researchers typically employ to generate stimuli for this type of experiment, the exposure distributions for /d/ and /t/ in both conditions differ primarily along VOT but, notably, also differ along f0. Panel B -Test (identical for both exposure groups):</p><p>Numbers indicate the item ID of the test tokens used in subsequent plots, with IDs in increasing order corresponding to 85%, 65%, 55%, 45%, 35%, 15% expected /d/-responses prior to exposure (e.g., in a test-only norming experiment).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Test phase</head><p>The test phase consists of the six stimuli shown in <ref type="figure" target="#fig_6">Figure 18B</ref>, chosen to yield 15%, 35%, 45%, 55%, 65%, 85% expected /d/-responses in a norming experiment without any prior exposure to the talker's speech. This closely resembles the test stimulus placement typical for perceptual recalibration experiments, which tend to examine tokens at the two ends of the continuum as well as those placed near the category boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Next, we use ASP to illustrate to what extent changes in representations, response biases, or normalization can explain the typical behavioral signature of perceptual recalibration experiments: a shift in the category boundary in the same direction as the shifted tokens during exposure (optionally accompanied by a change in the slope of the categorization functions). The goal of these computational demonstrations is to illustrate the general type of pattern that the three different hypotheses can account for.</p><p>All three change models start from the same prior state. Specifically, we assume that listeners have acquired category representations with expected category means (E( / / ), E( / / )) and variances (E( / / ), E( / / )) that reflect the talker-normalized distributions in <ref type="bibr">Chodroff and</ref> Wilson (2018; see <ref type="figure" target="#fig_2">Figure 6</ref>). Prior to any exposure, decision-making is assumed to employ uniform response biases ( / / = / / = .5). Here and throughout this article, we marginalize over the expected consequences of perceptual noise, attentional lapses, and decision-making (both for adaptation during exposure and for categorization during test). This can be seen as predicting the state of an 'average' listener after exposure to a specific set of stimuli. 9 The findings we present below do not qualitatively depend on these specific assumptions.</p><p>Finally, we note that our simulations predict categorization at the beginning of the test phase, prior to repeated testing. This should be kept in mind when comparing our results against previous work, including the results of  in <ref type="figure" target="#fig_4">Figure 17</ref>. As is typical for experiments on perceptual recalibration, participants in Kraljic and Samuel's experiment heard the same six test tokens many times. In their visualizations and analyses, Kraljic and Samuel averaged participants' responses across these repetitions. While this approach continues to be the norm, it is now known to underestimate the true boundary shift, as repeated testing reduces the effects of exposure (L. <ref type="bibr" target="#b172">Mitterer et al., 2011;</ref><ref type="bibr" target="#b234">Scharenborg &amp; Janse, 2013;</ref><ref type="bibr"></ref> for early discussion, see <ref type="bibr">Norris et al., 2003, p. 11)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Changes in representations</head><p>We begin by modeling exposure-driven changes in the mapping from VOT and f0 to the /d/ and /t/ categories. This is arguably the mechanism that is most commonly assumed to underlie the boundary shift observed in perceptual recalibration experiments. Specifically, we use the −1 ideal adaptor model described in Section 2.2.2 while varying the ,0 and ,0 parameters. We set 9 For any particular experiment, however, researcher have to estimate, e.g., participants' categorization functions from their categorization responses. This is important to keep in mind, for example, when using ASP to estimate the statistical power of an experiment. To support predictive power simulations, the ASP functions provided on OSF also allow simulations that sample the effects of perceptual noise, attentional lapses, and decision-making for adaptation and categorization. This allows simulations of trial-level behavior for individual participants.</p><p>the other two parameters of the −1 ideal adaptor (m and S) so that they match the expected mean and covariance of the data in Chodroff and Wilson (2018) (as we did in Section 2.2.2).</p><p>Normalization and response biases did not change based on exposure ( 0 = ∞; = 0), and attentional lapses were assumed to be zero ( = 0). <ref type="figure">Figure 19</ref> shows the predicted categorization functions after /d/-shifted and /t/-shifted exposure, depending on the strength of the prior beliefs for the category means and variances. We show the results for ,0 s and ,0 s ranging from 1024 (very slow learning) to 4 (very fast learning). These values are best understood in the context of the number of critical exposure stimuli. Given 20 exposure tokens for each category, a ,0 = 20 would mean that the listeners' beliefs about the distribution of the category mean after exposure is a 50/50 mix of their beliefs prior to exposure and the mean of the exposure stimuli (see Equation <ref type="formula" target="#formula_5">4</ref>). For ,0 = 4, listeners'</p><p>beliefs about the category mean are thus primarily determined by the mean of the exposure stimuli, whereas a ,0 = 1024 essentially means that exposure does not affect listeners' belief about the category mean at all (and mutatis mutandis, for ,0 ). <ref type="figure">Figure 19</ref> demonstrates that distributional learning can account for the typical result of perceptual recalibration experiments. Of note, the range of parameterizations that best fit human responses in a series of distributional learning experiments on /b/ and /p/ (gray panel in <ref type="figure">Figure   19</ref>, / /,0 = / /,0 = 160 (95% CI: 75-780) and / /,0 = / /,0 = 510 (95% CI: 160-1000), Kleinschmidt, 2020) also provides a good qualitative fit against the /d/-/t/ perceptual recalibration results by . <ref type="figure">Figure 19</ref> further shows that boundary shifts can result from either changes in the beliefs about category means (small ,0 , e.g. right column of <ref type="figure">Figure 19</ref>) or changes in the beliefs about category covariances (small ,0 , e.g., bottom row in <ref type="figure">Figure 19</ref>). This replicates an observation made in <ref type="bibr">Kleinschmidt and Jaeger (2015, p. 168</ref>; see also 2016; 2019), and highlights that "category expansion" and "category shifts" can both be seen as consequences of distributional learning (see also <ref type="bibr" target="#b10">Bent &amp; Baese-Berk, 2021;</ref>. <ref type="figure" target="#fig_16">Figure 20</ref> serves to further clarify how the different parameter settings for ,0 and ,0 affect the expected category likelihoods for a subset of the panels of <ref type="figure">Figure 19</ref>, leading to category shifts, expansion, shrinkage, or rotation, depending on both the model parameters and the input during exposure.  <ref type="figure">Figure 19</ref>. Predictions of a learning model that derives perceptual recalibration as changes in category representations. Predicted categorization responses are shown for the 6 test tokens after /d/-and/t/-shifted exposure, depending on the strength of the prior beliefs in categories means ( ,0 ) and covariances ( ,0 ). Smaller ,0 and ,0 indicate faster learning, weighting previous longterm experience less during the integration with the observations made during the exposure phase of the experiment (see Equation <ref type="formula" target="#formula_5">4</ref>). The highlighted panel corresponds to the best-fitting ,0 and ,0 observed in previous work within other types of paradigms <ref type="bibr" target="#b124">(Kleinschmidt, 2020;</ref>.  <ref type="figure">Figure 19</ref> are shown. Specifically, we compare scenarios with very slow changes in representations (first column), fast changes in beliefs about the category means (leading 'category shifts', second and last column), and fast changes in beliefs about the category covariances (leading to 'category expansions', 'category shrinkage', and/or 'category rotation', third and last column).</p><formula xml:id="formula_8">κ /d/ , 0 = κ /t/ , 0 = 1024 κ /d/ , 0 = κ /t/ , 0 = 256 κ /d/ , 0 = κ /t/ , 0 = 64 κ /d/ , 0 = κ /t/ , 0 = 16 κ /d/ , 0 = κ /t/ , 0 = 4 ν /d/ , 0 = ν /t/ , 0 = 1024 ν /d/ , 0 = ν /t/ , 0 = 256 ν /d/ , 0 = ν /t/ , 0 = 64 ν /d/ , 0 = ν /t/ , 0 = 16 ν /d/ , 0 = ν /t/ , 0 =</formula><formula xml:id="formula_9">κ 0 , /d/ = κ 0 , /t/ = 1024 ν 0 , /d/ = ν 0 , /t/ = 1024 κ 0 , /d/ = κ , /t/ = 4 ν 0 , /d/ = ν 0 , /t/ = 1024 κ 0 , /d/ = κ 0 , /t/ = 1024 ν 0 , /d/ = ν 0 , /t/ = 4 κ 0 , /d/ = κ 0 , /t/ = 4 ν 0 , /d/ = ν 0 , /t/ = 4 /d/−shifted /t/−</formula><p>Finally, <ref type="figure">Figure 19</ref> shows that distributional learning not only predicts shifts in the category boundary but can also predict changes in the slope of those boundaries. This is evident, for </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Changes in decision-making</head><p>Next, we model the effects of changes in decision-making. Such changes have rarely been considered as an explanation for boundary shifts (but see <ref type="bibr" target="#b36">Clarke-Davidson et al., 2008)</ref>. In addition to varying the rate at which response biases change , we also vary the lapse rate parameter . Normalization and representations did not change based on exposure ( 0 = ,0 = ,0 = ∞). Since the change model for decision-making is sensitive to the order of stimuli during exposure (see Section 2.2.3), each panel of the figure averages over 50 simulations, each of them randomizing the order of exposure. We confirmed that this number of simulations was more than sufficient to achieve reproducible estimates for the range of s considered here (the order-sensitivity of the change model increases for faster change rates, i.e., larger ). <ref type="figure">Figure 21</ref> shows the effects of changes in response biases for lapse rates ranging from negligible lapse rates ( = .0005, top row) to a scenario in which listeners always lapse ( = 1). In the latter-rather implausible-edge case, listeners' responses only reflect response biases and are completely stimulus-independent (bottom row). For reference, lapse rates for perception experiments like the ones modeled here typically fall between 1-10% (e.g.,  constrained lapse rates to be &lt; 5%; Kleinschmidt &amp; Jaeger, 2016b, report a best-fitting value of 5%).</p><p>The primary insight from <ref type="figure">Figure 21</ref> is that changes in response biases can account for the type of boundary shift that is observed in perceptual recalibration experiments. This shows that the signature result of perceptual recalibration experiments is ambiguous between two explanations that evoke very different cognitive architectures. For this case study, perhaps the closest match to the findings from  is observed for plausible lapse rates up to 5% and small changes in response bias (second or third column, top rows).</p><p>Figure 21 also shows that changes in response biases do not necessarily result in effects that are symmetric around the uniform response biases assumed to hold prior to the experiment ( / / = / / = .5). For example for = .8, the /d/-shifted condition results in a /d/-bias of / / = .97, whereas /t/-shifted condition results in / / = .16 (≠ 1 − .97). This type of asymmetry is a consequence of the assumption that listeners change their response biases only when their categorization is in conflict with the category label indicated in the input (e.g., when the listener hears a /t/ but the lexical context is lemona_e). This means that the degree to which listeners change their response biases depends on the degree to which the acoustic properties of the exposure stimuli are in conflict with the lexical contexts they appear in.</p><p>Finally, <ref type="figure">Figure 21</ref> illustrates the effects of lapse rates. The higher the lapse rate, the more the overall response pattern is determined by the response biases, rather than by stimulus-dependent aspects. This also means that it can be important to keep lapse rates in mind  <ref type="figure">Figure 21</ref>. Predictions of a model that derives perceptual recalibration as changes in decisionmaking. Predicted categorization responses are shown for the 6 test locations after /d/-and/t/shifted exposure, depending on the rate at which response biases change ( ) and the rate of attentional lapses ( ). The response biases towards /d/ that results from are shown in the bottom row for each of the two exposure conditions, and are identical within each column (when all trials are lapses, as in the bottom row, the response distribution is identical to the response biases).</p><formula xml:id="formula_10">π /d/ = 0.5 π /d/ = 0.5 π /d/ = 0.52 π /d/ = 0.48 π /d/ = 0.62 π /d/ = 0.42 π /d/ = 0.72 π /d/ = 0.35 π /d/ = 0.85 π /d/ = 0.23 π /d/ = 0.96 π /d/ = 0.16 β π = 0 β π = 0.01 β π = 0.05 β π = 0.1 β π = 0.2 β π = 0.8 λ =</formula><p>when analyzing behavioral data. Consider, for example, a scenario in which listeners' lapse rates differ after /d/-shifted and /t/-shifted exposure-e.g., because one exposure condition resulted in a more difficult or less engaging task, or in less plausible stimuli. Compare, say, the blue line for = .05, = .005 against the red line for = .05, = .5. Analyses that fail to take into account the difference in lapse rates would wrongly conclude that the category representations have changed since the slopes of the categorization functions resulting from the two exposure conditions seem to differ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Changes in normalization</head><p>Finally, we compare a model that normalizes test tokens based on the phonetic inputs experienced during exposure to a model that continues to apply normalization based on previous long-term experience. The model that changes normalization based on the exposure tokens essentially subtracts the cue means experienced during exposure-which varies based on the exposure condition-from that of each of the test tokens. We implement this by adjusting the cue values of the test tokens by the difference between the prior mean of cues based on previously experienced input (estimated in the SI, §2) and the mean of cues experienced during exposure.</p><p>All other parameters have the same setting as in the previous sections, except that no changes in representations or response biases were considered.</p><p>To illustrate the consequences of normalization, we vary the only parameter of our change model for normalization, 0 . <ref type="figure">Figure 22</ref> illustrates the effect of normalization on the cue values of the test tokens. <ref type="figure">Figure 23</ref> shows the results of different speed in the changes of normalization.</p><p>Paralleling the results for changes in representations and response biases, changes in normalization can account for the signature boundary shift of perceptual recalibration experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Summary</head><p>We applied the three change models developed in Section 2 to a (simulated) perceptual recalibration experiment. We found that all three change models can qualitatively predict the type of boundary shift characteristic of such experiments. To us, and we imagine to many other researchers, this finding is surprising. On the one hand, all three change models were designed to <ref type="figure">Figure 22</ref>. Effects of changes in normalization on the perception of test locations, depending on the relative weighting of previous experience ( 0 ) during the inference of the cue mean during exposure. Normalization based on exposure results in a shift in the perception of the test stimuli. The magnitude of that shift depends on 0 , with larger shifts (more learning) for smaller 0 (see Equation (3)). Before we discuss what would be required to achieve this goal, we present the second case study using another common experimental paradigm.</p><formula xml:id="formula_11">κ 0 = 1024 κ 0 = 256 κ 0 = 64 κ 0 = 16 κ 0 =</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Case Study 2: accent adaptation</head><p>The second paradigm we consider focuses on naturally accented speech-e.g., dialectal <ref type="bibr" target="#b249">(Smith et al., 2014)</ref>, varietal <ref type="bibr" target="#b241">(Shaw et al., 2018)</ref>, or second language (L2) accents <ref type="bibr" target="#b19">(Bradlow &amp; Bent, 2008;</ref><ref type="bibr" target="#b243">Sidaras et al., 2009;</ref><ref type="bibr" target="#b299">Weil, 2001</ref>). Typically, exposure to an unfamiliar accent is compared to a control condition in which listeners are exposed to a familiar accent, most often the 'standard' variety of listeners' L1. Following exposure, listeners in either group are tested on the unfamiliar accent. In an influential study, <ref type="bibr" target="#b19">Bradlow and Bent (2008)</ref>   <ref type="bibr" target="#b6">-Berk et al., 2020)</ref>. We now know that substantially shorter exposure can lead to similarly large improvements in accuracy (e.g., 80 sentences in a single session, about 2-5 minutes of speech, , that these can persist over hours and days <ref type="bibr" target="#b303">(Witteman et al., 2015;</ref><ref type="bibr" target="#b308">Xie, Earle, &amp; Myers, 2018)</ref>, and that accent adaptation can sometimes generalize across talkers of the same or similar accents (e.g., <ref type="bibr" target="#b5">Baese-Berk et al., 2013;</ref><ref type="bibr" target="#b280">Tzeng et al., 2016;</ref>.</p><p>As in the case of perceptual recalibration, accent adaptation is often attributed to changes in category representations (e.g., <ref type="bibr" target="#b10">Bent &amp; Baese-Berk, 2021;</ref><ref type="bibr" target="#b243">Sidaras et al., 2009;</ref><ref type="bibr" target="#b265">Sumner &amp; Samuel, 2009;</ref><ref type="bibr" target="#b280">Tzeng et al., 2016;</ref>. This might in part be due to the intuition that the other change mechanisms are not sufficiently flexible to explain adaptation to complex differences between accents. For example, a common assumption seems to be that changes in decision/response biases can only explain trade-offs in accuracy: as the accuracy for one category improves, it has to inevitably decrease for all other categories. Under this trade-off assumption (which we show below to be false), changes in decision-making could not possibly explain overall improvements in recognition accuracy. Similarly, pre-linguistic normalization is rarely considered a plausible mechanism for accent adaptation. However, previous work has never actually put these intuitions to a test. Case Study 2 provides this test.</p><p>Compared to perceptual recalibration paradigms, experiments on accent adaptation exhibit more heterogeneity in their designs and tasks. Case Study 2 focuses on experiments in which treatment exposure employs a single talker with the unfamiliar accent, and the test phase heard by both groups of participants employs previously unheard stimuli from the same accented talker (e.g.,  </p><p>and other similar work. As in any experiment on accent adaptation, the results of our simulated experiment are expected to depend on the acoustic-phonetic characteristics of both the L1 and the L2 accent. In the discussion of Case Study 2, we thus consider other common differences between L1 and L2 accents, and show how these accent properties are expected to affect the three different change models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>The stimulus generation procedure is described in detail in the SI ( §5). <ref type="figure" target="#fig_17">Figure 24A</ref> shows the stimuli for the exposure and test phases of the experiment. In the L2-accented exposure condition, listeners hear word recordings containing L2-accented initial /d/ and /t/ (30 tokens per category). In the control condition with L1-accented exposure, listeners hear the same words but from an L1-accented talker. 12 For L1-accented exposure, the category likelihoods were set to match those observed in , after C-CuRE normalization (i.e., the distributions shown in <ref type="figure">Figure 5B</ref>). This follows the same approach we took for the typical tokens in Case Study 1. For L2-accented exposure, /d/ and /t/ categories</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Exposure phase</head><p>were created following the VOT and f0 statistics of Korean-accented US English reported in . The /d/ and /t/ categories in this L2 accent differ from L1-accented US English in both category means and variances. First, the VOTs of both stop categories are longer in the L2 accent, making the /d/s more similar to /t/s for native-English listeners who rely on VOT as a primary cue to voicing distinction. As a result, the recognition accuracy is expected to be lower for /d/ than for /t/ for the L1-accented exposure condition. Second, the L2-accented categories exhibit the same ordering along f0 as in L1-accented US English (lower f0 for /d/ than for /t/) but this difference along f0 is enhanced in Korean-accented US English. This makes syllable-initial stop voicing in Korean-accented US English a representative case of cue reweighting, a common difference between L2 and L1 accents that has received much attention in research on accent adaptation (e.g., <ref type="bibr" target="#b58">Escudero et al., 2009;</ref><ref type="bibr" target="#b118">Kim et al., 2020;</ref><ref type="bibr" target="#b236">Schertz et al., 2016;</ref><ref type="bibr"></ref> see also <ref type="bibr" target="#b79">Harmon et al., 2019;</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Test phase</head><p>During test, listeners from both exposure conditions hear the same recordings from the same L2-accented talker used in the L2-accented exposure condition. 60 test tokens are randomly sampled from the distribution of each L2-accented category, half from the /d/ category and half</p><p>12 The use of L1-accented exposure, rather than L2-accented exposure without /d/, as control follows a typical design in accent adaptation studies (e.g., <ref type="bibr" target="#b19">Bradlow &amp; Bent, 2008)</ref>, rather than . Xie and colleagues instead employed L2-accented exposure without /d/, using the same L2-accented talker as during test (see also . For the present purpose, both types of control conditions lead to identical predictions (as long as the L2-accented control exposure successfully avoids conveying non-negligible amount of information about the categories considered during the test phase) since the current implementation of the three change models do not consider talker-switch costs.</p><p>from the /t/ category ( <ref type="figure" target="#fig_17">Figure 24B</ref>). and are identical for the two exposure conditions. Ellipses show the 95% probability mass for the two categories in L2-accented exposure speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Paralleling Case Study 1, we ask which of the three change models can account for the signature results of accent adaptation experiments. Specifically, we assess for each change model whether it can explain the two types of signature results observed in, for example, Xie et al. <ref type="formula" target="#formula_12">2017</ref> As in Case Study 1, we first model changes in representations, and then compare them against changes in decision-making and normalization. We consider a larger range of parameterizations than in Case Study 1, because the models with the highest accuracy for L2-accented exposure (henceforth, the best-performing parameterization) in some cases fell outside of the parameter ranges considered in Case Study 1. These best-performing  <ref type="bibr" target="#b25">(Byrd et al., 1995</ref>, implemented in function optim() in R), and are indicated in all result plots we present below. <ref type="table" target="#tab_10">Table 1</ref> summarizes the parameter ranges considered by the optimization algorithm ( ,0 must be larger than the number of cues + 1, Murphy, 2012, p. 134). <ref type="bibr">13</ref> We emphasize that we use the term "best-performing" to refer to the parameterization that achieves the highest recognition accuracy for L2-accented test tokens, rather than the best fit against human responses in a perception experiment. In the general discussion, we describe how the same approach can be used to fit change models to the results of perception experiments. <ref type="figure" target="#fig_18">Figure 25</ref> shows the predicted categorization accuracy after exposure to L1-or L2-accented speech, as a function of the strength of the prior beliefs for the category means and variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Changes in representations</head><p>First consider the top left panel, where both ,0 s and ,0 have very high values. This simulates a very slow learner who has strong prior beliefs for both category means and variances such that the small number of tokens heard during exposure phase has minimal influence on subsequent perception of the L2-accented test tokens. Therefore, the performance from both L1-and L2-accented exposure conditions are identical, reflecting how a listener would categorize based on their long-term prior experience predominantly.</p><p>As ,0 s and ,0 get smaller (indicating weaker prior beliefs), the effects of exposure  become more noticeable and both of the signature results of experiments on accent adaptation begin to emerge. First, for L1-accented exposure, the accuracy is always predicted to be lower for /d/ than for /t/, indicating that /d/ is often misheard as /t/. Second, L2-accented exposure is predicted to improve recognition accuracy of /d/ compared to L1-accented exposure, and this improvement occurs without equivalent decreases in the recognition accuracy of /t/.Looking across the range of ,0 s and ,0 s, we make two more observations. First, for the scenario studied here, faster learning of category means improves recognition accuracy. When listeners' beliefs about category covariances are held constant (i.e., looking within each row), smaller ,0 values yield higher categorization accuracy. Second, faster updating of beliefs about the (co)variance also leads to accuracy improvements, although these improvements are less pronounced. Both results follow from the way that the Korean-accented stimuli differ from the L1 accented stimuli:</p><formula xml:id="formula_13">κ /d/ , 0 = κ /t/ , 0 = 4096 κ /d/ , 0 = κ /t/ , 0 = 1024 κ /d/ , 0 = κ /t/ , 0 = 256 κ /d/ , 0 = κ /t/ , 0 = 64 κ /d/ , 0 = κ /t/ , 0 = 16 κ /d/ , 0 = κ /t/ , 0 = 4 ν /d/ , 0 = ν /t/ , 0 = 4096 ν /d/ , 0 = ν /t/ , 0 = 1024 ν /d/ , 0 = ν /t/ , 0 = 256 ν /d/ , 0 = ν /t/ , 0 = 64 ν /d/ , 0 = ν /t/ , 0 = 16 ν /d/ , 0 = ν /t/ , 0 = 4 L 1 − a c c</formula><p>as shown in <ref type="figure" target="#fig_17">Figure 24</ref>, the category means of Korean-accented /d/ and /t/ are shifted relative to the L1-accented stimuli. In comparison, differences in category (co)variances are relatively subtle between the two sets of stimuli. For the present exposure stimuli, adapting to the L2 accent thus primarily hinges on learning the new category means. Taken together, these results demonstrate how changes in representation can explain the types of results that are considered the signature of accent adaptation. <ref type="figure" target="#fig_2">Figure 26</ref> shows the effects of changes in decision-making as a function of the rate at which response biases change and the lapse rate , averaged across all simulations for each parameterization. As in Case Study 1, the figure shows the average across 50 repeated simulations, each time randomizing the order of exposure. This was sufficient to achieve reproducible estimates even for the largest s considered here (SEs of the mean accuracy after L2-accented exposure across repeated simulations were smaller than 0.002, meaning that the 95% CI across the simulations spanned less than 1% in recognition accuracy).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Changes in decision-making</head><p>For L1-accented exposure, we again see that /d/ test tokens are categorized substantially less accurately than /t/ test tokens, regardless of the specific value of ( ). The second signature result-improved accuracy after L2-accented exposure for /d/-is obtained for sufficiently large  <ref type="figure" target="#fig_2">Figure 26</ref>. Predictions of a model that derives accent adaptation as changes in decision-making. Predicted categorization responses for the test tokens after L1-accented and L2-accented exposure, depending on the rate at which response biases change ( ) and the rate of attentional lapses ( ). The highlighted panel is the one closest to the best-performing parameterization ( = 0.34; = 1.9 − 30; overall accuracy= 0.91).</p><p>. As increases, the overall recognition accuracy first increases and then plateaus. The largest improvements are found for the smallest lapse rates and relatively fast change rates (gray panel in <ref type="figure" target="#fig_2">Figure 26</ref>).</p><p>Importantly, 26 shows that changes in response biases do not necessarily result in the type of zero-sum trade-off that is sometimes attributed to them-accuracy increasing by some degree for one category while decreasing by the same degree for the other category. Rather, L2-accented exposure can predict improvements in the overall recognition accuracy across both categories (e.g., top right panel). Zero-sum trade-offs are only expected under the highly implausible assumptions that responses are entirely independent of stimulus properties (bottom row of <ref type="figure" target="#fig_2">Figure 26</ref>). Indeed, for the specific L1-L2 accent combination considered here, the largest improvements observed for changes in decision-making are similar in magnitude to those observed for the representational change model, despite the fact that the former change model is computationally simpler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Changes in normalization</head><p>Finally, we compare models that normalize test tokens based on the phonetic inputs experienced during exposure to models that continue to apply normalization based on previous long-term L1</p><p>experience. <ref type="figure" target="#fig_4">Figure 27</ref> shows the predicted categorization accuracy following changes in normalization in L1-and L2-accented exposure conditions. We again obtain both of the signature results of experiments on accent adaptation. For L1-accented exposure, we continue to see that  </p><formula xml:id="formula_14">κ 0 = 1024 κ 0 = κ 0 = 64 κ 0 = 16 κ 0 = 4 κ = 1 L 1 − a c c</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exposure condition Predicted categorization accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category</head><p>/d/ /t/ <ref type="figure" target="#fig_4">Figure 27</ref> . Predictions of a model that derives accent adaptation from changes in normalization. Predicted categorization responses for the test tokens after L1-accented and L2-accented exposure, depending on the relative weighting of previous experience ( 0 ) during the inference of the cue mean during exposure. The highlighted panel is the one closest to the best-performing parameterization ( 0 = 1; overall accuracy = 0.92).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Summary</head><p>Paralleling Case Study 1 on perceptual recalibration, we find that any of the three change mechanisms can qualitatively explain the signature results of experiments on accent adaptation.</p><p>Even computationally simple, non-representational mechanisms-normalization and decision-making-can explain improvements in the perception of L2 accents that differ in complex ways from L1 listeners' prior expectations. And, contrary to common assumptions, changes in decision-making can lead to overall improvements in recognition accuracy, rather than only zero-sum trade-offs. Overall improvements in accuracy after exposure to an unfamiliar accent are thus not diagnostic of listeners' adaptation to L2-specific category realizations. This supports the conclusion of Case Study 1: at the level of analysis that is commonly applied in previous work (and thus here), experiments on accent adaptation do not necessarily rule out any of the three mechanisms as driving the benefits of exposure.</p><p>For the current hypothetical L2 accent considered in Case Study 2, the three models are not only similar in their qualitative predictions, but they also yield highly comparable quantitative results in terms of the maximal benefits of L2-accented exposure (compare the highlighted panels across <ref type="figure" target="#fig_4">Figure 25-27</ref>). This is not expected to always be the case. A critical insight of ASP is that the specific predicted benefit of L2-accented exposure under each mechanism depends on the statistics of the exposure and test stimuli, relative to L1 listeners' prior expectations. For experiments that employ naturally accented exposure and test tokens, this also means that the results are predicted to depend on the specific way in which the acoustic-phonetic distributions of an L2 accent deviate from those of the L1 accent.</p><p>To further illustrate this point, we simulated three additional scenarios of adaptation to an L2 accent (Panel A in <ref type="figure" target="#fig_6">Figure 28</ref>). Each of these scenarios is representative of commonly attested differences between L1-and L2-accents. The top row of <ref type="figure" target="#fig_6">Figure 28</ref> shows an example of contrast reduction, in which the L2 accent shows a greater category overlap than the L1 accent. Here it is simulated by shifting /d/ category towards /t/ along VOT while keeping the latter unchanged (as qualitatively attested for, e.g., vowels in Spanish-accented English, <ref type="bibr" target="#b292">Wade et al., 2007)</ref>. The    <ref type="table" target="#tab_13">Table 2</ref>) that yields the maximal benefit for the L2-accented exposure condition, following the same procedures described for the cue-reweighting case described above.</p><p>The three accent scenarios differ in terms of levels of difficulties they are predicted to pose for L1 listeners prior to exposure (see L1-accented exposure condition in Panel B of <ref type="figure" target="#fig_6">Figure 28</ref>). Contrast Second, the same change model can support more or less overall accuracy improvements (as gleaned from comparing the panels within each column), depending on the specific differences between the L2 and L1 accents. Consider the case of contrast shift (middle row). While changes in representations and normalization both predict large improvements in overall recognition accuracy in the L2-accented exposure, changes in decision-making do not (i.e., the difference in the predicted accuracy across L1-and L2-accented exposure conditions is negligible). This outcome aligns with the zero-sum trade-offs often attributed to this change mechanism (i.e., the recognition of /d/ improves at the cost of the recognition of /t/). The heterogeneity of the results across the three scenarios makes it clear that the trade-off is not an inherent property of the decision-making mechanism. It is instead a possible outcome arising from a combination of the specific change model and properties of the L2 accent (or L1-L2 accent differences).</p><p>Third, none of the change models predicts significant benefits from L2-accented exposure for contrast collapse (bottom row). This highlights an important, yet often under-appreciated, fact: sometimes null results are predicted for exposure-test experiment, because of the specific stimulus statistics (see <ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020)</ref>. Put differently, an absence of improvements does not necessarily constitute evidence against accent adaptation or any of the three mechanisms.</p><p>While the scenarios considered here cover only a small subset of the cross-accent differences that exist in the world, they clearly illustrate a general challenge: different types of cross-talker differences (including L2 accents) pose different type of challenges to listeners (and vice versa).</p><p>This is also reflected in the fact that the best-performing parameterizations vary across the different accent scenarios (see <ref type="table" target="#tab_13">Table 2</ref>). It follows that, depending on the exact nature and sources of the difficulties, listeners would benefit from different rates and types of adaptation. Since the properties of unfamiliar accents are not a priori known to listeners, this means that the optimal level of flexibility is achieved if the neural and cognitive systems underlying adaptive speech perception may need to adjust change rates based on the properties of the input (see discussion of the trade-off between flexibility and stability in <ref type="bibr">Kleinschmidt &amp; Jaeger, 2015, pp. 180-182)</ref>.</p><p>In summary, benefits of L2-accented exposure expected under each change mechanism hinge on the specifics of L2-accented categories. Beyond the accent scenarios examined here (cue-reweighting, contrast reduction, contrast shift, and contrast collapse), naturally produced L2 accents exhibit complex variations, which can pose difficulties to L1-listeners and researchers alike.</p><p>At the same time, it is the case that these differences offer a opportunity to investigate the relative engagement of each change mechanism. Because the three change mechanisms would predict distinct perceptual outcomes depending on the properties of the exposure and test stimuli, differences between accents can in theory be used to distinguish between model predictions. In the general discussion, we explore how such tests can be achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">General discussion</head><p>The two case studies we have presented together provide two important insights. First, the signature results from two influential lines of research-often taken to lend support to changes in category representations-are actually compatible with computationally more parsimonious change mechanisms (pre-linguistic signal normalization and changes in post-perceptual decision-making). Additional case studies not reported here suggest that this finding is likely to generalize at least partly to other types of exposure-test paradigms, such as distributional learning paradigms over a single phonetic cue ) and dimension-based statistical learning paradigms that manipulate the relative informativity of cues  Key to these recommendations is the second insight derived from our case studies: as we illustrated at the end of Case Study 2, each of the three mechanisms is subject to different computational limitations, and thus yields different predictions depending on the specific acoustic-phonetic properties of the exposure and test stimuli. Below we discuss how future experiments can be designed and analyzed so as to maximize researchers' ability to detect the differences in the predictions of the different change models, and to determine the relative engagement of each mechanism. Central to our recommendations is the use of ASP or similar frameworks to inform experiment design and analysis through simulations and quantitative model comparison. First, however, we discuss why we believe that computational simulations and model comparisons will be critical to advancing the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Beyond sufficiency tests</head><p>For our two case studies, we considered each of the three change models of the ASP framework separately. This served two purposes. The first was presentational: by presenting the predictions of each model while the other two change models were 'switched off', we hope to have provided readers with clearer intuitions about the inner workings of each model. The second purpose was the test of (in)sufficiency of each change mechanism in explaining the signature results from the two paradigms. We asked whether each of the mechanisms alone is sufficient to predict adaptive changes of speech perception. Ultimately, however, research on adaptive speech perception will have to go beyond such sufficiency tests. With a phenomenon as complex as human speech perception, it is most plausible that multiple mechanisms, from early perception to decision-making, jointly contribute to the observed adaptive behavior.</p><p>Indeed, existing evidence supports the idea that none of the three mechanisms is sufficient to explain the range of adaptive behaviors listeners exhibit in response to recent exposure. We summarize this evidence in more depth in the SI ( §7), where we also propose additional experiments on the (in)sufficiency of each of the three mechanisms. For example, the finding that non-speech stimuli-such as sine tones-can affect subsequent vowel perception (e.g.,  is easily explained in terms of pre-linguistic normalization but difficult to explain through changes in linguistic representations or decision-making (see also . Other findings, however, cannot easily be accommodated by an account that solely relies on pre-linguistic normalization. One example comes from research on perceptual recalibration: the effects of exposure do not only depend on the acoustic-phonetic cues of the exposure tokens but also their category labels (e.g.,   <ref type="bibr" target="#b244">Sjerps et al., 2019)</ref>, and whether differential activation in frontal areas reflect changes in decision-making (as seems to be assumed in, e.g., <ref type="bibr" target="#b182">Myers &amp; Mesite, 2014;</ref><ref type="bibr" target="#b251">Sohoglu &amp; Davis, 2016)</ref> or rather the cumulative upstream effect of distributed changes in representations. Observations like these about the current state of the field motivate the recommendations we present next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Methodological advances to facilitate more informative model comparisons</head><p>We offer five concrete recommendations as to how future research on speech perception can benefit from computationally-guided experiment design and data analysis methods. In addition, we emphasize here that improved standards of data annotation and sharing will be critical in supporting this endeavor, and to the field en large. Although listeners' responses are known to depend on the acoustic-phonetic properties of the speech input, studies on adaptive speech perception rarely provide annotations of those properties. We cannot hope to understand speech perception without moving beyond this status quo (for concrete suggestions, see SI §8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Recommendation 1: Prediction based on sufficiently constraining theories instead of (only) informal reasoning</head><p>Our first recommendation is to develop and employ strong theories and models, in the sense of Platt's strong inference approach to scientific inquiry <ref type="bibr" target="#b207">(Platt, 1964)</ref>. The majority of published research on adaptive speech perception-including some of our own work-continues to employ informally formulated, under-specified hypotheses. This leaves too much room for ad-hoc or post-hoc reasoning, with all the downsides that have been discussed in the context of the replicability crisis and elsewhere (e.g., <ref type="bibr" target="#b256">Starns et al., 2019;</ref><ref type="bibr" target="#b285">Vasishth &amp; Gelman, 2021;</ref><ref type="bibr" target="#b315">Yarkoni, 2022)</ref>. Even for research explicitly framed in terms of more or less clearly specified theories like "distributional learning" or "exemplar theory", reliance on informal reasoning alone is both risky and likely to miss insights that can be gained if computational frameworks are employed.</p><p>We have experienced this in our own work-for example, in  we were initially surprised that standard perceptual recalibration results can be explained through changes in beliefs about category variances rather than only through changes in beliefs about category means. It was the use of a computational model with spelled-out linking hypotheses about the entire chain from inputs (stimuli) to participants' categorization responses that led to that insight-an insight that in hindsight is obvious. Another example from our own work is , which failed to replicate the benefit of L2 accent exposure observed in  for another L1-L2 combination (Flemish-accented Swedish). To our surprise, post-hoc simulations found that the representational change model of  indeed predicted this replication failure: the acoustic-phonetic distributions of the stimuli used in  implied that even successful representational changes did not result in improved perception during test-despite the qualitative similarities of the L2 accents employed in the two studies. We surmise there are other null findings previously taken to motivate novel mechanisms that can be similarly reduced to the acoustic-phonetic properties of the exposure and test stimuli (see e.g., <ref type="bibr" target="#b65">Floccia et al., 2006;</ref><ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020)</ref>.</p><p>A third demonstration of how computational and theoretical rigor can revise intuitions comes from the now classic study "The Weckud Wetch of the Wast" <ref type="bibr" target="#b162">(Maye et al., 2008)</ref>. The study exposed listeners to speech in which the vowel categories had undergone systematic (phonological) shifts and observed adaptive changes in subsequent vowel recognition. Based on additional control conditions, <ref type="bibr" target="#b162">Maye et al. (2008)</ref> reasoned that this finding could not be explained by "general relaxation of the criterion for what constitutes a good exemplar of the accented vowel category" (p.543) but instead argued that listeners had learned ways in which vowel representations are shifted. <ref type="bibr" target="#b86">Hitczenko and Feldman (2016)</ref> recently revisited this result, using the representational change model of . Hitczenko and Feldman found that category expansion ("relaxation") explained the results of <ref type="bibr" target="#b162">Maye et al. (2008)</ref>  These resources can help researchers derive predictions prior to conducting an experiment, based on all the relevant acoustic-phonetic properties of the planned exposure and test stimuli (see Recommendation 4), and to compare the fit of different combinations of change models to the results once data collection has been completed (Recommendations 2 and 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Recommendation 2: Analyses that link the acoustic-phonetic properties of stimuli and participants' responses</head><p>In our case studies, we followed the approaches that continue to be employed in the majority of experiments on adaptive speech perception. In Case Study 1, we analyzed changes in categorization responses at six different test items. Following the majority of research on perceptual recalibration (for exceptions, see <ref type="bibr" target="#b226">Saltzman &amp; Myers, 2021)</ref>, we did not further relate these changes to the acoustic or phonetic properties of the exposure or test stimuli (for related discussion, see also <ref type="bibr" target="#b37">Clayards, 2018;</ref><ref type="bibr" target="#b274">Theodore, 2021)</ref>. In Case Study 2, we analyzed changes in accuracy. Like some previous studies (e.g., <ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020)</ref>, we showed these changes separately for the two categories investigated in the case study.</p><p>Other studies on accent adaptation further simplify the dependent measure and analyze only overall improvements in accuracy <ref type="bibr" target="#b19">(Bradlow &amp; Bent, 2008;</ref><ref type="bibr" target="#b243">Sidaras et al., 2009;</ref><ref type="bibr" target="#b280">Tzeng et al., 2016)</ref> or processing speed <ref type="bibr" target="#b35">(Clarke &amp; Garrett, 2004)</ref>.</p><p>Although in common use, these types of analyses over aggregated data constitute a missed opportunity. They discard stimulus-level data that could otherwise provide valuable information on the nature of the mechanisms underlying adaptive speech perception. This is a general, and well-known, problem: many competing hypotheses might provide plausible explanations for coarse-grained aggregate data (like overall or category-specific accuracies). On the other hand, models that make the same predictions for aggregate data might be distinguishable when compared against more fine-grained data. For experiments on adaptive speech perception, this means that researchers stand to benefit from analyzing changes in the categorization function -i.e., the mapping from acoustic-phonetic properties of the test stimuli to participants' responses-in response to recent exposure.</p><p>We illustrate this point in <ref type="figure" target="#fig_25">Figure 29</ref>, which shows the predicted categorization functions after L1-and L2-accented exposure for each of three change models for the best-performing  Critically, differences like those in Figures 29 will only be apparent when the data is analyzed at appropriately fine-grained detail-i.e., by assessing changes in the mapping from acoustic-phonetic properties of stimuli to participants' responses. Fitting ASP and similar models to the results of experiments is one way to conduct such analyses. Previous work has done so for competing normalization models (see, e.g., <ref type="bibr" target="#b202">Persson &amp; Jaeger, 2022a;</ref>) and competing parameterization of representational change models (e.g., <ref type="bibr" target="#b124">Kleinschmidt, 2020;</ref>. Future work can employ ASP to compare the fit of all three change models-including combinations of them-to the results of experiments:</p><p>with minimal modifications, the code we used to find the best-performing parameterizations in Case Study 2 can be used to find the parameterizations that best fit listeners' responses from a perception experiment. This will allow researchers to investigate what factors contribute to the relative engagement of different change mechanisms.</p><p>Alternatively, standard approaches to data analysis can be used to investigate changes in the mapping from acoustic-phonetic properties to participants' responses (for an excellent review, see . This includes regression models as long as they employ appropriate linking functions (e.g., logistic or multinomial regression for categorization, <ref type="bibr" target="#b98">Jaeger, 2008;</ref><ref type="bibr" target="#b302">Winter &amp; Wieling, 2016)</ref>. This approach is now increasingly common, taking advantage of stimulus-level variability within and across conditions to test hypotheses (e.g., <ref type="bibr" target="#b37">Clayards, 2018;</ref>. Regression analyses can further be expanded into psychometric models <ref type="bibr" target="#b300">(Wichmann &amp; Hill, 2001</ref>) by adding lapse rates and response biases (e.g., <ref type="bibr" target="#b124">Kleinschmidt, 2020)</ref>, and can be fit in standard statistics software (e.g., brms, . Optionally, such regression analyses can be enriched with predictive ASP simulations of the type we have employed in our case studies. Such simulations are computationally less demanding than fitting ASP models to perception experiments, and can help guide the interpretation of results (for examples of approaches that mix predictive simulation with standard data analysis, see <ref type="bibr" target="#b9">Bejjanki et al., 2011;</ref><ref type="bibr" target="#b86">Hitczenko &amp; Feldman, 2016;</ref>; see also discussion in <ref type="bibr" target="#b10">Bent &amp; Baese-Berk, 2021</ref>).</p><p>To fully take advantage of the types of analyses we have discussed here, it will, however, be important to plan experiments with these analyses in mind. This leads to our next recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Recommendation 3: Dense and targeted sampling of the stimulus space</head><p>Our third recommendation is to obtain data that more strongly characterize incremental changes in categorization functions that occur with exposure. Simply put, the more data an experiment  type of change that is predicted to occur (e.g., shifts vs. changes in the slope of categorization function; changes in the relative weighting of different cues). The amount of exposure determines how much change of that type is predicted.</p><p>Experimenters can take advantage of both aspects. For example, experiments can employ more than one exposure condition. For instance, Kleinschmidt and Jaeger (2016b) exposed different groups of participants to six different exposure conditions with distinct VOT distributions for /b/ and /p/. The data were then used to contrast different parameterizations of the same change model (for additional analyses and insightful discussion, see also <ref type="bibr" target="#b124">Kleinschmidt, 2020)</ref>. While some studies have employed multiple exposure conditions in perceptual recalibration and similar paradigms (e.g., <ref type="bibr" target="#b4">Babel et al., 2019;</ref><ref type="bibr" target="#b262">Sumner, 2011a)</ref>, this approach remains under-utilized.</p><p>Similarly, incremental testing within subjects can increase the ability to contrast the predictions of different change models <ref type="figure" target="#fig_27">(Figure 30</ref>). Even when all three change models predict more or less the same outcome of adaptation, they can differ in the trajectory of changes they predict (for some pioneering behavioral work, see e.g., <ref type="bibr" target="#b11">Bertelson et al., 2003;</ref><ref type="bibr" target="#b17">Bonte et al., 2017;</ref><ref type="bibr"></ref> and for computational models, see <ref type="bibr" target="#b126">Kleinschmidt &amp; Jaeger, 2012)</ref> Similarly, test phases in experiments on accent adaptation tend to densely sample the space around the accented category means-a side effect of using naturally accented stimuli. But any change model that can predict general improvements in accuracy will also tend to correctly predict the categorization for those stimuli, making them relatively uninformative about the types of changes that result from exposure. Future experiments can advance our understanding of exposure-driven changes in speech perception through more targeted sampling of the acoustic-phonetic space during test. Researchers should derive model predictions and sample test stimuli from the regions where model predictions would be maximally distinct from one another (for initial efforts along these lines, see . As shown in <ref type="figure" target="#fig_25">Figure 29</ref>, some of the largest predicted differences can occur in parts of the acoustic-phonetic space that are neither close to the category means, nor on the line between them. 16</p><p>While targeted sampling is most easily achieved for paradigms that employ (re)synthesized or otherwise phonetically manipulated stimuli (for examples, see <ref type="bibr" target="#b9">Bejjanki et al., 2011;</ref>, it is also possible in combination with naturally accented stimuli. For example, Chodroff and Wilson (2020) took advantage of naturally occurring variability, and created different exposure conditions by selecting different subsets of natural stimuli. This approach strikes a particularly intriguing balance between ecological validity and experimental control that deserves further attention in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.4">Recommendation 4: Predictive power analyses prior to conducting experiments</head><p>Like other computational frameworks, ASP can be used to estimate expected effect sizes and statistical power before conducting an experiment. Unlike commonly used power estimates, which assume effect sizes (e.g., "moderate" effects, <ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020)</ref>, predictive power-analyses of the type we envision are based on effect sizes that are derived from the acoustic properties of the very exposure and test stimuli used in the given experiment. This makes power simulations considerably more informative.</p><p>There are, however, challenges that will have to be met so that ASP can be used for predictive power simulations. For a specific set of exposure and test stimuli, and specific parameter settings for all change models, ASP predicts an expected categorization function. This is what we showed in, for example, in <ref type="figure" target="#fig_25">Figure 29</ref> (see also, e.g., <ref type="bibr" target="#b274">Theodore &amp;</ref> Monto, 2019; Xie, Buxó-Lugo, &amp; Kurumada, 2021, for similar approaches). This categorization function can be used to derive a predictive power estimate by repeatedly sampling responses for the planned test stimuli and the planned number of participants. This can be done for any individual exposure conditions, for combinations of exposure conditions, and/or the predicted <ref type="bibr">16</ref> The optimal choice of stimuli depends on the specific goals of the experiment. For example, stimuli locations that are optimal for estimating the categorization function after one exposure condition, are not necessarily optimal for estimating the categorization function in another exposure condition, and neither choice might be optimal if the goal is to detect differences between the two conditions or differences between the different change models. Predictive (power) simulations can help determine the optimal stimulus locations and repetitions, for any of these goals (Recommendation 4).</p><p>differences between exposure conditions.</p><p>However, the parameterization of the different models is typically not known to researchers-if they were, there would be no need for the present article. One important direction for future research will thus be to better characterize the functional consequences of each model's computational limitations. For example, in the SI ( §3.2.1), we show that changes in decision-making can only explain additive effects of exposure on the log-odds of categorization responses (for lapse rates of 0 or 1) or effects that resemble a step-function (for all other lapse rates). Further study of this and similar constraints will shed light on what range of adaptive behaviors each model can predict (for discussions of global, qualitative model comparisons, see <ref type="bibr" target="#b205">Pitt et al., 2006)</ref>. Another related approach is to derive predictions and calculate statistical power while marginalizing (i.e., averaging) over a plausible distribution of ASP parameters for the models they wish to contrast. In Bayesian terminology, this is achieved by defining "priors" over the ASP parameters. Initially, when relatively little is known about the relevant distribution of parameters, very weak priors are recommended that will consider a wide range of parameters as probable. As additional studies become available, this will further inform the range of plausible priors. Even now though, the plausible range of parameters is constrained by the fact that listeners can adapt within a certain number of observations. This constrains the joint distribution of ASP parameters since any plausible parameterization needs to</p><p>give at least one of the change models sufficient flexibility.</p><p>If researchers further wish to know which exposure or test stimuli would increase the predicted difference between hypotheses, that further requires comparison of different stimulus selections. Comparable approaches exist for simpler computational problems, and have been used extensively in psychometric research (incl. online stimulus selection during the experiment, depending on subject-specific performance, e.g., <ref type="bibr" target="#b211">Prins, 2013;</ref><ref type="bibr" target="#b291">Vul et al., 2011)</ref>. We believe this is an area of research that holds substantial potential.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.5">Recommendation 5: Integration with neural models of speech perception</head><p>Our final recommendation is to further integrate ASP with neural models of speech perception.</p><p>ASP as put forward here is a model that makes behavioral predictions. Similarly fully specified models of the neural computations underlying adaptive speech perception are a bigger challenge and remain lacking (but see <ref type="bibr" target="#b251">Sohoglu &amp; Davis, 2016</ref>; for discussion, see <ref type="bibr" target="#b75">Guediche et al., 2014)</ref>.</p><p>In the introduction, we outlined that models like ASP can support neuroimaging research by making more concrete-and thus more testable-the types of computations that are hypothesized to take place in different brain regions or networks. At the same time, future neuroimaging research can further constrain the hypothesis space, and inform frameworks like ASP.</p><p>One notable step towards integrating computational models of speech adaptation with evidence from neuroimaging is presented in <ref type="bibr" target="#b251">Sohoglu and Davis (2016)</ref>. Sohogulu and Davis</p><p>propose that prediction errors calculated in the superior temporal gyrus as part of spoken language understanding come to change decision biases. These updated decision biases are taken to affect the final, decision-making, stage of spoken language understanding on subsequent speech input, as reflected by activation in frontal areas (see also ). Our change model for decision-making is closely related to this proposal, and future integrations of these two lines of work strikes as a productive endeavor.</p><p>As in behavioral studies, existing neuroimaging results so far have not always singled out neural networks underlying behavioral changes in response to recent exposure. Adaptive changes in speech perception have been found to involve several different brain regions. These include cerebellum <ref type="bibr" target="#b75">(Guediche et al., 2014)</ref>, early auditory regions (anterior planum temporale, <ref type="bibr" target="#b17">Bonte et al., 2017;</ref><ref type="bibr" target="#b116">Kilian-Hütten et al., 2011)</ref> and regions responsible for representing phonemes and syllables (e.g., posterior superior temporal gyri/superior temporal sulcus, <ref type="bibr" target="#b17">Bonte et al., 2017;</ref><ref type="bibr" target="#b182">Myers &amp; Mesite, 2014;</ref><ref type="bibr" target="#b284">Ullas, 2020)</ref>, as well as regions for talker recognition (right temporal regions, <ref type="bibr" target="#b154">Luthra et al., 2020)</ref>. The left parietal lobe and the insula, which are implicated in perceptual decision-making (e.g., d <ref type="bibr">'Acremont et al., 2013;</ref><ref type="bibr" target="#b114">Keuken et al., 2014)</ref>, have also been shown to exhibit distinct activation for different exposure conditions.</p><p>While certain brain regions and/or networks have been identified to respond differently to different exposure conditions (e.g., familiar vs. unfamiliar talker accents), these regions often play multiple roles in cognitive processing. The exact interpretation of the findings still depends on the researchers' hypothesis of the underlying mechanism. For instance, the activation of left parietal lobe might reflect its general role in perceptual decision-making (e.g., d <ref type="bibr">'Acremont et al., 2013;</ref><ref type="bibr" target="#b114">Keuken et al., 2014)</ref>, or it could be due to a more specific role in phonological processing (e.g., processing abstract category information, <ref type="bibr" target="#b75">Guediche et al., 2014)</ref>. Similarly, changes in inferior frontal gyri activation in response to accented speech has been interpreted as reflecting greater computational demand <ref type="bibr" target="#b316">(Yi et al., 2014)</ref> or decision-related phonetic categorization of ambiguous stimuli <ref type="bibr" target="#b182">(Myers &amp; Mesite, 2014)</ref>. This ambiguity is compounded by univariate analysis methods which test an increase or a decrease of neural activity while largely leaving open the information content represented in the distinct brain regions. Clearer links between acoustic-phonetic cues and expected changes of recognition, as facilitated by ASP, can help resolve this ambiguity.</p><p>Recent research has begun to apply multivariate analyses that can be effectively combined with the approach we have described above. Multivariate analyses can be used to identify the encoding of perceptual experiences across a distinct array of experimental conditions, which helps to distinguish between cognitive models that make different predictions regarding the type of information encoded by different brain regions and networks (e.g., <ref type="bibr" target="#b16">Blank &amp; Davis, 2016</ref>). An additional advantage of multivariate analyses is that they are more sensitive in detecting fine-grained patterns within regions (e.g., <ref type="bibr" target="#b17">Bonte et al., 2017;</ref><ref type="bibr" target="#b154">Luthra et al., 2020)</ref>. For instance, while recent electrocorticography studies have provided some direct evidence for prelinguistic cue-level normalization within the middle and posterior STG areas <ref type="bibr" target="#b108">(Johnson &amp; Sjerps, 2021;</ref><ref type="bibr" target="#b271">Tang et al., 2017b</ref>; see also <ref type="bibr" target="#b244">Sjerps et al., 2019)</ref>, it remains an open question how normalization supports the kind of adaptive changes as observed in perceptual recalibration or accent adaptation.</p><p>Representational similarity analysis (RSA) of fMRI data allows researchers to take advantage of specific similarity matrix for a set of stimuli, rather than just the overall activation level for each condition. By selecting test stimuli so as to maximize the contrast between the similarity matrices of different change models, RSA can generate novel insights on the computations performed by different brain regions. Model-guided experimental designs as described in Recommendations 1-4 can facilitate such stimuli selection.</p><p>The synergy between behavioral, computational, and neural studies may uncover new knowledge about the relative engagement of the three mechanisms over time. <ref type="bibr" target="#b182">Myers and Mesite (2014)</ref> found that boundary shifts in a perceptual recalibration study were initially driven by changes in the brain regions responsible for decision-making in the absence of changes in acoustic-phonetic representations (as indexed by STG activation). However, over the course of critical exposure trials, evidence of retuned perceptual sensitivities slowly emerged. The authors concluded that this indicates a "transfer of decision-related or lexical-level information to more bottom-up or perceptual processes in the temporal lobes" (p. 91). To extend this finding, future research should track brain responses over a more extended period of exposure. ASP models' abilities to predict incremental changes for multiple change mechanisms make it a tool well-suited to aid the design of such new experiments.</p><p>Finally, another promising avenue is to pair temporally-sensitive techniques with imaging methods with good spatial resolution. For instance, studies employing a combination of EEG and MEG have begun to teas apart the role of signal properties and prior expectations in regulating perceptual learning of degraded speech: although both properties seem to affect activation of the same region in STG, they operate over different timescales <ref type="bibr" target="#b251">(Sohoglu &amp; Davis, 2016</ref>.</p><p>Temporally-sensitive methods are also helpful in distinguishing between distinct mechanisms that may underlie adaptive speech perception. Using P200 as an index for acoustic-phonetic processing, Romero-Rivas et al. <ref type="formula">2015</ref>found that the extraction of spectral information and other acoustic features was more difficult for foreign-accented speech than for native speech.</p><p>Critically, this difference in acoustic-phonetic mapping did not attenuate within a single exposure session, compared to faster improvements in lexical-semantic processing, as indexed by N400. To the extent that the P200 and N400 reflect acoustic-phonetic vs. post-lexical processes, respectively, these results are compatible with the possibility that neural changes associated with decision-making criteria (driven by the prediction error experienced during lexical processing, cf.</p><p>Delaney-Busch et al., 2019; Kuperberg, 2016) occur faster than those responsible for acoustic-phonetic remapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Conclusion</head><p>We have introduced a theoretical and computational framework for adaptive speech perception (ASP). ASP formalizes three distinct mechanisms of speech perception ('processing') and adaptive speech perception ('learning'), ranging from low-level auditory (normalization), to linguistic (category representations), and cognitive processes (decision-making). In the present paper, we have presented specific categorization and change models that aimed to be general-purpose, capturing the most common assumptions shared between theories of speech perception. By writing this article in R markdown, we hope to have made it easier for other researcher to revisit any of the assumptions we made, e.g., by substituting alternative models of normalization, If you want to knit the document into a PDF file, you will some additional packages. First, make sure that your version of the R package tinytex is up-to-date. Then run tinytex::install_tinytex() to install latex on your computer and/or link it to R. As of 12/20/2022, it was also necessary to use tinytex::tlmgr_install('biber') to install biber, though that step might become unnecessary in the future. Pandoc version 2.19.2 was tested. If you do not have at least that version then update RStudio, which will also install the newest version of pandoc (you can check by running rmarkdown::pandoc_version()). Finally, you might need to download the IPA font SIL Doulos, which is required for the IPA symbols in the paper. §2 A database of natural productions of word-initial stop voicing in L1 US English  All case studies presented in the main text are based on a phonetically annotated database of word-initial stop voicing in L1 US English . <ref type="bibr">Chodroff and Wilson (2018, p.</ref> 3) describe the database:</p><p>The Following advice from Eleanor Chodroff, we removed tokens with f0 measurements of above 350 Hz, as those were implausible and likely reflected a measurement error (pitch doubling). We further subset the data talkers for which all three cues (VOT, COG, and f0) were available for at least 25 observations each per stop category. This was done because we detected that the f0 of a good number of talkers exhibited evidence of bimodality. To remove talkers with bimodal f0</p><p>measures, we applied a test of multimodality (the dip test, as implemented in the library diptest <ref type="bibr" target="#b386">Maechler, 2021b)</ref>. Restricting our data set to talkers with at least 25 observations each per stop category allowed us to more reliably identify bimodal f0 distributions. Talkers for which the null of unimodality was rejected ( &lt; 0.1) for the raw f0 or Mel-transformed f0 of any stop category were excluded. 17</p><formula xml:id="formula_15">in R,</formula><p>This left 40,459 observations from 104 different talkers and 98 words. These are the data that we used to derive plausible estimate of the overall and category-specific VOT and Mel distributions that underlie the case studies presented in the main text. <ref type="figure">Figure 31</ref> shows the individual tokens and fitted bivariate Gaussian category likelihood of three randomly selected talkers from this data set prior to C-CuRE normalization. <ref type="figure">Figure 32</ref> further illustrates the degree of cross-talker variability by plotting all talkers' category means relative to the category likelihood across all talkers prior to normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>§2.1 Applying C-CuRE</head><p>We follow McMurray and Jongman (2011) and use linear regression to remove the effects of talker from each observation in the database. In extending normalization accounts to our present goals, we encountered three decision points that we have not previously seen discussed:</p><p>1. C-CuRE removes the overall cue mean from each observation's cue value. Based on this, it <ref type="bibr">17</ref> We thank Eleanor Chodroff for help with this issue. Her inspection of some example tokens revealed that both creaky voice and pitch halving contributed to the bimodal pattern. Pitch halving refers to cases in which the f0 detection algorithm wrongly infers the f0 to be half of its true value. One reason for such estimation mistakes can be when the true f0 falls outside the range considered by the algorithm (here: 75-500 Hz, regardless of talker gender, Eleanor <ref type="bibr">Chodroff, p.c.)</ref>.  <ref type="figure">Figure 31</ref>. Unormalized VOT and f0 of word-initial stop consonants in L1 US English from 3 random talkers from the database . Transparent points show individual tokens, which cover a range of different phonotactic, lexical, and utterance contexts. Solid points show talker-specific means over these tokens, connected by a gray line. Ellipses show the 95% probability mass boundary for the talker-specific bivariate Gaussian category likelihoods.  <ref type="figure">Figure 32</ref>. By-talker means of VOT and f0 for all six stop consonants and all 104 talkers in the database  for which all phonetic cues were available. Ellipses show the 95% probability mass for talker-independent bivariate Gaussian categories if the data from all talkers are pooled independent of talker identity.</p><p>would seem most appropriate to include all six stop categories in the estimation of the cue means. However, the experiments we model in the main text involve only two of the categories (/d/ and /t/). We thus decided to only include tokens of /d/ and /t/ in the estimation of cue means. This decision was made because C-CuRE is intended to correct observed cue values for listeners' expectations for the current context. Put differently, we assume that listeners expect that the sound will be a /d/ or a /t/ since these are the only two response options provided to participants. This assumption affects some of our results (but not as much as it would if we studied /b/-/p/ or /g/-/k/ since the mean cue values for /d/s and /t/s are closer to the mean cue values across all six categories).</p><p>2. C-CuRE is meant to correct for effects of both talkers and phonological contexts. However, in the  data /d/ and /t/ occur across different phonological contexts, so that inclusion of phonological contexts as a predictor in the regression model would indirectly capture information about category identity. We thus limited the data further to 9 pairs of /d/-and /t/-items that had identical vowels following the stop consonant (e.g, died and time). While this does not completely remove the effects of phonological context, it both reduces the variability in cue values associated with phonological contexts (thus providing a more accurate estimate of the expected outcome of normalization) and balances the effect of phonological context (de-confounding it from category identity).</p><p>3. Finally, the original data from  contained nearly three times as many /d/s as /t/s, and this asymmetry was retained after the data cleaning procedures described above. While this particular imbalance is probably not reflective of natural speech, natural speech will often exhibit some form of asymmetry in the relative frequencies of categories. This raises the question of whether listeners somehow correct for these asymmetries when normalizing the speech input for an experiment for which there all categories can be expected to be equally frequent. Following similar considerations as in Point 1 above, we assume this to be the case. We thus randomly subsampled equal numbers of tokens for each /d/ and /t/ from all talkers. This number was determined by the number of tokens of the less frequent category for each talker. For instance, if a talker produced 40 /d/s and 20 /t/s, then 20 /d/ and 20 /t/ observations were randomly pulled from the data.</p><p>For experimenters, the issues described here will arise whenever the distribution of categories and/or phonological contexts differ between prior exposure and the exposure in the experiment, or between exposure and test in the experiment: the estimated mean will then reflect expectations that do not veridically reflect the statistics of the current input. In previous evaluations of C-CuRE this was never the case, since those evaluations made a number of unrealistic assumptions: the data previously used to test C-CuRE typically were balanced across combinations of (1) categories, (2) phonological contexts, and (3) talkers, and (4) were so equally for both C-CuRE was 'fit' on and the data that it was tested on (see, e.g., ; for a critique and demonstration that these assumptions can affect the conclusions to be drawn about the plausibility of different normalization approaches, see <ref type="bibr" target="#b327">Barreda &amp; Nearey, 2018)</ref>.</p><p>For the present study, we investigate how listeners might transfer and adapt expectations based on previous long-term exposure to novel input from an unfamiliar talker. We therefore used subsamples that were well-balanced between /d/ and /t/ tokens in terms of their frequency and phonological contexts-a pattern matched to those employed during the exposure and test in typical experiments. We note, however, that none of our core results seem to depend on the assumptions we make here. We obtained qualitatively identical results for all critical comparisons in previous simulations that did not subsample the data to be balanced with regard to /d/ and /t/ or their phonological contexts.</p><p>The three issues raised above also raise questions about C-CuRE that go beyond practical concerns for experimenters. For any of the three decisions we described above, it is an empirical question whether listeners do something similar. Put differently, there are complexities in applying approaches like C-CuRE to scenarios that are likely to occur in everyday speech perception that need to be investigated in future research.</p><p>For example, our third assumption essentially means that normalization is sensitive to which category tokens are inferred to originate from (unlike any normalization accounts we know of), and this can result in some counter-intuitive predictions. Consider a scenario, in which a listener hears 100 typical /d/ tokens that match the listener's prior expectations for /d/. As formulated in McMurray and Jongman (2011), C-CuRE would predict that the listener's estimate for the cue mean will move towards the category mean of /d/ (since normalization is assumed to be insensitive to which category tokens originate from). 18 Alternatively, if normalization is sensitive to which category a token is inferred to originate from, then the listener's estimate of the cue mean is predicted to not change much at all (since all tokens were expected given that they were a /d/). Which of these two rather different conceptualizations of normalization is empirically more adequate is, to the best of our knowledge, unknown.</p><p>Decisions 1-3 left a total of 5632 observations (2816 each for /d/ and /t/). To avoid over-fitting to individual talkers, we use linear mixed-effects regression rather than ordinary linear regression. This 'shrinks' talker-specific estimates of the cue means towards the overall (population-level) mean, and does so more when less data is available for the particular talker.</p><p>Separate regressions were use to predict VOT and f0 (Mel). Both regressions used the formula:</p><formula xml:id="formula_16">∼ 1 + (1| )<label>(5)</label></formula><p>Rather than to just use the residuals of these regressions, we only subtracted the random effects (BLUPs) from each observation. This removes the talker-specific effects from each token (as intended by C-CuRE) but leaves observations in the original cue space (rather than residual VOTs centered around 0), thus achieving talker normalization without loss in interpretability.</p><p>The R code for the steps described here is found in R markdown document for the main text, at the end of Section 2. <ref type="figure" target="#fig_32">Figures 33 and 34</ref> replot <ref type="figure">Figures 31 and 32</ref> after C-CuRE normalization has been applied to the data.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Changes in category representations</head><p>The updating of the four −1 parameters after observations of a category from the talker is described by the equations in (6), and is deterministic (for details and derivation, see <ref type="bibr">Murphy, 2012, p. 134)</ref>. and simply increase by 1 with each observation, capturing the fact that each observation adds additional information about the talker's category mean and covariances. m , is a weighted combination of its prior value m 0, and the category mean of the observations</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2452̄-</head><p>following the same logic that we applied to the inference of the overall cue mean in Equation</p><p>(3). Similarly, S , is a weighted combination of its prior value S 0, and the category variability of the observations, 19 plus an additional term that captures the uncertainty about the category mean. <ref type="figure">Figure 35</ref> visualizes the belief-updating process in Equations <ref type="formula" target="#formula_5">4</ref> </p><formula xml:id="formula_17">= S 0, + S + 0, m 0, m 0, − , m , m ,<label>(6)</label></formula><p>The s and s are also sometimes called "pseudocounts" because they have a rather intuitive interpretation: the value of these parameters can be seen as describing the number of observations of this category that the listener assumes to have observed from the talker. For example, a listener with ,0 = 100 updates her beliefs about an unfamiliar talker's category mean as if she has already seen 100 observations of that category from the talker prior to having received any input from that talker. After 900 observations of that category from the unfamiliar talker, this listener's belief about the talker's category mean would be a weighted mixture, made up to 10% by the prior m ,0 and to 90% of the mean of the 900 observed category instances̄. 20 §3.1.1 Setting the 0, and 0, parameters It is possible to treat 0, and 0, as free parameters of the Normal-Inverse-Wishart belief-updating model, and to infer them from participants' responses in perceptual experiments . This makes it possible to compare whether estimates of these parameters that are purely based on listeners' behavior correspond to distributions of category means and category covariances Σ that match those observed in the input that listeners have received throughout their lives-i.e., the joint distribution of and Σ observed in phonetically annotated databases that are are representative of the input listeners have previously received. If such a match is indeed observed, this would lend support to the hypothesis that listeners learn and store knowledge about the statistics of cue-to-category mappings in the input (for initial tests <ref type="bibr">20</ref> The extent to which listeners transfer prior expectations to an unfamiliar talker or context (i.e., the values of ,0 and ,0 ) is expected to differ across phonological contrasts (see discussion in . <ref type="figure">Figure 35</ref>. −1 Bayesian belief-updating model, as employed here. We set m 0, = E( ) and S 0, = E(Σ ), where E( ) and E(Σ ) are observable from phonetically annotated databases. We further assume that all categories share a common 0, and 0, , shown as 0 and 0 . These 0 and 0 are the only two degrees of freedom in this highly simplified model of distributional learning (in the manuscript, we keep the subscript to avoid confusion with the parameter for changes in normalization in Equation 3). All other variables are either observable (filled gray circles) or fully determined by other variables. of this type, and further discussion, see . However, it is also possible to instead set m 0, and S 0, based on phonetically annotated data. This fixes all DFs for m 0, and 2 ( 2 + ) DFs for S 0, prior to predicting listeners' behavior but assumes (rather than tests) that listeners learn and store knowledge about the statistics of cue-to-category mappings in the input. This latter approach is the one that we took in our case studies. The core idea is to select m 0, and S 0, so that they yield a prior joint distribution of and Σ that match those observed in a sufficiently large phonetic database that can reasonably assumed to approximate the type of input an average participant has received throughout their life.</p><formula xml:id="formula_18">Σ −1 , m , S , , update (Equation 6) m 0, 0 0 S 0, E( ) E(Σ ) ∀ ∈ ∀ ∈</formula><p>For the present purpose, we simplify this estimation problem further by setting m 0, and S 0, so that the expected values of the marginal distributions of and Σ match the maximum likelihood estimates of the category mean and covariance matrix, respectively, in the phonetic database . This means that we set m 0,c to the empirical mean (i.e., The prior distribution of the category covariance matrix Σ is described by the Inverse-Wishart distribution with scale parameter S 0,c and degree of freedom 0, . For our case studies, we thus again set S 0,c , such that the expected prior category covariance matrix matches the empirical covariance matrix̄(i.e., the empirical sum of squares matrix divided by the number of observations) estimated from the phonetic database given 0, . This yields</p><formula xml:id="formula_19">S 0,c = E(Σ )( 0, − − 1) =̄( 0, − − 1)</formula><p>, where is the dimensionality of input (i.e., the number of phonetic cues considered, cf. <ref type="bibr">Murphy, 2012, p. 134-5)</ref>.</p><p>We note that the approach employed in our case studies does not take into account that category means and covariance matrices can be correlated. In that case, the expected values of the marginal distributions of and Σ will not be identical to the expected value of the joint distribution of and Σ . 21 For future work, it would thus be more appropriate to estimate the joint distribution of and Σ from phonetic data, and to find the values for m 0, and S 0, that best approximate this distribution (e.g., through moment-matching). For the present purpose, however, this change is not expected to qualitatively affect the conclusions reached in our case studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>§3.2 Changes in decision-making</head><p>Here, we model the prediction error as the surprisal experienced when observing the category label, ( ). This surprisal is a log-inverse function of the posterior probability of the category label given the beliefs held by the listener prior to observing the category label.</p><formula xml:id="formula_20">logit( , ) = logit( −1, ) + ( ) = logit( −1, ) − log 2 −1 ( )<label>(7)</label></formula><p>The same amount that is added to the bias of the observed (labeled) category is subtracted from the response biases for all other categories (uniformly distributed across those categories).</p><p>Like the representational change model, the change model for response biases is sensitive to the mismatch between listeners' expectations based on the input and labeling information provided by the context. Unlike the representational change model, however, the change model for response biases uses the new observations to update response biases rather than beliefs about category likelihoods. As such, the change for response biases does not directly change the mapping from stimulus properties to categorization responses. The change model for response biases can, however, affect this mapping indirectly. This means that even simple changes in response biases can change listeners' categorization function in complex ways.</p><p>We also briefly considered another simple change model for decision-making but never implemented it since it could not possibly explain the findings we present in Sections 4 and 5.</p><p>This alternative model holds that listeners aim to infer the relative probability of each category based on recent input, and that response biases reflect these estimates. For example, listeners might enter an experiment with expectations about the relative probability of each category problematic, either for researchers or for listeners.</p><p>based on their relative frequency in previously experienced input, and then update their expectations based on the relative frequency of the categories within the experiment (similar to belief-updating models of syntactic adaptation, . However, such a model could not possibly explain exposure effects in, for example, a typical perceptual recalibration experiment since the relative frequency of the two categories does not differ between exposure conditions. §3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">(Non)-additivity of changes as a function of</head><p>In <ref type="figure" target="#fig_10">Figures 14 and 15</ref> in the main text, we demonstrate that the (non)-additivity of changes in decision-making depends on . Specifically, changes are additive in the log-odds of the posterior probability of categories if and only if ∈ {0, 1}. To see how this limitation arises, consider how the log-odds of a category-e.g., /d/-in Equation (2) depend on the response biases when = 0:</p><formula xml:id="formula_21">(/ /| ) = (1 − ) ( | / / , Σ / / ) / / Σ ( | , Σ ) + / / Σ = (1 − ) ( | / / , Σ / / ) / / Σ ( | , Σ ) + / / = (1 − ) ( | / / , Σ / / ) / / + / / Σ ( | , Σ ) Σ ( | , Σ ) ⇒ log (/ /| ) (/ /| ) = log (1 − ) ( | / / , Σ / / ) / / + / / Σ ( | , Σ ) (1 − ) ( | / / , Σ / / ) / / + / / Σ ( | , Σ ) = log (1 − ) ( | / / , Σ / / ) + Σ ( | , Σ ) (1 − ) ( | / / , Σ / / ) + Σ ( | , Σ ) + log / / / /<label>(8)</label></formula><p>When = 1, this simplifies to:</p><formula xml:id="formula_22">log (/ /| ) (/ /| ) = log / / / /<label>(9)</label></formula><p>And for = 0:</p><formula xml:id="formula_23">log (/ /| ) (/ /| ) = log ( | / / , Σ / / ) ( | / / , Σ / / ) + log / / / /<label>(10)</label></formula><p>Either way, a change in responses ( ) will result in a change in predicted categorization behavior that is independent of the , leading to changes in the log-odds of categorization responses that are constant across the acoustic-phonetic space.</p><p>Even when ∉ {0, 1}, equation <ref type="formula" target="#formula_21">8</ref>suggests that the type of changes in posterior log-odds that can be explained through changes in decision-making are constrained. For example, when the two categories exhibit equal variance (so that log</p><formula xml:id="formula_24">( | / / ,Σ / / ) ( | / / ,Σ / / ) describes a line)</formula><p>, changes in decision-biases are predicted to lead to changes in categorization that are most extreme between the two category means and converge against two different constants 'outside' of the two category means (see <ref type="figure" target="#fig_2">Figure 36)</ref>. The shape of the predicted changes further gains in complexity if the variances of the two categories differ <ref type="figure" target="#fig_4">(Figure 37</ref>). Further study of this constraint and similar limitations of the other changes models is needed to characterize the range of adaptive behaviors each model can predict (see Recommendation 5 in the general discussion). §4 Creating the stimuli for the (simulated) perceptual</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>recalibration paradigm</head><p>As also mentioned in the main text, many studies on perceptual recalibration do not report the acoustic properties of the exposure and test stimuli, 22 and analyses that relate the acoustic properties of exposure and test stimuli to participants' responses during test remain the exception.</p><p>In our experience, it is also not uncommon that original recordings are no longer available or only partially available (see one of our recommendations in the general discussions). Phonetic annotations that aid the extraction of acoustic information about these recordings are available  <ref type="figure" target="#fig_2">Figure 36</ref>. Predicted difference in posterior log-odds of /d/ as a function of the lapse rate ( ), prior response bias for /d/ ( / / ) and the change in that response bias after exposure (Δ / / ). For this example, only VOT is considered. The mean of /d/ and /t/ were set to that observed in  and the variance was held equal across the two categories (at the average of the variances observed in .  <ref type="figure" target="#fig_4">Figure 37</ref> . Same as in <ref type="figure" target="#fig_2">Figure 36</ref> but while setting the variances of the two categories to the unequal values observed in .</p><formula xml:id="formula_25">∆ π/d/ = 0.025 ∆ π/d/ = 0.05 ∆ π/d/ = 0.1 ∆ π/d/ = 0.2 π /d/ = 0.3 π /d/ = 0.5 π /d/ =</formula><p>for only a very small number of studies. 23 For that reason, we use simulated data in our case study on perceptual recalibration. Our stimulus generation procedure aims to capture the qualitative properties of the most common approaches to stimulus selection in perceptual recalibration experiments.</p><p>23 Some notable exceptions for research on US English include the labs of Drs. Babel (UBC), Myer (UConn), and Theodore (UConn). In an ongoing project at Rochester, we have collected a database of phonetically annotated perceptual recalibration experiments on L1 US English /s/-/ʃ/ that links stimulus recordings, phonetic annotations, and over 20 phonetic extracted phonetic cues to categorization responses from several thousand participants across a dozen experiments from multiple labs. Researchers interested in the database can contact any of the authors. §4.1 Exposure</p><p>As described in the main text, the exposure phase of a typical perceptual recalibration experiment employs both typical stimuli and stimuli that are manipulated to be perceptually ambiguous between the two categories. In practice, researchers determine this point of perceptual ambiguity by first generating a continuum from the recording of the typical sound (e.g., crocodile) to a recording in which that sound is replaced with the opposite sound (crocotile). Procedures to create these continua range from simple blending of the two recordings-mixing the two recordings weighted by different amplitudes (from 100% crocodile and 0% crocotile to 0%</p><p>"crocodile" and 100% crocotile)-to more careful phonetic manipulations (e.g., inserting addition silence to create longer VOTs) or the use of speech synthesis (for an insightful critique of the frequently used blending procedure, see <ref type="bibr" target="#b425">Theodore &amp; Cummings, 2021)</ref>. The former is the by far more common approach. The perceptually most ambiguous point along the resulting continua is then determined either by the experimenter(s) or in a separate norming experiment, with the former approach being far more common. In short, perceptual recalibration experiments do neither carefully select the tokens within each category based on phonetic properties, nor is there any form of counter-balancing of the average phonetic or perceptual shifts across the two bias conditions.</p><p>For the sake of generality, we simulate the general outcome of any of these procedures by imaging an experimenter (or participants) listening to stimuli along a continuum ranging from typical /d/ to typical /t/. We simulate the experimenter with the same perceptual model we assume for general L1-listeners (see Section 2). We assume that the experimenter, who can listen arbitrarily often to any of the stimuli, will make her final decision as to which stimuli should be selected for the shifted tokens without attentional lapses ( = 0). We further assume that experimenter's response bias is affected by the lexical context. Specifically, we set = ( | ) = 0.7. This captures the fact that even the experimenter's perception is somewhat affected by the lexical context. <ref type="figure" target="#fig_6">Figure 18A</ref> shows the phonetic properties of an instance of stimuli generated in this way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>§4.2 Test</head><p>For the test phase, we followed a similar procedure. We used the same continuum from a typical /d/ to a typical /t/, and then selected six stimuli along that continuum that would be expected to yield 15%, 35%, 45%, 55%, 65%, 85% /d/-responses in a norming experiment without any prior exposure to the talker's speech. Since the test tokens present the phonetic contrast in a non-biasing context (e.g., /ɪ_ɪ/), we set the effect of lexical context to ( | ) = .5. The resulting test tokens shown in <ref type="figure" target="#fig_6">Figure 18B</ref> closely resemble the placement of test stimuli expected in experiments on perceptual recalibration (e.g., : as is typical for such experiments, test tokens are placed primarily where they are expected to be perceptually most ambiguous prior to exposure (i.e., close to the prior category boundary), with one additional test token towards each end of the continuum (typically somewhere between 10-25% and 75-90%, respectively). Our approach further assumes that the exposure and test stimuli are carefully chosen to have phonological contexts that allow generalization from exposure to test, as differences in the types of phonological context between exposure and test can reduce or even completely block perceptual recalibration . For example, the original study that we model our procedure on mostly used exposure stimuli in which /d/ or /t/ occurred word-medially at the onset of a syllable, between two vowels (e.g., crocodile, academic, etc., see <ref type="table" target="#tab_10">Table 1</ref> in  or at least between two sonorants (e.g., legendary, secondary). In the test stimuli, the /d/-/t/ contrast occurred in a similar position (either /a_a/ or /ɪ_ɪ/). §5 Creating the stimuli for the (simulated) accent adaptation paradigm</p><p>As is the case for experiments on perceptual recalibration, the majority of studies on accent adaptation do not report the acoustic properties of the exposure and test stimuli, or present analyses that relate those properties to participants' responses. <ref type="bibr">24</ref> The stimulus generation</p><p>24 Notable exceptions include, for example, the labs of Drs. Chodroff (UZurich), Kartushina (UOslo) and <ref type="bibr">Schertz (UToronto)</ref>. In past work, we have analyzed to what extent the results of experiments on accent adaptation (including differences between experiments) can be explained by the specific phonetic properties of the stimuli (e.g., . These studies find that the results of procedure described below mimics a scenario that has been reported in previous work (e.g., . §5.1 Exposure</p><p>We simulate a scenario where the /t/ category remains unchanged between the L1-and L2-accents while the /d/ category is altered in the L2 accent. In the specific simulations presented in the main text, the cue weighting was changed so that the primary cue for L1 listeners (VOT) becomes the secondary cue in the L2-accented speech. This was achieved by adjusting the category mean of /d/ so that its distance from the category mean of /t/ is reduced along VOT but increased along f0, while preserving the relative ordering (i.e., the category mean of /d/ has smaller f0 and VOT than that of /t/). Additionally, we assume no difference in category covariance between the L1 and the L2 accents. This was done to focus our analysis on the influence of relative locations of the two categories between L1 and L2, keeping the effects of category dispersion constant. We note, however, that L1 and L2 categories also often differ both the location (category means) and their dispersion (category variance-covariance, e.g., <ref type="bibr" target="#b448">X. Xie &amp; Jaeger, 2020)</ref>. The code in this R markdown document can be straightforwardly extended to simulate such cases as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>§5.2 Test</head><p>For the test phase, we randomly sample 60 tokens per category from the L2-accented categories.</p><p>This procedure matches the approach typically taken by studies on accent adaptation: researchers record L2-accented speakers' productions of the target categories without making specific selection based on acoustic-phonetic features. §6 Optimization steps for Case Study 2 experiments on accent adaptation can strongly depend on the choice of stimuli. On the one hand, this should not be surprising. But it is often not considered in the interpretation of seemingly unexpected results. Indeed, though not necessarily framed as such, some previous findings already speak to the (in)sufficiency of the three mechanisms. Here we summarize some of those key findings, and describe possible extensions to them. We note, however, that-as we outlined in the general discussion-we do not believe that such (in)sufficiency tests are themselves sufficient to advance research on adaptive speech perception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>§7.1 Normalization vs. changes in category representations</head><p>While both normalization and the representational change model assume that listeners are sensitive to talker-specific changes in the usage of phonetic cues, only the latter tracks those differences separately for each category (e.g., /d/ vs /t/). This makes normalization computationally more parsimonious than representational changes for both researchers and listeners: for the normalization model, the number of parameters that researchers need to determine (e.g., fit from the behavioral data of perception experiments), and the number of estimates that listeners need to infer and store from the speech input does not increase with the number of categories (for related discussion, see also . For example, for the C-CuRE-based normalization model employed in our case studies, researchers need to determine only one parameter ( 0 ) and listeners are assumed to infer and store only the overall means of all cues ( values for cues). In contrast, the representational change model employed in our case studies requires researchers to determine two parameters per category, and listeners are assumed to infer and store the cue means and covariance matrices of each category ( + 2 ( 2 + ) values for cues and categories). 25</p><p>While the parsimony of normalization offers a computational advantage in terms of efficiency, it also comes with limitations. We discuss three such limitations that future work can exploit to evaluate the sufficiency of this mechanism. First, normalization accounts predict that the effects of exposure on subsequent perception do not depend on the category membership inferred by listeners. For example, for C-CuRE, only the overall cue mean of the input can affect subsequent perception, regardless of whether the lexical context labels the input as one category or another. <ref type="bibr">26</ref> Although not originally discussed in the context of normalization, there is evidence that challenges this prediction. In their seminal study on perceptual recalibration, Norris et al.</p><p>(2003) exposed participants to /f/-or /s/-biased inputs using the same general design that we discussed for Case Study 1. As is now typical for perceptual recalibration experiments, participants were exposed either to words with typical /f/ and words with atypical (shifted) /s/ or to words with typical /s/ and words with atypical (shifted) /f/. This resulted in the signature perceptual recalibration effect.</p><p>Of relevance to the present discussion, one of several control experiments conducted by Norris and colleagues exposed participants either to words with typical /f/ and non-words with atypical (shifted) /s/, or to words with typical /s/ and non-words with atypical (shifted) /f/. The atypical /f/ and /s/ sounds in these control conditions were acoustically identical to those in the experimental conditions, and the non-word contexts in the control conditions matched the word contexts in terms of the phonetic context surrounding the critical /f/ and /s/ sounds (specifically, in terms of lexical stress and the vowel immediately /f/ or /s/). In short, the two control conditions differed from the experimental conditions almost exclusively in whether the atypical inputs were lexically labeled to be of a particular category. Unlike the experimental conditions, however, the control conditions did not elicit the signature boundary shift <ref type="bibr">(Norris et al., 2003, Experiment 2)</ref>. Perceptual recalibration thus seems to depend on the category that the shifted atypical tokens are attributed to <ref type="bibr">(Norris et al., 2003, p. 227)</ref>-contrary to what would be expected if adaptive speech perception was solely achieved through cue normalization. 27</p><p>A second computational limitation of normalization accounts is specific to accounts that only correct for differences in the overall mean of cues but not differences in cue variability (like C-CuRE). In a ground-breaking study that was targeted at a separate question, Clayards et al.</p><p>(2008) exposed participants to distributions of synthesized /b/ and /p/ tokens (as in, e..g, beach-peach continuum). Between participants, the VOT of these tokens had been manipulated to either form wide or narrow VOT distributions for both /b/ and /p/. The VOT means of /b/ and /p/ were identical in both conditions. Since acoustic cues are encoded relative to the cue mean only in C-CuRE and similar normalization accounts, these accounts thus do not predict any differences in the effects of these exposure conditions. Clayards and colleagues, however, found that participants in the wide variance condition exhibited shallower categorization functions along the VOT continuum (conceptually replicated in Nixon et al., 2016)-as predicted by representational change models (see . Future research should test whether this finding replicates for more natural-sounding (rather than resynthesized, robotic-sounding) stimuli and in situations where 27 There might be a way to repair this apparent deficiency of normalization accounts that is compatible with the central idea behind C-CuRE. If the inferred category of a token is included in the contextual factors used to remove expectations from the observed cues, then the findings of  can be accounted for (since the category label is unknown when the token is embedded in a non-word context). Specifically, normalization would have to remove from each cue expectations due to the token's inferred category and then add those expectations back in prior to interpreting the cue (e.g., following the same approach we employed throughout this study with regard to talkers; see §2.1). This modification to C-CuRE would entail that top-down feedback from category representations can affect the interpretation of cues (though one might argue that C-CuRE already makes the same assumption with regard to surrounding phonological and lexical context)-an assumption compatible with neuro-anatomical evidence of feedback connections from cortical to subcortical areas involved in auditory processing but potentially in conflict with some theories and findings (e.g., <ref type="bibr" target="#b399">Norris et al., 2000;</ref>. We are not aware that this change to C-CuRE has been discussed in the literature.</p><p>task demands more closely resemble those of everyday speech perception (less repetition, more lexical heterogeneity, words presented in sentential contexts rather than in isolation, etc.). If such replications are obtained, this would argue that normalization would at least have to include standardization or similar corrections for the variability of cues (as proposed in <ref type="bibr" target="#b371">Johnson, 2020;</ref><ref type="bibr" target="#b392">Monahan &amp; Idsardi, 2010)</ref>.</p><p>A third limitation of normalization accounts that can be productively explored in future research is the lack of category specificity. Consider for example, a possible extension of the study by Clayards and colleagues. In the study by , both /b/ and /p/ either had narrow variance along VOT (SD = 8 msecs) or wide variance (SD = 14 msecs). This confounds the category-specific variance with the overall variance of the cues along VOT. It is, however, possible to manipulate the variance of the two categories while keeping both the means of the two categories (and thus the overall cue mean) and the overall cue variance constant. <ref type="figure">Figure 39</ref> depicts two exposure conditions that achieve this, along with recognition accuracies predicted by normalization and representational change models. 28 This demonstrates how researchers might use the lack of category-specificity to disentangle normalization and representational change accounts. Other possible manipulations in this vein could include category-specific changes in the covariance of cues. Basically, any manipulation that leaves the overall cue mean and variance unaffected while predicting differences in the categorization function under the representational change model can test whether the human listeners exhibit more flexibility than expected by normalization accounts. We note, however, that any such test should take into account that listeners can have strong prior beliefs based on the speech input they have received previously, and that this might include strong prior beliefs about how the realization of categories varies across talkers . If the manipulations employed by researchers strongly violate those expectations, this needs to be carefully considered in the derivation of predictions.</p><p>28 The specific predictions for the representational change model shown here assume that listeners have equally strong prior beliefs about the variance of both of the two categories (i.e., one 0, for both categories). This is what we assumed in our case studies-which aimed to show that even simplified versions of each change model can explain a wide range of findings in the literature-but it is not an inalienable assumption for representational change models (for discussion, see also . The general prediction of representational change models that listeners are sensitive to the category-specific variance should hold even if this assumption is removed. How easy to detect this predicted difference is, however, expected to depend on this assumption.  <ref type="figure">Figure 39</ref>. A possible way to contrast normalization and representational change accounts. Panel A: two exposure conditions with identical overall means and variances along VOT, but different category-specific variances. Panels B and C: the predictions of the best-performing representational and normalization change models. For this purpose, the normalization model was extended to both center and standardize the cues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>§7.2 Changes in decision-making vs. changes in category representations</head><p>In Section 2, we showed that the limitations of change models for decision-making are less well understood than sometimes assumed. One recommendation for future research is thus to further explore the mathematical limitations of decision-making change models. Designs that limit attentional lapses to basically zero (e.g., by employing more engaging tasks, as in gamified paradigms, <ref type="bibr" target="#b380">Lim &amp; Holt, 2011;</ref><ref type="bibr" target="#b429">Wade &amp; Holt, 2005)</ref> would emphasize the computational limitations of decision-making change models. In such scenarios, changes in response biases can only explain changes that are additive in the posterior log-odds of categories (Section 2.2.3). That is, changes in response biases cannot account for changes in the slope of categorization functions.</p><p>Future studies should use exposure conditions for which such changes are predicted by representational or normalization models to test whether changes in response biases are sufficient to explain adaptive speech perception. Since it can be difficult to detect changes in categorization slopes-especially without making strong linearity assumptions, we suspect that this question is better explored by manipulating the relative reliability of two cues (see also <ref type="figure" target="#fig_25">Figure 29</ref>). Such manipulations are routinely used in a paradigm known as "dimension-based statistical learning" . With recent trends towards analyses that more transparently link phonetic cues to changes in participants' responses , see also Section 6.2) this field of study is in a good position to test the sufficiency of changes in decision-making accounts. An ongoing project from one of our labs, uses ASP-like simulations in combination with experimental designs that are intended to directly address this question .</p><p>Conversely, there are ways to assess whether representational changes alone are sufficient to explain all forms of adaptive speech perception. For example, if auditory input that arguably carries no information about category statistics affects subsequent speech perception, this provides evidence that changes in representations alone cannot explain all aspects of adaptive speech perception. Perhaps one of the most convincing demonstrations of this type comes from the findings of auditory enhancement effects, wherein non-speech stimuli (e.g., pure tones) can systematically alter the perception of subsequently played speech stimuli <ref type="bibr" target="#b358">Holt, 2005</ref>; for review, see also . While these demonstrations might be challenged for lack of ecological validity (potentially inviting meta-reasoning about experimenters' intentions that is unlikely to be present during everyday speech perception), it is unclear how representational changes-or, for that matter, changes in response biases-can explain such findings. At the very least then, these findings suggest that normalization can be involved in adaptive speech perception.</p><p>In sum, by focusing on the computational assumptions of the different change models, it is possible to conduct behavioral experiments that can decisively determine whether either of the two computationally more parsimonious change models is sufficient to explain adaptive speech perception, or whether changes in representations are necessary to explain adaptive speech perception. §8 Advanced standards of data annotation and sharing</p><p>As we mentioned under Recommendation 1, predicting adaptive changes of recognition requires estimates of the acoustic-phonetic properties of both input listeners have received prior to the experiment and the input they receive during the experiment. The former can be obtained from sufficiently large phonetically annotated databases that capture the type of speech input a typical participant in the experiment is likely to have received throughout their life. Fortunately, large and phonetically annotated databases can offer good estimates of the speech input of listeners receive. Such databases are now available for an increasing number of phonetic contrasts and languages (e.g., <ref type="bibr" target="#b341">Clopper &amp; Pisoni, 2006;</ref><ref type="bibr" target="#b357">Hillenbrand et al., 1995;</ref><ref type="bibr" target="#b426">Theodore et al., 2009;</ref><ref type="bibr" target="#b448">X. Xie &amp; Jaeger, 2020</ref>, among many others).</p><p>One caveat is that many of these databases either only contain a subset of the speech varieties that an average listener of a language has plausibly been exposed to or contain very little data for each variety. In particular, databases that contain both a large number of talkers and a large number of tokens per talker continue to be the exception. Researchers thus need to carefully consider these implications when employing databases. In some cases, researchers might find that the best way forward is to collect phonetically annotated data that meets the specific requirements for their study (see <ref type="bibr" target="#b406">Persson &amp; Jaeger, 2022;</ref>. An alternative option is to eschew phonetically annotated data in favor of computational methods that work from the raw signal or some automatically obtained transformation of the raw data (e.g., mel-frequency cepstral coefficients, <ref type="bibr" target="#b389">Mermelstein, 1976)</ref>. Such models have been developed for automatic speech recognition and have been employed to model human language acquisition <ref type="bibr" target="#b346">(Dupoux, 2018;</ref>. More recently, they have also been applied to address questions about the effects of recent exposure . The ASP framework can, at least in theory, be combined with such models.</p><p>The second set of estimates-the acoustic-phonetic properties of the stimuli-require researchers to phonetically annotate the stimuli in their perception experiments. Such annotations entail a substantial but manageable effort: perception experiments typically employ a small number of speech stimuli that are repeated across participants. A typical perceptual recalibration experiment would require the annotation of fewer than 100 isolated word recordings.</p><p>A large study on accent adaptation like <ref type="bibr" target="#b19">Bradlow and Bent's (2008)</ref> Experiment 2 would require the annotation of about 1000 sentences. As a reference point, studies on phonetic production regularly annotate data sets many times larger. Researchers' efforts will be supported by clear standards for reproducibility and software developments that aid phonetic annotation and data sharing (e.g., <ref type="bibr" target="#b336">Cassidy &amp; Schmidt, 2017;</ref><ref type="bibr" target="#b407">Picoral et al., 2021;</ref><ref type="bibr" target="#b412">Roettger et al., 2019;</ref><ref type="bibr" target="#b445">Winkelmann et al., 2017)</ref>. If annotations are not reported and shared-and ideally even if they are-then all audio recordings should be shared in an open and accessible way (e.g., OSF). This will require perception researchers to use human subject protocols that gives them the consent to distribute stimulus recordings for the purpose of scientific inquiry. In other words, perception and production researchers should make concerted efforts to link the listener's knowledge of productions and inferences they make during perception.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 .</head><label>6</label><figDesc>(a) Distributions for /b/ and /p/ (b) Distributions for /d/ and /t/ (c) Distributions for /g/ and /k/ (d) Categorization for /b/-/p/ (e) Categorization for /d/-/t/ (f) Categorization for /g/-/k/ Illustrating listeners' implicit category representations. Top row: Bivariate Gaussian category likelihoods learned from (fit to) the by-talker normalized cue distributions in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7</head><label>7</label><figDesc>Figure 7 . Illustrating the effects of and on the posterior probability of /d/, using the two bivariate Gaussian categories of /d/ and /t/ shown in Figure 6b. The colored planes indicate the ceiling and flooring levels of posterior probability of /d/. Panel a) here is identical to Panel e) in Figure 6with = 0 and / / = .5. Top panel: Differences in lapse rate for a uniform bias of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>beliefs about cue mean (1 DF)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Graphical representation of Equation 3, describing how normalization changes with exposure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 11shows how the expected category likelihoods of the four models change as a function of input from the new Prior κ c,0 = ν c,0 = 4 B) Prior κ c,0 = 4 , ν c,0 = 1024 C) Prior κ c,0 = 1024 , ν c,0 = 4 D) Prior κ c,0 = ν c,0 = 1024</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>captured by changes in representations than by normalization (which of these two change mechanisms better describes listeners' abilities is, however, an open question). beliefs about category mean (up to DF) category mean observed from unfamiliar talker number of observations for category from unfamiliar talker S ,0 prior beliefs about category covariance matrix (up to 2 ( 2 + ) DF) 0 strength of prior belief about category covariance (up to DF) S category sums of squares observed from unfamiliar talker Figure 10. Simplified graphical representation of Equation 4, describing how category representations change with exposure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure 13expresses the change model for decision-making as a graphical model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 14</head><label>14</label><figDesc>illustrates the proposed change model for three different values of when the lapse rate = 0. Here and in the case studies in Sections 4 and 5, we assume uniform initial biases across all categories, leaving as the only degree of freedom. The right panel highlights an interesting limitation in the types of results that can be explained through changes in response biases: in the absence of lapses ( = 0) or when all responses are lapses ( = 1), changes in response biases can only explain additive effects on the log-odds of the categories, but not changes in the slope of the categorization function. This property does not depend on the specific change model assumed here (for derivation, see SI, §3.2.1). Critically, this strong constraint on changes in decision-making only follows if ∈ {0, 1}. For ∉ {0, 1}, changes in response biases lead to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 .</head><label>15</label><figDesc>Same asFigure 14but for a lapse rate = 0.05. For such non-zero lapse rates, changes to the response bias have non-additive effects on the posterior log-odds. This means that, even in log-odds, changes in response biases can have effects that go beyond purely additive changes in the categorization functions ('shifts in category boundaries'). Animation controls require Acrobat PDF reader.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 17 .</head><label>17</label><figDesc>Categorization functions observed during the test phase of the perceptual recalibration experiment presented in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 18</head><label>18</label><figDesc>shows the stimuli for the exposure and test phases of the experiment. During /d/-shifted exposure, listeners hear 20 lexically-labeled word recordings containing /d/ shifted towards /t/ and 20 lexically-labeled word recordings containing typical /t/, mixed in with word and non-word fillers for a total of 200 recordings. As is typical for perceptual recalibration experiments, these fillers are assumed not to contain any information about the VOT distributions of /d/ and /t/, and thus do not affect listeners' beliefs about those distributions. During /t/-shifted exposure, participants hear lexically-labeled 20 word recordings containing /t/ shifted toward /d/ and 20 lexically-labeled word recordings containing typical /d/. Shifted recordings are selected to be perceptually half-way between /d/ and /t/.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 20 .</head><label>20</label><figDesc>Expected category likelihoods (based on expected category mean and covariance matrices) after exposure, depending on the exposure condition and the strength of the prior beliefs in categories means ( ,0 ) and covariances ( ,0 ). Only a illustrative subset of the ,0 and ,0 values from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 24 .</head><label>24</label><figDesc>Panel A -Exposure: Distribution of the stimuli used during the exposure phase of the accent adaptation experiment (30 tokens each of L1-accented and L2-accented /d/ and /t/, respectively). Panel B -Test: Distribution of the stimuli used during the test phase of the accent adaptation experiment. The test tokens come from L2-accented speech (60 tokens per category)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 25 .</head><label>25</label><figDesc>Predictions of a learning model that derives accent adaptation as changes in category representations. Predicted categorization accuracies for the L2-accented test tokens after L1-accented and L2-accented exposure, as a function of the strength of the prior beliefs in category means ( ,0 ) and covariances ( ,0 ). The average accuracy across /d/ and /t/ is shown above the bars for each exposure condition. Error bars show 95% bootstrapped confidence intervals. The highlighted panel is the one closest to the best-performing parameterization ( 0, = 1; ,0 = 4; overall accuracy = 0.93).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>middle row shows an example of contrast shift, where two categories in L2-accented speech are shifted along one or more of the cue dimensions as compared to L1-accented speech. Here it is simulated by shifting both /d/ and /t/ categories towards lower VOT (qualitatively attested for, e.g., word-initial stops in French-accented English, Sumner, 2011b). The bottom row ofFigure 28shows a more extreme example, exhibiting almost complete contrast collapse (similar to the loss of the [s]-[θ]  contrast that can occur in Mandarin-accented English,<ref type="bibr" target="#b321">Zheng &amp; Samuel, 2020)</ref>. Here it is simulated by making /d/ identical to /t/.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure</head><label></label><figDesc>28B further shows the predictions of the best-performing parameterization for each change model (listed in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 28 .</head><label>28</label><figDesc>Predicted adaptation for three types of L2 accents, from top to bottom: contrast reduction, contrast shift and contrast collapse. Predictions were derived for one random experiment of the same number of exposure and test stimuli as in Case Study 2. Multiple simulations were performed following the same procedure described in the main scenario above. Panel A -Distributions of L1-accented and L2-accented categories: L1-accented categories, represented in light shades, are kept constant across the three scenarios and identical to that in the main scenario above; L2-accented categories, represented by solid ellipses, are varied across scenarios. Panel B -Change model predictions: Predicted categorization accuracies for the L2-accented test tokens after L1-accented and L2-accented exposure, for the best-performing parameterizations of each change model (cf. highlighted panels inFigure 25-27). The average accuracy across all test tokens for each condition is shown above the bars. Error bars show 95% bootstrapped confidence intervals.reduction (top row) and contrast collapse (bottom row), for example, resemble the scenario considered in Case Study 2: without informative exposure, L1 listeners unfamiliar with the accent are expected to struggle with the recognition of /d/ than the recognition of /t/. The opposite is observed for our example of contrast shift (middle row). This illustrates how differences in the realization of L2 vs. L1 accents can give rise to different perceptual consequences for L1 listeners.The three scenarios also differ in the maximal benefits that L1 listeners can gain from L2 accent exposure. Three aspects are worth noting. First, corroborating the point we raised above, changes of representations do not always outperform the other two mechanisms. For the case of contrast reduction (top row), changes in decision-making and normalization perform as well as, or better than, changes in category representations. This underscores our main conclusion from Case Studies 1 and 2 that the computational complexity afforded for the representational change model does not always result in higher recognition accuracy than the other two mechanisms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 29 .</head><label>29</label><figDesc>Using the best-performing parameterization for each model, the three change models predict different categorization functions when applied to the data from Case Study 2. From left to right: predictions for changes in representations, decision-making, and normalization. Top row: Predicted recognition accuracy from the three change models. Second row: Predicted categorization functions after L1-accented exposure. Third row: Same but after L2-accented exposure. Bottom row: Differences in predicted posterior log-odds of /d/ between the two exposure conditions. Blue indicates higher predicted posterior log-odds of /d/ in the L2-accented exposure condition, relative to the L1-accented exposure condition. Red indicates the opposite. Gray indicates a difference of 0. The three models make distinct predictions about how exposure affects the perception of specific tokens across the VOT-f0 space. parameters that predict highly similar overall accuracy. While predicted categorization functions are quite similar across the three change models for the L1-accented exposure condition (second row), they vary more widely for the L2-accented exposure condition (third row). The bottom row ofFigure 29further suggests that the three change models differ qualitatively in what type of change in the categorization function they predict after L2-accented exposure. Whereas the effect of L2-accented, compared to L1-accented, exposure can be complex for the representational model (bottom left panel), it appears more constrained for changes in decision-making (bottom center panel) and normalization (bottom right panel). These differences reflect the computational limitations of each change models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>yields on how different types of exposure change the shape and location of the categorization function, the easier it is to determine the relative engagement of the different change mechanisms.Each change model is subject to different computational limitations, and these limitations affect what types of changes in categorization functions the different change models can account for (see, e.g.,Figure 29in the previous section). This idea is further illustrated inFigure 30. In this section, we discuss how researchers can design their experiments that generate results that are informative about changes in categorization functions. Several design properties under researchers' control can make an experiment more informative about the constraints on changes in listeners' categorization functions. As described under Recommendation 1, the changes in categorization functions predicted by different change models depend on both the exposure and test stimuli. For exposure, both the stimulus location in the acoustic-phonetic space-relative to listeners' prior expectations-and the number of exposure stimuli affect the predictions of change models. The location of exposure stimuli determines the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 30 .</head><label>30</label><figDesc>Illustrating how dense and repeated sampling of categorization responses can shed light on the relative engagement of different change mechanisms. Panel A: Observed changes of human responses from before to after exposure can be characterized along multiple acousticphonetic dimensions. Panel B: Different change models predict different incremental changes in human behavior. Repeated sampling of human responses after different types and amounts of exposure (e.g., Tests 1-3) increases researchers' power to distinguish between mechanisms. Each line represents a particular parameterization of ASP's change models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>. A particular parameterization of ASP's change model can simulate how human listeners' behavior could change after different types and amounts of exposure. Repeated and incremental sampling of human responses (e.g., as indicated as Tests 1-3 in Figure 30) can thus boost researchers' abilities to distinguish between the underlying mechanisms as well as any combinations of them.Researchers can also benefit from selecting test stimuli to be maximally informative about changes listeners' categorization functions. Paralleling our recommendations for exposure stimuli, this includes considerations about both the location and the number of test stimuli. For example, to detect differences between the different categorization functions, an experiment needs to employ test stimuli that are sufficiently distributed across the acoustic-phonetic space. This is worth emphasizing since it is typically not the case in experiments on perceptual recalibration and accent adaptation. For perceptual recalibration, experimenters tend to target stimuli that are expected to be maximally ambiguous. This makes sense if the goal is to detect the existence of a shift in the categorization function. But it is far from optimal when the goal is to understand the relative engagement of different change mechanisms, which requires identifying the nature of changes in the categorization function (Recommendation 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head></head><label></label><figDesc>data was extracted from an audited subset of the Mixer 6 corpus (Brandschain et al. 2010, Brandschain et al. 2013; Chodroff et al. 2016) containing approximately 45 minutes of read speech from 180 native AE speakers (102 female). Transcripts were aligned to the corresponding WAV files with the Penn Forced Aligner (Yuan and Liberman 2008), and all word-initial prevocalic stop consonants were further processed with AutoVOT (Keshet et al. 2014). AutoVOT automatically identifies the stop release and following vowel onset within a user-specified window of analysis. Further details about the talkers, read sentences, and boundary alignments can be found in Chodroff and Wilson (2017).³ COG, positive VOT, and onset f0 in the following vowel were measured for each stop. COG was calculated from a smoothed spectrum over the initial portion of the release burst. Each spectrum was computed by averaging FFTs from seven consecutive 3 ms windows, with the first window centered on the burst transient and a window shift of 1 ms (Hanson and Stevens 2003; Flemming 2007; Chodroff and Wilson 2014). Positive VOT was defined as the duration from stop release to the onset of periodicity in the vowel; this was automatically extracted from the AutoVOT boundaries or from manually-corrected boundaries when available. The f0 value was the first one measured by Praat (Boersma and Weenink 2016) within 50 ms after the following vowel onset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 33 .</head><label>33</label><figDesc>Same asFigure 31but for normalized VOT and f0. Normalization does not affect the relative placement of tokens within the talker's space but it does affect the absolute placement. This is also evident inFigure 34</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 34 .</head><label>34</label><figDesc>Same as Figure 32 but for normalized VOT and f0-both for the means and for the 95% ellipse. §3 Additional details about the change models This section contains additional details about the change models. §3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head></head><label></label><figDesc>maximum likelihood estimate) of the category's cue distribution,̄, estimated from the phonetic database. Since the Normal-Inverse-Wishart belief-updating model describes the prior distribution of the category mean as a Normal distribution with mean m 0, yields an expected prior category mean E( ) = m 0,c =̄.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 38</head><label>38</label><figDesc>summarizes the effects of parameterizations for each of the three change models on the overall accuracy for L2-accented speech after L2-accented exposure in Case Study 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 38 .</head><label>38</label><figDesc>Parameter space explored by the search for the best-performing parameterizations of the three different change models in Case Study 2. §7 Computational limitations of change models afford qualitative tests of their sufficiencyThe three change models-as well as the three general hypotheses that they aim to implement-differ in their computational assumptions. Given these assumptions, it is possible to conduct experiments that can decisively test the (in)sufficient of any of the three mechanisms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>The two case studies build on each other, each introducing new insights. Experiments on perceptual recalibration use comparatively simple stimulus designs, intended to elicit simple boundary shifts along a uni-dimensional perceptual continuum. And while the specific tasks employed during exposure and test can vary across studies, the general stimulus design is</figDesc><table /><note>remarkably similar across experiments. This allows us to use Case Study 1 to introduce many of the relevant concepts while keeping the paradigm comparatively simple. Case Study 2 then introduces additional complexities that come with modeling natural accents, which can deviate from listeners' expectations in heterogeneous ways across multiple acoustic-phonetic dimensions. This additional complexity has caused researchers to question whether the same mechanisms that underlie perceptual recalibration also underlie adaptation to natural accents (see recent reviews, Baese-Berk et al., 2018; Bent &amp; Baese-Berk, 2021; Zheng &amp; Samuel, 2020). Case Study 2 sheds new light on this question by asking whether even simple changes in decision-making or normalization can suffice to explain accent adaptation. Additionally, Case Study 2 allows us to illustrate an important consideration for future work: while all three change mechanisms predict that exposure should facilitate-or at least not hinder-subsequent processing of the same accent, the exact effects of exposure are predicted to depend on the specific accent properties and how they relate to listeners' prior expectations. In the general discussion, we elaborate on this point and how future work can draw on it.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>example, in the top-right panel. Although such changes in slopes are often not discussed, they are present in many perceptual recalibration experiments (e.g.,<ref type="bibr" target="#b182">Myers &amp; Mesite, 2014)</ref>.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>explain adaptive speech perception. As such, it is not surprising that all three models predict changes in the 'right' direction, compared to the absence of an adaptive response-i.e., that all models change the categorization function in ways that is meant to accommodate the acoustic properties of the exposure stimuli. 10 On the other hand, the three change mechanisms assume very different cognitive architectures, and each of the three change models is subject to different computational limitations. Specifically, the two simpler change models for normalization and decision-making involve fewer degrees of freedom, and have access to less information, compared to the change model for category representations. Recall, for example, that normalization affects cue values regardless of category membership, or that changes in decision-making can only predict</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>κ 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">1024</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">/d/−shifted</cell><cell></cell><cell></cell><cell cols="2">/t/−shifted</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>f0 (Mel)</cell><cell></cell><cell cols="2">1 2345 6 1 6</cell><cell></cell><cell></cell><cell></cell><cell cols="2">1 2345 6 1 2345 6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>200</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>25</cell><cell cols="2">50</cell><cell>75</cell><cell></cell><cell>25</cell><cell>50</cell><cell>75</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">VOT (msec)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Exposure condition</cell><cell cols="2">/d/−shifted</cell><cell cols="2">/t/−shifted</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Proportion /d/−responses</cell><cell>0.00 0.25 0.50 0.75 1.00</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell cols="2">2 Test token 4</cell><cell>6</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>2</cell><cell>4 4</cell><cell>6</cell></row></table><note>Figure 23. Predictions of a model that derives perceptual recalibration from changes in normaliza- tion. Predicted categorization responses are shown for the 6 test locations after /d/-and/t/-shifted exposure, depending on the relative weighting of previous experience ( 0 ) during the inference of the cue mean during exposure. Smaller 0 indicate faster learning.additive changes in the log-odds of categorization responses (when listeners have lapse rates of 0 or 1). Given these differences between the models, it seemed plausible that the simpler models would have insufficient functional flexibility to account for the types of boundary shifts associated with perceptual recalibration. Case Study 1 suggests that this is not the case. At least at the level of analysis that is typically applied in these experiments, the signature result of perceptual recalibration experiments therefore does not constitute decisive evidence for changes in representations. Rather, boundary shifts could result from any of the three types of change mechanisms. This does not, of course, mean that perceptual recalibration experiments are necessarily uninformative about the mechanisms underlying adaptive speech perception. To anticipate the general discussion, if adequate approaches to data analysis are chosen, it is possible to distinguish between the three different change mechanisms (and even combinations of them).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>had listeners transcribe a total of 160 sentences of either Mandarin-accented US English or L1-accented US English, distributed over two sessions on two separate days. In a subsequent test phase, both groups transcribed Mandarin-accented sentences. Participants who were first exposed to Mandarin-accented US English were significantly more accurate during test (over 90% accuracy compared to about 80%). This finding has since been replicated and extended (for review, see Baese</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>). 11 For example, in an exposure-test experiment, exposed two groups of L1-US English listeners to Mandarin-accented US English speech. In exposure, participants in the treatment group heard 30 words ending in /d/ (e.g., overload) together with 60 word fillers and 90 nonword fillers.Participants in the control group did not hear any words that contain /d/. After exposure, participants in both conditions categorized recordings of 60 minimal /d/-/t/ pairs (e.g., seed vs. seat) spoken by the same Mandarin-accented talker. Participants who heard /d/-final words during exposure were more likely to categorize /d/-final words correctly during test, compared to the control condition. At the same time, a non-significant numerical decrease in accuracy was</figDesc><table /><note>observed for /t/-final words (see also Xie, Earle, &amp; Myers, 2018). Related paradigms have yielded similar results for other contrasts and other L1-L2 pairs (e.g., Eisner et al., 2013; Zheng &amp; Samuel, 2020). For Case Study 2, we construct a hypothetical experiment that closely follows this type of design. For the sake of continuity, we focus on the same syllable-initial /d/-/t/ contrast used in Case Study 1, simulating exposure to Korean-accented L2 English. Like in Case Study 1, we analyze the data following the conventions of the field. For experiments on accent adaptation, this typically means that the facilitatory effects of L2-accented exposure are assessed through improvements in categorization accuracy during test. As in Case Study 1, we ask whether any of the three change mechanisms can qualitatively explain the signature results found in Xie et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 1</head><label>1</label><figDesc>Parameter range considered for each change model</figDesc><table><row><cell>Model</cell><cell cols="2">Parameters Range</cell></row><row><cell>Changes in decision-making</cell><cell></cell><cell>0 to 1</cell></row><row><cell></cell><cell></cell><cell>0.001 to 100</cell></row><row><cell>Changes in representations</cell><cell>,0</cell><cell>1 to 10000</cell></row><row><cell></cell><cell>,0</cell><cell>4 to 10000</cell></row><row><cell>Changes in normalization</cell><cell>0</cell><cell>1 to 10000</cell></row><row><cell cols="3">parameterizations were determined by bounded quasi-Newton optimization of the recognition</cell></row><row><cell>accuracy during test after L2-accented exposure</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>That is, like the other two change models, normalization can predict overall improvements in recognition accuracy after L2-accented exposure. Indeed, for the specific L1-L2 accent combination considered here, the computationally simple model for changes in normalization yields improvements similar to those predicted by changes in category representations-paralleling the results for changes in decision-making.</figDesc><table><row><cell>0.78</cell><cell>0.8</cell><cell>0.79</cell><cell>0.83</cell><cell>0.79</cell><cell>0.88</cell><cell>0.8</cell><cell>0.91</cell><cell>0.8</cell><cell>0.91</cell><cell>0.8</cell><cell>0.92</cell></row></table><note>/d/ test tokens are categorized substantially less accurately than /t/ test tokens. For L2-accented exposure, recognition accuracy is improved for /d/ test tokens without the cost of equivalent decreases in recognition accuracy for /t/.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>Best-performing parameterizations across different accent scenarios (rounded). Recall that</cell></row><row><cell>best-performing here refers to the parameterization that achieves the highest accuracy on</cell></row><row><cell>L2-accented test tokens, rather than best quantitative fit against human data (which we do not</cell></row><row><cell>have).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>). 14As already mentioned, this does not mean that normalization, representation, and decision-making mechanisms always predict the same response patterns-they do not. Nor does it mean that the relative involvement of the three mechanisms cannot be empirically determined through experiments. Rather, as we show in more detail below, it means that the design and level of analysis employed in many studies severely limit what the resulting experiments can tell us about the relative engagement of the different change mechanisms. This, we argue, calls for changes to the paradigms and analyses that are commonly employed in research on adaptive speech perception, and we make specific recommendations below.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>In short, research on adaptive speech perception is at an important juncture. On the one hand, existing findings suggests that no single change mechanisms can explain the full variety of adaptive responses that humans exhibit. Put this way, it seems obvious that the field will have to move beyond (in)sufficiency tests, towards experiments that determine how multiple change mechanisms jointly achieve adaptive speech perception. This will likely require research on howthe relative engagement of different change mechanisms depends on stimulus properties, task demands, or individual differences between listeners. For example, simple shifts of categories along a single continuum (as simulated in perceptual recalibration experiments) may engage change mechanisms different from those that are used to navigate more complex shifts as seen in Similarly, it is possible that the relative engagement of different change mechanisms depends on the type of phonetic contrast, or even the type of cue. This would be expected, for example, because different types of cues exhibit different degrees of within-and between-talker variability (see discussions in Kleinschmidt &amp; Jaeger, 2015, p. 179-180; Kraljic &amp; Samuel, 2007; Xie, Buxó-Lugo, &amp; Kurumada, 2021). However, the paradigms and analyses commonly employed in the study of adaptive speech perception are not well-suited to address these questions. This issue is most obvious for the behavioral paradigms we have discussed in our case studies: if a paradigm cannot distinguish between three mechanisms even if one assumes that only one of these mechanisms is at work, that paradigm cannot possibly determine the relative engagement of multiple mechanisms. However, neuroimaging studies are not exempt from this issue. While such studies might determine the involvement of multiple brain regions, they leave open what types of computations are performed in each brain region. It is not known, for example, whether subcortical areas involved in auditoryprocessing are necessarily restricted to normalization or whether these areas can take category identity into consideration (e.g., through documented feedback projections from cortical areas,<ref type="bibr" target="#b55">Erb et al., 2013a)</ref>. Similarly, it is an open question whether differential activation of early cortical areas indicates changes in category representations or normalization (e.g., the involvement of Heschl's gyrus in adaptive speech perception,</figDesc><table><row><cell>natural accent (for discussion, see Bent &amp; Baese-Berk, 2021; Samuel &amp; Kraljic, 2009; Zheng &amp;</cell></row><row><cell>Samuel, 2020). Another, mutually compatible, hypothesis holds that the earliest moments of</cell></row><row><cell>exposure to an unfamiliar talker primarily reflect change mechanisms that are computationally</cell></row><row><cell>less flexible but simpler. With increasing input, computationally more complex mechanisms,</cell></row><row><cell>which ultimately can support higher recognition accuracy, would increasingly come to determine</cell></row><row><cell>listeners' behavior. 15 For listeners, this would reduce the risk of overfitting parameters to the</cell></row><row><cell>input, a risk that applies more strongly to change models with a larger number of parameters (for</cell></row><row><cell>discussion, see Apfelbaum &amp; McMurray, 2015; Kleinschmidt &amp; Jaeger, 2015; Toscano &amp;</cell></row><row><cell>McMurray, 2010).</cell></row><row><cell>, Experiment 2; for</cell></row><row><cell>details, see SI,  §7). Further support for the hypothesis that adaptive speech perception is the</cell></row><row><cell>result of multiple mechanisms comes from neuroimaging studies: across paradigms, adaptive</cell></row><row><cell>speech perception implicates brain regions ranging all the way from pre-cortical structures (e.g.,</cell></row><row><cell>in the brain stem, Chandrasekaran et al., 2009; Polonenko &amp; Maddox, 2021; Zhao &amp; Kuhl, 2018)</cell></row><row><cell>to the (pre-)frontal cortex (Blanco-Elorrieta et al., 2021; Defenderfer et al., 2021; Hickok &amp;</cell></row><row><cell>Poeppel, 2007).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>In exposure-test experiments like those discussed in our case studies, (1) is further divided into two components: (1a) expectations based on the long-term speech statistics experienced prior to the experiment; and (1b) the input experienced during the exposure phase, where (1b) is assumed to incrementally change (1a) that a listener brings into a subsequent perceptual response. In short, there is broad agreement that the commonalities and differences between prior experience, exposure, and test jointly affect listeners' behavior in our experiments. This points to complex Both classes of models have some variants that are now freely available as R library (e.g., for normalization: phonTools, Barreda, 2015; for changes in category representations: beliefupdatr and its extension MVBeliefUpdatr,.ASP integrates models of all three change mechanisms in R (provided at https://osf.io/q7gjp/).</figDesc><table><row><cell>interactions that are difficult to understand without the use of computational models (for further</cell></row><row><cell>examples and discussion, see Apfelbaum &amp; McMurray, 2015; Sohoglu &amp; Davis, 2016; Tan et al.,</cell></row><row><cell>2021; Theodore &amp; Monto, 2019; Toscano et al., 2018; Xie, Buxó-Lugo, &amp; Kurumada, 2021).</cell></row><row><cell>Just as computational researchers benefit from familiarity with experiments, experimental</cell></row><row><cell>psychologists and neuroscientists stand to benefit from increased familiarity with the</cell></row><row><cell>computational models that are directly relevant to their research. Computational models</cell></row><row><cell>complement hypothesis testing by advancing our understanding of the cognitive functions</cell></row><row><cell>underlying complex tasks such as adaptive speech perception (Kriegeskorte &amp; Douglas, 2018), and</cell></row><row><cell>they are now more accessible than ever. For instance, formal models of normalization have been</cell></row><row><cell>available for decades and some of them are no more complex than standard data analysis (e.g.,</cell></row><row><cell>linear regression for C-CuRE, McMurray &amp; Jongman, 2011). Similarly, fully specified</cell></row><row><cell>distributional learning models have been available for at least two decades (e.g., mixtures of</cell></row><row><cell>Gaussians, Feldman et al., 2013; McMurray, 2007; Toscano &amp; McMurray, 2010; exemplar models,</cell></row><row><cell>Apfelbaum &amp; McMurray, 2015; Foulkes &amp; Hay, 2015; Johnson, 2005; ideal adaptors, Kleinschmidt</cell></row><row><cell>just as well as We submit that computational models are not only useful for research on speech perception, category shift. but likely indispensable given the complexity of multiple, potentially interacting, adaptive &amp; Jaeger, 2015). Specifically, the three change models of ASP spell out competing hypotheses about how exposure</cell></row><row><cell>mechanisms. For example, all major theories of adaptive speech perception agree that two types (1b) is integrated with prior experience (1a). Then the categorization model (updated based on</cell></row><row><cell>of information affect listeners' interpretation of speech from an unfamiliar talker: (1) listeners' the exposure input) determines how these changes are expected to affect listeners' responses to</cell></row><row><cell>test items (2).</cell></row></table><note>prior expectations based on the statistics of previously experienced speech input; and (2) the statistics of the present speech input (i.e., in test) relative to those prior expectations.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head></head><label></label><figDesc>data.table(Version 1.14.6;<ref type="bibr" target="#b344">Dowle &amp; Srinivasan, 2021)</ref>, devtools (Version 2.4.4;<ref type="bibr" target="#b443">Wickham, Hester, et al., 2022)</ref>, diptest (Version 0.76.0; Maechler, 2021a), dplyr (Version 1.0.10;<ref type="bibr" target="#b441">Wickham, François, et al., 2021)</ref>, forcats (Version 0.5.2;<ref type="bibr" target="#b436">Wickham, 2021a)</ref>, gganimate (Version 1.0.8; This includes the MVBeliefUpdatr library that supports working with multivariate Gaussian ideal observers and adaptors (see also Dave Kleinschmidt's beliefupdatr library that this library is based on). The full session information is provided at the end of this document.The 3D figures require the orca commandline tool. It is recommended that you use "Method 4" to install the standalone binaries. Some of the R libraries evoked in the R markdown code might require additional freely available non-R software (e.g., the R library sf requires non-R gdal). For line-by-line execution of this document, this is all you should need. If installation of any R library fails, follow the prompts in the error message.</figDesc><table><row><cell cols="2">Supplementary information for Xie, Jaeger, &amp; Kurumada (2022). What we do (not) know about the mechanisms underlying adaptive speech perception 2021a), Pedersen &amp; Robinson, 2020), ggplot2 (Version 3.4.0; Wickham, 2016), kableExtra (Version 1.3.4;</cell></row><row><cell cols="2">category representations, and decision-making. Finally, the simulations in our case studies Both the main text and these supplementary information (SI) are derived from the same R Zhu, 2021), LaplacesDemon (Version 16.1.6; Statisticat &amp; LLC., 2021), latexdiffr (Version 0.1.0;</cell></row><row><cell cols="2">explored what can (and cannot) be concluded from previous work about the three mechanisms, markdown document available via OSF at https://osf.io/q7gjp/. The PDFs for both the Hugh-Jones, 2021), linguisticsdown (Version 1.2.0; Liao, 2019), lme4 (Version 1.1.30; Bates et al.,</cell></row><row><cell cols="2">and how future research can develop behavioral and neuroimaging studies that shed light on the main text and the SI are best viewed using Acrobat Reader. Some links and animations 2015), magick (Version 2.7.3; Ooms, 2021b), magrittr (Version 2.0.3; Bache &amp; Wickham, 2020),</cell></row><row><cell cols="2">relative engagement of these mechanisms. might not work in other PDF viewers. Matrix (Version 1.4.1; Bates &amp; Maechler, 2021), mixtools (Version 1.2.0; Benaglia et al., 2009),</cell></row><row><cell cols="2">modelr (Version 0.1.9; Wickham, 2020), papaja (Version 0.1.1.9,001; Aust &amp; Barth, 2020), phonR</cell></row><row><cell cols="2">§1 Required software (Version 1.0.7; McCloy, 2016), plotly (Version 4.10.0; Sievert, 2020), processx (Version 3.8.0;</cell></row><row><cell cols="2">Csárdi &amp; Chang, 2021), purrr (Version 0.3.5; Henry &amp; Wickham, 2020), Rcpp (Version 1.0.9;</cell></row><row><cell cols="2">The document was compiled using knitr (Y. Xie, 2021) in RStudio with R: Eddelbuettel &amp; Balamuta, 2018; Eddelbuettel &amp; François, 2011), readr (Version 2.1.2; Wickham,</cell></row><row><cell cols="2">## Hester, &amp; Bryan, 2021), rlang (Version 1.0.6; Henry &amp; Wickham, 2021), rmarkdown (Version 2.18; _</cell></row><row><cell cols="2">## platform Y. Xie et al., 2018, 2020), stringr (Version 1.4.1; Wickham, 2019b), tibble (Version 3.1.8; Müller &amp; aarch64-apple-darwin20</cell></row><row><cell cols="2">## arch Wickham, 2021), tidyr (Version 1.2.1; Wickham, 2021b), tidyverse (Version 1.3.2; Wickham et al., aarch64</cell></row><row><cell cols="2">## os 2019), tinylabels (Version 0.2.3; Barth, 2022), tufte (Version 0.12; Y. Xie &amp; Allaire, 2022), and darwin20</cell></row><row><cell cols="2">## system usethis (Version 2.1.6; Wickham, Bryan, &amp; Barrett, 2022). If opened in RStudio, the top of the R aarch64, darwin20</cell></row><row><cell cols="2">## status markdown document should alert you to any libraries you will need to download, if you have not</cell></row><row><cell cols="2">## major already installed them. 4</cell></row><row><cell>## minor</cell><cell>2.1</cell></row><row><cell>## year</cell><cell>2022</cell></row><row><cell>## month</cell><cell>06</cell></row><row><cell>## day</cell><cell>23</cell></row><row><cell>## svn rev</cell><cell>82513</cell></row><row><cell>## language</cell><cell>R</cell></row><row><cell cols="2">## version.string R version 4.2.1 (2022-06-23)</cell></row><row><cell>## nickname</cell><cell>Funny-Looking Kid</cell></row><row><cell cols="2">We used the following R packages to create this document: R (Version 4.2.1; R Core Team,</cell></row><row><cell cols="2">2021) and the R-packages assertthat (Version 0.2.1; Wickham, 2019a), brms (Version 2.17.0;</cell></row><row><cell cols="2">Bürkner, 2017, 2018, 2021), cowplot (Version 1.1.1; Wilke, 2020), curl (Version 4.3.2; Ooms,</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The term normalization is often used to refer to both of these components together. For example, some of the most common normalization approaches involve both log-transforms and further normalization steps (e.g.,Lobanov  normalization, Lobanov, 1971; height-backness normalization, Miller &amp; Volaitis, 1989). Transformation and normalization can, however, be understood as separate processes.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">We estimated the VOT range inFigure 17based on the observation that post-burst aspiration accounts for about 2/3 s of the stop durations reported inKraljic and Samuel (2007, p. 6). We also averaged over the two talkers employed in the study, as Kraljic and Samuel did not report results relative to talker-specific VOT ranges.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">That the predicted changes in categorization functions indeed improve recognition accuracy will become more evident in Case Study 2.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">The approach we take here can also be applied to cross-talker generalization-i.e., paradigms in which speech from different talkers of the same (or different) accent as the exposure talker is used during test<ref type="bibr" target="#b5">(Baese-Berk et al., 2013;</ref><ref type="bibr" target="#b19">Bradlow &amp; Bent, 2008;</ref><ref type="bibr" target="#b243">Sidaras et al., 2009)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">In Case Study 1, there was no measure like accuracy for which performance can unambiguously be interpreted as 'better' or 'worse'.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">There are, however, important differences in the extent to which different research traditions have already implemented the recommendations we make below. For example, some lines of research tend to interpret findings relative to the distribution of phonetic cues in the speech input (e.g., studies on distributional learning,<ref type="bibr" target="#b9">Bejjanki et al., 2011;</ref><ref type="bibr" target="#b159">Malone, 2021</ref>; studies on dimension-based statistical learning,; for review, see, whereas this remains the exception in other lines of research (but see, e.g.,<ref type="bibr" target="#b86">Hitczenko &amp; Feldman, 2016;</ref> Tan et al., 2021, for  accent adaptation; Theodore &amp; Monto, 2019, for perceptual recalibration). See also SI ( §7).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">In ASP, this is most naturally be accounted for in terms of slow 'learning rates' for the more complex change model (e.g., high 0, s and 0, s for changes in representations).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18">Intriguingly, this would predict that the listener will categorize fewer tokens along the prototypical /d/ to /t/ continuum as /d/-in line with findings that repeated exposure to prototypical tokens of a category leads to selective adaptation (e.g.,<ref type="bibr" target="#b414">Samuel, 1986;</ref>  for discussion, see also.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19">S ≜ Σ =1 , , is the uncentered sum of squares matrix of the observations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21">This might also reveal that some of the assumptions of the Normal-Inverse-Wishart belief-updating model are</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22">Some studies provide aggregate information (e.g.,<ref type="bibr" target="#b165">, 2007</ref> and very few provide detailed information and visualization (e.g.,.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25">Even if C-CuRE normalization, which only centers cues, is made more comparable to the representational change model by extending normalization to include cue standardization (also known as z-scoring, as used in, e.g.,Lobanov  normalization, Lobanov, 1971), this would introduce just one additional parameter for researchers (the equivalent for 0 but for the estimation of the cue variances), and listeners would be assumed to learn and store 2 values for cues.26 To be precise, some normalization accounts allow the category identities of surrounding segments of speech to affect the normalization of cues on the target segment. This is, for example, how C-CuRE normalizes for effects of surrounding phonetic context.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Voice-timing perception in spanish word-initial stops</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Abramson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lisker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A comparison of vowel normalization procedures for language variation research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Adank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Smits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Hout</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.1795335</idno>
		<ptr target="https://doi.org/10.1121/1.1795335" />
		<imprint>
			<date type="published" when="2004" />
			<publisher>Acoustical Society of America</publisher>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="3099" to="3107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Relative cue encoding in the context of sophisticated models of categorization: Separating information from categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Apfelbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-014-0783-2</idno>
		<ptr target="https://doi.org/10.3758/s13423-014-0783-2" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="916" to="943" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Phonetic recalibration does not depend on working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroomen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00221-010-2264-9</idno>
		<ptr target="https://doi.org/10.1007/s00221-010-2264-9" />
	</analytic>
	<monogr>
		<title level="j">Experimental Brain Research</title>
		<imprint>
			<biblScope unit="volume">203</biblScope>
			<biblScope unit="page" from="575" to="582" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Do social preferences matter in lexical retuning? Laboratory Phonology: Journal of the Association for Laboratory Phonology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Babel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bishop</surname></persName>
		</author>
		<idno type="DOI">10.5334/labphon.133</idno>
		<ptr target="https://doi.org/10.5334/labphon.133" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Accent-independent adaptation to foreign accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Baese-Berk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="174" to="180" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Perception of non-native speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Baese-Berk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Mcgowan</surname></persName>
		</author>
		<idno type="DOI">10.1111/lnc3.12375</idno>
		<ptr target="https://doi.org/10.1111/lnc3.12375" />
	</analytic>
	<monogr>
		<title level="j">Language and Linguistics Compass</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Variability in speaking rate of native and non-native speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Baese-Berk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bradlow</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.5067612</idno>
		<ptr target="https://doi.org/10.1121/1.5067612" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="1717" to="1717" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Phontools: Functions for phonetics in r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barreda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>R package version 0.2-2.1</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cue integration in categorical tasks: Insights from audio-visual speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Bejjanki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clayards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Knill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<editor>D. G. Pelli</editor>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Perceptual learning of accented speech. The Handbook of Speech Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Baese-Berk</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781119184096.ch16</idno>
		<ptr target="https://doi.org/10.1002/9781119184096.ch16" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="428" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual recalibration of auditory speech identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bertelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>De Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="592" to="597" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<idno type="DOI">10.1046/j.0956-7976.2003.psci_1470.x</idno>
		<ptr target="https://doi.org/10.1046/j.0956-7976.2003.psci_1470.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving older adults&apos; understanding of challenging speech: Auditory training, rapid adaptation and perceptual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gordon-Salant</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.heares.2020.108054</idno>
		<ptr target="https://doi.org/10.1016/j.heares.2020.108054" />
	</analytic>
	<monogr>
		<title level="j">Hearing Research</title>
		<imprint>
			<biblScope unit="volume">402</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural correlates of sensory and decision processes in auditory object identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liebenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Possing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Medler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="301" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptation to mis-pronounced speech: Evidence for a prefrontal-cortex repair mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blanco-Elorrieta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pylkkänen</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-79640-0</idno>
		<ptr target="https://doi.org/10.1038/s41598-020-79640-0" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Prediction errors but not sharpened signals simulate multivoxel fmri patterns during speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1002577</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reading-induced shifts of perceptual speech representations in auditory cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Correia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keetels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Formisano</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-017-05356-3</idno>
		<ptr target="https://doi.org/10.1038/s41598-017-05356-3" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cognitive load makes speech sound fast, but does not modulate acoustic context effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Bosker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Reinisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sjerps</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2016.12.002</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.jml.2016.12.002" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="166" to="176" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Perceptual adaptation to non-native speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="707" to="729" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">People as contexts in conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown-Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">O</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Ryskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Learning and Motivation</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="59" to="99" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/bs.plm.2014.09.003</idno>
		<ptr target="https://doi.org/10.1016/bs.plm.2014.09.003" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Delayed information benefits adaptation to unexpected pronunciations: Evidence for maintenance of perceptual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Burchill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Advanced bayesian multilevel modeling with the r package brms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Phonology and language use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bybee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A limited memory algorithm for bound constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on scientific computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1190" to="1208" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Context-dependent encoding in the human auditory brainstem relates to hearing speech in noise: Implications for developmental dyslexia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hornickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Skoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nicol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="319" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2009.10.006</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.neuron.2009.10.006" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Becoming syntactic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="234" to="272" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Language adaptation and learning: Getting explicit about implicit learning. Linguistics and Language Compass</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Janciauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="259" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<idno type="DOI">10.1002/lnc3.337</idno>
		<ptr target="https://doi.org/10.1002/lnc3.337" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Predictability of stop consonant phonetics across talkers: Between-category and within-category dependencies among cues for place and voice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chodroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1515/lingvan-2017-0047</idno>
		<ptr target="https://doi.org/10.1515/lingvan-2017-0047" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Acoustic-phonetic and auditory mechanisms of adaptation in the perception of sibilant fricatives. Attention, Perception, and Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chodroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-019-01894-2</idno>
		<ptr target="https://doi.org/10.3758/s13414-019-01894-2" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="2027" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Whatever next? predictive brains, situated agents, and the future of cognitive science. The Behavioral and brain sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="181" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.1017/S0140525X12000477</idno>
		<ptr target="https://doi.org/10.1017/S0140525X12000477" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Rapid adaptation to foreign-accented english. The Journal of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Garrett</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.1815131</idno>
		<ptr target="https://doi.org/10.1121/1.1815131" />
		<imprint>
			<date type="published" when="2004" />
			<publisher>Acoustical Society of America</publisher>
			<biblScope unit="volume">116</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Does perceptual learning in speech reflect changes in phonetic category representation or decision bias ? Perception &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Clarke-Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Sawusch</surname></persName>
		</author>
		<idno type="DOI">10.3758/PP.70.4.604</idno>
		<ptr target="https://doi.org/10.3758/PP.70.4.604" />
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="604" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Differences in cue weights for speech perception are correlated for individuals within and across contrasts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clayards</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.5052025</idno>
		<ptr target="https://doi.org/10.1121/1.5052025" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="172" to="177" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Perception of speech reflects optimal use of probabilistic speech cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clayards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Tanenhaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="804" to="809" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2008.04.004</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2008.04.004" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unmasking the acoustic effects of vowel-to-vowel coarticulation: A statistical modeling approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Linebaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Munson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.wocn.2009.08.004</idno>
		<ptr target="https://doi.org/10.1016/j.wocn.2009.08.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="167" to="184" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">How talker identity relates to language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Creel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Bregman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics and Language Compass</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="190" to="204" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.1749-818X.2011.00276.x</idno>
		<ptr target="https://doi.org/10.1111/j.1749-818X.2011.00276.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A graph-theoretic approach to identifying acoustic cues for speech sound categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Crinnion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Malmskog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Toscano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1104" to="1125" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The human brain encodes event frequencies while forming subjective beliefs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Acremont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="10887" to="10897" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.5829-12.2013</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.5829-12.2013" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Three functions of prediction error for bayesian inference in speech perception. The cognitive neurosciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sohoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="177" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Defenderfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijeakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hedrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Plyler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Buss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Frontotemporal activation differs between perception of simulated cochlear implant speech and speech in background noise: An image-based fnirs study</title>
		<idno type="DOI">10.1016/j.neuroimage.2021.118385</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2021.118385" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">240</biblScope>
			<biblScope unit="page">118385</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Neural evidence for bayesian trial-by-trial adaptation on the n400 during semantic priming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Delaney-Busch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Kuperberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="10" to="20" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Lexically guided perceptual tuning of internal phonetic category structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Drouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">.org/10.1121/1.4964468</idno>
		<ptr target="https://doi.org/doi.org/10.1121/1.4964468" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="307" to="313" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The specificity of perceptual learning in speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception And Psychophysics</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="224" to="238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Perceptual learning in speech: Stability over time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1950" to="1953" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.2178721</idno>
		<ptr target="https://doi.org/10.1121/1.2178721" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Constraints on the transfer of perceptual learning in accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Melinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00148</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2013.00148" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">148</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The brain dynamics of rapid perceptual adaptation to adverse listening conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Erb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Obleser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="10688" to="10697" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.4596-12.2013</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.4596-12.2013" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The brain dynamics of rapid perceptual adaptation to adverse listening conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Erb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Obleser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">26</biblScope>
			<biblScope unit="page" from="10688" to="10697" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Native, non-native and l2 perceptual cue weighting for dutch vowels: The case of dutch, german, and spanish listeners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Benders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Lipski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="452" to="465" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The influence of categories on perception: Explaining the perceptual magnet effect as optimal statistical inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="752" to="782" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Word-level information influences phonetic learning in adults and infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="427" to="438" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2013.02.007</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.cognition.2013.02.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Rapid expectation adaptation during syntactic comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Farmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qian</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0077661</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0077661" />
	</analytic>
	<monogr>
		<title level="j">PloS ONE</title>
		<editor>K. Paterson</editor>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Discriminatory analysis-nonparametric discrimination: Consistency properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Hodges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Statistical Review</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="238" to="247" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Production of the word-final english /t/-/d/ contrast by native speakers of english, mandarin, and spanish. The Journal of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Flege</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Skelton</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.404278</idno>
		<ptr target="https://doi.org/10.1121/1.404278" />
		<imprint>
			<date type="published" when="1992" />
			<publisher>Acoustical Society of America</publisher>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="128" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Does a regional accent perturb speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Floccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Girard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konopczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">1276</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">The emergence of sociophonetic structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Foulkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hay</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781118346136.ch13</idno>
	</analytic>
	<monogr>
		<title level="m">The Handbook of Language Emergence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="292" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<idno type="DOI">10.1002/9781118346136.ch13</idno>
		<ptr target="https://doi.org/doi:10.1002/9781118346136.ch13" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Parietal cortex and insula relate to evidence seeking relevant to reward-related decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Furl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Averbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="17572" to="17582" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Adaptive plasticity under adverse listening conditions is disrupted in developmental dyslexia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gabay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1355617720000661</idno>
		<ptr target="https://doi.org/10.1017/S1355617720000661" />
	</analytic>
	<monogr>
		<title level="j">Journal of the International Neuropsychological Society</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="12" to="22" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Classification of self-normalized vowels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gerstman</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAU.1968.1161953</idno>
		<ptr target="https://doi.org/10.1109/TAU.1968.1161953" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio and Electroacoustics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="80" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Words and voices: Episodic traces in spoken word identification and recognition memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Goldinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning Memory and Cognition</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1166" to="1183" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Echoes of echoes?: An episodic theory of lexical access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Goldinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="251" to="279" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Episodic memory reflected in printed word naming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Goldinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Azuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="716" to="722" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Auditory masking and the critical band</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Greenwood</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.1908699</idno>
		<ptr target="https://doi.org/10.1121/1.1908699" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="484" to="502" />
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Speech perception under adverse conditions: Insights from behavioral, computational, and neuroscience research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guediche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Blumstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fiez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnsys.2013.00126</idno>
		<ptr target="https://doi.org/10.3389/fnsys.2013.00126" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Systems Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Evidence for cerebellar contributions to adaptive plasticity in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guediche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fiez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1867" to="1877" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">When one person&apos;s mistake is another&apos;s standard usage: The effect of foreign accent on syntactic processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hanulíková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Van Alphen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Van Goch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_00103</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_00103" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="878" to="887" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Sink positive: Linguistic experience with th substitutions influences nonnative word recognition. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hanulíková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-011-0259-7</idno>
		<ptr target="https://doi.org/10.3758/s13414-011-0259-7" />
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="613" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Learning mechanisms in cue reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kapatsinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page" from="76" to="88" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Stuffed toys and speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Drager</surname></persName>
		</author>
		<idno type="DOI">10.1515/LING.2010.027</idno>
		<ptr target="https://doi.org/10.1515/LING.2010.027" />
	</analytic>
	<monogr>
		<title level="j">Linguistics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="865" to="892" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Abstract social categories facilitate access to socially skewed words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title/>
		<idno type="DOI">10.1371/journal.pone.0210793</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0210793" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Brain networks involved in accented speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ventura-Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miró-Padilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ávila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and Language</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="12" to="22" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.bandl.2019.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.bandl.2019.03.003" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">The cortical organization of speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hickok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Poeppel</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn2113</idno>
		<ptr target="https://doi.org/10.1038/nrn2113" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="393" to="402" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Modeling adaptation to a novel accent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hitczenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 38th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1367" to="1372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Modeling vowel normalization and sound perception as sequential processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Hoffmann Bion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Escudero</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.4782397</idno>
		<ptr target="https://doi.org/10.1121/1.4782397" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3188" to="3188" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Speech categorization in context: Joint effects of nonspeech and speech precursors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="4016" to="4026" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.2195119</idno>
		<ptr target="https://doi.org/10.1121/1.2195119" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Influence of fundamental frequency on stop-consonant voicing perception: A case of learned covariation or auditory enhancement?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Lotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Kluender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="764" to="774" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.1339825</idno>
		<ptr target="https://doi.org/10.1121/1.1339825" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Evidence for the central origin of lexical tone normalization (l)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="1145" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.3543994</idno>
		<ptr target="https://doi.org/10.1121/1.3543994" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Word recognition reflects dimension-based statistical learning (2011/10/17)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0025641</idno>
		<ptr target="https://doi.org/10.1037/a0025641" />
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1939" to="1956" />
		</imprint>
	</monogr>
	<note>Journal of experimental psychology. Human perception and performance</note>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Generalization of dimension-based statistical learning. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1744" to="1762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13414-019-01956-5</idno>
		<ptr target="https://doi.org/10.3758/s13414-019-01956-5" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Categorical data analysis: Away from anovas (transformation or not) and towards logit mixed models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="434" to="446" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Redundancy and reduction: Speakers manage syntactic information density</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2010.02.002</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2010.02.002" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="23" to="62" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Strong evidence for expectation adaptation during language understanding, not a replication failure. a reply to harrington stack, james, and watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Burchill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bushong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>XXXX</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Alignment as a consequence of expectation adaptation: Syntactic priming is affected by the prime&apos;s prediction error given both prior and recent experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="page" from="57" to="83" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Positional effects in the lexical retuning of speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="943" to="950" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Speaker normalization in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.1002/9780470757024.ch15</idno>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title/>
		<idno type="DOI">10.1002/9780470757024.ch15</idno>
		<ptr target="https://doi.org/doi:10.1002/9780470757024.ch15" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Resonance in an exemplar-based lexicon: The emergence of social identity and phonology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="485" to="499" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Auditory-visual integration of talker gender in vowel perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Strand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Imperio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="359" to="384" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title/>
		<idno type="DOI">10.1006/jpho.1999.0100</idno>
		<ptr target="https://doi.org/10.1006/jpho.1999.0100" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Speaker normalization in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sjerps</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781119184096.ch6</idno>
		<ptr target="https://doi.org/https://doi.org/10.1002/9781119184096.ch6" />
	</analytic>
	<monogr>
		<title level="m">The handbook of speech perception</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="145" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Speech and language processing : An introduction to natural language processing, computational linguistics, and speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Syntactic adaptation. The psychology of learning and motivation: Current topics in language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="85" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/bs.plm.2018.08.003</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/bs.plm.2018.08.003" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">This construction needs learned</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Kaschak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Glenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="450" to="467" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0096-3445.133.3.450</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.133.3.450" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Brain networks of perceptual decision-making: An fmri ale meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Keuken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Müller-Axt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neumann</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2014.00445</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2014.00445" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title level="m" type="main">Theories and models of speech perception. The Routledge Handbook of Phonetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kiefte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Nearey</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780429056253-12</idno>
		<ptr target="https://doi.org/10.4324/9780429056253-12" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="289" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Brain activation during audiovisual exposure anticipates future perception of ambiguous speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kilian-Hütten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Formisano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="1601" to="1607" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuroimage.2011.05.043</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2011.05.043" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Individual differences in perceptual adaptation to unfamiliar phonetic categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clayards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Kong</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.wocn.2020.100984</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.wocn.2020.100984" />
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">100984</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Effects of prosodic prominence on obstruent-intrinsic f0 and vot in German</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kleber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Siddins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harrington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Speech Prosody 2020</title>
		<meeting>Speech Prosody 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="210" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title/>
		<idno type="DOI">10.21437/SpeechProsody.2020-43</idno>
		<ptr target="https://doi.org/10.21437/SpeechProsody.2020-43" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title level="m" type="main">Structure in talker variability: How much is there and how much can it help? [&lt;b&gt;From Duplicate 1 (&lt;i&gt;Structure in talker variability: How much is there and how much can it help?&lt;/i&gt; -Kleinschmidt, Dave F)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<idno type="DOI">10.1080/23273798.2018.1500698</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Language</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="43" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/23273798.2018.1500698</idno>
		<ptr target="https://doi.org/10.1080/23273798.2018.1500698" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">What constrains distributional learning in adults? PsyArXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">A bayesian belief updating model of phonetic recalibration and selective adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Workshop on Cognitive Modeling and Computational Linguistics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">A continuum of phonetic adaptation : Evaluating an incremental belief-updating model of recalibration and selective adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual Meeting of the Cognitive Science Society (CogSci12)</title>
		<meeting>the 34th Annual Meeting of the Cognitive Science Society (CogSci12)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="605" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Robust speech perception: Recognize the familiar, generalize to the similar, and adapt to the novel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0038695</idno>
		<ptr target="https://doi.org/10.1037/a0038695" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="148" to="203" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Re-examining selective adaptation: Fatiguing feature detectors, or distributional learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="678" to="691" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">What do you expect from an unfamiliar talker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<editor>J. C. Trueswell, A. Papafragou, D. Grodner, &amp; D. Mirman</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Supervised and unsupervised learning in phonetic adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raizada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 37th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1129" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Vowel-length differences before voiced and voiceless consonants: An auditory explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Kluender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Diehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="153" to="169" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Perceptual learning for speech: Is there a return to normal?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraljic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="141" to="178" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Generalization in perceptual learning for speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraljic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="262" to="268" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Perceptual adjustments to multiple speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraljic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Cognitive computational neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Douglas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1148" to="1160" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">A unified model of categorical effects in consonant and vowel perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kronrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Coppess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin and Review</title>
		<imprint>
			<biblScope unit="page" from="1681" to="1712" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13423-016-1049-y</idno>
		<ptr target="https://doi.org/10.3758/s13423-016-1049-y" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Separate streams or probabilistic inference? what the n400 can tell us about the comprehension of events. Language, cognition and neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Kuperberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="602" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Thinking probabilistically in the study of intonational speech prosody</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kurumada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Roettger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Cognitive Science</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title/>
		<idno type="DOI">10.1002/wcs.1579</idno>
		<ptr target="https://doi.org/https://doi.org/10.1002/wcs.1579" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">The interaction between competition, learning, and habituation dynamics in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lancia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Winter</surname></persName>
		</author>
		<idno type="DOI">10.1515/lp-2013-0009</idno>
		<ptr target="https://doi.org/10.1515/lp-2013-0009" />
	</analytic>
	<monogr>
		<title level="j">Laboratory Phonology</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Using tone information in cantonese continuous speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Ching</surname></persName>
		</author>
		<idno type="DOI">10.1145/595576.595581</idno>
		<ptr target="https://doi.org/10.1145/595576.595581" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian Language Information Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="102" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Nevertheless, it persists: Dimension-based statistical learning and normalization of speech impact different levels of perceptual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lehet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2020.104328</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2020.104328" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Perception of the speech code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Liberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Shankweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Studdert-Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="431" to="461" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Plasticity of categories in speech perception and production. Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clayards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gennari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Gaskell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="707" to="731" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/23273798.2021.2018471</idno>
		<ptr target="https://doi.org/10.1080/23273798.2021.2018471" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Inferring causes during speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2018.01.003</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2018.01.003" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page" from="55" to="70" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Talker-specific pronunciation or speech error? discounting (or not) atypical pronunciations during speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000693</idno>
		<ptr target="https://doi.org/10.1037/xhp0000693" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1562" to="1588" />
		</imprint>
	</monogr>
	<note>Journal of experimental psychology. Human perception and performance</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Dimension-based statistical learning of vowels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1783" to="1798" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0025641</idno>
		<ptr target="https://doi.org/10.1037/a0025641" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Classification of russian vowels spoken by different speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lobanov</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.1912396</idno>
		<ptr target="https://doi.org/10.1121/1.1912396" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="606" to="608" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Recognizing spoken words: The neighborhood activation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Pisoni</surname></persName>
		</author>
		<idno type="DOI">10.1097/00003446-199802000-00001</idno>
		<ptr target="https://doi.org/10.1097/00003446-199802000-00001" />
	</analytic>
	<monogr>
		<title level="j">Ear and Hearing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title level="m" type="main">Individual choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1959" />
			<publisher>John Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Lexical Information Guides Retuning of Neural Patterns in Perceptual Learning for Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luthra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Correia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mesite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2001" to="2012" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title/>
		<idno type="DOI">10.1162/jocn_a_01612</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_01612" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Acoustic differences, listener expectations, and the perceptual accommodation of talker variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Magnuson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Nusbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="391" to="409" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">Earshot: A minimal neural network model of incremental human speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Magnuson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luthra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Escabí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Allopenna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Monto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Rueckl</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.12823</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title/>
		<idno type="DOI">10.1111/cogs.12823</idno>
		<ptr target="https://doi.org/10.1111/cogs.12823" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<monogr>
		<title level="m" type="main">Phonological adaptation in children and adults: Testing for a bayesian learning mechanism [Doctoral dissertation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Malone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
		<respStmt>
			<orgName>State University of New York at Buffalo</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Models of integration given multiple sources of information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Massaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="225" to="252" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0033-295X.97.2.225</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.97.2.225" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">The weckud wetch of the wast: Lexical adaptation to a novel accent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Maye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Tanenhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="543" to="562" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/03640210802035357</idno>
		<ptr target="https://doi.org/10.1080/03640210802035357" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">The trace model of speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="86" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Defusing the childhood vocabulary explosion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="page">317</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">What information is necessary for speech categorization?: Harnessing variability in the speech signal by integrating cues computed relative to expectations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jongman</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0022325.What</idno>
		<ptr target="https://doi.org/10.1037/a0022325.What" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="219" to="246" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">What comes after /f/?: Prediction in speech derives from data-explanatory processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jongman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="43" to="52" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0956797615609578</idno>
		<ptr target="https://doi.org/10.1177/0956797615609578" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Phonological abstraction in the mental lexicon (2006/11/12)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1113" to="1126" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title/>
		<idno type="DOI">10.1207/s15516709cog0000\_79</idno>
		<ptr target="https://doi.org/10.1207/s15516709cog0000\_79" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Effect of speaking rate on the perceptual structure of a phonetic category</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Volaitis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="505" to="512" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<title level="m" type="main">Phonological abstraction in processing lexical-tone variation: Evidence from a learning paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mitterer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<idno>/03/25</idno>
		<ptr target="1551-6709&lt;br/&gt;&lt;br/&gt;Mitterer,Holger&lt;br/&gt;&lt;br/&gt;Chen,Yiya&lt;br/&gt;&lt;br/&gt;Zhou,Xiaolin&lt;br/&gt;&lt;br/&gt;JournalArticle&lt;br/&gt;&lt;br/&gt;ResearchSupport" />
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>Non-U.S</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.1551-6709.2010.01140.x.Epub</idno>
		<ptr target="Gov&apos;t&lt;br/&gt;&lt;br/&gt;UnitedStates&lt;br/&gt;&lt;br/&gt;CognSci" />
		<imprint>
			<date type="published" when="2010-02" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="184" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="184" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.1551-6709.2010.01140.x</idno>
		<ptr target="https://doi.org/10.1111/j.1551-6709.2010.01140.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Phonological abstraction without phonemes in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mitterer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Scharenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="356" to="361" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2013.07.011</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2013.07.011" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Suggested formulae for calculating auditory-filter bandwidths and excitation patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Glasberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="750" to="753" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">Processing time, accent, and comprehensibility in the perception of native and foreign-accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Derwing</surname></persName>
		</author>
		<idno type="DOI">10.1177/002383099503800305</idno>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title/>
		<idno type="DOI">10.1177/002383099503800305</idno>
		<ptr target="https://doi.org/10.1177/002383099503800305" />
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="289" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<title level="m" type="main">Machine learning: A probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Neural systems underlying perceptual adjustment to non-standard speech tokens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Mesite</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="80" to="93" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.jml.2014.06.007</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2014.06.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Static, dynamic, and relational properties in vowel perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Nearey</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.397861</idno>
		<ptr target="https://doi.org/10.1121/1.397861" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="2088" to="2113" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<title level="m" type="main">Phonological contrast in experimental phonetics: Relating distributions of production data to perceptual categorization curves. Experimental phonology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Nearey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Hogan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="141" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">The perceptual consequences of within-talker variability in fricative production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Clouse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Burnham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="1181" to="1196" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Perceptual normalization for speaking rate: Effects of temporal distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Sawusch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="540" to="560" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/BF03213089</idno>
		<ptr target="https://doi.org/10.3758/BF03213089" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">The effect of social information on the perception of sociolinguistic variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Niedzielski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="62" to="85" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0261927X99018001005</idno>
		<ptr target="https://doi.org/10.1177/0261927X99018001005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">The temporal dynamics of perceptual uncertainty: Eye movement evidence from cantonese segment and tone perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Rij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="103" to="125" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.jml.2016.03.005</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2016.03.005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Shortlist b: A bayesian model of continuous speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="357" to="95" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0033-295X.115.2.357</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.115.2.357" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Perceptual learning in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cutler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="204" to="238" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Speech perception as a talker-contingent process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Nygaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Sommers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Pisoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="42" to="46" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.1467-9280.1994.tb00612.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9280.1994.tb00612.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Speech-specific perceptual adaptation deficits in children and adults with dyslexia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ozernov-Palchik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Beach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Centanni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gaab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kuperberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Perrachione</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D E</forename><surname>Gabrieli</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001145</idno>
		<ptr target="https://doi.org/10.1037/xge0001145" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">Learning additional languages as hierarchical probabilistic inference: Insights from first language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pajak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1111/lang.12168</idno>
		<ptr target="https://doi.org/10.1111/lang.12168" />
	</analytic>
	<monogr>
		<title level="m">Language Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="900" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Dysfunction of rapid neural adaptation in dyslexia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Perrachione</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N D</forename><surname>Tufo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Murtagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Halverson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Christodoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Gabrieli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="1383" to="1397" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuron.2016.11.020</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2016.11.020" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<title level="m" type="main">Comparing pre-linguistic normalization models against us english listeners&apos; vowel perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
		<respStmt>
			<orgName>Stockholm University</orgName>
		</respStmt>
	</monogr>
	<note>manuscript</note>
</biblStruct>

<biblStruct xml:id="b203">
	<monogr>
		<title level="m" type="main">Evaluating normalization accounts against the dense vowel space of central swedish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
		<respStmt>
			<orgName>Stockholm University</orgName>
		</respStmt>
	</monogr>
	<note>manuscript</note>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Exemplar dynamics: Word frequency, lenition and contrast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Pierrehumbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">John Benjamins</title>
		<editor>J. Bybee &amp; P. Hopper</editor>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Global model analysis by parameter space partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Myung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="57" to="83" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0033-295X.113.1.57</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.113.1.57" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">Strong inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">3462</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Talker-specific generalization of pragmatic inferences based on under-and over-informative prenominal adjective use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pogue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kurumada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Tanenhaus</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2015.02035</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2015.02035" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<monogr>
		<title level="m" type="main">Exposing distinct subcortical components of the auditory brainstem response evoked by continuous naturalistic speech. eLife</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Polonenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Maddox</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.62329</idno>
		<ptr target="https://doi.org/10.7554/eLife.62329" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Rapid syntactic adaptation in self-paced reading: Detectable, but only with many participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Linzen</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0001046</idno>
		<ptr target="https://doi.org/10.1037/xlm0001046" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1156" to="1172" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">The psi-marginal adaptive method: How to give nuisance parameters the attention they deserve (no more, no less)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Prins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Impacts of acoustic-phonetic variability on perceptual development for spoken language: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Quam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Creel</surname></persName>
		</author>
		<idno type="DOI">10.1002/wcs.1558</idno>
		<ptr target="https://doi.org/10.1002/wcs.1558" />
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Cognitive Science</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing. R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
		<idno type="DOI">10.1038/4580</idno>
		<ptr target="https://doi.org/10.1038/4580" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">The allure of status: High-status targets are privileged in face processing and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hugenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Shriver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167211407210</idno>
		<ptr target="https://doi.org/10.1177/0146167211407210" />
	</analytic>
	<monogr>
		<title level="j">Personality &amp; Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1003" to="1015" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<monogr>
		<title level="m" type="main">Lexically guided phonetic retuning of foreign-accented speech and its generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Reinisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0034409</idno>
		<ptr target="https://doi.org/10.1037/a0034409" />
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="539" to="555" />
		</imprint>
	</monogr>
	<note>Journal of experimental psychology. Human perception and performance</note>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Listeners retune phoneme categories across languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Reinisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mitterer</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0027979</idno>
		<ptr target="https://doi.org/10.1037/a0027979" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="75" to="86" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Remez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Crank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Kostro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Cheimets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. S</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<monogr>
		<title level="m" type="main">Short-term perceptual tuning to talker characteristics. Language, Cognition and Neuroscience</title>
		<idno type="DOI">10.1080/23273798.2018.1442580</idno>
		<ptr target="https://doi.org/10.1080/23273798.2018.1442580" />
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1083" to="1091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Evaluating low-level speech features against human perceptual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Salgado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jansen</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00071</idno>
		<ptr target="https://doi.org/10.1162/tacl_a_00071" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="425" to="440" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">Processing changes when listening to foreign-accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Romero-Rivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in human neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">167</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<monogr>
		<title level="m" type="main">Rstudio: Integrated development environment for r. RStudio, PBC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rstudio</forename><surname>Team</surname></persName>
		</author>
		<ptr target="http://www.rstudio.com/" />
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Parallel distributed processing: Explorations in the microstructure of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">foundations</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1986" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<monogr>
		<title level="m" type="main">Information integration in modulation of pragmatic inferences during online language comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ryskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kurumada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown-Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.12769</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title/>
		<idno type="DOI">10.1111/cogs.12769</idno>
		<ptr target="https://doi.org/10.1111/cogs.12769" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<date type="published" when="12769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Listeners are initially flexible in updating phonetic beliefs over time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Saltzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-021-01885-1</idno>
		<ptr target="https://doi.org/10.3758/s13423-021-01885-1" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Lexical representations are malleable for about one second: Evidence for the non-automaticity of perceptual recalibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="88" to="114" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cogpsych.2016.06.007</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2016.06.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">Auditory selective adaptation moment by moment, at multiple timescales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dumay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">596</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<monogr>
		<title level="m" type="main">Perceptual learning for speech. Attention, perception, &amp; psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraljic</surname></persName>
		</author>
		<idno type="DOI">10.3758/APP.71.6.1207</idno>
		<ptr target="https://doi.org/10.3758/APP.71.6.1207" />
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1207" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">Perceptual normalization for speaking rate ii: Effects of signal discontinuities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Sawusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="285" to="300" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/BF03205549</idno>
		<ptr target="https://doi.org/10.3758/BF03205549" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<analytic>
		<title level="a" type="main">Response organization in selective adaptation to speech sounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Sawusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pisoni</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03208275</idno>
		<ptr target="https://doi.org/10.3758/BF03208275" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="413" to="418" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">Comparing lexically guided perceptual learning in younger and older listeners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Scharenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Janse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="525" to="536" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">Individual differences in phonetic cue use in production and perception of a non-native sound contrast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Warner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="183" to="204" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">Individual differences in perceptual adaptability of foreign sound categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Warner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="355" to="367" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">Phonetic cue weighting in perception and production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Clare</surname></persName>
		</author>
		<idno type="DOI">10.1002/wcs.1521</idno>
		<ptr target="https://doi.org/10.1002/wcs.1521" />
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">Toddlers recognize words in an unfamiliar accent after brief exposure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schmale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cristia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="732" to="738" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.1467-7687.2012.01175.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-7687.2012.01175.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<monogr>
		<title level="m" type="main">I know what you&apos;re probably going to say: Listener adaptation to variable use of uncertainty expressions. Cognition, 203, 104285</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Degen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2020.104285</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.cognition.2020.104285" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<analytic>
		<title level="a" type="main">Resilience of english vowel perception across regional accent variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Docherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Foulkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mulak</surname></persName>
		</author>
		<idno type="DOI">10.5334/labphon.87</idno>
		<ptr target="https://doi.org/10.5334/labphon.87" />
	</analytic>
	<monogr>
		<title level="j">Laboratory Phonology: Journal of the Association for Laboratory Phonology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<analytic>
		<title level="a" type="main">Exemplar models as a mechanism for performing bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<idno type="DOI">10.3758/PBR.17.4.443</idno>
		<ptr target="https://doi.org/10.3758/PBR.17.4.443" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="443" to="464" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<analytic>
		<title level="a" type="main">Perceptual learning of systematic variation in spanish-accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sidaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Nygaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="3306" to="3316" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">Speaker-normalized sound representations in the human auditory cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sjerps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-019-10365-z</idno>
		<ptr target="https://doi.org/10.1038/s41467-019-10365-z" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2465</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<analytic>
		<title level="a" type="main">The bounds on flexibility in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sjerps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology. Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="195" to="211" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0016803</idno>
		<ptr target="https://doi.org/10.1037/a0016803" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<title level="a" type="main">Listening to different speakers: On the time-course of perceptual compensation for vocal-tract characteristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sjerps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mitterer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2011.09.044</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2011.09.044" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="3831" to="3846" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">Auditory cortical changes precede brainstem changes during rapid implicit learning: Evidence from human eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Skoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krizman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="page">1007</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b249">
	<analytic>
		<title level="a" type="main">Cross-accent intelligibility of speech in noise: Long-term familiarity and short-term familiarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Holmes-Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pettinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-A</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly journal of experimental psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="590" to="608" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b250">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/17470218.2013.822009</idno>
		<ptr target="https://doi.org/10.1080/17470218.2013.822009" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b251">
	<analytic>
		<title level="a" type="main">Perceptual learning of degraded speech by minimizing prediction error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sohoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of</title>
		<meeting>the National Academy of Sciences of the United States of</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b252">
	<analytic>
		<title/>
		<idno type="DOI">10.1073/pnas.1523266113</idno>
		<ptr target="https://doi.org/10.1073/pnas.1523266113" />
	</analytic>
	<monogr>
		<title level="j">America</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="1747" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">Rapid computations of spectrotemporal prediction error support perception of degraded speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sohoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">58077</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">Predictive top-down integration of prior knowledge during speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sohoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Peelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carlyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page" from="8443" to="8453" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.5069-11.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.5069-11.2012" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b256">
	<analytic>
		<title level="a" type="main">Assessing theoretical conclusions with blinded inference to investigate a potential inference crisis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Starns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Cataldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Rotello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Annis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aschenbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Curl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">G</forename><surname>Dobbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Enam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Fraundorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gronlund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="335" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b257">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/2515245919869583</idno>
		<ptr target="https://doi.org/10.1177/2515245919869583" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<analytic>
		<title level="a" type="main">A scale for the measurement of the psychological magnitude pitch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Volkmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Newman</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.1915893</idno>
		<ptr target="https://doi.org/10.1121/1.1915893" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="185" to="190" />
			<date type="published" when="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">Acoustic context effects in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stilp</surname></persName>
		</author>
		<idno type="DOI">10.1002/wcs.1517</idno>
		<ptr target="https://doi.org/https://doi.org/10.1002/wcs.1517" />
	</analytic>
	<monogr>
		<title level="j">WIREs Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<analytic>
		<title level="a" type="main">Uncovering the role of gender stereotypes in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Strand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="86" to="100" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b261">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0261927x99018001006</idno>
		<ptr target="https://doi.org/10.1177/0261927x99018001006" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b262">
	<analytic>
		<title level="a" type="main">The role of variation in the perception of accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sumner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2010.10.018</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2010.10.018" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="131" to="136" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b263">
	<analytic>
		<title level="a" type="main">The role of variation in the perception of accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sumner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2010.10.018</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2010.10.018" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="131" to="136" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title level="a" type="main">The socially weighted encoding of spoken words: A dual-route approach to speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sumner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcgowan</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.01015</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2013.01015" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1015" to="1028" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">The effect of experience on the perception and representation of dialect variants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sumner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="487" to="501" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.jml.2009.01.001</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2009.01.001" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b267">
	<monogr>
		<title level="m" type="main">Listeners&apos; categorisation behaviour correlates with gradient changes in exposure statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sabatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Savic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>ExLing</publisher>
			<biblScope unit="page">145</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b268">
	<analytic>
		<title level="a" type="main">Using rational models to understand experiments on accent adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b269">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fpsyg.2021.676271</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2021.676271" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<analytic>
		<title level="a" type="main">Intonational speech prosody encoding in the human auditory cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">801</biblScope>
			<biblScope unit="page" from="797" to="801" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<analytic>
		<title level="a" type="main">Intonational speech prosody encoding in the human auditory cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">801</biblScope>
			<biblScope unit="page" from="797" to="801" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b272">
	<monogr>
		<title level="m" type="main">Diana: Towards computational modeling reaction times in lexical decision in north american english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ernestus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1576" to="1580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b273">
	<monogr>
		<title/>
		<idno type="DOI">10.21437/Interspeech.2015-366</idno>
		<ptr target="https://doi.org/10.21437/Interspeech.2015-366" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<monogr>
		<title level="m" type="main">A manuscript under development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">Distributional learning for speech reflects cumulative exposure to a talker&apos;s phonetic distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Monto</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-018-1551-5</idno>
		<ptr target="https://doi.org/10.3758/s13423-018-1551-5" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="985" to="992" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b276">
	<analytic>
		<title level="a" type="main">Role of left inferior prefrontal cortex in retrieval of semantic knowledge: A reevaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Thompson-Schill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Aguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Farah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">26</biblScope>
			<biblScope unit="page" from="14792" to="14797" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<analytic>
		<title level="a" type="main">Cue integration with categories: Weighting acoustic cues in speech using unsupervised learning and distributional statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Toscano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="434" to="464" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b278">
	<analytic>
		<title level="a" type="main">Cue integration and context effects in speech: Evidence against speaking rate normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Toscano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Attention Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="1284" to="1301" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b279">
	<monogr>
		<title level="m" type="main">A single mechanism for language learning across the lifespan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Toscano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Toscano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<ptr target="https://www.academia.edu/14767901/A_single_mechanism_for_language_learning_across_the_lifespan" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">The role of training structure in perceptual learning of accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E D</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sidaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Nygaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/xhp0000260%5C%5Cnhttp://</idno>
		<ptr target="http://dx.doi.org/10.1037/xhp0000260%5C%5Cnhttp://" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b282">
	<analytic>
		<title level="a" type="main">A second chance for a first impression: Sensitivity to cumulative input statistics for lexically guided perceptual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Nygaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Theodore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1003" to="1014" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b283">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13423-020-01840-6</idno>
		<ptr target="https://doi.org/10.3758/s13423-020-01840-6" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b284">
	<analytic>
		<title level="a" type="main">Lexical and audiovisual bases of perceptual adaptation in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ullas</surname></persName>
		</author>
		<idno type="DOI">10.26481/dis.20200617su</idno>
		<ptr target="https://doi.org/10.26481/dis.20200617su" />
	</analytic>
	<monogr>
		<title level="m">Ipskamp Printing BV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b285">
	<analytic>
		<title level="a" type="main">How to embrace variation and accept uncertainty in linguistic and psycholinguistic data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vasishth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1311" to="1342" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b286">
	<monogr>
		<title/>
		<idno type="DOI">10.1515/ling-2019-0051</idno>
		<ptr target="https://doi.org/10.1515/ling-2019-0051" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b287">
	<analytic>
		<title level="a" type="main">Response bias modulates the speech motor system during syllable discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Venezia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saberi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hickock</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00157</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2012.00157" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b288">
	<analytic>
		<title level="a" type="main">Recalibration of phonetic categories by lipread speech: Measuring aftereffects after a 24-hour delay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="341" to="350" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b289">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0023830909103178</idno>
		<ptr target="https://doi.org/10.1177/0023830909103178" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b290">
	<analytic>
		<title level="a" type="main">Visual recalibration and selective adaptation in auditory-visual speech perception: Contrasting build-up courses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Linden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>De Gelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bertelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="572" to="577" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b291">
	<analytic>
		<title level="a" type="main">Functional adaptive sequential testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">I</forename><surname>Macleod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fechner&apos;s legacy in psychology</title>
		<imprint>
			<publisher>Brill</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="87" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b292">
	<analytic>
		<title level="a" type="main">Effects of acoustic variability in the perceptual learning of non-native-accented speech sounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jongman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sereno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phonetica</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="122" to="144" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b293">
	<monogr>
		<title/>
		<idno type="DOI">10.1159/000107913</idno>
		<ptr target="https://doi.org/10.1159/000107913" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b294">
	<analytic>
		<title level="a" type="main">Congruence between &apos;word age&apos; and &apos;voice age&apos; facilitates lexical access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hay</surname></persName>
		</author>
		<idno type="DOI">10.1515/labphon.2011.007</idno>
		<ptr target="https://doi.org/10.1515/labphon.2011.007" />
	</analytic>
	<monogr>
		<title level="j">Laboratory Phonology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="219" to="237" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b295">
	<analytic>
		<title level="a" type="main">Can you hear my age? influences of speech rate and speech spontaneity on estimation of speaker age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Waller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sörqvist</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2015.00978</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2015.00978" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b296">
	<analytic>
		<title level="a" type="main">Speech perception and generalization across talkers and accents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weatherholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1093/acref</idno>
		<ptr target="http://oxfordre.com/linguistics/view/10.1093/acref" />
	</analytic>
	<monogr>
		<title level="j">Oxford Research Encyclopedia of Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b297">
	<monogr>
		<title/>
		<idno type="DOI">10.1093/acrefore/9780199384655.013.95</idno>
		<ptr target="https://doi.org/10.1093/acrefore/9780199384655.013.95" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b298">
	<monogr>
		<title level="m" type="main">Exemplar models, evolution and language change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Wedel</surname></persName>
		</author>
		<idno type="DOI">10.1515/TLR.2006.010</idno>
		<ptr target="https://doi.org/doi:10.1515/TLR.2006.010" />
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="247" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b299">
	<monogr>
		<title level="m" type="main">Foreign accented speech: Encoding and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Weil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>The Ohio State University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b300">
	<analytic>
		<title level="a" type="main">The psychometric function: I. fitting, sampling, and goodness of fit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1293" to="1313" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b301">
	<analytic>
		<title level="a" type="main">Speech: It&apos;s not as acoustic as you think</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Winn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acoustics Today</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b302">
	<analytic>
		<title level="a" type="main">How to analyze linguistic change using mixed models, growth curve analysis and generalized additive modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wieling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Evolution</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="18" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b303">
	<analytic>
		<title level="a" type="main">Automaticity and stability of adaptation to a foreign-accented speaker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Witteman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Bardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="168" to="189" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b304">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0023830914528102</idno>
		<ptr target="https://doi.org/10.1177/0023830914528102" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b305">
	<analytic>
		<title level="a" type="main">Encoding and decoding of meaning through structured variability in speech prosody</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buxó-Lugo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kurumada</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2021.104619</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.cognition.2021.104619" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b306">
	<analytic>
		<title level="a" type="main">Sleep facilitates talker generalization of accent adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Earle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="3342" to="3342" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b307">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.4970675</idno>
		<ptr target="https://doi.org/10.1121/1.4970675" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b308">
	<analytic>
		<title level="a" type="main">Sleep facilitates generalisation of accent adaptation to a new talker. Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Earle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="196" to="210" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b309">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/23273798.2017.1369551</idno>
		<ptr target="https://doi.org/10.1080/23273798.2017.1369551" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b310">
	<analytic>
		<title level="a" type="main">Cross-talker generalization in the perception of non-native speech: A large-scale replication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001039</idno>
		<ptr target="https://doi.org/10.1037/xge0001039" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="22" to="56" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b311">
	<analytic>
		<title level="a" type="main">Learning a talker or learning an accent: Acoustic similarity constrains generalization of foreign accent adaptation to new talkers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2017.07.005</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.jml.2017.07.005" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="30" to="46" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b312">
	<analytic>
		<title level="a" type="main">More than a boundary shift: Perceptual adaptation to foreign-accented speech reshapes the internal structure of phonetic categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="206" to="217" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b313">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/xhp0000285</idno>
		<ptr target="https://doi.org/10.1037/xhp0000285" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b314">
	<analytic>
		<title level="a" type="main">Rapid adaptation to foreign-accented speech and its transfer to an unfamiliar talker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weatherholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bainton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Burchill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.5027410</idno>
		<ptr target="https://doi.org/10.1121/1.5027410" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b315">
	<analytic>
		<title level="a" type="main">The generalizability crisis (2020/12/21)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yarkoni</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X20001685</idno>
		<ptr target="https://doi.org/DOI:10.1017/S0140525X20001685" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b316">
	<analytic>
		<title level="a" type="main">The neural processing of foreign-accented speech and its relationship to listener bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Smiljanic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2014.00768</idno>
		<ptr target="https://doi.org/10.3389/fnhum.2014.00768" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b317">
	<analytic>
		<title level="a" type="main">The time course of normalizing speech variability in vowels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bandl.2021.105028</idno>
		<ptr target="https://doi.org/10.1016/j.bandl.2021.105028" />
	</analytic>
	<monogr>
		<title level="j">Brain and Language</title>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b318">
	<analytic>
		<title level="a" type="main">Perceptual learning of speech under optimal and adverse conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0033182</idno>
		<ptr target="https://doi.org/10.1037/a0033182" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="200" to="217" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b319">
	<analytic>
		<title level="a" type="main">Linguistic effect on speech perception observed at the brainstem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Kuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="8716" to="8721" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b320">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1800186115</idno>
		<ptr target="https://doi.org/10.1073/pnas.1800186115" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b321">
	<analytic>
		<title level="a" type="main">The relationship between phonemic category boundary changes and perceptual adjustments to natural accents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning Memory and Cognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1270" to="1292" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b322">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/xlm0000788</idno>
		<ptr target="https://doi.org/10.1037/xlm0000788" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b323">
	<monogr>
		<title level="m" type="main">Subdivision of the audible frequency range into critical bands (frequenzgruppen). The Journal of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zwicker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961" />
			<publisher>Acoustical Society of America</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="248" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b324">
	<analytic>
		<title level="a" type="main">Relative cue encoding in the context of sophisticated models of categorization: Separating information from categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Apfelbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-014-0783-2</idno>
		<ptr target="https://doi.org/10.3758/s13423-014-0783-2" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="916" to="943" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b325">
	<monogr>
		<title level="m" type="main">papaja: Create APA manuscripts with R Markdown</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Aust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Barth</surname></persName>
		</author>
		<ptr target="https://github.com/crsh/papaja" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 0.1.0.9997</note>
</biblStruct>

<biblStruct xml:id="b326">
	<monogr>
		<title level="m" type="main">Magrittr: A forward-pipe operator for r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Bache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=magrittr" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 2.0.1</note>
</biblStruct>

<biblStruct xml:id="b327">
	<analytic>
		<title level="a" type="main">A regression approach to vowel normalization for missing and unbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barreda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Nearey</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.5047742</idno>
		<ptr target="https://doi.org/10.1121/1.5047742" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="500" to="520" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b328">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Barth</surname></persName>
		</author>
		<title level="m">tinylabels: Lightweight variable labels</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>R package version 0.2.3</note>
</biblStruct>

<biblStruct xml:id="b329">
	<analytic>
		<title level="a" type="main">Fitting linear mixed-effects models using lme4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mächler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v067.i01</idno>
		<ptr target="https://doi.org/10.18637/jss.v067.i01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b330">
	<monogr>
		<title level="m" type="main">Matrix: Sparse and dense matrix classes and methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=Matrix" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 1.3-4</note>
</biblStruct>

<biblStruct xml:id="b331">
	<analytic>
		<title level="a" type="main">mixtools: An R package for analyzing finite mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Benaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chauveau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b332">
	<monogr>
		<title level="m" type="main">Delayed information benefits adaptation to unexpected pronunciations: Evidence for maintenance of perceptual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Burchill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b333">
	<analytic>
		<title level="a" type="main">brms: An R package for Bayesian multilevel models using Stan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v080.i01</idno>
		<ptr target="https://doi.org/10.18637/jss.v080.i01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b334">
	<analytic>
		<title level="a" type="main">Advanced Bayesian multilevel modeling with the R package brms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<idno type="DOI">10.32614/RJ-2018-017</idno>
		<ptr target="https://doi.org/10.32614/RJ-2018-017" />
	</analytic>
	<monogr>
		<title level="j">The R Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="395" to="411" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b335">
	<analytic>
		<title level="a" type="main">Bayesian item response modeling in R with brms and Stan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v100.i05</idno>
		<ptr target="https://doi.org/10.18637/jss.v100.i05" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="54" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b336">
	<monogr>
		<title level="m" type="main">Tools for multimodal annotation. Handbook of Linguistic Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-94-024-0881-2_7</idno>
		<ptr target="https://doi.org/10.1007/978-94-024-0881-2_7" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="209" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b337">
	<monogr>
		<title level="m" type="main">Predictability of stop consonant phonetics across talkers: Between-category and within-category dependencies among cues for place and voice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chodroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1515/lingvan-2017-0047</idno>
		<ptr target="https://doi.org/10.1515/lingvan-2017-0047" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b338">
	<monogr>
		<title level="m" type="main">Acoustic-phonetic and auditory mechanisms of adaptation in the perception of sibilant fricatives. Attention, Perception, and Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chodroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-019-01894-2</idno>
		<ptr target="https://doi.org/10.3758/s13414-019-01894-2" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="2027" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b339">
	<analytic>
		<title level="a" type="main">Perception of speech reflects optimal use of probabilistic speech cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Clayards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Tanenhaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="804" to="809" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b340">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2008.04.004</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2008.04.004" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b341">
	<analytic>
		<title level="a" type="main">The nationwide speech project: A new corpus of american english dialects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Clopper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Pisoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="633" to="644" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b342">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.specom.2005.09.010</idno>
		<ptr target="https://doi.org/10.1016/j.specom.2005.09.010" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b343">
	<monogr>
		<title level="m" type="main">Processx: Execute and control system processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csárdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chang</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=processx" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 3.5.2</note>
</biblStruct>

<biblStruct xml:id="b344">
	<monogr>
		<title level="m" type="main">Data.table: Extension of &apos;data.frame</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dowle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=data.table" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 1.14.2</note>
</biblStruct>

<biblStruct xml:id="b345">
	<analytic>
		<title level="a" type="main">Lexically guided perceptual tuning of internal phonetic category structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Drouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">.org/10.1121/1.4964468</idno>
		<ptr target="https://doi.org/doi.org/10.1121/1.4964468" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="307" to="313" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b346">
	<analytic>
		<title level="a" type="main">Cognitive science in the era of artificial intelligence: A roadmap for reverse-engineering the infant language-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dupoux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="43" to="59" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b347">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2017.11.008</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.cognition.2017.11.008" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b348">
	<analytic>
		<title level="a" type="main">Extending extitR with extitC++: A Brief Introduction to extitRcpp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eddelbuettel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Balamuta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="36" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b349">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/00031305.2017.1375990</idno>
		<ptr target="https://doi.org/10.1080/00031305.2017.1375990" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b350">
	<analytic>
		<title level="a" type="main">Rcpp: Seamless R and C++ integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eddelbuettel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>François</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v040.i08</idno>
		<ptr target="https://doi.org/10.18637/jss.v040.i08" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b351">
	<analytic>
		<title level="a" type="main">Constraints on the transfer of perceptual learning in accented speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Melinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00148</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2013.00148" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">148</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b352">
	<analytic>
		<title level="a" type="main">Word-level information influences phonetic learning in adults and infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="427" to="438" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b353">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2013.02.007</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.cognition.2013.02.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b354">
	<analytic>
		<title level="a" type="main">Evidence for implicit learning in syntactic comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.12022</idno>
		<ptr target="https://doi.org/doi:10.1111/cogs.12022" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="578" to="591" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b355">
	<monogr>
		<title level="m" type="main">Purrr: Functional programming tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 0.3.4</note>
</biblStruct>

<biblStruct xml:id="b356">
	<monogr>
		<title level="m" type="main">Rlang: Functions for base types and core r and &apos;tidyverse&apos; features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=rlang" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 0.4.12</note>
</biblStruct>

<biblStruct xml:id="b357">
	<analytic>
		<title level="a" type="main">Acoustic characteristcs of american english vowels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hillenbrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Getty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wheeler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="3099" to="3111" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b358">
	<analytic>
		<title level="a" type="main">Temporally nonadjacent nonlinguistic sounds affect speech categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0956-7976.2005.01532.x</idno>
		<ptr target="https://doi.org/10.1111/j.0956-7976.2005.01532.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="305" to="312" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b359">
	<analytic>
		<title level="a" type="main">Speech categorization in context: Joint effects of nonspeech and speech precursors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="4016" to="4026" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b360">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.2195119</idno>
		<ptr target="https://doi.org/10.1121/1.2195119" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b361">
	<analytic>
		<title level="a" type="main">Influence of fundamental frequency on stop-consonant voicing perception: A case of learned covariation or auditory enhancement?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Lotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Kluender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="764" to="774" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b362">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.1339825</idno>
		<ptr target="https://doi.org/10.1121/1.1339825" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b363">
	<monogr>
		<title level="m" type="main">Evidence for the central origin of lexical tone normalization (l)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b364">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="1145" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b365">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.3543994</idno>
		<ptr target="https://doi.org/10.1121/1.3543994" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b366">
	<monogr>
		<title level="m" type="main">Latexdiffr: Diff &apos;rmarkdown&apos; files using the &apos;latexdiff&apos; utility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugh-Jones</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=latexdiffr" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 0.1.0</note>
</biblStruct>

<biblStruct xml:id="b367">
	<monogr>
		<title level="m" type="main">Word recognition reflects dimension-based statistical learning (2011/10/17)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0025641</idno>
		<ptr target="https://doi.org/10.1037/a0025641" />
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1939" to="1956" />
		</imprint>
	</monogr>
	<note>Journal of experimental psychology. Human perception and performance</note>
</biblStruct>

<biblStruct xml:id="b368">
	<monogr>
		<title level="m" type="main">Generalization of dimension-based statistical learning. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1744" to="1762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b369">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13414-019-01956-5</idno>
		<ptr target="https://doi.org/10.3758/s13414-019-01956-5" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b370">
	<monogr>
		<title level="m" type="main">Strong evidence for expectation adaptation during language understanding, not a replication failure. a reply to harrington stack, james, and watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Burchill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bushong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>XXXX</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b371">
	<analytic>
		<title level="a" type="main">The f method of vocal tract length normalization for vowels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.5334/labphon.196</idno>
		<ptr target="https://doi.org/10.5334/labphon.196" />
	</analytic>
	<monogr>
		<title level="j">Laboratory Phonology: Journal of the Association for Laboratory Phonology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b372">
	<analytic>
		<title level="a" type="main">Robust speech perception: Recognize the familiar, generalize to the similar, and adapt to the novel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0038695</idno>
		<ptr target="https://doi.org/10.1037/a0038695" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="148" to="203" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b373">
	<analytic>
		<title level="a" type="main">Re-examining selective adaptation: Fatiguing feature detectors, or distributional learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="678" to="691" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b374">
	<monogr>
		<title level="m" type="main">What do you expect from an unfamiliar talker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Kleinschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<editor>J. C. Trueswell, A. Papafragou, D. Grodner, &amp; D. Mirman</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b375">
	<analytic>
		<title level="a" type="main">Perceptual learning for speech: Is there a return to normal?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraljic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="141" to="178" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b376">
	<analytic>
		<title level="a" type="main">Generalization in perceptual learning for speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraljic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="262" to="268" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b377">
	<analytic>
		<title level="a" type="main">Perceptual adjustments to multiple speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraljic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b378">
	<analytic>
		<title level="a" type="main">Nevertheless, it persists: Dimension-based statistical learning and normalization of speech impact different levels of perceptual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lehet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2020.104328</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2020.104328" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b379">
	<monogr>
		<title level="m" type="main">Linguisticsdown: Easy linguistics document writing with r markdown</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=linguisticsdown" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>R package version 1.2.0</note>
</biblStruct>

<biblStruct xml:id="b380">
	<analytic>
		<title level="a" type="main">Learning foreign sounds in an alien world: Videogame training improves non-native speech categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1390" to="1405" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b381">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.1551-6709.2011.01192.x</idno>
		<ptr target="https://doi.org/10.1111/j.1551-6709.2011.01192.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b382">
	<analytic>
		<title level="a" type="main">Dimension-based statistical learning of vowels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1783" to="1798" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b383">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0025641</idno>
		<ptr target="https://doi.org/10.1037/a0025641" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b384">
	<analytic>
		<title level="a" type="main">Classification of russian vowels spoken by different speakers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lobanov</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.1912396</idno>
		<ptr target="https://doi.org/10.1121/1.1912396" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="606" to="608" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b385">
	<monogr>
		<title level="m" type="main">Diptest: Hartigan&apos;s dip test statistic for unimodality -corrected</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=diptest" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 0.76-0</note>
</biblStruct>

<biblStruct xml:id="b386">
	<monogr>
		<title level="m" type="main">Diptest: Hartigan&apos;s dip test statistic for unimodality -corrected</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 0.76-0</note>
</biblStruct>

<biblStruct xml:id="b387">
	<monogr>
		<title level="m" type="main">Phonr: Tools for phoneticians and phonologists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Mccloy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>R package version 1.0-7</note>
</biblStruct>

<biblStruct xml:id="b388">
	<analytic>
		<title level="a" type="main">What information is necessary for speech categorization?: Harnessing variability in the speech signal by integrating cues computed relative to expectations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jongman</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0022325.What</idno>
		<ptr target="https://doi.org/10.1037/a0022325.What" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="219" to="246" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b389">
	<analytic>
		<title level="a" type="main">Distance measures for speech recognition, psychological and instrumental</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mermelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="374" to="388" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b390">
	<analytic>
		<title level="a" type="main">Phonological abstraction without phonemes in speech perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mitterer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Scharenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="356" to="361" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b391">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2013.07.011</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2013.07.011" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b392">
	<analytic>
		<title level="a" type="main">Auditory sensitivity to formant ratios: Toward an account of vowel normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Monahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Idsardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and cognitive processes</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="808" to="839" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b393">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/01690965.2010.490047</idno>
		<ptr target="https://doi.org/10.1080/01690965.2010.490047" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b394">
	<monogr>
		<title level="m" type="main">Tibble: Simple data frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 3.1.6</note>
</biblStruct>

<biblStruct xml:id="b395">
	<monogr>
		<title level="m" type="main">Machine learning: A probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b396">
	<analytic>
		<title level="a" type="main">The perceptual consequences of within-talker variability in fricative production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Clouse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Burnham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="1181" to="1196" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b397">
	<analytic>
		<title level="a" type="main">The temporal dynamics of perceptual uncertainty: Eye movement evidence from cantonese segment and tone perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Rij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="103" to="125" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b398">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.jml.2016.03.005</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2016.03.005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b399">
	<analytic>
		<title level="a" type="main">Merging information in speech recognition: Feedback is never necessary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cutler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="299" to="370" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b400">
	<analytic>
		<title level="a" type="main">Shortlist b: A bayesian model of continuous speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="357" to="95" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b401">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0033-295X.115.2.357</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.115.2.357" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b402">
	<analytic>
		<title level="a" type="main">Perceptual learning in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cutler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="204" to="238" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b403">
	<monogr>
		<title level="m" type="main">Curl: A modern and flexible web client for r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ooms</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 4.3.2</note>
</biblStruct>

<biblStruct xml:id="b404">
	<monogr>
		<title level="m" type="main">Magick: Advanced graphics and image-processing in r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ooms</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 2.7.3</note>
</biblStruct>

<biblStruct xml:id="b405">
	<monogr>
		<title level="m" type="main">Gganimate: A grammar of animated graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=gganimate" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 1.0.7</note>
</biblStruct>

<biblStruct xml:id="b406">
	<monogr>
		<title level="m" type="main">Evaluating normalization accounts against the dense vowel space of central swedish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
		<respStmt>
			<orgName>Stockholm University</orgName>
		</respStmt>
	</monogr>
	<note>manuscript</note>
</biblStruct>

<biblStruct xml:id="b407">
	<analytic>
		<title level="a" type="main">Automated annotation of learner english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Picoral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Staples</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Reppen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Learner Corpus Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="17" to="52" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b408">
	<monogr>
		<title/>
		<idno type="DOI">10.1075/ijlcr.20003.pic</idno>
		<ptr target="https://doi.org/10.1075/ijlcr.20003.pic" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b409">
	<analytic>
		<title level="a" type="main">Rapid syntactic adaptation in self-paced reading: Detectable, but only with many participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Linzen</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0001046</idno>
		<ptr target="https://doi.org/10.1037/xlm0001046" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1156" to="1172" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b410">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing. R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b411">
	<analytic>
		<title level="a" type="main">Evaluating low-level speech features against human perceptual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Salgado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jansen</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00071</idno>
		<ptr target="https://doi.org/10.1162/tacl_a_00071" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="425" to="440" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b412">
	<analytic>
		<title level="a" type="main">Emergent data analysis in phonetic sciences: Towards pluralism and reproducibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Roettger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Baayen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b413">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.wocn.2018.12.001</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.wocn.2018.12.001" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b414">
	<analytic>
		<title level="a" type="main">Red herring detectors and speech perception: In defense of selective adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="452" to="499" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b415">
	<analytic>
		<title level="a" type="main">Auditory selective adaptation moment by moment, at multiple timescales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dumay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">596</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b416">
	<analytic>
		<title level="a" type="main">Individual differences in phonetic cue use in production and perception of a non-native sound contrast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Warner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="183" to="204" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b417">
	<analytic>
		<title level="a" type="main">Phonetic cue weighting in perception and production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Clare</surname></persName>
		</author>
		<idno type="DOI">10.1002/wcs.1521</idno>
		<ptr target="https://doi.org/10.1002/wcs.1521" />
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b418">
	<monogr>
		<title level="m" type="main">Interactive web-based data visualization with r, plotly, and shiny</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sievert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Chapman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b419">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Crc</surname></persName>
		</author>
		<ptr target="https://plotly-r.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b420">
	<monogr>
		<title level="m" type="main">Laplacesdemon: Complete environment for bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;</forename><surname>Statisticat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Llc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 16.1.6</note>
</biblStruct>

<biblStruct xml:id="b421">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bayesian-Inference.com. https</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b422">
	<monogr>
		<title level="m" type="main">Listeners&apos; categorisation behaviour correlates with gradient changes in exposure statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sabatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Savic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>ExLing</publisher>
			<biblScope unit="page">145</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b423">
	<analytic>
		<title level="a" type="main">Using rational models to understand experiments on accent adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b424">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fpsyg.2021.676271</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2021.676271" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b425">
	<monogr>
		<title level="m" type="main">A manuscript under development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cummings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b426">
	<analytic>
		<title level="a" type="main">Individual talker differences in voice-onset-time: Contextual influences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Desteno</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.3106131</idno>
		<ptr target="https://doi.org/10.1121/1.3106131" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="3974" to="3982" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b427">
	<analytic>
		<title level="a" type="main">Distributional learning for speech reflects cumulative exposure to a talker&apos;s phonetic distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theodore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Monto</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-018-1551-5</idno>
		<ptr target="https://doi.org/10.3758/s13423-018-1551-5" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="985" to="992" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b428">
	<analytic>
		<title level="a" type="main">Visual recalibration and selective adaptation in auditory-visual speech perception: Contrasting build-up courses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroomen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Linden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>De Gelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bertelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="572" to="577" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b429">
	<analytic>
		<title level="a" type="main">Incidental categorization of spectrally complex non-invariant auditory stimuli in a computer game task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.2011156</idno>
		<ptr target="https://doi.org/10.1121/1.2011156" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b430">
	<analytic>
		<title level="a" type="main">Speech perception and generalization across talkers and accents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weatherholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1093/acref</idno>
		<ptr target="http://oxfordre.com/linguistics/view/10.1093/acref" />
	</analytic>
	<monogr>
		<title level="j">Oxford Research Encyclopedia of Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b431">
	<monogr>
		<title/>
		<idno type="DOI">10.1093/acrefore/9780199384655.013.95</idno>
		<ptr target="https://doi.org/10.1093/acrefore/9780199384655.013.95" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b432">
	<monogr>
		<title level="m" type="main">Ggplot2: Elegant graphics for data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="https://ggplot2.tidyverse.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b433">
	<monogr>
		<title level="m" type="main">Assertthat: Easy pre and post assertions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>R package version 0.2.1</note>
</biblStruct>

<biblStruct xml:id="b434">
	<monogr>
		<title level="m" type="main">Stringr: Simple, consistent wrappers for common string operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=stringr" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>R package version 1.4.0</note>
</biblStruct>

<biblStruct xml:id="b435">
	<monogr>
		<title level="m" type="main">Modelr: Modelling functions that work with the pipe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=modelr" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 0.1.8</note>
</biblStruct>

<biblStruct xml:id="b436">
	<monogr>
		<title level="m" type="main">Forcats: Tools for working with categorical variables (factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=forcats" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 0.5.1</note>
</biblStruct>

<biblStruct xml:id="b437">
	<monogr>
		<title level="m" type="main">Tidyr: Tidy messy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 1.1.4</note>
</biblStruct>

<biblStruct xml:id="b438">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Averick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Mcgowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>François</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grolemund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Bache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ooms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Spinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yutani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b439">
	<analytic>
		<title level="a" type="main">Welcome to the tidyverse</title>
		<idno type="DOI">10.21105/joss.01686</idno>
		<ptr target="https://doi.org/10.21105/joss.01686" />
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">43</biblScope>
			<biblScope unit="page">1686</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b440">
	<monogr>
		<title level="m" type="main">Usethis: Automate package and project setup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Barrett</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=usethis" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>R package version 2.1.6</note>
</biblStruct>

<biblStruct xml:id="b441">
	<monogr>
		<title level="m" type="main">Dplyr: A grammar of data manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>François</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=dplyr" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 1.0.7</note>
</biblStruct>

<biblStruct xml:id="b442">
	<monogr>
		<title level="m" type="main">Readr: Read rectangular text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bryan</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=readr" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 2.1.1</note>
</biblStruct>

<biblStruct xml:id="b443">
	<monogr>
		<title level="m" type="main">Devtools: Tools to make developing r packages easier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bryan</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=devtools" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>R package version 2.4.4</note>
</biblStruct>

<biblStruct xml:id="b444">
	<monogr>
		<title level="m" type="main">Cowplot: Streamlined plot theme and plot annotations for &apos;ggplot2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">O</forename><surname>Wilke</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=cowplot" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 1.1.1</note>
</biblStruct>

<biblStruct xml:id="b445">
	<analytic>
		<title level="a" type="main">Emu-sdms: Advanced speech database management and analysis in r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Winkelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jänsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="392" to="410" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b446">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.csl.2017.01.002</idno>
		<ptr target="https://doi.org/10.1016/j.csl.2017.01.002" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b447">
	<analytic>
		<title level="a" type="main">Encoding and decoding of meaning through structured variability in speech prosody</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buxó-Lugo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kurumada</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2021.104619</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.cognition.2021.104619" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b448">
	<analytic>
		<title level="a" type="main">Comparing non-native and native speech: Are l2 productions more variable?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="3322" to="3347" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b449">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/10.0001141</idno>
		<ptr target="https://doi.org/10.1121/10.0001141" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b450">
	<analytic>
		<title level="a" type="main">Cross-talker generalization in the perception of non-native speech: A large-scale replication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001039</idno>
		<ptr target="https://doi.org/10.1037/xge0001039" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="22" to="56" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b451">
	<analytic>
		<title level="a" type="main">Learning a talker or learning an accent: Acoustic similarity constrains generalization of foreign accent adaptation to new talkers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2017.07.005</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.jml.2017.07.005" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="30" to="46" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b452">
	<monogr>
		<title level="m" type="main">Knitr: A general-purpose package for dynamic report generation in r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<ptr target="https://yihui.org/knitr/" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 1.36</note>
</biblStruct>

<biblStruct xml:id="b453">
	<monogr>
		<title level="m" type="main">Tufte: Tufte&apos;s styles for r markdown documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allaire</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=tufte" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>R package version 0.12</note>
</biblStruct>

<biblStruct xml:id="b454">
	<monogr>
		<title level="m" type="main">R markdown: The definitive guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grolemund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Chapman</publisher>
		</imprint>
	</monogr>
	<note>ISBN 9781138359338</note>
</biblStruct>

<biblStruct xml:id="b455">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Crc</surname></persName>
		</author>
		<ptr target="https://bookdown.org/yihui/rmarkdown" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b456">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dervieux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riederer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R markdown cookbook [ISBN 9780367563837</note>
</biblStruct>

<biblStruct xml:id="b457">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Crc</surname></persName>
		</author>
		<ptr target="https://bookdown.org/yihui/rmarkdown-cookbook" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b458">
	<monogr>
		<title level="m" type="main">Kableextra: Construct complex table with &apos;kable&apos; and pipe syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=kableExtra" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>R package version 1.3.4</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
