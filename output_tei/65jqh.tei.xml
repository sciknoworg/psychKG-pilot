<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data Driven Equation Discovery Reveals Non-linear Reinforcement Learning in Humans</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><forename type="middle">J</forename><surname>Lafollette</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychological Sciences</orgName>
								<orgName type="institution">Case Western Reserve University</orgName>
								<address>
									<settlement>Cleveland</settlement>
									<region>OH</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janni</forename><surname>Yuval</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google Research</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roey</forename><surname>Schurr</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Melnikoff</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Stanford Graduate School of Business</orgName>
								<address>
									<region>Stanford CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Goldenberg</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Harvard Business School</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Digital, Data and Design Institute</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data Driven Equation Discovery Reveals Non-linear Reinforcement Learning in Humans</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Computational models of reinforcement learning (RL), have significantly contributed to our understanding of human behavior and decision-making. Traditional RL models, however, often adopt a linear approach to updating reward expectations, potentially oversimplifying the nuanced relationship between human behavior and rewards. To address these challenges and explore new models of reinforcement learning, we utilized a novel method of model discovery using equation discovery algorithms. This method, currently used mainly in physics and biology, attempts to capture data by proposing a differential equation from an array of suggested linear and nonlinear functions. Using this novel method, we were able to identify a new model of RL which we termed, the Quadratic Q-Weighted model. The model suggests that reward prediction errors obey nonlinear dynamics and exhibit negativity biases, resulting in an underweighting of reward when expectations are low, and an overweighting of the absence of reward when expectations are high. We tested the generalizability of our model by comparing it to classical models used in 9 published studies. Our model surpassed traditional models in predictive accuracy across eight out of these nine published datasets, demonstrating not only its generalizability but also its potential to offer new insights into the complexities of human learning. This work showcases the integration of a novel behavioral task with advanced computational methodologies as a potent strategy for uncovering the intricate patterns of human cognition, marking a significant step forward in the development of computational models that are both interpretable and broadly applicable. Significance Statement Our article offers a novel answer to a foundational question in psychology and neuroscience: How do people learn from rewards and punishments? Specifically, we introduce a new computational model of human reinforcement learning that points to a non-linear updating of the probability of reward. The novelty of our model lies also in the process through which it was developed. Specifically, we discovered our model in a bottom-up fashion using symbolic regression-a class of machine learning tools applied primarily in physics and engineering. We believe that, in addition to the theoretical contributions of the model to the field of reinforcement learning, our work strongly demonstrates the utility of implementing equation-discovery tools in the field of social behavior. Over the past few decades, the social sciences have seen an increasing prevalence of computational cognitive modeling for explaining human behavior (1). Computational models have had a transformational contribution to a variety of domains, most notably reinforcement learning (RL) (2). RL provides a mathematical framework for understanding how agents learn and make decisions based on experience with rewards or punishments. Research on RL has contributed to our understanding of human and animal learning, including its neuronal underpinnings in the brain (3-7). Insights from RL in the social sciences have also been adopted in machine learning, contributing to tremendous improvements in facilitating learning in artificial agents (8-10). Although undoubtedly successful, RL models traditionally update reward expectations linearly, an assumption that may oversimplify human behavior&apos;s complex relationship with rewards. Contrary to this linear approach, evidence outside of RL models suggests that human behavior exhibits a nonlinear response to rewards, with subjective value not scaling linearly with the reward&apos;s objective size. This is supported by both psychological and economic theories (11-13), as well as neuroscientific findings, indicating a nonlinear coding of rewards in the brain (14-17). One of the most studied aspects of this nonlinearity is probability weighting, a concept central to decision-making theories such as Prospect Theory (13)). Probability weighting reflects the tendency of people to distort objective probabilities in systematic ways: overestimating low probabilities and underestimating high ones. This phenomenon is often captured by the well-known inverse &quot;S-shaped&quot; weighting function, where extreme probabilities are perceived to be less extreme. However, while this inverse S-shape has been widely accepted, there is ongoing debate about whether it universally applies across all contexts. Empirical findings suggest that the nature of the distortion may vary depending on the task, context, and the structure of rewards (14-16). Thus, while probability weighting provides valuable insights, it may be overly simplified by fixed functional forms, leaving room for alternative interpretations of how people perceive and learn from probabilistic rewards. Yet, despite the empirical evidence in support of a nonlinearity in human expectation, linear delta-updating rules remain an assumption in virtually every RL study. The Rescorla-Wagner model(17), arguably one of the most influential delta-updating rules, assumes exactly this: A linear relationship between expectations and change in response to feedback. Variations of the model that incorporate decay over time, or asymmetric learning rates for positive and negative feedback, all share this common assumption that learning is linear. This underscores a complex problem in model development: Despite their achievements, RL models-and computational models of social behavior in general-are vulnerable to the biases and limitations of their designers, as they are mostly developed top-down based on theoretical insights or adapted from historically dominant models. This is perhaps why canonical RL models struggle to find a balance between interpretability, parsimony, accuracy, and generalizability across individuals and contexts (18). New models are being proposed continuously; however, they suffer from many of the same limitations as the models they aim to replace (19). Deep learning may come to mind as a suitable alternative to top-down model development, but comes with its own tradeoffs: high prediction accuracy at the expense of interpretability and limited generalization outside training data. Recently, however, efforts to merge deep learning with traditional models have aimed at enhancing interpretability and systematic discovery (20-23). Constraining deep learning within the bounds of theory has yielded more understandable models (24-27), though their broad applicability remains unproven. A complementary approach is to improve existing interpretable models using bottom-up, machine learning, approaches (28). These methods,</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>while innovative, still depend on pre-existing models and extensive data. To address these gaps and promote model discovery in the social sciences, we propose to adopt algorithms designed for datadriven discovery of nonlinear differential equations in physics and engineering. These data-driven approaches allow the freedom to explore a vast range of functional forms in relatively small datasets while constraining the models to be interpretable.</p><p>The notion that dynamic models can be discovered using bottom up approaches received increased attention in recent decades, especially in physics <ref type="bibr" target="#b29">(29,</ref><ref type="bibr" target="#b30">30)</ref>. Early work in this space suffered from overfitting and required immense computing power. However, recent developments allow for implementations of bottom-up equation discovery in complex, noisy and multidimensional systems <ref type="bibr" target="#b31">(31)</ref><ref type="bibr" target="#b32">(32)</ref><ref type="bibr" target="#b33">(33)</ref>, making it well suited for model discovery in social sciences. Unlike other, more opaque machine learning approaches, these algorithms generate systems of equations that researchers can interpret. Users can also predetermine the space of possible terms that describe the system and control the level of complexity of the obtained model.</p><p>Here we utilize an equation discovery algorithm, SINDy (Sparse Identification of Nonlinear Dynamics; 24), to develop and improve human RL models. SINDy is based on the idea of sparse regression, seeking to identify a minimal set of ordinary differential equations that aim describe the underlying dynamics of a system that produced the observed data (here, the underlying cognitive process). It uses a combination of optimization and feature selection to find the sparse set of candidate functions through iterative multiple regression, and it can amalgamate a wide variety of linear and nonlinear terms (see Methods for details). SINDy has been applied in physics <ref type="bibr" target="#b35">(35,</ref><ref type="bibr" target="#b36">36)</ref>, engineering <ref type="bibr" target="#b37">(37,</ref><ref type="bibr" target="#b38">38)</ref> and biology <ref type="bibr" target="#b18">(19,</ref><ref type="bibr" target="#b39">39)</ref>. An introductory paper suggested its use in social sciences <ref type="bibr" target="#b40">(40)</ref>, but it has not</p><p>been used yet for model development with empirical data.</p><p>The goal of the current project is to discover novel models of RL. We use SINDy to enable testing of multiple RL models without the biases inherent to traditional top-down model development.</p><p>In phase 1, we designed a simple RL task that allows us to capture participants' estimation of a probability of reward across multiple trials. Using SINDy, we then revealed a new interpretable model-termed the Quadratic Q-Weighted model-that introduces new behavioral insights on how people learn the probability of reward. This model, in line with probability weighting theories, demonstrates that participants exhibit a systematic distortion in their estimation or probability, which is similar to the nonlinear probability weighting seen in previous decision-making research. What sets the model apart, however, is its ability to capture a dynamic transition between S-shaped and inverse S-shaped distortions, revealing a context-dependent flexibility influenced by participants' expectations.</p><p>In phase 2 we then take the Quadratic Q-Weighted model and compare its ability to predict reward data on completely different kinds of tasks involving evaluating reward in much more complicated situations such as a two-armed bandit task. We do not use SINDy directly in this phase; rather, we take the Quadratic Q-Weighted model discovered using our simple RL task and embed that model within existing models of more complex decision-making. We demonstrate that the application of the Quadratic Q-Weighted model achieves better results than previous state-of-the-art models across eight of nine public datasets, each published in leading academic journals. This work therefore makes a twofold contribution: First, it provides a proof of concept for utilizing an equation discovery algorithm in the social sciences, enabling the discovery of a novel RL model from behavioral data. Second, it suggests a new model of human RL that accounts for probability weighting distortions and demonstrates its generalization capabilities to more complex decision-making tasks, thereby unveiling novel insights into human cognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phase 1: Equation Discovery from Empirical Probability Estimates.</head><p>Our first goal was to determine whether algorithms discovered by SINDy can provide novel insights into probabilistic learning when trained on empirical data from human learners. To this end, we conducted two empirical studies using a novel learning task composed of 100 trials. Participants assumed the role of an inspector tasked with identifying the rate at which a factory produces working versus defective phones ( <ref type="figure" target="#fig_0">Figure 1</ref>). On each of the 100 trials, participants inspected a new phone produced by the factory and learned whether it was working or defected. Participants then reported the probability that the next phone would be working (see Methods for detailed description). The true probability of a receiving a working phone changed trial-to-trial according to a Gaussian random walk (SD=0.1), bounded between 0.1-0.9; the initial value was drawn from a uniform distribution in the range 0.1-0.9. To incentivize accurate predictions, we offered participants a $0.03 bonus per response within 5% of the true probability. Attention checks were included during the task to ensure data quality; participants who did not pass our criteria for attention checks were excluded from analysis (see Methods). On each trial, a single phone was revealed to either be working or defective. Following each observation, participants were asked to rate on a scale from 0-100% what they thought was the likelihood of the next phone being a working phone.</p><p>We ran two versions of the task. In Study 1 (N = 455), we set the initial probability of a working phone to 0.5. This probability changed every trial according to a Gaussian random walk with SD=0.025; the random walk was unique for every participant. We used diffusion in the true reward rate in order to keep participants engaged with the task, as done in similar tasks <ref type="bibr" target="#b41">(41)</ref><ref type="bibr" target="#b42">(42)</ref><ref type="bibr" target="#b43">(43)</ref>.</p><p>In Study 2 (N = 177), the task was the same as in Study 1 except for two modifications. First, the initial value of the true probability of a working phone was randomly drawn from a uniform distribution U(0.1, 0.9) rather than being fixed at 0.5. Second, we increased the SD of the random walk from 0.025 to 0.1. The purpose of these modifications was to explore how SINDy performed across a broad range of task parameters. Neither Studies 1 or 2 were preregistered and all analyses should be considered exploratory.</p><p>We trained SINDy using data from all participants who met our inclusion criteria (see Methods for exclusions), separately for each study. Input data provided to SINDy were limited to participants'</p><p>reported expectations of observing a working phone , their observations of whether a phone was working or defective , and trial number t. We also provided SINDy with a matrix of candidate functions for feature selection, allowing for a variety of critic models to be identified. These included identity functions for previous expectations and reward, time-dependent decaying functions, and exponential functions for non-linearity (see Methods for specifics on candidate functions and fitting procedure). Consequentially, the Rescorla-Wagner model could be discovered by SINDy if it best explained the empirical data from either study. This was ensured through a series of simulation studies (see Methods: Simulations).</p><p>For Study 1, SINDy discovered the following novel model (R 2 =0.204):</p><formula xml:id="formula_0">+1 = 0.11 − 0.24 2</formula><p>For Study 2, SINDy discovered a near identical model (R 2 =0.196):</p><formula xml:id="formula_1">+1 = 0.10 − 0.17 2</formula><p>To demonstrate that these models were superior in fit to the Rescorla-Wagner model, we separately trained SINDy with a smaller matrix of candidate features limited to only the r-Q term. This limited SINDy to only discover the Rescorla-Wagner model. These limitations yielded worse fit in both studies (Study 1 R2=0.144; Study 2 R2=0.174).</p><p>Note that the coefficients of the discovered models' parameters are not symbolic and are fixed across participants. In both studies, SINDy discovered models of identical form, albeit with slightly different numerical values. We termed the model that SINDy produced the Quadratic Q-Weighted model since the model includes a quadratic term on previous expectation rather than a linear one (hence "Quadratic") and the model includes unequal scaling coefficients for present reward and previous expectation (Q-value; hence "Q-Weighted"). The Quadratic Q-Weighted model accounts for several interesting behavioral phenomena discussed in the results. Most importantly, the functional form of the Quadratic Q-Weighted model leads to an asymptotic bias in the estimation of the true probability. Namely, the model implies that over the long term, participants tend to underestimate Q values when reward probability is high and tend to overestimate Q values and reward probability is low. The transition between under-and over-estimation happens approximately when the true probability of reward is equal to a/b where:  <ref type="figure" target="#fig_1">Figure 2</ref> demonstrate that the Quadratic Q-Weighted model implies the asymptotic bias in the estimation of the true probability. One example of the underestimation is that within this model an agent cannot predict Q values larger than the stable point √ / even when the reward probability is 1 -this is where expectations stabilize. Noisy agents, like humans, can occasionally predict Q values larger than √ / , but thereafter will be biased to lower their expectations back toward √ / even if met with further reward. To further explore the implications of the Quadratic Q-Weighted model on participants'</p><formula xml:id="formula_2">+1 = −</formula><p>behavior, we employed linear mixed effects models to predict changes in expectations as a function of reward and distance from the stable point √ / . We conducted a total of four models; two for each study, one of which included only post-reward trials and the other post-non-reward trials. The independent variable in each of the models was whether the current Q value was lower or higher than the stable point √ / . The dependent variable was change in Q from previous trial. We dummy coded the model such that the data above the stable point would be the intercept of the model. This allowed us to not only compare significance between the conditions (above or below √ / ), but also compare  Error bars are 95% confidence intervals. 10% of observations are included as dots to visualize the response distribution. Decreases in Q can be observed when Q is greater than the stable point, even following reward.</p><p>Building on these findings, we next employed a complementary approach to balance the discovery of generalizable learning dynamics with the need to capture individual variability. Although the analysis conducted with the SINDy algorithm allowed us to identify the core functional form of a learning model by pooling data across participants, we recognize that pooling data in this way can obscure meaningful individual differences. To address this possibility, we next used the probabilistic programming language Stan <ref type="formula">45</ref>  <ref type="figure" target="#fig_3">Figure 4</ref>. These results at the individual participant-level support our prior grouplevel analyses conducted with the support of SINDy: Participants' behavior in making probabilistic inference in our study is best explained by a novel RL algorithm, the Quadratic Q-Weighted model.  Although it may be necessary to tailor models to task-specific dynamics, perhaps like those of the go/no-go task, it is equally as valuable that models generalize across a wider range of decisionmaking contexts. Importantly, we did show in our empirical studies that the identified Quadratic Q- More broadly, this work highlights how data-driven discovery can complement theory-driven approaches, offering a path toward more interpretable and predictive models that deepen our understanding of human behavior.Methods Explaining SINDy. For our analysis, we used PySINDy (60, 61), a Python package that provides tools for applying the SINDy algorithm (34) for model discovery. SINDy is used to approximate the unknown governing equations of a dynamical system using a sparse regression framework. It assumes that the dynamics can be expressed as a sum of known functions, multiplied by unknown coefficients.</p><p>By leveraging sparsity-promoting techniques, SINDy aims to identify the most relevant terms in the equation, effectively providing a parsimonious representation of the system's behavior. Typically, SINDy estimates derivatives for system variables of the following form:</p><formula xml:id="formula_3">= ( , )</formula><p>Where X is a matrix of observed variables to be modeled, U is a matrix of control variables that are not to be modeled but may be important for modeling variables in X, ( , ) is a matrix of candidate features selected by the researcher that transform the data, and B is a vector of coefficients that scale the candidate features. Through sparsification techniques such as L2 ridge regression, most of these coefficients are reduced to zero and only the most predictive features remain (see below for details on how we chose to promote sparsity). The objective of the SINDy algorithm is to solve for B</p><p>given the researcher selected candidate features and the approximated first-0rder derivatives of the observed data.</p><p>For most experiments in the social sciences, observed data are collected in discrete trials.</p><p>Therefore, we used SINDy to estimate discrete-time models of the form:</p><formula xml:id="formula_4">+1 = ( , )</formula><p>Where are the observed variables to be modeled from X at timepoint k, and are the control variables (such as r and t in this case) at timepoint k. Rather than calculating a system of derivatives, using SINDy we calculated a matrix X' where the columns of X' are measures of x moved forward in time until the final datapoint at time K (i.e., <ref type="bibr">[1,2,3, … ,̇]</ref>). With this approach, SINDy estimates discrete-time equations for system variables in the form:</p><formula xml:id="formula_5">′ = ( , )</formula><p>We solve for B by using a variation of stepwise sparse regression (SSR) <ref type="bibr" target="#b62">(62)</ref> to minimize the objective function:</p><formula xml:id="formula_6">‖ ′ − ( , ) ‖ 2 2 + ‖ ‖ 2 2</formula><p>Where each element of the coefficient vector B is regularized with the L2 ridge regression value in the penalty term. We chose = 0.2 for all analyses (simulations and empirical data).</p><p>Selecting the value of is crucial as it determines the trade-off between accuracy and parsimony; it is a hyperparameter that should be tuned by the modeler. On each iteration of the minimization procedure, SINDy first solves a standard least square regression to obtain a tentative, non-sparse solution b:</p><formula xml:id="formula_7">= argmin ∈ℝ ‖ ′ − ( , ) ‖ 2 2</formula><p>All possible b are considered, each with one coefficient set to zero, and the solution b with the smallest residual error is selected. Least-squares regression is then again performed on the remaining degrees of freedom. This process continues until there is only one coefficient remaining. Next, we iterate in reverse order over the history of solutions starting from the simplest solution where all but one coefficient is set to 0. We continue to add non-0 coefficients back to the model until the next change in residual error is less than 0.05 times the previous iteration's residual error, at which point the process terminates, providing a sparse solution vector B. This provides a solution that is most parsimonious with the least loss. Like , this multiplier of 0.05 is also a hyperparameter and can be tuned to select a sparsity level for the solution that neither under-or over-fits the data.</p><p>Simulations. The first step of any SINDy analysis is collecting or simulating data to populate the timeseries observational data X and U. These functions were chosen since they provide necessary components to allow SINDy to discover existing theories of learning. Of course, SINDy can also find novel combinations of these candidate functions. Q and r are the building blocks for the model and serve as basic variables for delta-updating rules (2) and as changes may vary over time we also added t as a potential variable. A few decay rates (e.g., -t/10, -t/20) were chosen to allow for a variety of exponential shapes. We initialized the model with linear terms to allow for a classic Rescorla-Wagner model. We also introduced quadratic terms as we wanted to test whether changes in prediction of Q or in the evaluation of r may not be linear, in line with the notion that stimuli is represented by individuals with some form of power transformation <ref type="bibr" target="#b63">(63)</ref>. We also wanted to examine whether the two terms, Q and r, interact with each other or with time, and whether the absolute difference between Q and r might modulate learning.</p><p>Finally, we wanted to allow changes in both Q and r to decay at different rates. As can be seen from this list, we were conservative in our function choices in order to make sure that the resulting model was interpretable. Future work may use other terms in line with the researcher's goals and evaluation of the appropriate relationship between variables. informed consent was obtained from all research participants. In setting our sample size for Study 1, we decided to start with a large sample of 500 participants in order to determine the appropriate sample required for SINDy to make accurate predictions. We recruited participants through Prolific.</p><p>Participants were paid $4 for their participation in the study in addition to $.03 for every time that their estimate was within 5% of the true reward rate. Participants were given attention checks to ensure data quality. On the first and fiftieth trials, participants were asked to type a predetermined word. On the second trial, and every twenty trials thereafter, participants were asked to respond to the slider scale with a specific percentage. On these attention check trials, participants were instead prompted with "This is an attention check. Please move the slider to _%", where the percentage was a number between 0-100. Participants who failed either of the word typing checks or more than 2 of the slider checks were excluded from analysis. Because we assumed that some participants would not be able to complete the task, we recruited a larger number of participants than required N = 543. Our exclusion criteria were conditioned on attention checks (see Attention Checks and Exclusion Criteria below). We removed 3 participants for failed word typing checks and 85 for failed slider checks, for a After establishing the results from Study 1, we conducted an analysis to test the appropriate sample size required for SINDy to capture the appropriate model. We randomly sampled participants from Study 1 to find the smallest N necessary to reliably recover the Quadratic Q-weighted model. 100 iterations of this sampling procedure suggested that ~200 participants were enough for SINDy to reliably capture the model. In Study 2, we therefore aimed for N = 200. We again used Prolific for recruitment and paid participants the same sum as in Study 1. Our initial sample was 206. We used the same selection criteria for exclusions. We remove 29 participants for failed slider checks, for a final sample was N = 177 (Men: 87, Women: 85, other or refused to answer: 5; Age, M = 37.88, SD = 12.06).</p><p>Task. We used jsPsych <ref type="bibr" target="#b64">(64)</ref> to conduct our study. Participants logged in and were told to imagine that they are inspecting a factory that produces phones. The factory produces phones one at a time and will then be inspected by the participant. Participants were told that the phone would wither be working on defective. Participants were told that they are asked to estimate the probability that the next phone will be a working phone (see <ref type="figure" target="#fig_1">Figure 2</ref>). After a single practice trial, participants completed 100 trials of the task. Participants were first presented with an inspection slide, depicting a factory and a phone with a "?" printed on it. Participants were to click a button labeled "Inspect" below the images without any time constraints. After clicking the "Inspect" button the phone with the "?" printed on it was revealed to either be working with a green check mark, or defective with a red "X". Participants were required to observe this feedback screen for 3 seconds before they could advance the page. On the following slide, participants were asked to respond on a slider scale from 0% to 100% what they believed the probability was that the next phone would be a working phone. Participants had to move the slider from its initial value (50%) in order to make their prediction. Participants were given as much time as they needed to make this judgment, but were required to wait 3 seconds before they could respond. This completed a trial and was repeated for a total 100 trials. A fixation cross was presented for 1 second between trials. After completing the task, participants were sent to a Qualtrics survey to fill in their demographics.</p><p>Measures. When participants completed the learning task, they were asked to estimate the probability that the next phone will be defected. After completing the task, participants filled out a TIPI 10-item personality measure (65) and a short demographics survey in which they were asked for their name, age, gender, race, ethnicity, first language, political affiliation, citizenship, nation of birth, annual income, and email address. See SI for full analysis of demographics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phase 2: Evaluating Decision Models by assuming the Quadratic Q-Weighed Model in existing datasets</head><p>Paper selection. We identified papers and datasets for reanalysis using the Niv Lab OpenData repository (https://nivlab.github.io/opendata/). Tags "2-arm bandit", "restless bandit", and "twostep" were considered. Criteria for reanalysis included (1) having freely accessible trial-level data, <ref type="bibr" target="#b1">(2)</ref> having freely accessible code for model fitting and analysis, (3) the use of a Rescorla-Wagner deltaupdating rule nested within the fitted model (4) and association with a published paper. Many datasets did not meet the criteria, narrowing our search to the following 9 datasets:</p><p>Kool et al., 2017 <ref type="bibr">Experiments 1 &amp; 2 (66)</ref>. Published in Psychological Science (https://osf.io/yg82m/).</p><p>The goal of this project was to examine whether people choose between model-free versus modelbased control based on a cost-benefit analysis. The task was based on the Daw two-step decision making task <ref type="bibr" target="#b67">(67)</ref>. Participants made a first choice between two spaceships (green or blue), each leading to two planets with different probabilities in each of the studies (red, or purple). In Study 1, the probability of getting to a certain planet with a certain ship was always 100%. In Study 2 the probability of getting to one of the two planets was always 70% for each spaceship. When they arrived to the planet participants met either one alien (Experiment 1) or chose one two aliens <ref type="table">(Experiment 2)</ref> who gave them a reward. Aliens were either in a good or a bad part of a mine and the probability of quality of their reward changed over time (drift rate in reward). In both studies, the researchers manipulated the size of the reward (stakes: 1 point or 5 points).  <ref type="bibr" target="#b57">(57)</ref>. Published in Nature Human Behavior. Each of these datasets and analysis code were acquired from a meta-analytic study, Palminteri, 2023(70) (https://github.com/spalminteri/conf-biasmeta-analysis). We followed the models of Palminteri, 2023 for reanalyzing each of these four datasets. Shared amongst the authors was an interest in the confirmation bias hypothesis, in which a person learns more from positive reinforcement that supports their preexisting biases than they do negative reinforcement disproving their beliefs. The tasks were all variants of a simple two-armed bandit. Participants chose between two alternatives presented as symbols and either received or did not receive reward. Each bandit had a predesignated probability of reward but in all tasks, participants observed the outcome of their chosen symbol, but received no information from the unchosen symbol. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Structure of learning task used in Studies 1 and 2. Participants inspected phones produced from an assembly line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>An overview of behavior of the Quadratic Q-Weighted model we discovered using empirical data with SINDy. The x-axes reflect reported Q value and the y-axes are the median change in value. Grey dots show binned Q into 10 discrete categories, each with a bin size of 0.1. Categories were labeled with the upper bound of each bin. Error bars are 95% confidence intervals. (A) Study 1 empirical change in Q following no reward. (B) Study 1 empirical change in Q following reward. (C) Study 2 empirical change in Q following no reward. (D) Study 2 empirical change in Q following reward. Predicted changes in Q according to the best fit Quadratic Q-Weighted model (solid red) and the best fit Rescorla-Wagner model (dashed blue) are overlaid.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Empirical changes in expectation Q as a function of Q's position relative to the stable point and reward (√ / ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Expected value estimates (Qt) over 100 trials for a single representative participant. The "Empirical" panel represents the participant's reported values (black lines), while the remaining panels depict predictions (red lines) from models: RW (Rescorla-Wagner), RW with exponential decay, RW with asymmetric learning rates, QQW (Quadratic Q-Weighted), and the Kalman Filter. Missing data correspond to trials where attention checks were administered. Although all models demonstrate a generally good fit to the observed data, the QQW model stands out with a superior fit.Having established theQuadratic Q-Weighted model's superior fit at both the group and individual levels, we next examined the distribution of individualized parameters to explore the extent of heterogeneity in participants' learning behavior. Beyond the superior group-level fit indicated by BIC, we also find at the individual-level that the Quadratic Q-Weighted model best fit 68.35% of participants in Study 1, and 64.41% in Study 2. Importantly, the a and b coefficients scaling the reward and Q terms ( +1 = − 2 ) were free to vary between participants in these fitted models. This revealed substantial heterogeneity amongst individuals around the group coefficient values discovered by SINDy: Study 1 mean a = 0.21 ± 0.18, Study 1 mean b = 0.45 ± 0.46; Study 2 mean a = 0.28 ± 0.19, Study 2 mean b = 0.61 ± 0.52. These findings suggest significant individual differences in how participants weigh recent rewards and adjust for previous estimates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Weighted</head><label></label><figDesc>model was robust to changes in initial reward probability and to varying levels of diffusion noise. However, the model's utility in tasks where reward probabilities remain static over time or where probabilities are more conservatively bounded has yet to be tested. Future studies could further evaluate the model under these conditions, such as the change-point detection studies conducted by Nassar and colleagues<ref type="bibr" target="#b58">(58,</ref><ref type="bibr" target="#b59">59)</ref>, where participants are asked to predict continuously varyingoutcomes. These tasks involve different reward structures that could help determine whether the nonlinearity identified in our model captures more general aspects of human learning, particularly under conditions of uncertainty and dynamically changing environments. Future research should extend the model to such decision-making problems and explore additional nonlinearities, such as exponential or logarithmic transformations. It is also important that future research consider edge cases. An important aspect of the Quadratic Q-Weighted model is its prediction of asymptotic behavior, particularly in situations where the model suggests an inherent bias in how individuals estimate extreme probabilities. Specifically, the model predicts that participants cannot estimate Q values beyond a certain stable point (√(a/b)), even in situations where the true reward probability is maximal (e.g., 1). This creates an opportunity for empirical validation, whereby edge cases can be specifically designed to test these predictions. For example, future experiments could involve a prolonged sequence of trials with a constant reward probability of 1 to determine if participants' estimates truly converge at the stable point predicted by the model or if they adaptively reach the true value. If participants are found to be limited by this predicted asymptotic bias, it would lend further support to the model's validity. Conversely, if participants adapt beyond the predicted stable point, it may indicate the need for further refinement of the model. Such empirical tests would help to identify the conditions under which the model captures or fails to capture human learning behavior and highlight the importance of understanding model limitations within different reinforcement learning environments. That said, we acknowledge that the model may fail to predict behavior under such rigid conditions. Although future studies have the potential to further validate the Quadratic Q-Weighted model, we suggest that the model's scope be interpreted with the constraints of the learning environment in mind. Overall, this study demonstrates the potential of bottom-up equation discovery methods, such as SINDy, to advance model development in the social sciences. The Quadratic Q-Weighted model provides key insights into human learning, uncovering systematic biases in probability estimation and generalizing across diverse datasets. By improving fit and influencing interpretations of prior studies, the model showcases the power of integrating non-linear dynamics into decision-making frameworks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>final sample of N = 455 (Men: 216, Women: 216, Other or refused to answer: 23; Age, M = 36.25, SD = 12.94).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Lefebvre et al., 2017 Experiments 1 &amp; 2 used probabilities 25%/75%, Chambon et al., 2020 Experiment 4 used 30%/70%, and Palminteri et al. Experiment 1 used 50%/50%, 25%/75%, and a 17%/83%. These probabilities reversed halfway through the task, depending on assignment to experimental conditions. Decker et al., 2016(71). Published in Psychological Science; Potter et al., 2017(72). Published in Developmental Cognitive Neuroscience; and Nussenbaum et al., 2020(73) Published in Collabra: Psychology. Each of these three datasets and analysis code were acquired from a reanalysis conducted by Nussenbaum et al., 2020 (https://osf.io/we89v/). The authors all investigated the emergence of model-based control across development, using the classic version of the Two-Step task as a propensity measure of model-based control. The task was identical to the version used in Kool et al., 2017 Experiment 2, without manipulating the size of reward. Data and Code Availability All simulation and empirical data are available on the Open Science Framework here: https://osf.io/aeujf/?view_only=88b2b75499f54a3895502fc353f4d244. All analysis scripts and modeling code are available on Github here: https://github.com/GoldenbergLab/analysis-rl-sindykyle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure 2 illustrates why the Quadratic Q-Weighted model implies such over/under estimation, showing the change in Q as a function of either reward or no-reward and as dependent on previous Q (see SI for a proof of this point of under-to-over estimation). For low values of Q, the change in Q in</figDesc><table><row><cell>the Quadratic Q-Weighted model is positively shifted both for reward and no reward compared to</cell></row><row><cell>classic Rescorla-Wagner when Q values are low. Conversely, for high values of Q, the change in Q in</cell></row><row><cell>the Quadratic Q-Weighted model is negatively shifted both for reward and no reward compared to</cell></row><row><cell>classic Rescorla-Wagner when Q values are high. Since the Rescorla-Wagner model asymptotically</cell></row><row><cell>always converges to the true probability for any learning rate (44), the shifts shown in</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>results from above the stable point to zero. Our model also included a random variable of participant id. Starting with the intercept of the model, which compared the above the stable point results to zero, results suggested that in both Study 1 and Study 2, when received a reward and when they were above</figDesc><table><row><cell>the stable point, participants significantly lowered their estimation of Q (Figure 3 Orange bar</cell></row><row><cell>compared to 0; Study 1: b=-0.167, p&lt;0.001; Study 2: b=-0.085, p&lt;0.001). These results would not</cell></row><row><cell>have been seen if participants were using a classical Rescorla-Wagner model in which participants</cell></row><row><cell>always increase their estimation of Q following a reward. Similar results were found in cases where</cell></row><row><cell>there was no reward, such that when above the stable point, participants also significantly lowered</cell></row><row><cell>their estimation of Q (Figure 3 Orange bar compared to 0; Study 1: b=-0.291, p&lt;0.001; Study 2: b=-</cell></row><row><cell>0.328, p&lt;0.001). These results should be expected, as both in our model and in a classic Rescorla</cell></row><row><cell>Wagner model, participants would lower their estimation of Q following a no-reward. Having</cell></row><row><cell>established this difference from zero, results also suggested that in all cases, there was a significant</cell></row></table><note>difference in change in Q as a function of whether the previous Q was above or below the stable point (Study 1 Rewarded: b=0.320, p&lt;0.001; Study 1 Unrewarded: b=0.341, p&lt;0.001; Study 2 Rewarded: b=0.223, p&lt;0.001; Study 2 Unrewarded: b=0.337, p&lt;0.001). These results are congruent with Rescorla-Wagner.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Evaluating Decision Models by assuming the Quadratic Q-Weighed Model in existing datasetsLimitations and Future Directions We</head><label></label><figDesc>To further probe this variability, we allowed the exponent on Q to vary freely as an exploratory follow-up. This adjustment improved the model fit for 61.1% of participants in Study 1 and 77.96% in Study 2, indicating that the fixed exponent of 2 used in the original Quadratic Q-Weighted model does not fully capture all individual differences. These individualized exponents were estimated to be on average 1.52 ± 0.76 in Study 1 and 1.43 ± 0.81 in Study 2, indicating a high degree of variability amongst individuals in how they update expectations.After finding the Quadratic Q-Weighted model with empirical data, we aimed to demonstrate its value by reanalyzing prior studies of choice behavior. Our goal was to determine whether the Quadratic Q-Weighted model provided a better account of learning in decision-making tasks than does the Rescorla-Wagner model. The vast majority of decision-making tasks do not probe estimates of probability overtly; they instead ask participants to act on implicit learned probabilities by selecting between two or more alternatives. Researchers are often most interested in the elements governing these selections, such as explore-exploit tendencies and stochasticity. However, because it is assumed that selection depends on one's estimates of reward probability, it is critical that researchers assume a learning model that best captures those estimates and their dynamics. To this end, we reanalyzed open datasets sourced from nine papers published in leading academic journals, each using the Rescorla-Wagner updating rule nested within larger decision models, with the goal of replacing that rule with our Quadratic Q-Weighted model. In each of the datasets, we used the authors' original analysis scripts for model fitting (See SI for details). To compare the authors' model and our variation with the Quadratic Q-Weighted model as a learning rule, we modified the original authors' scripts to fit a variation of their model using the general form of the Quadratic Q-Weighted model in place of Rescorla-Wagner. Notice that the model produced by SINDy in the empirical phase had a specific coefficient value for each term. In these analyses we allowed those coefficients to vary freely between subjects, as is common in the field.To compare the model that was used in each paper to our Quadratic Q-Weighted we calculated the Bayesian information criterions (BIC) of both models using the summed likelihood estimates of each participant's data. BIC was chosen due to its consistency in identifying parsimonious yet wellfitting models by penalizing more heavily for superfluous parameterization. Likewise, BIC was used by all authors of the selected datasets. In all but one dataset, the model using Quadratic Q-Weighted learning rule outperformed the original best model(Table 1). Beyond fit, models using the Quadratic Q-Weighted learning rule may provide downstream benefits to understanding processes of decision-making. For example, one dataset in particular, Kool et al., 2017 Experiment 2, SINDy's yielded decision-making parameter estimates that diverged from the authors' main findings. In their 2017 article, Kool and colleagues proposed that arbitration between model-based (MB) and model-free (MF) learning systems involves a cost-benefit analysis. The MB system, which plans towards goals, is more accurate but computationally demanding, whereas the MF system relies on habits and is computationally efficient but less flexible. Kool et al. suggested that people decide which system to use by weighing the benefits of the MB system's accuracy against its cognitive cost. This implies that MB control is employed when its benefits (in terms of reward) outweigh the costs (in terms of cognitive effort). The most common method for measuring individual difference in this cost-benefit analysis is with the Two-Step Task (Daw et al., 2011), a complex, multi-step decision-making task. Despite this, Kool et al. demonstrated in an earlier paper (Kool et al., 2016) that there exists no cost-benefitrelationship between model-based vs. model-free strategy and performance on the task, and remediate this with a novel version of the task. To explore this further, they tested the effect of monetary stakes on strategy use in the original task, positing that high stakes should fail to yield increased MB control They found that there was no difference in MB control between high and low stakes on the original version of the task (Experiment 2; t(99)=0.4132, p=0.6804). In interpreting these findings, the authors suggest that participants might have a prior belief that MB control is generally associated with higher rewards, driven by real-world experiences where MB control is usually beneficial. This belief, reinforced by training, led participants to maintain a mix of MB and MF strategies. This is because high stakes can be stressful and impose cognitive load. MB control is costlier, despite it being equally as effective in this case, and the cognitive effort required to use MB control could be too demanding in high stakes situations. It is possible that parameter estimates could be improved and better reflect our hypothesized effect if a novel learning model were fit to the data which better reflects peoples' true learning. To test this, we modified the fitted dual systems RL model to instead use the Quadratic Q-Weighted model discovered by SINDy in our empirical studies. We found that our version of the dualsystems model with the Quadratic Q-Weighted model as a learning rule better fit Kool et al.'s Experiment 2 data (BICQQW=450.23) than the original dual systems RL model (BICRW=474.32). Note: BIC is Bayesian Information Criterion. Lower BIC reflects better model fit. Original BIC is for the model used by the authors of the dataset. Quadratic Q-weighted BIC is for the variation of those models using the Quadratic Q-Weighted model as a nested learning rule in place of the Rescorla-Wagner learning rule. Across multiple levels of analysis, what stands out as the most important feature of the Quadratic Q-Weighted model is its prediction that participants tend to overestimate low probabilities and underestimate high probabilities. This systematic bias could be reminiscent of a persistent prior in Bayesian inference (47, 48)). In Bayesian models, a prior represents the learner's initial beliefs about This bias exists even when expectations of reward are high and reward is received, such that expectations are predicted to decrease. This raises an interesting question about the cognitive processes underlying such behavior: are individuals relying on a heuristic that resembles the application of a prior, or is there an explicit internal representation akin to Bayesian updating? Future work could explore this connection further by comparing the performance of the Quadratic Q-Weighted model with explicit Bayesian models that incorporate a persistent prior. Additionally, empirical studies could manipulate participants' initial beliefs or expectations to determine whether similar biases are observed, thereby testing whether the quadratic form is indeed capturing the influence of a persistent prior While the current work focused on model development within RL, we envision many exciting new directions for model development in various social domains. Many subdomains in social sciencesare still utilizing existing top-down models and these models can potentially be improved while maintaining interpretability. For example, models of social contagion, such the SIR epidemic models acknowledge several limitations in using SINDy for model discovery in social science. First, our implementation is at present limited to modeling directly observable data. Across our empirical studies, Q-value was an explicit variable. In many RL experiments, expected value is a latent variable that is estimated from directly observable decisions<ref type="bibr" target="#b47">(47,</ref><ref type="bibr" target="#b55">55)</ref>. Other models could include these latent variables, such as for uncertainty in expectations, which could potentially improve their quality in terms of predictability and generalizability. Despite these limitations, the approach we adopted here has the potential to change how models are developed in the social science.A second limitation is that the SINDy algorithm is bounded by the specific decisions made in its implementation, such as the list of candidate functions and hyperparameters that govern the discovered model's sparsity (and hence control over its complexity). These decisions, as well as the indication of whether the discovered model is suitable, are subjective. Therefore, it is possible that there may exist other alternative models which could be better fitting. For example, the present study omitted candidate functions of continuous time. Although our discovered Quadratic Q-Weighted model provides a novel perspective on probability weighting, it departs from the broader theoretical basis of RL models like Temporal Difference (TD) learning<ref type="bibr" target="#b1">(2)</ref>, which can be applied in real-time and have demonstrated strong links to learning processes in the brain<ref type="bibr" target="#b44">(44,</ref><ref type="bibr" target="#b56">56)</ref>. The quadratic transform used here, although beneficial for capturing nonlinearity in probability estimates, does not provide the same foundation for understanding learning as a general, time-continuous process. However, it may be possible to incorporate the discovered nonlinearity within a TD learning framework. Specifically, future work could modify the TD update equations to include a transformed value function, such as f(V)=V+βV2, allowing us to retain the incremental, time-based learning properties of TD while introducing systematic biases that capture non-linearities in human learning behavior. This would create a hybrid model that not only improves predictive performance but also preserves the dynamic learning structure of TD, potentially bridging these two perspectives effectively.A third limitation of this study is that the model that was discovered by SINDy was based on a relatively narrow empirical task. Although the Quadratic Q-Weighted model showed excellent generalizability in predicting behavior across two new empirical studies and eight of nine reanalyzed datasets, its broader applicability requires further exploration. One notable exception to the Quadratic Q-Weighted model's superior performance was observed in a go/no-go dataset<ref type="bibr" target="#b57">(57)</ref>, where the Rescorla-Wagner model provided a better fit to the underlying learning process. We note that this dataset's structure-featuring a large number of trials per participant (N=600) but a small number of participants (N=20)-may have reduced its ability to robustly differentiate between models. However, the unique demands of go/no-go tasks, which rely heavily on inhibitory control, may inherently favor Weighted model captures well. Moreover, the candidate features that we provided to SINDy for modeling learning in forced-choice tasks may not adequately capture learning dynamics unique to go/no-go tasks. These findings may suggest that tailoring candidate functions to task-specific dynamics is crucial for improving the generalizability and performance of discovered models.</figDesc><table><row><cell></cell><cell>Original BIC</cell><cell>Quadratic Q-Weighted BIC</cell></row><row><cell>Potter et al. 2017</cell><cell>25784.64</cell><cell>25373.13</cell></row><row><cell cols="3">Quadratic Q-Weighted BIC 62360.65 the probability distribution of an outcome. If individuals maintain a strong prior centered around a Nussenbaum et al. 2020 63378.57 moderate probability value (e.g., 0.5) and continue to apply this prior across multiple learning trials, it will naturally lead to a pattern where extreme probabilities are systematically pulled toward the center-low probabilities are overestimated, and high probabilities are underestimated. This behavior observe this in both our first empirical study where all reward probabilities start at 0.5, thereby encouraging the integration of this prior, and in our second empirical study where starting probabilities vary. (49), which already benefit from further development using tools such as SINDy (19), can also be tested in explaining social interaction and contagion. Other domains such as decision making (50), Phase 2: Original BIC is qualitatively similar to the effects captured by our model's quadratic weighting term. And we planning (51), norm formation (52), affect (53) and many others all have models that are constantly</cell></row><row><cell>Kool et al. 2017 Experiment 1</cell><cell>461.35</cell><cell>458.47</cell></row><row><cell>Kool et al. 2017 Experiment 2</cell><cell>474.32</cell><cell>450.23</cell></row><row><cell>Lefebvre et al. 2017 Experiment 1</cell><cell>3857.55</cell><cell>3806.44</cell></row><row><cell>Lefebvre et al. 2017 Experiment 2</cell><cell>2512.77</cell><cell>2496.62</cell></row><row><cell>Palminteri et al. 2017 Experiment 1</cell><cell>3206.48</cell><cell>3199.18</cell></row><row><cell>Chambon et al. 2020 Experiment 4</cell><cell>10987.38</cell><cell>10997.49</cell></row><row><cell>Decker et al. 2016</cell><cell>37463.96</cell><cell>36956.91</cell></row></table><note>when it provides no advantage They tested this by fitting a dual-systems RL model to their data (Daw et al., 2011). This RL model includes three separate Rescorla-Wagner updating rules for changing participants' expectations of reward followed by choosing specific spaceships and aliens.We disagreed with this conclusion: If MB control is no better than MF on the original version of the task, participants should use MB control less than MF under high stakes.Furthermore, we observed that the fitted free parameters for the MB weight in high stakes was indeed significantly less than the MB weight in low stakes (t(99)=2.9303, p=0.0042), supporting our hypothesis. Table 1. Model fits from each reanalyzed datasets using original authors' models and variations replacing Rescorla-Wagner learning rules with the Quadratic Q-Weighted model.Discussion In this work we demonstrated that bottom-up equation discovery algorithms can be used for model development in social sciences. We collected empirical data in two variations of a learning task and used SINDy to develop an appropriate model for participants' behavior. This novel model -the Quadratic Q-Weighted model -provided new insights into human learning and accounts for several interesting behavioral phenomena. Most importantly, the model introduces a tendency over the long term to underestimate Q values when true reward rates are high and overestimate Q values and true reward rates are low. Finally, we nested the Quadratic Q-Weighted model within existing, more complex decision models used by the authors of nine published datasets. These models notably were of decisions made on complex decision-making tasks, entirely different from our probability estimation task. We found that the new models using our Quadratic Q-Weighted model instead of the Rescorla- Wagner updating rule provided a better fit in eight out of nine of those cases compared to the models originally used by the authors. We further demonstrate that the Quadratic Q-Weighted model does more than simply improve fit; it impacted the conclusions and interpretation of a previous study of complex decision-making. These results provide a promising path for the use of the Quadratic Q- Weighted model, as well as the use of equation discovery algorithms to development of interpretable but more predictive computational models.The persistence of such a prior, even after observing evidence that should shift beliefs significantly, reflects a form of 'conservatism' in updating. Instead of fully integrating new information, individuals may effectively average it with their prior beliefs, leading to a systematic under-adjustment. This can explain why the observed estimates do not align perfectly with the objective probabilities but are instead biased toward intermediate values. In our model, the quadratic term captures these non-linearities in value estimation without explicitly invoking a Bayesian prior. However, the resulting behavior-where estimates of extreme probabilities are biased toward the middle-suggests that the quadratic transformation may implicitly represent the effect of a strong, persistent prior belief.being developed using top-down approaches, and these domains could potentially benefit from using equation discovery algorithms for model improvement and development. Finally, many domains in the social sciences involve analysis of longitudinal data, which is often analyzed using structural equation modeling or other tools that mostly test for linear processes(54). SINDy and other equation discovery tools are well suited to fit existing longitudinal data in order to uncover driving equations. It's important to note that we do not wish to eliminate hypothesis testing or theory-based models, but rather to expand the modeler's toolbox in considering alternative models for comparison and later confirmatory analyses, thus encouraging the discovery of novel, interpretable, predictive and generalizable models.simpler models like Rescorla-Wagner. Unlike the other datasets analyzed, the go/no-go task may not highlight the nuanced reward-probability interactions or asymptotic behaviors that the Quadratic Q-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>: Equation Recovery from Simulated Data</head><label></label><figDesc>To investigate the applicability of SINDy in recovering the governing equations of established reinforcement learning models, we generated synthetic data through simulations. We selected well-known reinforcement learning models -the Rescorla-Wagner model and variants -as the basis for generating the data. See SIfor details. Our simulated agents estimated the probability of reward as X. The history of reward and trial number were represented as separate columns in U. From these observations, we used SINDy to calculate X' as the matrix of discrete-time variables xk shifted xk+1. To ensure that SINDy's solution B was interpretable, we provided SINDy with the following matrix of</figDesc><table><row><cell cols="3">candidate functions:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">( , ) = [</cell><cell>2</cell><cell>2</cell><cell>*</cell><cell>*</cell><cell>*</cell><cell cols="2">1 + 100</cell><cell>− 30</cell><cell>− 20 ⋯ ]</cell></row><row><cell>[⋯</cell><cell>− 10</cell><cell>+ 100</cell><cell>*  − 30</cell><cell cols="2">*  − 20</cell><cell>*  − 10</cell><cell></cell><cell>+ 100</cell><cell>| − | | −</cell><cell>2 | ⋯ ]</cell></row><row><cell></cell><cell cols="2">[⋯  *  − 30</cell><cell>*  − 20</cell><cell>*  − 10</cell><cell></cell><cell>+ 100</cell><cell cols="2">*  − 30</cell><cell>*  − 20</cell><cell>*  − 10 ⋯ ]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Phase 1: Equation Discovery from Empirical Probability Estimates.</head><label></label><figDesc></figDesc><table /><note>Participants. All experiments received IRB approval from Harvard Business School (IRB22-0546) and</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Lefebvre et al., 2017 Experiments 1 &amp; 2(68). Published in Nature Human Behavior; Palminteri et al., 2017 Experiment 1(69). Published in PLOS Computational Biology; and Chambon et al., 2020 Experiment 4</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How computational modeling can force theory building in psychological science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Guest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspect Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="789" to="802" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">What is dopamine doing in model-based reinforcement learning? Current Opinion in Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Walton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="74" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The ubiquity of model-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Doll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1075" to="1081" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Believing in dopamine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Uchida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="703" to="714" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reinforcement learning in artificial and biological systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">O</forename><surname>Neftci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Averbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Mach Intell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="143" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reinforcement learning in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hoane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deep</forename><surname>Blue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="57" to="83" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Grandmaster level in StarCraft II using multi-agent reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">575</biblScope>
			<biblScope unit="page" from="350" to="354" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Von Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Morgenstern</surname></persName>
		</author>
		<title level="m">Theory of games and economic behavior</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On the possible psychophysical laws</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="81" to="95" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Prospect theory: An analysis of decision under risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="263" to="291" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reference-dependent risk sensitivity as rational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Denrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="461" to="484" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A meta-analytic review of two modes of learning and the description-experience gap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">U</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mergenthaler-Canseco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Bull</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="140" to="176" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The reversed description-experience gap: Disentangling sources of presentation format effects in risky choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glöckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Hilbig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Henninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fiedler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Gen</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="486" to="508" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A theory of Pavlovian conditioning : Variations in the effectiveness of reinforcement and nonreinforcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rescorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Classical Conditioning II: Current Research and Theory</title>
		<imprint>
			<publisher>Appleton-Century-Crofts</publisher>
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">What do reinforcement learning models measure? Interpreting model parameters in cognition and neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="128" to="137" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Algorithmic discovery of dynamic models from infectious disease data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Horrocks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Bauch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">7061</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pirrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Scientific Discovery in Psychology. Perspect Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="178" to="189" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Beyond playing 20 questions with nature: Integrative experiment design in the social and behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Almaatouq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<idno type="DOI">10.1017/S0140525X22002874</idno>
		<ptr target="https://doi.org/10.1017/S0140525X22002874" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using deep learning to predict human decisions and using cognitive models to explain deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Osadchy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">4736</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Integrating explanation and prediction in computational social science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hofman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">595</biblScope>
			<biblScope unit="page" from="181" to="188" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Automatic discovery of cognitive strategies with tiny recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ji-An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Benna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Mattar</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.04.12.536629v2</idno>
		<ptr target="https://www.biorxiv.org/content/10.1101/2023.04.12.536629v2" />
		<imprint>
			<date type="published" when="2023-07" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modelling human behavior in cognitive tasks with latent dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">I</forename><surname>Jaffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Bissett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="986" to="1000" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Extracting the dynamics of behavior in sensory decision-making experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="597" to="610" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Cognitive Model Discovery via Disentangled RNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.06.23.546250v1</idno>
		<ptr target="https://www.biorxiv.org/content/10.1101/2023.06.23.546250v1" />
		<imprint>
			<date type="published" when="2023-07" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scaling up psychology via Scientific Regret Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="8825" to="8835" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Automated reverse engineering of nonlinear dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bongard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="9943" to="9948" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distilling Free-Form Natural Laws from Experimental Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="81" to="85" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sparse identification of nonlinear dynamics for model predictive control in the low-data limit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">474</biblScope>
			<biblScope unit="page">20180335</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Model selection for dynamical systems via sparse regression and information criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Mangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Proctor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">473</biblScope>
			<biblScope unit="page">20170009</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Data-driven discovery of partial differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1602614</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Discovering governing equations from data by sparse identification of nonlinear dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="3932" to="3937" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Data-driven discovery of reduced plasma physics models from fully kinetic simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Alves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fiuza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">33192</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning Discrepancy Models From Experimental Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kaheman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Strom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1909.08574" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
	<note>Accessed</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sparse structural system identification method for nonlinear dynamic systems with hysteresis/inelastic behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nagarajaiah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mechanical Systems and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="813" to="842" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Sparse identification for nonlinear optical communication systems: SINO method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sorokina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sygletos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Turitsyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opt. Express, OE</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="30433" to="30443" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Inferring biological networks by sparse identification of nonlinear dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Mangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Kutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Molecular, Biological and Multi-Scale Communications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="52" to="63" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Equations of mind: Data science for inferring nonlinear dynamics of sociocognitive systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Bhat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Systems Research</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="275" to="290" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Reminders of past choices bias decisions for reward in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bornstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Khaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">15958</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cortical substrates for exploratory decisions in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">441</biblScope>
			<biblScope unit="page" from="876" to="879" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Uncertainty and exploration in a restless bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="351" to="367" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Temporal difference models and reward-related learning in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Critchley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="329" to="337" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stan: A probabilistic programming language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A simple model for learning in volatile environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1007963</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Bayesian theories of conditioning in a changing world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="294" to="300" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Brain networks for confidence weighting and hierarchical inference during probabilistic learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meyniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3859" to="3868" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A contribution to the mathematical theory of epidemics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">W</forename><surname>Kermack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Mckendrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<date type="published" when="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Using large-scale experiments and machine learning to discover theories of human decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Bourgin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reichman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="page" from="1209" to="1214" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">People construct simplified mental representations to plan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">606</biblScope>
			<biblScope unit="page" from="129" to="136" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The emergence of social norms and conventions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">X D</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Goldstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="158" to="169" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Tears and fears: Modeling emotions and emotional behaviors in synthetic agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gratch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marsella</surname></persName>
		</author>
		<idno type="DOI">10.1145/375735.376309</idno>
		<ptr target="https://doi.org/10.1145/375735.376309" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth international conference on Autonomous agents</title>
		<meeting>the fifth international conference on Autonomous agents</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="278" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Structural Equation Modeling: Reviewing the Basics and Moving Forward</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality assessment</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="35" to="50" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A unifying probabilistic view of associative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Temporal difference models describe higher-order learning in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">429</biblScope>
			<biblScope unit="page" from="664" to="667" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Information about action outcomes differentially affects learning from selfdetermined versus imposed choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chambon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1067" to="1079" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An Approximately Bayesian Delta-Rule Model Explains the Dynamics of Belief Updating in a Changing Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heasly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="12366" to="12378" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Rational regulation of learning dynamics by pupil-linked arousal systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1040" to="1046" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">PySINDy: A Python package for the Sparse Identification of Nonlinear Dynamics from Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Silva</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2004.08424" />
		<imprint>
			<date type="published" when="2023-07" />
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
	<note>Preprint] (2020). Available at</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">PySINDy: A comprehensive Python package for robust sparse system identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Kaptanoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSS</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">3994</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Sparse learning of stochastic dynamical equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boninsegna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nüske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clementi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">241723</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">On the psychophysical law</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="153" to="181" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">jsPsych: Enabling an open-source collaborative ecosystem of behavioral experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Luchterhandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">5351</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A very brief measure of the Big-Five personality domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gosling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Rentfrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Swann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="504" to="528" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Cushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1321" to="1333" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Model-Based Influences on Humans&apos; Choices and Striatal Prediction Errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="1204" to="1215" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Behavioural and neural characterization of optimistic reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meyniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bourgeois-Gironde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Kilford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-J</forename><surname>Blakemore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">1005684</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Choice-confirmation bias and gradual perseveration in human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral Neuroscience</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="78" to="88" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">From creatures of habit to goal-directed learners: Tracking the developmental emergence of model-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="848" to="858" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Cognitive components underpinning the development of model-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C S</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Bryce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="272" to="280" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Moving developmental research online: comparing in-lab and web-based studies of model-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nussenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scheuplein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Phaneuf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Collabra: Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">17213</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
