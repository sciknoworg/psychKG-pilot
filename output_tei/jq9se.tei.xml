<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Conversational User Interfaces: Explanations and Interactivity Positively Influence Advice Taking from Generative Artificial Intelligence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><forename type="middle">R</forename><surname>Rebholz</surname></persName>
							<email>tobias.rebholz@uni-tuebingen.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alena</forename><surname>Koop</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Hütter</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Psychology Department</orgName>
								<orgName type="institution">University of Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Psychology Department</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<addrLine>Schleichstr. 4</addrLine>
									<postCode>72076</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Conversational User Interfaces: Explanations and Interactivity Positively Influence Advice Taking from Generative Artificial Intelligence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tobias R. Rebholz: Conceptualization (lead), Data Curation, Formal Analysis (lead), Investigation (lead), Methodology (lead), Project Administration, Resources (supporting), Software (lead), Supervision, Validation, Visualization, Writing -Original Draft, Writing -Review &amp; Editing (lead)</term>
					<term>Alena Koop: Conceptualization (supporting), Formal Analysis (supporting), Investigation (supporting), Methodology (supporting), Resources (lead), Software (supporting), Writing -Review &amp; Editing (supporting)</term>
					<term>Mandy Hütter: Conceptualization (supporting), Funding acquisition, Writing -Review &amp; Editing (supporting) generative artificial intelligence, large language model, conversational user interface, advice taking, algorithm aversion</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Preregistration documents, materials, surveys, data, and analysis scripts are publicly available at the Open Science Framework repository (https://osf.io/v9je8). We have no known conflicts of interest to disclose.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELF-EXPLANATORY GENERATIVE AI 4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conversational User Interfaces: Explanations and Interactivity Positively Influence Advice</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Taking from Generative Artificial Intelligence</head><p>In 2016, the European Union enacted the General Data Protection Regulation (GDPR). A key aspect of this legislation is the implicit establishment of a "right to explanation," which mandates that people affected by augmented (i.e., algorithmically assisted) or fully automated judgment and decision-making processes have a right to be informed about the rationale behind them <ref type="bibr" target="#b55">(Selbst &amp; Powles, 2017)</ref>. This legislative move aimed to increase transparency and accountability in the deployment of artificial intelligence (AI) technologies, addressing growing concerns about their opacity and impact on individual rights and freedoms. Crucially, the advent of chatbots represents a notable evolution in this context. OpenAI's ChatGPT, Google's Gemini, Meta's LLaMA, or Anthropic's Claude by design live out the right to explanation. Their conversational user interfaces allow users to directly and interactively inquire about the reasoning behind the algorithmic output generated <ref type="bibr" target="#b8">(Bubeck et al., 2023)</ref>, underscoring the potential of generative AI (GenAI) systems to comply with regulatory requirements.</p><p>It is important to note that although these systems can generate responses that may seem like explanations, they are not explanations in the traditional sense. The generated responses often seem to align well with the underlying decision-making process, but they can also be completely unrelated and thus misleading. In fact, GenAI systems consistently make certain types of errors in certain domains, such as complex arithmetic operations <ref type="bibr" target="#b66">(Tuncer et al., 2023)</ref>.</p><p>Therefore, the ability of GenAI to provide explanations for its output is also often criticized for the risk of communicating falsities with high confidence (e.g., in education; <ref type="bibr" target="#b30">Johnson, 2023)</ref>.</p><p>While the inherent capabilities of chatbots to generate explanations for their behavior underscores the potential of GenAI systems to engage users in a dialogue about their outputs, SELF-EXPLANATORY GENERATIVE AI 5 they should not be mistaken for reliable explanations. Nevertheless, these systems can serve as a starting point for promoting a culture of transparency and informed user engagement in the digital ecosystem, provided their limitations are clearly communicated and understood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Advice Taking from Algorithms in the Age of Conversational GenAI</head><p>The limitations of traditional AI systems, such as their inability to adapt to changes in the decision-making environment <ref type="bibr" target="#b11">(Dawes, 1979)</ref> or to account for individual differences <ref type="bibr" target="#b26">(Grove &amp; Meehl, 1996)</ref>, were originally identified as the main cause of "algorithm aversion" <ref type="bibr" target="#b13">(Dietvorst et al., 2015)</ref>. This aversion is characterized by the tendency of individuals to prefer interacting with humans rather than algorithms, which reduces the utilization of often superior algorithmic output <ref type="bibr" target="#b42">(Mahmud et al., 2022;</ref><ref type="bibr" target="#b48">Prahl &amp; van Swol, 2017)</ref>. Essentially, the conversational style of contemporary large language models (LLMs) is almost indistinguishable from a natural human conversation (e.g., <ref type="bibr" target="#b39">Lee et al., 2020)</ref>. Therefore, there should be no reason to expect aversion against advanced chatbots-unless they can be easily debunked as such, despite their advanced communication capabilities. <ref type="bibr" target="#b42">Mahmud et al. (2022)</ref> define it as "general aversion" when, for instance, people have an innate distrust of algorithms regardless of how well they perform <ref type="bibr" target="#b45">(Önkal et al., 2009;</ref><ref type="bibr" target="#b48">Prahl &amp; van Swol, 2017)</ref>. Accordingly, the mere knowledge that one is interacting with an algorithm rather than another human can trigger aversive behavior, such as a reduced weighting of algorithmic advice (i.e., judgments made by an algorithmic agent).</p><p>For traditional AI systems, <ref type="bibr" target="#b41">Logg et al. (2019)</ref> found that users were more willing to rely on algorithmic advice than human judgments, including their own, when the algorithm's prior performance was not as transparent as in studies showing algorithm aversion. This "algorithm appreciation" was found across many judgment domains-subjective (e.g., music and dating) and objective (e.g., weight estimation)-for which advanced chatbots can be used as advisors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELF-EXPLANATORY GENERATIVE AI 6</head><p>Moreover, conversational user interfaces to GenAI have considerably increased the popularity of LLMs <ref type="bibr" target="#b75">(Xi et al., 2023)</ref>. Indeed, familiarity with a decision support system has been identified as an important reason for people's increased willingness to rely on it <ref type="bibr" target="#b33">(Komiak &amp; Benbasat, 2006;</ref><ref type="bibr" target="#b43">Mahmud et al., 2024)</ref>. Therefore, research on the appreciation of LLM-generated advice is rapidly gaining importance.</p><p>In summary, we argue that conversational user interfaces constitute a promising tool for counteracting algorithm aversion and promoting algorithm appreciation, thereby enabling the utilization of often superior algorithmic output. Thus, our aim here is to investigate the tension between algorithm aversion and algorithm appreciation in interactions with GenAI that uses a natural style of conversation. To this end, by experimentally manipulating participants'</p><p>interactions with ChatGPT as the most popular LLM, we test the influence of two critical design features of conversational user interfaces on advice taking from algorithms. Specifically, we systematically vary the levels of explanation and interactivity with a GenAI capable of providing advice, along with explanations of the underlying rationale, to examine their effects on the utilization of its output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Interplay of Explanations and Interactivity</head><p>We argue that it is the combination of explanations and interactivity that underpins the widespread popularity and impact of contemporary GenAI systems. Providing explanations increases the transparency of the algorithmic judgment and decision-making process <ref type="bibr" target="#b46">(Papamichail, 2003)</ref>. Furthermore, the disclosure of intermediate steps makes algorithmic reasoning more understandable and cognitively accessible <ref type="bibr" target="#b67">(van Dongen &amp; van Maanen, 2013)</ref>.</p><p>As a consequence, explanatory algorithms are perceived as more trustworthy, leading to higher levels of stated trust in <ref type="bibr" target="#b21">Goodwin et al. (2013)</ref>, and their advice is weighted more strongly, SELF-EXPLANATORY GENERATIVE AI 7 especially when the accompanying explanations convey higher informational value <ref type="bibr" target="#b19">(Gönül et al., 2006)</ref>. Therefore, we expect that advice from a GenAI provided along with an explanation is weighted more strongly than the same advice presented without additional details about the underlying rationale (Hypothesis 1).</p><p>Recommender systems that are designed to appear more human-like (e.g., voice, visual appearance) have been found to increase user trust and usage intention <ref type="bibr" target="#b50">(Qiu &amp; Benbasat, 2009)</ref>.</p><p>The opportunity to interactively engage with an algorithm is an anthropomorphic feature of a system that enhances users' trust calibration and satisfies their desire for control <ref type="bibr" target="#b67">(van Dongen &amp; van Maanen, 2013</ref>; see also <ref type="bibr">Westphal et al., 2023, on control)</ref>. Essentially, the responsibility associated with higher levels of controllability of an algorithm's behavior has been found to increase users' willingness to rely on its output <ref type="bibr" target="#b14">(Dietvorst et al., 2018)</ref>. Therefore, we expect that algorithmic advice is weighted more strongly when users have the opportunity to actively interact with the GenAI providing the advice, compared to situations where interactivity is not possible (Hypothesis 2).</p><p>In the case of an opportunity to interact that allows users to request further information, interactivity can also be understood as a cue to reasoning capabilities. In this sense, the ability to provide explanations can be considered equivalent to the ability to provide arguments for one's position, which is a common feature of conversation across cultures <ref type="bibr" target="#b44">(Mercier &amp; Sperber, 2017)</ref>.</p><p>Therefore, we expect that actively requested optional explanations for algorithmic advice are most effective in enhancing its informational influence on users, and thus are associated with the highest weight of algorithmic advice relative to explanations that are provided by default, optional explanations that are not requested, or neither mandatory nor optional explanations SELF-EXPLANATORY GENERATIVE AI 8 (Hypothesis 3). There are two reasons for our expectation, depending on the explanation versus interactivity perspective, as discussed in the following.</p><p>Information asymmetry occurs when one party has more or better information than the other party <ref type="bibr" target="#b29">(Hütter &amp; Ache, 2016;</ref><ref type="bibr" target="#b67">van Dongen &amp; van Maanen, 2013;</ref><ref type="bibr" target="#b77">Yaniv, 2004;</ref><ref type="bibr" target="#b79">Yaniv &amp; Kleinberger, 2000)</ref>. By providing information upon request, parties can reduce information asymmetry, signaling their willingness to be open and transparent. Therefore, the algorithmic judgment and decision-making process should be perceived as more transparent if the algorithm is willing-in the sense of the deliberately programmed capability-to reveal additional details upon request, rather than providing them by default. Consequently, explanations that are provided upon the user's individual request should have a stronger effect on advice weighting than explanations that are provided by default (Hypothesis 3a).</p><p>Although the mere opportunity to request an explanation might satisfy users' core desire for control, the salience of influencing an algorithm's behavior is greater when an explanation is actively requested than when it is provided by default. In <ref type="bibr" target="#b14">Dietvorst et al. (2018)</ref>, marginal amounts of control over an algorithm's behavior were shown to reduce algorithm aversion.</p><p>Furthermore, the opportunity to interact is of little consequence in terms of building trust through explanation if it is not used to request an explanation from the algorithm <ref type="bibr" target="#b21">(Goodwin et al., 2013)</ref>.</p><p>Consequently, the opportunity to request an explanation should have a stronger effect on advice weighting when it is used than when it is forgone (Hypothesis 3b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>In a judge-advisor system (JAS; <ref type="bibr" target="#b58">Sniezek &amp; Buckley, 1995)</ref>, 472 participants solved a series of ten estimation tasks with access to pre-generated output from ChatGPT as advice. We report how we determined our sample size, all data exclusions (if any), all manipulations, and all SELF-EXPLANATORY GENERATIVE AI 9 measures. The experiment was preregistered and unless stated otherwise, the sample size, manipulations, measures, data exclusions, and analyses adhere to the preregistration. A significance level of 5% was used for statistical testing. Preregistration documents, materials, surveys, data, and analysis scripts are publicly available at the Open Science Framework repository (https://osf.io/v9je8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>Our experiment implemented three between-subjects conditions with repeated measures.</p><p>Participants in the control condition (n = 119) did not have the opportunity to interactively engage with ChatGPT and received no explanation of the assumptions and calculations it made.</p><p>They only received the numerical output generated by the GenAI as advice for a given stimulus item. In the two treatment conditions, participants also received this numerical output as advice.</p><p>However, in the mandatory explanation condition (n = 118), participants additionally received a detailed explanation of how ChatGPT formed its judgments by default. That is, participants in this condition also did not have the opportunity to interactively engage with ChatGPT, but were provided with an explanation of the assumptions and calculations it made. In the optional explanation condition (n = 235), by contrast, participants could voluntarily request this explanation on a trial-by-trial basis. As preregistered, we recruited about twice as many participants in this condition to achieve a roughly balanced number of participants in each of the four resulting groups. In fact, participants in the optional explanation condition self-selected into the optional explanation requested group on 1730 out of 2350 (73.62%) trials by making use of their opportunity to interactively engage with ChatGPT to request additional explanations on a given trial, whereas the remaining trials (i.e., 26.38%) formed the optional explanation forgone group. Thus, the amount of interactive engagement with ChatGPT was relatively high compared SELF-EXPLANATORY GENERATIVE AI 10 to requests for additional explanations from rule-based or expert systems (see <ref type="bibr" target="#b25">Gregor &amp; Benbasat, 1999</ref>, for a review).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>In another dataset from our lab, detailed explanations of the specific workings of an algorithm in a numerical judgment and advice taking task significantly increased participants' weighting of algorithmic advice relative to more abstract descriptions of the same algorithm in the other three conditions <ref type="bibr" target="#b52">(Rebholz, 2024)</ref>. Treating this as a proxy for advice taking from a GenAI that provides explanations of its underlying rationale, we used the effect size from this study (Cohen's d = 0.29; Judd et al., 2017) for our power simulation using the R package simr <ref type="bibr" target="#b23">(Green &amp; MacLeod, 2016)</ref>. Based on 1,000 iterations, sufficient power (95% confidence that 1β ≥ 0.80) required the collection of data from at least 452 participants. Recruitment via the general mailing list of the University of Tübingen over seven full days in July 2023, as preregistered, resulted in a final sample of size N = 472 (313 female, 154 male, 5 diverse). The median age of our participants was 23 years (IQR = 4.25).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head><p>Participants solved a series of ten Fermi problems, which are simple numerical judgment or order-of-magnitude estimation tasks. For instance, they were asked to estimate the total number of hours of schooling completed by German high school graduates, or how many days it would take to walk around the equator. The key to solving Fermi problems is to break the question down into simpler, more tangible parts, make reasonable assumptions, and then perform often simple calculations to arrive at plausible estimates <ref type="bibr" target="#b0">(Ärlebäck, 2009;</ref><ref type="bibr" target="#b16">Edge &amp; Dirks, 1983</ref>).</p><p>In the second example from above, one would need to know or guess the length of the equator, make an assumption about the average walking speed, possibly reduced by reasonable maximum SELF-EXPLANATORY GENERATIVE AI 11 daily walking times and full days of rest in regular sequences, to arrive at a plausible estimate of the total walking time along the equator.</p><p>Advice and explanations for each estimation task were pre-generated using OpenAI's gpt-3.5-turbo model. We used their development platform to be able to control parameters of the model that were critical to our application. In particular, the temperature parameter controls the degree of randomness in the LLM's output. A higher temperature results in a more varied output, in the sense that the model generates a different response each time it is prompted in exactly the same way, whereas a lower value results in a more deterministic output. By setting the temperature to zero, our goal was to minimize randomness and thereby ensure more realistic estimates for the Fermi problems presented to participants as advice. In addition, we used a standardized script for prompting the LLM to solve each Fermi problem. The model was asked to solve a particular problem step-by-step and to produce a concrete value as an estimate at the end. This is because chain-of-thought prompts have been shown to improve the reasoning capabilities of LLMs <ref type="bibr" target="#b72">(Wei et al., 2022;</ref><ref type="bibr" target="#b80">P. Zhang, 2023)</ref>. More details on how the stimulus items were created can be found in the Materials folder of the online repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>The experiment, with a median duration of 10.27 minutes (IQR = 6.70), was conducted online using SoSci Survey <ref type="bibr" target="#b40">(Leiner, 2021)</ref>. After entering the study and giving their informed consent to participate, participants were first asked to rate their experience with numerical estimation tasks (M = 1.77, SD = 0.91) and with using ChatGPT (M = 1.61, SD = 1.24) on 5point Likert scales ranging from 0 ("no experience") to 4 ("much experience"). They were then informed of their task, which was to solve a series of ten estimation tasks following a typical JAS procedure. That is, participants were instructed to make an independent initial judgment in the SELF-EXPLANATORY GENERATIVE AI 12 first estimation phase of a trial, and that they would have access to advice from ChatGPT in the second estimation phase. We tried to closely simulate real interactions with ChatGPT by presenting user prompts, advice, and explanations as screenshots in the original layout (see the Survey folder of the online repository for an example). Participants in the optional explanation condition were also informed that they could voluntarily request additional explanations from ChatGPT for its advice. On trials in which they pressed a button to "request an explanation for this estimate," they also received ChatGPT's rationale for its advice. After providing two integer estimates for all ten Fermi problems, participants were asked for their demographic information and could provide their contact information to voluntarily enter a raffle for 20 vouchers from a German bookstore chain, worth 10 € each. At the end of the experiment, participants were fully debriefed and thanked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures</head><p>Our main dependent variable was <ref type="bibr" target="#b28">Harvey and Fischer's (1997)</ref> weight of advice <ref type="bibr">(WOA)</ref> index, which is calculated as the ratio of the distance between participants' final and initial judgments to the distance between ChatGPT's advice and participants' initial judgment.</p><p>Accordingly, a WOA of zero indicates complete disregard of ChatGPT's advice, a value of one indicates complete adoption of the advice, and everything in between and outside this interval represents a corresponding weighted linear combination of ChatGPT's advice and the participants' own initial estimates. Outliers of WOA were excluded based on <ref type="bibr" target="#b65">Tukey's (1977)</ref> fences. That is, we removed trials on which the WOA fell below the 25th percentile or exceeded the 75th percentile by more than 1.5 times the interquartile range of the entire WOA distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELF-EXPLANATORY GENERATIVE AI 13</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Analysis</head><p>As preregistered, we conducted a multilevel regression analysis using R Version 4.3.1 (R Core Team, 2023), and the packages lme4 <ref type="bibr" target="#b6">(Bates et al., 2015)</ref> and lmerTest <ref type="bibr" target="#b37">(Kuznetsova et al., 2017)</ref>. WOA was used as the dependent variable, and random intercepts for participants and stimulus items were included to account for repeated measures, specifically variation in advice taking across participants and differences in item difficulty, respectively. To experimentally investigate the effects of explanation and interactivity on participants' utilization of ChatGPT advice, the model included fixed effects of explanation (contrast-coded as -0.5 for not provided and 0.5 for provided) and interactivity (contrast-coded as -0.5 for not possible and 0.5 for possible), as well as the interaction term of the two treatment factors. Thus, the intercept of the regression model provided an estimate of the unweighted grand mean across conditions, the first fixed effect measured the main effect of explanations, the second fixed effect measured the main effect of the opportunity to interactively engage with ChatGPT, and the interaction term measured the additional contribution of interactively requested explanations over and above the sum of the two main effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As shown in the bar chart of mean WOA (93 out of 4720, or 1.97%, outliers excluded) in <ref type="figure" target="#fig_0">Figure 1</ref>, the mean weighting of algorithmic advice was descriptively highest on trials where optional explanations were requested (M = 0.68, SD = 0.41). Advice taking was reduced on trials where optional explanations were forgone (M = 0.66, SD = 0.42), as well as in the mandatory explanations group (M = 0.66, SD = 0.43). However, the lowest WOA was observed in the control group (M = 0.58, SD = 0.40). Thus, there was descriptive evidence for all three hypotheses. <ref type="figure">Figure 2</ref> shows the characteristic distributions of WOA, which, reminiscent of a W-shape <ref type="bibr" target="#b60">(Soll &amp; Larrick, 2009)</ref>, have three modes at complete disregard of ChatGPT's advice (WOA = 0), unweighted averaging of the advice and the participants' own initial judgment (WOA = 0.5), and complete adoption of the advice (WOA = 1). However, the distributions were slightly more left-skewed than in traditional JAS studies (overall pooled meta-analytic WOA = 0.39; <ref type="bibr" target="#b2">Bailey et al., 2022)</ref>, indicating relatively high advice taking from ChatGPT. Notably, the proportions of complete disregard and unweighted averaging were substantially higher in the control group than in all other conditions. Whereas there were no striking differences between the remaining three conditions for the two modes with lower levels of advice taking, the proportions of complete adoption appear to be the main driver of the quantitative differences at the aggregate level  <ref type="bibr" target="#b65">Tukey's (1977)</ref> fences.</p><p>SELF-EXPLANATORY GENERATIVE AI 15 reported above. In particular, advice provided with mandatory explanations and without optional explanations was completely adopted more frequently than advice in the control condition, but the proportions of complete adoption were also substantially lower than for the interaction opportunity used to request a detailed explanation of the underlying rationale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confirmatory Multilevel Modeling</head><p>The full multilevel regression model with WOA as the dependent variable and fixed effects of explanation, interactivity, and their interaction is summarized in <ref type="table" target="#tab_0">Table 1</ref>. As indicated by the estimate of the intercept, the weighting of ChatGPT's advice was relatively high on average across all conditions in our study (d = 1.55; <ref type="bibr" target="#b31">Judd et al., 2017)</ref>. More importantly, consistent with Hypothesis 1, we found that participants weighted algorithmic advice</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>Distributions of Weight of Advice (WOA) per Explanation and Interactivity Group Note. Gaussian kernel density plots with the bandwidth chosen according to <ref type="bibr">Silverman's (1986)</ref> rule of thumb. Outliers of WOA are excluded based on <ref type="bibr" target="#b65">Tukey's (1977)</ref> fences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELF-EXPLANATORY GENERATIVE AI</head><p>16 significantly more strongly when it was accompanied by an explanation (d = 0.15), regardless of whether these explanations were provided by default or actively requested. Consistent with Hypothesis 2, interactivity significantly increased participants' WOA (d = 0.11), regardless of whether these opportunities to interactively engage with ChatGPT were actually used or not. For Hypothesis 3, there was no evidence for an interaction effect of explanation and interactivity (d = participants S and M = 10 stimulus items T resulted in a total number of 4627 observations after excluding outliers based on <ref type="bibr" target="#b65">Tukey's (1977)</ref> fences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELF-EXPLANATORY GENERATIVE AI</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>17</head><p>-0.07). That is, actual interactive engagement to request an explanation did not additionally increase WOA beyond the additive effects of explanation and interactivity individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exploratory Analyses</head><p>As the negative interaction term is descriptively smaller in absolute terms than either of the two main effects, it suggests a small increase in the weighting of advice provided along with actively requested optional explanations. In other words, the net effect of the combination of the two treatment factors was indeed positive, as expected (see also <ref type="figure" target="#fig_0">Figure 1</ref>). According to post hoc linear hypothesis testing using the R package car <ref type="bibr" target="#b18">(Fox &amp; Weisberg, 2019)</ref>, there was no evidence for Hypothesis 3a, or an increase in WOA for actively requested explanations over explanations provided by default, binteractivity + 0.5 * bexplanation × interactivity = 0.03, χ 2 (1) = 1.47, p = .226. That is, there was no evidence for a differential weighting of advice provided with optional versus mandatory explanations. In contrast, there was evidence for Hypothesis 3b, that is, for a significant increase in WOA for actually making use of the interaction opportunity compared to not making use of it, bexplanation + 0.5 * bexplanation × interactivity = 0.05, χ 2 (1) = 4.79, p = .029.</p><p>Apparently, the mere possibility of interactive engagement was not as valuable in terms of higher WOA as actually making use of it to receive additional explanations.</p><p>The random intercept for the stimulus items indicated considerable variation in participants' advice taking for different Fermi problems. Therefore, we also included random slopes of explanation to examine whether the observed item-wise variance in WOA could be attributed to the corresponding explanations provided <ref type="table" target="#tab_0">(Table A1</ref>). According to likelihood ratio testing, our data were significantly better explained by this extended model than by the preregistered one without random slopes, χ 2 (4) = 37.44, p &lt; .001. Moreover, the conditional modes of the random item slopes revealed systematic variations in the item-specific effects of SELF-EXPLANATORY GENERATIVE AI 18 explanation on WOA. Post hoc examination of the stimulus items revealed that the largest and, according to the 95% CI of the dot plots shown in <ref type="figure">Figure 3</ref>, only significantly negative effects on WOA were observed for the two items for which ChatGPT's explanations indicated a deficient quality of the generated advice (i.e., unrealistic assumptions, such as for the space occupied by a person in item number 10, or incorrect calculations, such as a missing trailing zero in item number 5; see <ref type="table" target="#tab_0">Table S1</ref> in the supplementary material of the online repository). This finding suggests that participants were also appropriately sensitive to inaccuracies and falsities in the generated explanations. Nevertheless, the mean WOA for these two items was still relatively high and significantly positive, M3 = 0.67, SD3 = 0.39, t(465) = 37.42, p &lt; .001, and M4 = 0.52, SD3 = 0.48, t(456) = 23.32, p &lt; .001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3</head><p>Conditional Modes of Item Random Slopes of Explanation in the Extended Model of <ref type="table" target="#tab_0">Table A1</ref> Note. Error bars show the 95% CI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELF-EXPLANATORY GENERATIVE AI 19</head><p>We also conducted post hoc multilevel modeling with random intercepts for participants and items as well as fixed effects of the demographic variables. The results indicate that male participants (M = 0.60, SD = 0.44) take significantly less advice from ChatGPT than female participants (M = 0.67, SD = 0.40), t(466.51) = -3.28, p = .001. In addition, the weighting of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>For more objective tasks, the "perfection schema" <ref type="bibr" target="#b15">(Dzindolet et al., 2001;</ref><ref type="bibr" target="#b48">Prahl &amp; van Swol, 2017)</ref> and the "machine heuristic" <ref type="bibr" target="#b62">(Sundar, 2008)</ref> posit that users attribute superior performance to algorithms over humans. This may explain why the weighting of ChatGPT's advice was relatively high on average across all conditions in our study using Fermi problems as estimation tasks. For instance, estimating the total number of hours of schooling completed by German high school graduates or the number of days it would take to walk around the equator can be considered fairly objective tasks that the GenAI should thus be able to solve well. More importantly, however, both the explanation provided and the opportunity to interact with the chatbot exert positive effects on participants' advice taking from ChatGPT (see also <ref type="figure" target="#fig_0">Figure 1</ref>), with corresponding theoretical implications as discussed in the following.</p><p>Making use of the opportunity to request an optional explanation significantly enhances the positive effect of interactivity. That is, simply providing the infrastructure to interactively SELF-EXPLANATORY GENERATIVE AI 20 engage with the GenAI is beneficial, but does not lead users to weight the algorithmic advice as much as in situations where they actively use this opportunity to request more information.</p><p>Indeed, it is less surprising that people would prefer advice that is accompanied by some form of reasoning, reflecting their inherent desire to understand and make sense of the information they receive <ref type="bibr" target="#b44">(Mercier &amp; Sperber, 2017)</ref>. When no additional explanation is requested, participants are left to rely solely on the advice given, without any context or rationale, leading to a lower weighting of the advice due to the lack of transparency and understanding. In contrast, when a rationale is provided, the informational asymmetry is reduced, making the advice more understandable and thus more likely to be taken into consideration.</p><p>There is no evidence for a differential weighting of advice provided with mandatory versus optional explanations of the underlying rationale generated by ChatGPT. However, our findings suggest that advice taking from GenAIs could potentially be increased by the provision of an explanation of the underlying rationale, even when not explicitly requested. Note that this benefit of explanation does not contradict the so-called "verbosity bias" of LLMs, which have been criticized for their general tendency to favor long and wordy texts over short and concise texts of similar or even better quality, leading to the generation of unnecessarily long responses <ref type="bibr" target="#b54">(Saito et al., 2023)</ref>. According to the systematic item-wise random effects of explanation (see <ref type="figure">Figure 3</ref>), participants in our study weighted lower quality advice less than higher quality advice.</p><p>In other words, our data highlight the value of explanations in assessing the quality of GenAIgenerated advice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Practical Implications</head><p>The distributional patterns of WOA ( <ref type="figure">Figure 2</ref>) provide a more detailed picture of qualitative differences between the explanation and interactivity conditions. In particular, the SELF-EXPLANATORY GENERATIVE AI 21 provision of explanations and the opportunity to interact reduce the propensity of users to completely neglect algorithmic advice. Furthermore, the hypothesized interaction between these two factors is clearly evident at higher levels of advice weighting, as the density of informational influence is highest for actively requested explanations. Note that the definition of aversion against algorithms relative to humans includes users' overweighting of their own (e.g., initial)</p><p>judgments <ref type="bibr" target="#b42">(Mahmud et al., 2022)</ref>. Accordingly, the distributional observations suggest that conversational user interfaces primarily empower ChatGPT to counteract algorithm aversion and promote algorithm appreciation relative to one's own estimate, respectively. In contrast to the findings of <ref type="bibr" target="#b4">Bansal et al. (2021)</ref>, who studied joint decision-making in human-AI teams, GenAIgenerated explanations did not lead users to blindly trust the algorithmic advice regardless of its quality, but instead enabled them to calibrate their trust appropriately (Y. <ref type="bibr" target="#b81">Zhang et al., 2020</ref>).</p><p>As we did not manipulate the output of ChatGPT, some of the explanations indicated advice of deficient quality. In addition to increasing the ecological validity of our study, the inclusion of these items allowed us to assess the effects of falsities in algorithmic explanations on advice taking in our data. Indeed, the weighting of advice of deficient quality was significantly below average for items number 5 and 10 ( <ref type="figure">Figure 3)</ref>. Although this suggests that participants were sensitive to falsities in ChatGPT's reasoning, the mean WOA for these two items was still relatively high and significantly positive. This may be due in part to the unavailability of cues to the quality of the advice provided in the control group and on trials where participants did not make use of the opportunity to interact <ref type="bibr" target="#b46">(Papamichail, 2003)</ref>, again supporting the relevance of explanations. A recent study provides evidence that ultimately "hallucination is inevitable" for LLMs <ref type="bibr" target="#b76">(Xu et al., 2024)</ref>, with negative consequences for user engagement and advice taking, as demonstrated in our study. The unintentional generation of SELF-EXPLANATORY GENERATIVE AI 22 falsities and hallucinations, but also the intentional misuse of GenAI to efficiently produce convincing sounding misinformation, are relevant and non-negligible societal risks of further innovations in this technology <ref type="bibr" target="#b8">(Bubeck et al., 2023)</ref>. By varying the quality of explanations, negative consequences should thus be addressed more systematically in future research.</p><p>Our results suggest that the mere presence of features that enhance interactivity increases users' advice taking from conversational GenAI, potentially leading to an overreliance on lowquality and misleading advice. In other words, while the anthropomorphic features of interactivity may enhance users' trust calibration <ref type="bibr" target="#b67">(van Dongen &amp; van Maanen, 2013)</ref>, useless or inappropriately designed conversational user interfaces also run the risk of undermining the calibration of trust. For instance, organizations could increase the utilization of their models' output by implementing mock-up interfaces for interactive engagement. We also found that actual interactive engagement to request explanations further increases the positive effect of interactivity. In most languages, the same message can be phrased in multiple ways. Therefore, it may be even more problematic to provide only a seemingly modified output that actually conveys the same message as the original advice. Deliberately programming chatbots to simply rephrase the virtually identical information using a different tone of voice and/or wording (e.g., using synonyms) to respond to user requests for truly updated information would, according to our results, run the risk of overreliance on such algorithmic advice. This insight has the potential to contribute to the debate about the possible dangers of increasing implementations of GenAI in digitalized societies. Seemingly updated algorithmic advice in response to user requests for genuine updates poses threats beyond hallucinations and misinformation to human autonomy in augmented judgment and decision-making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELF-EXPLANATORY GENERATIVE AI 23</head><p>Limitations and Future Directions</p><p>Our study focused primarily on the behavioral consequences of explanations and interactivity, which we deem most pertinent to our research question about the factors influencing the utilization of GenAI-generated advice. Therefore, we did not directly measure other theoretical constructs such as controllability, perceived transparency, and salience of interactivity. These constructs were inferred from existing literature (e.g., controllability: <ref type="bibr" target="#b14">Dietvorst et al., 2018;</ref><ref type="bibr">perceived transparency: Papamichail, 2003)</ref> and served as the theoretical foundation for our hypotheses regarding behavioral consequences. We assume that these constructs do not differ significantly in interactions with GenAI as compared to traditional decision support systems, so that their effects would be implicitly reflected in the measured WOA. However, we recognize that direct measurement of these constructs in future research could enrich our understanding of the phenomena under investigation.</p><p>Our convenience sample of Western, educated, industrialized, rich, and democratic (WEIRD) university students is not representative of the general population. In addition, other unidentified factors may influence individuals' engagement with LLMs. For instance, user characteristics such as personality (e.g., extroversion, self-esteem) or their attitudes toward technology have been found to influence perception, trust, and utilization of algorithms (see <ref type="bibr" target="#b42">Mahmud et al., 2022</ref>, for an overview). By including random intercepts for participants in our models, we at least statistically accounted for potential individual differences in the propensity to rely on algorithmic advice. Moreover, post hoc multilevel modeling suggests that advice taking from ChatGPT depends on demographic variables such as participants' age and gender.</p><p>Accordingly, more systematic investigation of relevant user characteristics and collection of data SELF-EXPLANATORY GENERATIVE AI 24 from non-WEIRD populations is an important avenue for future research on the effect of explanation and interactivity on advice taking from algorithms.</p><p>In addition to user characteristics, human-GenAI interactions are also shaped by specific design features and functionalities of LLMs. In our experiment, interactivity was limited to pressing a button to request more information. We tried to closely simulate real interactions with</p><p>ChatGPT by presenting user prompts, advice, and explanations in the original layout. However, real conversational user interfaces allow for much more flexible and dynamic engagement with the GenAI, affecting user engagement by providing a more conversational experience. This includes elements of anthropomorphism, which could lead users to perceive the system as more human-like and thus be more inclined to trust it <ref type="bibr" target="#b48">(Prahl &amp; van Swol, 2017;</ref><ref type="bibr" target="#b50">Qiu &amp; Benbasat, 2009)</ref>. By tightly controlling interactivity and using pre-generated algorithmic advice and explanations, our intention was to avoid overly individualized advice interactions. The reason for this was that, technically, LLMs generate text based on probabilistic token forecasts given the current context <ref type="bibr" target="#b69">(Vaswani et al., 2017)</ref>. This functionality implies that the advice and explanations generated are highly attuned to the intentions and beliefs of the specific users providing the relevant context <ref type="bibr" target="#b8">(Bubeck et al., 2023)</ref>. We hypothesize that confirmation bias-the tendency to favor information that is consistent with one's prior beliefs <ref type="bibr" target="#b17">(Fiedler, 2000;</ref><ref type="bibr" target="#b70">Wason, 1960</ref>)-would increase users' willingness to accept highly individualized algorithmic advice resulting from open conversations. Therefore, in future research, we plan to investigate the impact of free and unconstrained (multi-shot) prompting on users' willingness to take advice from self-explanatory GenAI.</p><p>One of the major advantages of using pre-generated advice would have been to systematically vary certain properties of the GenAI-generated explanations. Important variables SELF-EXPLANATORY GENERATIVE AI 25 include explanatory depth, or how detailed and comprehensive certain explanations are <ref type="bibr" target="#b32">(Kizilcec, 2016;</ref><ref type="bibr" target="#b61">Sovrano &amp; Vitali, 2022)</ref>, explanatory focus, or how relevant the information contained in an explanation is to its target stimulus <ref type="bibr" target="#b56">(Shimony, 1993)</ref>, and the degree of personalization, or the extent to which explanations are tailored to individual problem-solving strategies <ref type="bibr" target="#b53">(Ribera &amp; Lapedriza, 2019;</ref><ref type="bibr" target="#b74">Westphal et al., 2023)</ref>. More advanced large language models, such as Google's Gemini or OpenAI's GPT-4, are capable of multimodal reasoning, such as interpreting and/or generating images. Research on explainable AI shows that visual <ref type="bibr" target="#b10">(Cheng et al., 2019)</ref> or-depending on user expertise-hybrid (i.e., textual and visual;</p><p>Szymanski et al., 2021) explanations improve users' objective understanding of complex algorithms, such as classification algorithms used in classical profiling tasks like university admissions. Thus, similar to other properties of explanations, the utilization of algorithmic advice is likely to be influenced by the modality of the explanations provided along with it. The procedure introduced in the present research can be extended for investigating these issues in future research.</p><p>In our study, there is no evidence for an effect of prior experience with numerical estimation tasks or using ChatGPT on the weighting of its advice. In general, however, contextual and environmental factors, such as users' familiarity with the algorithm and task <ref type="bibr" target="#b43">(Mahmud et al., 2024)</ref> or their experience and expertise <ref type="bibr" target="#b53">(Ribera &amp; Lapedriza, 2019)</ref>, also affect the processing of explanations and the conditional utilization of algorithmic advice. For instance, the effectiveness of explanations of an AI's behavior was found to be negatively affected by users' cognitive load <ref type="bibr" target="#b74">(Westphal et al., 2023)</ref>. Put differently, there is a natural trade-off between increased comprehensibility of the underlying rationale and increased cognitive load due to the complexity added by explanations of the GenAI's numerical judgment. In contrast to Westphal et SELF-EXPLANATORY GENERATIVE AI 26 al. (2023), we found a positive effect of general, non-user-centered explanations on advice taking from algorithms. However, in our online study, we could not directly control for cognitive load during participation from any location at any time. In general, understanding how the decisionmaking ecology affects the processing of advice provided along with explanations from interactive GenAI is essential for optimizing the design of conversational user interfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The inherent explanatory capabilities of GenAI and the opportunity to interactively engage with it independently increase users' advice taking. In fact, the mere existence of conversational user interfaces promotes the influence of GenAI on humans without the need for users to engage extensively with these interfaces. On the one hand, this feature can facilitate the efficient use of information. On the other hand, it may be considered a threat to human autonomy in interactions with conversational GenAI systems. However, our data also suggest that GenAIgenerated explanations did not lead users to blindly trust the algorithmic advice regardless of its quality, but instead enabled them to calibrate their trust appropriately. This finding underscores the potential of conversational user interfaces to LLMs, as implemented in ChatGPT and the like, to improve individuals' augmented judgment and decision-making. Our study extends our knowledge of advice taking by highlighting both the benefits and potential risks of integrating GenAI into these processes, suggesting a nuanced impact on user autonomy and trust calibration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 Mean</head><label>1</label><figDesc>Weight of Advice (WOA) per Explanation and Interactivity Group Note. Error bars show the 95% CI. Outliers of WOA are excluded based on</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>algorithmic advice decreases significantly with participant age, b = -0.01, t(471.99) = -4.33, p &lt; .001. Finally, controlling for (centered) experience in the preregistered multilevel model for the main analysis did not affect the main conclusions with respect to the manipulated variables and revealed no significant effects of any type of prior experience on advice weighting, b = -0.01, t(468.11) = -0.94, p = 0.350, for numerical estimation experience, and b = 0.00, t(468.73) = 0.02, p = 0.986, for ChatGPT experience.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Full Multilevel Regression of Weight of Advice (WOA) on Explanation, Interactivity, and Their</figDesc><table><row><cell>Interaction</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Estimate</cell><cell>95% CI</cell><cell>SE</cell><cell>t</cell><cell>df</cell><cell>p</cell></row><row><cell>b0</cell><cell>0.6421***</cell><cell>[0.5780, 0.7061]</cell><cell>0.0327</cell><cell>19.66</cell><cell>10.61</cell><cell>&lt;.001</cell></row><row><cell>bexplanation</cell><cell>0.0643***</cell><cell>[0.0284, 0.1001]</cell><cell>0.0183</cell><cell>3.52</cell><cell>870.61</cell><cell>&lt;.001</cell></row><row><cell>binteractivity</cell><cell>0.0464*</cell><cell>[0.0049, 0.0879]</cell><cell>0.0211</cell><cell>2.19</cell><cell>513.54</cell><cell>.028</cell></row><row><cell>bexplanation ×</cell><cell>-0.0303</cell><cell>[-0.1020, 0.0414]</cell><cell>0.0366</cell><cell>-0.83</cell><cell>870.72</cell><cell>.407</cell></row><row><cell>interactivity</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>τ0,S</cell><cell>0.1912</cell><cell>[0.1731, 0.2071]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>τ0,T</cell><cell>0.0977</cell><cell>[0.0488, 0.1444]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>σ</cell><cell>0.3554</cell><cell>[0.3480, 0.3633]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ICC</cell><cell>0.27</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>R 2 marg.</cell><cell>0.01</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>R 2 cond.</cell><cell>0.28</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Note. Two-sided *p &lt; 0.05, **p &lt; 0.01, and ***p &lt; 0.001. Wald 95% CI for fixed effects and</cell></row></table><note>bootstrap 95% CI (with 1,000 iterations) for random effects are shown. Sample sizes of N = 472</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>participants S and M = 10 stimulus items T resulted in a total number of 4627 observations after excluding outliers.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the use of realistic Fermi problems for introducing mathematical modelling in school</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Ärlebäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Mathematics Enthusiast</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="364" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<idno type="DOI">10.54870/1551-3440.1157</idno>
		<ptr target="https://doi.org/10.54870/1551-3440.1157" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A metaanalysis of the weight of advice in decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Moustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weidemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Psychology</title>
		<imprint>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/s12144-022-03573-2</idno>
		<ptr target="https://doi.org/10.1007/s12144-022-03573-2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nushi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weld</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Does the whole exceed its parts? The effect of AI explanations on complementary team performance</title>
		<idno type="DOI">10.1145/3411764.3445717</idno>
		<ptr target="https://doi.org/10.1145/3411764.3445717" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fitting linear mixed-effects models using lme4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mächler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<idno type="DOI">10.18637/jss.v067.i01</idno>
		<ptr target="https://doi.org/10.18637/jss.v067.i01" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<idno type="DOI">10.48550/arXiv.2303.12712</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.12712" />
		<title level="m">Sparks of Artificial General Intelligence: Early experiments with GPT-4 (Version 5). arXiv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Explaining decision-making algorithms through UI: Strategies to help non-expert stakeholders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300789</idno>
		<ptr target="https://doi.org/10.1145/3290605.3300789" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The robust beauty of improper linear models in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Dawes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<idno type="DOI">10.1037/0003-066X.34.7.571</idno>
		<ptr target="https://doi.org/10.1037/0003-066X.34.7.571" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000033</idno>
		<ptr target="https://doi.org/10.1037/xge0000033" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="114" to="126" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overcoming algorithm aversion: People will use imperfect algorithms if they can (even slightly) modify them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.2016.2643</idno>
		<ptr target="https://doi.org/10.1287/mnsc.2016.2643" />
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1155" to="1170" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting misuse and disuse of combat identification systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Dzindolet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Dawe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15327876MP1303_2</idno>
		<ptr target="https://doi.org/10.1207/S15327876MP1303_2" />
	</analytic>
	<monogr>
		<title level="j">Military Psychology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="147" to="164" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Problem solving, Enrico Fermi and the bull moose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R M</forename><surname>Edge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Dirks</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1949-8594.1983.tb10144.x</idno>
		<ptr target="https://doi.org/10.1111/j.1949-8594.1983.tb10144.x" />
	</analytic>
	<monogr>
		<title level="j">School Science and Mathematics</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="601" to="608" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Beware of samples! A cognitive-ecological sampling approach to judgment biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fiedler</surname></persName>
		</author>
		<idno type="DOI">10.1037//0033-295X.107.4.659</idno>
		<ptr target="https://doi.org/10.1037//0033-295X.107.4.659" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="659" to="676" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">An R companion to applied regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weisberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>Sage</pubPlace>
		</imprint>
	</monogr>
	<note>Third edition</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The effects of structural characteristics of explanations on use of a DSS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Gönül</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Önkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1481" to="1493" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.dss.2005.12.003</idno>
		<ptr target="https://doi.org/10.1016/j.dss.2005.12.003" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Antecedents and effects of trust in forecasting advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sinan Gönül</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Önkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="354" to="366" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.ijforecast.2012.08.001</idno>
		<ptr target="https://doi.org/10.1016/j.ijforecast.2012.08.001" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SIMR: An R package for power analysis of generalized linear mixed models by simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Macleod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods in Ecology and Evolution</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="498" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/2041-210X.12504</idno>
		<ptr target="https://doi.org/10.1111/2041-210X.12504" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Explanations from intelligent systems: Theoretical foundations and implications for practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Benbasat</surname></persName>
		</author>
		<idno type="DOI">10.2307/249487</idno>
		<ptr target="https://doi.org/10.2307/249487" />
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Comparative efficiency of informal (subjective, impressionistic) and formal (mechanical, algorithmic) prediction procedures: The clinical-statistical controversy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Grove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Meehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology, Public Policy, and Law</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="293" to="323" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/1076-8971.2.2.293</idno>
		<ptr target="https://doi.org/10.1037/1076-8971.2.2.293" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Taking advice: Accepting help, improving judgment, and sharing responsibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<idno type="DOI">10.1006/obhd.1997.2697</idno>
		<ptr target="https://doi.org/10.1006/obhd.1997.2697" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="133" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Seeking advice: A sampling approach to advice taking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hütter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ache</surname></persName>
		</author>
		<idno type="DOI">10.1017/S193029750000382X</idno>
		<ptr target="https://doi.org/10.1017/S193029750000382X" />
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="415" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How to harness generative AI to accelerate human learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="DOI">10.1007/s40593-023-</idno>
		<ptr target="https://doi.org/10.1007/s40593-023-" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Experiments with more than one random factor: Designs, analytic models, and statistical power</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Judd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Westfall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Kenny</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-122414-033702</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-122414-033702" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="601" to="625" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">How much information? Effects of transparency on trust in an algorithmic interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Kizilcec</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858402</idno>
		<ptr target="https://doi.org/10.1145/2858036.2858402" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2390" to="2395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The effects of personalization and familiarity on trust and adoption of recommendation agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y X</forename><surname>Komiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Benbasat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="941" to="960" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.2307/25148760</idno>
		<ptr target="https://doi.org/10.2307/25148760" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Taking ChatGPT advice-Investigating the impact of explanations and interactive engagement [Data set, code book, analysis script</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Rebholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hütter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
	<note>and supplementary material</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<idno type="DOI">10.17605/OSF.IO/V9JE8</idno>
		<ptr target="https://doi.org/10.17605/OSF.IO/V9JE8" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">lmerTest package: Tests in linear mixed effects models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H B</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<idno type="DOI">10.18637/jss.v082.i13</idno>
		<ptr target="https://doi.org/10.18637/jss.v082.i13" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">I hear you, I feel you&quot;: Encouraging deep self-disclosure through a chatbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376175</idno>
		<ptr target="https://doi.org/10.1145/3313831.3376175" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">SoSci Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Leiner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Version 3.4.10) [Computer software</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Algorithm appreciation: People prefer algorithmic to human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Logg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Minson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.obhdp.2018.12.005</idno>
		<ptr target="https://doi.org/10.1016/j.obhdp.2018.12.005" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="90" to="103" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">What influences algorithmic decision-making? A systematic literature review on algorithm aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K M N</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smolander</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.techfore.2021.121390</idno>
		<ptr target="https://doi.org/10.1016/j.techfore.2021.121390" />
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Decoding algorithm appreciation: Unveiling the impact of familiarity with algorithms, tasks, and algorithm performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K M N</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mikalef</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dss.2024.114168</idno>
		<ptr target="https://doi.org/10.1016/j.dss.2024.114168" />
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
	<note>Robert</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The enigma of reason</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mercier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sperber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The relative influence of advice from human experts and statistical methods on forecast adjustments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Önkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gönül</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pollock</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.637</idno>
		<ptr target="https://doi.org/10.1002/bdm.637" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="390" to="409" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Explaining and justifying the advice of a decision support system: A natural language generation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papamichail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="48" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/S0957-4174(02</idno>
		<ptr target="https://doi.org/10.1016/S0957-4174(02" />
		<imprint>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Understanding algorithm aversion: When is advice from automation discounted</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Swol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="691" to="702" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<idno type="DOI">10.1002/for.2464</idno>
		<ptr target="https://doi.org/10.1002/for.2464" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Evaluating anthropomorphic product recommendation agents: A social relationship perspective to designing information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Benbasat</surname></persName>
		</author>
		<idno type="DOI">10.2753/MIS0742-1222250405</idno>
		<ptr target="https://doi.org/10.2753/MIS0742-1222250405" />
	</analytic>
	<monogr>
		<title level="j">Journal of Management Information Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="145" to="182" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/SELF-EXPLANATORYGENERATIVEAI32" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Algorithm Familiarity [Data set and code book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Rebholz</surname></persName>
		</author>
		<idno type="DOI">10.17605/OSF.IO/8JR6N</idno>
		<ptr target="https://doi.org/10.17605/OSF.IO/8JR6N" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Can we do better explanations? A proposal of usercentered explainable AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Ribera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Proceedings of the ACM IUI 2019 Workshop</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Verbosity bias in preference labeling by large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Akimoto</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=magEgFpK1y" />
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Meaningful information and the right to explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Selbst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Powles</surname></persName>
		</author>
		<idno type="DOI">10.1093/idpl/ipx022</idno>
		<ptr target="https://doi.org/10.1093/idpl/ipx022" />
	</analytic>
	<monogr>
		<title level="j">International Data Privacy Law</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="233" to="242" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The role of relevance in explanation I: Irrelevance as statistical independence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Shimony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="281" to="324" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/0888-613X</idno>
		<ptr target="https://doi.org/10.1016/0888-613X" />
		<imprint>
			<biblScope unit="page">90027</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Cueing and cognitive conflict in judge-advisor decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Sniezek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<idno type="DOI">10.1006/obhd.1995.1040</idno>
		<ptr target="https://doi.org/10.1006/obhd.1995.1040" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Strategies for revising judgment: How (and how well) people use others&apos; opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Soll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Larrick</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0015145</idno>
		<ptr target="https://doi.org/10.1037/a0015145" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="780" to="805" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Explanatory artificial intelligence (YAI): Human-centered explanations of explainable AI and complex data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sovrano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vitali</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10618-022-00872-xSELF-EXPLANATORYGENERATIVEAI33</idno>
		<ptr target="https://doi.org/10.1007/s10618-022-00872-xSELF-EXPLANATORYGENERATIVEAI33" />
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The MAIN model: A heuristic approach to understanding technology effects on credibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sundar</surname></persName>
		</author>
		<idno type="DOI">10.1162/dmal.9780262562324.073</idno>
		<ptr target="https://doi.org/10.1162/dmal.9780262562324.073" />
	</analytic>
	<monogr>
		<title level="m">Digital Media, Youth, and Credibility</title>
		<editor>M. J. Metzger &amp; A. J. Flanagin</editor>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Visual, textual or hybrid: The effect of user expertise on different explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Szymanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Millecamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Verbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Intelligent User Interfaces</title>
		<meeting>the 26th International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="109" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3397481.3450662</idno>
		<ptr target="https://doi.org/10.1145/3397481.3450662" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Exploratory data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Solving the multiplication problem of a large language model system using a graph-based method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuncer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hafeez-Baig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">R</forename><surname>Acharya</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2310.13016</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2310.13016" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A framework for explaining reliance on decision aids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Dongen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-P</forename><surname>Van Maanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="410" to="424" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.ijhcs.2012.10.018</idno>
		<ptr target="https://doi.org/10.1016/j.ijhcs.2012.10.018" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, &amp; R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">On the failure to eliminate hypotheses in a conceptual task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Wason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="140" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/17470216008416717</idno>
		<ptr target="https://doi.org/10.1080/17470216008416717" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">In</forename><forename type="middle">S</forename><surname>Koyejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belgrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<title level="m">Advances in neural information processing systems</title>
		<editor>&amp; A. Oh</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Decision control and explanations in human-AI collaboration: Improving user perceptions and compliance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Westphal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vössing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Satzger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Yom-Tov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rafaeli</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107714</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107714" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">The rise and potential of large language model based agents: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2309.07864</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2309.07864" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Hallucination is inevitable: An innate limitation of large language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kankanhalli</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.11817</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.11817" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Receiving other people&apos;s advice: Influence and benefit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.obhdp.2003.08.002</idno>
		<ptr target="https://doi.org/10.1016/j.obhdp.2003.08.002" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Advice taking in decision making: Egocentric discounting and reputation formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yaniv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kleinberger</surname></persName>
		</author>
		<idno type="DOI">10.1006/obhd.2000.2909</idno>
		<ptr target="https://doi.org/10.1006/obhd.2000.2909" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="260" to="281" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Taking Advice from ChatGPT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.11888</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.11888" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K E</forename><surname>Bellamy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m">Conference on Fairness, Accountability, and Transparency</title>
		<imprint>
			<biblScope unit="page" from="295" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3351095.3372852</idno>
		<ptr target="https://doi.org/10.1145/3351095.3372852" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Self-Explanatory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Generative Ai</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
