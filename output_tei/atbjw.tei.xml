<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Epistemic biases in human reinforcement learning: behavioral evidence, computational characterization, normative status and possible applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Palminteri</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire de Neurosciences Cognitives et Computationnelles</orgName>
								<orgName type="institution">Institut National de la Santé et de la Recherche Médicale</orgName>
								<address>
									<settlement>Paris</settlement>
									<country>France (</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Departement d&apos;Etudes Cognitifs</orgName>
								<orgName type="institution">Ecole Normale Supérieure</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Epistemic biases in human reinforcement learning: behavioral evidence, computational characterization, normative status and possible applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T12:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>The reinforcement learning framework provides a computational and behavioral foundation for understanding how agents learn to maximize rewards and minimize punishments through interaction with their environment. This framework has been widely applied across disciplines, including artificial intelligence, animal psychology, and economics. Over the last decade, a growing body of research has shown that human reinforcement learning often deviates from normative, objective standards, exhibiting systematic biases. The aim of this paper is to propose a conceptual framework and taxonomy for evaluating computational biases within reinforcement learning. We specifically propose a distinction between praxic biases, characterized by a mismatch between internal representations and selected actions, and epistemic biases, characterized by a mismatch between past experiences and internal representations. Building on this foundation, we characterize two primary types of epistemic biases at the computational level: relative valuation and biased update. We describe their behavioral signatures, discuss their potential adaptive roles, and explore their implications for applied research. Finally, we speculate on how these findings may shape future developments in both theoretical and applied domains. Notably, despite being widely used in clinical and educational settings, reinforcement-based interventions have been comparatively neglected in the domains of public policy and decisionmaking, particularly when compared to more popular approaches such as nudges and boosts. Acknowledgements The author is deeply thankful to Maëva L&apos;Hôtellier for feedback on the manuscript and to Roman Cecchi for feedback and assistance in preparing the figure. Maëva L&apos;Hôtellier and Isabelle Hoxha provided the data displayed in Figure 6. The author also wishes to thank the many collaborators who, over the past years, have helped shape these lines of research and whose names can be found among the 20-something self-citations (oops…) listed at the end of the paper.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main text</head><p>The reinforcement learning framework Reinforcement learning (RL) captures the ability to guide choices to maximize the occurrence of pleasant events (rewards) and minimize the occurrence of unpleasant events (punishments) <ref type="bibr" target="#b87">(Sutton &amp; Barto, 2018)</ref>. In other words, RL is the process of learning through experience, employing trial and error to optimize outcomes <ref type="bibr" target="#b14">(Dayan &amp; Abbott, 2005)</ref>. RL has immense adaptive value, which explains its presence across diverse group of species (phyla), including nematodes, arthropods, mollusks, and chordates <ref type="bibr" target="#b8">(Brembs, 2003)</ref>.</p><p>Reinforcement learning in animals and humans exists in various forms. One form is classical or Pavlovian conditioning, which is of less concern here because its effects are exerted without involving a decision-making component and are accordingly referred to as "reflexes". A wellknown example is Pavlov's dog, which learned to salivate in response to a neutral stimulus previously associated with food <ref type="bibr" target="#b46">(Lavond &amp; Steinmetz, 2003)</ref>. The other form of reinforcement learning, known as instrumental or operant learning, is the primary focus here, as it deals with how past outcomes shape future decisions (J. E. R. <ref type="bibr" target="#b86">Staddon &amp; Cerutti, 2003)</ref>.</p><p>The reinforcement-learning process is often summarized by the idiom "carrot and stick." What does this phrase mean? It refers to rewards and punishments, which are specific stimuli capable of eliciting particular responses <ref type="bibr" target="#b25">(Frank et al., 2004;</ref><ref type="bibr" target="#b68">Palminteri &amp; Pessiglione, 2017;</ref><ref type="bibr" target="#b81">Shohamy et al., 2004;</ref><ref type="bibr" target="#b92">Young, 1952)</ref>. In the context of instrumental learning, rewards and punishments are defined precisely by their effects on the frequency of future actions. Rewards are stimuli that increase the frequency of the actions that precede them and reduce the frequency of actions that prevent their delivery. Conversely, punishments are stimuli whose delivery decreases the frequency of the preceding action and whose omission increases it ( <ref type="table">Table 1)</ref>. While these are necessary operational definitions, we all have an intuitive understanding of what constitutes a reward (e.g., good food, sex, success, winning money) and a punishment (e.g., pain, losing money). <ref type="table">Table 1</ref>. The table illustrate different configurations of instrumental learning in relation to different types of outcomes (rewards and punishments) and their effects on the subsequent action (reinforcement: increase in frequency; weakening: decrease in frequency). The frequency of an action increases if it is rewarded or if it allows escaping a punishment. Symmetrically the frequency of an action decreases if it leads to a punishment or the omission of a reward.</p><p>This learning mechanism (improving choices based on the past experience of rewards and punishments) can capture virtually all levels of decision-making. For instance, RL guides motor learning, such as mastering the use of a spoon. In this example, the reward is represented by successfully eating without spilling food, while the punishment is represented be dropping food and creating a mess. Similarly, RL may underpin higher cognitive tasks cognitive tasks, like optimizing the route between home and work; educational strategies, such as tailoring study methods for university exams based on past performance; and professional activities, like a physician refining treatment based on therapeutic outcomes <ref type="bibr" target="#b37">(He et al., 2022;</ref><ref type="bibr" target="#b42">Jayaraman et al., 2024;</ref><ref type="bibr" target="#b65">Palminteri et al., 2011)</ref>. More recently, the RL framework has been applied to explain the dynamics of financial markets, as well as social media engagement <ref type="bibr" target="#b52">(Lindström et al., 2021;</ref><ref type="bibr" target="#b56">Lussange et al., 2024;</ref><ref type="bibr" target="#b89">Turner et al., 2024)</ref>. In essence, RL describes an evolutionary old and preserved cognitive building block that can underpin the generation of more complex behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cognitive bias: an ecumenic definition for a debated concept</head><p>After this general preamble on some basic notions of reinforcement learning, it is essential to introduce an operational definition of cognitive bias that aligns with our specific goals and could also serve as a valuable resource for future explorations of this topic. Establishing such a definition is particularly important because "cognitive bias" is one of the most contested concepts in the broader rationality debate. This debate contrasts the view that human decision-making should be evaluated against normative standards of logic and probability with the perspective that rationality lies in finding efficient solutions to real-life constraints <ref type="bibr" target="#b9">(Brighton &amp; Gigerenzer, 2015)</ref>. This is particularly important given that the notion of cognitive bias plays a central role in the debate on how and when psychological insights should be used to improve, shape, or inform policymaking across various domains, such as economic outcomes, well-being, and climate change. 1: information processing-based illustration of noise and bias within cognitive processes, whose goal is to transform an objective value (input) into a subjective one (output). (A) Noiseless and unbiased process. (B) Noisy and unbiased process. In the simulation we used a Gaussian noise, with a mean of zero and a variance proportion to the value of the objective variable (Weber's law) (C) Noiseless and biased process. In the simulation, the cognitive process overestimates the value of the objective variable in the lower range and underestimates it in mid/high range. (D) Noisy and biased process. We argue that much of this debate could be simplified-or even circumvented-if a clear and operational definition were available. Traditionally, within the heuristics and biases framework, cognitive biases are often treated as flaws in human cognition-features that undermine performance, coherence, or lead to undesirable outcomes across various contexts <ref type="bibr" target="#b10">(Camerer, 1998;</ref><ref type="bibr" target="#b15">DellaVigna, 2009)</ref>. In contrast, the adaptive rationality perspective views these heuristics and biases as elements of an (evolutionarily or environmentally) crafted adaptive toolbox. From this perspective, cognitive biases, while not necessarily normative in a logical or statistical sense, are seen as highly adapted to real-world, ecological scenarios <ref type="bibr" target="#b29">(Gigerenzer &amp; Gaissmaier, 2011;</ref><ref type="bibr" target="#b31">Haselton et al., 2009</ref><ref type="bibr" target="#b33">Haselton et al., , 2015</ref><ref type="bibr" target="#b40">Hertwig et al., 2022)</ref>. The divergence between these frameworks primarily lies in the valence ascribed to the instrumental or functional consequences of cognitive biases-whether they are considered negative or positive. For this reason, we believe that fruitful debate and characterization of cognitive biases require adopting a definition grounded in computational and information-processing terms, which emains independent of any a priori judgment of biases as inherently "good" or "bad."</p><p>Rooted in the metaphor of the brain as a computer, our operational definition of a cognitive bias begins with the assumption that a cognitive process can be conceptualized as a series of computational operations transforming input into output. The input is characterized as having an "objective" value, such as the physical properties of sensory stimuli (e.g., light intensity or sound pressure levels impacting the eyes or ears), which is then transformed into a subjective (internal) estimation (or representation). This transformation is carried out by the cognitive process, which can vary in its features. In an idealized scenario, the process might be noiseless and unbiased ( <ref type="figure">Figure 1A)</ref>. In such a case, the relationship between the objective variable and its subjective representation would be linear and error-free, theoretically allowing perfect inference of the objective value from its subjective counterpart. However, this scenario is highly unrealistic for biological cognitive systems, facing in open-ending, stochastic scenarios.</p><p>Cognitive processes are performed by the brain, a biological organ whose physical implementation inherently introduces errors and compromises precision due to the trade-off between accuracy and efficiency. Moreover, many objective variables are intrinsically stochastic, meaning that any given sample may not perfectly represent its true distribution at a given moment. As a result, subjective representations are realistically affected by both internal (computational errors generated by the process itself) and external (random errors in variable sampling) sources of noise ( <ref type="figure">Figure 1B)</ref>  <ref type="bibr" target="#b19">(Faisal et al., 2008;</ref><ref type="bibr" target="#b21">Findling et al., 2019;</ref><ref type="bibr" target="#b75">Sanborn et al., 2024)</ref>. Although noise reduces the capacity to perfectly infer objective variables from subjective estimations, it does not introduce systematic deviations between the two.</p><p>Systematic deviations, however, are a hallmark of biased cognitive processes ( <ref type="figure">Figure 1C)</ref>. The key distinction between noise and bias lies in their nature: noisy processes create random, nondirectional distortions, whereas biased processes produce systematic deviations between objective variables and their internal representations. Importantly, bias and noise are orthogonal features of cognitive processes; they are independent and can coexist in practice ( <ref type="figure">Figure 1D</ref>).  It is now crucial to understand why, from this straightforward yet robust information-processing perspective, cognitive biases are not inherently negative features of a cognitive process. This requires distinguishing between epistemic accuracy and instrumental accuracy. Epistemic accuracy refers to the correspondence between the objective value of a variable and its internal representation-in essence, the degree to which the knowledge (in ancient Greek epistemeἐπιστήμη -means knowledge) of the cognitive system aligns with reality. In this framework, maximum epistemic accuracy is achieved by noiseless and unbiased cognitive processes.</p><p>However, for biological cognitive systems (until recently the only type of cognitive systems), epistemic accuracy is not always the primary goal. Instead, the primary goal is often to enable the best possible course of action-what we refer to as instrumental accuracy. Ultimately, survival depends not on having perfect knowledge of the prey's distribution but on successfully catching the rabbit to satisfy immediate needs. Although epistemic and instrumental accuracy often align, they can diverge. In some cases, distorting or ignoring certain pieces of objective information may lead to better decisions. Consequently, when focusing on instrumental accuracy, the value of cognitive biases should not be assessed based on their contribution to epistemic accuracy but rather on their role in facilitating better decisions, regardless of the gap between subjective representations and reality. In the remainder of this paper, we will explore examples of the dissociation between epistemic and instrumental accuracy within the context of reinforcement learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reinforcement learning formal framework</head><p>We now turn to a more formal description of the reinforcement learning process. A reinforcement learning agent operates within an environment that provides a context, offering options among which the agent can choose, and rewards that follow the agent's choices. In this framework, options, actions, and rewards are the observable elements.</p><p>The internal representations of a reinforcement learning agent refer to the latent variables and stored information that underlie its learning and action-selection (or decision-making) processes. While there is no complete consensus, most accounts agree that these representations include context-specific action values, which guide the selection of the most advantageous or appropriate action for a given trial and context. These context-specific hidden values are typically updated after the agent receives new outcome (reward or punishment), reflecting a dynamic process of learning and adaptation <ref type="figure" target="#fig_2">(Figure 2A)</ref>.</p><p>At the formal level, the process of selecting an action in reinforcement learning is often implemented using a Softmax function <ref type="bibr" target="#b55">(Luce, 2005)</ref>. This function determines the probability of choosing a particular option based on the difference in value between the available options.</p><p>(Eq.1)</p><formula xml:id="formula_0">( ) = 1 1 + ( ( , )− ( , )) *</formula><p>(where and are available options in context and is a parameter governing the stochasticity of the process). While other selection rules exist, the Softmax function remains the most widely used in behavioral reinforcement learning due to its simplicity and effectiveness.</p><p>Once a new outcome is obtained, whether it is a reward or punishment, the update process begins with the calculation of a reward prediction error <ref type="bibr" target="#b54">(Ljung, 2002;</ref><ref type="bibr" target="#b60">Niv &amp; Schoenbaum, 2008)</ref>. This prediction error is the difference between the reward received and the value previously assigned to the chosen option.</p><formula xml:id="formula_1">(Eq.2) = − ( , )</formula><p>(where is the reward obtained in a given trial). The prediction error is then used to update the estimated value of the option through a delta rule, a straightforward and intuitive error correction model <ref type="bibr" target="#b48">(Lee et al., 2020;</ref><ref type="bibr" target="#b72">Rescorla &amp; Holland, 1977)</ref>.</p><formula xml:id="formula_2">(Eq.3) ( , ) ← ( , ) + *</formula><p>This prediction error and delta rule framework is not only foundational in machine learning (dating back to the perceptron) but is also deeply established in human and animal behavior, with welldocumented neural correlates <ref type="bibr" target="#b23">(Fouragnan et al., 2018;</ref><ref type="bibr" target="#b78">Schultz &amp; Dickinson, 2000)</ref>.</p><p>With this basic model in place, we can now identify potential sources of bias within this framework, as defined earlier. These biases fall into two categories. The first arises at the interface between option values and action selection-essentially, in the selection process. The second occurs at the interface between outcomes and option values, during the update process ( <ref type="figure" target="#fig_2">Figure 2B</ref>).</p><p>Because they pertain to action selection, we term the first category of biases praxic (from the Greek "praxis", πρᾶξις, meaning action). Praxic biases are characterized as mismatches between the calculated option values and the actions that are actually chosen. These mismatches may arise from interference between different memory systems. A common example of a praxic bias in human reinforcement learning is choice repetition or perseveration, where actions are repeated regardless of the rewards received, causing actions to deviate from the calculated option values.</p><p>The second category of biases is epistemic, because they relate to the agent's internal representation of option values (in a sense, the 'knowledge' of the agent). Epistemic biases reflect mismatches between the outcomes experienced and the values assigned to the options. In the remainder of this paper, we will explore two specific epistemic biases in detail, examining them at computational, behavioral, and functional levels. : two epistemic biases of human reinforcement learning with their key equations mapped into the reinforcement learning agent. The first step is represented by subjective outcome encoding (relative valuation), the second one the error prediction error calculation, the third one by value update and, finally, the last one by action selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Epistemic biases in reinforcement learning</head><p>In this section, we will describe in detail two epistemic biases recently reported in human reinforcement learning, both by our lab and others around the world <ref type="figure" target="#fig_3">(Figure 3)</ref>. The first bias concerns the encoding of outcomes, occurring before the calculation of the reward prediction error. The central idea is that objective rewards (e.g., the amount of money a participant wins on a given trial) are transformed into subjective rewards <ref type="bibr" target="#b63">(Palminteri &amp; Lebreton, 2021)</ref>. This transformation is influenced by other outcomes encountered in the same context, either simultaneously (spatial context) or in the recent past (temporal context).</p><p>Conceptually, this effect is analogous to classic optical illusions, such as the Ebbinghaus circles or the Müller-Lyer arrows, where subjective judgments about size are influenced by the context surrounding of the object under evaluation <ref type="bibr" target="#b7">(Bratzke, 2024)</ref>. In reinforcement learning, outcome context-dependence often manifests as a normalization process. Two popular functional formsexpressing how the input are related to the output values-have been proposed for this normalization. The first is reference point-dependent normalization, a feature shared with prospect theory and consistent with the phenomenon of incentive relativity, where motivation for a reward depends on the expectation of the average reward in a given situation <ref type="bibr" target="#b22">(Flaherty, 1996;</ref><ref type="bibr" target="#b43">Kahneman &amp; Tversky, 1979)</ref>. Here, the subjective value of an outcome is rescaled as a function of the average value of the context in which it is experienced, a context value known as the reference point (a process often referred to as reward "centering") <ref type="bibr" target="#b34">(Hayes &amp; Wedell, 2023a;</ref><ref type="bibr" target="#b58">Naik et al., 2023;</ref><ref type="bibr" target="#b62">Palminteri et al., 2015)</ref>. Another popular functional form of outcome context-dependence is range normalization, in which the subjective value of an outcome is rescaled based on the minimum and maximum outcomes possible within a given context, defining the contextual range <ref type="bibr" target="#b2">(Bavard et al., 2018</ref><ref type="bibr" target="#b5">(Bavard et al., , 2021</ref><ref type="bibr" target="#b3">Bavard &amp; Palminteri, 2023;</ref><ref type="bibr" target="#b35">Hayes &amp; Wedell, 2023b)</ref>, as illustrated in the equation below:</p><formula xml:id="formula_3">(Eq.4) ( ) = − ( ) ( ) − ( )</formula><p>Where ( ) and ( ) are the contextual he contextual bounds, i.e., the current estimations of the maximum and minimum rewards expected in a given situation. Both functional forms have been descriptively successful in explaining human behavior in reinforcement learning tasks. However, the range normalization rule is more general, as it can account for some effects traditionally explained by reference point centering, whereas the reverse is not true <ref type="bibr" target="#b5">(Bavard et al., 2021)</ref>. A typical experimental demonstration of outcome context-dependence employs a twophase design, comprising a learning phase and a transfer phase. During the learning phase, participants learn to associate options (e.g., A, B, C, D) with specific outcomes. These options often have different expected values, which refer to the average reward one can expect from a given option. During the learning phase, are presented within stable contexts (e.g., option A is always presented with option B, while option C is consistently paired with option D). Following this, the transfer phase, also called the post-learning or generalization phase, requires participants to make choices between options presented in novel pairings (e.g., B with C). The architecture of the learning phase is designed such that the preferences expressed during the transfer phase will differ depending on whether option values are encoded in an objective manner or in a context-dependent manner (e.g., using range normalization) <ref type="figure" target="#fig_4">(Figure 4)</ref>. Importantly, the options in the transfer phase are often structured in a way that results in an economic cost for participants who encode outcomes and option values in a context-dependent manner. Specifically, such encoding leads to suboptimal choices that minimize expected value, meaning that the choices made result in lower rewards compared to the best possible options. This pattern is frequently, if not systematically, observed and provides compelling evidence for the prevalence and impact of context-dependent biases in human reinforcement learning Evidence supporting context-dependence in reinforcement learning tasks, particularly those employing a learning/transfer design as described above, appears to be both robust and highly replicable. These findings have been consistently reported across various countries and species, suggesting a very preserved and generalizable phenomenon <ref type="bibr" target="#b0">(Anlló et al., 2024;</ref><ref type="bibr" target="#b71">Pompilio &amp; Kacelnik, 2010;</ref><ref type="bibr" target="#b83">Solvi et al., 2022)</ref>. Similar patterns of context-dependent behavior have been observed across a broad range of outcome values, encompassing both gains and losses, different outcomes magnitudes, and outcomes distributions such as Gaussian or Bernoullian <ref type="bibr" target="#b5">(Bavard et al., 2021;</ref><ref type="bibr" target="#b3">Bavard &amp; Palminteri, 2023)</ref>.</p><p>Moreover, recent evidence suggests that this context-dependent reward encoding is genuinely epistemic, as it affects participants' declarative memory and knowledge <ref type="bibr" target="#b84">(Soukupova et al., 2024)</ref>. Post-learning preferences consistently display clear signs of context-dependence, regardless of whether values are inferred through choices or directly assessed via episodic memory or subjective ratings. This further underscores the stability and pervasiveness of context-dependent biases in human reinforcement learning, as well as its truly epistemic nature.</p><p>Another well-documented epistemic bias in human reinforcement learning concerns the update step that occurs after the calculation of the prediction error <ref type="figure" target="#fig_3">(Figure 3)</ref>. Specifically, studies have shown that option values are updated more following positive prediction errors than negative ones <ref type="bibr" target="#b64">(Palminteri &amp; Lebreton, 2022)</ref>. Computationally, this bias is modeled by assuming different learning rates for positive and negative prediction errors <ref type="figure" target="#fig_5">(Figure 5)</ref>.</p><formula xml:id="formula_4">(Eq.6) ( , ) ← ( , ) + { + * , &gt; 0 _ * , &lt; 0</formula><p>Where the asymmetry + &gt; _ indicates that individuals learn faster from outcomes that are better than expected, while + &lt; _ suggests faster learning from worse-than-expected outcomes. Conceptually, it resembles the "good news/bad news" effect observed in belief updating across various domains, which may contribute to the broader optimism bias often displayed in decisionmaking <ref type="bibr" target="#b79">(Sharot &amp; Garrett, 2016)</ref>. However, it is important to note that this update bias favoring positive prediction errors is not unconditional as it depends on several key factors. Notably, the bias is observed primarily when outcomes follow freely chosen actions, meaning rewards or punishments are directly tied to an individual's performance <ref type="bibr" target="#b12">(Chambon et al., 2020)</ref>. Conversely, the bias is reversed when learning from the outcomes of forgone options (i.e., counterfactual updates). This reversal is intuitive: a negative prediction error for a forgone outcome signals "good news" for the participant (e.g., avoiding a negative outcome), while a positive prediction error for a forgone option signals "bad news" (e.g., missing out on a reward) .</p><p>The positivity bias in option value updating is a robust phenomenon, replicated across species and across a variety of task designs <ref type="bibr" target="#b20">(Farashahi et al., 2019;</ref><ref type="bibr" target="#b61">Ohta et al., 2021)</ref>. Strikingly, it has been observed even in scenarios involving primary punishments (e.g., electric shocks) and in volatile environments <ref type="bibr" target="#b26">(Gagne et al., 2020)</ref>. The latter condition is particularly informative, as volatile tasks-featuring frequent changes in option values-require heightened sensitivity to negative prediction errors, which signal shifts in contingencies and should prompt a change in choice policy. In such situations, the behavioral hallmark of the positivity bias manifests as a tendency to persist with previously rewarded options, even in the face of accumulating negative feedback.  <ref type="figure">Figure 1</ref>, how we move from unbiased and noiseless update to biased and noisy one. More specifically the graph shows the relationship between the prediction error and the Q-value modification in the positive (green) and negative (red) domains. Note that the noise takes the form of a Gaussian noise with a mean of zero and variance proportional to the size of the prediction error, while the update bias takes the form of a positivity bias (the slope is higher positive, compare to negative prediction errors).</p><p>Research has shown that asymmetries in learning rates for positive and negative prediction errors predict subjective and explicit confidence ratings during reinforcement learning tasks <ref type="bibr" target="#b74">(Salem-Garcia et al., 2023)</ref>. Specifically, the positivity bias has been linked to over-confidence, defined as the tendency to overestimate one's own probability of success. This connection suggests that the asymmetry in learning rates for positive and negative prediction errors may not only influence the updating of option values but also shape subjective judgments about performance and outcomes. By favoring positive feedback over negative, individuals may develop an inflated sense of confidence in their decisions, reinforcing the cognitive and behavioral patterns associated with optimism bias <ref type="bibr" target="#b28">(Gervais &amp; Odean, 2001)</ref>. The fact that the signature of the bias (in this case over-confidence) is reflected in the explicit reports of the subject, further underscores the "epistemic" nature of the positivity bias.</p><p>Finally, additional evidence for the stability and pervasiveness of these biases in human cognition comes from recent pioneering studies examining the reinforcement learning capacities of Large Language Models (LLMs), such as ChatGPT, Claude, Llama, and PaLM. In these studies, bandit tasks, similar to those used to uncover these biases in humans, were adapted into textual formats and presented to LLMs. The responses generated by the models were then collected and analyzed using computational methods similar to those applied to human data <ref type="bibr" target="#b91">(Yax et al., 2024)</ref>. The results revealed that, when fitted with computational models, LLM-generated responses exhibited both relative value learning biases and positivity bias <ref type="bibr" target="#b36">(Hayes et al., 2024;</ref><ref type="bibr" target="#b76">Schubert et al., 2024)</ref>. Given that these models are trained on vast corpora of human-generated text, followed by additional training with human feedback, these findings suggest that relative value encoding and positivity bias are deeply embedded in the way human language is produced and used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The possible adaptive values of epistemic biases</head><p>Epistemic biases in human reinforcement learning have been widely studied in contexts where they are shown to be detrimental to performance. For example, relative value learning has been shown to induce expected-value-minimizing choices in novel decision-making scenarios, where options are extrapolated from their original learning contexts <ref type="bibr" target="#b5">(Bavard et al., 2021)</ref>. Similarly, the positivity bias has been found to promote reluctance to switch options in reversal learning tasks, where option values change, causing previously correct options to become incorrect . Demonstrating these biases in situations where they result in economic costs is significant because it reinforces the notion that these biases are relatively rigid features of human cognition. This methodological focus often perpetuates the view that cognitive biases are flaws. The very existence of these biases, however, suggests they have been shaped by evolution and may serve some adaptive functions. This perspective is frequently overlooked when research focuses solely on contexts where these biases appear detrimental, neglecting the potential advantages they may offer to decision-makers in other environments. One potential adaptive advantage lies in the generation of self-serving beliefs and representations, which we term "weak" optimality. The "weak" aspect refers to the idea that these biases may not lead to optimal outcomes in terms of maximizing rewards or efficiency within a given reinforcement learning context. Optimality, rather, lies in their ability to enhance subjective utility, by producing internal beliefs and representations that are self-serving <ref type="bibr" target="#b80">(Shepperd et al., 2008)</ref>. For instance, evaluating outcomes relative to a contextual range can help adjust expectations and, consequently, happiness to a set of reasonable outcomes <ref type="bibr" target="#b16">(Diener et al., 2009;</ref><ref type="bibr" target="#b69">Parducci, 1984)</ref>. This mechanism could, for example, prevent dissatisfaction with one's salary when compared to unrealistic benchmarks, such as the exorbitant remunerations of top CEOs.</p><p>Similarly, the positivity bias, by increasing subjective confidence in the probability of being correct, can foster overconfidence and optimism. These traits have been associated with numerous positive life outcomes and are evolutionarily stable under conditions where mating success is linked to assertiveness <ref type="bibr" target="#b1">(Bailey et al., 2007;</ref><ref type="bibr" target="#b27">Gannon &amp; Zhang, 2020;</ref><ref type="bibr" target="#b38">Heifetz &amp; Spiegel, 2000)</ref>. Thus, both relative value learning and positivity biases can be understood as cognitive adaptations that, while sometimes suboptimal in specific reinforcement learning tasks, provide broader psychological and evolutionary benefits to the individual.</p><p>Another possibility, which we term "strong" optimality, is that cognitive biases have been selected because they are advantageous even within the context of reinforcement learning problems. They could be optimal by solving fundamental information-processing challenges and by being welladapted to problems commonly encountered in ecological scenarios. In fact, while it is possible to identify situations and tasks where these biases appear detrimental (e.g., the post-learning phase), it is equally possible to reverse-engineer scenarios where the same biases prove optimal. The key question then becomes how plausible and general these scenarios are. This is typically addressed through mathematical analysis or simulations, both of which can provide insight into the adaptive value of these biases.</p><p>In the case of range normalization, both mathematical analysis and simulation studies suggest that its adaptive value lies in maintaining internal representations within a consistent scale. This consistency enables the adjustment of response stochasticity-commonly referred to as balancing exploration and exploitation-to the range of possible outcomes <ref type="bibr" target="#b51">(L'Hôtellier et al., 2024;</ref><ref type="bibr" target="#b73">Rustichini et al., 2023)</ref>. As a result, algorithms endowed with range normalization achieve what is known in machine learning as "scale invariance," the ability to perform equally well regardless of the magnitude of rewards at stake ( <ref type="figure" target="#fig_6">Figure 6A</ref>) <ref type="bibr" target="#b51">(L'Hôtellier et al., 2024)</ref>. Crucially, range normalization achieves this result in a bottom-up manner, without incurring the cost of encoding task-specific information <ref type="bibr" target="#b57">(Mnih et al., 2015)</ref>. In other words, it allows for effective adjustment without any additional computational effort or resource expenditure. This property mirrors how the human brain appears to automatically adjust value encoding across vastly different contexts and quickly move from making decisions that involve quite high stakes (such as picking a hotel room -in the hundreds of euros) versus very small ones (such as choosing what to have for breakfast -in the range of a few cents). Moreover, we note that magnitude insensitivity is a robust feature of human reinforcement learning, as evidenced by numerous studies where participants' performance is the same across, sometimes very different, magnitude domains <ref type="bibr" target="#b0">(Anlló et al., 2024;</ref><ref type="bibr" target="#b2">Bavard et al., 2018</ref><ref type="bibr" target="#b5">Bavard et al., , 2021</ref>.</p><p>The optimality of biased update, such as positivity bias, has been assessed in several studies <ref type="bibr" target="#b11">(Cazé &amp; van der Meer, 2013;</ref><ref type="bibr" target="#b50">Lefebvre et al., 2022)</ref>. A consistent finding is that in bandit tasks similar to those described earlier, algorithms incorporating a positivity bias (or confirmation bias) tend to outperform unbiased algorithms across many types of environments, with the exception of those with generally high reward rates, which are unlikely to have been encountered in natural settings (Finding food, especially high-calorie food, was a relatively rare event for our ancestors). More specifically, a recent study using evolutionary simulations demonstrated the evolvability of positivity bias in various two-armed bandit scenarios, including, somewhat counterintuitively, environments with moderate levels of volatility (i.e., changes in reward probabilities) ( <ref type="figure" target="#fig_6">Figure 6B</ref>) <ref type="bibr" target="#b41">(Hoxha et al., 2024)</ref>. Another study employing a meta-reinforcement learning framework-training a neural network to perform bandit tasks optimally-revealed that positivity bias naturally emerged as a cognitive feature of the network, suggesting its adaptive value in reinforcement learning contexts <ref type="bibr" target="#b76">(Schubert et al., 2024)</ref>.</p><p>In summary, both relative value encoding (in the form of range normalization) and biased updating (in the form of positivity bias) have been shown to outperform unbiased models across a wide array of scenarios. This suggests that these biases may have been selected and maintained due to their statistical optimality. However, the two mechanisms address different challenges in reinforcement learning. Range normalization functions as a "tuning" mechanism, adjusting both the "perceptions" and "responses" of the model to virtually any range of potential outcomes. In contrast, positivity bias, particularly in the context of probabilistic (Bernoullian) outcomes, serves as a form of "noise cancellation". A moderate insensitivity to negative outcomes can be advantageous-for instance, when a correct option is rewarded 75% of the time, it is optimal to choose it 100% of the time while disregarding the occasional negative outcomes. As expected the unbiased model presents a scale-dependent performance (e.g., it is tuned well only for a narrow range of outcome magnitudes). On the other side the range model performs equally well across the whole range of magnitudes (adapted from <ref type="bibr" target="#b51">(L'Hôtellier et al., 2024)</ref>). (B) Evolutionary trajectory of the positive (y-axis) and the negative (x-axis) learning rate in population of 1000 agents across 200 generations, whose fitness is defined as the performance in a bandit task. Regardless of very different initial points the population converge to a positive bias (points above the diagonal) (adapted from <ref type="bibr" target="#b41">(Hoxha et al., 2024)</ref>).</p><p>These findings illustrate an important principle: epistemic accuracy and instrumental accuracy can be dissociated <ref type="bibr" target="#b44">(Kelly, 2003)</ref>. It is possible to hold distorted or biased knowledge (as resulting from range normalization and positivity bias) while performing better than if one's knowledge were unbiased. Since evolutionary success is ultimately determined by the quality of decisions and actions that we make, rather than the accuracy of their underlying beliefs, this dissociation between epistemic and instrumental accuracy provides a compelling explanation for the prevalence of cognitive biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion: applying reinforcement learning</head><p>Reinforcement learning is a powerful cognitive process with recognized potential as a strategy to correct and enhance decision-making. As a fundamental component of behavioral analysis -the applied branch of Skinner's behaviorism, aimed at promoting behavioral change through learning. It has been widely applied in therapeutic and educational contexts (although its principles are often applied implicitly or incompletely, leaving considerable room for improvements) <ref type="bibr" target="#b70">(Pierce &amp; Cheney, 2017</ref>. An additional testament to the power of RL-inspired techniques is their routine use in marketing to increase user engagement and by gambling institutions, sometimes leading to maladaptive behaviors akin to behavioral addiction <ref type="bibr" target="#b24">(Foxall, 2001;</ref><ref type="bibr" target="#b53">Linehan et al., 2015)</ref>. Despite this, RL's proven potential as a tool for improving decision-making and acquiring skills, it remains surprisingly overlooked in the ongoing debate dominated by approaches such as "nudges" and, to a lesser extent, "boosts" <ref type="bibr" target="#b13">(da Rocha &amp; Hunziker, 2020;</ref><ref type="bibr" target="#b30">Hallsworth, 2023;</ref><ref type="bibr" target="#b39">Hertwig &amp; Grüne-Yanoff, 2017;</ref><ref type="bibr" target="#b88">Tagliabue, 2023)</ref>. We believe this is at least partly due to the long-standing misconceptions associated with behaviorism in psychology, ranging from the incorrect belief that it is epistemologically flawed to the perception that it is not humane <ref type="bibr" target="#b47">(Leahey, 1992;</ref><ref type="bibr">J. Staddon, 1993</ref><ref type="bibr" target="#b85">J. Staddon, , 2014</ref>.</p><p>However, it is crucial to recognize the comparative advantages and disadvantages of reinforcement learning-based interventions compared to traditional nudges. Unlike nudges, which focus on modifying the choice architecture <ref type="table">(Table 2)</ref>, RL-based strategies modify the learning architecture, which will generally result in slower and more resource-intensive interventions. However, the trade-off is that RL-based intervention will result in longer-lasting effects, making them more valuable for promoting sustained behavioral change. Furthermore, while nudges are inherently limited in their ability to generalize by design, RL-based interventions have the potential for broader applicability, as generalization is a core feature of reinforcement learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nudging</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Applied behavioral analysis</head><p>Underlying framework Heuristic and biases Reinforcement learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Focus</head><p>Antecedent of decisions (choice architecture)</p><p>Consequences of decisions (learning architecture)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Role of learning No Yes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Duration of the effect Short Long</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalizability of the effect No Yes</head><p>Cost of the intervention Low Low to High <ref type="table">Table 2</ref>. Main approaches to improve decision-making based on behavior sciences. Underlying framework refers to the scientific tradition upon which the framework is based. Learning is central to "applied behavioral analysis" (name given by Skinner to the reinforcement learning-based interventions) and not leveraged by "nudges", whose effect disappears as soon as the choice architecture is reverted back to "normal". For this reason (lack of learning) the effect of "nudges" is short lived and, since it's not associated to the acquisition of a new skills, does not generalize.</p><p>Beyond shaping decisions in desirable directions, RL could also serve as a valuable tool for teaching abstract information in a direct, engaging, and effective manner. A great example is that of RL widespread use in language-learning apps where learners earn points, badges, and streaks for completing lessons (Laura De La <ref type="bibr" target="#b45">Cruz et al., 2023)</ref>. These features provide positive reinforcement, which helps sustain motivation and encourages continued engagement. This same principle could be applied to address critical societal challenges rooted in widespread misconceptions such as those surrounding migration or climate change 1 . Traditional approaches to correcting these beliefs often rely on presenting abstract information. However, RL-based training offers a potentially more effective alternative by shifting from top-down teaching to a feedback-driven, bottom-up learning experience.</p><p>Of course, as with any behavioral science-based intervention, ethical considerations are in order.</p><p>In the context of RL-based strategies, it is essential to prioritize the use of rewards over punishments. This is not only more ethically sound but also leads to more robust and sustainable results. Punishments, while effective at suppressing specific actions, fail to guide individuals toward desirable alternatives and may even produce unintended or undesirable behaviors <ref type="bibr" target="#b18">(Eysenck, 2013;</ref><ref type="bibr" target="#b82">Solomon, 1964)</ref>. By emphasizing rewards, RL-based interventions can achieve their goals in a manner that is both effective and ethically responsible. When developing and implementing RL-based interventions, it is crucial to consider the findings reviewed here, particularly those concerning epistemic biases. Assuming that humans process feedback in an unbiased manner can lead to flawed conclusions and ineffective interventions. Moreover, the reviewed results raise new ethical concerns, especially the demonstrated dissociation between epistemic and instrumental accuracy. While biased knowledge can, in many situations, lead to better decisions, would it be acceptable to deliberately induce biased or "wrong" knowledge to improve decision-making outcomes? This question demands careful consideration to balance the benefits of improved instrumental accuracy with the ethical implications of distorting epistemic accuracy.</p><p>Another critical consideration is that, in many real-world scenarios-particularly those involving communication-epistemic accuracy may be as important as instrumental accuracy. For example, in situations where individuals need to not only act based on the value of an option but also communicate their reasoning or justify their choices, biased knowledge could have negative consequences. Addressing this balance will be essential for the responsible application of RLbased strategies.</p><p>Finally, a major challenge for scaling RL-based interventions lies in understanding how findings on epistemic biases from controlled laboratory settings translate to complex ecological environments. In the case of contextual effects, laboratory studies often treat "context" as a clearly defined variable. In real-world environments however, defining what constitutes a context becomes far more complex as spatial and temporal contextual factors often overlap and extend across multiple scales.</p><p>As for positivity bias, it has been predominantly studied in individual scenarios where a single person interacts with their environment. However, real-world decision-making often involves social interactions of multiple nature (e.g., cooperation, competition). These social components play a big role in shaping behaviors and outcomes, yet their interaction positivity bias remains underexplored. Investigating how positivity bias manifests in social contexts will be critical for understanding its broader implications and leveraging it effectively in practical applications <ref type="bibr" target="#b6">(Bergerot et al., 2024;</ref><ref type="bibr" target="#b49">Lefebvre et al., 2024;</ref><ref type="bibr" target="#b59">Najar et al., 2020;</ref><ref type="bibr" target="#b77">Schultner et al., 2024;</ref><ref type="bibr" target="#b90">Witt et al., 2024)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure</head><label></label><figDesc>Figure 1: information processing-based illustration of noise and bias within cognitive processes, whose goal is to transform an objective value (input) into a subjective one (output). (A) Noiseless and unbiased process. (B) Noisy and unbiased process. In the simulation we used a Gaussian noise, with a mean of zero and a variance proportion to the value of the objective variable (Weber's law) (C) Noiseless and biased process. In the simulation, the cognitive process overestimates the value of the objective variable in the lower range and underestimates it in mid/high range. (D) Noisy and biased process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>a box-and-arrow representation of a reinforcement learning agent. (A) Options, actions and outcomes are observables (i.e., in the environment), option values are latent variable (i.e., internal to the agent). The agent interfaces with the environment in at least three main aspects: options recognition, action emission and outcome integration. (B) Praxic biases: the actions do not match the internal representations of values (e.g., because of the interference of another decision-making system). (C) Epistemic biases: the internal representations of value do not match the experienced outcomes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure 3: two epistemic biases of human reinforcement learning with their key equations mapped into the reinforcement learning agent. The first step is represented by subjective outcome encoding (relative valuation), the second one the error prediction error calculation, the third one by value update and, finally, the last one by action selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Relation between subjective values and objective after range normalization in different contexts. The figure shows how relative value encoding can distort subjective value of options as a function of different learning architectures (i.e., contexts). In all cases the hypothetical agent is represented with four options with increasing expected values (A,B,C and D). The three columns represent three different scenarios where the option values have been learned from different learning architectures (i.e., different contexts). (A) The values of the four options were learned within the same context. In this case objective (absolute) and subjective (relative) value representation coincide. (B) and (C) The values of the four options were learned in different contexts (AB vs CD or AC vs. BD). In this cases objective (absolute) and subjective (relative) value representation do not coincide.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>From unbiased and noiseless update to biased and noise update. The figure illustrates, in a way similar to that used in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>(A)  performance of an unbiased model (blue) and a model featuring range normalization (red) in bandits task featuring a large range of outcome magnitudes (x-axis).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://impactco2.fr/outils/quiz</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparing experience-and description-based economic preferences across 11 countries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Anlló</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benmarrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bonagura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cerrotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cicue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gueguen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kadieva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lukumon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sartorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Zinchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Silva Concha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Konova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-024-01894-9</idno>
		<ptr target="https://doi.org/10.1038/s41562-024-01894-9" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1554" to="1567" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hope and optimism as related to life satisfaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Eng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Frisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename></persName>
		</author>
		<idno type="DOI">10.1080/17439760701409546</idno>
		<ptr target="https://doi.org/10.1080/17439760701409546" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Positive Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="168" to="175" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reference-point centering and rangeadaptation enhance human reinforcement learning at the cost of irrational preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khamassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coricelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-018-06781-2</idno>
		<ptr target="https://doi.org/10.1038/s41467-018-06781-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4503</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The functional form of value normalization in human reinforcement learning. eLife, 12, e83891</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.83891</idno>
		<ptr target="https://doi.org/10.7554/eLife.83891" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Does the notion of intrinsic reward explain context-dependent valuation in reinforcement learning? OSF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/23ng4</idno>
		<ptr target="https://doi.org/10.31234/osf.io/23ng4" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Two sides of the same coin: Beneficial and detrimental consequences of range adaptation in human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1126/sciadv.abe0340</idno>
		<ptr target="https://doi.org/10.1126/sciadv.abe0340" />
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Moderate confirmation bias enhances decision-making in groups of reinforcement-learning agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bergerot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Barfuss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Romanczuk</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1012404</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1012404" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Three examples of bidirectional space-time interference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bratzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ebbinghaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ponzo</forename><surname>Müller-Lyer</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-024-02491-7</idno>
		<ptr target="https://doi.org/10.3758/s13423-024-02491-7" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2285" to="2292" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Operant conditioning in invertebrates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brembs</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2003.10.002</idno>
		<ptr target="https://doi.org/10.1016/j.conb.2003.10.002" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="710" to="717" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The bias bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbusres.2015.01.061</idno>
		<ptr target="https://doi.org/10.1016/j.jbusres.2015.01.061" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1772" to="1784" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Prospect Theory In The Wild: Evidence From The Field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Camerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Behavioral Economics</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive properties of differential learning rates for positive and negative outcomes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Cazé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A A</forename><surname>Van Der Meer</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00422-013-0571-5</idno>
		<ptr target="https://doi.org/10.1007/s00422-013-0571-5" />
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="711" to="719" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Information about action outcomes differentially affects learning from self-determined versus imposed choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Théro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vandendriessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haggard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-020-0919-5</idno>
		<ptr target="https://doi.org/10.1038/s41562-020-0919-5" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1067" to="1079" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A Behavior-Analytic View on Nudges: Individual, Technique, and Ethics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A A</forename><surname>Da Rocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H L</forename><surname>Hunziker</surname></persName>
		</author>
		<idno type="DOI">10.1007/s42822-020-00037-9</idno>
		<ptr target="https://doi.org/10.1007/s42822-020-00037-9" />
		<imprint>
			<date type="published" when="2020" />
			<publisher>Behavior and Social Issues</publisher>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="138" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Psychology and Economics: Evidence from the Field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dellavigna</surname></persName>
		</author>
		<idno type="DOI">10.1257/jel.47.2.315</idno>
		<ptr target="https://doi.org/10.1257/jel.47.2.315" />
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Literature</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="315" to="372" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Happiness is the Frequency, Not the Intensity, of Positive Versus Negative Affect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Diener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sandvik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pavot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Assessing Well-Being: The Collected Works of Ed Diener</title>
		<editor>E. Diener</editor>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="213" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer Netherlands</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-90-481-2354-4_10</idno>
		<ptr target="https://doi.org/10.1007/978-90-481-2354-4_10" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Experiments in Behaviour Therapy: Readings in Modern Methods of Treatment of Mental Disorders Derived from Learning Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Eysenck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Noise in the nervous system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Faisal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P J</forename><surname>Selen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Wolpert</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn2258</idno>
		<ptr target="https://doi.org/10.1038/nrn2258" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="292" to="303" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Flexible combination of reward information across primates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farashahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Y</forename><surname>Hayden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soltani</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0714-3</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0714-3" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1215" to="1224" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Computational noise in reward-guided learning drives behavioral variability in volatile environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Findling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Skvortsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dromnelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41593-019-0518-9</idno>
		<ptr target="https://doi.org/10.1038/s41593-019-0518-9" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2066" to="2077" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Incentive relativity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Flaherty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<pubPlace>Cambridge [England</pubPlace>
		</imprint>
	</monogr>
	<note>with Internet Archive</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Separate neural representations of prediction error valence and surprise: Evidence from an fMRI meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fouragnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Retzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Philiastides</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.24047</idno>
		<ptr target="https://doi.org/10.1002/hbm.24047" />
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2887" to="2906" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Foundations of Consumer Behaviour Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Foxall</surname></persName>
		</author>
		<idno type="DOI">10.1177/147059310100100202</idno>
		<ptr target="https://doi.org/10.1177/147059310100100202" />
	</analytic>
	<monogr>
		<title level="j">Marketing Theory</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="165" to="199" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">By Carrot or by Stick: Cognitive Reinforcement Learning in Parkinsonism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Seeberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Reilly</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1102941</idno>
		<ptr target="https://doi.org/10.1126/science.1102941" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">306</biblScope>
			<biblScope unit="issue">5703</biblScope>
			<biblScope unit="page" from="1940" to="1943" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Impaired adaptation of learning to contingency volatility in internalizing psychopathology. eLife, 9</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gagne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Zika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Bishop</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.61387</idno>
		<ptr target="https://doi.org/10.7554/eLife.61387" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">An Evolutionary Justification for Overconfidence (SSRN Scholarly Paper No. 3026885). Social Science Research Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.3026885</idno>
		<ptr target="https://doi.org/10.2139/ssrn.3026885" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to Be Overconfident</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gervais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Odean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Review of Financial Studies</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Heuristic Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-120709-145346</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-120709-145346" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="451" to="482" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A manifesto for applying behavioural science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hallsworth</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01555-3</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01555-3" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="310" to="322" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Haselton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wilke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Frederick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galperin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Frankenhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adaptive Rationality: An Evolutionary Perspective on Cognitive Bias</title>
		<idno type="DOI">10.1521/soco.2009.27.5.733</idno>
		<ptr target="https://doi.org/10.1521/soco.2009.27.5.733" />
	</analytic>
	<monogr>
		<title level="j">Social Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="733" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The Evolution of Cognitive Bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Haselton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nettle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Andrews</surname></persName>
		</author>
		<idno type="DOI">10.1002/9780470939376.ch25</idno>
		<ptr target="https://doi.org/10.1002/9780470939376.ch25" />
	</analytic>
	<monogr>
		<title level="m">The Handbook of Evolutionary Psychology</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="724" to="746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Effects of blocked versus interleaved training on relative value learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Wedell</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-023-02290-6</idno>
		<ptr target="https://doi.org/10.3758/s13423-023-02290-6" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1895" to="1907" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Testing models of context-dependent outcome encoding in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Wedell</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2022.105280</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2022.105280" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">230</biblScope>
			<biblScope unit="page">105280</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Large Language Models are Biased Reinforcement Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2405.11422</idno>
		<idno type="arXiv">arXiv:2405.11422</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2405.11422" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A comparison of reinforcement learning models of human spatial navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Eschapasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Beveridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">I</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-18245-1</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-18245-1" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">13923</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">On the Evolutionary Emergence of Optimism (SSRN Scholarly Paper No. 247355). Social Science Research Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heifetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Spiegel</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.247355</idno>
		<ptr target="https://doi.org/10.2139/ssrn.247355" />
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Nudging and Boosting: Steering or Empowering Good Decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Grüne-Yanoff</surname></persName>
		</author>
		<idno type="DOI">10.1177/1745691617702496</idno>
		<ptr target="https://doi.org/10.1177/1745691617702496" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="973" to="986" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Studies in Ecological Rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leuker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pachur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Spiliopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
		</author>
		<idno type="DOI">10.1111/tops.12567</idno>
		<ptr target="https://doi.org/10.1111/tops.12567" />
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="467" to="491" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Evolving choice hysteresis in reinforcement learning: Comparing the adaptive value of positivity bias and gradual perseveration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hoxha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sperber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2410.19434</idno>
		<idno type="arXiv">arXiv:2410.19434</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2410.19434" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Primer on Reinforcement Learning in Medicine for Clinicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Desman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabounchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Nadkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sakhuja</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-024-01316-0</idno>
		<ptr target="https://doi.org/10.1038/s41746-024-01316-0" />
	</analytic>
	<monogr>
		<title level="j">Npj Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Prospect Theory: An Analysis of Decision under Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<idno type="DOI">10.2307/1914185</idno>
		<ptr target="https://doi.org/10.2307/1914185" />
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="291" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Epistemic Rationality as Instrumental Rationality: A Critique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kelly</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1933-1592.2003.tb00281.x</idno>
		<ptr target="https://doi.org/10.1111/j.1933-1592.2003.tb00281.x" />
	</analytic>
	<monogr>
		<title level="j">Philosophy and Phenomenological Research</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="612" to="640" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Use of gamification in English learning in Higher Education: A systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura De La</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Noa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Turpo Gebera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">W</forename><surname>Valencia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Milagritos Bazán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Velasquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Postigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOTSE</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="480" to="497" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The Classical Conditioning Paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lavond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Steinmetz</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4615-0263-0_1</idno>
		<ptr target="https://doi.org/10.1007/978-1-4615-0263-0_1" />
	</analytic>
	<monogr>
		<title level="m">Handbook of Classical Conditioning</title>
		<editor>D. G. Lavond &amp; J. E. Steinmetz</editor>
		<imprint>
			<publisher>Springer US</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The mythical revolutions of American psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Leahey</surname></persName>
		</author>
		<idno type="DOI">10.1037/0003-066X.47.2.308</idno>
		<ptr target="https://doi.org/10.1037/0003-066X.47.2.308" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="308" to="318" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">The human as delta-rule learner. Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Kable</surname></persName>
		</author>
		<idno type="DOI">10.1037/dec0000112</idno>
		<ptr target="https://doi.org/10.1037/dec0000112" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="55" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The roots of polarization in the individual reward system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Deroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<idno type="DOI">10.1098/rspb.2023.2011</idno>
		<ptr target="https://doi.org/10.1098/rspb.2023.2011" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="page">20232011</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A Normative Account of Confirmation Bias During Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco_a_01455</idno>
		<ptr target="https://doi.org/10.1162/neco_a_01455" />
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="307" to="337" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Achieving Scale-Invariant Reinforcement Learning Performance with Reward Range Normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>L'hôtellier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/bjyr9</idno>
		<ptr target="https://doi.org/10.31234/osf.io/bjyr9" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A computational reward learning account of social media engagement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lindström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bellander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Schultner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Tobler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Amodio</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-020-19607-x</idno>
		<ptr target="https://doi.org/10.1038/s41467-020-19607-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1311</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Linehan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kirman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roche</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/9788.003.0006</idno>
		<ptr target="https://doi.org/10.7551/mitpress/9788.003.0006" />
		<title level="m">Gamification as Behavioral Psychology</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Prediction error estimation methods. Circuits, Systems and Signal Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ljung</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01211648</idno>
		<ptr target="https://doi.org/10.1007/BF01211648" />
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="11" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Individual choice behavior: A theoretical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<ptr target="https://search.ebscohost.com/direct.asp?db=pzh&amp;jid=%22201344649%22&amp;scope=site" />
		<imprint>
			<date type="published" when="2005" />
			<publisher>Dover Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Mesoscale effects of trader learning behaviors in financial markets: A multi-agent reinforcement learning study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lussange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vrizzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gutkin</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0301141</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0301141" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature14236</idno>
		<ptr target="https://doi.org/10.1038/nature14236" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Reward Centering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=i4eDGZFcva" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The actions of others act as a pseudo-reward to drive imitation in the context of social reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Najar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pbio.3001028</idno>
		<ptr target="https://doi.org/10.1371/journal.pbio.3001028" />
	</analytic>
	<monogr>
		<title level="j">PLOS Biology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Dialogues on prediction errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schoenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2008.03.006</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2008.03.006" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="265" to="272" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The asymmetric learning rates of murine exploratory behavior in sparse reward environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Satori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takarada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ishizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Morimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Takahashi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neunet.2021.05.030</idno>
		<ptr target="https://doi.org/10.1016/j.neunet.2021.05.030" />
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="218" to="229" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Contextual modulation of value signals in reward and punishment learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khamassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joffily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coricelli</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms9096</idno>
		<ptr target="https://doi.org/10.1038/ncomms9096" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">8096</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Context-dependent outcome encoding in human reinforcement learning. Current Opinion in Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2021.06.006</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2021.06.006" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="144" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The computational roots of positivity and confirmation biases in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2022.04.005</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2022.04.005" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="607" to="621" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Worbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lehéricy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vidailhet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grabli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pessiglione</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Dopamine-dependent reinforcement of motor skill learning: Evidence from Gilles de la Tourette syndrome</title>
		<idno type="DOI">10.1093/brain/awr147</idno>
		<ptr target="https://doi.org/10.1093/brain/awr147" />
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2287" to="2301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Kilford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-J</forename><surname>Blakemore</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1005684</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1005684" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Chapter 23 -Opponent Brain Systems for Reward and Punishment Learning: Causal Evidence From Drug and Lesion Studies in Humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pessiglione</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-0-12-805308-9.00023-3</idno>
		<ptr target="https://doi.org/10.1016/B978-0-12-805308-9.00023-3" />
	</analytic>
	<monogr>
		<title level="m">Decision Neuroscience</title>
		<editor>J.-C. Dreher &amp; L. Tremblay</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="291" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Value Judgments: Toward a Relational Theory of Happiness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parducci</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4613-8251-5_1</idno>
		<ptr target="https://doi.org/10.1007/978-1-4613-8251-5_1" />
	</analytic>
	<monogr>
		<title level="m">Attitudinal Judgment</title>
		<editor>J. R. Eiser</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="3" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Behavior Analysis and Learning: A Biobehavioral Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Cheney</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315200682</idno>
		<ptr target="https://doi.org/10.4324/9781315200682" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Sixth Edition. 6th ed.</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Context-dependent utility overrides absolute memory as a determinant of choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pompilio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kacelnik</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0907250107</idno>
		<ptr target="https://doi.org/10.1073/pnas.0907250107" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="508" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Associations in Pavlovian conditioned inhibition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rescorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Holland</surname></persName>
		</author>
		<idno type="DOI">10.1016/0023-9690(77)90044-3</idno>
		<ptr target="https://doi.org/10.1016/0023-9690(77)90044-3" />
	</analytic>
	<monogr>
		<title level="j">Learning and Motivation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="429" to="447" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Adaptive Coding is Optimal in Reinforcement Learning (SSRN Scholarly Paper No. 4320894). Social Science Research Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soukupova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4320894</idno>
		<ptr target="https://doi.org/10.2139/ssrn.4320894" />
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Linking confidence biases to reinforcement-learning processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Salem-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000424</idno>
		<ptr target="https://doi.org/10.1037/rev0000424" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1017" to="1043" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Spicer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>León-Villagrá</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Falbén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<ptr target="https://wrap.warwick.ac.uk/id/eprint/185516/" />
		<title level="m">Noise in cognition: Bug or feature? Perspectives on Psychological Science</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.03969</idno>
		<idno type="arXiv">arXiv:2402.03969</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.03969" />
		<title level="m">-context learning agents are asymmetric belief updaters</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Transmission of social bias through observational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Schultner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Lindström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cikara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Amodio</surname></persName>
		</author>
		<idno type="DOI">10.1126/sciadv.adk2030</idno>
		<ptr target="https://doi.org/10.1126/sciadv.adk2030" />
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">26</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Neuronal Coding of Prediction Errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dickinson</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.neuro.23.1.473</idno>
		<ptr target="https://doi.org/10.1146/annurev.neuro.23.1.473" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="473" to="500" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Forming Beliefs: Why Valence Matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sharot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Garrett</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2015.11.002</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2015.11.002" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Exploring Causes of the Self-serving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shepperd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Malone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sweeny</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1751-9004.2008.00078.x</idno>
		<ptr target="https://doi.org/10.1111/j.1751-9004.2008.00078.x" />
	</analytic>
	<monogr>
		<title level="j">Bias. Social and Personality Psychology Compass</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="895" to="908" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Cortico-striatal contributions to feedback-based learning: Converging data from neuroimaging and neuropsychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
		<idno type="DOI">10.1093/brain/awh100</idno>
		<ptr target="https://doi.org/10.1093/brain/awh100" />
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="851" to="859" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Solomon</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0042493</idno>
		<ptr target="https://doi.org/10.1037/h0042493" />
	</analytic>
	<monogr>
		<title level="j">Punishment. American Psychologist</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="239" to="253" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Bumblebees retrieve only the ordinal ranking of foraging options when comparing memories obtained in distinct settings. eLife, 11, e78525</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Solvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chittka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.78525</idno>
		<ptr target="https://doi.org/10.7554/eLife.78525" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Context induces distortions in value representations: A test across multiple elicitation methods and learning modalities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soukupova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/yrjfaStaddon</idno>
		<ptr target="https://doi.org/10.31234/osf.io/yrjfaStaddon" />
	</analytic>
	<monogr>
		<title level="j">Behaviorism. Duckbacks</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
	<note>J.</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Staddon</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315798172</idno>
		<ptr target="https://doi.org/10.4324/9781315798172" />
		<title level="m">The New Behaviorism: Second Edition</title>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Operant Conditioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E R</forename><surname>Staddon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Cerutti</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.54.101601.145124</idno>
		<ptr target="https://doi.org/10.1146/annurev.psych.54.101601.145124" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="115" to="144" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<title level="m">Reinforcement Learning</title>
		<imprint>
			<publisher>An Introduction. MIT Press</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tagliabue</surname></persName>
		</author>
		<idno type="DOI">10.1007/s40614-021-00324-9</idno>
		<ptr target="https://doi.org/10.1007/s40614-021-00324-9" />
		<title level="m">Tutorial. A Behavioral Analysis of Rationality, Nudging, and Boosting: Implications for Policymaking. Perspectives on Behavior Science</title>
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="89" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Old strategies, new environments: Reinforcement Learning on social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Orben</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsych.2024.12.012</idno>
		<ptr target="https://doi.org/10.1016/j.biopsych.2024.12.012" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychiatry</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Humans flexibly integrate social information despite interindividual differences in reward</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Witt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Toyokawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Lala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2404928121</idno>
		<ptr target="https://doi.org/10.1073/pnas.2404928121" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">39</biblScope>
			<biblScope unit="page">2404928121</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Studying and improving reasoning in humans and machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Anlló</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44271-024-00091-8</idno>
		<ptr target="https://doi.org/10.1038/s44271-024-00091-8" />
	</analytic>
	<monogr>
		<title level="j">Communications Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">The role of hedonic processes in the organization of behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0057176</idno>
		<ptr target="https://doi.org/10.1037/h0057176" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="249" to="262" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
