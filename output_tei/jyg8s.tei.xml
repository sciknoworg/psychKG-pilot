<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Optimal Metacognitive Decision Strategies in Signal Detection Theory</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Maniscalco</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Cognitive Sciences</orgName>
								<orgName type="institution">University of California Irvine</orgName>
								<address>
									<postCode>92697</postCode>
									<settlement>Irvine</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucie</forename><surname>Charles</surname></persName>
							<email>l.charles@ucl.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Cognitive Neuroscience</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">Alexandra House</orgName>
								<address>
									<addrLine>17 Queen Square</addrLine>
									<postCode>WC1N 3AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megan</forename><forename type="middle">A K</forename><surname>Peters</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Cognitive Sciences</orgName>
								<orgName type="institution">University of California Irvine</orgName>
								<address>
									<postCode>92697</postCode>
									<settlement>Irvine</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Institute of Cognitive Neuroscience</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>Alexandra House, 17 Queen Square</addrLine>
									<postCode>WC1N 3AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Optimal Metacognitive Decision Strategies in Signal Detection Theory</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Signal detection theory (SDT) has long provided the field of psychology with a simple but powerful model of how observers make decisions under uncertainty. SDT can distinguish sensitivity from response bias and characterize optimal decision strategies. Recent work has extended SDT to quantify metacognitive sensitivity. Here we further advance the application of SDT to the study of metacognition by providing a formal account of normative metacognitive decision strategies -i.e., type 2/confidence criterion setting -for ideal observers.</p><p>Optimality is always defined relative to a given objective. We use SDT to derive formulae for optimal type 2 criteria under four distinct objectives: maximizing type 2 accuracy, maximizing type 2 reward, calibrating confidence to accuracy, and maximizing the difference between type 2 hit rate and false alarm rate. Where applicable, we consider these optimization contexts alongside their type 1 counterparts (e.g. maximizing type 1 accuracy) to deepen understanding. We examine the different strategies implied by these formulae and further consider how optimal type 2 criterion setting differs when metacognitive sensitivity deviates from SDT expectation. We also provide an online toolbox for implementing these analyses.</p><p>The theoretical framework provided here can be used to better understand the metacognitive decision strategies of real observers. Possible applications include characterizing observers' spontaneously chosen metacognitive decision strategies, assessing their ability to fine-tune metacognitive decision strategies to optimize a given outcome when instructed, determining over-or under-confidence relative to an optimal standard, and more. This framework opens new avenues for enriching our understanding of metacognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Signal detection theory (SDT) has long provided the field of psychology with a simple but powerful model of how observers make decisions under uncertainty <ref type="bibr" target="#b19">(Green &amp; Swets, 1966;</ref><ref type="bibr" target="#b27">Macmillan &amp; Creelman, 2004)</ref>. Central to SDT is the distinction between sensitivity and criterion setting. Sensitivity corresponds to an observer's overall ability to distinguish different states of the world (e.g. the visual sensitivity of detecting the presence or absence of a visual event, the memory sensitivity of discerning whether a stimulus has been encountered before or not, etc.). Criterion setting corresponds to the decision-making strategy the observer uses to convert graded and potentially ambiguous internal evidence into a definite classification (e.g. deciding to report that a visual event did indeed occur, in spite of uncertainty about its occurrence). Whereas sensitivity is constrained by various external and internal factors (e.g. in a visual task, the size, duration, and contrast of the stimulus, the observer's visual acuity and available attentional and motivational resources, etc.), criterion setting is largely under the observer's control and can be altered depending on task demands. For instance, the observer may choose to be more liberal or conservative in reporting stimulus presence depending on his or her internal bias, or what is most appropriate to the current context.</p><p>The SDT framework can be used not only to describe an observer's response strategy, but also to determine a normative strategy for how the observer should set their decision criterion depending on their goals and priorities. If the observer is trying to optimize a particular outcome measure, such as reward or accuracy, it is then possible to compute how they should set their criterion, given their particular level of sensitivity and the decision-making context. For instance, suppose the observer is performing a visual task in which they must determine on every trial whether a stimulus was presented on the left or right side of fixation. If the stimulus is considerably more likely to appear on the left and the observer wishes to maximize their probability of making correct decisions, then it is optimal for them to adopt a criterion biased towards left responses. Indeed, a criterion that requires relatively stringent standards for reporting "right" -essentially giving "left" responses the benefit of the doubt and only reporting "right" when evidence for right is particularly strong -will lead to more correct responses. The exact level of conservativeness in reporting "right" needed to optimize accuracy can be computed from the odds of stimulus location and the observer's sensitivity, as discussed below. The actual and optimal criteria can then be compared to one another in order to assess to what extent the observer's decision-making strategy deviates from the optimal strategy for maximizing accuracy.</p><p>Importantly, optimality can only ever be assessed with respect to a definite outcome measure or loss function, and the optimal strategy is therefore likely to differ for different outcome measures. We should thus never speak of "optimality" in absolute terms, but only speak of "optimality for X". For instance, in the example above, the observer chooses a criterion setting strategy that optimizes accuracy. Specifically, because stimuli frequently occur on the left side of fixation, the observer optimizes accuracy by choosing to be liberal in responding "left." However, suppose we add rewards and punishments such that the observer is now very heavily rewarded for making correct "right" responses, but only lightly rewarded for correct "left" responses. The observer may now be less interested in optimizing for accuracy than in optimizing for expected reward. Indeed, if the asymmetry in rewards is strong enough, then the optimal strategy for maximizing reward may be to be liberal in producing "right" responses, even in spite of the fact that stimuli more frequently occur on the left. In other words, what is optimal for one outcome measure (or cost function) is not necessarily optimal for another.</p><p>In addition to discriminating states of the world, the observer may also discriminate their own internal states. For instance, the observer may wish to determine not only whether the stimulus was on the left or right (a "first order" or "type 1" judgment about the world), but also whether the subjective experience of the stimulus was clear or vivid, or whether the left/right decision can be endorsed with high confidence (both being "type 2", "second-order", or "metacognitive" judgments about the nature of the observer's internal perceptual processing) . The SDT framework can be extended to type 2 1 decision-making <ref type="bibr" target="#b17">(Galvin et al., 2003;</ref><ref type="bibr" target="#b29">Maniscalco &amp; Lau, 2012</ref>. In type 2 SDT, sensitivity corresponds to how well an observer's type 2 reports (e.g. confidence or subjective clarity) discriminate between correct and incorrect type 1 decisions about the world, and criterion setting refers to the observer's strategy for producing reports of high confidence <ref type="bibr">(or clarity, etc.)</ref>. Type 2 sensitivity is constrained by various factors (including type 1 sensitivity) and extensive literature has explored how to measure it in a meaningful way <ref type="bibr" target="#b5">(Barrett et al., 2013;</ref><ref type="bibr" target="#b14">Fleming &amp; Daw, 2017;</ref><ref type="bibr" target="#b15">Fleming &amp; Lau, 2014)</ref>. Importantly, although type 2 criterion setting is a central aspect of modelling confidence judgments using signal detection theory, it remains less studied and poorly understood. In particular, it remains unclear how the demands of the decision-making context affect the confidence criterion-setting strategy for both ideal and actual observers, and to what extent actual observers' strategies resemble ideal strategies for optimizing various outcome measures of metacognitive performance.</p><p>As for type 1 decisions, it is possible to mathematically characterize the normative type 2 criterion-setting strategy an observer should adopt in order to optimize some outcome measure that depends on the confidence report. These normative strategies can then be compared to an observer's actual type 2 criterion setting behavior to characterize to what extent the observer's strategy deviates from optimality. Crucially however, normative type 2 criterion setting has not yet been formally characterized in the literature. Thus, in the present paper we explore type 2 criterion setting strategies for optimizing different second-order outcome measures. We consider four main strategies for determining the position of confidence criteria: (1) maximize the accuracy of confidence reports in discriminating correct from incorrect type 1 responses; (2) maximize the reward obtained from confidence report according to the experimental reward schedule; (3) calibrate confidence so that high confidence reports are associated with a minimal level of choice accuracy (e.g. only report "high confidence" when the choice is at least 80% likely to be correct); or (4) maximize the difference between the proportion of high confidence reports for correct vs incorrect type 1 responses. For each strategy, we provide equations defining the optimal type 2 criteria (with full derivations in the Appendix) and give visual intuitions for how these optimal criteria change with various factors such as task performance, stimulus priors, reward contingencies, etc. Where applicable, we present these equations and their derivations side-by-side with their type 1 analogues, as it is instructive to compare and contrast optimal criterion setting in the type 1 and type 2 cases. Finally, we also use simulations to explore how optimal type 2 criterion setting changes under conditions of suboptimal metacognitive sensitivity, i.e. when an observer's confidence fails to optimally track type 1 accuracy on a trial-by-trial basis. This work can inform future research that seeks to characterize type 2 criterion setting relative to optimality for various kinds of type 2 outcome measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">A Brief Primer on Type 1 and Type 2 SDT</head><p>We preface the section on optimal criterion setting with a brief primer on signal detection theory (SDT) for the unfamiliar reader. Readers well versed in SDT may wish to skip to Section 2: Optimizing Criterion Setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Type 1 and type 2 criterion in Signal Detection Theory. (A)</head><p>The standard type 1 signal detection model. The observer discriminates between two stimuli S1 and S2. Evidence generated by each stimulus is distributed normally on the decision axis (denoted as "x") and the distance between the two distributions, expressed in standard deviation units, reflects the sensitivity of the observer to discriminate between the two stimuli (d'). The observer's type 1 criterion c 1 corresponds to the signal x above which the observer will report "S2" rather than "S1". When S1 and S2 stimuli are equally probable, the criterion that maximizes decision accuracy is placed midway between the two distributions, illustrated here by a dark gray vertical line labelled c 1 . If the observer's decision criterion is shifted to the left, the observer will respond "S2" more often (black vertical line) and if the observer's decision criterion is shifted to the right, the observer will respond "S1" more often (light gray vertical line). (B) Type 1 Receiving Operating Characteristics (ROC) curve corresponding to the hit rates (p("S2" response | S2 stimulus)) and false alarm rates (p("S2" response | S1 stimulus)) for an observer with a given level of sensitivity (d') but a varying decision criterion (c 1 ). Decision criteria highlighted in (A) are also highlighted on the ROC curve to illustrate their effect on hit and false alarm rates. (C) The Type 2 signal detection model for "S2" responses. Since "S2" responses occur when x &gt; c 1 , here we consider only the portion of the graph in (A) to the right of c 1 . The observer sets a type 2 criterion c 2,"S2" ≥ c 1 (red vertical line) that separates the signal above which the observer will respond "high confidence" rather than "low confidence" for "S2" responses. If c 2,"S2" is shifted towards c 1 , the observer will respond "high confidence" more often (light red vertical line) and if c 2,"S2" is shifted away from c 1 , the observer will respond "high confidence" less often (dark red vertical line). The type 2 model for "S1" responses (not shown) follows similar principles: here the observer sets a type 2 criterion c 2,"S1" ≤ c 1 such that evidence values smaller than c 2,"S1" yield "high confidence" responses, and "low confidence" otherwise, and c 2,"S1" becomes more liberal or conservative as it is shifted closer to or farther from c 1 , respectively. (D) Type 2 ROC curve for "S2" responses, corresponding to the type 2 hit rates (p("high confidence" response | correct "S2" response)) and type 2 false alarm rates (p("high confidence" response | incorrect "S2" response)), for an observer with a given level of sensitivity (d') and type 1 decision criterion (c 1 , black vertical line) but varying confidence criterion (c 2,"S2" ). Confidence criteria highlighted in (C) are also highlighted on the type 2 ROC curve to illustrate their effect on type 2 hit and false alarm rates. Note that type 2 hit and false alarm rates can be derived from the graph in (C) after normalizing the distributions so that the area under each curve sums to 1. Similar principles hold for the construction of the type 2 ROC curve for "S1" responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.1">Type 1 SDT</head><p>In its simplest and most canonical form, SDT characterizes the task of using ambiguous evidence to make a binary classification decision about some external state of the world. The observer is modeled as making this decision by using a continuous, one-dimensional internal evidence variable x. This one-dimensional continuum forms the decision axis along which evidence is evaluated. On each trial, x takes on a single numerical value; the exact value it takes depends on both the strength of evidence (e.g. due to stimulus strength, attentional state, etc.) and stochastic processes, such that identical presentations of a stimulus on successive trials may generate different evidence values x due to random noise. SDT assumes that the distribution of evidence values generated by repeated presentations of a stimulus across trials is Gaussian, where the mean of the distribution reflects the average strength of internal evidence generated by the stimulus. Thus, in the case where one of two possible stimuli, S1 or S2, is shown on each trial, there are two Gaussian distributions, f(x|S1) and f(x|S2), corresponding to the probability density functions of evidence values contingent on presentation of S1 or S2 ( <ref type="figure">Figure 1A)</ref>. By convention, the mean of the S1 distribution is less than the mean of the S2 distribution, and is often set such that the mean of S1 is the negative of the mean of S2. For simplicity, in this paper we make a standard assumption that the standard deviations of the two distributions are equal . In the following 2 primer, we also make the additional simplifying assumption that S1 and S2 are equally likely to occur, i.e. the prior probabilities of S1 and S2 are equal unless otherwise specified. This assumption is relaxed as <ref type="bibr">2</ref> The standard assumption of equal variance across the S1 and S2 distributions is typically appropriate for two-choice and two-alternative forced choice discrimination tasks as well as two-interval forced-choice detection tasks, but not for yes-no detection tasks. Therefore, we set the variances of S1 and S2 to be equal here, with the understanding that this assumption may not be appropriate for yes-no detection tasks <ref type="bibr" target="#b22">(Kellij et al., 2020;</ref><ref type="bibr" target="#b32">Mazor et al., 2020</ref><ref type="bibr" target="#b33">Mazor et al., , 2021</ref>.</p><p>we discuss deriving optimal criterion placement for the type 1 and type 2 criteria (and their relationship) in Section 2.</p><p>Sensitivity -i.e., the observer's overall ability to distinguish between S1 and S2 -depends on the degree of overlap between the evidence distributions for S1 and S2. In cases where the distributions overlap substantially, the two stimuli generate very similar distributions of evidence, meaning that a given evidence value observed on a particular trial might be highly consistent with the presentation of either S1 or S2. Since the observer only ever has access to the evidence value generated by the stimulus on that trial and must use this to infer which stimulus was presented, such ambiguity makes the task difficult and entails the inevitability of frequent errors. By contrast, when the distributions are well-separated, then the stimuli are more easily distinguished and errors are rare. Sensitivity is quantified in SDT by the measure d', which corresponds to the number of standard deviations that separate the means of the S1 and S2 distributions. When d' = 0, the distributions overlap perfectly and the observer's performance is at the chance level of 50% correct, whereas d' values of 1, 2, and 3 correspond to accuracy rates of 69%, 84%, and 93% when the observer's responding is unbiased (see below).</p><p>It is not enough to have a graded evidence value x on a given trial; the observer must use x to make a definite decision about whether the stimulus was S1 or S2. According to SDT, the observer accomplishes this by setting a decision criterion (denoted by the variable c 1 ) at some point along the decision axis, and comparing x to c 1 in order to decide what the stimulus was on the current trial. Specifically, the observer reports "S1" whenever x &lt; c 1 , and reports "S2" otherwise . By convention, when the variances of the 3 distributions are assumed to be equal (and their prior probabilities equal and the mean of S1 is the negative of the mean of S2, as mentioned above), then x = 0 corresponds to the point on the decision axis where the distributions intersect, i.e. x = 0 is the evidence value for which S1 and S2 were equally likely to have generated x. Thus, an observer is said to have an unbiased criterion when c 1 = 0, a liberal criterion when c 1 &lt; 0, and a conservative criterion when c 1 &gt; 0 (where "liberal" and "conservative" connote the observer's propensity for reporting "S2").</p><p>An alternative formulation for the decision criterion is the likelihood ratio of the stimulus distributions β 1 , where . (Again, here it is assumed that the prior probabilities of S1 and S2 are β 1 =</p><formula xml:id="formula_0">( | 2) ( | 1) = '</formula><p>equal.) Thus, for an unbiased observer with c 1 = 0, the criterion can be expressed instead as β 1 = 1, i.e. for an unbiased observer the criterion is placed at the point on the decision axis where x is equally likely to have been generated by S1 and S2. Similarly, β 1 &lt; 1 for a liberal criterion and β 1 &gt; 1 for a conservative criterion. Expressing criterion in terms of β 1 can be mathematically elegant and conceptually useful, as we will see below.</p><p>Together, d' and c 1 determine the observer's hit rate and false alarm rate, where hit rate = HR = p(response = "S2" | stimulus = S2) and false alarm rate = FAR = p(response = "S2" | stimulus = S1). HR and FAR correspond to the areas under the f(x|S2) and f(x|S1) curves exceeding c 1 , respectively. Indeed, we infer an observer's d' and c 1 based on their empirically measured HR and FAR in a task using the equations and , where is the inverse</p><formula xml:id="formula_1">' = ( ) − ( ) 1 =− 0. 5 ( ) + ( ) [ ] (•)</formula><p>cumulative distribution function for the Gaussian distribution.</p><p>Whereas d' is constrained by properties of the stimulus, environment, and observer, c 1 is free to vary depending on the observer's decision-making strategy or bias. Thus, it is possible that the same observer discriminating the same stimuli may set different values of c 1 in different experimental conditions that encourage or reveal different criterion setting strategies, even while d' remains fixed. In this case, each experimental condition will generate a distinct pair of HR and FAR values. Plotting the HR vs FAR values against each other yields a receiver operating characteristic (ROC) curve, which reveals how HR and FAR trade off as a function of criterion setting while sensitivity is held constant ( <ref type="figure">Figure 1B)</ref>. Mathematically, the ROC curve corresponds to the infinite set of (FAR, HR) pairs that are generated for a fixed level of d' by sweeping c 1 from negative to positive infinity. The strong empirical success of SDT can essentially be framed as the remarkable ability of this very simple model to generate theoretical ROC curves that capture the forms taken by empirical ROC curves generated by human and animal observers over a wide range of tasks and circumstances <ref type="bibr" target="#b19">(Green &amp; Swets, 1966;</ref><ref type="bibr" target="#b27">Macmillan &amp; Creelman, 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.2">Type 2 SDT</head><p>Thus far we have presented the SDT model of type 1 decision making, i.e. making judgments about states of the world. It is possible to extend the SDT model to type 2 decision making, i.e. making judgments about the accuracy of one's own decision (type 1 judgments), in a fairly straightforward way. For simplicity, here we will assume that the type 2 decision amounts to deciding whether to report "high confidence" or "low confidence" in the type 1 decision . We start with a simple scenario in which we Each type 2 criterion applies only to one kind of type 1 response, and so the value of the type 2 criterion is constrained to be located on the appropriate side of the type 1 criterion c 1 . For example, since c 2,"S1" is the criterion used to evaluate confidence for "S1" responses, and since "S1" responses by definition only occur for x &lt; c 1 , then it must be the case that c 2,"S1" ≤ c 1 . By similar reasoning, c 2,"S2" ≥ c 1 .</p><p>Evidence values further away from c 1 denote stronger magnitudes of evidence supporting one response or another, and so the observer reports high confidence for "S1" responses whenever x &lt; c 2,"S1" , and similarly, high confidence for "S2" responses whenever x &gt; c 2,"S2" . Sensitivity in the type 2 task corresponds to how well the observer's type 2 responses distinguish between their own correct and incorrect type 1 responses. By analogy to the type 1 case, this type 2 sensitivity depends on how much overlap there is between the type 2 distributions of evidence, i.e. f(x|correct) and f(x|incorrect). However, we cannot simply assume that these type 2 distributions are Gaussian, as we did in the type 1 case. In fact, specifying d' and c 1 in the type 1 SDT model already determines an expected set of type 2 distributions, and these are indeed not Gaussian <ref type="bibr" target="#b17">(Galvin et al., 2003)</ref>. For instance, for simplicity let us consider "S2" responses only, i.e. the portion of the decision axis where x &gt; c 1 ( <ref type="figure">Figure 1C)</ref>. Over this region of the decision axis, by definition, the observer responds correctly whenever the true stimulus is S2, and incorrectly when it is S1. Thus, for x &gt; c 1 , the f(x|S2) and f(x|S1) distributions correspond to correct and incorrect responses, respectively . It follows that the 5 degree of overlap between the f(x|S2) and f(x|S1) distributions over the x &gt; c 1 region of the decision axis determines type 2 sensitivity for "S2" responses. Similar reasoning applies to the separate case of "S1" responses. For this reason, the SDT model predicts that type 1 d' and c 1 jointly determine type 2 sensitivity <ref type="bibr" target="#b17">(Galvin et al., 2003;</ref><ref type="bibr" target="#b29">Maniscalco &amp; Lau, 2012</ref>.</p><p>The c 2,"S2" criterion determines which x values for "S2" responses are sufficient to generate "high confidence" responses. By analogy with the type 1 case, when the type 2 criterion is applied to the type 2 distributions, it generates type 2 hit rates and false alarm rates, where type 2 hit rate = HR 2 = p(high confidence | correct) and type 2 false alarm rate = FAR 2 = p(high confidence | incorrect). For "S2" responses, HR 2 corresponds to the area under the f(x|S2) curve that exceeds c 2,"S2" (i.e. the probability of a high confidence "S2" response for the S2 stimulus) divided by the area under the f(x|S2) curve that exceeds c 1 (i.e. the overall probability of an "S2" response for the S2 stimulus). Similarly, for "S2" responses, FAR 2 corresponds to the area under the f(x|S1) curve that exceeds c 2,"S2" divided by the area under the f(x|S1) curve that exceeds c 1 . Similar reasoning applies to the separate case of "S1" responses.</p><p>For an observer with fixed type 1 and type 2 sensitivity observing a fixed set of stimuli, multiple (HR 2,"S2" , FAR 2,"S2" ) pairs can be derived by adjusting the type 2 criterion across experimental conditions . These can 6 be plotted against each other to form an empirical type 2 ROC curve for "S2" responses ( <ref type="figure">Figure 1D</ref>), which describes how HR 2,"S2" and FAR 2,"S2" trade off as a function of type 2 criterion setting for a fixed level of type 2 sensitivity. Similar reasoning applies to "S1" responses.</p><p>As discussed above, SDT predicts that type 2 evidence distributions, and thus type 2 ROC curves, are jointly determined by type 1 d' and c 1 . However, it is empirically observed that type 2 sensitivity can vary independently from type 1 sensitivity <ref type="bibr" target="#b16">(Fleming et al., 2010)</ref>, and so the simple SDT model cannot be the whole story about type 2 decision making. Nonetheless, it is theoretically useful to characterize observed type 2 sensitivity in terms of the value of d' that best characterizes a set of empirical type 2 ROC curve data, according to SDT. This is what is accomplished by the measure of type 2 sensitivity called meta-d' <ref type="bibr" target="#b29">(Maniscalco &amp; Lau, 2012</ref>. This measure allows us to estimate the metacognitive efficiency of an observer by comparing the meta-d' fitted to their type 2 ROC curves to their empirically measured d'. For an observer who is ideal according to SDT, it should be the case that meta-d' = d', i.e. empirical type 2 ROC curves should be consistent with the theoretical type 2 ROC curves derived from SDT, as predicted from the observer's d' and c 1 . If meta-d' ≠ d', this implies that the relationship between type 1 and type 2 sensitivity does not conform to SDT expectation. In most such cases meta-d' is smaller than d', which indicates suboptimal metacognitive sensitivity relative to SDT expectation. Alternatively, it has also been found that meta-d' can be greater than d' <ref type="bibr" target="#b10">(Charles et al., 2013)</ref> if time-pressure on the response is increased and participants are able to detect and correct a large proportion of their fast erroneous guesses.</p><p>One interpretation of empirical findings of suboptimal metacognitive efficiency relative to SDT expectation <ref type="bibr">(meta-d' &lt; d')</ref> is that the evidence used to form type 2 judgments is somehow degraded relative to the evidence used to form type 1 judgments. The details of such an account is still a matter of ongoing research <ref type="bibr" target="#b5">(Barrett et al., 2013;</ref><ref type="bibr" target="#b14">Fleming &amp; Daw, 2017;</ref><ref type="bibr" target="#b15">Fleming &amp; Lau, 2014)</ref>. One possibility is that additional noise corrupts type 2 distributions <ref type="bibr" target="#b31">(Maniscalco &amp; Lau, 2016;</ref><ref type="bibr" target="#b35">Peters et al., 2017;</ref><ref type="bibr" target="#b42">Shekhar &amp; Rahnev, 2021a</ref><ref type="bibr" target="#b43">, 2021b</ref>, possibly because type 2 decisions occur later in time than type 1 decisions or are constructed in downstream brain regions <ref type="bibr" target="#b31">(Maniscalco &amp; Lau, 2016;</ref><ref type="bibr" target="#b36">Pleskac &amp; Busemeyer, 2010)</ref>. In Section 2.5, we discuss how cases where meta-d' &lt; d' impact our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Optimizing criterion setting for different tasks and goals</head><p>In selecting the location for the type 1 and type 2 criteria, an observer ought to consider the goals they want to achieve. What is the quantity they want to maximize or minimize? For example, an observer might want to maximize accuracy or reward in the type 1 task. Likewise, in the type 2 task the observer might want to maximize the correspondence between confidence and accuracy, or reward contingent on confidence ratings, and so on.</p><p>In this section we discuss these scenarios, and derive the optimal placement for type 2 criteria with regards to optimal -and suboptimal -type 1 criterion placement across four outcome measures that an observer might wish to optimize. These are: (1) optimizing accuracy (both type 1 and type 2); (2) optimizing reward (both type 1 and type 2); (3) calibrating confidence to expected accuracy; and (4) maximizing the difference between hit and false alarm rates (both type 1 and type 2).</p><p>How should the observer set their type 2 criteria so as to achieve optimal outcomes? The general strategy for answering this question involves writing down an equation for the outcome measure to be optimized, and then using SDT and calculus to derive the type 2 criteria that maximize that outcome. (The strategy we employ for calibration is somewhat different, as discussed below.) The derived equations reveal how optimal type 2 criterion setting depends on factors such as prior probability of stimulus presentation (p(S2)), type 1 sensitivity (d'), type 1 criterion (c 1 ), and others.</p><p>In <ref type="figure" target="#fig_1">Figure 2</ref>, we show an initial example of optimal type 2 criterion setting under the four optimization contexts considered in this paper. These plots show how the outcome measure to be optimized varies as a function of placement of the type 2 criteria for "S1" and "S2" responses. For type 2 accuracy ( <ref type="figure" target="#fig_1">Figure  2A)</ref>, type 2 reward ( <ref type="figure" target="#fig_1">Figure 2B)</ref>, and HR 2 -FAR 2 ( <ref type="figure" target="#fig_1">Figure 2D)</ref>, the outcome measures for each response type are unimodal functions of the type 2 criteria, and the optimal type 2 criteria are the ones occurring at the maximal values of these outcome functions (denoted in red). For calibration <ref type="figure" target="#fig_1">(Figure 2C)</ref>, the optimal type 2 criteria correspond to locations on the decision axis where expected task accuracy given an evidence sample x is equal to a target level of accuracy. These plots illustrate the basic idea behind the modeling and derivation of optimal type 2 criteria in SDT as explored below. We have also specially constructed these example plots so that the optimal type 2 criteria for type 2 reward ( <ref type="figure" target="#fig_1">Figure 2B</ref>), calibration ( <ref type="figure" target="#fig_1">Figure 2C)</ref>, and HR 2 -FAR 2 ( <ref type="figure" target="#fig_1">Figure 2D)</ref> are identical, which illustrates the principle that in certain special cases, optimal type 2 criterion setting can be equivalent across different contexts. We elaborate on this idea throughout the paper.</p><p>Notation used in all derivations and presentation of results is shown in response type "S1" "S2" "S1" "S2" optimiza tion context  <ref type="table" target="#tab_0">Table 1</ref>. Notation used in derivations (see Appendix) for finding the optimal type 1 (also referred to as "first-order") and type 2 ("second-order" or "metacognitive") criteria under the four optimization contexts: accuracy, reward, calibration, and hit rate minus false alarm rate. The use of * indicates that the criterion in question is the optimal criterion under the context denoted by superscript capital letters, while the subscript of 1 or 2 indicates whether this criterion is for type 1 or type 2 decisions, respectively. Top panel shows signal distributions for an unbiased observer (c 1 = 0) with a d' = 2 and equal probability of S1 and S2 used for the simulations. Black vertical lines depict type 1 criterion c 1 ; dashed red lines depict optimal type 2 criterion (the superscript capital letter is elided for generality) for 2," 1" * "S1" responses and solid red lines depict optimal type 2 criterion for "S2" responses. (A) Type 2 2," 2" * accuracy as a function of c 2 position on the decision axis. For this unbiased observer, type 2 accuracy decreases when placing the type 2 criterion further away from the type 1 criterion, and the optimal type 2 criterion is therefore identical to the type 1 criterion. (B) Expected type 2 reward as a function of c 2 position for a reward contingency table where reporting low confidence for error trials is maximally rewarded (R CR2 = 5.37, R hit2 = 1, R miss2 = R FA2 = 0). Note that if reporting high confidence for correct trials is maximally rewarded, the optimal confidence criteria become equal to the type 1 criterion for an unbiased observer (see Section 2.2.2 for details). (C) Expected accuracy as a function of evidence sample x. If the observer wishes to report high confidence only for trials where expected accuracy exceeds some threshold p(correct 1 ) T , then they must place type 2 criteria at the locations where the function p(correct 1 |x) intersects p(correct 1 ) T . In this example the threshold p(correct 1 ) T is set equal to 0.843, which is equal to the observer's overall accuracy when d' = 2 and c 1 = 0. (D) Difference in type 2 hit and false-alarm rates as a function of c 2 position. These example plots are constructed so that the optimal type 2 criteria are the same in panels B-D, illustrating that in special cases, optimal type 2 criterion setting can be equivalent across different contexts. Specifically, when priors are equal (p(S1) = p(S2)) and the observer is unbiased (c 1 = 0), maximizing HR 2 -FAR 2 is equivalent to calibrating confidence to one's overall level of accuracy, i.e. setting p(correct 1 ) T = p(correct 1 ); in this example, both equal 0.843. In turn, calibration is equivalent to maximizing type 2 reward when the odds ratio of a correct response at the threshold level of accuracy for calibration (O T ) is equal to the relative reward quotient for maximizing reward (Q 2 ); in this example, both equal 5.37. See Sections 2.3 and 2.4.2 for further discussion of these equivalences.</p><formula xml:id="formula_2">accuracy (A) 1 * β 1 * 2," 1" * 2," 2" * β 2," 1" * β 2," 2" * reward (R) 1 * β 1 * 2," 1" * 2," 2" * β 2," 1" * β 2," 2" * calibration (C) 1 * β 1 * 2," 1" * 2," 2" * β 2," 1" * β 2," 2"</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Optimizing Accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Optimal Type 1 Criterion for Maximizing Type 1 Accuracy</head><p>Suppose an observer with sensitivity d' wishes to place the type 1 criterion c 1 so as to maximize proportion of correct responses in discriminating two stimulus classes, S1 and S2, where p(S1) and p(S2) denote the prior probabilities of S1 and S2 being presented on a given trial. As discussed above (Section 1.1.1), when p(S1) = p(S2), the optimal location for the type 1 criterion c 1 is at x = 0, or equivalently at β 1 = 1. In the more general case where p(S1) and p(S2) can differ, the placement of the criterion needs to account for these (potentially different) prior probabilities. The measure to be optimized, proportion correct, is given by</p><formula xml:id="formula_3">(1) ( ) = 2 ( ) + 1 ( ) (1 − )</formula><p>where HR = hit rate = p(response = "S2" | stimulus = S2) and FAR = false alarm rate = p(response = "S2" | stimulus = S1). The value of c 1 that maximizes type 1 accuracy (p(correct)) is given by</p><formula xml:id="formula_4">(2) 1 * = ln ( 1)<label>( 2)</label></formula><p>'</p><p>Equivalently in terms of likelihood ratio,</p><formula xml:id="formula_5">β 1 * = ( | 2) ( | 1) = ' = ( 1) ( 2)<label>(3)</label></formula><p>It is now clear why, when presentation of S1 and S2 is equally probable, the observer maximizes type 1 accuracy by setting (equivalently ), i.e. at the location at which the 1 = 1 * = 0 β 1 = β 1 * = 1 distributions intersect and evidence is equally likely to have been generated by S1 or S2 ( <ref type="figure" target="#fig_3">Figure 3A)</ref>. In this case, decisions depend only on the relative likelihoods of the evidence x under S1 and S2 -the observer responds "S2" whenever x has higher probability density for S2 than for S1 (c 1 &gt; 0 and β 1 &gt; 1), and "S1" otherwise.</p><p>When priors are imbalanced ( <ref type="figure" target="#fig_3">Figure 3B-C)</ref>, the observer must compensate by incorporating an equal and opposite imbalance in how they evaluate evidence. This is accomplished by setting the criterion at the location of the decision axis where the likelihood ratio of S2 to S1 (i.e. β 1 ) matches the prior probability ratio of S1 to S2 (Eq. 3). For instance, if S2 is half as likely to be presented as S1, then the observer should have a conservative response bias, only responding "S2" if the evidence for S2 is at least twice as strong as the evidence for S1.</p><p>This decision-making policy is consistent with Bayesian reasoning. A Bayesian observer should respond "S2" whenever S2 has the greater posterior probability, i.e. whenever , and respond "S1"</p><formula xml:id="formula_6">( 2| ) ( 1| ) &gt; 1</formula><p>otherwise. Using Bayes' rule, this ratio of posterior probabilities can be expressed as the Bayes factor, i.e.</p><p>. Substituting the Bayes factor into the inequality and rearranging</p><formula xml:id="formula_7">( 2| ) ( 1| ) = ( | 2) ( 2) ( | 1) ( 1) ( 2| ) ( 1| ) &gt; 1</formula><p>yields a policy of responding "S2" whenever , which is equivalent to the</p><formula xml:id="formula_8">( | 2) ( | 1) &gt; ( 1)<label>( 2)</label></formula><p>decision-making policy implicit in Eq. 3. Thus, the criterion setting policy for maximizing accuracy (Eqs. 2-3) can be understood intuitively as a decision policy to respond "S2" whenever S2 is the most probable stimulus given the evidence x, i.e. whenever .</p><formula xml:id="formula_9">( 2| ) ( 1| ) &gt; 1</formula><p>Derivation of the criterion that optimizes type 1 accuracy ( , Eq. 2) is provided in Appendix Section  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Optimal Type 2 Criteria for Maximizing Type 2 Accuracy</head><p>Type 2 task performance can be understood by way of analogy to the type 1 case. Just as in the type 1 task the observer must classify S1 and S2 stimuli with type 1 responses "S1" and "S2," so in the type 2 task the observer must classify correct and incorrect type 1 responses with type 2 responses "high confidence" and "low confidence."</p><p>Extending the analogy, we can consider a type 2 response to be "correct" when it is congruent with accuracy and incorrect otherwise, as summarized in <ref type="table">Table 2</ref>. For clarity and brevity, we write "correct 1 " to denote "type 1 correct" and "correct 2 " to denote "type 2 correct," and similarly for incorrect trials.</p><p>type 1 task Classification response = "S1" response = "S2"  <ref type="table">Table 2</ref>. Types of responses that can be given in type 1 and type 2 tasks. Subscripts denote the type of task.</p><p>Also by way of analogy to the type 1 case, the observer may wish to set type 2 criteria so as to maximize p(correct 2 ) -i.e., the probability that confidence reports are congruent with accuracy -where</p><formula xml:id="formula_10">(4) 2 ( ) = 1 ( ) 2 + 1 ( ) (1 − 2 )</formula><p>where HR 2 = type 2 hit rate = p(high conf | correct 1 ) and FAR 2 = type 2 false alarm rate = p(high conf | incorrect 1 ) (compare to Eq. 1).</p><p>Notably, whereas in the type 1 case the event priors p(S1) and p(S2) depend on observer-independent states of the world, in the type 2 case the event priors p(correct 1 ) and p(incorrect 1 ) are determined by the observer's type 1 task performance. As a consequence, unlike in the type 1 case where it is usually convenient for the experimenter to set p(S1) = p(S2), in the type 2 case the event priors are only equal in the special case where p(correct 1 ) = p(incorrect 1 ), i.e. when the observer's type 1 task performance is at chance. As task performance increases, so does the disparity in the type 2 event priors p(correct 1 ) and p(incorrect 1 ).</p><p>It is mathematically convenient to characterize type 2 performance separately for type 1 "S1" and "S2" responses. For "S2" responses, the observer must set the type 2 criterion for "S2" responses, c 2,"S2" , so as to maximize type 2 accuracy for "S2" responses, p(correct 2,"S2" ):</p><formula xml:id="formula_11">(5) 2," 2" ( ) = 1," 2" ( ) 2," 2" + 1," 2" ( ) 1 − 2," 2" ( )</formula><p>where correct 1,"S2" = p(correct 1 | resp = "S2"), incorrect 1,"S2" = p(incorrect 1 | resp = "S2"), HR 2,"S2" = type 2 hit rate for "S2" responses = p(high conf | correct 1,"S2" ), and FAR 2,"S2" = type 2 false alarm rate for "S2" responses = p(high conf | incorrect 1,"S2" ). The value of c 2,"S2" that maximizes p(correct 2,"S2" ) is given by</p><formula xml:id="formula_12">2," 2" * = max ln ( 1) ( 2) ' , 1 ( ) = max 1 * , 1 ( )<label>(6)</label></formula><p>Equivalently in terms of likelihood ratio,</p><formula xml:id="formula_13">β 2," 2" * = max ( 1) ( 2) , β 1 ( ) = max β 1 * , β 1 ( )<label>(7)</label></formula><p>Similarly for "S1" responses, the observer must set c 2,"S1" , so as to maximize p(correct 2,"S1" ):</p><formula xml:id="formula_14">(8) 2," 1" ( ) = 1," 1" ( ) 2," 1" + 1," 1" ( ) 1 − 2," 1" ( )</formula><p>The value of c 2,"S1" that maximizes p(correct 2,"S1" ) is given by</p><formula xml:id="formula_15">2," 1" * = min ln ( 1) ( 2) ' , 1 ( ) = min 1 * , 1 ( )<label>(9)</label></formula><p>Equivalently in terms of likelihood ratio, The left column depicts joint distribution functions f(x, S1) and f(x, S2) to better illustrate the influence of changing priors on optimal criterion setting, as discussed in the legend for <ref type="figure" target="#fig_1">Figure 2</ref>. The red shaded areas in panels A-I represent the region of the decision axis in which participants will respond "low confidence". The optimal type 2 criteria (red dashed line) and (red solid line) are shown on 2," 1" * 2," 2" * each side of the type 1 criterion c 1 (black solid line). When the type 1 criterion optimizes type 1 accuracy (i.e, ) as in (B), type 2 criteria are identical to the type 1 criterion and the observer never reports 1 = 1 * "low confidence". When the type 1 criterion is suboptimal (all panels besides B), one of the optimal type 2 criteria is equal to the optimal type 1 criterion ( ), while consistency constraints require the other 1 * type 2 criterion to be equal to the actual, suboptimal, type 1 criterion (c 1 ).</p><formula xml:id="formula_16">β 2," 1" * = min ( 1) ( 2) , β 1 ( ) = min β 1 * , β 1 ( )<label>(10)</label></formula><p>Derivations of the type 2 criteria that optimize type 2 accuracy for "S2" and "S1" responses ( and 2," 2" * via Eqs. 6 and 9, respectively) are provided in Sections A1.2.1 and A1.2.2 of the Appendix.</p><p>2," 1" * Interestingly, and are virtually identical to the criterion that optimizes type 1 accuracy,</p><formula xml:id="formula_17">2," 2" * 2," 1" * 1 * (Eq. 2).</formula><p>The only difference is in cases where the type 1 criterion is set suboptimally, thus preventing one of the type 2 criteria from equaling due to the consistency constraints that and</p><formula xml:id="formula_18">1 * 2," 2" ≥ 1</formula><p>. For instance, when p(S1) = p(S2) = 0.5 <ref type="figure" target="#fig_4">(Figure 4</ref>, top row), the optimal criterion for type 1 2," 1" ≤ accuracy is ( <ref type="figure" target="#fig_4">Figure 4B</ref>, black solid line), and the optimal type 2 criteria are also ( <ref type="figure" target="#fig_4">Figure 4A</ref>, black solid line), then the closest value to 0 that the optimal type 2 criterion for "S1" responses can achieve is due to the consistency constraint that (Figure</p><formula xml:id="formula_19">2," 1" * = 1 = − 1 2," 1" ≤ 1</formula><p>4A, red dashed line). Conversely, the optimal criterion for "S2" responses remains , and thus 2," 2" * = 0 the observer reports low confidence for "S2" responses whenever -1 ≤ x ≤ 0 (red-shaded area between black and red lines).</p><p>Similar logic can be applied in the other plots of <ref type="figure" target="#fig_4">Figure 4</ref>. Of particular interest may be cases when p(S1) and p(S2) are not equal. When p(S1) ≠ p(S2), the optimal type 1 criterion is inversely related to d' (Eq. to consistency constraints, such that one of the optimal type 2 criteria equals the optimal type 1 criterion , and the other equals the actual type 1 criterion c 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">*</head><p>Thus, provided that the observer sets the type 1 criterion optimally, i.e. so as to maximize type 1 accuracy, the observer maximizes type 2 accuracy by always reporting high confidence. If the observer sets the type 1 criterion suboptimally (e.g. c 1 = -1 when p(S1) = p(S2) as in <ref type="figure" target="#fig_4">Figure 4A</ref>), then type 2 accuracy is maximized by reporting low confidence only for evidence samples that fall between the optimal and actual type 1 criterion (e.g. evidence samples between the optimal and the actual 1 * = 0 c 1 = -1). We can understand this behavior by reference to the observation above that the criterion setting policy for optimizing type 1 accuracy (Eqs. 2-3) is equivalent to a Bayesian decision policy of responding "S2" when , and responding "S1" otherwise. Regions of the decision axis lying between the</p><formula xml:id="formula_20">( 2| ) ( 1| ) &gt; 1</formula><p>actual and optimal type 1 criteria correspond to evidence samples where this decision policy is not used, i.e. cases where the observer responds "S2" in spite of S1 being the more probable stimulus (when the actual criterion c 1 is more liberal than the optimal ), or where the observer responds "S1" in spite of 1 * S2 being more probable (when the actual criterion c 1 is more conservative than the optimal ). On such 1 * trials, the observer's classification response is actually more likely to be incorrect than correct. It follows that in order to maximize type 2 accuracy for these trials, the observer should report low confidence, since this strategy yields more type 2 correct rejections (low confidence incorrects) than the amount of type 2 hits (high confidence corrects) that could be accrued by reporting high confidence. Conversely, when the optimal response for a given evidence sample is given (all regions of the decision axis that do not lie between the actual c 1 and optimal ), then the response is more likely than not to be correct, 1 * meaning the observer should report high confidence since the expected frequency of type 2 hits from high confidence reports exceeds the expected frequency of type 2 correct rejections from low confidence reports.</p><p>In short, the optimal strategy for maximizing type 2 accuracy (Eqs. 6-7 and 9-10) is simply to report high confidence when the response is more likely than not to be correct (i.e. when the optimal type 1 response is given), and low confidence otherwise.</p><p>From this discussion, we can see that this notion of confidence rating is therefore somewhat redundant with type 1 decision making, since low confidence only indicates when a type 1 decision was made poorly (i.e. is likely to be incorrect). By contrast, in most experimental scenarios it is customary for ratings of low confidence to reflect cases where, although the decision is more likely than not to be correct, it nonetheless fails to surpass some more stringent criterion for reporting high confidence.</p><p>However, this notion of confidence rating does map very naturally onto post-decision error detection <ref type="bibr" target="#b8">(Boldt &amp; Yeung, 2015;</ref><ref type="bibr" target="#b11">Charles &amp; Yeung, 2019;</ref><ref type="bibr" target="#b47">Yeung &amp; Summerfield, 2012)</ref>, where a rating of low confidence would correspond to a report that the type 1 response was likely to be an error <ref type="bibr" target="#b8">(Boldt &amp; Yeung, 2015;</ref><ref type="bibr" target="#b11">Charles &amp; Yeung, 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Optimizing Reward</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Optimal Type 1 Criterion for Maximizing Type 1 Reward Contingencies</head><p>Instead of optimizing task accuracy, an observer might have a different goal. Suppose an observer is presented with a reward matrix defining reward "points" (this could be e.g. money for a human subject, or drops of juice for a monkey, etc.) to be won or lost depending on the observer's behavior, as follows <ref type="table" target="#tab_2">(Table 3):</ref> type 1 payoff matrix Classification response = "S1" response = "S2" For instance, R hit corresponds to the number of points awarded following a hit trial. R values can be positive (typically for hits and correct rejections), zero, or negative (typically for misses and false alarms).</p><formula xml:id="formula_21">Event stimulus = S1 R CR R FA stimulus = S2 R miss R hit</formula><p>The observer's objective is to gain as many points as possible. The measure to be optimized, expected reward, can therefore be expressed as</p><formula xml:id="formula_22">(11) ( ) = 2 ( ) ℎ + (1 − ) [ ] + 1 ( ) (1 − ) + [ ]</formula><p>with HR and FAR defined as above.</p><p>For convenience, let us define a relative reward quotient for type 1 reward, Q 1 , as</p><formula xml:id="formula_23">1 = − ( ) ℎ − ( )<label>(12)</label></formula><p>The value of c 1 that maximizes E(reward) is given by</p><formula xml:id="formula_24">1 * = ln ( 1) ( 2) +ln 1 ' = 1 * + ln 1 '<label>(13)</label></formula><p>Equivalently in terms of likelihood ratio,</p><formula xml:id="formula_25">β 1 * = ( 1) ( 2) 1 = β 1 * 1 (14)</formula><p>Thus, the criterion for maximizing expected reward (Eqs. 13 and 14) is similar to the criterion for maximizing type 1 accuracy (Eqs. 2-3), but with an added term Q 1 (Eq. 12) that summarizes the relative balance of all possible type 1 reward outcomes.</p><p>The numerator of Q 1 , (R CR -R FA ), measures the relative reward for a correct vs an incorrect response when an S1 stimulus is shown. As this quantity increases, the optimal criterion becomes more conservative (Eq. 13) in order to make correct responses to S1 stimuli more likely and thereby reap the associated rewards. Conversely, the denominator of Q 1 , (R hit -R miss ), measures the relative reward for a correct vs an incorrect response when an S2 stimulus is shown. This quantity acts as a counterbalancing force in the criterion setting process, where increases tend to make the optimal criterion more liberal in order to increase reward from correct vs incorrect responses to S2 stimuli.</p><p>When stimulus priors are unequal (i.e., p(S1) ≠ p(S2)), Eq. 13 describes how consideration of stimulus priors trades off with consideration of reward contingencies. For instance, if S2 stimuli are twice as likely to occur as S1 stimuli, this would tend to make the optimal criterion more liberal to increase the frequency of "S2" responses. However, this consideration could be modulated or even overturned if the relative reward quotient Q 1 favors "S1" responses strongly enough. For instance, if correct vs incorrect trials are rewarded three times as strongly for S1 stimuli (i.e. Q 1 = 3), then the optimal criterion would actually be conservative, favoring "S1" responses in spite of S2 stimuli occurring twice as often (i.e.</p><p>).</p><p>( <ref type="formula" target="#formula_32">1)</ref>( 2) = 1 2</p><p>In the special case where (R CR -R FA ) = (R hit -R miss ), the effects of relative reward contingencies for S1 and S2 stimuli cancel out and optimal criterion setting reduces to considering only the stimulus priors (Eqs. 2-3).</p><p>Note that the optimal criterion is undefined when (R CR -R FA ) = 0 or (R hit -R miss ) = 0. This is intuitive, since e.g. if (R CR -R FA ) = 0 and (R hit -R miss ) &gt; 0 this implies that S1 stimuli have no reward consequences, and the observer should always respond "S2" to maximize reward (i.e. optimal ). The optimal criterion</p><formula xml:id="formula_26">1 * =− ∞</formula><p>is also undefined when Q 1 &lt; 0. This is also intuitive, as this corresponds to a case where incorrect 1 * trials are rewarded more than correct trials for one stimulus type but not the other, which precludes formulation of a rational decision strategy.</p><p>Derivation of (Eq. 13) is provided in Appendix Section A.2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">*</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Optimal Type 2 Criteria for Maximizing Type 2 Reward Contingencies</head><p>It is possible that reward depends not only on type 1 performance (i.e. whether a response is a hit, miss, correct rejection, or false alarm), but also type 2 performance (i.e. whether those type 1 responses are endorsed with high or low confidence). This gives a type 2 payoff matrix , as follows <ref type="table" target="#tab_4">(Table 4)</ref>  R hit2 , R FA2 , R CR2 , and R miss2 correspond to the number of points following type 2 hits (high confidence corrects), type 2 false alarms (high confidence incorrects), type 2 correct rejections (low confidence incorrects), and type 2 misses (low confidence corrects). R values can be positive (typically for type 2 hits and correct rejections), zero, or negative (typically for type 2 misses and false alarms).</p><p>Let us call reward in such a task reward 2 to denote that it depends on type 2 performance <ref type="table" target="#tab_4">(Table 4)</ref>, as contrasted to reward under a payoff matrix that only depends on type 1 performance ( <ref type="table" target="#tab_2">Table 3)</ref>. For "S2" responses, the observer must set the type 2 criterion so as to maximize E(reward 2,"S2" ):</p><formula xml:id="formula_27">2," 2" 2," 2" ( ) = ℎ 1 , |" 2" ( ) 2 + ℎ 1 , |" 2" ( ) ℎ 2 + 1 , |" 2" ( ) 2 + 1 , |" 2" ( ) 2<label>(15)</label></formula><p>For convenience, let us define a relative reward quotient for type 2 reward, Q 2 , as</p><formula xml:id="formula_28">2 = 2 − 2 ( ) ℎ 2 − 2 ( )<label>(16)</label></formula><p>The value of c 2,"S2" that maximizes E(reward 2,"S2" ) is given by</p><formula xml:id="formula_29">2," 2" * = max ln ( 1) ( 2) + ln 2 ' , 1 ( ) = max 1 * + ln 2 ' , 1 ( )<label>(17)</label></formula><p>Equivalently in terms of likelihood ratio,</p><formula xml:id="formula_30">β 2," 2" * = max ( 1) ( 2) 2 , β 1 ( ) = max β 1 * 2 , β 1 ( )<label>(18)</label></formula><p>Similarly for "S1" responses, the observer must set c 2,"S1" , so as to maximize E(reward 2,"S1" ):</p><formula xml:id="formula_31">2," 1" ( ) = 1 , |" 1" ( ) 2 + 1 , |" 1" ( ) ℎ 2 + 1 , |" 1" ( ) 2 + 1 , |" 1" ( ) 2 (19)</formula><p>The value of c 2,"S1" that maximizes E(reward 2,"S1" ) is given by</p><formula xml:id="formula_32">1," 2" * = min ln ( 1) ( 2) +ln 1 2 ' , 1 ( ) = min 1 * − ln 2 '<label>, 1 ( ) (20)</label></formula><p>Equivalently in terms of likelihood ratio,</p><formula xml:id="formula_33">β 2," 1" * = min ( 1) ( 2) 1 2 , β 1 ( ) = min β 1 * 1 2 , β 1 ( )<label>(21)</label></formula><p>Derivations of the type 2 criteria that optimize type 2 reward for "S2" and "S1" responses ( and (reward 2 , see main text), according to type 1 d' (x-axis) for different relative reward quotients Q 2 (Eq. 16; rows) and different type 1 criteria (columns). The red shaded areas represent the zone in which an observer will report low confidence. The optimal type 2 criteria (red dashed line) and (red 2," 1" * 2," 2" * solid line) are shown on each side of the type 1 criterion c 1 (black solid line). When Q 2 &lt; 1 (A-C), pursuit of high confidence corrects is incentivized more than avoidance of high confidence errors, leading to a liberal bias in type 2 criterion setting. When Q 2 = 1 (D-F), there is equal incentive to pursue high confidence corrects and avoid high confidence errors, and optimal type 2 criterion setting reduces to optimizing type 2 accuracy. When Q 2 &gt; 1 (G-I), avoidance of high confidence errors is more strongly incentivized, leading to a conservative bias in type 2 criterion setting.</p><p>Thus, the type 2 criteria for maximizing expected type 2 reward ( and , Eqs. 17 and 20) are 2," 2" * 2," 1" * similar to the type 2 criteria for maximizing type 2 accuracy ( and , Eqs. 6 and 9), but with an 2," 2" * 2," 1" * added term Q 2 (Eq. 16) that summarizes the relative balance of all possible type 2 reward outcomes. The numerator of Q 2 , (R CR2 -R FA2 ), measures the relative reward for low vs high confidence when the classification response is incorrect, whereas the denominator (R hit2 -R miss2 ) measures relative reward for high vs low confidence when the response is correct. Thus, Q 2 quantifies the tradeoff in reward for avoiding high confidence errors (numerator) vs pursuing high confidence correct responses (denominator).</p><p>As the numerator (R CR2 -R FA2 ) increases, the observer is increasingly rewarded for avoiding high confidence errors. This incentivizes the observer to set type 2 criteria more conservatively, i.e. farther away from the type 1 criterion. Numerically, this conservative bias manifests as an increase in the type 2 criterion for "S2" responses (Eq. 16) and as a decrease in the type 2 criterion for "S1" responses (Eq. 19).</p><p>Conversely, as the denominator (R hit2 -R miss2 ) increases, the observer is increasingly rewarded for pursuing high confidence correct responses. However, in many instances such incentives may turn out to be superfluous due to consistency constraints on type 2 criterion setting for "S1" and "S2" responses. For instance, suppose the observer sets their type 1 criterion optimally for maximizing type 1 accuracy, i.e.</p><p>. Further suppose that the observer is incentivized to emphasize pursuit of high confidence 1 = 1 * correct responses more than avoidance of high confidence errors, i.e. Q 2 &lt; 1, which entails ln(Q 2 ) &lt; 0. It follows from Eq. 16 that Q 2 incentivizes the observer to set their type 2 criterion for "S2" responses ( ) to a value lower than . Consistency constraints forbid this, meaning the observer should set 2," 2" * 1 * = and thus always report high confidence for "S2" responses (as well as "S1" responses by 2," 2" * 1 * similar reasoning) in order to maximize type 2 reward.</p><p>More generally, when pursuit of high confidence corrects is incentivized by setting Q 2 &lt; 1, the optimal type 2 criteria for maximizing reward behave similarly to the case of optimizing type 2 accuracy. This is trivial in the case where the type 1 criterion is optimal, as the ideal observer maximizes type 2 reward by always reporting high confidence. Recall that when the type 1 criterion is suboptimal, then the ideal observer seeking to maximize type 2 accuracy reports low confidence on the region of the decision axis between the actual and optimal type 1 criteria <ref type="figure" target="#fig_4">(Figure 4)</ref>. The ideal observer seeking to maximize type 2 reward when Q 2 &lt; 1 behaves similarly, with the exception that this region of low confidence is smaller (and potentially non-existent) due to reward-based incentives to be more liberal in reporting high confidence. Thus, for the case of optimizing type 2 reward, the behavior of the ideal observer is more interesting when incentivized to avoid high confidence errors (Q 2 &gt; 1, <ref type="figure">Figure 5G</ref>-I) than when incentivized to pursue high confidence corrects (Q 2 &lt; 1, <ref type="figure">Figure 5A</ref>-C). And finally, in the special case where (R hit2 -R miss2 ) = (R CR2 -R FA2 ), the effects of relative type 2 reward contingencies for correct and error trials cancel out and optimal criterion setting for maximizing type 2 reward reduces to optimal criterion setting for maximizing type 2 accuracy (i.e. Eqs. 17 and 20 reduce to Eqs. 6 and 9).</p><p>Note that the optimal type 2 criteria are undefined when (R CR2 -R FA2 ) = 0 or (R hit2 -R miss2 ) = 0. This is intuitive, since if (R CR2 -R FA2 ) = 0 and (R hit2 -R miss2 ) &gt; 0 this implies that incorrect trials have no reward consequences, and the observer should always report high confidence to maximize reward (i.e. both and should equal c 1 ). Similarly if (R CR2 -R FA2 ) &gt; 0 and (R hit2 -R miss2 ) = 0, the observer should 2," 2" * 2," 1" * always report low confidence (i.e. and should be at +∞ and -∞, respectively). The optimal 2," 2" * 2," 1" * type 2 criteria are also undefined when Q 2 &lt; 0. This is also intuitive, as this corresponds to a case where "type 2 incorrect" trials are rewarded more than "type 2 correct" trials for one accuracy type (i.e. correct or incorrect trials) but not the other, which precludes formulation of a rational decision strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Calibrating Confidence to Expected Accuracy</head><p>Suppose the observer wishes to place high confidence ratings to reflect that some benchmark of type 1 accuracy has been achieved. For instance, the observer may choose to rate "high confidence" only when the estimated probability of a correct type 1 choice, p(correct 1 ), exceeds 0.8. Here we name this objective "calibration," taking inspiration from classic metacognition research in which calibration referred to how well an observer's estimated accuracy predicted their actual accuracy <ref type="bibr" target="#b24">(Koriat et al., 1980;</ref><ref type="bibr" target="#b25">Lichtenstein et al., 1977;</ref><ref type="bibr" target="#b46">Wagenaar, 1988)</ref>. In the context of SDT, a well-calibrated observer is one who can accurately assess the location on the decision axis at which a given level of accuracy is achieved and use that knowledge to guide type 2 criterion setting. This type of goal may occur in the context of learning if confidence is to be used as a proxy for reward prediction error in the absence of external feedback, for example <ref type="bibr" target="#b20">(Guggenmos et al., 2016;</ref><ref type="bibr" target="#b37">Ptasczynski et al., 2021)</ref>. How should the observer set type 2 criteria so as to achieve this goal?</p><p>More formally, let p(correct 1 ) T be the threshold value of accuracy needed to report high confidence (where T denotes threshold), and let p(correct 1 |x) be the observer's estimate of being correct on the current trial based upon the evidence sample x. Then the observer seeking to calibrate confidence to accuracy uses the following decision policy for rating confidence:</p><formula xml:id="formula_34">( 1 | ) &gt; ( 1 ) → ℎ ℎ (22) ( 1 | ) ≤ ( 1 ) →</formula><p>As before, we consider "S1" and "S2" responses separately. On trials where the observer responds "S2," the quantity the observer must consider in order to calibrate confidence to accuracy is p(correct 1,"S2" |x), where p(correct 1,"S2" ) denotes probability of a correct type 1 response, given that the response was "S2". Following Eq. 22, the observer must report high confidence for "S2" responses when p(correct 1,"S2" |x) &gt; p(correct 1 ) T . This objective can be accomplished by setting the type 2 criterion c 2,"S2" at the location of the decision axis value x where p(correct 1,"S2" |x) = p(correct 1 ) T .</p><p>For convenience, let us define O T as the odds of a correct response at the threshold level of accuracy, p(correct 1 ) T :</p><formula xml:id="formula_35">= ( 1 ) 1− ( 1 ) (23)</formula><p>Then the value of c 2,"S2" that satisfies p(correct 1,"S2" | x=c 2,"S2" ) = p(correct 1 ) T is given by</p><formula xml:id="formula_36">2," 2" * = max ln ( 1) ( 2) + ln ' , 1 ( ) = max 1 * + ln ' , 1 ( )<label>(24)</label></formula><p>Equivalently in terms of likelihood ratio,</p><formula xml:id="formula_37">β 2," 2" * = max ( 1) ( 2) , β 1 ( ) = max β 1 * , β 1 ( )<label>(25)</label></formula><p>Similarly for "S1" responses,</p><formula xml:id="formula_38">2," 1" * = min ln ( 1) ( 2) + ln 1 ' , 1 ( ) = min 1 * − ln ' , 1 ( )<label>(26)</label></formula><p>Equivalently in terms of likelihood ratio,</p><formula xml:id="formula_39">β 2," 1" * = min ( 1) ( 2) 1 , β 1 ( ) = min β 1 * 1 , β 1 ( )<label>(27)</label></formula><p>Derivations of the type 2 criteria that optimize calibration for "S2" and "S1" responses ( and  are shown on each side of the first-order criterion c 1 (black solid line). We assume the same prior probability for S1 and S2 (i.e., p(S1) = p(S2) = 0.5).</p><p>Thus, the type 2 criteria for optimizing calibration (Eqs. 24 and 26) are similar to the type 2 criteria for maximizing type 2 accuracy (Eqs. 6 and 9), but with an added term O T (Eq. 23) corresponding to the odds of a correct response at the threshold level of accuracy, p(correct 1 ) T .</p><p>When p(correct 1 ) T = 0.5, O T = 1 and optimal criterion setting for calibration reduces to optimal criterion setting for maximizing type 2 accuracy (i.e. Eqs. 24 and 26 reduce to Eqs. 6 and 9). This is in agreement with earlier observations that maximizing type 2 accuracy is equivalent to reporting high confidence whenever the type 1 response is more likely than not to be correct.</p><p>As p(correct 1 ) T increases, the observer becomes increasingly stringent in what level of type 1 accuracy they will endorse with high confidence. This corresponds to setting type 2 criteria more conservatively, i.e. further away from the type 1 criterion. Numerically, this conservative bias manifests as an increase in the optimal type 2 criterion for "S2" responses (Eq. 24) and as a decrease in the optimal type 2 2," 2" * criterion for "S1" responses (Eq. 26).</p><p>2," 1" * The equations for the type 2 criteria that optimize calibration ( and , Eqs. 24 and 27) bear a 2," 2" * 2," 1" * close resemblance to the equations for those that optimize type 2 reward ( and , Eqs. 17 and</p><formula xml:id="formula_40">2," 2" * 2," 1" * 20)</formula><p>, with the relative reward quotient Q 2 (Eq. 16) playing the same role in type 2 criterion setting for optimizing type 2 reward as the odds of a correct response at the threshold level of accuracy O T (Eq. 23) plays in type 2 criterion setting for optimizing calibration. In particular, increasing reward-based incentives to avoid high confidence errors (Q 2 ) is equivalent to increasing the threshold level of accuracy for reporting high confidence (O T ); in both cases, the ideal observer achieves their objective by becoming more conservative in reporting high confidence.</p><p>More generally, the equations for optimal type 2 criterion setting under reward maximization and calibration reveal a simple numerical and conceptual correspondence between these seemingly distinct strategies. For instance, the optimal strategy for type 2 criterion setting when avoidance of high confidence errors is rewarded twice as much as pursuit of high confidence corrects (Q 2 = 2) is equivalent to the optimal strategy for calibrating confidence reports such that high confidence trials are at least twice as likely to be correct as low confidence trials (O T = 2, or equivalently p(correct 1 ) T = 2/3).</p><p>Interestingly, as observed in <ref type="figure" target="#fig_9">Figure 6</ref>, the position of and is highly dependent on type 1 2," 2" * 2," 1" * accuracy. Therefore, even when p(correct 1 ) T is set to a low value such as p(correct 1 ) T = 0.7 ( <ref type="figure" target="#fig_9">Figure 6A-C)</ref>, an observer will very rarely report high confidence when their d' is low (e.g. d' = 0.5). Likewise, when an observer has very high sensitivity (e.g. d' = 3), they will almost always report high confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Maximizing the Difference between Hit Rate and False Alarm Rate</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Optimal Type 1 Criterion for Maximizing HR 1 -FAR 1</head><p>In the type 1 task, maximizing the difference between type 1 hit rate and false alarm rate is trivially accomplished by setting (see Appendix Section A4.1 for derivation). 1 = 1 * = 0 Unlike the optimal type 1 criteria for maximizing accuracy ( , Eq. 2) and reward ( , Eq. 13), does not depend on stimulus priors or d'. This is because HR 1 and FAR 1 are rates of responding "S2" conditional upon presentation of S2 and S1 stimuli, respectively. As a result, the outcome measure HR 1 -FAR 1 is independent of stimulus priors, which is not the case with type 1 accuracy (Eq. 1) or reward (Eq. 11). Since HR 1 -FAR 1 does not depend on stimulus priors, it follows that the equation for the type 1 criterion that maximizes HR 1 -FAR 1 does not need to take priors into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Optimal Type 2 Criteria for Maximizing HR 2 -FAR 2</head><p>Suppose the observer has the objective of maximizing the difference between type 2 hit rate and type 2 false alarm rate:</p><formula xml:id="formula_41">(28) 2 = 2 − 2</formula><p>For "S2" responses, this is accomplished by setting 2," 2"</p><formula xml:id="formula_42">* = max ln 1 1 ' , 1 ( )<label>(29)</label></formula><p>Equivalently in terms of likelihood ratio, β 2," 2"</p><formula xml:id="formula_43">* = max 1 1 , β 1 ( )<label>(30)</label></formula><p>Similarly for "S1" responses,</p><formula xml:id="formula_44">2," 1" * = min ln 1− 1 1− 1 ' , 1 ( )<label>(31)</label></formula><p>Equivalently in terms of likelihood ratio, β 2," 1"</p><formula xml:id="formula_45">* = min 1− 1 1− 1 , β 1 ( )<label>(32)</label></formula><p>Derivations of the type 2 criteria that optimize HR 2 -FAR 2 for "S2" and "S1" responses ( and  of the first-order criterion c 1 (black solid line). We assume the same prior probability for S1 and S2 (i.e., p(S1) = p(S2) = 0.5).</p><p>Optimizing HR 2 -FAR 2 differs from the previously considered type 2 criterion setting strategies in that it does not depend on the stimulus priors p(S1) and p(S2). In this respect it is similar to the type 1 criterion that maximizes HR 1 -FAR 1 , which is also independent of stimulus priors (see Section 2.4.1). In both cases, the reason for the independence from stimulus priors is the same: since the outcome measures being maximized (HR 2 -FAR 2 and HR 1 -FAR 1 ) do not depend on stimulus priors, the criterion setting strategy for maximizing these outcome measures does not have to take those priors into account.</p><p>As in the other optimization contexts, d' appears in the denominator of the equations for and 2," 1" * . However, the influence of d' on the optimal type 2 criteria is far more limited when maximizing 2," 2" * HR 2 -FAR 2 than in the other optimization contexts (compare <ref type="figure" target="#fig_12">Figure 7</ref> to <ref type="figure" target="#fig_4">Figures 4-6)</ref>. The reason for this is that in the other optimization contexts, the numerator of the criteria equations contain terms that are fixed and independent of d' (p(S1), p(S2), Q 2 , O T ). By contrast, for the numerator is ln(HR 1 ) -2," 2" * ln(FAR 1 ), whereas the denominator is d' = z(HR 1 ) -z(FAR 1 ) where z is the inverse of the normal cumulative distribution function. It turns out that for a fixed value of c 1 , the ratio of the functions ln(HR 1 ) -ln(FAR 1 ) and z(HR 1 ) -z(FAR 1 ) is approximately constant for typical values of d' in <ref type="bibr">[0,</ref><ref type="bibr">5]</ref> (which spans p(correct 1 ) values from 0.5 to 0.99 for an unbiased observer). Similar considerations hold for , where the 2," 1" * numerator is ln(1 -HR 1 ) -ln(1 -FAR 1 ). Thus, and are sensitive to c 1 but relatively 2," 1" * 2," 2" * independent of d' <ref type="figure" target="#fig_12">(Figure 7)</ref>. These observations suggest a possible source for empirical observations suggesting a 'fixed' or immobile type 2 criterion across conditions or even tasks <ref type="bibr" target="#b26">(Li et al., 2018;</ref><ref type="bibr" target="#b39">Rahnev et al., 2011;</ref><ref type="bibr" target="#b44">Solovey et al., 2015)</ref>. See Section 3.2 for further discussion.</p><p>Another unique characteristic of and is that they are constrained to have negative and 2," 1" * 2," 2" * positive values, respectively. When d' &gt; 0 it must be the case that HR 1 &gt; FAR 1 , which entails that ln(HR 1 / FAR 1 ) &gt; 0 and thus &gt; 0 (Eq. 29). By similar reasoning, when d' &gt; 0 it must be the case that &lt; 0.</p><p>2," 2" * 2," 1" * However, although they are constrained to have opposite signs, the two type 2 criteria can be located asymmetrically around 0 <ref type="figure" target="#fig_12">(Figure 7)</ref>.</p><p>In the special case where stimulus priors are equal (i.e. p(S1) = p(S2)) and the observer sets the type 1 criterion optimally for maximizing type 1 accuracy (i.e. ), maximizing HR 2 -FAR 2 is 1 = 1 * = 0 equivalent to calibrating confidence to the observer's actual overall accuracy in the task, i.e. optimizing calibration when setting p(correct 1 ) T = p(correct 1 ). For instance, compare the type 2 criteria for "S2" responses that optimize calibration ( , Eq. 24) and HR 2 -FAR 2 ( , Eq. 29). Setting these equations </p><formula xml:id="formula_46">= = ( 1 ) 1− ( 1 )</formula><p>, there is a symmetry whereby overall accuracy p(correct 1 ) is identical to both hit rate HR 1 1 = 1 * = 0 and correct rejection rate (1 -FAR 1 ), which in turn implies . Thus, in this special case,</p><formula xml:id="formula_47">1 1 = ( 1 ) 1− ( 1 )</formula><p>Eqs. 24 and 29 are identical when p(correct 1 ) T = p(correct 1 ). Similar reasoning applies to "S1" responses. An example of this equivalence is illustrated in <ref type="figure" target="#fig_1">Figure 2C</ref>-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">The Impact of Suboptimal Metacognition: When meta-d' &lt; d'</head><p>Thus far, we have only considered optimization of type 2 criteria when metacognitive sensitivity conforms to the expectations of standard signal detection theory, i.e. when meta-d' = d' <ref type="bibr" target="#b29">(Maniscalco &amp; Lau, 2012)</ref>. However, empirically it is often the case that this expectation is violated, such that meta-</p><formula xml:id="formula_48">d' ≠ d'.</formula><p>In most such cases meta-d' is smaller than d', which indicates suboptimal metacognitive sensitivity relative to SDT expectation. Alternatively, it has also been found that meta-d' can be greater than d' <ref type="bibr" target="#b10">(Charles et al., 2013)</ref> if time-pressure on the response is increased and participants are able to detect and correct a large proportion of their fast erroneous guesses. Therefore, an important question is how the derived optimal type 2 criteria may change in cases where metacognitive sensitivity cannot be adequately captured by the standard SDT model (i.e. cases where meta-d' ≠ d').</p><p>When meta-d' ≠ d', one might be tempted to simply substitute meta-d' for all occurrences of d' in the formulae for optimal type 2 criteria. However, this is not appropriate since the meta-d' framework is not intended to provide a model of the specific computational processes by which the SDT expectation that meta-d' = d' is violated. Rather, the meta-d' framework answers the counterfactual question, "what d' would a hypothetical SDT-ideal observer require in order to reproduce the observed type 2 ROC curves?" As a consequence, the type 2 criteria in the meta-d' model apply to this hypothetical SDT-ideal observer, not to the actual observer whose data is being analyzed. Thus, substituting meta-d' for d' in the above equations would inform us about how this hypothetical SDT-ideal observer should set their type 2 criteria in order to be optimal. However, it would not necessarily shed much light on optimal type 2 criterion setting for the actual observer whose data violates SDT expectation. Indeed, below we will show that optimal type 2 criteria can differ for the same value of meta-d', depending on the computational processes whereby that meta-d' value was generated.</p><p>It is therefore necessary to first specify a model which makes explicit the computational mechanisms whereby meta-d' ≠ d' can occur, and then investigate how the behavior of that model influences optimal type 2 criterion setting. For instance, a simple example of such a process model (considered further below) is one that is identical to the standard SDT model, but with the added mechanism that the evidence samples used for type 1 judgments receive extra noise before being used for type 2 judgments. However, even for this very simple extension of the standard SDT model, the mathematics for deriving optimal type 2 criteria become intractable . Fortunately, optimal type 2 criterion setting under such 8 models can be explored via computational simulation.</p><p>There are many possible models of how the SDT expectation that meta-d' = d' might be violated, and a comprehensive exploration of how every possible model that has been proposed in the literature might impact type 2 criterion setting is beyond the scope of this paper. Thus, here we investigate two simple example models -a "type 2 noise" model and a "type 2 signal loss" model -for the sake of illustrating how different mechanisms that allow for meta-d' ≠ d' might similarly and differentially impact optimal type 2 criterion setting <ref type="bibr" target="#b31">(Maniscalco &amp; Lau, 2016;</ref><ref type="bibr" target="#b35">Peters et al., 2017;</ref><ref type="bibr" target="#b42">Shekhar &amp; Rahnev, 2021a</ref><ref type="bibr" target="#b43">, 2021b</ref>. Readers interested in exploring optimal type 2 criterion setting in alternative models are invited to adapt the code used for the simulations below to their own purposes. This simulation code is available online at https://github.com/CNClaboratory/opt_t2c and is designed to be easily used with any specified model of type 2 processes.</p><p>In the interest of brevity and exploring illustrative examples rather than being exhaustive, we also consider only two of the four optimization contexts explored above: maximizing type 2 reward and maximizing the difference between type 2 hit rate and type 2 false alarm rate. As seen above, the equations for optimizing type 2 accuracy, type 2 reward, and calibration in the traditional SDT model are similar, and thus we chose type 2 reward optimization as a representative optimization context from this set. For interested readers, the simulation code available online allows for exploration of optimal type 2 criterion setting for type 2 accuracy and calibration.</p><p>Our general approach to the simulations was to investigate how a representative range of values for the parameter controlling metacognitive sensitivity (σ 2 and k in the type 2 noise and type 2 signal loss models, respectively) affected optimal type 2 criterion setting, holding all other parameters of the model constant as a fixed reference. To this end, we used parameter settings of d' = 2, c 1 = 0, and p(S2) = 0.5, and in the reward optimization simulations, we set Q 2 = 3. (As a reminder, setting Q 2 = 3 roughly corresponds to rewarding the avoidance of high confidence errors 3 times as much as rewarding the pursuit of high confidence correct responses (Eq. 15), thus encouraging a conservative bias in type 2 criterion setting <ref type="bibr">(Eqs. 16 &amp; 18)</ref>. Although it may seem odd to incentivize avoidance of high confidence errors more than pursuit of high confidence correct responses, we remind the reader that in cases where this is reversed (e.g., Q 2 = 0.33), c 2 collapses onto its maximally liberal value, i.e. the type 1 criterion (see <ref type="figure">Figure 5</ref> and the text in Section 2.2.2) and is therefore less interesting to consider.)</p><p>All simulations described below followed standard Monte Carlo approaches using 10,000,000 trials at each level of type 2 noise or signal loss tested. On each simulated trial, the parameter values of the model were used to generate evidence samples x 1 (for type 1 decisions) and x 2 (for type 2 decisions) from the presentation of either an S1 or S2 stimulus; see below for details of the relationship between x 1 and x 2 . Type 1 decision was set to "S2" when x 1 &gt; c 1 , and "S1" otherwise. To explore how type 2 criterion setting influenced outcome measures, we simulated type 2 responses for a range of type 2 criteria spanning values <ref type="bibr">[-4, 0]</ref> for "S1" responses and [0, 4] for "S2" responses, in increments of 0.01. For each simulated trial, we computed the confidence responses generated by each of these type 2 criterion values based on where x 2 fell in relation to them, with x 2 defined in Eqs. 33 and 34, below. For a given type 2 criterion, confidence was set to "high" when x 2 &lt; c 2,"S1" (for "S1" responses) or when x 2 &gt; c 2,"S2" (for "S2" responses), and "low" otherwise. To determine optimal type 2 criteria for a given set of parameter values, we found the values of c 2,"S1" and c 2,"S2" that yielded the maximum type 2 outcome measure (e.g. maximum type 2 reward) across all simulated trials. Since parameter values were chosen so as to make outcomes for "S1" and "S2" responses symmetrical, for simplicity we present only data from simulated trials where the response was "S2" in the discussion below. Simulations were performed in Matlab (version 2017a).</p><p>We also used the simulated data to examine how model parameters controlling metacognitive sensitivity (σ 2 and k in the type 2 noise and type 2 signal loss models, respectively) were related to the SDT-based measure of metacognitive sensitivity, meta-d' <ref type="bibr" target="#b29">(Maniscalco &amp; Lau, 2012</ref>. To compute meta-d' for a given set of model parameters, we defined 9 type 2 criteria on either side of the type 1 criterion with values evenly spaced over the range c 1 ± [.1, 4]. On each simulated trial, the x 2 evidence sample was compared to these criteria to derive a confidence rating on the scale of 1 -10. We chose these settings because using a large rating scale with evenly spaced type 2 criteria allows for high-fidelity approximation of the type 2 ROC curves used for fitting meta-d'. Using these simulated confidence ratings in conjunction with other simulated data, we computed meta-d' using MLE fitting to response-conditional type 2 ROC curves <ref type="bibr" target="#b30">(Maniscalco &amp; Lau, 2014)</ref>. In presenting the simulation results, we summarize metacognitive efficiency as M ratio = meta-d' / d'. 3) as a function of possible type 2 criterion values for "S1" responses (x-axis values lower than c 1 ) and "S2" responses (x-axis values higher than c 1 ). The presence of type 2 noise (thicker lines) 'flattens' the expected reward functions relative to the case of zero type 2 noise (thinner lines), such that reward is maximized by a type 2 criterion being placed at 0 rather than around ±0.5. (C) Expected HR 2 -FAR 2 as a function of possible type 2 criterion values for "S1" responses (x-axis values lower than 0) and "S2" responses (x-axis values higher than 0). Here type 2 noise flattens the type 2 outcome functions (thicker lines) relative to the case of zero type 2 noise (thinner lines), similar to (B). However, unlike in (B), the effect of this flattening is to move the maxima of the functions farther away from c 1 , rather than closer to c 1 . Thus, in these two example cases with identical parameter values, type 2 noise makes the optimal type 2 criteria more conservative (closer to 0) when optimizing reward, but more liberal (farther from 0) when optimizing HR 2 -FAR 2 . See main text for details and results of simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Type 2 Noise Model</head><p>In the type 2 noise model, type 2 evidence samples are noisier than their type 1 counterparts, thus yielding suboptimal metacognitive sensitivity relative to SDT expectation. Specifically, the relationship between type 1 signal x 1 and type 2 signal x 2 on a given trial is given by</p><formula xml:id="formula_49">(33) 2 = 1 + ε, ε~(0, σ 2 )</formula><p>where σ 2 is the standard deviation of the additional type 2 noise, over and above any noise present at the type 1 level.</p><p>We performed simulations where σ 2 ranges from 0 to 2 in steps of 0.1. In the absence of type 2 noise, when σ 2 = 0, the model reduces to the standard SDT model described above in Section 1.1, and as σ 2 grows larger, metacognitive sensitivity decreases. This range of cases we simulated spans the range from M ratio = 1 to M ratio ≈ 0.5, which fully spans the range of values of M ratio typically encountered in real data.</p><p>In <ref type="figure" target="#fig_14">Figure 8</ref> we provide an initial intuition for how type 2 noise affects type 2 criterion setting, using an example where d' = 2, c 1 = 0, and p(S2) = 0.5 ( <ref type="figure" target="#fig_14">Figure 8A)</ref>. In a reward optimization context with Q 2 = 3 and no type 2 noise (σ 2 = 0), expected reward for each response type is a unimodal function of c 2 position ( <ref type="figure" target="#fig_14">Figure 8B</ref>, thin black lines), and the optimal type 2 criteria are the c 2 values at which the maxima of these functions occur (thin red lines). When type 2 noise is introduced (σ 2 = 1), the expected reward functions flatten out such that the maxima of the functions for each response type move inwards towards the type 1 criterion ( <ref type="figure" target="#fig_14">Figure 8B</ref>, thick black lines). As a consequence, type 2 noise has the effect of making the optimal type 2 criteria for maximizing reward more liberal (thick red lines, partially occluded by the type 1 criterion). Interestingly, in the case of HR 2 -FAR 2 , type 2 noise still has the effect of flattening out the objective functions, but does so in such a way that the maxima of the functions move farther from the type 1 criterion <ref type="figure" target="#fig_14">(Figure 8C)</ref>, thereby making the optimal type 2 criteria more conservative. Thus, although type 2 noise has the same general effect of flattening out the objective functions, this can induce opposite effects on optimal type 2 criteria depending on the optimization context. Below we examine these behaviors in more detail.</p><p>In <ref type="figure" target="#fig_15">Figure 9A</ref> we plot expected type 2 reward as a function of c 2 position for "S2" responses when σ 2 = 0.2 (top), 0.8 (middle), or 1.2 (bottom), using similar format to <ref type="figure" target="#fig_14">Figure 8B</ref>. (Reminder: Since parameter values were chosen so as to make outcomes for "S1" and "S2" responses symmetrical, here we only plot "S2" responses for simplicity.) As in <ref type="figure" target="#fig_14">Figure 8B</ref>, it can be seen that as σ 2 increases, the reward function flattens out and its peaks move inwards towards the type 1 criterion, with the consequence that the optimal c 2 becomes more liberal. . Notably, there is minimal benefit of moving c 2,"S2" to account for noise: the thick and thin lines in (C) and (F) are almost entirely overlapping.</p><p>The relationship between σ 2 and optimal in the reward optimization context is characterized more 2," 2" * fully in <ref type="figure" target="#fig_15">Figure 9B</ref>, which shows the optimal becoming increasingly liberal until it hits the most 2," 2" * liberal possible value at , which occurs when σ 2 ≈ 1 at an M ratio value of ≈ 0.5. We note, however, that increasing type 2 noise does not always make more liberal: If we set Q 2 = 6 instead 2," 2" * of Q 2 = 3, increasing type 2 noise actually makes the optimal c 2 more conservative, not more liberal (data not shown). We encourage the interested reader to use the toolbox (https://github.com/CNClaboratory/opt_t2c) to explore the consequences of different reward scenarios in more detail.</p><p>In addition to knowing how type 2 noise affects the location of the optimal type 2 criterion, it is also very relevant to know how much these changes actually affect the magnitude of expected reward. Put simply, how much will the observer lose if they ignore the presence of type 2 noise, and instead use the optimal c 2 value for the σ 2 = 0 case? We explore this question in <ref type="figure" target="#fig_15">Figure 9C</ref>. For the same simulation parameters used above, we see that the magnitude of lost expected reward due to neglecting type 2 noise is quite small -especially when σ 2 &lt; 1, which corresponds to M ratio &gt; 0.5, as is commonly observed in empirical studies. Thus, for these settings of type 1 performance and type 2 reward contingencies (as summarized in the measure Q 2 ), an observer with typical metacognitive sensitivity (M ratio &gt; 0.5) would not suffer much loss of expected type 2 reward by simply neglecting the effect of type 2 noise on type 2 criterion setting.</p><p>Finally, we see qualitatively similar results when using the difference between type 2 hit and false alarm rate as the measure to be optimized. First, as above, in <ref type="figure" target="#fig_15">Figure 9D</ref> we plot the expected difference between type 2 hit and false alarm rates as a function of c 2 when σ 2 = 0.2 <ref type="figure" target="#fig_15">(Figure 9D, top)</ref>, 0.8 ( <ref type="figure" target="#fig_15">Figure  9D, middle)</ref>, or 1.2 <ref type="figure" target="#fig_15">(Figure 9D, bottom)</ref>. We can see that type 2 noise has a modest effect on placement of the optimal type 2 criterion ( <ref type="figure" target="#fig_15">Figure 9E)</ref>, but in practice the observer can simply neglect the effect of type 2 noise without experiencing an appreciable loss in type 2 performance ( <ref type="figure" target="#fig_15">Figure 9F)</ref>. As previously illustrated in <ref type="figure" target="#fig_14">Figure 8</ref>, comparing panels A and D of <ref type="figure" target="#fig_15">Figure 9</ref> shows that type 2 noise can make the optimal type 2 criterion more liberal or conservative depending on the measure to be optimized and the parameter settings of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Type 2 Signal Loss Model</head><p>In the type 2 signal loss model, in addition to the presence of type 2 noise, the magnitude of the internal signal used to make type 2 judgments can also be smaller than its type 1 counterpart. Specifically, the relationship between type 1 signal x 1 and type 2 signal x 2 on a given trial is given by</p><formula xml:id="formula_50">(34) 2 = (1 − ) 1 + ε, ε~(0, σ 2 )</formula><p>where 0 ≤ k ≤ 1 is the signal loss parameter and σ 2 is the standard deviation of the additional type 2 noise. When σ 2 = 0 and 0 &lt; k &lt; 1, (1 -k) scales the mean and standard deviation of x 1 to an equal extent, and so signal-to-noise ratio for the scaled x 2 samples is equivalent to the signal-to-noise ratio of the original x 1 samples. As a consequence, M ratio remains constant at 1 for all k in 0 &lt; k &lt; 1 when σ 2 = 0. However when σ 2 &gt; 0, increases in k yield reductions in M ratio . Thus here we set σ 2 to a small constant value of 0.1 and explore the effect of modulating k on optimal type 2 criterion setting.</p><p>We performed simulations where k ranges from 0 to 0.98 in steps of 0.02. The simulated cases span a wide range, from M ratio ≈ 0.5 to M ratio ≈ 1, covering the range of values of M ratio typically encountered in real data. <ref type="figure">Figure 10</ref>. Simulation of the effect of type 2 signal loss (k) on the optimal type 2 criterion for "S2" responses when optimizing type 2 reward (A-C) or HR 2 -FAR 2 (D-F). (A&amp;D) Effect of different values of type 2 signal loss k (from top to bottom, k = 0.2, 0.5, or 0.8) on the expected reward (A, thick line) and on HR 2 -FAR 2 (B, thick line) according to the position of c 2,"S2" . The optimal type 2 criterion (i.e. the 2," 2" * criterion that maximizes the function) for each value of type 2 signal loss is displayed as a large red dot. For comparison, the same function in the absence of type 2 signal loss is displayed as a thin line, and the corresponding optimal type 2 criterion in the absence of type 2 signal loss is shown as a small red dot.</p><p>(B&amp;E) Value of the optimal type 2 criterion as a function of type 2 signal loss k when optimizing Unlike under the type 2 noise model, there is an appreciable benefit from moving c 2,"S2" to account for signal loss, especially at higher levels of signal loss: the thick and thin lines in (C) and (F) diverge as k increases.</p><p>Following the logic presented above for type 2 reward optimization, we can first plot expected type 2 reward as a function of c 2,"S2" when k = 0.2, k = 0.5, or k = 0.8 ( <ref type="figure">Figure 10A)</ref>. In <ref type="figure">Figure 10B</ref> we then plot the effect of k on optimal type 2 criterion setting. Similar to the results for the type 2 noise simulation ( <ref type="figure" target="#fig_15">Figure 9B)</ref>, we see that as k increases and M ratio decreases, the optimal c 2 becomes increasingly conservative.</p><p>We also see in <ref type="figure">Figure 10C</ref> that in this model, neglecting type 2 signal degradation has more severe consequences for loss in expected reward than neglecting type 2 noise did in <ref type="figure" target="#fig_15">Figure 9C</ref>, even though the simulations span similar ranges of M ratio and use identical values for d', c 1 , p(S2), and Q 2 . This suggests, as hinted at earlier, that the impact of suboptimal metacognitive sensitivity on optimal type 2 criterion setting depends strongly upon the specific details of the computational model one uses to characterize the mechanisms underlying that suboptimal metacognitive sensitivity. We expand on this observation in the next section.</p><p>Lastly, we can examine the results of type 2 signal loss on the optimal c 2 for maximizing the difference between type 2 hits and false alarms, HR 2 -FAR 2 . As above, in <ref type="figure">Figure 10D</ref> we plot HR 2 -FAR 2 as a function of c 2 when k = 0.2, k = 0.5, or k = 0.8. As k increases and M ratio decreases, the optimal c 2 becomes increasingly conservative <ref type="figure">(Figure 10E)</ref>, in contrast to the type 2 noise model where the optimal c 2 becomes increasingly liberal as σ 2 increases and M ratio decreases ( <ref type="figure" target="#fig_15">Figure 9E)</ref>. Similar to the results for maximizing reward <ref type="figure">(Figure 10C)</ref>, the penalty in HR 2 -FAR 2 incurred by neglecting to take type 2 signal loss into account in computing the optimal c 2 is quite salient <ref type="figure">(Figure 10F)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3">Summary of Suboptimal Metacognition Simulations</head><p>In the above simulations, we provide only a relatively restricted exploration of how optimal type 2 criterion setting changes in models where metacognitive sensitivity can deviate from SDT expectation. In particular, we consider two models that allow for meta-d' &lt; d' (the type 2 noise and type 2 signal loss models) in two optimization contexts (maximizing type 2 reward or HR 2 -FAR 2 ). In these contexts, we examine how the optimal type 2 criterion changes with metacognitive sensitivity (as controlled by σ 2 and k) while holding the type 1 parameters of the model (d', c 1 , and p(S2)) fixed. Thus, these simulations are by no means intended to provide an exhaustive characterization of how optimal type 2 criterion setting changes when meta-d' ≠ d'. Rather, they are intended to demonstrate the general principle that there is not a simple and universal characterization of how optimal type 2 criterion setting changes when meta-d' ≠ d'. In particular, optimal type 2 criterion setting in such cases depends upon specific details of the context, including the postulated computational processes whereby meta-d' ≠ d', as well as the outcome measure to be optimized.</p><p>In all simulations explored here, optimal type 2 criterion setting changes as a function of metacognitive sensitivity (as controlled by σ 2 and k). This finding indicates that, in general, deviations of metacognitive sensitivity from SDT expectation do indeed impact optimal type 2 criterion setting. However, the simulations reveal that the exact nature of this change -its direction and its practical significance for outcome optimization -depends strongly on the process model and optimization context, as discussed further below.</p><p>For the type 2 noise model examined here, the optimal c 2,"S2" becomes either more conservative ( <ref type="figure" target="#fig_15">Figure  9B</ref>) or more liberal ( <ref type="figure" target="#fig_15">Figure 9E)</ref> as type 2 noise increases and metacognitive sensitivity decreases, depending on whether the outcome measure to be maximized is type 2 reward or HR 2 -FAR 2 . However, in both cases the practical effect of decreased metacognitive sensitivity on outcome optimization is not very salient, as nearly identical outcomes can be achieved by ignoring type 2 noise when determining the optimal type 2 criterion <ref type="figure" target="#fig_15">(Figure 9C &amp; 9F)</ref>.</p><p>By contrast, for the type 2 signal loss model, the optimal c 2,"S2" becomes more conservative as type 2 signal loss increases and metacognitive sensitivity decreases for both outcome optimization contexts <ref type="figure">(Figure 10B &amp; 10E)</ref>. Additionally, for this model the effect of decreased metacognitive sensitivity on outcome optimization is quite salient, as ignoring type 2 signal loss leads to significant reductions in outcome for moderate to high levels of signal loss <ref type="figure">(Figure 10C &amp; 10F)</ref>.</p><p>The different behavior of the type 2 noise and type 2 signal loss models can be further illustrated by considering how optimal type 2 criterion setting depends on M ratio according to each model. Whereas values of the type 2 noise and type 2 signal loss parameters σ 2 and k are not directly comparable, each entails values of M ratio ( <ref type="figure" target="#fig_18">Figure 11A)</ref>, and so the models can be directly compared at parameter values that yield identical M ratio values <ref type="figure" target="#fig_18">(Figure 11B &amp; 11C)</ref>. This plotting method highlights that even when M ratio values are identical, optimal type 2 criterion setting differs depending on the process model and optimization context.</p><p>The foregoing points underscore the importance of context -including the specified process model and outcome measure to be optimized -for characterizing optimal type 2 criterion setting when meta-d' ≠ d'. For simplicity we have not considered the impact of type 1 parameters d', c 1 , and p(S2), but it is likely that these parameters introduce further interesting complexities in characterizing optimal type 2 criterion setting. The upshot of all this is that analyses intended to characterize optimal type 2 setting when meta-d' ≠ d' need to utilize theoretical or simulation-based approaches that are carefully tailored to the specifics of the empirical or theoretical phenomena under consideration. We note that the code for the above simulations is available in our online toolbox (https://github.com/CNClaboratory/opt_t2c) that can be readily used to explore optimal type 2 criterion setting for any parameter settings of the type 2 noise and type 2 signal loss models, and for any of the four optimization contexts considered in this manuscript. It can also be readily adapted to explore the behavior of alternative process models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">General Discussion</head><p>An observer's strategy for rating confidence in their decisions depends highly on that observer's goal: just as with type 1 decisions, the optimal strategy for producing type 2 ratings of confidence changes whether the observer wishes to maximize type 2 accuracy, type 2 reward, the correspondence between confidence and accuracy, or the difference between type 2 hit and false alarm rates. In this paper, we explored the different strategies an observer can adopt to optimize these various outcomes using the framework of second-order signal detection theory. To facilitate this exploration and derivation of optimal strategies, we first reviewed how, according to classic signal detection theory, the decision criterion can be set to optimize a particular outcome measure following the experimenter's instructions and stimuli presented. We then explored how such optimization could apply to confidence judgments, evaluating how different outcome measures at the type 2 level could be optimized, and how this would affect the position of the criteria for reporting high confidence. We considered four distinct optimization strategies (in the context of their type 1 counterparts as appropriate): 1) maximize type 2 accuracy, 2) maximize type 2 reward, 3) adjust confidence to a threshold probability of type 1 accuracy and 4) maximize the difference between type 2 hit rate and type 2 false alarm rate. For each outcome measure, we derived mathematical formulae for computing the optimal type 2 criteria in the standard signal detection theory model. Finally, we used computational simulations to conduct a preliminary exploration of how optimal type 2 criterion setting changes when metacognitive sensitivity deviates from SDT expectation, i.e. models in which type 2 signal is altered compared to type 1 signal (which entails meta-d' ≠ d').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Summary of Results</head><p>In this work we have derived formulae for type 2 criteria that optimize various optimization contexts in the classical signal detection theory model. For a binary confidence rating of "high" vs "low," this entails setting two type 2 criteria on either side of the type 1 criterion, corresponding to separate type 2 criteria for "S1" and "S2" responses. The type 2 criterion for each response type determines how evidence samples receiving that response are mapped onto high vs low confidence. Importantly, these type 2 criteria c 2,"S1" and c 2,"S2" are subject to consistency constraints: since by definition "S1" responses occur for evidence values lower than c 1 , it must be the case that the type 2 criterion for "S1" responses is lower than c 1 as well (c 2,"S1" ≤ c 1 ), and by similar reasoning c 2,"S2" ≥ c 1 . These general considerations set the stage for characterizing optimal type 2 criteria for the various optimization contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Optimizing Type 2 Accuracy</head><p>The most common target for optimizing type 1 task performance is to maximize accuracy. It is therefore natural to consider the objective of maximizing the analogue of accuracy in the type 2 confidence rating task <ref type="table">(Table 2)</ref>, where "correct" type 2 trials are those in which confidence is congruent with accuracy (high confidence for correct trials and low confidence for incorrect trials).</p><p>Derivation of the optimal type 2 criteria for maximizing type 2 accuracy ( and ) reveals that ; in this case, one type 2 criterion is set to the location of the 1 * optimal type 1 criterion and the other is set to the location of actual type 1 criterion c 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">*</head><p>Thus to maximize type 2 accuracy, the observer reports low confidence only for evidence samples that fall between the actual and optimal type 1 criterion. These are trials for which the observer gives suboptimal type 1 responses, i.e. responses that are more likely than not to be incorrect. Thus, the optimal strategy is to report high confidence for responses that are likely to be correct and low confidence for responses that are likely to be incorrect. It follows that in order to maximize type 2 accuracy, confidence rating should be treated like an error detection task in which low confidence ratings flag likely errors. When the observer sets the type 1 criterion optimally, responses are never more likely to be incorrect than correct, and thus the ideal strategy is to always report high confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Optimizing Type 2 Reward</head><p>When hits, misses, correct rejections, and false alarms in the type 1 task are associated with different rewards <ref type="table" target="#tab_2">(Table 3)</ref>, the observer may seek to respond in a way that maximizes reward rather than accuracy. The objective to maximize reward can also influence type 2 criterion setting in cases where reward depends on type 2 hits, misses, correct rejections, and false alarms ( <ref type="table" target="#tab_4">Table 4)</ref>.</p><p>The optimal type 2 criteria for maximizing reward contingent upon type 2 outcomes ( and )</p><p>2," 1" * 2," 2" * are located symmetrically around the optimal type 1 criterion that maximizes type 1 accuracy ( ), 1 * subject to consistency constraints <ref type="bibr">(Eqs. 17 &amp; 20)</ref>. Their distance from depends on the relative reward 1 * quotient Q 2 (Eq. 16), which measures the ratio of the reward for avoiding high confidence errors (R CR2 -R FA2 ) to the reward for pursuing high confidence corrects (R hit2 -R miss2 ). When the ratio Q 2 = 1, there is no reward-based incentive to be either conservative or liberal in rating confidence, and so optimizing type 2 reward reduces to optimizing type 2 accuracy. When Q 2 &lt; 1, pursuit of high confidence correct responses is emphasized, leading to an especially liberal bias in confidence rating in which even some trials that are likely to be incorrect are endorsed with high confidence. When Q 2 &gt; 1, avoidance of high confidence errors is emphasized, leading to a conservative bias in confidence rating.</p><p>The case where rewards incentivize the observer to avoid high confidence errors (Q 2 &gt; 1) is of the greatest interest, since here the optimal type 2 criteria do not collapse onto . In this scenario, the 1 * observer should not limit low confidence reports to trials where an error is likely (as is the case for optimizing type 2 accuracy), but should also report low confidence when a response is likely to be correct but nonetheless has relatively weak supporting evidence. This of course is the manner in which confidence ratings are typically employed in metacognition research. (Another way of expressing this observation is that setting Q 2 &gt; 1 is equivalent to setting O T &gt; 1 in the calibration framework, i.e. setting the threshold level of accuracy for reporting high confidence greater than the chance level of accuracy 0.5; see following section.)</p><p>When the reward ratio encourages conservative or liberal type 2 criterion setting (Q 2 &gt; 1 or Q 2 &lt; 1, respectively), the magnitude of its influence on type 2 criterion setting is moderated by the type 1 sensitivity of the observer (d'). The optimal type 2 criteria and deviate from maximally consistency constraints). Thus when d' is low the ideal observer relies more heavily on the payoff matrix as a kind of prior to guide confidence rating, whereas when d' is high the ideal observer conforms more closely to the strategy for maximizing type 2 accuracy. In the most relevant case where rewards incentivize the ideal observer to be conservative in setting type 2 criteria (Q 2 &gt; 1), d' enacts an opposing influence such that as d' increases, the ideal observer becomes more liberal in setting their type 2 criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Calibrating Confidence to Accuracy</head><p>A natural confidence rating strategy is to report high confidence whenever the estimated likelihood that one's response is correct surpasses some threshold level of accuracy, p(correct 1 ) T . For instance, one might report high confidence whenever one estimates that one's response is at least 80% likely to be correct. In this case, the optimal type 2 criterion setting strategy does not involve maximizing some outcome measure, but rather consists in accurately assessing the location on the decision axis corresponding to the desired threshold accuracy level.</p><p>The optimal type 2 criteria for calibrating confidence to a threshold probability of being correct p(correct 1 ) T ( and ) are located symmetrically around the optimal type 1 criterion ( ), p(correct 1 ) T to (1 -p(correct 1 ) T ), denoted O T (Eq. 23). The higher one sets p(correct 1 ) T , the higher the estimated accuracy of a particular response must be in order to report high confidence, leading to increasingly conservative biases in confidence rating. When p(correct 1 ) T = 0.5 then the equations for the optimal confidence criteria and reduce to the equations for optimizing type 2 accuracy. This 2," 1" * 2," 2" * stands in agreement with the above observation that when optimizing type 2 accuracy, one reports high confidence whenever the response is more likely than not to be correct, i.e. when p(correct 1 ) &gt; 0.5.</p><p>The equations for and <ref type="bibr">(Eqs. 24 &amp; 26)</ref> are remarkably similar to the equations for the type 2 2," 1" * 2," 2" * criteria that optimize reward, and <ref type="bibr">(Eqs. 17 &amp; 20)</ref>. In fact, these equations are identical with 2," 1" * 2," 2" * the exception that the Q 2 term in the reward equations is replaced by the O T term in the calibration equations. This suggests a strong conceptual link between these two optimization contexts, with Q 2 and O T performing closely related functions. For instance, the optimal type 2 criteria in a reward context with Q 2 = 2 are identical to the optimal type 2 criteria in a calibration context with O T = 2. This entails that for the ideal observer, rewarding the avoidance of high confidence errors twice as much as the pursuit of high confidence corrects (Q 2 = 2) is equivalent to calibrating confidence such that high confidence is reported whenever a response is at least twice as likely to be correct as it is to be incorrect (O T = 2).</p><p>Due to the close similarity of their equations, d' has a similar impact on the type 2 criteria optimizing calibration to a type 1 accuracy threshold ( and ) as it does for type 2 criteria optimizing type 2," 1" * 2," 2" * 2 reward ( and ). In the most relevant case where p(correct 1 ) T &gt; 0.5, increasing d' has the 2," 1" * 2," 2" * effect of making the optimal type 2 criteria more liberal. This is intuitive in that as d' increases, the evidence distributions f(x|S1) and f(x|S2) become increasingly separated, which entails that the likelihood ratio needed to achieve a target level of accuracy occurs at less extreme values of the decision axis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Optimizing the Difference between Type 2 Hit Rate and False Alarm Rate</head><p>A somewhat different approach from the foregoing is to maximize the difference between type 2 hit rate and false alarm rate (HR 2 -FAR 2 ). This strategy differs from the others in that HR 2 and FAR 2 do not depend upon stimulus priors p(S1) and p(S2), and as a consequence the optimal type 2 criteria for maximizing HR 2 -FAR 2 ( and ) do not depend on on the optimal type 1 criterion (which acts as a kind  <ref type="figure" target="#fig_4">4-6)</ref>.</p><p>In the special case where stimulus priors are equal (p(S1) = p(S2)) and the observer is unbiased ( ), maximizing HR 2 -FAR 2 is equivalent to calibrating confidence to one's average type 1 1 = 1 * = 0 accuracy (setting p(correct 1 ) T = p(correct 1 )). This follows from the fact that under equal stimulus priors and unbiased responding, p(correct 1 ) = HR 1 and (1 -p(correct 1 )) = (1 -HR 1 ) = FAR 1 , and thus Eqs. 29 and 31 reduce to Eqs. 24 and 26.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.5">The Influence of Suboptimal Metacognition upon Optimal Type 2 Criterion Setting</head><p>The foregoing discussion applies to optimal type 2 criterion setting in the classical signal detection theory (SDT) model. However, SDT makes a strong prediction about the relationship between metacognitive sensitivity and task performance (i.e. that meta-d' = d') which in practice does not always hold, necessitating consideration of alternative models.</p><p>We considered two simple models that allow for alteration in type 2 evidence samples, which causes suboptimal metacognitive sensitivity relative to SDT expectation (meta-d' &lt; d') via two distinct mechanisms (type 2 noise and type 2 signal loss). We examined the behavior of these models in two different optimization contexts (maximizing type 2 reward and HR 2 -FAR 2 ). Because exact derivation of optimal type 2 criteria in these models was not possible, we examined their behavior using computational simulations. In the simulations, we held the type 1 parameters of the models fixed and examined how changes in the parameters controlling metacognitive sensitivity affected optimal type 2 criterion setting.</p><p>In all cases, optimal type 2 criterion setting changed as a function of metacognitive sensitivity, confirming that this is a relevant factor to consider in analyzing type 2 criterion setting <ref type="figure" target="#fig_15">(Figures 9 &amp; 10,  panels A, B, D, &amp; E)</ref>. However, we also showed that decreasing metacognitive sensitivity could make optimal type 2 criteria become either more liberal or more conservative depending on the model and optimization context <ref type="figure" target="#fig_15">(Figures 9 and 10, panels A, B, D, &amp; E)</ref>. Moreover, the costs of neglecting to take suboptimal metacognitive sensitivity into account when setting type 2 criteria can be either negligible or considerable, depending on the model <ref type="figure" target="#fig_15">(Figures 9 &amp; 10, panels C &amp; F)</ref>. Crucially, even when M ratio is matched, different sources of metacognitive suboptimality can entail different rules for optimal type 2 criterion setting <ref type="figure" target="#fig_18">(Figure 11)</ref>.</p><p>These results demonstrate that when analyzing optimal type 2 criterion setting outside of the confines of classical SDT, it is necessary to pay special attention to the unique details of the model and optimization context under consideration. We provide the code used to conduct the simulations presented in this manuscript as an online toolbox that can be readily adapted to investigate optimal type 2 criterion setting in different models, optimization contexts, and parameter settings than the ones considered here (https://github.com/CNClaboratory/opt_t2c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Assessing the Metacognitive Strategies of Real Observers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">General Considerations</head><p>Thus far we have discussed normative strategies of type 2 criterion setting for ideal observers, but naturally this theoretical work is primarily of interest to provide context for better understanding the confidence reporting behavior of actual observers. Two questions of interest here are (1) what type 2 criterion setting strategy do observers spontaneously use when not given explicit instruction? And (2) how well are observers able to enact a given type 2 criterion setting strategy when explicitly instructed to do so?</p><p>Notably, current protocols used to study confidence often do not implement a normative set of instructions for confidence reports, instead letting participant interpret "high" and "low" confidence as they wish <ref type="bibr" target="#b13">(De Martino et al., 2013;</ref><ref type="bibr" target="#b16">Fleming et al., 2010;</ref><ref type="bibr" target="#b18">Gherman &amp; Philiastides, 2018;</ref><ref type="bibr" target="#b48">Zylberberg et al., 2012</ref><ref type="bibr" target="#b49">Zylberberg et al., , 2014</ref>. In such cases, the observer may spontaneously attempt to follow a normative strategy, such as calibrating reports of high confidence to a threshold accuracy of 80% correct, or alternatively they may adopt a more heuristic approach that does not strictly follow any of the optimization strategies considered here. Even in cases where an observer attempts to follow a normative strategy -of their own volition, or to follow task instructions -they may not always be able to execute the strategy effectively or completely, necessitating a nuanced analysis.</p><p>As we have seen, type 2 criterion setting strategies involve deciding how to report confidence in order to pursue a definite objective (e.g. maximizing reward), making adjustments for various factors that mediate the relationship between criterion and outcome (e.g. d', c 1 , p(S2), Q 2 , O T ). It follows that fully understanding an observer's type 2 criterion setting strategy requires measuring their confidence reports across conditions where factors that potentially modulate criterion setting (e.g. d', c 1 , p(S2), and where applicable, Q 2 , O T , or other factors) are systematically manipulated through experimental manipulations. With such data in hand, the observer's empirical pattern of type 2 criterion setting across conditions can then be compared with the theoretical patterns of type 2 criterion setting corresponding to one or more strategies for optimal type 2 criterion setting in order to better understand the observer's criterion setting strategy.</p><p>The manner in which this comparison of empirical and theoretical type 2 criterion setting should be conducted depends in part on whether the observer's strategy is instructed or spontaneous. When the observer is instructed to use a particular strategy (e.g. maximizing reward), their type 2 criterion setting patterns can be compared to the optimal type 2 criteria for that strategy to assess how effective the observer was at implementing the instructed strategy. In such cases, in addition to exploring the influences of d', c 1 , and/or p(S2), the experimenter may wish to systematically vary the relative reward quotient Q 2 or the threshold level of accuracy O T (where applicable) in order to investigate how well the observer can adjust their type 2 criteria to various performance targets.</p><p>When the observer is free to choose their own strategy, analysis might more broadly investigate which optimal strategy (if any) most closely resembles the observer's empirical type 2 criterion setting patterns across conditions. In the absence of explicit instruction regarding target outcomes or strategies, experimental manipulation of Q 2 and O T is presumably not applicable, and so experiments would instead focus on manipulating d', c 1 , and/or p(S2). Indeed, investigating optimization of externally imposed rewards seems incompatible with investigating spontaneous type 2 criterion setting behavior, since the experimental introduction of a system of rewards and punishments already implies the imposition of norms for criterion setting. Conversely, analyzing the observer's spontaneous criterion setting behavior in terms of the calibration framework would be a natural choice. In this case, given that O T is not experimentally controlled, analysis could assess what value of O T best explains the observer's type 2 criterion setting patterns as other factors such as d' and p(S2) change. Given the close link between the reward and calibration frameworks, the value of O T that best explains an observer's behavior could also be interpreted as reflecting a set of internal "rewards" associated with different type 2 outcomes, as summarized in an internal reward quotient Q 2 with the same value as O T . These internal "rewards" could correspond to e.g. emotional states or cognitive appraisals of value that contribute to criterion setting. For instance, if an observer spontaneously sets O T to a high value of 9 (only reporting high confidence for decisions at least 90% likely to be correct), this is equivalent to setting Q 2 = 9 in a reward framework, which could reflect the spontaneously chosen strategy of a risk-averse observer who values avoiding high confidence errors nine times as strongly as pursuing high confidence correct responses. Alternatively, if the observer utilizes a heuristic strategy that does not resemble any of the optimal strategies considered here, analysis could illuminate the nature of this heuristic by characterizing the observer's type 2 criterion setting patterns across conditions.</p><p>Optimizing type 2 accuracy differs qualitatively from the other optimization contexts considered here, which has consequences for experimental investigations of this strategy. As noted previously, optimizing type 2 accuracy amounts to using low confidence reports to flag likely errors, which is not consistent with how participants typically spontaneously choose to report confidence (e.g. <ref type="bibr" target="#b11">(Charles &amp; Yeung, 2019)</ref>. Thus, assessing an observer's adherence to the strategy of optimizing type 2 accuracy may not be directly relevant for many research purposes, with the notable exception of research on error detection.</p><p>There is also a conceptual tension involved in instructing an observer to optimize type 2 accuracy. The ideal observer must compute the type 1 criterion that optimizes accuracy ( ) in determining their type 1 * 2 criteria <ref type="bibr">(Eqs. 6 &amp; 9)</ref>. But if the observer can compute for the purposes of type 2 criterion setting, 1 * they should also be able to use it for type 1 criterion setting as well and set . In this case the 1 = 1 * strategy for optimizing type 2 accuracy is trivial -always report high confidence. However, if the observer has some rational grounds for setting in spite of being able to compute , then it 1 ≠ 1 * 1 * becomes meaningful to investigate whether the observer can optimize type 2 accuracy (i.e. accurately detect likely errors) in cases where their type 1 criterion setting strategy causes them to sometimes make decisions that are likely to be incorrect. For instance, suppose that the reward structure of the task incentivizes the observer to set a type 1 criterion that maximizes reward but not accuracy (i.e. ). Here it might be interesting to ask whether the observer can reliably report when this 1 = 1 * ≠ 1 * type 1 response strategy generates responses that are likely to be incorrect, which would require setting one type 2 criterion equal to the actual type 1 criterion , and the other equal to the type 1 criterion 1 * for optimizing accuracy, , in line with Eqs. 6 &amp; 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">*</head><p>In practice, resource limitations might often preclude an experimenter from exhaustively probing the influence of factors such as d', p(S2), etc. on type 2 criterion setting. Comparison of empirical and theoretical type 2 criteria can always be conducted regardless -even, in principle, for data from a single experimental condition where no potential influences on type 2 criterion setting are systematically varied. The analysis results in such cases can still be informative, provided that the conclusions one draws from the analysis take appropriate stock of the limitations imposed by the available data.</p><p>One possible approach for investigating type 2 criterion setting in the face of such resource limitations would be to focus the experimental design and analysis on specific aspects of criterion setting strategy, such as the potential influence of d' on type 2 criterion setting, as discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Factorizing the Optimization Strategies</head><p>Thus far we have discussed optimal strategies as if they are unitary, undifferentiated processes, but it is also worth noting that the optimal type 2 criterion formulae can be decomposed into several mathematical components, each of which encompasses one particular facet of the optimal criterion setting strategy. Consideration of these separate components could provide further insights and discoveries regarding type 2 criterion setting. For instance, an observer might only partially implement an optimal type 2 criterion setting strategy by implementing some aspects of the strategy but not others.</p><p>In the case of optimizing type 2 reward and calibration, the formulae for the optimal type 2 criteria <ref type="bibr">(Eqs. 17,</ref><ref type="bibr">20,</ref><ref type="bibr">24,</ref><ref type="bibr">and 26)</ref> suggest three separable components of the optimal criterion setting strategy: (1) both type 2 criteria uniformly shift to remain equidistant from , which itself depends on p(S2) and d';</p><formula xml:id="formula_51">1 *</formula><p>(2) type 2 criteria become more liberal (closer to ) with increasing d' (provided Q 2 &gt; 1 or O T &gt; 1); and 1 *</p><p>(3) type 2 criteria become more conservative (farther from ) with increasing Q 2 or O T . It could be the 1 * case that e.g. an observer neglects (1) entirely by failing to adjust type 2 criteria as a function of stimulus priors, but nonetheless accomplishes (2) and (3) and thereby partially follows the optimal strategy.</p><p>When optimizing HR 2 -FAR 2 , the formulae for the optimal type 2 criteria (Eqs. 29 and 31) imply a different set of component strategies: (1) type 2 criteria shift as a function of c 1 due to the effect that c 1 has on HR 1 and FAR 1 <ref type="figure" target="#fig_12">(Figure 7)</ref>; (2) type 2 criteria are largely independent of d'; and (3) type 2 criteria for "S1" and "S2" responses are always negative and positive, respectively, when d' &gt; 0. (See Section 2.4.2 above for further discussion on these somewhat unusual properties.) Here again, it could be the case that an observer attempting to optimize HR 2 -FAR 2 might follow some but not all of these component strategies.</p><p>The procedure for optimizing type 2 accuracy is simpler than the other optimization contexts in that it only requires computation of the optimal type 1 criterion, <ref type="bibr">(Eqs. 6 &amp; 9)</ref>. The empirical test for this 1 * strategy would be to assess whether a participant sets their type 2 criteria as close as possible to , 1 * subject to consistency constraints imposed by the placement of their actual c 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Assessing Over-Confidence and Under-Confidence</head><p>Whenever there is a normative standard for what an observer's confidence should be, it follows that they can potentially be over-confident or under-confident relative to that standard. Specifically, the observer is over-confident if their actual type 2 criteria are more liberal than the optimal type 2 criteria, leading to more frequent high confidence reports than is optimal, and similarly they are under-confident if their actual type 2 criteria are more conservative than the optimal type 2 criteria, leading to less frequent high confidence reports than is optimal. Being able to rigorously characterize an observer's confidence reports as over-confident or under-confident in this way can add an extra dimension of richness to understanding their metacognitive performance.</p><p>However, there may be cases where it is not trivial to decide which strategy the observer is attempting to follow, or ought to follow -especially when they do not receive explicit instruction on what strategy to use. In such cases where there are no clear grounds for saying what the observer's confidence should be, it follows that there are no clear grounds for characterizing their performance as over-or under-confident. A somewhat related and important point is that the same confidence behavior can be over-confident relative to one optimization strategy, and under-confident relative to another. Just as there is not a single, monolithic optimal strategy for rating confidence, but rather different strategies that are optimal relative to different objectives, similarly there is no such thing as over-or under-confidence in the abstract, but rather there is over-or under-confidence relative to a given standard. Thus, some caution and nuance is required when assessing an observer's putative over-or under-confidence.</p><p>One approach for quantifying over-or under-confidence in a standardized way is to normalize the distance of the actual type 2 criterion from the type 1 criterion by the distance of the optimal type 2 criterion from the type 1 criterion, i.e. (c 2 -c 1 ) / (c * 2 -c 1 ) <ref type="bibr" target="#b9">(Charles et al., 2020)</ref>. This ratio thus expresses type 2 criterion setting relative to the optimal standard, where over-confidence corresponds to the ratio being less than 1 (i.e., c 2 is "too close" to c 1 ), under-confidence corresponds to the ratio being greater than 1 (i.e., c 2 is "too far" from c 1 ), and optimality corresponds to the ratio being exactly 1. This approach has some affinity with the standardized expression of metacognitive sensitivity as the ratio of meta-d' to d' <ref type="bibr" target="#b29">(Maniscalco &amp; Lau, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Inferring Type 2 Criterion Setting when meta-d' ≠ d'</head><p>In most of the above, we considered evaluating an observer's metacognitive strategy using the formulae for optimal type 2 criteria in classical signal detection theory, which assumes meta-d' = d'. However, it is often the case empirically that meta-d' ≠ d'. In Section 2.5 we showed that in such cases an alternative model is needed to specify the computational processes governing the observer's metacognitive sensitivity, and optimal type 2 criterion setting according to this alternative model may differ from its classical SDT counterpart. How should assessment of the observer's type 2 criterion setting proceed in such cases?</p><p>The most thorough approach would be to consider the observer's data in light of a model that specifies computational processes which account for deviations from the metacognitive sensitivity expected by classical SDT, analogous to the simple type 2 noise or type 2 signal loss models considered in this paper. Ideally when applied to empirical data, the model's appropriateness for characterizing the data would be well-validated e.g. by model comparison analysis or by reference to previous research. This model could then be used to ascertain the optimal type 2 criteria, either by derived mathematical formulae or by simulations. The optimal type 2 criteria derived from the model could then be compared to the observer's actual type 2 criteria according to fits of the model to the observer's data, in line with the considerations discussed above <ref type="figure" target="#fig_1">(Sections 3.2.1, 3.2.2, and 3.2.3)</ref>.</p><p>Depending on the research question, the optimal type 2 criteria derived from classical SDT might still be of interest for shedding light on empirical data even in cases where meta-d' ≠ d'. For instance, it might be of interest to know how the observer would ideally set type 2 criteria if their metacognitive sensitivity were also ideal according to SDT, i.e. if it had been the case that the observer's meta-d' were equal to their empirically established d'. It might also be of interest to know how the ideal observer would set their type 2 criteria if they ignored deviations of metacognitive sensitivity from SDT-defined optimality. This question might be of particular interest in cases where the deviation of meta-d' from d' is small, and/or cases where neglecting sources of type 2 suboptimality has relatively negligible consequences for optimization outcomes (e.g. as in the type 2 noise model's behavior shown in <ref type="figure" target="#fig_15">Figure 9C &amp; 9F)</ref>.</p><p>Complications arising from meta-d' ≠ d' might also be relaxed in cases where the researcher is more interested in investigating qualitative patterns in type 2 criterion setting, rather than in computing exact type 2 criterion values. For instance, it is likely the case that for most plausible models allowing for meta-d' ≠ d', the qualitative patterns that type 2 criteria should become more liberal with increasing d', or more conservative with increasing Q 2 or O T , hold. (Indeed, simulations confirm that these qualitative patterns hold under type 2 noise. We do not show these data here, but provide code for running this analysis in the online toolbox.) If the researcher is mainly interested in assessing such qualitative patterns, then it may not be necessary to engage with the complexities of characterizing exact type 2 criterion values when meta-d' ≠ d'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Alternative optimization strategies and heuristics</head><p>As we have alluded to in the preceding discussion, it is important to keep in mind that there are many possible type 2 criterion setting strategies that an observer could adopt aside from the four main optimal strategies considered in this paper. One category of such alternative strategies might be partial adoption of an optimal strategy, as considered in Section 3.2.2; for instance, an observer might neglect to take stimulus priors into account when enacting a calibration strategy due to ignorance or resource limitations, while still adhering to the other components of the optimal strategy. It is also possible that an observer might choose a strategy that is optimal for some objective not considered in this paper; for example, one natural choice might be to make reports of high confidence maximally diagnostic of accuracy by maximizing p(correct|high confidence) -p(incorrect|high confidence) -a measure related to, but distinct from, HR 2 -FAR 2 . There are of course many other possible optimization contexts not discussed here, and exploration of them all is beyond the scope of the present project. Finally, an observer could employ a more heuristic strategy that does not optimize for any particular objective, but nonetheless serves some useful purpose. The present work is only an initial exploration of the rigorous study of optimal metacognitive decision strategies in an SDT framework, and will need to be built upon by subsequent theoretical and empirical research which further expands on the space of optimal and actual metacognitive decision strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Advantages and Disadvantages Vary by Strategy</head><p>Which type 2 criterion setting strategy an observer chooses to employ might depend on the relative advantages and disadvantages of the various strategies. Here we consider what those advantages and disadvantages might be. Since optimizing type 2 accuracy is limited to special cases where the observer is concerned with error detection, and since optimizing reward behaves similarly to calibration, we focus our discussion particularly on the comparison between optimizing type 2 calibration and maximizing HR 2 -FAR 2 .</p><p>Calibration tethers confidence reports to a fixed level of accuracy regardless of changes to the decision-making context, which makes such confidence reports clear, immediately applicable to managing uncertainty and risk and useful for informing subsequent decisions <ref type="bibr" target="#b3">(Balsdon et al., 2020;</ref><ref type="bibr" target="#b7">Boldt &amp; Gilbert, 2019;</ref><ref type="bibr" target="#b20">Guggenmos et al., 2016;</ref><ref type="bibr" target="#b45">Stolyarova et al., 2019)</ref>, and readily communicable to other observers in a social context and hence useful for group decision-making <ref type="bibr" target="#b2">(Bahrami et al., 2010</ref><ref type="bibr" target="#b1">(Bahrami et al., , 2012</ref><ref type="bibr" target="#b4">Bang et al., 2017;</ref><ref type="bibr" target="#b23">Koriat, 2012;</ref><ref type="bibr" target="#b34">Pescetelli et al., 2016)</ref>. By comparison, the objective to maximize HR 2 -FAR 2 may be relatively obscure and unintuitive to typical human and animal observers since it requires assessing the probability of high confidence conditional on correct and incorrect responses, and then computing their difference.</p><p>On the other hand, the complexity of implementing the calibration strategy is a potential disadvantage. Calibration requires (1) accurately tracking stimulus priors (p(S2)) and task performance (d'), and (2) utilizing these values in the proper way to compute the correct type 2 criteria <ref type="bibr">(Eqs. 24 &amp; 26)</ref>. These requirements are computationally demanding, and if the resource costs incurred by them are salient enough, it may actually be preferable for the observer to forgo attempting to implement the optimal calibration strategy and instead resort to simpler heuristics that approximate the optimal strategy well enough while incurring significantly less computational costs <ref type="bibr" target="#b0">(Adler &amp; Ma, 2018;</ref><ref type="bibr" target="#b21">Jones, 1999;</ref><ref type="bibr" target="#b41">Schwartz et al., 2011)</ref>. An additional difficulty arises from the fact that both p(S2) and d' are aggregate measures that characterize aspects of the decision-making context that only fully manifest over extended time periods or many trials, and so the observer may encounter further difficulties in accurately updating type 2 criteria to account for changes to the decision-making context. Indeed, preliminary evidence suggests that whereas type 2 criteria can adjust to changes in the decision-making context when these changes are grouped into temporally contiguous blocks of trials, such adjustment does not take place when the changes occur on faster time scales at the level of individual trials <ref type="bibr" target="#b28">(Maniscalco et al., 2020)</ref>.</p><p>By comparison, the strategy of maximizing HR 2 -FAR 2 is potentially far simpler and less resource-intensive to implement in that it does not depend on stimulus priors and is largely independent of changes in d'; rather, it mainly exhibits a relatively simple dependence on the observer's type 1 criterion <ref type="figure" target="#fig_12">(Figure 7)</ref>. Furthermore, we have shown that when stimulus priors are equal and the observer's type 1 criterion is unbiased ( ), optimizing HR 2 -FAR 2 is equivalent to calibrating confidence to 1 = 1 * one's average type 1 accuracy, suggesting that this strategy could function as a kind of convenient heuristic for approximating a reasonable and robust calibration strategy. Some preliminary evidence <ref type="bibr" target="#b9">(Charles et al., 2020)</ref> suggests that participants might indeed employ a type 2 criterion setting strategy that aims to maximize HR 2 -FAR 2 . In that study, participants reported their confidence on a 4-point scale; results demonstrated that participants placed the type 2 criteria separating ratings 2 and 3 (corresponding to the middle of the confidence scale) close to the location of the type 2 criteria that maximize HR 2 -FAR 2 . Further evidence is needed to confirm if optimizing HR 2 -FAR 2 is indeed a strategy widely employed by human observers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Application to Common Experimental Practices</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Optimal Type 2 Criterion Setting for Confidence Rating Scales with More than Two Levels</head><p>We have discussed optimal type 2 criterion setting when utilizing a binary confidence rating scale consisting of low vs high confidence. This entails setting a single type 2 criterion on either side of the type 1 criterion which separates low vs high confidence regions of the decision axis for each response type. However, many studies use more expansive confidence rating scales; common examples include 4-point scales (e.g. <ref type="bibr" target="#b9">(Charles et al., 2020)</ref>, 6-point scales (e.g. <ref type="bibr" target="#b8">(Boldt &amp; Yeung, 2015)</ref> and semi-continuous scales (e.g. <ref type="bibr" target="#b38">(Rahnev &amp; Fleming, 2019;</ref><ref type="bibr" target="#b40">Rouault et al., 2019)</ref>. In general, for an N-point confidence rating scale, N-1 type 2 criteria for each response type are required to divide the decision axis on either side of the type 1 criterion into N regions corresponding to the N confidence levels. Thus, the question naturally arises: how does the present treatment of optimal type 2 criteria for binary confidence ratings apply to more expansive rating scales requiring more than one type 2 criterion per response type?</p><p>A preliminary general observation is that although for many purposes it is convenient to reduce confidence rating to a binary low vs high judgment, such an approach does not necessarily preclude application to scales with more than two levels. For instance, type 2 ROC curves <ref type="bibr" target="#b12">(Clarke et al., 1959;</ref><ref type="bibr" target="#b17">Galvin et al., 2003;</ref><ref type="bibr" target="#b30">Maniscalco &amp; Lau, 2014)</ref> are an example of an analysis approach that both binarizes confidence ratings and also allows for consideration of the entire rating scale. This is accomplished by computing type 2 hit rate and false alarm rate for every possible binarization of the scale. For instance, a 4-point rating scale has three possible ways of being reduced to a 2-point scale, and each such binarization generates a corresponding (FAR 2 , HR 2 ) pair for use in type 2 ROC analysis.</p><p>However, most of the optimization contexts considered here involve finding the single, unique type 2 criterion for each response type that yields the single best outcome for the observer's objective. For instance, there is only one type 2 criterion (for a given response type) that yields the maximum possible type 2 accuracy, type 2 reward, or HR 2 -FAR 2 . Thus, the criteria that optimize these outcomes can only apply to one of the multiple type 2 criteria for a given response type when more than two levels of confidence can be reported.</p><p>Since optimizing type 2 accuracy entails reporting low confidence only when the response is likely to be an error, the corresponding optimal type 2 criteria may not be relevant for rating scales in which the lowest possible confidence rating is intended to denote responses that have minimal supporting evidence, as opposed to responses that are not merely uncertain but are actually suspected as likely to be incorrect. However, some confidence rating scales explicitly include options to indicate that the response was likely incorrect (e.g., <ref type="bibr" target="#b8">(Boldt &amp; Yeung, 2015)</ref>); for such scales, the optimal type 2 criteria for maximizing type 2 accuracy provide a natural characterization of what value should be used for the type 2 criteria separating "likely incorrect" from "likely correct" ratings.</p><p>The type 2 criterion optimizing HR 2 -FAR 2 for a given response type occurs at intermediate values on the decision axis <ref type="figure" target="#fig_12">(Figure 7)</ref> and thus could be an appropriate target for one of the type 2 criteria in a typical task. For example, this is consistent with the previously mentioned finding that in one data set, participants set the type 2 criteria separating confidence ratings of 2 and 3 at a value consistent with the criterion that maximizes HR 2 -FAR 2 <ref type="bibr" target="#b9">(Charles et al., 2020)</ref>. Similarly, a reward matrix that is contingent upon type 2 outcomes as outlined in <ref type="table" target="#tab_4">Table 4</ref> implies a single type 2 criterion for each response type that yields maximum reward. It is possible that an expanded reward matrix that includes different reward outcomes for each level of an N-point rating scale for N &gt; 2, contingent on the accuracy of the type 1 response, could specify normative values for each of the N-1 type 2 criteria and thereby be applicable to N-point rating scales. We leave investigation of this possibility to future work.</p><p>The notable exception here is the calibration framework, which naturally extends to arbitrarily many type 2 criteria and thus to arbitrarily large rating scales. This is because it is natural to evaluate confidence with reference to many threshold levels of accuracy, none of which are mutually exclusive with the others. For instance, to utilize a 4-point rating scale, one might set three type 2 criteria corresponding to accuracy thresholds of 70%, 80%, and 90% correct. There is only one optimal type 2 criterion for each threshold level of accuracy, but arbitrarily many such thresholds can be evaluated simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Using Average Confidence as a Proxy for Type 2 Criterion Setting</head><p>It is common practice for researchers to analyze average confidence ratings, and these are sometimes taken as a kind of proxy for measuring type 2 criterion setting or metacognitive bias per se. However, caution is needed in making inferences about an observer's metacognitive decision strategy from average confidence, since according to SDT confidence depends on d' and c 1 as well as the observer's type 2 criteria, and only the latter pertain directly to the observer's metacognitive decision strategy per se.</p><p>The influence of d' upon average confidence is easy to understand. Holding type 1 and type 2 criteria constant, increasing d' has the effect of increasing the separation of the evidence distributions for S1 and S2 stimuli, with the result that a higher proportion of the distributions' probability mass exceeds the type 2 criteria and therefore higher levels of confidence are more frequently reported. Thus, it is possible for changes in confidence to be driven entirely by changes in d', even as an observer's type 2 criteria remain fixed. As a consequence, it is not appropriate to use average confidence to assess the influence of d' upon metacognitive decision strategy, but rather a modeling approach must be used to isolate type 2 criterion setting independent of changes in d'. For other purposes it may still be appropriate to use average confidence as a proxy for type 2 criterion setting, but only if d' is held constant across conditions.</p><p>The effect of c 1 upon average confidence is more subtle. Changes in c 1 can alter average confidence if the observer employs a strategy that adjusts type 2 criteria for "S1" and "S2" responses relative to c 1 . For instance, suppose an observer adopts a simple strategy of always setting c 2,"S1" = c 1 -1 and c 2,"S2" = c 1 + 1. Suppose in condition A, d' = 2 and c 1 = 0; then c 2,"S1" = -1, c 2,"S2" = 1, and the observer's average p(high confidence) = 0.52. Suppose in condition B, d' remains constant but c 1 shifts to a new value of 1; then c 2,"S1" = 0, c 2,"S2" = 2, and the observer's average p(high confidence) = 0.58. The rightward shift of the decision criteria causes an increase in average confidence for "S1" responses (p(high confidence) = 0.68) and a decrease in average confidence for "S2" responses (p(high confidence) = 0.31), while also making "S1" responses more frequent overall (p("S1" response) = 0.74), with the net effect that overall confidence increases. When c 1 is biased (c 1 ≠ 0), p(S2) can also influence response-conditional and overall average confidence. Thus, it is recommended to keep not only d' but also c 1 and p(S2) constant across conditions if using average confidence to make inferences about metacognitive decision strategy.</p><p>To summarize, because average confidence depends on a range of factors in addition to type 2 criterion setting, it follows that average confidence is only appropriate for making inferences about metacognitive decision strategy (i.e. type 2 criterion setting) when other factors are properly controlled. This entails ensuring that d', c 1 , and p(S2) are held constant across conditions where average confidence is compared. But this constraint requires some experimental finesse to achieve in real data, and furthermore restricts one from investigating the potential role of d', c 1 , and p(S2) in an observer's type 2 criterion setting strategy. Thus, for many purposes it may be preferable to use a modeling approach to make inferences about metacognitive decision strategies by reference to type 2 criterion setting, rather than using average confidence. This is not to say that average confidence is not an interesting or relevant measure in its own right, only that it is not an ideal tool for making specific inferences about metacognitive decision strategy per se.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Closing Remarks</head><p>Here, we have used type 2 signal detection theory to derive optimal metacognitive criterion setting strategies under four optimization contexts: type 2 accuracy, type 2 reward, calibration of confidence to accuracy, and maximizing the difference between type 2 hit rate and false alarm rate. Our formal derivation approach provides both theoretical and practical contribution to the study of decision-making and metacognition. Further, our simulation code provides a practical tool by which researchers in the field may explore the impact of metacognitive suboptimality on confidence judgments across a wide range of situations and tasks. Together, our findings represent a significant step forward in the scientific study of metacognitive evaluation of decisions made under uncertainty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX: Derivations of Optimal Type 1 and Type 2 Criteria</head><p>A1. Optimizing Accuracy A1.1. Optimal Type 1 Criterion for Maximizing Type 1 Accuracy Suppose an observer with perceptual sensitivity d' wishes to place the type 1 criterion c1 so as to maximize the proportion of correct responses in discriminating two stimulus classes, S1 and S2, where p(S1) and p(S2) denote the prior probabilities of S1 and S2 being presented on a given trial. The measure to be optimized, proportion correct, can be expressed as</p><formula xml:id="formula_52">( ) = ( 2) + ( 1) (1 − )<label>( 1)</label></formula><p>where HR = hit rate = p(response = "S2" | stimulus = S2) and FAR = false alarm rate = p(response = "S2" | stimulus = S1). For a given d' and c1, HR and FAR can be expressed in the equal variance signal detection theory model as</p><formula xml:id="formula_53">= 1 − ( 1 | ′ 2 ) ( 2) = 1 − ( 1 |− ′ 2 )<label>( 3)</label></formula><p>where ( | ) is the cumulative distribution function of the normal distribution with mean and standard deviation = 1 evaluated at x. (Here we set = 1 for convenience, without loss of generality, as d' corresponds to the signal-to-noise ratio 2 − 1 .)</p><p>To find the criterion c1 that maximizes p(correct), we set the derivative of p(correct) with respect to c1 equal to zero and solve for c1. The derivative is given by</p><formula xml:id="formula_54">1 [ ( )] = − ( 2) ( 1 | ′ 2 ) + ( 1) ( 1 |− ′ 2 )<label>( 4)</label></formula><p>where ( | ) is the probability density function of the normal distribution with mean and standard deviation = 1 evaluated at x:</p><formula xml:id="formula_55">( | ) = 1 √2 − ( − ) 2 2 ( 5)</formula><p>Setting the derivative equal to zero and solving for c1 gives</p><formula xml:id="formula_56">( 2) ( 1 | ′ 2 ) = ( 1) ( 1 |− ′ 2 ) ln ( 1) ( 2) = ln ( 1 | ′ 2 ) ( 1 |− ′ 2 ) = − ( 1 − ′ 2 ) 2 2 − − ( 1 + ′ 2 ) 2 2 = 1 ′ 1 * = ln ( 1) ( 2) ′ ( 6)</formula><p>where the "A*" superscript denotes that Equation A6 defines the optimal c1 for maximizing type 1 accuracy (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1.2.2. Optimal Type 2 Criterion for Maximizing Type 2 Accuracy for "S2" Responses</head><p>Next, suppose the observer wishes to place the type 2 criterion c2 so as to maximize the proportion of correct responses in rating "high confidence" for correct type 1 responses and "low confidence" for incorrect type 1 responses, when responding "S2". The observer must set the type 2 criterion for "S2" responses, 2," 2" , so as to maximize p(correct2,"S2"):</p><formula xml:id="formula_57">( 2," 2" ) = ( 1," 2" ) 2," 2" + ( 1," 2" ) (1 − 2," 2" )<label>( 7)</label></formula><p>where HR2,"S2" and FAR2,"S2" correspond to type 2 hit rate and false alarm rate for "S2" responses:</p><formula xml:id="formula_58">2," 2" = 1 − ( 2," 2" | ′ 2 ) 1 ( 8) 2," 2" = 1 − ( 2," 2" |− ′ 2 ) 1 ( 9)</formula><p>and where p(correct1,"S2") and p(incorrect1,"S2") correspond to the probability of a correct or incorrect type 1 decision, given that the type 1 response was "S2":</p><p>( 1," 2" ) = ( = 2 | = " 2") ( 10) ( 1," 2" ) = ( = 1 | = " 2")</p><p>Eqs. A10 and A11 can be re-expressed as Thus, substituting Eqs. A8-9 and A12-13 into Eq. A7, p(correct2,"S2") can be written</p><formula xml:id="formula_60">( 2," 2" ) = ( 2) 1 ( = " 2") 1 − ( 2," 2" | ′ 2 ) 1 + ( 1) 1 ( = " 2") ( 1 − ( 1 − ( 2," 2" |− ′ 2 ) 1 ) ) Simplifying, ( 2," 2" ) = ( 2) ( = " 2") (1 − ( 2," 2" | ′ 2 )) + ( 1) ( = " 2") ( 1 − 1 + ( 2," 2" |− ′ 2 ))</formula><p>Differentiating with respect to c2,"S2" gives</p><formula xml:id="formula_61">2," 2" [ ( 2," 2" )] = − ( 2) ( = " 2") ( 2," 2" | ′ 2 ) + ( 1) ( = " 2") ( 2," 2" |− ′ 2 )<label>( 14)</label></formula><p>Setting the derivative equal to zero and solving for c2,"S2" gives</p><formula xml:id="formula_62">( 2) ( = " 2") ( 2," 2" | ′ 2 ) = ( 1) ( = " 2") ( 2," 2" |− ′ 2 ) log ( 1) ( 2) = ln ( 2," 2" | ′ 2 ) ( 2," 2" |− ′ 2 ) = 2," 2" ′ 2," 2" = ln ( 1) ( 2) ′<label>( 15)</label></formula><p>Enforcing the constraint that 2," 2" ≥ 1 yields a final solution for c2,"S2" as</p><formula xml:id="formula_63">2," 2" * = max ( ln ( 1) ( 2) ′ , 1 )<label>( 16)</label></formula><p>where the "A*" superscript denotes that Equation A16 defines the optimal c2,"S2" for maximizing type 2 accuracy (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p><p>A1.2.2. Optimal Type 2 Criterion for Maximizing Type 2 Accuracy for "S1" Responses For "S1" responses, the observer must set the type 2 criterion for "S1" responses, c2,"S1", so as to maximize p(correct2,"S1"):</p><formula xml:id="formula_64">( 2," 1" ) = ( 1," 1" ) 2," 1" + ( 1," 1" ) (1 − 2," 1" )<label>( 17)</label></formula><p>where</p><formula xml:id="formula_65">2," 1" = ( 2," 1" |− ′ 2 ) (1 − 1 )<label>( 18)</label></formula><p>2," 1" =</p><formula xml:id="formula_66">( 2," 1" | ′ 2 ) (1 − 1 )<label>( 19)</label></formula><formula xml:id="formula_67">( 1," 1" ) = ( 1) (1 − 1 ) ( = S1)<label>( 20)</label></formula><formula xml:id="formula_68">( 1," 1" ) = ( 2) (1 − 1 ) ( = S1)<label>( 21)</label></formula><p>Substituting Eqs. A18-21 into Eq. A17, p(correct2,"S2") can be written</p><formula xml:id="formula_69">( 2," 1" ) = ( 1) (1 − 1 ) ( = " 1") ( 2," 1" |− ′ 2 ) (1 − 1 ) + ( 2) (1 − 1 ) ( = " 1") ( 1 − ( ( 2," 1" | ′ 2 ) (1 − 1 ) ) )</formula><p>which simplifies to</p><formula xml:id="formula_70">( 2," 1" ) =<label>( 1)</label></formula><formula xml:id="formula_71">( = " 1") ( 2," 1" |− ′ 2 ) + ( 2) ( = S1) ((1 − 1 ) − ( 2," 1" | ′ 2 ))</formula><p>Differentiating with respect to c2,"S1" gives</p><formula xml:id="formula_72">2," 1" [ ( 2," 1" )] = ( 1) ( = " 2") ( 2," 1" |− ′ 2 ) − ( 2) ( = " 2") ( 2," 1" | ′ 2 ) ( 22)</formula><p>Setting the derivative equal to zero and solving for c2,"S1" gives</p><formula xml:id="formula_73">( 1) ( = " 2") ( 2," 1" |− ′ 2 ) =</formula><p>( 2) ( = " 2")</p><formula xml:id="formula_74">( 2," 1" | ′ 2 ) log ( 1) ( 2) = ln ( 2," 1" | ′ 2 ) ( 2," 1" |− ′ 2 ) = 2," 1" ′ 2," 1" = ln ( 1) ( 2) ′<label>( 23)</label></formula><p>Enforcing the constraint that 2," 1" ≤ 1 yields a final solution for c2,"S1" as</p><formula xml:id="formula_75">2," 1" * = min ( ln ( 1) ( 2) ′ , 1 )<label>( 24)</label></formula><p>where the "A*" superscript denotes that Equation A24 defines the optimal c2,"S1" for maximizing type 2 accuracy (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2. Optimizing Reward</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.1. Optimal Type 1 Criterion for Maximizing Type 1 Reward Contingencies</head><p>Suppose the observer wishes to place the type 1 criterion so as to maximize the reward earned via an environmental structure that differentially rewards different type 1 responses. The observer must set c1 so as to maximize expected reward from a type 1 reward contingency table:</p><formula xml:id="formula_76">( ) = ( 2)[ ℎ + (1 − )] + ( 1)[ (1 − ) + ]<label>( 25)</label></formula><p>where Rhit, Rmiss, RCR, and RFA correspond to the number of points gained or lost following hits, misses, correct rejections, and false alarms (see <ref type="table">Table 2</ref> in the main manuscript). To find the criterion c1 that maximizes E(reward), we substitute for HR and FAR using Eqs. A2 and A3, set the derivative of E(reward) with respect to c1 equal to zero, and solve for c1. The derivative is given by</p><formula xml:id="formula_77">1 [ ( )] = ( 2) [− ℎ ( 1 | ′ 2 ) + ( 1 | ′ 2 )] + ( 1) [ ( 1 |− ′ 2 ) − ( 1 |− ′ 2 )]<label>( 26)</label></formula><p>where ( | ) is the probability density function of the normal distribution with mean and variance = 1 evaluated at x, as given in Eq. A5.</p><p>Setting the derivative equal to zero and solving for c1 gives where the "R*" superscript denotes that Equation A27 defines the optimal c1 for maximizing type 1 reward (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p><p>A2.2.1. Optimal Type 2 Criterion for Maximizing Type 2 Reward Contingencies for "S2" Responses Now suppose the observer wishes to maximize earned reward, where reward assignment is controlled by type 2 response categories. For "S2" responses, the observer must set the type 2 criterion for "S2" responses, c2,"S2", so as to maximize E(reward2,"S2"):</p><p>( 2," 2" ) = (ℎ 1 , |"S2") 2 + (ℎ 1 , |"S2") ℎ 2 + ( 1 , |"S2") 2 + ( 1 , |"S2") 2</p><p>where e.g. p(hit1, LC | "S2") is the probability of a low confidence hit given that the observer responded "S2," or more formally, (ℎ 1 , |"S2") = ( = 2, = | = " 2") = ( = 2 ∩ = "S2" ∩ = ) ( = "S2")</p><p>This expression can be re-written as (ℎ 1 , |"S2") = ( 2) 1 (1 − 2," 2" ) ( = "S2")</p><p>and similarly, (ℎ 1 , |"S2") = ( 2) 1 2," 2" ( = "S2")</p><p>( 1 , |"S2") = ( 1) 1 (1 − 2," 2" ) ( = "S2")</p><p>( 1 , |"S2") = ( 1) 1 2," 2" ( = "S2")</p><p>Rearranging the equation for E(reward2,"S2") (Eq. A28) and using Eqs. A8-9 to substitute for the HR2,"S2" and FAR2,"S2" terms gives ( 2," 2" ) =</p><p>( 2) 1 (1 − 2," 2" ) ( = " 2") 2 +</p><p>( 2) 1 2," 2" ( = " 2") ℎ 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+</head><p>( 1) 1 (1 − 2," 2" ) ( = " 2") 2 + Differentiating with respect to c2,"S2" gives </p><formula xml:id="formula_84">+ ln ( 2 − 2 ) ( ℎ 2 − 2 ) ′<label>( 2)</label></formula><p>Enforcing the constraint that 2," 2" ≥ 1 yields a final solution for c2,"S2" as 2," 2" * = max (</p><formula xml:id="formula_86">ln ( 1) ( 2) + ln ( 2 − 2 ) ( ℎ 2 − 2 ) ′ , 1 )<label>( 35)</label></formula><p>where the "R*" superscript denotes that Equation A35 defines the optimal c2,"S2" for maximizing type 2 reward (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p><p>A2.2.2. Optimal type 2 Criterion for Maximizing Type 2 Reward Contingencies for "S1" Responses For "S1" responses, the observer must set the type 2 criterion for "S1" responses, c2,"S1", so as to maximize E(reward2,"S1"):</p><p>( 2," 1" ) = ( 1 , |"S1") 2 + ( 1 , |"S1") ℎ 2 + ( 1 , |"S1") 2 + ( 1 , |"S1") 2</p><p>where e.g. p(CR1, LC | "S1") is the probability of a low confidence correct rejection given that the observer responded "S1." By similar reasoning for the derivation of Eq. A29, we can write</p><p>( 1 , |"S1") = ( 1) (1 − 1 ) (1 − 2," 1" ) ( = "S1")</p><p>( 1 , |"S1") = ( 1) (1 − 1 )</p><p>2," 1" ( = "S1")</p><p>( 1 , |"S1") =</p><p>( 2) (1 − 1 ) (1 − 2," 1" ) ( = "S1")</p><p>( 1 , |"S1") = ( 2) (1 − 1 )</p><p>2," 1" ( = "S1")</p><p>Rearranging the equation for E(reward2,"S1") (Eq. A36) and using Eqs. A18-19 to substitute for the HR2,"S1" and FAR2,"S1" terms gives ( 2," 1" ) =</p><p>( 1) (1 − 1 ) (1 − 2," 1" ) ( = " 1") 2 +</p><p>( 1) (1 − 1 )</p><p>2," 1" ( = " 1") ℎ 2 +</p><p>( 2) (1 − 1 ) (1 − 2," 1" ) ( = " 1") 2 +</p><p>( 2) (1 − 1 )</p><p>2," 1" ( = " 1") ( 2," 1" ) =</p><p>( 1) (1 − 1 ) ( = " 1") [(1 − 2," 1" ) 2 + 2," 1" ℎ 2 ] +</p><p>( 2) (1 − 1 ) ( = " 1") [(1 − 2," 1" ) 2 + 2," 1" 2 ] Differentiating with respect to c2,"S1" gives </p><p>Setting the derivative equal to zero and solving for c2,"S1" gives</p><p>( 1) ( 2," 1" |− ′ 2 ) ( ℎ 2 − 2 ) = − ( 2) ( 2," 1" | </p><p>Enforcing the constraint that 2," 1" ≤ 1 yields a final solution for c2,"S1" as 2," 1" * = min (</p><formula xml:id="formula_95">ln ( 1) ( 2) + ln ( ℎ 2 − 2 ) ( 2 − 2 ) ′ , 1 )<label>( 43)</label></formula><p>where the "R*" superscript denotes that Equation A43 defines the optimal c2,"S1" for maximizing type 2 reward (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3. Optimizing Calibration</head><p>(In the below we intentionally decline to include a Section A3.1, as optimizing type 2 calibration does not have a natural analogue in the type 1 case.)</p><p>Suppose the observer wishes to place high confidence ratings to reflect that some benchmark of type 1 accuracy has been achieved. For instance, the observer may choose to rate "high confidence" only when the estimated probability of a correct type 1 choice, p(correct1), exceeds 0.8.</p><p>More formally, let p(correct1)T be the threshold value of accuracy needed to report high confidence (where T denotes threshold), and let p(correct1|x) be the observer's estimate of being correct on the current trial based upon the evidence sample x. Then the observer seeking to calibrate confidence to accuracy uses the following decision policy for rating confidence:</p><formula xml:id="formula_96">= { ℎ ℎ, ( 1 | ) &gt; ( 1 ) , ( 1 | ) ≤ ( 1 )<label>( 44)</label></formula><p>The computation of the type 2 criterion that achieve this decision policy differs for "S1" and "S2" responses.</p><p>A3.2.1. Optimal Type 2 Criterion for Calibrating "S2" Responses On trials where the observer responds "S2," the quantity the observer must consider in order to calibrate confidence to accuracy is p(correct1,"S2"|x), where p(correct1,"S2") denotes probability of a correct type 1 response, given that the response was "S2". Since "S2" responses are correct whenever the stimulus is S2, it follows that p(correct1,"S2"|x) = p(stim=S2|x), where p(stim=S2|x) is given by the relative likelihood that x was generated by S2 rather than S1: </p><formula xml:id="formula_97">(</formula><p>Following Eq. A44, the observer must report high confidence for "S2" responses when p(correct1,"S2"|x) &gt; p(correct1)T. This objective can be accomplished by setting the type 2 criterion c2,"S2" at the location of the decision axis value x where p(correct1,"S2"|x) = p(correct1)T :</p><p>( 1 ) =</p><p>( 2) ( 2," 2" | ′ 2 )</p><p>( 1) ( 2," 2" |− ( 1) ( 2) + ln ( 1 ) 1 − ( 1 ) = 2," 2" ′ 2," 2" = ln ( 1)</p><formula xml:id="formula_99">+ ln ( 1 ) 1 − ( 1 ) ′<label>( 2)</label></formula><p>Enforcing the constraint that 2," 2" ≥ 1 yields a final solution for c2,"S2" as 2," 2" * = max (</p><formula xml:id="formula_101">ln ( 1) ( 2) + ln ( 1 ) 1 − ( 1 ) ′ , 1 )<label>( 48)</label></formula><p>where the "C*" superscript denotes that Equation A48 defines the optimal c2,"S2" for maximizing type 2 calibration (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p><p>A3.2.2. Optimal Type 2 Criterion for Calibrating "S1" Responses Following similar logic as for "S2" responses, the probability of being correct given a particular evidence value x for an "S1" response is given by </p><p>Following Eq. A44, the observer must report high confidence for "S1" responses when p(correct1,"S1"|x) &gt; p(correct1)T. This objective can be accomplished by setting the type 2 criterion c2,"S1" at the location of the decision axis value x where p(correct1,"S1"|x) = p(correct1)T :</p><p>( 1 ) =</p><p>( 1) ( 2," 1" |−</p><p>( 1) ( 2," 1" |− </p><formula xml:id="formula_104">+ ln 1 − ( 1 ) ( 1 ) ′<label>( 2)</label></formula><p>Enforcing the constraint that 2," 1" ≤ 1 yields a final solution for c2,"S1" as 2," 1" * = min (</p><formula xml:id="formula_106">log ( 1) ( 2) + log 1 − ( 1 ) ( 1 ) ′ , 1 )<label>( 52)</label></formula><p>where the "C*" superscript denotes that Equation A52 defines the optimal c2,"S1" for maximizing type 2 calibration (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p><p>A4. Optimizing HR -FAR A4.1. Optimal Type 1 Criterion for Maximizing HR1 -FAR1</p><p>Suppose the observer has the objective of maximizing the difference between type 1 hit rate and type 1 false alarm rate:</p><formula xml:id="formula_107">1 = 1 − 1<label>( 53)</label></formula><p>where HR1 and FAR1 are defined as in Eqs. A2 and A3, respectively. Thus, D1 can be written</p><formula xml:id="formula_108">1 = 1 − ( 1 | ′ 2 ) − (1 − ( 1 |− ′ 2 )) = − ( 1 | ′ 2 ) + ( 1 |− ′ 2 )</formula><p>Differentiating with respect to c1 gives</p><formula xml:id="formula_109">1 [ 1 ] = − ( 1 | ′ 2 ) + ( 1 |− ′ 2 )<label>( 54)</label></formula><p>Setting the derivative equal to zero and solving for c1 gives</p><formula xml:id="formula_110">( 1 | ′ 2 ) = ( 1 |− ′ 2 ) ln ( 1 | ′ 2 ) ( 1 |− ′ 2 ) = ln 1 1 ′ = 0 1 * = 0<label>( 55)</label></formula><p>where the "HF*" superscript denotes that Equation A55 defines the optimal c1 for maximizing the difference between type 1 hit rate and type 1 false alarm rate (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p><p>A4.2.1. Optimal Type 2 Criterion for Maximizing H2 -FAR2 for "S2" Responses Suppose the observer has the objective of maximizing the difference between type 2 hit rate and type 2 false alarm rate:</p><formula xml:id="formula_111">2 = 2 − 2<label>( 56)</label></formula><p>For "S2" responses, the observer must set the type 2 criterion for "S2" responses, c2,"S2", so as to maximize D2,"S2":</p><p>2," 2" = 2," 2" − 2," 2"</p><p>where HR2,"S2" and FAR2,"S2" are defined as in Eqs. A8 and A9, respectively. Thus, D2,"S2" can be written Enforcing the constraint that 2," 2" ≥ 1 yields a final solution for c2,"S2" as 2," 2" * = max ( ln</p><formula xml:id="formula_113">1 1 ′ , 1 )<label>( 61)</label></formula><p>where the "HF*" superscript denotes that Equation A61 defines the optimal c2,"S2" for maximizing the difference between type 2 hit rate and type 1 false alarm rate (see <ref type="table" target="#tab_0">Table 1</ref>, main text).</p><p>A4.2.2. Optimal Type 2 Criterion for Maximizing H2 -FAR2 for "S1" Responses For "S1" responses, the observer must set the type 2 criterion for "S1" responses, c2,"S1", so as to maximize D2,"S1":</p><p>2," 1" = 2," 1" − 2," 1"</p><p>where HR2,"S1" and FAR2,"S1" are defined as in Eqs. A18 and A19, respectively. Thus, D2,"S2" can be written</p><formula xml:id="formula_115">2," 1" = ( 2," 1" |− ′ 2 ) (1 − 1 ) − ( 2," 1" | ′ 2 ) (1 − 1 )<label>( 63)</label></formula><p>Differentiating with respect to c2,"S1" gives 2," 1"</p><formula xml:id="formula_116">[ 2," 1" ] = 1 (1 − 1 ) ( 2," 1" |− ′ 2 ) − 1 (1 − 1 ) ( 2," 1" | ′ 2 )<label>( 64)</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Example of four distinct outcome measures as a function of the positions of the confidence criteria.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .*</head><label>3</label><figDesc>Optimal position of the first-order criterion which maximizes first-order accuracy as a 1 function of d' and p(S2). Each row represents different probabilities of stimulus presentation: (A) p(S2) = 0.5; (B) p(S2) = 0.3; (C) p(S2) = 0.15. Here instead of the traditional probability density functions conditional upon stimulus presentation, f(x|S1) and f(x|S2), we plot joint distribution functions f(x, S1) and f(x, S2) in the left column for a fixed d' value of 2 to illustrate how stimulus priors affect optimal criterion setting. In this representation, the optimal type 1 criterion corresponds to where the 1 * functions intersect; thus e.g. as f(x, S2) loses probability mass with the reduction of p(S2) (solid black lines in left column), the location where f(x, S1) and f(x, S2) intersect becomes increasingly positive, meaning becomes increasingly conservative. Plots in the right column show how the value of this 1 * increasingly conservative criterion is modulated by different d' values. Y-axes in the right panels represent the internal decision axis, as displayed in the left panels. Similarly, as p(S2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Positions of the optimal type 2 d' (x-axis), for different type 1 criteria c 1 (columns) and ratios of stimulus probability (rows).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>Figure 4B, red solid line). However, if priors are equal and the observer sets c 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>such that takes on extreme values when d' is very small (with the sign and magnitude determined 1 * by the disparity in the priors), and asymptotes towards zero as d' approaches infinity(Figure 2). The optimal type 2 criteria and inherit this behavior(Figure 4, middle and bottom rows), subject</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 5. Positions of the optimal type 2 criteria and when maximizing type 2 reward 2," 1" *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>24 and 26, respectively)  are provided in Sections A3.2.1 and A3.2.2 of the Appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 .</head><label>6</label><figDesc>Positions of the optimal type 2 criteria and when calibrating confidence to a accuracy p(correct 1 ) T , according to type 1 d' (x-axis), for different values of p(correct 1 ) T (0.7 and 0.8; rows) and type 1 criterion (columns). The red shaded areas represent the zone in which the observer reports low confidence. The optimal criteria (red dashed line) and (red solid line)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>via</head><label></label><figDesc>Eqs. 29 and 31, respectively) are provided in Sections A4.2.1 and A4.2.2 of the Appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 .</head><label>7</label><figDesc>Positions of the optimal type 2 and false alarm rates according to type 1 d' (x-axis), for different values of type 1 criterion c 1 (columns). The red shaded areas represent the zone in which the observer reports low confidence. The optimal criteria (red dashed line) and (red solid line) are shown on each side 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 8 .</head><label>8</label><figDesc>Example illustrations of how type 2 noise affects optimal type 2 criterion setting by changing the distribution of the outcome measure to be optimized. (A) The standard signal detection theoretic framework is shown for reference, with values of d' = 2 and c 1 = 0. (B) Expected type 2 reward (given Q 2 =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 9 .</head><label>9</label><figDesc>Simulation of the effect of type 2 noise on the optimal type 2 criterion for "S2" responses when optimizing type 2 reward (A-C) or HR 2 -FAR 2 (D-F). (A&amp;D) Effect of different values of type 2 noise (from top to bottom, σ 2 = 0.2, 0.8 , or 1.2) on the expected reward (A, thick line) and on the type 2 hit and false alarm rate difference (B, thick line) according to the position of c 2,"S2" . The optimal type 2 criterion 2," 2" * (i.e. the criterion that maximizes the function) for each value of type 2 noise is displayed as a large red dot. For comparison, the same function in the absence of type 2 noise is displayed as a thin line, and the corresponding optimal type 2 criterion in the absence of type 2 noise is shown as a small red dot. (B&amp;E)Value of the optimal type 2 criterion as a function of type 2 noise σ 2 when optimizing type 2 or HR 2 -FAR 2 (E). Optimal type 2 criteria for the values of type 2 noise simulated in (A) and (D) are highlighted by red dots, and the corresponding values of M ratio are indicated. (C&amp;F) Expected reward (C) and HR 2 -FAR 2 (F) achieved at the optimal type 2 criterion, plotted as a function of type 2 noise, separately for when type 2 noise is taken into account (thick line) or ignored (thin line) in the estimation of the optimal type 2 criterion. The values of the expected reward (C) and HR 2 -FAR 2 (F) for the values of type 2 noise simulated in (A) and (D) are highlighted by red dots. The thin lines in (C) and (F) represent the outcome that the observer achieves if they set c 2,"S2" optimally under the assumption that σ 2 = 0, i.e. if they neglect to take type 2 noise into account when setting c 2,"S2" but are otherwise optimal. This corresponds to the value of the objective functions from (A) and (D) under type 2 noise conditions (thick black lines) where the optimal under no type 2 noise (thin red lines) crosses the2," 2" * function. The thick lines in (C) and (F) represent the outcome that the observer achieves if they set 2," 2" * optimally when taking into account σ 2 . This corresponds to the maxima of the objective functions from (A) and (D) under type 2 noise conditions (thick black lines), as picked out by the optimal under</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>(B) or HR 2 -FAR 2 (E). Optimal type 2 criteria for the values of type 2 signal loss simulated in (A) and (D) are highlighted by red dots, and the corresponding values of M ratio are indicated. (C&amp;F) Expected reward (C) and HR 2 -FAR 2 (F) achieved at the optimal type 2 criterion, plotted as a function of type 2 signal loss, separately for when type 2 signal loss is taken into account (thick line) or ignored (thin line) in the estimation of the optimal type 2 criterion. The values of the expected reward (C) and HR 2 -FAR 2 (F) for the values of type 2 signal loss simulated in (A) and (D) are highlighted by red dots. The thin lines in (C) and (F) represent the outcome that the observer achieves if they set c 2,"S2" optimally under the assumption that k = 0 and σ 2 = 0, i.e. if they neglect to take type 2 signal loss and noise into account when setting c 2,"S2" but are otherwise optimal. This corresponds to the value of the objective functionsfrom (A) and (D) under type 2 signal loss conditions (thick black lines) where the optimal under no loss (thin red lines) crosses the function. The thick lines in (C) and (F) represent the outcome that the observer achieves if they set optimally when taking into account k and σ 2 . This 2," 2" * corresponds to the maxima of the objective functions from (A) and (D) under type 2 signal loss conditions (thick black lines), as picked out by the optimal under type 2 signal loss (thick red lines).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 11 .</head><label>11</label><figDesc>Effect of type 2 noise and signal loss parameters on M ratio and on the position of the optimal confidence criterion . (A) Effect of type 2 noise (σ 2 , light blue) and type 2 signal loss (k, dark blue) 2," 2" * on M ratio . (B-C) Position of according to the M ratio resulting from different levels of type 2 noise (σ 2 , 2," 2" * light blue) and type 2 signal loss (k, dark blue), when maximizing type 2 reward (B) or HR 2 -FAR 2 (C).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>*</head><label></label><figDesc>related to the optimal type 1 criterion for maximizing type 1 accuracy ( ): the optimal 1 strategy is essentially to place the type 2 criteria as close as possible to the type 1 criterion, subject to consistency constraints(Eqs. 6 &amp; 9). When the type 1 criterion is optimal (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>of d'. In the limit as d'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>constraints (Eqs. 24 &amp; 26). Their distance from depends on the odds ratio of 1 *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>false alarm rate(Eqs. 29 &amp; 31). Another distinct characteristic of this strategy is that for a fixed value of c 1 , and are relatively independent of d', unlike the optimal type 2 criteria for contexts (compareFigure 7toFigures</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>, and expanded</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Reward contingency table for type 1 responses. R indicates the points to be gained or lost under each response category.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table /><note>Reward contingency table for type 2 responses. As before, R indicates the points to be gained or lost under each response category.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Throughout the manuscript we use "type 1" and "first-order" interchangeably, and "type 2", "second-order", and "metacognitive" interchangeably.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This follows the convention of specifying "S1" (in quotes) as an observer's response when reporting that they believe the stimulus belongs to the S1 category, as opposed to denoting the true stimulus category.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">suppose that the observer sets two type 2 decision criteria on the decision axis, one on either side of the type 1 criterion c 1 . These correspond to the criteria used to rate confidence separately for "S1" and "S2" responses, and so we call them c 2,"S1" and c 2,"S2" .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">It is worth noting that the type 2 report could also be about something other than confidence, such as subjective clarity of the stimulus. It is also frequently assumed that the type 2 response scale could take on multiple ordinal categories (e.g., response on a scale of 1-4) or even continuous reporting (e.g., an analog slider for type 2 report). In such cases, however, it is always possible to reduce the confidence data into a binary high vs low categorization, e.g. by applying a median split.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">It is also possible to create type 2 ROC curves within a single experiment or condition by having the type 2 rating scale offer more than two levels, as briefly mentioned above. Although many investigations use this method, the optimal setting of more than one type 2 criterion is beyond the scope of this paper. See Section 3.4.1 for further discussion.5  Note that the distributions must be renormalized before they are proper probability density functions such that the total area under each curve sums to 1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">It is possible to define type 2 rewards differently for "S1" and "S2" responses, which might make sense in some experimental designs or situations. However, here for simplicity we only consider the case where the same type 2 rewards are available regardless of the type 1 response category.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The presence of Gaussian type 2 noise entails that the integrals corresponding to p(high confidence) terms in the SDT model contain the normal cumulative distribution function, which has no closed form expression. It follows that in the presence of Gaussian type 2 noise, there is no closed form solution for p(high confidence) terms.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Setting the derivative equal to zero and solving for c2,"S1" gives</p><p>Enforcing the constraint that 2," 1" ≤ 1 yields a final solution for c2,"S1" as</p><p>where the "HF*" superscript denotes that Equation A66 defines the optimal c2,"S1" for maximizing the difference between type 2 hit rate and type 1 false alarm rate (see <ref type="table">Table 1</ref>, main text).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparing Bayesian and non-Bayesian accounts of human confidence reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1006572</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">What failure in collective decision-making tells us about metacognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roepstorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="1350" to="1365" />
			<date type="published" when="1594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roepstorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimally Interacting Minds. Science</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="issue">5995</biblScope>
			<biblScope unit="page" from="1081" to="1085" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Confidence controls perceptual evidence accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Balsdon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1753</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Confidence matching in group decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Aitchison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Herce Castanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rafiee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahmoodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y F</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Measures of metacognition on signal-detection theoretic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dienes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Seth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="535" to="552" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Confidence modulates exploration and exploitation in value-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience of Consciousness</title>
		<imprint>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gilbert</surname></persName>
		</author>
		<title level="m">Confidence guides spontaneous cognitive offloading. Cognitive Research: Principles and Implications</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Shared Neural Markers of Decision Confidence and Error Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3478" to="3484" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evidence for metacognitive bias in perception of voluntary action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haggard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="page">104041</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distinct brain mechanisms for conscious versus subliminal error detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Opstal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="80" to="94" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic sources of evidence supporting confidence judgments and error detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yeung</surname></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000583</idno>
		<ptr target="https://doi.org/10.1037/xhp0000583" />
	</analytic>
	<monogr>
		<title level="j">In Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="52" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Two Types of ROC Curves and Definitions of Parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Birdsall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Tanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="629" to="630" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Confidence in value-based choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-evaluation of decision-making: A general Bayesian framework for metacognitive computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="114" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How to measure metacognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">443</biblScope>
			<date type="published" when="2014-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Relating introspective accuracy to individual differences in brain structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="page" from="1541" to="1543" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Type 2 tasks in the theory of signal detectability: discrimination between correct and incorrect decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Galvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Podd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Drga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Whitmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="843" to="876" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Human VMPFC encodes early signatures of confidence in perceptual decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gherman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Philiastides</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.38293</idno>
		<ptr target="https://doi.org/10.7554/eLife.38293" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Signal Detection Theory and Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<publisher>John Wiley &amp; Sons, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Mesolimbic confidence signals guide perceptual learning in the absence of external feedback. eLife</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guggenmos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wilbertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Hebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BOUNDED RATIONALITY. Annual Review of Political Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="297" to="321" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An investigation of how relative precision of target encoding influences metacognitive performance. Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kellij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fahrenfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A K</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Odegaard</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-020-02190-0</idno>
		<ptr target="https://doi.org/10.3758/s13414-020-02190-0" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">When Are Two Heads Better than One and Why?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koriat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="issue">6079</biblScope>
			<biblScope unit="page" from="360" to="362" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reasons for confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koriat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lichtenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology. Human Learning and Memory</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">107</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Calibration of Probabilities: The State of the Art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lichtenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Decision Making and Change in Human Affairs: Proceedings of the Fifth Research Conference on Subjective Probability, Utility, and Decision Making</title>
		<editor>H. Jungermann &amp; G. De Zeeuw</editor>
		<meeting><address><addrLine>Darmstadt; Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1975-09" />
			<biblScope unit="page" from="275" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An investigation of detection biases in the unattended periphery during simulated driving. Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Odegaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1325" to="1332" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Detection Theory: A User&apos;s Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Macmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Creelman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Taylor &amp; Francis</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The metaperceptual function: Exploring dissociations between confidence and task performance with type 2 psychometric curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">G</forename><surname>Castaneda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Odegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajananda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A K</forename><surname>Peters</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/5qrjn</idno>
		<ptr target="https://doi.org/10.31234/osf.io/5qrjn" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="422" to="430" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Signal detection theory analysis of type 1 and type 2 data: meta-d&apos;, response-specific meta-d&apos;, and the unequal variance SDT mode</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<editor>S. M. Fleming &amp; C. D. Frith</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The signal processing architecture underlying subjective reports of sensory awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Neuroscience of Consciousness</publisher>
			<biblScope unit="page" from="1" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Distinct neural contributions to metacognition for detecting, but not discriminating visual stimuli. eLife, 9</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">53900</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Metacognitive asymmetries in visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience of Consciousness</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The perceptual and social components of metacognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pescetelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology. General</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="949" to="965" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Transcranial magnetic stimulation to visual cortex induces suboptimal introspection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A K</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Amendi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Knotts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="119" to="132" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Two-stage dynamic signal detection: a theory of choice, decision time, and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="864" to="901" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The value of confidence: Confidence prediction errors drive value-based learning in the absence of external feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Ptasczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Steinecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guggenmos</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/wmv89</idno>
		<ptr target="https://doi.org/10.31234/osf.io/wmv89" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">How experimental procedures influence estimates of metacognitive ability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Neuroscience of Consciousness</publisher>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Attention induces conservative subjective biases in visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1513" to="1515" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Forming global estimates of self-performance from local confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rouault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1141</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">What makes a good decision? Robust satisficing as a normative standard of rational decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ben-Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dacso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal for the Theory of Social Behaviour</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="227" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sources of Metacognitive Inefficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="23" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The nature of metacognitive inefficiency in perceptual decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="70" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A decisional account of subjective inflation of visual perception at the periphery. Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Solovey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Graney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="258" to="271" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dissociable roles for Anterior Cingulate Cortex and Basolateral Amygdala in Decision Confidence and Learning under Uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolyarova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rakhshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>O'dell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A K</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soltani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Izquierdo</surname></persName>
		</author>
		<idno type="DOI">10.1101/655860</idno>
		<ptr target="https://doi.org/10.1101/655860" />
	</analytic>
	<monogr>
		<title level="m">bioRxiv</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">655860</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Calibration and the effects of knowledge and reconstruction in retrieval from memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Wagenaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="296" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Metacognition in human decision-making: confidence and error monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="1310" to="1321" />
			<date type="published" when="1594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The construction of confidence in a perceptual decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barttfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Integrative Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="79" to="79" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Variance misperception explains illusions of confidence in simple perceptual decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zylberberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="246" to="253" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
