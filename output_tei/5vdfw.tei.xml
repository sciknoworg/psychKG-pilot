<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Artificial Morality: Differences in Responses to Moral Choices by Human and Artificial Agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Armbruster</surname></persName>
							<email>diana.armbruster@psychologie.tu-chemnitz.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09120</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Personality Psychology and Assessment</orgName>
								<orgName type="department" key="dep2">Institute of Psychology</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09120</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Mandl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09120</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Zeiler</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09120</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Strobel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09120</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Artificial Morality: Differences in Responses to Moral Choices by Human and Artificial Agents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>moral dilemmas</term>
					<term>moral judgement</term>
					<term>artificial agents</term>
					<term>AI</term>
					<term>blame</term>
					<term>trust</term>
				</keywords>
			</textClass>
			<abstract>
				<p>A consensus on moral &quot;rights&quot; and &quot;wrongs&quot; is essential for ensuring societal functioning. Moral decision-making has been investigated for decades focusing on human agents. More recently, research has started into how humans evaluate artificial moral agents. With increasing presence of artificial intelligence (AI) in society, this question becomes ever more relevant. We investigated responses from a third-party perspective to moral judgments of human and artificial agents in high-stakes and low-stakes dilemmas. High-stakes dilemmas describe life-or-death scenarios while low-stakes dilemmas do not have lethal albeit nevertheless substantial negative consequences. In two online studies, participants responded to the actions resp. inactions of human and artificial agents in four high-stakes scenarios (N1 = 491) and four low-stakes dilemmas (N2 = 490). In line with previous research, agents received generally more blame in high-stakes scenarios and actions resulted overall in more blame than inactions. While there was no effect of scenario type on trust, agents were more trusted when they did not act. Although humans, on average, were blamed more than artificial agents they were nevertheless also more trusted. The most important predictor for blame and trust was whether participants agreed with the moral choice of an agent and considered the chosen course of action as morally appropriateregardless of the nature of the agent. Religiosity emerged as further predictor for blaming both human and artificial agents, while trait psychopathy was associated with more blame of and less trust in human agents. Additionally, negative attitudes towards robots predicted blame and trust in artificial agents.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Agreement on what is morally "right" and "wrong" is essential to the functioning of society.</p><p>Until very recently humans have been deemed to be the only beings capable of moral decisions, although some animals have been, albeit inconsistently, seen as moral creatures (even if not as full moral agents) and the issue of animal morality is currently discussed anew (cf. <ref type="bibr" target="#b60">Mons√≥ et al., 2018)</ref>. However, the ongoing rapid development of the capabilities of artificial intelligence (AI) might give rise to a new type of moral agent. Thus, for future societies of humans coexisting with various types of artificial and hybrid agents to function, questions need to be addressed regarding their respective tasks and responsibilities <ref type="bibr" target="#b58">(Meyer et al., 2023)</ref>. Given their current rapid development, these new agents will likely gain in autonomy and their decisions might (to varying degrees) be dissimilar from those that humans might take <ref type="bibr" target="#b28">(Gesmann-Nuissl, 2018)</ref>. Increasingly, artificial agents will also be involved in situations requiring moral judgments <ref type="bibr" target="#b41">(Jentzsch et al., 2019)</ref>. Although there is no complete agreement among all humans even on key moral issues and considerable individual and cultural differences exist in human moral decision-making <ref type="bibr" target="#b22">(Friesdorf et al., 2015;</ref><ref type="bibr" target="#b33">Graham et al., 2016)</ref>, disagreements between humans and artificial agents on moral questions represent a new type of challenge. Since such disagreements also touch on the more fundamental issue of roles, rights, and responsibilities of humans and the emerging different artificial societal actors <ref type="bibr" target="#b58">(Meyer et al., 2023)</ref>, this challenge needs to be timely met. Thus, the question of how humans judge and respond to the decisions of artificial moral agents warrants further investigation, even iffor nowthis concerns decisions in fictional scenarios.</p><p>Moral decisions in humans have been investigated for decades using different approaches <ref type="bibr">(review: Ellemers et al., 2019)</ref> with moral dilemmas being one well-established method. Moral dilemmas describe a brief (fictional) scenario with usually two mutually exclusive outcomes to choose (first-party perspective). Alternatively, the decisions of others in a dilemma situation might be presented to be judged from a third-party perspective <ref type="bibr" target="#b16">(Christensen &amp; Gomila, 2012)</ref>. Importantly, the application of different moral principles suggests conflicting courses of action in these scenarios. Deontological principles are based on universal rules of what is right and wrong and are thus independent of a specific situation and its outcome. Conversely, utilitarian principles focus on the outcome of an action (or inaction) and ultimately aim to maximize benefit for as many people as possible even if it means harming one or a few individuals <ref type="bibr" target="#b27">(Gawronski &amp; Beer, 2017)</ref>. Notably, these two principles are not necessarily in conflict with each other in every situation where moral decisions are required. However, moral dilemmas are specifically designed to pit these principles against each other. Furthermore, research into moral scenarios highlighted the importance of various design and content factors that affect responses <ref type="bibr" target="#b16">(Christensen &amp; Gomila, 2012)</ref>. Among those factors are methodological aspects (e.g., word count, question format, expression style) and conceptual variables (e.g., personal force, intention, benefit recipient; <ref type="bibr" target="#b15">Christensen et al., 2014;</ref><ref type="bibr" target="#b16">Christensen &amp; Gomila, 2012)</ref>. It should also be noted that the validity of various scenarios, including the well-known trolley dilemma, has been questioned because some of these dilemmas are lacking in realism <ref type="bibr" target="#b21">(Fried, 2012;</ref><ref type="bibr" target="#b32">Gold et al., 2014;</ref><ref type="bibr" target="#b42">Kahane, 2015)</ref>. In response, new scenarios based on real-life events have been developed (e.g., <ref type="bibr" target="#b46">K√∂rner &amp; Deutsch, 2022)</ref> and every-day dilemmas with lower stakes have been proposed (e.g., <ref type="bibr" target="#b78">Singer et al., 2019)</ref>, though these have been less studied to date.</p><p>Third-party perspective. Responses of third parties (i.e., 'observers') to moral decisions of others are of additional interest because third parties are important for maintaining social cooperation and interpersonal trust which depend on consistent reprimanding and punishment of moral transgressions <ref type="bibr" target="#b9">(Boyd et al., 2003)</ref>. Observers have been suggested to act as everyday judges and to object to perceived violations of moral or social norms even if they are not involved themselves <ref type="bibr" target="#b83">(Weiner, 2006)</ref>. They are of particular importance in this regard in larger and increasingly anonymous societies with frequent one-off interactions <ref type="bibr" target="#b6">(Bendor &amp; Swistak, 2001;</ref><ref type="bibr" target="#b9">Boyd et al., 2003)</ref>. Thus, although most studies on moral decision-making have investigated the first party perspective, there is a strong ongoing research interest in responses of observers to moral choices of others (e.g., <ref type="bibr" target="#b5">Behnke et al., 2020)</ref>.</p><p>Moral choices of artificial agents. While the majority of third-party studies investigated moral decisions by humans, research has started on responses to moral choices by artificial agents (e.g., <ref type="bibr" target="#b2">Awad et al., 2018;</ref><ref type="bibr" target="#b7">Bigman &amp; Gray, 2018;</ref><ref type="bibr" target="#b53">Malle et al., 2019;</ref><ref type="bibr" target="#b55">Malle et al., 2015)</ref>. The studies used similar approaches to the ones on human decision-makers and presented moral dilemmas to assess whether various decisions of (fictional) artificial moral agents were deemed appropriate. In addition, measures of blame and trust have been explored (cf. <ref type="bibr" target="#b55">Malle et al., 2015)</ref>.</p><p>Findings suggest that artificial agents are expected to act more utilitarian than human agents in adaptations of the trolley dilemma, i.e., to sacrifice one individual to save four <ref type="bibr" target="#b55">(Malle et al., 2015</ref>). Furthermore, human and artificial agents receive different amounts of blame for the same moral choices, although findings are inconsistent on whether artificial agents can be blamed at all, i.e., whether they can be morally responsible. While some studies reported that artificial agents were blamed (although to a different degree) by most participants <ref type="bibr" target="#b53">(Malle et al., 2019;</ref><ref type="bibr" target="#b55">Malle et al., 2015)</ref>, others found that the majority did not or just to a small extent ascribe morality to robots and consequently did not blame them <ref type="bibr" target="#b11">(Bretschneider et al., 2022;</ref>. <ref type="bibr" target="#b7">Bigman and Gray (2018)</ref>, who investigated to what extend human decision makers are preferred to artificial agents in various (fictional) medical, legal, or military scenarios, concluded that there is a general preference for human agents. They described an 'aversion' to moral decision-making by artificial agents whose degree depended on the agents' perceived experience and expertise <ref type="bibr" target="#b7">(Bigman &amp; Gray, 2018)</ref>. However, they also emphasized that they investigated life-or-death scenarios and that results might differ in dilemmas with less at stake.</p><p>In sum, there is growing interest into how artificial moral agents are evaluated by human observers accompanied by an ongoing debate about whether and to what extent such agents are actually capable of moral decisions and whether they should be allowed to make them <ref type="bibr" target="#b52">(Malle, 2016;</ref><ref type="bibr" target="#b58">Meyer et al., 2023;</ref><ref type="bibr" target="#b59">Misselhorn, 2018)</ref>.</p><p>Individual differences in evaluating moral choices. In addition to general preferences for human vs. artificial moral agents, individual differences in evaluating moral choices by artificial agents can be expected. Research focusing on human moral agents indicated gender differences with men being more likely to endorse utilitarian options (e.g., <ref type="bibr" target="#b0">Armbruster et al., 2021;</ref><ref type="bibr" target="#b4">Banerjee et al., 2010;</ref><ref type="bibr" target="#b8">Bjorklund, 2003;</ref><ref type="bibr" target="#b14">Capraro &amp; Sippel, 2017;</ref><ref type="bibr" target="#b23">Fumagalli et al., 2010)</ref> although some studies did not find differences between men and women (e.g., <ref type="bibr" target="#b10">Brannon et al., 2019;</ref><ref type="bibr" target="#b74">Seyedsayamdost, 2015)</ref>. Furthermore, there are gender differences in attitudes towards robots and AI <ref type="bibr" target="#b25">(Funk et al., 2020;</ref><ref type="bibr" target="#b77">Sindermann et al., 2021)</ref> as well as towards technology in general (meta-analysis: <ref type="bibr" target="#b13">Cai et al., 2017)</ref> with men reporting more positive attitudes. Thus, gender differences might also exist in judging decisions of artificial moral agents.</p><p>In addition to gender effects, general population differences in attitudes towards technology, robots, or AI are likely to affect responses towards artificial agents making moral decisions.</p><p>Previous studies show, for instance, that negative attitudes towards robots influence interactions with them <ref type="bibr" target="#b3">(Babel et al., 2022;</ref><ref type="bibr" target="#b62">Nomura et al., 2008)</ref> and evaluations of their behavior styles <ref type="bibr" target="#b80">(Syrdal et al., 2009)</ref>, while affinity for technology interaction as a more general measure of approaches to technology has been linked to self-reported usage of technical systems <ref type="bibr" target="#b20">(Franke et al., 2019)</ref>. Therefore, different outlooks on both broader as well as specific technological issues might predict responses to artificial moral agents.</p><p>Personality traits have also been found to be associated with moral judgement tendencies including, for instance, Need for Cognition (NFC) and trait psychopathy. NFC refers to the tendency to engage in and enjoy effortful cognitive activities <ref type="bibr" target="#b12">(Cacioppo &amp; Petty, 1982)</ref>. Previous studies have linked NFC to utilitarian judgement tendencies (e.g., <ref type="bibr" target="#b18">Conway &amp; Gawronski, 2013)</ref> although findings are not consistent and associations with deontological preferences have also been found (e.g., <ref type="bibr" target="#b47">K√∂rner et al., 2020;</ref><ref type="bibr" target="#b66">Park et al., 2016)</ref>. Higher NFC levels had initially been suggested to lead to increased deliberation of costs and benefits and thus been associated with utilitarian decisions. However, recently NFC has also been proposed to result in increased reflections of moral norms to explain correlations with deontological decisions <ref type="bibr" target="#b47">(K√∂rner et al., 2020</ref>). Furthermore, NFC predicts self-reported moral behavior, e.g., donating and supporting others in need or considering action consequences for others, suggesting that enjoyment of and engagement in effortful cognitions might represent a 'moral capacity' <ref type="bibr" target="#b79">(Strobel et al., 2017)</ref>.</p><p>Contrariwise, deviant moral behavior has been recognized as a core element of psychopathy as reflected in its early descriptions as 'moral derangement' <ref type="bibr" target="#b71">(Rush, 1812)</ref> or 'moral insanity' <ref type="bibr" target="#b70">(Prichard, 1835)</ref>. Psychopathy comprises characteristics like antisocial behavior, lack of empathy, remorse or guilt, glibness, shallow affect and impulsivity <ref type="bibr" target="#b37">(Hare &amp; Neumann, 2009)</ref>. Since psychopathy exists on a continuum, the clinical construct was adapted to the sub-clinical domain (cf. <ref type="bibr" target="#b36">Hare, 1985)</ref>. Findings of moral dilemma studies suggest that individuals with higher trait psychopathy are more inclined to make utilitarian choices (meta-analysis: <ref type="bibr" target="#b57">Marshall et al., 2018)</ref>, which results in less casualties in (fictional) sacrificial dilemmas. This conflicts with real-life behavior of persons with increased levels of psychopathy, who usually appear to be not particularly concerned with enhancing the 'greater good' as they are responsible for a disproportionate amount of physical, financial, social or emotional harm <ref type="bibr" target="#b44">(Kiehl &amp; Hoffman, 2011)</ref>.</p><p>Further research has shown that a general lack of empathy and reduced compassion for others <ref type="bibr" target="#b31">(Glenn et al., 2009;</ref><ref type="bibr" target="#b73">Seara-Cardosa et al., 2013)</ref> together with a reduced dislike for performing harmful actions <ref type="bibr" target="#b67">(Patil, 2015</ref>) may contribute to these 'utilitarian' choices. Recent studies revealed that individuals scoring higher in trait psychopathy actually show reduced deontological and reduced utilitarian inclinations but increased action tendencies <ref type="bibr" target="#b47">K√∂rner et al., 2020)</ref>. Trait psychopathy belongs to the group of 'dark' traits which have been originally suggested to comprise a Dark Triad together with narcissism and Machiavellianism <ref type="bibr" target="#b69">(Paulhus &amp; Williams, 2002)</ref>. Later research proposed additional traits (e.g., spitefulness, egoism) as the basis of the dark core of personality <ref type="bibr" target="#b61">(Moshagen et al., 2018)</ref>. Given the links between these traits and moral attitudes in general, they might also impact reactions towards moral choices by artificial agents.</p><p>Religion has been identified as another important factor influencing moral decisions and attitudes <ref type="bibr" target="#b17">(Cohen, 2015;</ref><ref type="bibr" target="#b33">Graham et al., 2016)</ref> with deontological judgements being positively associated with religiosity <ref type="bibr" target="#b81">(Szekely et al., 2015)</ref>. Furthermore, religiosity has been linked to negative views on interactions with robots <ref type="bibr" target="#b30">(Giger et al., 2017)</ref> and to more fearful attitudes towards them <ref type="bibr" target="#b43">(Katz &amp; Halpern, 2014)</ref>, although different religions have been proposed to exert different effects in this regard <ref type="bibr" target="#b34">(Halpern &amp; Katz, 2012;</ref><ref type="bibr" target="#b51">MacDorman et al., 2009;</ref><ref type="bibr" target="#b75">Shaw-Garlock, 2009</ref>).</p><p>Nevertheless, religiosity might shape attitudes towards artificial moral agents.</p><p>In this study, we aim to investigate potential differences in responses to moral choices by human vs. artificial agents. We evaluate ratings on whether these choices are considered (1) morally appropriate as well as (2) how much blame an agent deserved for their decision and <ref type="formula">3</ref>to what degree the agent can be trusted. Furthermore, we investigate the effect of situation and person variables on response outcomes. Situation-related, we contrast responses to high-stakes with low-stakes dilemmas while person-wise we investigate effects of religiosity, NFC, Dark Triad traits, attitudes towards technology and robots as well as age and gender. We preregistered the following hypotheses (see https://osf.io/ukn28 and https://osf.io/e4jsb): (1a) Artificial moral agents are blamed less for acting in high as well as low-stakes dilemmas compared to human agents, and are thus rated more positively. (1b) Artificial moral agents are lamed more for in-action in both dilemma types compared to human agents. (2) Need for Cognition (NFC) is negatively associated with blaming artificial agents and positively with trusting them, particularly when those agents chose action over inaction. We also preregistered the following research questions: Compared to human agents, how much trust is attributed to artificial moral agents after action resp. inaction? How do attitudes towards robots influence the relationship between To what extent does Affinity for Technology Interaction (ATI) influence the relationship between agent type and the evaluation of the decision to act resp. not to act? Are there differences between evaluation of artificial moral agents and human actors in high-vs. low-stake dilemmas?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Methods</head><p>We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study <ref type="bibr" target="#b76">(Simmons et al., 2012)</ref>. All materials, data, and analyses of this study are available online (https://osf.io/mf2ax/ and https://osf.io/x8d4m/). Both studies were preregistered (https://osf.io/ukn28 and https://osf.io/e4jsb).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Samples</head><p>We conducted two online studies and originally recruited N1=500 and N2=500 participants using Prolific Academic (www.prolific.co; Palan &amp; Schitter, 2018) who responded to decisions of human and artificial agents in high-stakes (study 1) and low-stakes (study 2) moral dilemma scenarios. Individuals who took part in study 1 could not participate in study 2. To ensure comprehension of the scenarios' text, participants had to be either German native speakers or had to speak the language at a proficient level. In study 1, n = 247 female (49.4%), n = 246 male (49.2%), and n = 7 diverse individuals (1.4%) participated. In study 2, n = 257 female (51.4%), n = 233 male (46.6%) and n = 10 diverse individuals (2.0%) took part. Since gender effects were investigated in all analyses, diverse subjects had to be excluded because of the small subsample size. Furthermore, two individuals indicated to be under 18 years of age and were excluded from all analyses as well. Thus, in the final first sample, N = 491 individuals remained (mean age = 30.53, SD = 11.06, range = 18-72 years) while the second sample consisted of N = 490 individuals (mean age = 31.46, SD = 10.97, range = 18-72 years).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Moral Dilemmas</head><p>In study 1, four high-stakes dilemmas detailing public health related scenarios were adapted from . They were rephrased in the third-party perspective with either a treating physician or a treating care robot as moral agent who decided to follow a suggested course of action or not (cf. <ref type="bibr" target="#b55">Malle et al., 2015)</ref>. Similarly, in study 2 four low-stakes dilemmas in the third-party perspective were employed. Content-wise, low stake dilemmas included mainly administrative decisions (e.g., on study grants or library bans) with either a human or an artificial moral agent who decided for or against a certain action. Three of the four lowstakes dilemmas were adapted from pre-existing scenarios. The library ban scenario is a modified version of the smart house dilemma <ref type="bibr" target="#b50">(Liao et al., 2019)</ref> and the early parole scenario is based on a dilemma used by <ref type="bibr" target="#b7">Bigman &amp; Gray (2018)</ref>. The obese patient dilemma was adapted from a conflict scenario posted on the Open Roboethics institute's website (Open Roboethics Institute, 2015), while the scholarship dilemma is inspired by real-life differences between funding bodies in how they take into account different characteristics of an applicant when deciding who gets funding and who does not. While in each high-stakes dilemma the lives of a single individual or multiple persons were on the line, none of the low-stakes scenarios contained a life-or-death situation. Thus, in contrast to the sacrificial high-stakes scenarios, low-stakes dilemmas represent every-day moral conflicts. The exact wording of all dilemmas can be found in the supplement and online (https://osf.io/mf2ax/ and https://osf.io/x8d4m/).</p><p>After reading the main text of a scenario, participants first indicated whether they judged it morally appropriate or not for the human or artificial agent to take the suggested action. Following, participants were presented with the decision made by the respective agent who either chose to act or not. Agreement (yes vs. no) between participants' own moral judgements and an agent's actual decision was later calculated for each scenario to which participants responded. Participants then rated how much blame the agent deserved for their choice on a visual analog scale ranging from "no blame at all" to "maximum blame"; see also supplement for a depiction of the scale) and to what degree the agent could be trusted. Trust was evaluated on an 8-point Likert scale ranging from 0 = "not at all" (trustworthy) to 7 = "very much". In both studies we used a 2 (agent: human vs. artificial) √ó 2 (decision: action vs. inaction) design. To obtain a balanced distribution in these four conditions across the four dilemmas, a Latin square was used in both studies resulting in 16 randomization groups in each study with differing condition combinations to which participants were randomly assigned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questionnaires</head><p>To assess Need for Cognition, the German version of the NFC Short Scale <ref type="bibr">(Bless et al., 1994)</ref> was used. Participants responded to the 16 items of the questionnaire on a 7-point Likert scale with higher sum scores indicating higher Need for Cognition levels. Internal consistency of the NFC short scale was Œ± = .89 (sample 1) and Œ± = .87 (sample 2), respectively. Religiosity was assessed with three items each from the Duke University Religion Index (DUREL; <ref type="bibr" target="#b45">Koenig &amp; B√ºssing, 2010)</ref> and the Centrality of Religiosity Scale (CRS; <ref type="bibr" target="#b38">Huber &amp; Huber, 2012)</ref>. In addition, participants responded to one item assessing self-perceived general religiosity (ranging from 1 -not religious to 10 -religious). Combining these z-standardized items resulted in a scale with an internal consistency of Œ± = .90 and .91, respectively, in the two samples. Thus, a single indicator of religiosity was used with higher mean scores indicating higher trait levels.</p><p>The German Version of the Dirty Dozen <ref type="bibr" target="#b48">(K√ºfner et al., 2015)</ref> was employed to measure the three traits of the Dark Triad: psychopathy, narcissism, and Machiavellianism (assessed with four items each). Participants responded on a 9-point Likert scale with higher means in the respective sub-scales indicating higher trait levels. In the two samples, Cronbach's alpha for the subscales were as follows: psychopathy Œ± = .67 and .62, narcissism Œ± = .74 and .82, and Machiavellianism Œ± = .79 and .82. We used the Affinity for Technology Interaction (ATI) scale <ref type="bibr" target="#b20">(Franke et al., 2019)</ref> to assess the tendency to actively engage in technology interaction. The 9item scale was originally developed in German and uses a 6-point Likert scale response format.</p><p>Internal consistency of the ATI scale in the two samples was Œ± =.91 and .92, respectively. The German version of the Negative Attitudes towards Robots Scale (NARS; <ref type="bibr" target="#b62">Nomura et al., 2008)</ref> was used to capture attitudes concerning interaction and communication with robots. The scale comprises a total of 14 items on three sub-scales assessing negative attitudes towards (1) situations and interactions with robots (six items; Œ± = .75 and .74), (2) social influence of robots (five items; Œ± = .72 and .70), and (3) emotions in interaction with robots (three items; Œ± = .63 and .67). The NARS uses a 5-point Likert scale response format <ref type="bibr" target="#b63">(Nomura et al., 2006)</ref> with higher mean scores indicating more pronounced negative attitudes towards robots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>In both online studies, participants were first informed about the study aims and protocol as well as about data protection policies and were asked to indicate their consent via button press. Afterwards, a number of demographical variables (e.g., age, gender, education) were assessed.</p><p>Following, participants completed questionnaires to measure Need for Cognition (NFC), Religiosity, Dark Triad traits, as well as Affinity towards Technology in Interaction (ATI) and</p><p>Negative Attitudes towards Robots (NARS). Afterwards, participants were introduced to the moral dilemma experiment. They then completed the four scenario √ó condition combinations they had been randomly assigned to. As described above, for each scenario participants first indicated whether a suggested course of action was morally appropriate or not for a respective agent to take. Following, they were informed about the choice of the agent and rated blame for and trust in the agent. After completing the survey, participants were thanked. Participants of both samples received 5 ‚Ç¨ each for completing the study. The study design and protocol was approved by the ethics committee of Chemnitz University of Technology (#101499823).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analysis</head><p>All analyses were performed with SPSS 29 (IBM Statistics). Using repeated measurements ANOVAs, we first analyzed effects on (a) participants' ratings on whether it was morally appropriate for the respective agent to take the suggested action. Agent type (human vs. artificial) was entered as within-subject factor, while dilemma type (low vs. high-stakes) and gender were entered as between-subject factors. In additional ANOVAs effects of dilemma type, agent type, agent's decision (action/inaction) and gender on (b) blame and (c) trust ratings were investigated. Following, regression analyses (enter method) were conducted to further assess the role of personality traits and attitudes as potential predictors of the amount of blame agents received and to what degree they were trusted. The following variables were entered as predictors for responses to human agents: dilemma type, agreement with agents' moral choices, gender, age, Need for Cognition (NFC), religiosity, and the Dark Triad traits narcissism, psychopathy and Machiavellianism. Agreement ratings were based on whether participants' own moral judgements in a given scenario were in line with the presented moral choice of the agent or not. In addition to the aforementioned predictors, four more variables were included to predict responses to artificial agents: affinity towards technology interaction (ATI) and the three NARS subscales negative attitudes towards (1) situations and interactions with robots, (2) social influence of robots, and (3) emotions in interaction with robots. Ancillary correlation analyses were conducted to investigate associations between the various personality traits and attitudes as well as between trust and blame whose results can be found in the supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANOVA: Effects on moral appropriateness ratings of actions in dilemma situations</head><p>Participants rated for both high-stakes and low-stakes dilemmas whether a suggested course of action was appropriate or not for the respective agent. There was no difference between the averaged appropriateness ratings to the two dilemmas types (high-stakes: 49.03%; low-stakes: 50.05%; F1, 976 = 0.51, p = 0.477). Furthermore, there was no general effect of agent type (F1, 976 = 0.09, p = 0.767) with endorsement rates of suggested actions being 49.39% for human agents and 49.80% for artificial agents. There was also no interaction between dilemma type and type of agent (F1, 976 = 0.64, p = .422) and men and women did not differ in their overall endorsement of suggested actions (F1, 976 = 0.004, p = .948). There were also no interactions between gender and agent type (F1, 976 = 0.74, p = 0.389) or gender and dilemma type (F1, 976 &lt; 0.001, p = .993). However, there was a three-way interaction between dilemma type, agent and gender (F1, 976 = 7.61, p = .006, Œ∑ p 2 = 0.008; see <ref type="figure" target="#fig_1">Figure 1</ref>). The effect is mainly due to highstakes dilemmas with follow-up analyses revealing a significant gender √ó agent interaction (F1, 489 = 7.01, p = .008, Œ∑ p 2 = 0.014) which was not found in the low-stakes scenarios (F1, 487 = 1.69, p = .195). In high-stakes scenarios, women were somewhat less likely than men to endorse the actions of human agents (0.45 vs. 0.51). Contrariwise, more women than men endorsed the actions of artificial agents in high-stakes scenarios (0.53 vs. 0.47). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANOVA: Effects on blame of moral agents</head><p>Blame ratings differed by dilemma type (F1, 976 = 63.61, p &lt; .001, Œ∑ p 2 = 0.061) with increased blame in high-stakes scenarios. Overall blame ratings were also higher for human compared to artificial agents (F1, 976 = 46.24, p &lt; .001, Œ∑ p 2 = 0.045) and for actions compared to inactions (F1, 976 = 83.56, p &lt; .001, Œ∑ p 2 = 0.079). Furthermore, there were significant interactions between dilemma type and agent (F1, 976 = 7.65, p = .006, Œ∑ p 2 = 0.008), dilemma type and decision type (action/inaction; F1, 976 = 17.01, p &lt; .001, Œ∑ p 2 = 0.017) and agent type and decision type (F1, 976 = 10.01, p = .001, Œ∑ p 2 = 0.010; see <ref type="figure" target="#fig_2">Figure 2</ref>). Follow-up analyses revealed that in both highstakes and low-stakes scenarios there was more overall blame for human agents (all p ‚â§ .003) and for actions compared to inactions (all p ‚â§ .001). However, there was an agent type √ó decision type interaction effect on blame in the high-stakes scenarios (F1, 489= 8.64, p = .003, Œ∑ p 2 = 0.017) but not in the low-stakes dilemmas (p = .121). Overall, we could confirm one part of our hypothesis regarding differences in blaming human vs. artificial agents. Artificial agents were indeed blamed less for choosing to act, but they were also blamed less when deciding not to act. Contrary to our expectation, there were thus general higher blame ratings for human agents, not just in the "action" condition. There was no main effect of gender (F1, 976 = 0.028, p = .866), nor were there any interaction effects involving gender on blame ratings (all p ‚â• .244). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANOVA: Effects on trust of moral agents</head><p>Overall, trust in the respective agents did not differ in high-compared to low-stakes scenarios (F1, 826 = 0.21, p = .644). However, there was a significant effect of agent type (F1, 826 = 6.35, p = .012, Œ∑ p 2 = 0.008) with higher trust ratings for human agents as well as a decision type main effect (F1, 826 = 15.68, p &lt; .001, Œ∑ p 2 = 0.019) with higher trust ratings for agents who chose not to take action. There was also an interaction between dilemma type and decision type (F1, 826 = 7.79, p = .005, Œ∑ p 2 = 0.009) and between agent and decision type (F1, 826 = 5.19, p = .023, Œ∑ p 2 = 0.006; see <ref type="figure" target="#fig_3">Figure 3</ref>). Follow-up analyses revealed an interaction between agent and decision type in high-stakes scenarios (F1, 489 = 4.07, p = .044, Œ∑ p 2 = 0.008) that was not present in the low-stakes dilemmas (p = .193). Trust in human agents in high-stakes scenarios is only higher when agents do not take action while there is no difference between human and artificial agents when they do decide to act. Similar to blame ratings, gender did not affect trust ratings (F1, 826 = 0.004, p = .948) nor where there any significant interactions involving gender (all p ‚â• .300). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regression analyses: Prediction of blame and trust in human agents</head><p>Regression analyses revealed the following predictors for blame of human agents: agreement with agents' moral choices (Œ≤ = -.384, p &lt; .001), dilemma type (Œ≤ = -.238, p &lt; .001), trait psychopathy (Œ≤ = .077, p = .028) and religiosity (Œ≤ = .060, p = .037). NFC, narcissism, Machiavellianism, gender, and age did not predict blame for human agents (all p ‚â• .063; see <ref type="table" target="#tab_0">Table 1</ref>).</p><p>Trust in human agents was predicted by agreement with agents' choices (Œ≤ = .258, p &lt; .001) and trait psychopathy (Œ≤ = -.095, p = .015). No other predictor reached significance (all p ‚â• .132; see <ref type="table" target="#tab_1">Table 2</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regression analyses: Prediction of blame and trust in artificial agents</head><p>Blame of artificial agents was predicted by agreement with agents' choices (Œ≤ = -.323, p &lt; .001), dilemma type (Œ≤ = -.106, p &lt; .001), negative attitudes towards situations and interactions with robots (NARS subscale 1, Œ≤ = .109, p = .005), narcissism (Œ≤ = .096, p = .007), religiosity (Œ≤ = .063, p = .040), and age (Œ≤ = -.077, p = .014). Affinity for technology interaction, NARS subscales 2 and 3 as well as Machiavellianism, psychopathy, gender, and, contrary to our initial hypothesis, NFC did not predict blame for artificial agents (all p ‚â• .070; see <ref type="table" target="#tab_2">Table 3</ref>). Trust in artificial agents was predicted by agreement with agents' choices (Œ≤ = .218, p &lt; .001) and negative attitudes towards emotions in interaction with robots (NARS subscale 3, Œ≤ = -.085, p = .025). All other predictors did not reach significance, including, again contrary to our hypothesis, NFC (all p ‚â• .146; see <ref type="table" target="#tab_3">Table 4</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Perceived appropriates of moral choices by human and artificial agents. We investigated responses to human and artificial agents in high-and low-stakes moral dilemmas, respectively.</p><p>Overall, there were no differences in perceived appropriateness of suggested actions in the two dilemma types and decision approval did not differ between human and artificial agents. Intriguingly, while there were also no overall gender differences in moral appropriateness ratings, an interaction occurred suggesting differences between men's and women's moral judgements in high-stakes scenarios depending on agent type. In the case of human agents, women endorsed the suggested course of action (i.e., instrumental harm to achieve a greater good) to a lesser degree than men. This result mirrors findings from previous moral dilemma research with human agents. Women have been reported to be less likely to choose 'utilitarian' options, i.e., to opt for actions that required harm to one or a few persons for the benefit of multiple individuals (e.g., <ref type="bibr" target="#b0">Armbruster et al., 2021;</ref><ref type="bibr" target="#b4">Banerjee et al., 2010;</ref><ref type="bibr" target="#b8">Bjorklund, 2003;</ref><ref type="bibr" target="#b14">Capraro &amp; Sippel, 2017;</ref><ref type="bibr" target="#b23">Fumagalli et al., 2010)</ref> although findings are not entirely consistent (e.g., <ref type="bibr" target="#b10">Brannon et al., 2019;</ref><ref type="bibr" target="#b74">Seyedsayamdost, 2015)</ref>. Notably, a similar effect of gender was not present in the low-stakes dilemmas. Previous moral dilemma research has predominantly used scenarios that can be classified as high-stakes dilemmas similar to the ones used in study 1 where lives are on the line.</p><p>Contrariwise, in low-stake scenarios there are no life-or-death consequences associated with any of the two response options. Although choices in these scenarios may result in negative outcomes, their impact is considerably less severe which might explain the lack of difference between the ratings of men and women. Furthermore, in high-stakes scenarios with artificial agents the opposite pattern regarding gender was observed: women were more likely to endorse the suggested course of action compared to men. Again, no gender difference of this kind was found for the low-stakes scenarios.</p><p>Blaming and trusting moral agents. Unlike the assessment of moral appropriateness, blame and trust ratings differed between human and artificial agents. Overall, human agents received considerably more blame but were also more trusted. Blame requires attribution of moral responsibility which in turn depends on various legal and psychological capacities (e.g., the capacity to act, legal capacity, autonomy, liability, explainability, and moral agency) most of which are usually not ascribed to artificial agents <ref type="bibr" target="#b58">(Meyer et al., 2023)</ref>. Our finding of lower blame ratings for artificial agents (for making the same decisions as their human counterparts) indicate that they are held less responsible. Contrary to <ref type="bibr" target="#b55">Malle et al. (2015)</ref>, and to our own initial hypothesis, we did not find higher blame ratings of artificial agents in inaction conditions. Differences in blame ratings of human vs. artificial agents varied and were least pronounced in the low-stakes inaction condition but never veered in the opposite direction. Notably, response differences to human vs. artificial moral agents have been reported to be modulated by additional factors,</p><p>including an artificial agent's physical appearance <ref type="bibr" target="#b49">(Laakasuo et al., 2021)</ref> or their perceived expertise and experience <ref type="bibr" target="#b7">(Bigman &amp; Gray, 2018)</ref>. Furthermore, research into human moral agents highlighted the importance of dilemma content features for judging agents' decisions as morally right or wrong <ref type="bibr" target="#b15">(Christensen et al., 2014;</ref><ref type="bibr" target="#b16">Christensen &amp; Gomila, 2012)</ref>. While, for instance, <ref type="bibr" target="#b55">Malle et al. (2015)</ref> used a scenario modelled after the trolley dilemma, we investigated moral decisions in medical and administrative contexts. Thus, the response pattern regarding blame and trust found in our study might also be partly due to dilemmas features and might differ in other moral scenarios. Furthermore, we did not provide participants with pictures of the robots or other clues regarding their features. Since the look of a robot has been recently shown to affect humans' responses to the robot's moral decisions <ref type="bibr" target="#b49">(Laakasuo et al., 2021)</ref>, the (different) way participants might have imagined them to look like, may have had an effect on their responses in this study as well.</p><p>Blame and trust were also affected by dilemma and decision type. In both high-and low-stakes dilemmas, actions resulted generally in higher blame and reduced trust ratings compared to inactions, which is in line with previous findings on omission bias. The latter refers to a typical preference of not taking action in moral dilemmas when both acting and doing nothing are expected to result in adverse outcomes, particularly when the consequences are perceived as similarly harmful (cf. <ref type="bibr" target="#b40">Jamison et al., 2020)</ref>. Furthermore, average blame ratings were higher in high-stakes compared to low-stakes scenarios, although there was no difference in trust ratings between the two dilemma types. Interaction effects indicate that these general tendencies are partly modified by other factors. For instance, in high-stakes dilemmas trust in human compared to artificial agents was only higher in the inaction condition, while there was no difference in trust when agents took action. Contrariwise, there was no interaction of this kind in low-stakes scenarios. Regression analysis additionally confirmed dilemma type as a predictor for blame ratings. However, the by far strongest and most consistent predictor for blame of and trust in both types of agents was agreement with agents' moral choices. Unsurprisingly, agents whose choices tended to be in line with those of the participants received on average less blame and were perceived as more trustworthy. If this finding proves to be robust, it would have significant implications for people's expectations of the behavior of artificial agents. Previously, <ref type="bibr" target="#b55">Malle et al. (2015)</ref> reported that participants, who considered it impermissible to sacrifice one individual to save four persons, blamed human and artificial agents considerably more for choosing to act than for refraining to act. However, blame ratings of participants, who found it permissible to sacrifice the one person, did not significantly differ between agents who decided to act and those who refrained from doing so <ref type="bibr" target="#b55">(Malle et al., 2015)</ref>.</p><p>Individual differences in blaming and trusting moral agents. Religiosity emerged as a further predictor for blaming human and artificial agents alike with higher trait levels being associated with more blame. Generally, religion and religiosity have been argued to be key factors in moral attitudes and judgements <ref type="bibr" target="#b17">(Cohen, 2015;</ref><ref type="bibr" target="#b33">Graham et al., 2016)</ref>. Previously, religiosity has been linked to deontological judgments and increased emotions while processing moral dilemmas <ref type="bibr" target="#b81">(Szekely et al., 2015)</ref>. Our findings of higher blame ratings (for human agents) are in line with this. However, religious values vary substantially within and between cultures contributing to considerable differences in morality <ref type="bibr" target="#b33">(Graham et al., 2016)</ref>. Furthermore, there are also associations between religion and religiosity, respectively, and attitudes towards robots and AI. <ref type="bibr" target="#b30">Giger et al. (2017)</ref> reported an association between religiousness and negative attitudes towards interactions with robots. Religiosity has also been linked to a more fearful attitude towards robots <ref type="bibr" target="#b43">(Katz &amp; Halpern, 2014)</ref>. These connections between religiosity and more negative attitudes towards robots or AI might be partly responsible for our finding of more blame for artificial agents by individuals with higher religiosity scores. This notion is supported by positive correlations between religiosity and the NARS subscales in our samples, in particular with subscale 2 (negative attitudes towards social influence of robots; Supplemental <ref type="table" target="#tab_0">Table 1</ref>). However, it should be noted that distinct religious belief systems are likely to differently affect acceptance of and attitudes towards robots and AI <ref type="bibr" target="#b34">(Halpern &amp; Katz, 2012;</ref><ref type="bibr" target="#b51">MacDorman et al., 2009;</ref><ref type="bibr" target="#b75">Shaw-Garlock, 2009)</ref>. Recently, <ref type="bibr" target="#b39">Ikari et al. (2023)</ref> investigated moral care for robots in US participants with predominantly Abrahamic beliefs and in Japanese participants with Shinto-Buddhist traditions. They found higher moral care for robots in Japan. Furthermore, more pronounced religious beliefs were linked to less moral care in the American but not the Japanese sample.</p><p>Additionally, lower scores in anthropocentrism and higher ones in animism were also linked to increased moral care <ref type="bibr" target="#b39">(Ikari et al., 2023)</ref>. Given the cultural background of our participants, the association of religiosity and increased blame of artificial agents is in line with similar findings in Western samples (e.g., <ref type="bibr" target="#b30">Giger et al., 2017)</ref>.</p><p>Of the Dark Triad traits, psychopathy in particular showed associations with blame and trust ratings. Psychopathy was associated with more blame of and less trust in human agents while narcissism was related to blame of artificial agents. Higher levels of trait psychopathy have been associated with harsher punishment of (human) moral agents in fictional moral dilemmas despite concomitantly being linked to reduced inappropriateness ratings of moral transgressions and increased understanding emotions towards the moral agent <ref type="bibr" target="#b5">(Behnke et al., 2020)</ref>. Psychopathy is also linked to increased vengefulness, and both psychopathy and narcissism have been found to predict reduced forgiveness <ref type="bibr" target="#b29">(Giammarco &amp; Vernon, 2014)</ref>. Shared features of traits belonging to the Dark Triad <ref type="bibr" target="#b69">(Paulhus &amp; Williams, 2002)</ref> or the dark core of personality <ref type="bibr" target="#b61">(Moshagen et al., 2018)</ref> are behavioral tendencies for self-promotion and maximizing one's own interests while ignoring, accepting, or maliciously causing detriment to others combined with beliefs that justify such behavior <ref type="bibr" target="#b61">(Moshagen et al., 2018;</ref><ref type="bibr" target="#b69">Paulhus &amp; Williams, 2002)</ref>. The key is the disregard of others linked to social malevolence, which together with reduced forgiveness might have manifested here in an inclination to ascribe greater blame and indicate less trust.</p><p>Contrary to initial expectations, NFC did not predict responses to moral agents, although it only just missed the significance level for blame (human agents: p = .101, artificial agents: p = .070).</p><p>NFC reflects the tendency to engage in and enjoy effortful cognitive activities <ref type="bibr" target="#b12">(Cacioppo &amp; Petty, 1982)</ref>. Although previous findings are not entirely consistent, reasoning abilities and propensities (i.e., deliberate thinking styles like NFC) have been linked to increased preferences for utilitarian moral choices and optimization of overall welfare without being associated with reduced harm aversion (e.g., <ref type="bibr" target="#b68">Patil et al., 2021)</ref>. Cognitive abilities resp. motivation have be proposed to contribute to differences in processing moral problems with studies showing selective impairment of utilitarian judgements by cognitive load <ref type="bibr" target="#b18">(Conway &amp; Gawronski, 2013;</ref><ref type="bibr" target="#b82">Timmons &amp; Byrne, 2019)</ref>. Based on findings that NFC is negatively associated with punitive responses, <ref type="bibr" target="#b72">Sargent (2004)</ref> suggested that higher NFC levels might result in an increased ability and/or willingness to invest cognitive effort to reflect on specifics and constraints of dilemma settings and protagonists. Although associations of NFC with reduced blame did not reach significance in our study, they are, on a descriptive level, in line with reported links of NFC and reduced support for punishment <ref type="bibr" target="#b72">(Sargent, 2004)</ref>. Both are likely due to a more in-depth cognitive analysis of a dilemma situation and its protagonists.</p><p>Finally, negative attitudes towards situations and interactions with robots (NARS subscale 1) was a predictor of blaming artificial agents, while negative attitudes towards emotions in interaction with robots (NARS subscale 3) was a predictor of how much they were trusted. The other NARS subscales as well as Affinity for Technology Interaction (ATI) did not predict blame of resp. trust in artificial agents. NARS scores have been linked to actual behavior towards robots (e.g., time talking with them or touching them; <ref type="bibr" target="#b62">Nomura et al., 2008)</ref> and evaluation of robot behavior styles <ref type="bibr" target="#b80">(Syrdal et al., 2009)</ref>. NARS scores were found to be negatively associated with complying with a robot's request in a VR setting <ref type="bibr" target="#b3">(Babel et al., 2022)</ref>, although in another reallife experiment, NARS scores did not correlate with complying with requests made by a geminoid robot <ref type="bibr" target="#b1">(Aroyo et al., 2018)</ref>. Thus, despite some inconsistent findings, self-reported attitudes towards robots appear to be linked to behavioral responses to robots, which is echoed in our findings on their associations with blame and trust. Contrary to NARS, Affinity for Technology Interaction (ATI) showed no association with responses to artificial agents, which might be due to the more general scope of the questionnaire which is not tailored to interactions with robots/AI but focuses on dealing with technology in comparatively broad terms.</p><p>Overall, our findings emphasize several general tendencies when responding to artificial compared to human agents. While humans were generally more blamed compared to artificial agents for the same decisions, they were nevertheless more trusted. Also, high-stakes scenarios resulted in higher blame ratings compared to low-stakes dilemmas. However, responses to agents' decisions also showed considerable individual variance and several person variables emerged as predictors of blame and trust. The most important and consistent ones were moral appropriateness ratings, i.e., whether there was agreement or not with an action that an agent was suggested to take. Further predictors included dilemma type and religiosity for blame of both human and artificial agents, and psychopathy for blaming and trusting specifically human agents. For artificial agents, negative attitudes towards robots were additional predictors for blame and trust, respectively. Still, the amount of explained variance (R 2 =.163-.225 for blame and .071-0.79 for trust; see also Tables 1-4) indicates that there are other predictors, particularly for trust, that were not part of the study and require further investigation.</p><p>Limitations. The study has several limitations. While we were able to recruit sufficiently large samples, the online format adds limits to data quality control. Furthermore, individuals who register on platforms like Prolific to partake in research studies are usually better educated.</p><p>Accordingly, in both samples about half of our participants reported to hold a university degree and more than additional 30% had graduated from high school ('Abitur/Matura'; see also Supplemental Material). Also, to ensure thorough comprehension of the dilemma texts, only German native speakers and individuals who spoke German at a sufficiently high level could participate. Furthermore, while the age range of our samples is rather large (18-72 years), more than 80% of participants were under 40 years old. Regarding the scenarios used, content variety was limited in particular for high-stakes dilemmas, all of which were set in a medical context.</p><p>As dilemma content features can affect responses <ref type="bibr" target="#b15">(Christensen et al., 2014;</ref><ref type="bibr" target="#b16">Christensen &amp; Gomila, 2012)</ref>, scenarios with different settings might lead to different results. Furthermore, we only investigated responses to 'generic' types of agents without further specifications or modifications of their characteristics. However, physical features <ref type="bibr" target="#b49">(Laakasuo et al., 2021)</ref> and perceived experience and expertise of artificial agents <ref type="bibr" target="#b7">(Bigman &amp; Gray, 2018)</ref> might modulate responses to their moral decisions. Thus, there are several design factors limiting generalizabil-ity of our findings and further research is needed to investigate the interplay of agent and dilemma features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion.</head><p>In sum, our study provides further insight into how moral decisions of artificial in contrast to human agents are evaluated and which variables might affect individual differences in those responses. While (dis)agreement with one's own moral choice preferences proofed to be the most important predictor for blaming and trusting other moral agents, several additional predictors emerged. Although studies investigating responses to artificial moral agents cannot sufficiently address the question of whether these agents are actually capable of making moral choices (cf. <ref type="bibr" target="#b58">Meyer et al., 2023)</ref>, findings nevertheless yield important information. Understanding human perception of and responses to artificial agents in situations with moral implications is essential for optimizing these interactions with due consideration of their psychological and legal limitations. With the presence of artificial agents increasing, ensuring smooth encounters with humans becomes ever more important for future societal functioning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) NFC and blame judgement and (b) NFC and trust in artificial moral agents? How do Dark Triad personality traits (narcissism, psychopathy, Machiavellianism) influence blame judgement resp. trust in artificial moral agents after a decision for action/inaction in moral dilemmas?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Mean percentage of agreement with suggested actions in high-stakes and low-stakes dilemmas with human and artificial agents (AI/R)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Mean blame ratings (¬± SEM; range: 0-100) for actions resp. inactions of human and artificial agents in high-stakes and low-stakes dilemmas</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Mean trust ratings (¬± SEM; range: 0-7) of acting resp. not acting human and artificial agents in high-stakes and low-stakes dilemma</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results of regression analysis on predicting blame of human agents</figDesc><table><row><cell></cell><cell>B</cell><cell>Std.-Error</cell><cell>Œ≤</cell><cell>p</cell><cell>95% CI lower bound</cell><cell>95% CI upper bound</cell></row><row><cell>(Constant)</cell><cell>80.138</cell><cell>5.954</cell><cell></cell><cell>&lt;.001</cell><cell>68.454</cell><cell>91.823</cell></row><row><cell>Dilemma Type</cell><cell>-11.968</cell><cell>1.432</cell><cell>-.238</cell><cell>&lt;.001</cell><cell>-14.777</cell><cell>-9.158</cell></row><row><cell>Agreement</cell><cell>-27.775</cell><cell>2.048</cell><cell>-.384</cell><cell>&lt;.001</cell><cell>-31.794</cell><cell>-23.756</cell></row><row><cell>Gender</cell><cell>-.271</cell><cell>1.498</cell><cell>-.005</cell><cell>.856</cell><cell>-3.212</cell><cell>2.669</cell></row><row><cell>Age</cell><cell>-.127</cell><cell>.068</cell><cell>-.056</cell><cell>.063</cell><cell>-.260</cell><cell>.007</cell></row><row><cell>Religiosity</cell><cell>1.905</cell><cell>.910</cell><cell>.060</cell><cell>.037</cell><cell>.119</cell><cell>3.690</cell></row><row><cell>NFC</cell><cell>-1.361</cell><cell>.828</cell><cell>-.048</cell><cell>.101</cell><cell>-2.986</cell><cell>.264</cell></row><row><cell>Machiavellianism</cell><cell>-.172</cell><cell>.553</cell><cell>-.012</cell><cell>.756</cell><cell>-1.258</cell><cell>.913</cell></row><row><cell>Psychopathy</cell><cell>1.279</cell><cell>.581</cell><cell>.077</cell><cell>.028</cell><cell>.138</cell><cell>2.420</cell></row><row><cell>Narcissism</cell><cell>-.025</cell><cell>.510</cell><cell>-.002</cell><cell>.960</cell><cell>-1.027</cell><cell>0.976</cell></row><row><cell>R</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>2 = .225, F9,980 = 31.30, p &lt; .001 Agreement = agreement with agent's moral choice, NFC = Need for Cognition</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of regression analysis on predicting trust in human agents</figDesc><table><row><cell></cell><cell>B</cell><cell>Std.-Error</cell><cell>Œ≤</cell><cell>p</cell><cell>95% CI lower bound</cell><cell>95% CI upper bound</cell></row><row><cell>(Constant)</cell><cell>3.498</cell><cell>.452</cell><cell></cell><cell>&lt;.001</cell><cell>2.611</cell><cell>4.384</cell></row><row><cell>Dilemma Type</cell><cell>.100</cell><cell>.109</cell><cell>.029</cell><cell>.359</cell><cell>-.114</cell><cell>.315</cell></row><row><cell>Agreement</cell><cell>1.296</cell><cell>.156</cell><cell>.258</cell><cell>&lt;.001</cell><cell>.989</cell><cell>1.603</cell></row><row><cell>Gender</cell><cell>.050</cell><cell>.114</cell><cell>.014</cell><cell>.663</cell><cell>-.175</cell><cell>.274</cell></row><row><cell>Age</cell><cell>.003</cell><cell>.005</cell><cell>.021</cell><cell>.531</cell><cell>-.007</cell><cell>.013</cell></row><row><cell>Religiosity</cell><cell>-.034</cell><cell>.069</cell><cell>-.016</cell><cell>.622</cell><cell>-.171</cell><cell>.102</cell></row><row><cell>NFC</cell><cell>.095</cell><cell>.063</cell><cell>.048</cell><cell>.132</cell><cell>-.029</cell><cell>.218</cell></row><row><cell>Machiavellianism</cell><cell>.004</cell><cell>.042</cell><cell>.004</cell><cell>.932</cell><cell>-.079</cell><cell>.086</cell></row><row><cell>Psychopathy</cell><cell>-.109</cell><cell>.044</cell><cell>-.095</cell><cell>.015</cell><cell>-.196</cell><cell>-.022</cell></row><row><cell>Narcissism</cell><cell>.011</cell><cell>.039</cell><cell>.011</cell><cell>.771</cell><cell>-.065</cell><cell>.087</cell></row><row><cell cols="2">R 2 = .079, F9,959 = 9.05, p &lt; .001</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Agreement = agreement with agent's moral choice, NFC = Need for Cognition</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of regression analysis on predicting blame of artificial agents</figDesc><table><row><cell></cell><cell>B</cell><cell>Std.-Error</cell><cell>Œ≤</cell><cell>p</cell><cell>95% CI lower bound</cell><cell>95% CI upper bound</cell></row><row><cell>(Constant)</cell><cell>60.541</cell><cell>8.692</cell><cell></cell><cell>&lt;.001</cell><cell>43.483</cell><cell>77.600</cell></row><row><cell>Dilemma Type</cell><cell>-5.712</cell><cell>1.619</cell><cell>-.106</cell><cell>&lt;.001</cell><cell>-8.888</cell><cell>-2.535</cell></row><row><cell>Agreement</cell><cell>-25.296</cell><cell>2.315</cell><cell>-.323</cell><cell>&lt;.001</cell><cell>-29.838</cell><cell>-20.753</cell></row><row><cell>Gender</cell><cell>.319</cell><cell>1.810</cell><cell>.006</cell><cell>.860</cell><cell>-3.233</cell><cell>3.871</cell></row><row><cell>Age</cell><cell>-.189</cell><cell>.076</cell><cell>-.077</cell><cell>.014</cell><cell>-.339</cell><cell>-.039</cell></row><row><cell>Religiosity</cell><cell>2.145</cell><cell>1.042</cell><cell>.063</cell><cell>.040</cell><cell>.101</cell><cell>4.189</cell></row><row><cell>NFC</cell><cell>-1.826</cell><cell>1.008</cell><cell>-.059</cell><cell>.070</cell><cell>-3.804</cell><cell>.152</cell></row><row><cell>Machiavellianism</cell><cell>-.019</cell><cell>.623</cell><cell>-.001</cell><cell>.976</cell><cell>-1.240</cell><cell>1.203</cell></row><row><cell>Psychopathy</cell><cell>-.009</cell><cell>.654</cell><cell>.000</cell><cell>.990</cell><cell>-1.292</cell><cell>1.275</cell></row><row><cell>Narcissism</cell><cell>1.568</cell><cell>.576</cell><cell>.096</cell><cell>.007</cell><cell>.438</cell><cell>2.698</cell></row><row><cell>ATI</cell><cell>-.211</cell><cell>1.009</cell><cell>-.007</cell><cell>.834</cell><cell>-2.192</cell><cell>1.770</cell></row><row><cell>NARS 1</cell><cell>4.101</cell><cell>1.470</cell><cell>.109</cell><cell>.005</cell><cell>1.216</cell><cell>6.985</cell></row><row><cell>NARS 2</cell><cell>-.832</cell><cell>1.316</cell><cell>-.024</cell><cell>.528</cell><cell>-3.414</cell><cell>1.751</cell></row><row><cell>NARS 3</cell><cell>-1.408</cell><cell>1.162</cell><cell>-.043</cell><cell>.226</cell><cell>-3.689</cell><cell>.873</cell></row><row><cell cols="2">R 2 = .163, F13,979 = 14.47, p &lt; .001</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Agreement = agreement with agent's moral choice, NFC = Need for Cognition, ATI = Affinity for Technology Interaction,</cell></row><row><cell cols="7">NARS = Negative Attitudes toward (1) Situations and Interactions with Robots, (2) Social Influence of Robots, and (3) Emo-</cell></row><row><cell cols="2">tions in Interaction with Robots</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Results of regression analysis on predicting trust in artificial agents (R 2 = .071)</figDesc><table><row><cell></cell><cell>B</cell><cell>Std.-Error</cell><cell>Œ≤</cell><cell>p</cell><cell>95% CI lower bound</cell><cell>95% CI upper bound</cell></row><row><cell>(Constant)</cell><cell>5.423</cell><cell>.695</cell><cell></cell><cell>&lt;.001</cell><cell>4.058</cell><cell>6.788</cell></row><row><cell>Dilemma Type</cell><cell>-.200</cell><cell>.129</cell><cell>-.050</cell><cell>.121</cell><cell>-.454</cell><cell>.053</cell></row><row><cell>Agreement</cell><cell>1.244</cell><cell>.183</cell><cell>.218</cell><cell>&lt;.001</cell><cell>.884</cell><cell>1.604</cell></row><row><cell>Gender</cell><cell>.048</cell><cell>.144</cell><cell>.012</cell><cell>.741</cell><cell>-.236</cell><cell>.331</cell></row><row><cell>Age</cell><cell>.004</cell><cell>.006</cell><cell>.020</cell><cell>.556</cell><cell>-.009</cell><cell>.016</cell></row><row><cell>Religiosity</cell><cell>.122</cell><cell>.084</cell><cell>.048</cell><cell>.146</cell><cell>-.043</cell><cell>.286</cell></row><row><cell>NFC</cell><cell>-.050</cell><cell>.080</cell><cell>-.022</cell><cell>.532</cell><cell>-.206</cell><cell>.106</cell></row><row><cell>Machiavellianism</cell><cell>-.047</cell><cell>.051</cell><cell>-.040</cell><cell>.353</cell><cell>-.147</cell><cell>.052</cell></row><row><cell>Psychopathy</cell><cell>-.070</cell><cell>.052</cell><cell>-.054</cell><cell>.179</cell><cell>-.173</cell><cell>.032</cell></row><row><cell>Narcissism</cell><cell>-.002</cell><cell>.047</cell><cell>-.002</cell><cell>.966</cell><cell>-.093</cell><cell>.089</cell></row><row><cell>ATI</cell><cell>.005</cell><cell>.081</cell><cell>.002</cell><cell>.954</cell><cell>-.154</cell><cell>.164</cell></row><row><cell>NARS 1</cell><cell>-.143</cell><cell>.117</cell><cell>-.052</cell><cell>.222</cell><cell>-.373</cell><cell>.087</cell></row><row><cell>NARS 2</cell><cell>.008</cell><cell>.105</cell><cell>.003</cell><cell>.942</cell><cell>-.198</cell><cell>.213</cell></row><row><cell>NARS 3</cell><cell>-.208</cell><cell>.092</cell><cell>-.085</cell><cell>.025</cell><cell>-.390</cell><cell>-.027</cell></row><row><cell>R</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>2 = .071, F13,922 = 5.34, p &lt; .001 Agreement = agreement with agent's moral choice, NFC = Need for Cognition, ATI = Affinity for Technology Interaction, NARS = Negative Attitudes toward (1) Situations and Interactions with Robots, (2) Social Influence of Robots, and (3) Emo- tions in Interaction with Robots</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was funded by the Deutsche Forschungsgemeinschaft (DFG), Grant CRC 1410.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest</head><p>The authors have no relevant financial or non-financial interests to disclose.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Androgenic Morality? Associations of Sex, Oral Contraceptive Use and Basal Testosterone Levels with Moral Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Armbruster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kirschbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strobel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bbr.2021.113196</idno>
		<ptr target="https://doi.org/10.1016/j.bbr.2021.113196" />
	</analytic>
	<monogr>
		<title level="j">Behavioural Brain Research</title>
		<imprint>
			<biblScope unit="volume">408</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Will People Morally Crack under the Authority of a Famous Wicked Robot?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Aroyo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kyohei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sciutti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ishiguro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<idno type="DOI">10.1109/ROMAN.2018.8525744</idno>
		<ptr target="https://doi.org/10.1109/ROMAN.2018.8525744" />
	</analytic>
	<monogr>
		<title level="m">27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</title>
		<meeting><address><addrLine>Nanjing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Moral Machine Experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Awad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dsouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Henrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shariff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Bonnefon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rahwan</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-018-0637-6</idno>
		<ptr target="https://doi.org/10.1038/s41586-018-0637-6" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">563</biblScope>
			<biblScope unit="issue">7729</biblScope>
			<biblScope unit="page" from="59" to="64" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Step Aside! Vr-Based Evaluation of Adaptive Robot Conflict Resolution Strategies for Domestic Service Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Babel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Angerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Seufert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1007/s12369-021-00858-7</idno>
		<ptr target="https://doi.org/10.1007/s12369-021-00858-7" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1239" to="1260" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Intuitive Moral Judgments Are Robust across Variation in Gender, Education, Politics and Religion: A Large-Scale Web-Based Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hauser</surname></persName>
		</author>
		<idno type="DOI">10.1163/156853710x531186</idno>
		<ptr target="https://doi.org/10.1163/156853710x531186" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognition and Culture</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="253" to="281" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">When the Killing Has Been Done: Exploring Associations of Personality with Third-Party Judgment and Punishment of Homicides in Moral Dilemma Scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Behnke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Armbruster</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0235253</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0235253" />
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Evolution of Norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bendor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Swistak</surname></persName>
		</author>
		<idno type="DOI">10.1086/321298</idno>
		<ptr target="https://doi.org/10.1086/321298" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1493" to="1545" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">People Are Averse to Machines Making Moral Decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">E</forename><surname>Bigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2018.08.003</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2018.08.003" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="21" to="34" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Need for Cognition: Eine Skala Zur Erfassung Von Engagement Und Freude Bei Denkaufgaben</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">; H</forename><surname>Bjorklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>W√§nke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bohner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Fellhauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
		<idno type="DOI">10.1046/j.1467-9450.2003.00367.x</idno>
		<ptr target="https://doi.org/10.1046/j.1467-9450.2003.00367.xBless" />
	</analytic>
	<monogr>
		<title level="m">Differences in the Justification of Choices in Moral Dilemmas: Effects of Gender</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="147" to="154" />
		</imprint>
	</monogr>
	<note>Zeitschrift f√ºr Sozialpsychologie</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Evolution of Altruistic Punishment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gintis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Richerson</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0630443100</idno>
		<ptr target="https://doi.org/10.1073/pnas.0630443100" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="3531" to="3535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exogenous Testosterone Increases Sensitivity to Moral Norms in Moral Dilemma Judgements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Brannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Josephs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gawronski</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0641-3</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0641-3" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="856" to="866" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Social Perception of Embodied Digital Technologies-a Closer Look at Bionics and Social Robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bretschneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Asbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meyer</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11612-022-00644-7</idno>
		<ptr target="https://doi.org/10.1007/s11612-022-00644-7" />
	</analytic>
	<monogr>
		<title level="j">Gruppe. Interaktion. Organisation. Zeitschrift f√ºr Angewandte Organisationspsychologie (GIO)</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="343" to="358" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Need for Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Cacioppo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Petty</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.42.1.116</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.42.1.116" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="131" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gender and Attitudes toward Technology Use: A Meta-Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compedu.2016.11.003</idno>
		<ptr target="https://doi.org/10.1016/j.compedu.2016.11.003" />
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Gender Differences in Moral Judgment and the Evaluation of Gender-Specified Moral Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Capraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sippel</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10339-017-0822-9</idno>
		<ptr target="https://doi.org/10.1007/s10339-017-0822-9" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="399" to="405" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Moral Judgment Reloaded: A Moral Dilemma Validation Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Flexas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Calabrese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Gut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gomila</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00607</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2014.00607" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">607</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Moral Dilemmas in Cognitive Neuroscience of Moral Decision-Making: A Principled Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gomila</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neubiorev.2012.02.008</idno>
		<ptr target="https://doi.org/10.1016/j.neubiorev.2012.02.008" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience and Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1249" to="1264" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Religion&apos;s Profound Influences on Psychology: Morality, Intergroup Relations, Self-Construal, and Enculturation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1177/0963721414553265</idno>
		<ptr target="https://doi.org/10.1177/0963721414553265" />
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="82" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deontological and Utilitarian Inclinations in Moral Decision Making: A Process Dissociation Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gawronski</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0031021</idno>
		<ptr target="https://doi.org/10.1037/a0031021" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="216" to="235" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Psychology of Morality: A Review and Analysis of Empirical Studies Published from 1940 through 2017</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ellemers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Der Toorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Paunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<idno type="DOI">10.1177/1088868318811759</idno>
		<ptr target="https://doi.org/10.1177/1088868318811759" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="332" to="366" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Personal Resource for Technology Interaction: Development and Validation of the Affinity for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Attig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wessel</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2018.1456150</idno>
		<ptr target="https://doi.org/10.1080/10447318.2018.1456150" />
	</analytic>
	<monogr>
		<title level="j">Technology Interaction (Ati) Scale International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="456" to="467" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">What Does Matter? The Case for Killing the Trolley Problem (or Letting It Die). The Philosophical Quarterly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Fried</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9213.2012.00061.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9213.2012.00061.x" />
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="505" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Friesdorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gawronski</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167215575731</idno>
		<ptr target="https://doi.org/10.1177/0146167215575731" />
	</analytic>
	<monogr>
		<title level="m">Gender Differences in Responses to Moral Dilemmas: A Process Dissociation Analysis</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="696" to="713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fumagalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mameli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marceglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mrakic-Sposta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lucchiari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Consonni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nordio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pravettoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Priori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<idno type="DOI">10.1007/s10339-009-0335-2</idno>
		<ptr target="https://doi.org/10.1007/s10339-009-0335-2" />
	</analytic>
	<monogr>
		<title level="m">Gender-Related Differences in Moral Judgments</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Science and Scientists Held in High Esteem across Global Publics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tyson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pew Research Center</title>
		<imprint>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Consequences, Norms, and Generalized Inaction in Moral Dilemmas: The Cni Model of Moral Decision-Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gawronski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Friesdorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspa0000086</idno>
		<ptr target="https://doi.org/10.1037/pspa0000086" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="343" to="376" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">What Makes Moral Dilemma Judgments &quot;Utilitarian&quot; or &quot;Deontological</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gawronski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Beer</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470919.2016.1248787</idno>
		<ptr target="https://doi.org/10.1080/17470919.2016.1248787" />
	</analytic>
	<monogr>
		<title level="j">Social Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="626" to="632" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">K√ºnstliche Intelligenz -Den Ersten Schritt Vor Dem Zweiten Tun!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gesmann-Nuissl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zeitschrift zum Innovations-und Technikrecht (InTeR)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="105" to="106" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Vengeance and the Dark Triad: The Role of Empathy and Perspective Taking in Trait Forgivingness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Giammarco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Vernon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.paid.2014.02.010</idno>
		<ptr target="https://doi.org/10.1016/j.paid.2014.02.010" />
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="23" to="29" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attitudes Towards Social Robots: The Role of Gender, Belief in Human Nature Uniqueness, Religiousness and Interest in Science Fiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Giger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pi√ßarra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">II International Congress on Interdisciplinarity in Social and Human Sciences</title>
		<meeting><address><addrLine>Faro, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Research Centre for Spatial and Organizational Dynamics, University of Algarve</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Are All Types of Morality Compromised in Psychopathy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Glenn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haidt</surname></persName>
		</author>
		<idno type="DOI">10.1521/pedi.2009.23.4.384</idno>
		<ptr target="https://doi.org/10.1521/pedi.2009.23.4.384" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality Disorders</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="384" to="398" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Outlandish, the Realistic, and the Real: Contextual Manipulation and Agent Role Effects in Trolley Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Pulford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Colman</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00035</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2014.00035" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cultural Differences in Moral Judgment and Behavior, across and within Societies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meindl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Beall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.copsyc.2015.09.007</idno>
		<ptr target="https://doi.org/10.1016/j.copsyc.2015.09.007" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="125" to="130" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Unveiling Robotophobia and Cyber-Dystopianism: The Role of Gender, Technology and Religion on Attitudes Towards Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m">ACM/IEEE International Conference on Human-Robot Interaction (HRI)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Comparison of Procedures for the Assessment of Psychopathy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hare</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-006x.53.1.7</idno>
		<ptr target="https://doi.org/10.1037//0022-006x.53.1.7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Consulting and Clinical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="16" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Psychopathy: Assessment and Forensic Implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Neumann</surname></persName>
		</author>
		<idno type="DOI">10.1177/070674370905401202</idno>
		<ptr target="https://doi.org/10.1177/070674370905401202" />
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Psychiatry</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="791" to="802" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">W</forename><surname>Huber</surname></persName>
		</author>
		<idno type="DOI">10.3390/rel3030710</idno>
		<ptr target="https://doi.org/10.3390/rel3030710" />
	</analytic>
	<monogr>
		<title level="j">The Centrality of Religiosity Scale (Crs). Religions</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="710" to="724" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Religion-Related Values Differently Influence Moral Attitude for Robots in the United States and Japan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ikari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Burdett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ishiguro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nakawake</surname></persName>
		</author>
		<idno type="DOI">10.1177/00220221231193369</idno>
		<ptr target="https://doi.org/10.1177/00220221231193369" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6-7</biblScope>
			<biblScope unit="page" from="742" to="759" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Action-Inaction Asymmetries in Moral Scenarios: Replication of the Omission Bias Examining Morality and Blame with Extensions Linking to Causality, Intent, and Regret</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jamison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Feldman</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2020.103977</idno>
		<ptr target="https://doi.org/10.1016/j.jesp.2020.103977" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The Moral Choice Machine: Semantics Derived Automatically from Language Corpora Contain Human-Like Moral Choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schramowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rothkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<idno type="DOI">10.1145/3306618.3314267</idno>
		<ptr target="https://doi.org/10.1145/3306618.3314267" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Aaai/Acm Conference on Ai</title>
		<meeting>the 2nd Aaai/Acm Conference on Ai</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sidetracked by Trolleys: Why Sacrificial Moral Dilemmas Tell Us Little (or Nothing) About Utilitarian Judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kahane</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470919.2015.1023400</idno>
		<ptr target="https://doi.org/10.1080/17470919.2015.1023400" />
	</analytic>
	<monogr>
		<title level="j">Social Neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="551" to="560" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Attitudes Towards Robots Suitability for Various Jobs as Affected Robot Appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Halpern</surname></persName>
		</author>
		<idno type="DOI">10.1080/0144929X.2013.783115</idno>
		<ptr target="https://doi.org/10.1080/0144929X.2013.783115" />
	</analytic>
	<monogr>
		<title level="j">Behaviour &amp; Information Technology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="941" to="953" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Criminal Psychopath: History, Neuroscience, Treatment, and Economics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Kiehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jurimetrics</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="355" to="397" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The Duke University Religion Index (Durel): A Five-Item Measure for Use in Epidemological Studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Koenig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>B√ºssing</surname></persName>
		</author>
		<idno type="DOI">10.3390/rel1010078</idno>
		<ptr target="https://doi.org/10.3390/rel1010078" />
	</analytic>
	<monogr>
		<title level="j">Religions</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deontology and Utilitarianism in Real Life: A Set of Moral Dilemmas Based on Historic Events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>K√∂rner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Deutsch</surname></persName>
		</author>
		<idno type="DOI">10.1177/01461672221103058</idno>
		<ptr target="https://doi.org/10.1177/01461672221103058" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Using the Cni Model to Investigate Individual Differences in Moral Dilemma Judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>K√∂rner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gawronski</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167220907203</idno>
		<ptr target="https://doi.org/10.1177/0146167220907203" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1392" to="1407" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Das Dreckige Dutzend Und Die Niedertr√§chtigen Neun. Kurzskalen Zur Erfassung Von Narzissmus, Machiavellismus Und Psychopathie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C P</forename><surname>K√ºfner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dufner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Backc</surname></persName>
		</author>
		<idno type="DOI">10.1026/0012-1924/a000124</idno>
		<ptr target="https://doi.org/10.1026/0012-1924/a000124" />
	</analytic>
	<monogr>
		<title level="j">Diagnostica</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="76" to="91" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Moral Uncanny Valley: A Robot&apos;s Appearance Moderates How Its Decisions Are Judged</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Laakasuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Palom√§ki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>K√∂bis</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12369-020-00738-6</idno>
		<ptr target="https://doi.org/10.1007/s12369-020-00738-6" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1679" to="1688" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Building Jiminy Cricket: An Architecture for Moral Agreements among Stakeholders AIES&apos;19</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Slavkovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Torre</surname></persName>
		</author>
		<idno type="DOI">10.1145/3306618.3314257</idno>
		<ptr target="https://doi.org/10.1145/3306618.3314257" />
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>Honolulu, HI, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Does Japan Really Have Robot Mania? Comparing Attitudes by Implicit and Explicit Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">F</forename><surname>Macdorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Ho</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-008-0181-2</idno>
		<ptr target="https://doi.org/10.1007/s00146-008-0181-2" />
		<imprint>
			<date type="published" when="2009" />
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="485" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Integrating Robot Ethics and Machine Morality: The Study and Design of Moral Competence in Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Malle</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10676-015-9367-8</idno>
		<ptr target="https://doi.org/10.1007/s10676-015-9367-8" />
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="243" to="256" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Ai in the Sky: How People Morally Evaluate Human and Machine Decisions in a Lethal Strike Dilemma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Malle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Magar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scheutz</surname></persName>
		</author>
		<editor>M. I</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldinhas</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sequeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Virk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tokhi</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-12524-0_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-12524-0_11" />
		<title level="m">Robotics and Well-Being</title>
		<editor>&amp; E. E. Kadar</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="111" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sacrifice One for the Good of Many?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Malle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scheutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voiklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cusimano</surname></persName>
		</author>
		<idno type="DOI">10.1145/2696454.2696458</idno>
		<ptr target="https://doi.org/10.1145/2696454.2696458" />
	</analytic>
	<monogr>
		<title level="m">People Apply Different Moral Norms to Human and Robot Agents 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</title>
		<meeting><address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Embodied Digital Technologies: First Insights in the Social and Legal Perception of Robots and Users of Prostheses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bretschneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gesmann-Nuissl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Asbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strobel</surname></persName>
		</author>
		<idno type="DOI">10.3389/frobt.2022.787970</idno>
		<ptr target="https://doi.org/10.3389/frobt.2022.787970" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Robotics and AI</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Do Psychopathic Individuals Possess a Misaligned Moral Compass? A Meta-Analytic Examination of Psychopathy&apos;s Relations with Moral Judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">O</forename><surname>Lilienfeld</surname></persName>
		</author>
		<idno type="DOI">10.1037/per0000226</idno>
		<ptr target="https://doi.org/10.1037/per0000226" />
	</analytic>
	<monogr>
		<title level="j">Personality Disorders: Theory, Research, and Treatment</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="50" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Responsibility in Hybrid Societies: Concepts and Terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gesmann-Nuissl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strobel</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-022-00184-2</idno>
		<ptr target="https://doi.org/10.1007/s43681-022-00184-2" />
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="25" to="48" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Artificial Morality. Concepts, Issues and Challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Misselhorn</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12115-018-0229-y</idno>
		<ptr target="https://doi.org/10.1007/s12115-018-0229-y" />
	</analytic>
	<monogr>
		<title level="j">Society</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="161" to="169" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Animal Morality: What It Means and Why It Matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mons√≥</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Benz-Schwarzburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bremhorst</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10892-018-9275-3</idno>
		<ptr target="https://doi.org/10.1007/s10892-018-9275-3" />
	</analytic>
	<monogr>
		<title level="j">Journal of Ethics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="310" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The Dark Core of Personality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moshagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Hilbig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zettler</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000111</idno>
		<ptr target="https://doi.org/10.1037/rev0000111" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="656" to="688" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Prediction of Human Behavior in Human--Robot Interaction Using Psychological Scales for Anxiety and Negative Attitudes toward Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nomura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kato</surname></persName>
		</author>
		<idno type="DOI">10.1109/TRO.2007.914004</idno>
		<ptr target="https://doi.org/10.1109/TRO.2007.914004" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="442" to="451" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Experimental Investigation into Influence of Negative Attitudes toward Robots on Human-Robot Interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nomura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Takayuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Suzuki</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-005-0012-7</idno>
		<ptr target="https://doi.org/10.1007/s00146-005-0012-7" />
		<imprint>
			<date type="published" when="2006" />
			<publisher>AI &amp; Society</publisher>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="138" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Results: Should a Carebot Bring an Alcoholic a Drink? Poll Says, It Depends on Who Owns the Robot Retrieved</title>
		<ptr target="https://openroboethics.org/results-should-a-carebot-bring-an-alcoholic-a-drink-poll-says-it-depends-on-who-owns-the-robot/" />
	</analytic>
	<monogr>
		<title level="j">Open Roboethics Institute</title>
		<imprint>
			<date type="published" when="2015-12-13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Prolific.Ac -a Subject Pool for Online Experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schitter</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbef.2017.12.004</idno>
		<ptr target="https://doi.org/10.1016/j.jbef.2017.12.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral and Experimental Finance</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="22" to="27" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">At the Heart of Morality Lies Neuro-Visceral Integration: Lower Cardiac Vagal Tone Predicts Utilitarian Moral Judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kappes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Bavel</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsw077</idno>
		<ptr target="https://doi.org/10.1093/scan/nsw077" />
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1588" to="1596" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Trait Psychopathy and Utilitarian Moral Judgement: The Mediating Role of Action Aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Patil</surname></persName>
		</author>
		<idno type="DOI">10.1080/20445911.2015.1004334</idno>
		<ptr target="https://doi.org/10.1080/20445911.2015.1004334" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="366" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Reasoning Supports Utilitarian Resolutions to Moral Dilemmas across Diverse Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Zucchelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fornasier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Calo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Silani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cikara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspp0000281</idno>
		<ptr target="https://doi.org/10.1037/pspp0000281" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="443" to="460" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The Dark Triad of Personality: Narcissism, Machiavellianism, and Psychopathy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Paulhus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0092-6566(02)00505-6</idno>
		<ptr target="https://doi.org/10.1016/S0092-6566(02" />
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="505" to="511" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">A Treatise on Insanity and Other Disorders Affecting the Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Prichard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1835" />
			<pubPlace>Sherwood, Gilbert and Piper</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Medical Inquiries and Observations Upon the Diseases of the Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rush</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1812" />
			<publisher>Kimber &amp; Richardson</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Less Thought, More Punishment: Need for Cognition Predicts Support for Punitive Responses to Crime</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sargent</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167204264481</idno>
		<ptr target="https://doi.org/10.1177/0146167204264481" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1485" to="1493" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Empathy, Morality and Psychopathic Traits in Women</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seara-Cardosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dolberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Roiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Viding</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.paid.2013.03.011</idno>
		<ptr target="https://doi.org/10.1016/j.paid.2013.03.011" />
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="333" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">On Gender and Philosophical Intuition: Failure of Replication and Other Negative Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Seyedsayamdost</surname></persName>
		</author>
		<idno type="DOI">10.1080/09515089.2014.893288</idno>
		<ptr target="https://doi.org/10.1080/09515089.2014.893288" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Psychology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="642" to="673" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Looking Forward to Sociable Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shaw-Garlock</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12369-009-0021-7</idno>
		<ptr target="https://doi.org/10.1007/s12369-009-0021-7" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="249" to="260" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">A 21 Word Solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Simonssohn</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.2160588</idno>
		<ptr target="https://ssrn.com/abstract=2160588orhttp://dx.doi.org/10.2139/ssrn.2160588" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sindermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wernicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sariyska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stavrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Montag</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13218-020-00689-0</idno>
		<ptr target="https://doi.org/10.1007/s13218-020-00689-0" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="109" to="118" />
		</imprint>
	</monogr>
	<note type="report_type">KI -K√ºnstliche Intelligenz</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Decision-Making in Everyday Moral Conflict Situations: Development and Validation of a New Measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kreuzpointner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Kudielka</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0214747</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0214747" />
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Need for Cognition as a Moral Capacity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pohling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strobel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.paid.2017.05.023</idno>
		<ptr target="https://doi.org/10.1016/j.paid.2017.05.023" />
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="42" to="51" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Syrdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Koay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Walters</surname></persName>
		</author>
		<title level="m">The Negative Attitudes Towards Robots Scale and Reactions to Robot Behaviour in a Live Human-Robot Interaction Study. Adaptive and Emergent Behaviour and Complex Systems: Proceedings of the 23rd Convention of the Society for the Study of Artificial Intelligence and Simulation of Behaviour</title>
		<meeting><address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-04" />
			<biblScope unit="page" from="6" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Religiosity Enhances Emotion and Deontological Choice in Moral Dilemmas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Opre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Miu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.paid.2015.01.036</idno>
		<ptr target="https://doi.org/10.1016/j.paid.2015.01.036" />
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="104" to="109" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Moral Fatigue: The Effects of Cognitive Fatigue on Moral Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Timmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Byrne</surname></persName>
		</author>
		<idno type="DOI">10.1177/1747021818772045</idno>
		<ptr target="https://doi.org/10.1177/1747021818772045" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="943" to="954" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Social Motivation, Justice and the Moral Emotions: An Attributional Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Weiner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Tayler &amp; Francis</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
