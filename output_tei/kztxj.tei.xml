<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Overcoming learning traps with summative feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaimie</forename><forename type="middle">E</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><forename type="middle">X</forename><surname>Li</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><forename type="middle">K</forename><surname>Hayes</surname></persName>
							<email>b.hayes@unsw.edu.au</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<settlement>Sydney</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<settlement>Sydney</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of New</orgName>
								<address>
									<addrLine>South Wales, Anzac Parade, Kensington, NSW</addrLine>
									<postCode>2052</postCode>
									<country key="AU">AUSTRALIA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Overcoming learning traps with summative feedback</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>exploration</term>
					<term>category learning</term>
					<term>feedback</term>
					<term>decision-making</term>
				</keywords>
			</textClass>
			<abstract>
				<p>All data, stimulus materials and details of statistical analyses for this paper can be found in the Open Science Framework archive https://osf.io/q3v9z/. The project was supported by Australian Research Council Discovery Grant DP220101592 to BKH. The authors have no known conflicts of interest to disclose. We would like to thank Todd Gureckis and Ben Newell for useful discussions of this work and Yuhang Wen for assistance with coding of the experiments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overcoming learning traps with summative feedback</head><p>Imagine that a new pizza restaurant has opened in your neighborhood. You decide to explore their offerings and order a pepperoni pizzawhich you disliked. Based on this negative experience, you conclude that the restaurant's food is generally poor and never make another order. This behavior would be adaptive if your belief was true. However, if the belief was false (i.e., other pizzas from that restaurant taste great), the failure to continue exploring means that you miss future rewards.</p><p>This illustrates what has been termed a learning trap <ref type="bibr">(Braunlich &amp; Love, 2021;</ref><ref type="bibr" target="#b8">Erev, 2014;</ref><ref type="bibr" target="#b16">Liquin &amp; Gopnik, 2022)</ref>. Early experience leads to the formation of an erroneous belief about the reward structure of the environment (e.g., that a particular choice option is always associated with a negative outcome). Subsequent avoidance of that option leads to the persistence of the belief and missed opportunities for future rewards. The consequences of such learning traps are often more serious than in our opening example. For instance, they can lead to repeated investment in stocks with suboptimal returns, erroneous beliefs about employee attributes that predict job success, or the development of social stereotypes <ref type="bibr" target="#b5">(Denrell, 2005;</ref><ref type="bibr" target="#b14">Le Mens &amp; Denrell, 2011;</ref><ref type="bibr" target="#b19">Rich &amp; Gureckis, 2018;</ref><ref type="bibr" target="#b22">Teodorescu &amp; Erev, 2014)</ref>.</p><p>Learning traps come in a number of forms. One type of trap involves environments where the outcomes that follow from approaching a particular prospect vary over time (e.g., on average the outcomes are positive but occasionally a large negative outcome is encountered).</p><p>Early experience with the negative outcome can lead to a "hot stove" effect, where the learner subsequently avoids the prospect and misses out on potential rewards <ref type="bibr">(Denrell, 2007;</ref><ref type="bibr" target="#b7">Denrell &amp; March, 2001</ref>).</p><p>In many if not most learning environments, however, we interact with stimuli composed of multiple features <ref type="bibr">(Murphy, 2005)</ref> and use to these to predict choice outcomes <ref type="bibr">(e.g., Bonder et al., 2023;</ref><ref type="bibr" target="#b19">Rich &amp; Gureckis, 2018;</ref><ref type="bibr">Schultz et al., 2018)</ref>. In such environments, people often 2 selectively attend to a subset of the features that can be used to predict category membership <ref type="bibr">(Blanco et al., 2023;</ref><ref type="bibr" target="#b23">Wills et al., 2015)</ref>. While this is often adaptive (e.g., making efficient use of working memory resources), in some environments such selective attention can lead to learning traps. For example, <ref type="bibr" target="#b19">Rich and Gureckis (2018)</ref> examined learning trap formation in a task where different categories (types of cartoon bees) were associated with rewards or losses.</p><p>A conjunctive rule involving two feature dimensions was a perfect predictor of the category bound and associated outcomes (e.g., bees with spots and antennae were "dangerous" and associated with a loss; bees with other feature combinations were "friendly" and associated with a gain). On each learning trial, participants could choose to approach or avoid an exemplar.</p><p>Approaching the exemplar led to the associated outcome, while avoidance meant that no gain or loss was incurred.</p><p>A crucial finding was that very different patterns of learning and decision-making emerged depending on the type of outcome feedback that learners received. In full feedback conditions, learners were informed about the category membership of each stimulus (e.g., whether a bee was friendly or dangerous) regardless of whether they decided to approach or avoid it. Most of those receiving this feedback learned the optimal rule that involved two feature dimensions. In contrast, those in contingent feedback condition only received feedback about the outcome of approach decisions. Only a minority of those in this condition learned the optimal category rule. Around half fell into a learning trap, relying on a sub-optimal, onedimensional categorization rule (e.g., "avoid bees with spots, approach bees with stripes"). As a result, these participants earned substantially fewer rewards.</p><p>The finding that decision-contingent feedback can lead people to adopt overly simplistic predictive rules that lead to the loss of rewards has now been replicated several times <ref type="bibr" target="#b15">(Li et al., 2021;</ref><ref type="bibr">Lee, W-J et al., 2023)</ref> and extended to stimuli composed of text descriptions of individuals <ref type="bibr" target="#b19">(Rich &amp; Gureckis, 2018)</ref>. The same type of learning trap has also been identified 3 in causal learning tasks <ref type="bibr" target="#b16">(Liquin &amp; Gopnik, 2022)</ref>. Another consistent finding is that, once formed, these traps persist despite further opportunities for learners to explore choice options that would lead to the correction of their false beliefs <ref type="bibr" target="#b15">(Li et al., 2021;</ref><ref type="bibr">Lee, W-J et al., 2023;</ref><ref type="bibr">Rick &amp; Gureckis, 2018)</ref>. As well as leading to reduced rewards, these types of learning traps can also induce "change blindness" -causing learners to miss dynamic changes in the reward structure of the environment <ref type="bibr">(Blanco et al., 2023;</ref><ref type="bibr">Lee, W. J. et al., 2023)</ref>. <ref type="bibr" target="#b19">Rich and Gureckis (2018)</ref> suggested that learning trap formation is driven by the process illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. Early experience highlights the relevance of feature values on one dimension (e.g., approaching instances with a feature value of 0 on dimension 1 have led to positive outcomes, while approaching instances with a feature value of 1 have led to negative outcome). This leads to the false belief that gains and losses can be predicted by this dimension alone. Consequently, there is reduced attention to feature values on the other relevant dimension, and avoidance of instances that actually yield rewards. When outcome feedback is contingent on approach decisions, the learner receives no error signal that would cause them to change their behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overcoming learning traps and the varieties of feedback</head><p>Given the pernicious and persistent effects of learning traps, it seems important to consider how they could be prevented or reversed. One approach suggested from the theoretical framework outline in <ref type="figure" target="#fig_0">Figure 1</ref> is to promote attention to multiple feature dimensions early in learning. Rich and Gureckis (2018) trialed a number of experimental interventions aimed at broadening attention such as randomly occluding some features across trials or adding stochasticity to decision outcomes. Unfortunately, neither manipulation reduced learning trap prevalence.</p><p>In the current work, we examine a different approach to reducing susceptibility to learning traps focused on the critical role played by outcome feedback. <ref type="figure" target="#fig_0">Figure 1</ref>, as well as 4 previous empirical work (e.g., <ref type="bibr" target="#b15">Li et al., 2021;</ref><ref type="bibr" target="#b19">Rich &amp; Gureckis, 2018)</ref>, highlights that learning traps are maintained by decision-contingent feedback but are rare when full outcome feedback is available. We argue, however, that full and contingent feedback, however, can be seen as extremes on a continuum representing the amount and specificity of environmental feedback about choice outcomes. Between these extremes, there are many other forms of feedback that can affect learning and decision-making (see <ref type="bibr">Balzer et al., 1989;</ref><ref type="bibr">Harvey &amp; Fischer, 2014 for reviews)</ref>.</p><p>One form of feedback that has been shown to improve learning in a number of task environments involves providing learners with a comparison between their current task performance and optimal levels of performance (e.g., <ref type="bibr">Evans &amp; Brown, 2017;</ref><ref type="bibr">Friedman &amp; Massaro, 1998;</ref><ref type="bibr">Newell et al., 2009;</ref><ref type="bibr" target="#b20">Shanks et al., 2002)</ref>. We refer to this as summative feedback, which allows learners to see how close or far their performance is from that achievable by an ideal learner. Unlike the more detailed trial-by-trial information about decision outcomes provided in full feedback, however, summative feedback provides no specific information about the correct learning rule or algorithm. <ref type="bibr" target="#b20">Shanks et al. (2002)</ref> examined whether a form of summative outcome feedback could increase probability maximizing in a binary choice task (i.e., consistently choosing the option with the highest mean reward value) as opposed to probability matching (i.e., distributing choices between alternatives in proportion to rewards previously associated with each option).</p><p>After a number of such choices, participants were told about their current earnings and the total amount that they could have earned by that point. <ref type="bibr" target="#b20">Shanks et al. (2002)</ref> found that summative feedback increased maximizing responses on subsequent trials.</p><p>Friedman and Massaro (1998) examined the effects of summative feedback in a more complex multiple-cue probability learning task. This involved a simulated medical diagnosis where two dimensions with feature continuous values (e.g., temperature, blood pressure) were stochastically associated with two alternative disease categories. On each trial, participants viewed the values on each dimension and made a binary judgment and confidence estimate about the most likely disease. All learners received feedback about the accuracy of their decision. Those in the summative feedback condition were also given a numerical score which compared their likelihood estimate with the true score proved by an ideal Bayesian learner. The optimal strategy in this task is to always choose the disease that has been more frequently associated with a particular symptom pattern (i.e., maximizing). Summative feedback significantly increased the proportion of maximizers. This effect was stronger than that achieved by incentivizing performance through increased monetary rewards.</p><p>Learning traps arise when the learner believes that an overly simplistic category rule is the best way of obtaining rewards and avoiding losses, and are maintained because the learner does not receive feedback that would challenge this belief. Providing a learner who is currently using a one-dimensional rule with summative feedback would provide a clear signal that this rule is suboptimal. We hypothesize that this could increase the likelihood that the learner will explore instances they are currently avoiding. The learner would therefore receive more specific trial feedback that would challenge their current category rule, and increase the chances of learning the correct rule.</p><p>We see the possible effect of summative feedback on learning trap formation as analogous to social learning involving feedback or advice from other learners (cf. <ref type="bibr" target="#b11">Harvey &amp; Fischer, 2014;</ref><ref type="bibr">Whalen et al., 2017)</ref>. By comparing one's own experience to the more positive experience of another learner, an individual may realize they are missing out on potential rewards. This could prompt them to re-explore the environment and potentially adjust their category beliefs. In our restaurant example, other diners may share their positive experiences with the restaurant's food, which may encourage an individual to return to the restaurant to understand the discrepancy between a friend's 5-star rating and their own 2-star rating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Current Studies</head><p>The goal of the current work was to examine whether providing learners with summative feedback can reduce the prevalence of learning traps. In a paradigm similar to that of <ref type="bibr" target="#b19">Rich and Gureckis (2018)</ref>, some learners received only decision-contingent feedback on each trial. Following the results of previous studies (e.g., <ref type="bibr" target="#b15">Li et al., 2021;</ref><ref type="bibr">Lee, W., et al., 2023;</ref><ref type="bibr" target="#b16">Liquin &amp; Gopnik, 2022;</ref><ref type="bibr" target="#b19">Rich &amp; Gureckis, 2018)</ref>, we expected that a substantial proportion of these participants would fall into the trap of using a one-dimensional category rule and missing available awards. Other learners also received summative feedback which compared their current reward earnings with optimal earnings. We expected that this would subsequently increase exploration of category exemplars, and reduce the chances of falling into the onedimensional learning trap.</p><p>A subsidiary aim of these studies was to examine the effects of the amount and timing of summative feedback. In previous work (e.g., <ref type="bibr">Friedman &amp; Massaro, 1998;</ref><ref type="bibr" target="#b20">Shanks et al., 2002)</ref>, summative feedback has generally been provided at multiple points throughout learning.</p><p>Whether or not such regular repetition of summative feedback is necessary for beneficial effects on learning and decision-making is not known. If summative feedback were to be considered as a way of reducing learning traps in training regimes outside the laboratory, it would be useful to know whether positive benefits could be achieved through lower "doses" of feedback. This issue was initially explored in Experiment 1. Experiment 2 followed up with a more systematic examination of whether smaller amounts of summative feedback provided either early or late in learning, could reduce the prevalence of learning traps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>This study examined the impact of summative feedback on learning trap formation in a paradigm similar to that used by <ref type="bibr" target="#b19">Rich and Gureckis (2018)</ref>. Learners in all conditions received choice-contingent feedback, such that choice outcomes on each learning trial were only revealed when an exemplar was approached. Different groups received either 0, 1, 2, or 5 doses of summative feedback over the course of learning. We examined whether increasing levels of summative feedback would reduce learning trap formation, as indexed by use of suboptimal one-dimensional rules (1D) instead of an optimal two-dimensional rule (2D) and erroneous beliefs about which dimensions predict category membership, was compared between groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Participants</head><p>We recruited 285 online participants via the platforms Amazon Mechanical Turk (70% of sample) and Prolific (30% of sample) (Mage = 37.5 years; 110 females, 170 males, 5 other).</p><p>Participants were randomly allocated by the experimental program to one of four conditions.</p><p>Four participants were excluded because they took 20 or more attempts to complete the instruction comprehension check. A further five participants were excluded because they approached items on every learning and test trial. <ref type="bibr">1</ref> The resulting sample sizes were contingent feedback only (n = 71), contingent feedback with 1 dose of summative feedback (n = 67), with 2 doses (n = 71), or with 5 doses (n = 67). Participants received a base payment of $2.00 USD.</p><p>Every extra point accrued in the study was converted to 1 cent, so a bonus of up to $1.70 USD could be earned. Cell sample sizes aimed to replicate those of Rich and Gureckis (2018, Experiment 2). Ethics approval for both experiments was obtained from the UNSW Human Research Ethics Panel. This study was not preregistered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure and Materials</head><p>The experimental paradigm was implemented online in jsPsych (de Leeuw, 2015) and delivered through a web browser. Participants were instructed that they were "virtual beekeepers" tasked with collecting honey from beehives. Hives were inhabited by either "friendly" bees who produced honey (leading to a 1-point gain) or "dangerous" bees who would sting (leading to a 3-point loss). Bees varied along four binary-valued feature dimensions (body pattern: stripes or spots; wings: single or double; number of legs: 2 or 6; antennae: present or absent). Participants were told that they could learn to discriminate between bee types using these features (see https://osf.io/q3v9z/ for details of training and test stimuli and experimental instructions).</p><p>Two of the four feature dimensions were relevant to categorizing bees (see <ref type="figure" target="#fig_0">Figure 1</ref> for an example). A conjunctive two-dimensional rule perfectly predicted category membership (e.g., bees with single wings and two legs were dangerous, bees with other feature combinations on these dimensions were friendly). Features on the remaining two dimensions were not predictive of category membership (i.e., across trials, features on these dimensions were equally likely to be associated with friendly or dangerous bees). The relevant dimensions and feature combinations that determined category membership were randomly assigned for each participant.</p><p>Before commencing the learning phase, participants had to complete an instruction comprehension check consisting of four multiple-choice questions. If a participant made an error on any question, they were returned to the instruction screens. The learning phase consisted of 8 blocks of 16 trials. On each trial, a bee exemplar was presented and the participant chose to approach ("harvest") or avoid the bee's hive by pressing labelled on-screen buttons. Participants started with a balance of 50 points. Approaching a friendly hive led to a 1-point gain; approaching a dangerous hive led to a 3-point loss. If a hive was avoided, no outcome feedback was provided and the points balance was unaffected. An on-screen counter tallied the current points earned, and was updated after each trial. In each block, participants encountered all 16 unique exemplars constructed from combinations of the four feature dimensions, including 12 friendly and 4 dangerous bees. Item presentation order was randomized within blocks and transition between blocks was not signaled to participants. Those in the contingent-feedback only condition received no other feedback.</p><p>Participants in the contingent + summative feedback conditions received additional screens that read: "In the past 20 trials, you have earned X points. The maximum number of points you could have earned in those trials is Y. There is a gap of Y-X points". The first summative feedback screen appeared after the end of the second learning block. For those in the summative 1-dose condition this was the only additional feedback. For those in the 2-dose condition, a second summative screen was presented after block five. Those in the 5-dose condition saw a further three summative screens, after blocks three, four and six. To mask the transitions between learning blocks, each presentation of summative feedback could appear up to 3 trials before or after the end of the relevant block but with at least 17 trials between each presentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10</head><p>The test phase followed learning and was the same for all conditions. It contained 32 trials with the 16 unique exemplars each shown twice. Participants were told that the test would be similar to the learning phase, with approach/avoid decisions leading to the same points gains and losses. However, no outcome feedback was provided.</p><p>The key outcome measure was the type of categorization rule that participants used to guide approach/avoid decisions during learning and test blocks. In a given block, perfect conformity to the optimal two-dimensional rule would result in approaching all 12 friendly bees and avoiding all 4 dangerous bees (i.e., net gain of 12 points). Perfect conformity to a onedimensional rule would result in approaching 8 friendly bees and avoiding 4 dangerous and 4 friendly bees (i.e., net gain of 8 points). In a given block, participants were classified as "2D rule users" or "1D rule users" if their approach choices were consistent with the relevant rule on at least 15 out of 16 trials (30 out of 32 trials in the test phase). Participants whose choices did not satisfy either criterion were said to be using an "unclassified rule". The stimulus structure meant that there were two possible one-dimensional rules (e.g., in the <ref type="figure" target="#fig_0">Figure 1</ref> example, participants could have focused on feature values for either dimension 1 "wings" or dimension 2 "legs"). Participants using either one-dimensional rule were classified together.</p><p>Participants' explicit beliefs about which dimensions predicted category membership were assessed at the end of the test phase. Text descriptions corresponding to the four stimulus feature dimensions ("wings", "legs", "body", "antennae") were presented in random order and participants checked boxes to indicate the dimensions that they believed were most relevant to bee classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>Use of the three possible categorization rules (1D, 2D, unclassified) across learning blocks is shown for each experimental group in <ref type="figure">Figure 2A</ref>. In all groups, there was clear evidence of rule acquisition during the learning phase with the proportion of participants using 1D or 2D rules increasing from the initial block (1D: 5%, 2D: 1%) to the final block (1D: 34%, 2D: 31%), (see https://osf.io/q3v9z/ for further details of learning data).</p><p>Test phase rule use in each feedback group is summarized in <ref type="figure">Figure 3A</ref>. These data were analyzed using multinomial logistic regression where levels of summative feedback were predictors of whether participants used a 2D or a 1D categorization rule. A model that included levels of summative feedback provided a better fit to the rule use data than an intercept-only model, (χ 2 (6) = 23.435, p &lt;.001). The contribution of each level of summative feedback in predicting rule use, as compared with contingent-only feedback, is indicated by the regression coefficients (β), Wald z statistics and odds ratios shown in <ref type="table">Table 1</ref>. A learner was 3.6 times more likely to be classified as a 2D rule user than a 1D rule user when they received 5 doses of summative feedback as compared with the contingent-only group (p = .004). Lower doses of summative feedback, however, had little effect on the pattern of rule use, with no significant change in the odds of 2D versus 1D rule-use found in comparisons between the contingent only and the 1-dose (p = 0.35) or 2-dose summative conditions (p = 0.065). In the latter case, the trend was for lower odds of being classified as a 2D than a 1D rule user when summative feedback was provided. We also analyzed the effects of feedback on the odds of using an "unclassified" rule at test, as compared with a 2D or 1D rule. These analyses found no change in these odds in comparisons of each of the various summative feedback conditions with the contingent only condition (all p's &lt; 0.06).</p><p>In the final test of beliefs about the feature dimensions relevant to categorization, those in the summative 5-dose condition were more likely to correctly identify the two relevant feature dimensions (39% of participants) than those in other conditions (17 -27% of participants), χ 2 (6, N = 276) = 14.282, p = .027.</p><p>These results suggest that frequent presentation of summative feedback can reduce the prevalence of learning traps. One concern, however, is that the 5-dose condition differed from the other summative feedback conditions, both in terms of the frequency and the timing of feedback. In the summative 5-dose condition, more feedback was provided early in the learning process (after blocks 2, 3, and 4) compared with the 2-dose condition. In the 5 dose-condition more feedback was also provided late in learning (after block 6) than in either of the other dose conditions. This potential confound is concerning given that we observed that traps typically emerged relatively early in learning (88% of those who used a 1D rule at test exhibited their first use of that rule at or before the fourth learning block). Experiment 2 was designed to address this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>Categorization This study examined the effects of the timing of summative feedback on learning trap formation by presenting a relatively low dose of summative feedback (two presentations) either early or late in the learning process. Feedback timing in these 2-dose early and 2-dose late conditions matched the first two doses, and the last two doses, administered in the 5-dose summative group from Experiment 1, respectively. Rule learning was compared between the early and late conditions, and was also compared to rule use in the contingent-only and 5-dose summative groups from Experiment 1. If early exposure to feedback is the key factor driving the positive effects of summative feedback, then those in the 2-dose early condition should be more likely to learn the correct 2D rule than those in the 2-dose late or contingent-only conditions. Further, the 2-dose early condition should show a similar pattern of rule learning to the 5-dose condition. If the positive effects of summative feedback depend on frequent presentation throughout learning, however, then more optimal rule learning should be observed following 5-doses of summative feedback compared with the 2-doses early condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited 202 online participants via Amazon Mechanical Turk (79% of sample and Prolific (21% of sample) (Mage = 37.74 years; 95 females, 106 males, 1 other). Participants were randomly allocated by the program to two groups. Four participants were excluded because they took 20 or more attempts to complete the instruction comprehension check. A further 12 participants were excluded because they approached items on every learning and test trial. The resulting samples were contingent 2 dose-early (n = 95) and 2 dose-late (n = 91).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure and Materials</head><p>These were identical to the Experiment 1, except that each group received two doses of summative feedback. These were presented either relatively early in learning (after blocks 2 and 3) or late in learning (after blocks 5 and 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As shown in <ref type="figure">Figure 2B</ref>, there was again clear evidence of rule acquisition during the learning phase with the proportion of participants using 1D or 2D rules increasing from the initial (1D: 4%, 2D: 0.3%) to the final block (1D: 26%, 2D: 28%), (see https://osf.io/q3v9z/ for details).</p><p>Test phase rule use in each group is summarized in <ref type="figure">Figure 3B</ref>. We again used multinomial logistic regression to examine changes in 2D or 1D rule use as a function of summative feedback. In the first analysis, we compared test phase rule use in the 2-dose early and 2-dose late conditions. The odds of using a 2D as compared with a 1D rule did not differ significantly between these conditions (odds ratio = 1.758, p = 0.185). We also compared the new summative feedback conditions to the contingent-only feedback group from Experiment 1, as shown in <ref type="table">Table 1</ref>, lower panel. The <ref type="table">Table shows</ref> that the odds of using a 2D or 1D rule did not differ between the contingent-only and either the 2-dose early (p = .305) or 2-dose late (p = .737) summative groups. An additional regression compared changes in rule use in the new 2-dose summative conditions with the 5-dose summative condition. This analysis found that the odds of using a 2D as compared with a 1D rule were higher in the 5-dose than in either the 2-dose early (odds ratio = 2.369, p = .049) or the 2-dose late conditions (odds ratio = 4.167, p = .002; see https://osf.io/q3v9z/ for details).</p><p>In the test of beliefs about relevant features, the proportion of participants who correctly identified the two relevant feature dimensions did not differ significantly between the 2-dose early (25%) and 2-dose late (15%) conditions, χ 2 (6, N = 186) = 3.253, p = .197.</p><p>These results suggest that provision of a low dose of summative feedback, delivered either early or late in the learning process, is insufficient to alter formation of a learning trap.</p><p>It appears that regular presentation of summative feedback throughout learning is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>The current studies found that when learners received feedback about chosen but not avoided options, they often fell into learning trapsforming erroneous and persistent beliefs about the cues that predict rewards. In this respect, the current work replicates the key finding from previous work examining the formation of learning traps (e.g., <ref type="bibr" target="#b15">Li et al., 2021;</ref><ref type="bibr" target="#b16">Liquin &amp; Gopnik, 2022;</ref><ref type="bibr" target="#b19">Rich &amp; Gureckis, 2018)</ref>.</p><p>Crucially, the current work also examined whether such learning traps can be overcome when learners receive additional summative feedback which signals that current choice patterns are suboptimal. The answer to this question was a qualified "yes". When summative feedback was presented at multiple points during learning, more participants learned the optimal twodimensional categorization rule and fewer fell into a one-dimensional learning trap. This was reflected in both patterns of approach and avoidance at test and in learners' explicit beliefs about which features were relevant for categorization. Test phase performance in our summative 5-dose condition (48% of participants learned the optimal rule) was actually comparable to that of learners in previous studies who received full feedback about decision outcomes on both approach and avoid trials (e.g., using a similar paradigm, <ref type="bibr" target="#b15">Li et al., 2021</ref> found 49% of those given full feedback learned the optimal rule).</p><p>An important caveat is that the effectiveness of summative feedback was dosedependent. Exposure to summative feedback on only one or two occasions had no effect on trap formation, regardless of when it was presented during learning. Experiment 2 confirmed that the difference between the 5-dose and other summative conditions was due to the frequency rather than the timing of the summative feedback.</p><p>Frequent presentation of summative feedback improved learning of the optimal categorization rule in two ways. In the majority of individuals in the 5-dose condition who eventually learned the correct rule (24 out of a total of 32 participants), summative feedback 20 prevented learning trap formationthese individuals never used a suboptimal one-dimensional rule. For the remaining participants, frequent summative feedback facilitated escape from a trap. These individuals used a one-dimensional categorization rule at some point during learning, but eventually learned the correct conjunctive rule. These results are particularly impressive given previous failures to prevent or reverse trap formation (e.g., <ref type="bibr" target="#b19">Rich &amp; Gureckis, 2018</ref>).</p><p>The positive effects found in the summative 5-dose condition may reflect the fact that more frequent presentation of summative feedback increases the likelihood that the feedback will be attended to and acted on. However, it is also consistent with a more nuanced explanation. After becoming aware that they are using a suboptimal rule, participants need to explore previously avoided exemplars with different feature combinations, as well as learning the associations between the features of the explored options and gain/loss outcomes. Multiple instances of summative feedback could benefit each of these steps, signaling that exploration of other features may be needed and helping learners to evaluate alternative hypotheses about which features predict category membership.</p><p>The current work shows that an intermediate form of feedback, which signals that a current decision rule is suboptimal but does not provide information about the outcomes of individual decisions, can reduce the prevalence of such traps. The learning trap that was the focus of the current work is just one example of problematic patterns of learning and decisionmaking that can emerge when learners explore small or unrepresentative samples of evidence, and only receive outcome feedback about sampled options. Analogous traps have been identified in social impression formation, personnel selection, and risky decision-making (e.g., <ref type="bibr">Fazio et al., 2004;</ref><ref type="bibr" target="#b9">Harris et al., 2020;</ref><ref type="bibr" target="#b6">Le Mens &amp; Denrell, 2020</ref>). An important goal for future work is to examine whether the positive impact of repeated summative feedback can be generalized to these other learning and decision-making environments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Examples of Friendly/Dangerous Bee Stimuli and Associated Points Rewards/LossesNote. The feature combination highlighted in red shows an example of a "target" feature conjunction associated with loss. Here, the relevant dimensions are wings and legs, and irrelevant dimensions are antennae and body pattern.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Results of Multinomial Logistic Regressions Predicting Test Phase Rule Use from Level ofNote. These logistic regressions examined the prediction of the odds of classification of test phase rule use as 2D vs. 1D, as a function of each level of summative feedback as compared to the contingent-only condition. The odds ratio represents the change in the likelihood of a participant being classified as a 2D rather than a 1D rule user, as a function of each level of feedback.</figDesc><table><row><cell cols="2">B. Figure 3 Experiment 2 Table 1</cell><cell>Experiment 2</cell></row><row><cell cols="3">Rule Use During Learning Categorization Rule Use in the Test Phase</cell></row><row><cell cols="4">A. 0% 20% 40% 60% 80% 100% 2D RULE Experiment 1 B1 B2 B3 B4 B5 B6 B7 B8 Learning Block Contingent Only Unclassified 1D RULE 0% 20% 40% 60% 80% 100% B1 B2 B3 B4 B5 B6 B7 B8 Proportion Proportion of Participants of Participants Learning Block Contingent + Summative 2 dose 2D RULE Unclassified 1D RULE 0% 20% 40% 80% Contingent + 2 dose early 0% 20% 40% 60% 80% 100% B1 B2 B3 B4 B5 B6 B7 B8 Proportion of Participants Learning Block Contingent + Summative 1 dose 2D RULE Unclassified 1D RULE 0% 20% 40% 60% 80% 100% B1 B2 B3 B4 B5 B6 B7 B8 Proportion Contingent + Summative 5 dose A. Experiment 1 Feedback 100% 100% Experiment 1 Participants 90% 60% B1 B2 B3 B4 B5 B6 B7 B8 Proportion of Learning Block 2D RULE Unclassified 30% 40% 50% 60% 70% 80% Test Phase Rule Prediction Predictor (Feedback) β z p Odds Ratio 95% Confidence Interval for Odds Ratio Participants Lower Bound Upper Bound Intercept -0.300 1.035 0.309 Proportion of 20% Contingent + 1 0.391 0.859 0.354 1.479 0.647 3.381 1D RULE 60% 80% 10% dose summative 2D rule vs. 0% 1D rule Contingent + 2 -0.863 3.412 0.065 0.422 0.169 1.054 Contingent-only Summative 1-Dose Summative 2-Dose Summative 5-Dose dose summative Contingent + 2 dose late Feedback Condition Contingent + 5 1.281 8.138 0.004* 3.600 1.49 8.68 100% 2D rule Unclassified 1D rule dose summative Participants B. Experiment 2 Experiment 2 of Participants Learning Block 2D RULE Unclassified 1D RULE Note: Color figures available in on-line version 0% 20% 40% B1 B2 B3 B4 B5 B6 B7 B8 of 90% 100% Test Phase Rule Prediction Predictor (Feedback) β z p Odds Ratio 95% Confidence Interval for Odds Ratio Proportion Learning Block 2D RULE Unclassified 1D RULE 20% 30% 40% 50% 60% 70% 80% of Lower Bound Upper Bound Participants Contingent + 2 0.418 1.054 0.305 1.519 0.684 3.373 2D rule vs. 1D rule dose summative early dose summative Proportion Contingent + 2 -0.146 0.113 0.737 0.864 0.368 2.028</cell></row><row><cell>10%</cell><cell>late</cell><cell></cell></row><row><cell>0%</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Summative 2-Dose (early)</cell><cell>Summative 2-Dose (late)</cell></row><row><cell></cell><cell></cell><cell cols="2">Feedback Condition</cell></row><row><cell></cell><cell>2D rule</cell><cell>Unclassified</cell><cell>1D rule</cell></row><row><cell cols="3">Note: Color figures available in on-line version</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices Statement</head><p>All data, stimulus materials and details of statistical analyses for this paper can be found in the Open Science Framework archive https://osf.io/q3v9z/. This archive also contains links to the GitHub repository which contains jsPsych code for the two experiments. Neither experiment was pre-registered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Footnote 1</head><p>Including the excluded participants in the analyses did not alter the key results. See https://osf.io/q3v9z/ for relevant analyses.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adaptive flexibility in category learning? Young children exhibit smaller costs of selective attention than adults</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Sloutsky</surname></persName>
		</author>
		<idno type="DOI">https://psycnet.apa.org/doi/10.1037/dev0000777</idno>
		<ptr target="https://doi.org/10.1037/dev0000777" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2060" to="2076" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bidirectional influences of information sampling and concept learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Braunlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="234" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/rev0000287</idno>
		<ptr target="https://doi.org/10.1037/rev0000287" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">jsPsych: A JavaScript library for creating behavioral experiments in a web browser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>De Leeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13428-014-0458-y</idno>
		<ptr target="https://doi.org/10.3758/s13428-014-0458-y" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Why most people disapprove of me</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denrell</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.112.4.951</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.112.4.951" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="951" to="978" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Revisiting the competency trap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Le Mens</surname></persName>
		</author>
		<idno type="DOI">10.1093/icc/dtz072</idno>
		<ptr target="https://doi.org/10.1093/icc/dtz072" />
	</analytic>
	<monogr>
		<title level="j">Industrial and Corporate Change</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="183" to="205" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptation as information restriction: The hot stove effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>March</surname></persName>
		</author>
		<idno type="DOI">10.1287/orsc.12.5.523.10092</idno>
		<ptr target="http://dx.doi.org/10.1287/orsc.12.5.523.10092" />
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="523" to="538" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recommender systems and learning traps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first international workshop on decision making and recommender systems</title>
		<editor>M. Ge &amp; F. Ricci</editor>
		<meeting>the first international workshop on decision making and recommender systems</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="38" to="41" />
		</imprint>
		<respStmt>
			<orgName>Free University of Bozen-Bolzano</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Biased preferences through 22 exploitation: How initial biases are consolidated in reward-rich environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fiedler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Marien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Custers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1855" to="1877" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/xge0000754</idno>
		<ptr target="https://doi.org/10.1037/xge0000754" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Development of experience-based judgment and decision making: The role of outcome feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The routines of decision making</title>
		<editor>T. Betsch &amp; S. Haberstroh</editor>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="119" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sensitivity to hypothesis size during information search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Hendrickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perfors</surname></persName>
		</author>
		<idno type="DOI">10.1037/dec0000039</idno>
		<ptr target="https://doi.org/10.1037/dec0000039" />
	</analytic>
	<monogr>
		<title level="j">Decision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="80" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hypothesis testing in rule discovery: Strategy, structure, and content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Ha</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.15.4.59</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.15.4.59" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="596" to="604" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rational learning and information sampling: On the &quot;naivety&quot; assumption in sampling explanations of judgment biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Mens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Denrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.1037/a0023010</idno>
		<ptr target="http://dx.doi.org/10.1037/a0023010" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="379" to="392" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Can losses help attenuate learning traps?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hayes</surname></persName>
		</author>
		<ptr target="https://escholarship.org/uc/item/85z4p46m" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1201" to="1207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Children are more exploratory and learn more than adults in an approach-avoid task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Liquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2021.104940</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2021.104940" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The influence of biased exposure to forgone outcomes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Plonsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Teodorescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="407" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<idno type="DOI">10.1002/bdm.2168</idno>
		<ptr target="https://doi.org/10.1002/bdm.2168" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The limits of learning: Exploration, generalization, and the development of learning traps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000466</idno>
		<ptr target="https://doi.org/10.1037/xge0000466" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1553" to="1570" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A re-examination of probability matching and rational choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Tunney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mccarthy</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.413</idno>
		<ptr target="https://doi.org/10.1002/bdm.413" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Putting bandits into context: How function learning supports decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="927" to="943" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the decision to explore new alternatives: The coexistence of under-and over-exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.1785</idno>
		<ptr target="https://doi.org/10.1002/bdm.1785" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="123" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Combination or differentiation? Two theories of processing order in classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Inkster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Milton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cogpsych.2015.04.002</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2015.04.002" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sensitivity to shared information in social learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Buchsbaum</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.12485</idno>
		<ptr target="https://doi.org/10.1111/cogs.12485" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="168" to="187" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The effect of foregone payoffs on underweighting small probability events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yechiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.509</idno>
		<ptr target="https://doi.org/10.1002/bdm.509" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
