<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Physical Anthropomorphism (but not Gender Presentation) Influences Trust in Household Robots</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Holbrook</surname></persName>
							<email>cholbrook@ucmerced.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Cognitive and Information Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95343</postCode>
									<settlement>Merced, Merced</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Health Sciences Research Institute</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95343</postCode>
									<settlement>Merced, Merced</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umesh</forename><surname>Krishnamurthy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Cognitive and Information Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95343</postCode>
									<settlement>Merced, Merced</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">P</forename><surname>Maglio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Cognitive and Information Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95343</postCode>
									<settlement>Merced, Merced</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Management of Complex Systems</orgName>
								<orgName type="department" key="dep2">School of Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95343</postCode>
									<settlement>Merced, Merced</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Aerospace Engineering</orgName>
								<orgName type="institution">The Pennsylvania State University</orgName>
								<address>
									<postCode>16802</postCode>
									<settlement>State College</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Cognitive and Information Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>5200 N. Lake Rd</addrLine>
									<postCode>95343</postCode>
									<settlement>Merced, Merced</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Physical Anthropomorphism (but not Gender Presentation) Influences Trust in Household Robots</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>artificial intelligence</term>
					<term>human-robot interaction</term>
					<term>human-computer interaction</term>
					<term>social robotics</term>
					<term>decision-making</term>
					<term>trust</term>
					<term>anthropomorphism</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This research explores anthropomorphism and gender presentation as prospective determinants of trust in household service robots with respect to care of objects (e.g., clothing, valuables), information (e.g., online passwords, credit card numbers), and living agents (e.g., pets, children). In Experiments 1 and 2, we compared trust in a humanoid robot presenting as male, female, or gender-neutral, finding no effects of gender presentation on any trust outcome. In Experiment 3, a fourth condition depicting a physically nonhumanoid robot was added. Relative to the humanoid conditions, participants reported less willingness to trust the nonhumanoid robot to care for their objects, personal information, or vulnerable agents; the reduced trust in care for objects or information was mediated by appraisals of the nonhumanoid as less intelligent and less likable, whereas the reduced trust in care of agents was mediated by appraisals of the nonhumanoid as less likable and less alive. In a parallel pattern, across all studies, participants&apos; appraisals of robots as intelligent tracked trust in them to take care of objects or information (but not agents), whereas appraisals of robots as likable and alive tracked trust in care of agents. The results are discussed as they inform past work examining effects of gender presentation and anthropomorphism on perceptions of, and trust in, robots.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The pace of development of service robots designed for use in the home or in other nonindustrial everyday settings is accelerating <ref type="bibr" target="#b21">(Lee, 2021)</ref>. One critical design consideration for the successful deployment of service robots is the extent to which humans will trust them to perform tasks which entail risk of harm to valuables or living agents should errors be made. An extensive human factors literature has identified anthropomorphic design as an important determinant of trust <ref type="bibr" target="#b5">(Chen &amp; Barnes, 2014</ref><ref type="bibr" target="#b17">, Hoff &amp; Bashir, 2015</ref><ref type="bibr" target="#b6">Chiou &amp; Lee, 2021;</ref><ref type="bibr" target="#b9">Deng, Mutlu &amp; Mataric, 2019)</ref>, which may be defined as the attitude that an agent will help one to achieve objectives under circumstances characterized by uncertainty and vulnerability <ref type="bibr" target="#b22">(Lee &amp; See, 2004)</ref>.</p><p>Anthropomorphic cues suggestive of interpersonal engagement, such as emotional expressiveness, eye gaze, and vocal variability, have been found to increase trust in social robots <ref type="bibr" target="#b25">(Mutlu, 2011;</ref><ref type="bibr">DeGraaf &amp; Allouch, 2013;</ref><ref type="bibr" target="#b20">Kuhnert, Ragni &amp; Lindner, 2017;</ref><ref type="bibr" target="#b33">Ruhland et al., 2015)</ref>. Indeed, robots exhibiting social cues such as gestures or facial expressions have been appraised as comparably trustworthy to human interaction partners <ref type="bibr" target="#b10">(DeSteno, Breazeal, Frank, Pizarro, Baumann, Dickens &amp; Lee, 2012)</ref>.</p><p>Gender constructs are a fundamental aspect of anthropomorphism. Concepts of femininity and masculinity are traditional social constructs associated with binary understandings of biological sex which remain culturally pervasive despite being scientifically oversimplified <ref type="bibr" target="#b11">(DuBois &amp; Shattuck-Heidorn, 2021)</ref>. Gender constructs organize social relationships-in varying ways and to varying degrees-across human societies <ref type="bibr" target="#b23">(Lew-Levy, Lavi, Reckin, Crist√≥bal-Azkarate, &amp; Ellis-Davies, 2018)</ref>. Natural selection likely favored the evolution of psychological mechanisms that categorize individuals by sex in order to facilitate inferences about highly fitness-relevant social considerations such compatibility for mating and parenting, in addition to inferences about individuals' likely aptitude and tendencies to engage in activities that may be gendered to a relevant extent in the society in which a human develops (e.g., potential cultural constructs linking gender roles with foraging, fighting, or leadership). Indeed, experiments in cognitive psychology reveal a robust, automatic categorization of individuals according to gender <ref type="bibr" target="#b28">(Pietraszewski, Cosmides, &amp; Tooby, 2014)</ref>. Accordingly, to the extent that they evoke human gender constructs, artificial agent designs incorporating gendered presentation may influence trust with regard to socially gendered task domains (e.g., the association between childcare roles and femininity) <ref type="bibr" target="#b2">(Bernotat, Eyssel, &amp; Sachse, 2021;</ref><ref type="bibr" target="#b35">Tay, Jung &amp; Park, 2014</ref><ref type="bibr">, Eysell &amp; Hegel, 2012</ref><ref type="bibr" target="#b19">Kuchenbrandt et al., 2014;</ref><ref type="bibr" target="#b30">Reich-Stiebert &amp; Eyssel, 2017)</ref>. Here, we examine gender presentation, as well as overall physical anthropomorphism, as prospective determinants of trust in robots with respect to care of household objects (e.g., clothing, valuables), living agents (e.g., pets, children), and information (e.g., online passwords, credit card numbers).</p><p>Prior human-robot interaction (HRI) research has obtained mixed results with regard to effects of gender presentation on trust. In a field study at a science museum, <ref type="bibr" target="#b34">Siegel, Breazeal, and Norton (2009)</ref> assigned a humanoid robot either a masculine or feminine voice, finding that men rated the female-presenting robot as more credible and trustworthy than the male-presenting robot, whereas the reverse pattern obtained (to a weaker degree) in women, who rated the malepresenting robot as slightly more credible and trustworthy than the female-presenting robot. In a later study, this time manipulating gender according to the voice and name assigned to the robot <ref type="bibr" target="#b1">(Alexander et al., 2014)</ref>, participants once again exhibited preferences for the robot of opposite apparent gender to their own. On the other hand, <ref type="bibr">Ghazali and colleagues (2018)</ref> found that participants experienced more negative thoughts and feelings when interacting with a robot portraying the opposite gender to themselves during a game task in which the robot attempted to influence their decisions using forceful language, with no effects of participant gender or the robot's gender presentation on trust. Similarly, <ref type="bibr">Rogers, Bryant and Howard (2020)</ref> found that attributions of gender to a humanoid robot did not significantly impact assessments of the robot's competency to perform various service tasks, although this study's experimental manipulation of gender may have been weak given that participants in a substantial number of cases reported perceiving the robot as corresponding to a gender identity other than the condition to which they had been assigned. Finally, a recent meta-analysis examining effects of robot gender presentation on HRI in studies published between 2005 and 2021 found no reliable impact on assessments of robots' competence, likability, or acceptability <ref type="bibr" target="#b27">(Perugia &amp; Lisy, 2023)</ref>.</p><p>The mixed effects of gender presentation on trust in robots may reflect the social contexts and/or focal tasks under which trust is gauged, such that relationships between gender and trust are more evident in task domains characterized by salient gender stereotypes. For example, <ref type="bibr" target="#b13">Eyssel and Hegel (2012)</ref> found that participants judged a female-presenting robot to be more well-suited to perform stereotypically feminine tasks (e.g., childcare, household maintenance), whereas a male-presenting robot was judged more well-suited to perform stereotypically masculine tasks (e.g., repairing equipment). In a complementary finding, <ref type="bibr">Carpenter and colleagues (2009)</ref> found that participants preferred a female-presenting, highly anthropomorphic humanoid (e.g., equipped with human facial features, skin and hair) to perform tasks such as cleaning or washing dishes inside their homes relative to a non-gendered, less anthropomorphic humanoid (e.g., covered in metal, lacking humanlike facial features). Likewise, <ref type="bibr" target="#b35">Tay, Jung, and Park (2014)</ref> similarly observed that gender presentation (manipulated via synthetic voice and gendered names: "John" versus "Joan") led participants in a laboratory study to accept a masculine-seeming robot over a feminine-seeming robot to perform household security tasks, (e.g., monitoring for intruders), but to accept a feminine-seeming robot to perform healthcare tasks. In another study supporting a link between gender presentation and trust to perform gender-aligned tasks, a robot assigned a feminine body shape (i.e., based on waist-to-hip ratio and shoulder width) was preferred for stereotypically female tasks over a robot with a typically male body shape, although the two robots were perceived as equally suitable to perform stereotypically male tasks <ref type="bibr" target="#b2">(Bernotat, Eyssel &amp; Sachse, 2021)</ref>. A recent meta-analysis likewise found that manipulations of robot gender-presentation are most successful at eliciting stereotypical biases in perceptions of their suitability to perform gendered tasks <ref type="bibr" target="#b27">(Perugia &amp; Lisy, 2023)</ref>. In summary, a body of findings indicates that trust in robots may be moderated by whether gender stereotypes associated with particular tasks align or diverge from the gender with which the robot presents.</p><p>Against the above pattern of findings, however, a study examining effects of the genderpronouns assigned a small humanoid robot (NAO; Gelin, 2017) on its perceived suitability for stereotypically gendered tasks (e.g., housework, physical labor) revealed no effects <ref type="bibr" target="#b29">(Rea, Wang, &amp; Young, 2015)</ref>, although these null results may be explained by the weakness of the manipulation, as the robot was neither made to appear or sound gendered, and as a miniature robot would presumably be ill-suited to the gendered tasks that were used. A study which utilized stronger methods, manipulating gender in terms of the name and voice of a larger humanoid presumably more capable of performing physical work (Pepper; <ref type="bibr" target="#b26">Pandey &amp; Gelin, 2018)</ref>, similarly observed no effects of gender-presentation on appraisals of trustworthiness or competency to perform gendered tasks <ref type="bibr" target="#b3">(Bryant, Borenstein, &amp; Howard, 2020)</ref>. These null results render the empirical picture, with regard to both effects of gender-presentation and interactions between robot gender and confidence in robots' ability to perform stereotypically gendered tasks, as mixed at best. Some null results may owe to the relatively anemic manipulations of gender used in prior work (e.g., subtle shifts in pronouns or names without distinctly gendered visual designs), as well as reliance on robots that realistically could not perform key service tasks (e.g., due to their small size or limitations in their physical affordances), such as the NAO, Furhat, or Robovie <ref type="bibr" target="#b27">(Perugia &amp; Lisy, 2023)</ref>. We therefore conducted three pre-registered experiments with an adult-sized humanoid robot programmed with clearly gendered faces and voices in order to provide a stronger test of the extent to which manipulations of gender presentation influence trust across distinct task domains varying in gender-associations (e.g., stereotypically feminine tasks such as childcare versus less gendered tasks such as managing vital personal information). In Experiments 1 and 2, we compared trust in a humanoid robot configured to present with a masculine face and voice, a feminine face and voice, or as a gender-neutral persona with no facial features and a synthetic-sounding voice. Accordingly, the latter condition constituted both a non-gendered and a less anthropomorphic presentation of the humanoid robot. In Experiment 3, we added a nonhumanoid robot condition to provide a clearer contrast in physical anthropomorphism. Taken together, these three studies test both the potential impact of gender presentation and of degree of physical anthropomorphism on trust.</p><p>In each study, we also measured the extent to which participants appraised the robot as intelligent and as likable, because trustworthiness has been conceptualized as rooted in corresponding perceptions of ability (i.e., task-competence presumably related to intelligence) and benevolence (i.e., desire to help presumably related affiliative likability) <ref type="bibr" target="#b24">(Mayer, Davis &amp; Schoorman, 1995)</ref>. We therefore expected ratings of robot trustworthiness to correspond with appraisals of both intelligence and likability. Some prior research also suggests that, in line with human gender stereotypes, robots designed to present as masculine are appraised as relatively high in ability whereas robots presenting as feminine are appraised as relatively high in benevolence (e.g., <ref type="bibr" target="#b13">Eyssel &amp; Hegel, 2012)</ref>, although other investigators have failed to observe these contrasts (e.g., <ref type="bibr" target="#b3">Bryant, Borenstein, &amp; Howard, 2020)</ref>; we sought to retest these claims here, using a robot platform capable of presenting unambiguously gendered, adult-sized humanoids.</p><p>For exploratory reasons, because the agents in question in this context of trust assessment are artificial, we also assessed appraisals of the robots as alive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predictions and Exploratory tests</head><p>The design allowed us to test a number of potential effects of gender presentation and anthropomorphism:</p><p>1. Gender presentation. The female persona may be rated as more trustworthy with regard to care of vulnerable agents relative to the other robot conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Anthropomorphism.</head><p>a. The faceless, less anthropomorphic humanoid may be rated as less trustworthy than the gender-presenting humanoids. b. The faceless, less anthropomorphic humanoid may be rated as less intelligent or likable than the gender-presenting humanoids.</p><p>c. The Nonhumanoid may be rated as less trustworthy than the humanoids (tested in Experiment 3).</p><p>d. The Nonhumanoid may be rated as less intelligent or likable than the humanoids (tested in Experiment 3).</p><p>3. Appraisals and trust. The extent to which participants trust (across domains) will be positively associated with appraisals of the robots as likable and intelligent.</p><p>In addition, we also explored whether trust in the three domains would be relatively more or less associated with appraisals of intelligence relative to appraisals of interpersonal likability or "aliveness" when entered as simultaneous predictors.</p><p>The pre-registrations, full materials, videos depicting all robot conditions, and the datasets for all experiments are publicly archived (see https://osf.io/378rq/). All studies were approved by the University of California, Merced, Institutional Review Board, informed consent was obtained prior to participation, and all methods were in accord with relevant guidelines and regulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>We targeted a sample size of 500, recruited via Amazon Mechanical Turk (500 + completed assignments, 99% approval, located in the USA) in exchange for U.S. $0.65 in the Fall of 2020. Data were prescreened for providing complete responses, answering a 'catch question,' watching the entire robot video (based on a page timer) and technical problems with video streaming reported by participants. The final sample consisted of 474 participants (47.9% female, Mage = 39.82 years, SD = 13.09).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>In a between-subjects design, a humanoid robot was presented with either a male face, voice and name (the Masculine condition, N = 158), a female face, voice and name (the Feminine condition, N = 163), or as faceless, nameless and using an artificial-sounding voice (the Less Anthropomorphic condition N = 153; see <ref type="bibr">Figure 1,</ref><ref type="bibr">top)</ref>. The humanoid was equipped with an actuated torso, legs, arms, hands and fingers (RoboThespian; Engineered Arts, n.d.a), and a head unit capable of rich variation in facial characteristics and expressiveness using a rearprojected face (Socibot; Engineered Arts, n.d.b). The robot introduced itself in a 35s video as a "household robot" which could be integrated into participants' homes "to perform a wide variety of tasks, including cleaning, cooking, home security and babysitting". The video was edited to resemble a promotional film, and included both facial closeups and shots highlighting its humanoid body shape and movement capacities (e.g., gesture). The Masculine robot identified itself as "Graham", the Feminine robot identified itself as "Rachel" (corresponding to the names assigned their synthesized voices; Acapela <ref type="bibr">Group, n.d.)</ref> , and the Less Anthropomorphic robot did not identify itself by name.</p><p>After watching the video, participants were asked to report their degree of willingness to trust the robot to perform five household tasks involving objects (i.e., cleaning, doing laundry, watering plants, cooking, handling valuables; composited as a measure of Trust in Care of Objects, Œ± = .87) or to provide care to five different types of living agents (i.e., pets, elderly people, teenagers, young children, infants; composited as a measure of Trust in Care of Agents, Œ± = .90). (A redundant measure probing trust to physically carry objects / agents was also included, see Supplementary Material for details.)</p><p>Participants were also asked to rate their appraisals of the robot's likability ("The robot seems friendly", "I like this robot"; r = .71), intelligence ("The robot seems intelligent", "The robot seems responsible"; r = .74) and aliveness ("The robot seems conscious", "The robot seems alive"; r = .83). The trust and appraisal items (randomized) were presented in separate blocks (randomized). All of the above ratings were produced using the same 7-point Likert scale (1 = Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither agree nor disagree, 5 <ref type="figure">Figure 1</ref>. Top: Humanoid "household" robots (RoboThespian with Socibot head unit), presenting with either a masculine face, name and voice (top left), a feminine face, name and voice (top middle), or faceless, nameless and equipped with a gender-neutral synthetic-sounding voice (top right). Bottom left: The humanoid robots (masculine persona shown here) were depicted producing humanlike gestures, facial expressions and postural shifts. Bottom right: Nonhumanoid "household" robot added as a fourth condition for Experiment 3, and depicted producing non-anthropomorphic movements of its base, appendages and grippers (modified Turtlebot). Due to the dark background, the hands and grippers depicted in still images are difficult to see, but were clearly visible in the videos (see Supplementary Material for links.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Preliminary analyses revealed no significant effects of participant gender, nor interactions between participant gender and robot condition, on any of the trust or appraisal outcomes. Accordingly, participant gender was not included in subsequent analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Null Effects of Robot Condition on Trust in Care of Objects or Agents</head><p>Against Predictions 1 and 2a, we observed no main effects of robot condition, ps .379 -.751, nor did post hoc contrasts reveal any significant differences between robot conditions, ps .187 -.799, on either Trust in Care of Objects or Trust in Care of Agents. Instead, on average, participants evinced a moderate degree of willingness to trust any of the three humanoid robots to care for valuable objects (see <ref type="bibr">Figure 2)</ref>, and a relatively low degree of willingness to trust any of the three humanoid robots to care for vulnerable agents (see <ref type="figure" target="#fig_4">Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Null Effects of Robot Condition on Appraisals of Likability, Intelligence, or Aliveness</head><p>We observed a significant main effect of the robot manipulation on appraisals of Aliveness, F(2, 471) = 4.54, p = .011, Œ∑p 2 = .02, and simple comparisons revealed that the Masculine robot was appraised to be more Alive than the Less Anthropomorphic robot, p = .003, 95% CI [.21, 1.00]. Against Prediction 2b, analyses of variance revealed no other significant effects of robot condition on appraisals of Likability, Intelligence, or Aliveness, ps .115-.852.</p><p>Instead, on average, participants appraised the three humanoid robots as comparably high in all three dimensions (see <ref type="table" target="#tab_0">Table 1</ref> for descriptives).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asymmetric Associations between Appraisal Dimensions and Trust Categories</head><p>Pearson's correlations revealed that the three trust and the three appraisal dimensions were all moderately positively associated rs .47 -.64, ps &lt; .001. We next conducted a series of simultaneous linear regressions including covarying appraisals of Likability, Intelligence, and of Agents in the model, p = .218.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Against predictions, we observed no effects of either the manipulation of gender presentation, or relative anthropomorphism, on either trust outcome. Similarly, we found no effects of condition on appraisals of Likability or Intelligence, although there was a modest significant contrast between the perceived Aliveness of the Masculine robot relative to the Less Anthropomorphic robot. Consistent with predictions, we found that appraisals of Likability and Intelligence, as well as Aliveness, were positively correlated with Trust in Care of both Objects and Agents. Strikingly, regression analyses revealed that trust in robots to care for Objects was positively associated with appraisals of their Intelligence (but not Likability or Aliveness), whereas trust in robots to care for vulnerable Agents was positively associated with appraisals of robot Likability and Aliveness (but not Intelligence). This pattern is consistent with claims that social robots activate intuitive social schemas, here, for example, linking perceived affiliative likability with traits associated with rendering care to living creatures and people, such as interpersonal warmth and compassion. In prior research, likability has similarly been shown to track trust in robots <ref type="bibr" target="#b15">(Ghazali et al., 2018)</ref>. But from an objective standpoint, likability and seeming aliveness appear mostly irrelevant to considerations of whether a machine can provide adequate care to pets, children, or the elderly. Notwithstanding the value of such appealing characteristics to enhancing the experiences of those being cared for (e.g., they may find affable robot caregivers more appealing), arguably the most critical capacity that should be desired in a caregiver is the capacity to respond intelligently and responsibly to circumstances. Yet here we observed that appraisals of Intelligencewhich, notably, was measured using the term "responsible" as well as "intelligent"did not drive trust in robots to care for agents, but instead predicted trust in the care of objects.</p><p>We next sought to replicate and to extend these findings in two ways. First, given the unexpected absence of effects of the gender and anthropomorphism manipulation, we added a measure of the robot's nurturing qualities, as gender stereotypes broadly associate femininity with nurturance <ref type="bibr" target="#b12">(Ellemers, 2018)</ref>. In this way, Experiment 2 provides a stronger test of whether the gendered presentation of the humanoid robot can cause participants to attribute gendered human social qualities to the robot (i.e., less nurturing qualities appraised in the Masculine condition than in the Feminine condition). Second, we added a domain of trust which would be unconfounded by differences in physical task demands, as, in addition to differing in what or whom is cared for, Trust in Care of Objects versus Agents may be imagined as requiring differing physical capacities. We therefore asked participants to assess the trustworthiness of the robot to care for their sensitive personal information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>We again targeted a sample size of 500, recruited via Amazon Mechanical Turk (500 + completed assignments, 99% approval, located in the USA) in exchange for U.S. $0.65 in the winter of 2020. Data were prescreened as in Experiment 1. The final sample consisted of 481 participants (58.8% female, Mage = 39.39 years, SD = 12.06).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>The between-subjects design mirrored Experiment 1 (Masculine condition, N = 165;</p><p>Feminine condition, N = 159; Less Anthropomorphic condition N = 157), with participants once again rating their degree of willingness to trust the robot to Trust in Care of Objects (Œ± = .89), or Trust in Care of Agents (Œ± = .92). In addition, participants were asked to report their willingness to Trust in Care of Information (i.e., bank account information, credit and debit card numbers, online passwords, social security numbers, healthcare-related information, passport and/or driver's license information, Œ± = .97). As in Experiment 1, participants were also again asked to rate their appraisals of the robot's Likability (r = .69), Intelligence (r = .68) and Aliveness (r = .74). In addition, we solicited participants' appraisals of the robot's Nurturant qualities (i.e., "The robot seems nurturing", "The robot seems warm", r = .77; see Supplementary Material for additional exploratory measures of assertiveness). The trust and appraisal items <ref type="bibr">(randomized)</ref> were again presented in separate blocks (randomized), and rated using the same 7-point Likert scale as previously. Finally, participants completed demographic questions, including an attention check, before being thanked and debriefed. We also added exploratory measures of i) sympathy toward the robot, and ii) individual differences in perceptions of the reliability of automated systems to Experiments 2 and 3 (see Supplementary Material for details and analyses).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Preliminary analyses revealed no significant effects of participant gender, nor interactions between participant gender and robot condition, on any of the trust or appraisal outcomes. Accordingly, participant gender was not included in subsequent analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Null Effects of Robot Condition on Trust in Care of Objects, Agents or Information</head><p>Against Predictions 1 and 2a, we again observed no main effects of robot condition, ps .146 -.847, nor did post hoc contrasts reveal any significant differences between robot conditions, ps .050 -.900, on Trust in Care of Objects, Trust in Care of Agents, or Trust in Care of Information. Instead, on average, participants evinced a moderate degree of willingness to trust any of the three humanoid robots to care for valuable objects <ref type="bibr">(Figure 2)</ref> or information <ref type="bibr">(Figure 4)</ref>, and, as in Experiment 1, a relatively low degree of willingness to trust any of the three humanoid robots to care for vulnerable agents <ref type="figure" target="#fig_4">(Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Null Effects of Robot Condition on Appraisals of Likability, Intelligence, Aliveness, Nurturance</head><p>Against Prediction 2b, and departing from the small effect with respect to appraisals of Aliveness observed in Experiment 1, we observed no significant main effects of the robot manipulation on appraisals of Likability, Intelligence, Aliveness, or Nurturance, ps .505 -.836, nor were there any significant contrasts between any of the robot conditions, ps .244 -.996 Instead, on average, participants appraised the three humanoid robots as comparably moderate in all three dimensions, in a pattern closely replicating that of Experiment 1 (see <ref type="table" target="#tab_0">Table 1</ref> for descriptives).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asymmetric Associations between Appraisal Dimensions and Trust Categories</head><p>Pearson's correlations revealed that the trust and the appraisal dimensions were again all moderately positively associated, rs .41 -.61, ps &lt; .001. We next conducted a series of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>As in Experiment 1, we again observed no effects of robot condition on any trust outcome. Similarly, against expectations, we found no effects of condition on appraisals of Likability, Intelligence, Aliveness, or Nurturance, the latter of which we had anticipated to be influenced by our manipulation of the robot's gender presentation. Consistent with predictions, and as in Experiment 1, we observed patterns of asymmetric association between appraisal dimensions and trust domains. As in the prior study, regression analyses revealed that trust in robots to care for vulnerable Agents was positively associated with appraisals of their Likability and Aliveness (but not Intelligence). Somewhat replicating the prior pattern, trust in robots to care for Objects was positively associated with appraisals of their Intelligence (but not Aliveness), although in Experiment 2 Likability was also associated albeit to a lesser degree than Intelligence. In a similar pattern, appraisals of the robot as Intelligent and as Likable (but not as alive) equivalently predicted respect to Trust in the Care of Information. In sum, Experiment 2 provided additional support for the hypothesis that trust across contexts is sensitive to thematically associated social qualities evoked by robots, such that perceptions of an agent as benevolently friendly and alive engender greater willingness to trust them to care for vulnerable agents than do perceptions of competent intelligence, which are more associated with willingness to care for physical objects or sensitive personal data.</p><p>In addition to testing prior claims regarding robot gender presentation, Experiments 1 and 2 were also intended to test potential related effects of anthropomorphism. However, these studies were limited insofar as we did not manipulate anthropomorphism in an unambiguous manner, but rather with the faceless humanoid in the Less Anthropomorphic condition.</p><p>Therefore, in Experiment 3 we added a nonhumanoid robot condition. The addition of this nonhumanoid condition allowed us to test Predictions 2c and 2d, with respect to effects of anthropomorphism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>We again targeted a sample size of 500, recruited via Amazon Mechanical Turk (500 + completed assignments, 99% approval, located in the USA) in exchange for U.S. $0.65 in the Spring of 2021. Data were prescreened as before, yielding a final sample of 463 participants (47.1% female, Mage = 42.92 years, SD = 13.14). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Departing from the results of Experiments 1 and 2, preliminary analyses revealed significant effects of participant gender as well as interactions between gender and robot condition. Accordingly, participant gender was included in the subsequent analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Robot Condition and Participant Gender on Trust in Care of Objects, Agents and Information</head><p>We conducted analyses of variance including gender as a covariate. Against Predictions 1 and 2a, and as in Experiments 1 and 2, planned contrasts again revealed no significant differences between the humanoid robot conditions, ps .249 -.964, on Trust in Care of Objects (see <ref type="figure">Figure 2</ref>), Trust in Care of Agents (see <ref type="figure" target="#fig_4">Figure 3</ref>), or Trust in Care of Information (see <ref type="figure" target="#fig_5">Figure   4</ref>). Instead, on average, participants again evinced a moderate degree of willingness to trust any of the three humanoid robots to care for valuable objects or information, and, as in Experiments 1 and 2, a relatively low degree of willingness to trust any of the three humanoid robots to care for vulnerable agents.</p><p>In support of Prediction 2c, the Nonhumanoid was rated less trustworthy with regard to Care of Objects than the Masculine humanoid, p = .001, 95% CI <ref type="bibr">[-1.02, -.25]</ref>, the Feminine humanoid, p &lt; .001, 95% CI <ref type="bibr">[-1.23, -.45]</ref>, or the Less Anthropomorphic humanoid, p &lt; .001, 95% CI <ref type="bibr">[-1.25, -.47]</ref> (see <ref type="bibr">Figure 2)</ref>. A similar pattern was obtained with regards to Trust in Care of Agents (see <ref type="figure" target="#fig_4">Figure 3)</ref>, such that the Nonhumanoid was rated less trustworthy than the Feminine humanoid, p = .024, 95% CI <ref type="bibr">[-.90, -.06]</ref>, or the Less Anthropomorphic humanoid, p = .046, 95% CI [-.85, -.01], although not significantly less trustworthy than the Masculine humanoid, p = .074, 95% CI <ref type="bibr">[-.79, .04]</ref>. Finally, the Nonhumanoid was rated less trustworthy with regard to Care of Information than the Masculine humanoid, p = .014, 95% CI [-1.13, -.13], the Feminine humanoid, p = .031, 95% CI [-1.07, -.05], or the Less Anthropomorphic humanoid, p = .036, 95% CI [-1.06, -.04] (see <ref type="bibr">Figure 4)</ref>.   The Nonhumanoid robot added in Experiment 3 is less trusted to care for information. The violin plot outlines illustrate kernel probability density; the width of the shaded areas represents the proportion of data located there, and the circles indicate the means (see text for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Robot Condition and Participant Gender on Appraisals of Likability, Intelligence, Aliveness, and Nurturance</head><p>We conducted analyses of variance, including gender as a covariate, on participants' appraisals of the robots. Against Prediction 2b, and as previously, planned contrasts revealed no significant differences between the humanoid robot conditions, ps .079 -.980, on appraisals of Likability, Intelligence, Aliveness, or Nurturance. Instead, on average, participants appraised the three humanoid robots as comparably moderate in all four dimensions (see <ref type="table" target="#tab_0">Table 1</ref> for descriptives).</p><p>In support of Prediction 2d, the Nonhumanoid was rated less Likable than the Masculine humanoid, p = .006, 95% CI <ref type="bibr">[-1.02, -.17]</ref>, the Feminine humanoid, p = .013, 95% CI <ref type="bibr">[-.97, -.12]</ref>, or the Less Anthropomorphic humanoid, p = .019, 95% CI [-.95, -.09], less Intelligent than the Masculine humanoid, p = .006, 95% CI <ref type="bibr">[-.91, -.16]</ref>, the Feminine humanoid, p = .014, 95% CI <ref type="bibr">[-.86, -.10]</ref>, or the Less Anthropomorphic humanoid, p = .016, 95% CI <ref type="bibr">[-.86, -.09]</ref>, less Alive than the Masculine humanoid, p = .010, 95% CI [-1.04, -.14], the Feminine humanoid, p = .004, 95%</p><p>CI <ref type="bibr">[-1.16, -.22]</ref>, or the Less Anthropomorphic humanoid, p = .032, 95% CI <ref type="bibr">[-.98, -.04]</ref>, and less Nurturant than the Masculine humanoid, p = .010, 95% CI [-1.04, -.14], the Feminine humanoid, p = .004, 95% CI <ref type="bibr">[-1.12, -.21]</ref>, or the Less Anthropomorphic humanoid, p = .039, 95% CI [-.94, -</p><p>.02] (see <ref type="table" target="#tab_0">Table 1</ref> for descriptives).</p><p>With respect to participant gender, we observed a main effect of participant gender on appraisals of robot Intelligence, F(1, 455) = 4.06, p = .045. Relative to male participants, women rated the robots (combining conditions) as slightly higher in Intelligence (Mwomen = 5.03, SD = 1.46; Mmen = 4.75, SD = 1.51). We also observed a significant interaction between participant gender and robot condition on appraisals of robot Aliveness, F(1, 455) = 2.99, p = .031. This interaction appears to have been driven by effects of participant gender on appraisals of the Aliveness of the Feminine humanoid (Mwomen = 4.33, SD = 1.86; Mmen = 3.66, SD = 1.82) and the Less Anthropomorphic humanoid (Mwomen = 4.22, SD = 1.76; Mmen = 3.41, SD = 1.83), as women rated both of these robots as seeming more alive than did men, whereas women rated the Masculine humanoid (Mwomen = 4.04, SD = 1.87; Mmen = 4.38, SD = 1.62) and the Nonhumanoid (Mwomen = 3.20, SD = 1.66; Mmen = 3.37, SD = 1.93), as slightly less alive-seeming than did men.</p><p>We observed no other significant effects of participant gender, nor interactions with robot condition, on appraisals of the robots' qualities, ps .093 -.882. Humanoid, 2 = Nonhumanoid). In each model, we entered this dichotomous robot condition as the independent variable, appraisals of Likability, Intelligence, and Aliveness as potential mediators, and the relevant trust outcome as the dependent variable (see <ref type="bibr">Figure 5</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Asymmetric Associations between Appraisal Dimensions and Trust Categories</head><p>We next sought, as in Experiments 1 and 2, to assess the extent to which Trust in Care of Objects, Agents or Information was driven by thematically distinct appraisals. Given the significant effects of the nonanthropomorphic condition relative to the humanoid conditions on trust and appraisal outcomes, we first tested whether the associations between appraisals of Likability, Intelligence, or Aliveness and the three trust outcomes were moderated by the Humanoid-versus-Nonhumanoid robot condition. We entered Humanoid-versus-Nonhumanoid condition, (standardized) appraisals of Likability, Intelligence, and Aliveness, and the interactions between each appraisal and the Humanoid-versus-Nonhumanoid condition as potential predictors in a series of regression models using Trust in Care of Objects, Agents, and Information as the outcome variables. We observed no interactions between the Humanoidversus-Nonhumanoid condition and any of the three appraisals on any of the three trust outcomes, ps .633 -.997, and therefore pooled all four robot conditions for subsequent regressions.</p><p>Pearson's correlations revealed that the trust and the appraisal dimensions were again all moderately positively associated, rs .40 -.68, ps &lt; .001. We next conducted a series of  The finding that the Nonhumanoid was less trusted to care for information, a task which does not require apparent physical abilities, merits attention given the likelihood that participants may have attributed greater physical abilities to humanoid robots depicted with articulable hands and limbs, relative to a nonhumanoid depicted with appendages and grippers. The comparability of the effect of the Nonhumanoid manipulation in lowering trust across domains suggests that the anthropomorphic appearance influences assessments of robots' psychological attributes in ways that affect trust beyond considerations of potential physical limitations.</p><p>In a main effect of gender unqualified by interactions with the distinct robot conditions, women evinced less trust in robots to care for vulnerable agents, despite appraising them as more intelligent relative to men. As this effect of gender was not observed in the prior two experiments, it should be treated with great caution. Tentatively, however, this pattern might be taken as further indicating that appraisals of Intelligence are orthogonal to participants' intuitions regarding the desirable qualities of a machine caretaker / nanny. In a significant interaction between robot condition and gender, women also rated the Feminine and Less Anthropomorphic humanoids as more Alive, while rating the Masculine humanoid and Nonhumanoid as less Alive.</p><p>This apparent pattern of bias wherein women [men] favored a female-presenting humanoid as more <ref type="bibr">[less]</ref> alive-seeming should be replicated before attempting further interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Across three experiments, we explored potential effects of both feminine versus masculine gender presentation and relative anthropomorphism on trust in household service robots. We manipulated anthropomorphism by presenting, in contrast to the gendered humanoids, a faceless humanoid robot with a synthetic-sounding, non-gendered voice in the first two experiments, as well as with an additional nonhumanoid robot using the same syntheticsounding voice in Experiment 3. Broadly consonant with prior work linking anthropomorphism to trust, we observed significantly less trust in the nonhumanoid relative to any of the three humanoids. However, against prior literature reporting effects of gender presentation (e.g., <ref type="bibr" target="#b13">Eyssel &amp; Hegel, 2012;</ref><ref type="bibr" target="#b2">Bernotat, Eyssel &amp; Sachse, 2021;</ref><ref type="bibr" target="#b27">Perugia &amp; Lisy, 2023)</ref>, we found no consistent patterns of difference between the masculine and feminine humanoids with regard to trust or appraisal outcomes, regardless of face-valid thematic links between the trust domains or appraisal dimensions and human gender stereotypes (e.g., linking femininity with trust in care of vulnerable agents or appraisals of nurturance). Similarly contradicting prior reports (e.g., <ref type="bibr" target="#b34">Siegel, Breazeal &amp; Norton, 2009;</ref><ref type="bibr" target="#b1">Alexander et al., 2014;</ref><ref type="bibr" target="#b2">Bernotat, Eyssel &amp; Sachse, 2021)</ref>, we observed no effects of participant gender, nor interactions between participant gender and gendered robot condition, on either trust in the gendered humanoids or appraisals of their likability or intelligence. On the one hand, the present null effects of both participant gender and robot gender presentation call prior reports into question as either limited in their generalizability or flukes.</p><p>On the other hand, our reliance on online viewing of robots via video rather than in person or in direct interaction raises the plausible possibility that some of the non-replicated prior observations were contingent on physical presence, interaction, or both (e.g., <ref type="bibr" target="#b34">Siegel, Breazeal &amp; Norton, 2009;</ref><ref type="bibr" target="#b35">Tay, Jung &amp; Park, 2014;</ref><ref type="bibr" target="#b30">Reich-Stiebert &amp; Eyssel, 2017)</ref>. In addition, to our knowledge, no prior studies examining effects of gender presentation have utilized humanoid robots equipped with highly human faces, raising the possibility that effects of gender presentation of the sort reported in prior literature can be obscured when robots are relatively high in anthropomorphism.</p><p>Although we did not observe interactions between participant gender and the gender with which the humanoids presented, we did observe a main effect of participant gender applicable across robot conditions. In Experiment 3, we found that women, relative to men, evinced less trust in household robots to care for vulnerable agents. However, although this result accords with both folk intuitions and prior literature attributing greater concern for the welfare of children to women (e.g., <ref type="bibr" target="#b18">Kroska, 2003)</ref>, the temptation to draw such conclusions should be tempered given that no effect of gender on trust in care of agents was obtained in either Experiments 1 or 2, nor did other prior researchers <ref type="bibr" target="#b15">(Ghazali et al., 2018;</ref><ref type="bibr" target="#b3">Bryant et al., 2020;</ref><ref type="bibr" target="#b29">Rea et al., 2015)</ref> find effects of gender on trust in gendered robots. Similarly, the effects of gender on appraisals of robot intelligence and seeming aliveness obtained in Experiment 3 should be treated with skepticism given that they were neither anticipated on theoretical grounds nor observed in the two prior studies.</p><p>As <ref type="figure" target="#fig_5">Figures 2-4</ref> show, we obtained considerable variation in participant's willingness to trust across domains, with participants reporting, on average, moderate trust in the robot to care for objects (just above the midpoint anchor of 'neither agree nor disagree'), or information (just below the midpoint anchor), and more skepticism regarding trust in the care of agents (midway between 'disagree' and 'somewhat disagree'). Future investigations should attempt to illuminate the individual differences driving the notable degree of variation, plausibly including determinants related to attitudes toward automation, familiarity with engineering and technology, and, as explored in the present studies, appraisals of the robots in question. In all three experiments, models using our face-valid measures of apparent intelligence, likability, and aliveness as predictors of trust outcomes evinced relatively good fit with the data, explaining between 18% and 49% of the variation. Future work either refining the way these constructs are measured or adding additional predictors, possibly including implicit or physiological responses to artificial agents rather than relying on self-report as here, may help to account for the considerable remaining variance.</p><p>Across all experiments, we obtained robustly consistent patterns of association between trust in specific domains and thematically related appraisals of the robots' qualities.</p><p>Simultaneous regression analyses revealed that appraisals of robots as intelligent tracked ratings of trust in them to take care of either objects or information (but not agents), whereas appraisals of robots as likable and alive tracked trust in them to care for agents, in a pattern resembling that reported by <ref type="bibr" target="#b15">Ghazali et al. (2018)</ref>, who also found tendencies to trust a robot's advice to be positively correlated with perceptions of the robot as likable. <ref type="bibr">Mayer and colleagues' (1995)</ref> influential model of factors predicting trust appears to conceptually accord with this pattern.</p><p>Within their model, benevolence, or the perceived desire of an agent to beneficially help the trustor, promotes trust and is intrinsically related to affiliative feelings of attachment, whereas ability promotes trust rooted in the agent's task-relevant skills and competencies. Although we did not directly assess perceived benevolence or ability in the present studies, our measures of likability and intelligence arguably relate to these respective dimensions. If so, then trust in robots to care for agents appears intuitively driven by assessments of these machines as benevolent, and by implication to harbor reciprocal feelings of affiliative attachment motivating them to advance the welfare of pets, children, the elderly, or other agents in their charge.</p><p>Notwithstanding calls to implement artificial empathy aligning AI with goals to support human welfare (e.g., <ref type="bibr" target="#b7">Christov-Moore et al., 2023)</ref>, intuiting kindly motives to robots is troublingly irrational: machines lack capacities for affiliation or associated benevolent intentions. The robust replicability of our findings linking trust in a robot's capacity to care for living beings as driven by perceptions of their likability moreso than of their intelligence suggests a na√Øve propensity to overestimate machine agents' suitability for caregiving tasks should they be designed to mimic social warmth and affability. To be fair, insofar as living agents would emotionally benefit from machine caregivers exhibiting affiliative cues, it may be sensible to prefer these social qualities (e.g., a pet or child might be more comfortable with a socially warm robot taking care of them).</p><p>Nonetheless, with regard to artificial agents' capacities to respond to safetyor health-relevant circumstances, appraisals of ability should supersede appraisals of likability or seeming aliveness. Our findings therefore motivate further work exploring the extent to which apparent warmth and likability may lead to dangerous overestimates of machines' suitability to care for vulnerable agents.</p><p>The nonhumanoid robot in Experiment 3 was trusted less in all domains, and these reductions were mediated by lower appraisals of its intelligence, likability, and aliveness, in patterns corresponding to the thematic links between appraisal dimensions and trust outcomes also observed in the humanoid robot conditions. The finding that participants trusted the nonhumanoid less with regard to care of information, a task which does not entail physical demands, further supports the interpretation that it was not inferred limitations of its physical design which depressed trust in its capacity to perform, but rather effects of its physical design on perceptions of it as less human-and hence as less intelligent, likable, nurturant or alive.</p><p>Correspondingly, the null differences between trust in the less anthropomorphic, faceless humanoid and the gendered humanoids may be explained by the comparably high appraisals of the three humanoids on all dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>A possible take-home summary of the present research could be that overall physical anthropomorphism is an important determinant of trust in household service robots, whereas gender presentation is not. We encourage readers to resist this conclusion pending further investigation employing behavioral measures of trust and longitudinal designs. It may be the case that individuals evince more or less trust in contexts of actual interaction than is captured by their self-reports regarding counterfactual trust scenarios. Likewise, whereas latent effects of gender presentation may be masked in a one-shot encounter with a highly anthropomorphic agent, particularly at the time of writing when human-robot interaction remains relatively rare for most individuals, iterated interaction with service robots may reveal gender presentation to be an important determinant of trust over time, particularly in gendered task domains. For now, our results may be taken to predict consequences of design choices with regard to gender presentation and physical anthropomorphism on the public's initial appraisals of and trust in household robots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Effects of Robot Condition on Trust to Physically Carry</head><p>We also included measures of trust in the robots to physically carry objects or agents in Experiment 1. In five questions, participants were asked to rate their trust in the robot to physically carry their clothes, their food, their computer, their money, or a baby, in random order, rated on the same 7-point scale as the trust and appraisal measures (1 = Strongly disagree, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Exploratory Measures of Assertiveness</head><p>We also included a measure of assertiveness in the robots to in Experiments 1 and 2 (i.e., "The robot seems assertive", "The robot seems confident", "The robot seems dominant", Œ± = </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Interactions Between Individual Differences in Assessments of Automated Systems and Robot Conditions on Trust Outcomes</head><p>In Experiments 2 and 3, for exploratory purposes, we administered <ref type="bibr" target="#b51">Merritt et al.'s (2015)</ref> measure of individual differences in beliefs regarding the performance of automated systems, which is based on their model of the Perfect Automation Schema (PAS). The PAS model, as operationalized by two subscales included within a seven-item scale (1=Strongly disagree; 2 =Disagree; 3=Somewhat disagree; 4=Neither agree nor disagree; 5=Somewhat agree; 6=Agree; 7=Strongly agree), is comprised of two distinct dimensions: High Expectations in automated systems (PAS-HE; four items, e.g., "Automated systems rarely make mistakes"; Œ±s &gt; .84 in both experiments), and All-or-None beliefs that automated systems that exhibit any performance errors are entirely unreliable (PAS-AN; three items, e.g., "If an automated system makes a mistake, then it is completely useless"; Œ±s &gt; .75 in both experiments). The high expectations subscale has been previously associated with higher trust in automation <ref type="bibr">(Lyons &amp; Guznov, 2017</ref>).</p><p>The PAS-HE ratings were significantly positively associated with all trust outcomes, ps &lt; .001 in both Experiments 2 and 3, whereas the PAS-AN ratings were significantly positively associated with most trust outcomes in both studies, ps &lt; .001, but not Trust in Care of Objects in Experiment 2, p =.069, or Experiment 3, p =.139 (see <ref type="table" target="#tab_0">Table S1</ref>).</p><p>We next assessed whether individual differences in either PAS dimension interacted with robot condition to moderate trust. In Experiment 2 we created dummy variables for the Masculine and Feminine humanoids, with the Less Anthropomorphic humanoid as the reference category, then entered those variables, the PAS scale of interest (standardized), and the interactions between the PAS scale and the dummy-coded robot conditions as potential predictors in a series of regression models using Trust in Care of Objects, Agents, and</p><p>Information as the outcome variables. In Experiment 3, we used a similar strategy, this time creating dummy variables for the Masculine, Feminine, and Less Anthropomorphic humanoids, with the Nonhumanoid as the reference category.</p><p>In Experiment 2, we detected significant interactions between PAS-HE and appraisals of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Interactions Between Individual Differences in Assessments of Automated Systems and Robot Conditions on Appraisal Outcomes</head><p>We next assessed whether individual differences in either PAS dimension interacted with robot condition to moderate any appraisal outcome. For Experiment 2 we once again created dummy variables for the Masculine and Feminine humanoids, with the Less Anthropomorphic humanoid as the reference category, then entered those variables, the PAS scale of interest (standardized), and the interactions between the PAS scale and the dummy-coded robot conditions as potential predictors in a series of regression models using appraisals of Intelligence, Likability, Aliveness and Nurturance as the outcome variables. In Experiment 3, we used a similar strategy, this time creating dummy variables for the Masculine, Feminine, and</p><p>Less Anthropomorphic humanoids, with the Nonhumanoid as the reference category. We detected no interactions in either experiment between either PAS-HE or PAS-AN and robot condition with regard to any of the appraisal outcomes, ps .144 -.964. Scale; PAS-AN = Perfect Automation Schema, All-or-None Scale <ref type="bibr" target="#b51">(Merritt et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Effects of Robot Condition on Sympathy</head><p>We added an exploratory measure of sympathy for the robot to Experiments 2 and 3.</p><p>Participants were provided the following prompt:</p><p>"Now, please imagine that the robot you just met were assaulted by a person who is biased against robots. The person strikes the robot repeatedly with a baseball bat, knocking the robot to the ground and causing significant damage. The robot repeatedly asks them to please stop, but the person ignores the robot. The robot calls out for help, but to no avail. Now, wires and gears are exposed, the robot has lost the use of its left arm, and the body is cracked."</p><p>They were then asked to rate their agreement with the following statements: "I would feel sorry for the robot," "I would feel sympathetic for the robot," "I would wish for the person to stop hitting the robot". The three items (Œ±s &gt; .88 in both studies) were presented in random order and rated on the same 7-point scale as the trust and appraisal measures (1 = Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither agree nor disagree, 5 = Somewhat agree, 6 = Agree, 7 = Strongly agree). Representations of the robot as possessing emotional capacitieshere, to suffer-were gauged based on participants' own spontaneous feelings of sympathy toward it because, following Holbrook (2018), we speculated that this may be a more effective way of tapping intuitions of the robot as a feeling agent, as opposed to asking participants to state their declarative beliefs regarding the robot's putative emotional states (i.e., the 'correct' answer would be that the robot lacks emotion).</p><p>We conducted analyses of variance, including participant gender as a covariate, on participants' sympathy for the robot, finding no effects of robot condition, nor interactions between robot condition and participant gender, in either study, ps .123 -.925, nor any effect of gender in Experiment 2, p = .397. However, we did detect a significant effect of gender in Experiment 3, F(1, 455) = 16.15, p &lt; .001, with women reporting significantly greater sympathy than men (combining robot conditions, Mwomen = 5.49, SD = 1.54; Mmen = 4.87, SD = 1.76).</p><p>Given that this interaction was not observed in both studies, the effect should be interpreted with skepticism. However, it is worth noting that participants tended to report a moderate degree of emotional sympathy for these machines, indicating an implicit (and irrational) perception of them as harboring a relevant degree of subjective emotional experience (e.g., the capacity to suffer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Interactions Between Participants' Gender Bias and Gendered Humanoids on Trust Outcomes (Experiment 3)</head><p>In Experiment 3, individual differences in explicit gender bias in appraisals of capability were assessed according to two items ("Please rate your feelings towards men", "Please rate your feelings towards women") rated according to a 10-point Likert scale (1 = Extremely incapable; 10 = Extremely capable); the scores targeting women were then subtracted from the scores targeting men to create a bias difference score, such that higher [lower] scores indicate a greater bias favoring men <ref type="bibr">[women]</ref>.</p><p>We assessed whether self-reports of overt gender bias in appraisals of overall capability moderated trust in either the Masculine or Feminine humanoid robot. We created dummy variables for the Masculine, Feminine, and Less Anthropomorphic humanoid conditions, with the Nonhumanoid as the reference category, then entered those variables, the gender bias difference score (standardized), and the interactions between the gender bias difference score and the dummy-coded robot conditions as potential predictors in a series of regression models using Trust in Care of Objects, Agents, and Information as the outcome variables. With regard to Trust in Care of Objects or Agents, we observed no interactions between the gender bias score and either the Masculine or Less Anthropomorphic conditions, ps .086 -.858. However, there were significant interactions between gender bias in appraisals of capability and the Feminine humanoid condition with regard to levels of trust in both the Care of Objects (b = .54, SE = .22, Œ≤ = .15, p = .013, 95% CI <ref type="bibr">[.11, .96]</ref>) and Agents (b = .55, SE = .23, Œ≤ = .14, p = .018, 95% CI [.10, 1.01]). In both cases, participants who expressed bias favoring men over women reported greater trust in the Feminine robot to care for household objects or agents, in line with gender stereotypes regarding tasks such as cooking, doing laundry, or providing childcare (see <ref type="figure" target="#fig_12">Figure   S1</ref>, below). There were no interactions between gender bias and humanoid condition with regard to Trust in Care of Information (a task domain which does not appear to be stereotypically gendered), ps .137 -.469.</p><p>It should be stressed that the above models relied on highly kurtotic data (13.59), as the great majority of participants (71.7%) did not report gender bias (i.e., their ratings for women and men were equivalent). Moreover, follow-up tests in which outliers of greater than three standard deviations above or below the mean gender bias rating were omitted detected no significant interaction the Feminine condition for Trust in the Care of Agents, p = .420, and only a trend for Trust in the Care of Objects (b = .76, SE = .39, Œ≤ = .13, p = .053, 95% CI [-.01, 1.53]),</p><p>indicating that the significant interactions obtained when using the full dataset are driven by outliers reporting relatively extreme degrees of gender bias. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Interactions Between Gender Bias and Gendered Humanoids on Appraisal</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcomes (Experiment 3)</head><p>We assessed whether self-reports of overt gender bias in appraisals of overall capability moderated appraisals of the humanoid robots, entering the dummy variables for the Masculine, Feminine, and Less Anthropomorphic humanoid conditions, the gender bias difference score (standardized), and the interactions between the gender bias difference score and the dummycoded robot conditions as potential predictors in a series of regression models with Likability,</p><p>Intelligence, Aliveness, and Nurturance as the outcomes variables. We observed no interactions between gender bias and any humanoid condition with regard to any of these appraisals, ps .088 -.881. Again, it should be noted that the models relied on highly kurtotic data (13.59), as the great majority of participants (71.7%) did not report gender bias (i.e., their ratings for women and men were equivalent).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Aliveness as potential predictor variables and Trust in Care of Objects and Trust in Care of Agents as the outcome variable, to assess the relative contributions of each appraisal on trust in these distinct categories. Perceived Intelligence Drives Trust in Care of Objects. The three appraisal dimensions explained a significant amount of the variance in Trust in Care of Objects, F(3, 470) = 125.64, p &lt; .001, R 2 = .45, R 2 Adjusted = .44. Intelligence was most strongly positively associated with Trust in Care of Objects (b = .45, SE = .06, Œ≤ = .44, p &lt; .001), followed by Likability (b = .25, SE = .05, Œ≤ = .27, p &lt; .001); Aliveness was not significantly associated with Trust in Care of Objects in the model, p = .953. Perceived Likability and Aliveness Drive Trust in Care of Agents. The three appraisal dimensions explained a significant amount of the variance in Trust in Care of Agents, F(3, 470) = 77.29, p &lt; .001, R 2 = .33, R 2 Adjusted = .33. Likability was most strongly positively associated with Trust in Care of Agents, (b = .32, SE = .05, Œ≤ = .33, p &lt; .001), followed by Aliveness (b = .20, SE = .04, Œ≤ = .25, p &lt; .001); Intelligence was not significantly associated with Trust in Care</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>simultaneous linear regressions including covarying appraisals of Likability, Intelligence, Aliveness as potential predictor variables and Trust in Care of Objects, Trust in Care of Agents, and Trust in Care of Information as the outcome variables, to assess the relative contributions of each appraisal on trust in these distinct categories. (We did not include our measure of Nurturance in these models as preliminary tests indicated a problematic degree of multicollinearity with appraisals of Likability.) Perceived Intelligence and Likability Drive Trust in Care of Objects. The appraisal dimensions explained a significant amount of the variance in Trust in Care of Objects, F(3, 477) = 116.20, p &lt; .001, R 2 = .42, R 2 Adjusted = .42. Departing somewhat from the results of Experiment 1, Intelligence (b = .44, SE = .06, Œ≤ = .39, p &lt; .001) and Likability (b = .33, SE = .05, Œ≤ = .34, p &lt; .001) were more comparably positively associated with Trust in Care of Objects. As in Experiment 1, Aliveness was not significantly associated with Trust in Care of Objects, p = .357. Perceived Likability and Aliveness Drive Trust in Care of Agents. The appraisal dimensions explained a significant amount of the variance in Trust in Care of Agents, F(3, 477) = 78.77, p &lt; .001, R 2 = .33, R 2 Adjusted = .33 As in Experiment 1, Likability was most strongly positively associated with Trust in Care of Agents, (b = .42, SE = .06, Œ≤ = .38, p &lt; .001), followed by Aliveness (b = .19, SE = .05, Œ≤ = .20, p &lt; .001); Intelligence was again not significantly associated with Trust in Care of Agents in the model, p = .242. Perceived Intelligence and Likability Drive Trust in Care of Information. The appraisal dimensions explained a significant amount of the variance in Trust in Care of Information, F(3, 477) = 35.96, p &lt; .001, R 2 = .18, R 2 Adjusted = .18. Appraisals of Likability (b = .29, SE = .08, Œ≤ = .23, p &lt; .001) and Intelligence (b = .26, SE = .09, Œ≤ = .18, p = .004) were most strongly positively associated with Trust in Care of Information. Appraisals of Aliveness were not correlated with Trust in Care of Information in the model, p = .263.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>The between-subjects design resembled Experiments 1 and 2 (Masculine condition, N = 122; Feminine condition, N = 115; Less Anthropomorphic condition N = 112), now adding a fourth robot manipulation (the Nonhumanoid condition, N = 114) depicting a nonhumanoid robot using the same synthetic voice as the Less Anthropomorphic humanoid condition (see Figure 1, bottom). Participants reported their willingness to trust as previously (Trust in Care of Objects, Œ± = .89; Trust in Care of Agents, Œ± = .93; Trust in Care of Information, Œ± = .98). Also as previously, participants rated their appraisals of the robot's Likability (r = .70), Intelligence (r = .73), Aliveness (r = .80), and Nurturance (r = .78). The trust and appraisal items (randomized) were again presented in separate blocks (randomized) and rated using the same 7-point Likert scale as previously. Finally, participants completed demographic questions, including an attention check, before being thanked and debriefed. (We also included an exploratory measure of explicit gender bias with regard to the relative capabilities of women and men in the demographic questions, and conducted interaction tests to explore whether levels of bias moderate the effects of gender presentation-see Supplementary Material for details and findings.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>With respect to participant gender, as in Experiments 1 and 2, we observed no significant effects on Trust in Care of Objects or Information, ps .446 -.727, nor interactions with robot condition with regard to any of the three trust outcomes, ps .232 -.564. However, we did observe a main effect of participant gender on Trust in Care of Agents, F(1, 455) = 15.46, p = .015, with women in Experiment 3 reporting lower trust (pooling robot conditions) (Mwomen = 2.52, SD = 1.55; Mmen = 2.88, SD = 1.68).\\Fig ure 2. Manipulation of the gender or relative anthropomorphism of the humanoid robot (the Masculine, Feminine and Less Anthropomorphic conditions) does not influence trust in care of household objects in any experiment. The Nonhumanoid robot added in Experiment 3 is less trusted to care for objects. The violin plot outlines illustrate kernel probability density; the width of the shaded areas represents the proportion of data located there, and the circles indicate the means (see text for details).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Manipulation of the gender or relative anthropomorphism of the humanoid robot (the Masculine, Feminine and Less Anthropomorphic conditions) does not influence trust in care of vulnerable agents in any experiment. The Nonhumanoid robot added in Experiment 3 is less trusted to care for agents. The violin plot outlines illustrate kernel probability density; the width of the shaded areas represents the proportion of data located there, and the circles indicate the means (see text for details).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Manipulation of the gender or relative anthropomorphism of the humanoid robot (the Masculine, Feminine and Less Anthropomorphic conditions) does not influence trust in care of vulnerable agents in either Experiment 2 or 3 (this measure was not collected in Experiment 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>(</head><label></label><figDesc>We did not include our measure of Nurturance in these mediation models as preliminary tests indicated a problematic degree of multicollinearity with appraisals of Likability.)Effect of Humanoid vs. Nonanthropomorphic Robot on Trust inCare for Objects Partially Mediated by Appraisals of Intelligence and Likability. Appraisals of Intelligence and Likability partially mediated the effect of Humanoid-versus-Nonhumanoid robot condition on Trust in Care of Objects. The effect of robot condition on Trust in Care of Objects (b = -.77, SE = .16, p &lt; .001, 95% CI [-1.09, -.46]) was of reduced magnitude in the model when including the three appraisal dimensions as potential mediators (b = -.42, SE = .12, p =.001, 95% CI [-.65, -.18]), whereas the indirect effects of both Intelligence (b = -.26, SE = .10, 95% CI [-.46, -.08]) and Likability (b = -.15, SE = .06, 95% CI [-.27, -.05]) on Trust in Care of Objects did not have confidence intervals overlapping with zero. Appraisals of Aliveness did not mediate the relationship, as the indirect effect was marginal and the confidence intervals did overlap with zero (b = .05, SE = .03, 95% CI [-.01, .12]). Effect of Humanoid vs. Nonanthropomorphic Robot on Trust in Care for Agents Fully Mediated by Appraisals of Likability and Aliveness. Appraisals of Likability and Aliveness fully mediated the effect of the Humanoid-versus-Nonhumanoid robot condition on Trust in Care of Agents. The effect of robot condition on Trust in Care of Agents (b = -.43, SE = .18, p = .015, 95% CI [-.77, -.09]) was of reduced magnitude, and no longer significant in the model when including the three appraisal dimensions as potential mediators (b = -.06, SE = .14, p = .690, 95% CI [-.34, .23]), whereas the indirect effects of both Likability (b = -.21, SE = .07, 95% CI = [-.37, -.08]) and Aliveness (b = -.13, SE = .05, 95% CI = [-.25, -.05]) on Trust in Care of Agents did not have confidence intervals overlapping with zero. Appraisals of Intelligence did not mediate the relationship, as the indirect effect was marginal and the confidence intervals did overlap with zero (b = -.03, SE = .03, 95% CI [-.11, .02]). Effect of Humanoid vs. Nonanthropomorphic Robot on Trust in Care for Information Fully Mediated by Appraisals of Likability and Intelligence. Appraisals of Likability and Intelligence fully mediated the effect of the Humanoid-versus-Nonhumanoid robot condition on Trust in Care of Agents. The effect of robot condition on Trust in Care of Information (b = -.58, SE = .21, p = .006, 95% CI [-.99, -.17]) was of reduced magnitude, and no longer significant in the model when including the three appraisal dimensions as potential mediators (b = -.22, SE = .19, p = .242, 95% CI [-.59, .15]), whereas the indirect effects of both Likability (b = -.20, SE = .08, 95% CI = [-.38, -.06]) and Intelligence (b = -.10, SE = .06, 95% CI = [-.24, -.01]) on Trust in Care of Agents did not have confidence intervals overlapping with zero. Appraisals of Aliveness did not mediate the relationship, as the indirect effect was marginal and the confidence intervals did overlap with zero (b = -.06, SE = .06, 95% CI [-.19, .04]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>simultaneous linear regressions including covarying appraisals of Likability, Intelligence, Aliveness as potential predictor variables and Trust in Care of Objects, Trust in Care of Agents, and Trust in Care of Information as the outcome variables, to assess the relative contributions of each appraisal on trust in these distinct categories. (As in Experiment 2, we did not include our measure of Nurturance in these models as preliminary tests indicated high multicollinearity with appraisals of Likability.) Perceived Intelligence and Likability Drive Trust in Care of Objects. The appraisal dimensions explained a significant amount of the variance in Trust in Care of Objects, F(3, 459) = 150.76, p &lt; .001, R 2 = .50, R 2 Adjusted = .49. Closely replicating the results of Experiment 2, Intelligence (b = .53, SE = .05, Œ≤ = .51, p &lt; .001) as well as Likability (b = .28, SE = .05, Œ≤ = .30, p &lt; .001) were positively associated with Trust in Care of Objects, whereas Aliveness was not, p = .138. Perceived Likability and Aliveness Drive Trust in Care of Agents. The appraisal dimensions explained a significant amount of the variance in Trust in Care of Agents, F(3, 459) = 83.66, p &lt; .001, R 2 = .35, R 2 Adjusted = .35. Closely replicating the findings of Experiments 1 and 2, Likability was most strongly positively associated with Trust in Care of Agents, (b = .37, SE = .06, Œ≤ = .38, p &lt; .001), followed by Aliveness (b = .19, SE = .05, Œ≤ = .21, p &lt; .001), and Intelligence was not significantly associated, p = .296. Perceived Intelligence and Likability Drive Trust in Care of Information. The appraisal dimensions explained a significant amount of the variance in Trust in Care of Information, F(3, 459) = 50.44, p &lt; .001, R 2 = .25, R 2 Adjusted = .24. Closely replicating the findings of Experiment 2, Appraisals of Likability (b = .36, SE = .07, Œ≤ = .31, p &lt; .001) and Intelligence (b = .21, SE = .08, Œ≤ = .16, p = .011) were positively associated with Trust in Care of Information, whereas</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>Standardized regression coefficients for the relationships between the Humanoid-vs-Nonhumanoid manipulation (1 = Humanoid, 2 = Nonhumanoid) and Trust in Care of Objects, Agents or Information as mediated by appraisals in Experiment 3. The standardized regression coefficients between the Humanoid-vs-Nonhumanoid manipulation and Trust in Care of Objects, Agents and Information when accounting for the three appraisals are in parentheses. Top: Effect of robot condition on Trust in Care of Objects partially mediated by appraisals of the Humanoids as higher in Intelligence and Likability (but not Aliveness). Middle: Effect of robot condition on Trust in Care of Agents fully mediated by appraisals of the Humanoid as higher in Likability and Aliveness (but not Intelligence). Bottom: Effect of robot condition on Trust in Care of Information fully mediated by appraisals of the Humanoid as higher in Likability and Intelligence (but not Aliveness). * p &lt; .05, **p &lt; .01, ***p &lt;.001.DiscussionAll of the trust and appraisal dimensions were significantly lower in the Nonhumanoid condition relative to the Humanoid condition. Mediation analyses revealed that differences between the Humanoid and Nonhumanoid with respect to trust in care of agents was partially mediated by differences in perceived Likability and Aliveness (but not Intelligence), whereas the lower trust in the Nonhumanoid to care for objects or information was mediated by lower appraisals of Intelligence and Likability. Correspondingly, and as in Experiments 1 and 2, we observed patterns of asymmetric association between appraisal dimensions and trust domains, such that trust in robots to care for vulnerable Agents was positively associated with appraisals of their Likability and Aliveness (but not Intelligence), and trust in robots to care for Objects or Information was positively associated with appraisals of their Intelligence and Likability (but not Aliveness).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>2 = Disagree, 3 =Agree, 7 =</head><label>37</label><figDesc>Somewhat disagree, 4 = Neither agree nor disagree, 5 = Somewhat agree, 6 = Strongly agree). These measures were dropped in subsequent experiments as evidently redundant to the other trust measures. We conducted analyses of variance, including participant gender as a covariate, finding no effects of robot condition on any question, ps .192 -.543. With regard to effects of participant gender, there was a mildly significant effect with regard to trust in the robot to carry a baby (combining robot conditions, Mwomen = 1.85, SD = 1.39; Mmen = 2.14, SD = 1.49), F(2, 405) = 4.07, p = .044, but no other gender differences, ps .237 -.910. Pooling genders and robot conditions, mean trust ratings inversely correlated with the risk inherent to the robot malfunctioning, with relatively high trust in the robot to physically carry clothes (M = 5.82, SD = 1.33) or food (M = 5.04, SD = 1.78), moderate trust with respect to carrying a computer (M = 4.02, SD = 2.03) or money (M = 4.00, SD = 2.03), and low trust with respect to carrying a baby (M = 2.00, SD = 1.45).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>. 71 in 1 = 5 =</head><label>7115</label><figDesc>Experiment 2, Œ± = .76 in Experiment 3), rated on the same 7-point scale as the other appraisal measures (Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither agree nor disagree, Somewhat agree, 6 = Agree, 7 = Strongly agree). We conducted analyses of variance, including participant gender as a covariate, finding no effects of robot condition, ps &gt; .367, participant gender, ps &gt;.057, or interactions between condition and participant gender, ps &gt; .132. Pooling conditions, participants appraised the robots as moderately assertive (Experiment 2: M = 4.39, SD = 1.26; Experiment 3: M = 4.30, SD = 1.36).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>the</head><label></label><figDesc>Masculine robot with regard to Trust in Care of Objects, p = .002, 95% CI[.185, .807], and Trust in Care of Information, p = .040, 95% CI [.019, .779], but not Trust in Care of Agents, p = .091. Higher PAS-HE ratings correlated more strongly with trust in the Masculine robot, r(164) = .47, than with trust in the Less Anthropomorphic robot, r(111) = .39, to care for Objects; the reverse pattern obtained for trust on care of Information in the Masculine condition, r(164) = .51, relative to the Less Anthropomorphic condition, r(111) = .60. It should be noted that the positive relationship between PAS-HE ratings and both trust outcomes, despite these interactions, were comparable across robot conditions in Experiment 2. Moreover, no such interactions between PAS-HE ratings and robot condition with regard to any of the trust outcomes were observed in Experiment 3. In Experiment 2, we also detected a significant interaction between PAS-AN and appraisals of the Masculine robot with regard to Trust in Care of Information, p = .043, 95% CI[.014, .826], with higher PAS-AN ratings correlated more strongly with trust in the Masculine robot, r(164) = .27, than with the Nonhumanoid, r(111) = .20. There were no interactions between PAS-AN and any of the trust outcomes in Experiment 3, ps .094 -.969. Given that these interactions were not predicted on theoretical grounds, nor generalizable across studies, nor meaningfully altering the patterns of positive association, they do not appear to be reliable or important.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure S1 .</head><label>S1</label><figDesc>Gender bias moderates the correlation between Trust in Care of Objects (top) and Trust in Care of Agents (bottom) in Experiment 3. The correlations with bias favoring men as more competent are significantly positive for the Feminine humanoid, but not the other humanoid robots (see text for details).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 Differences in Trust in the Nonanthropomorphic Vs. Humanoid Robots Mediated by Lower Appraisals of Likability, Intelligence, or Aliveness?</head><label>1</label><figDesc>Appraisals of Robot Likability, Intelligence, Aliveness and Nurturance, by Condition, AcrossWe next conducted a series of mediation tests to assess whether lower appraisals of the Nonhumanoid's qualities Likability, Intelligence, or Aliveness may have mediated the lower degree of trust participants expressed with regard to its ability to Care for Objects, Agents, or</figDesc><table><row><cell>Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Robot Condition</cell><cell></cell></row><row><cell></cell><cell>Masculine</cell><cell>Feminine</cell><cell>Less Anthro</cell><cell>Nonhuman</cell></row><row><cell></cell><cell>M (SD)</cell><cell>M (SD)</cell><cell>M (SD)</cell><cell>M (SD)</cell></row><row><cell>Experiment 1 (N = 474)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Likability</cell><cell>4.59 (1.50)</cell><cell>4.46 (1.51)</cell><cell>4.38 (1.52)</cell><cell>-</cell></row><row><cell>Intelligence</cell><cell>5.07 (1.43)</cell><cell>5.10 (1.28)</cell><cell>4.88 (1.39)</cell><cell>-</cell></row><row><cell>Aliveness</cell><cell>4.32 (1.75)</cell><cell>4.01 (1.77)</cell><cell>3.71 (1.81)</cell><cell>-</cell></row><row><cell>Experiment 2 (N = 481)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Likability</cell><cell>4.65 (1.51)</cell><cell>4.50 (1.64)</cell><cell>4.61 (1.64)</cell><cell>-</cell></row><row><cell>Intelligence</cell><cell>5.14 (1.33)</cell><cell>5.07 (1.31)</cell><cell>5.15 (1.28)</cell><cell>-</cell></row><row><cell>Aliveness</cell><cell>4.28 (1.63)</cell><cell>4.06 (1.72)</cell><cell>4.16 (1.72)</cell><cell>-</cell></row><row><cell>Nurturance</cell><cell>4.08 (1.61)</cell><cell>3.92 (1.65)</cell><cell>3.92 (1.73)</cell><cell>-</cell></row><row><cell>Experiment 3 (N = 463)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Likability</cell><cell>4.74 (1.48)</cell><cell>4.62 (1.48)</cell><cell>4.56 (1.57)</cell><cell>4.05 (1.63)</cell></row><row><cell>Intelligence</cell><cell>5.04 (1.40)</cell><cell>4.99 (1.46)</cell><cell>4.98 (1.44)</cell><cell>4.51 (1.61)</cell></row><row><cell>Aliveness</cell><cell>4.22 (1.75)</cell><cell>3.98 (1.86)</cell><cell>3.80 (1.83)</cell><cell>3.23 (1.81)</cell></row><row><cell>Nurturance</cell><cell>3.85 (1.78)</cell><cell>3.93 (1.73)</cell><cell>3.75 (1.75)</cell><cell>3.26 (1.76)</cell></row></table><note>Note. The robot's nurturant qualities were not appraised in Experiment 1, and the Nonhumanoid condition was not included in Experiments 1 or 2. Ratings produced on a 7-point scale (1 = Strongly disagree, 2 = Disagree, 3 = Somewhat disagree, 4 = Neither agree nor disagree, 5 = Somewhat agree, 6 = Agree, 7 = Strongly agree).(PROCESS can estimate the path coefficients in a mediator model and generate bootstrap confidence intervals for total and specific indirect effects of a predictor variable on an outcome variable through multiple potential mediator variables, adjusting all paths for the potential influence of covariates not categorized in the model as potential mediators.) As there were no significant differences between the three humanoid conditions with regard to either the appraisal or trust outcomes, we created a new dichotomous robot variable averaging the three humanoid conditions into one Humanoid category and the Nonhumanoid condition as the other (1 =</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table S1</head><label>S1</label><figDesc>Descriptive Statistics and Correlations for Perfect Automation SchemaSubscales, Trust   Outcomes, and Appraisal Outcomes (Pooling Robot Conditions)    </figDesc><table><row><cell>Variable</cell><cell>M</cell><cell>SD</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell></row><row><cell>Expt. 2 (N = 481)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1. PAS-HE</cell><cell cols="2">3.28 1.39</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2. PAS-AN</cell><cell cols="4">3.77 1.34 .50 *** -</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">3. Trust Objects 4.97 1.39 .32 *** .07</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">4. Trust Agents 3.03 1.62 .57 *** .20 *** .58 ***</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5. Trust Info</cell><cell cols="6">3.41 1.86 .45 *** .17 *** .54 *** .62 ***</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6. Intelligence</cell><cell cols="4">5.12 1.30 .31 *** .09</cell><cell cols="3">.61 *** .46 *** .39 ***</cell><cell>-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>7. Likability</cell><cell cols="4">4.59 1.59 .40 *** .11 *</cell><cell cols="4">.58 *** .56 *** .41 *** .70 ***</cell><cell>-</cell><cell></cell><cell></cell></row><row><cell>8. Aliveness</cell><cell cols="9">4.17 1.69 .35 *** .19 *** .41 *** .47 *** .32 *** .62 *** .63 ***</cell><cell>-</cell><cell></cell></row><row><cell>9. Nurturance</cell><cell cols="11">3.98 1.66 .38 *** .14 ** .46 *** .56 *** .40 *** .66 *** .82 *** .66 *** -</cell></row><row><cell>Expt. 3 (N = 463)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1. PAS-HE</cell><cell cols="2">3.14 1.37</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2. PAS-AN</cell><cell cols="4">3.63 1.42 .52 *** -</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">3. Trust Objects 4.75 1.54 .34 *** .07</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">4. Trust Agents 2.71 1.63 .61 *** .27 *** .59 ***</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5. Trust Info</cell><cell cols="6">3.39 1.96 .50 *** .13 ** .57 *** .63 ***</cell><cell>-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6. Intelligence</cell><cell cols="4">4.88 1.49 .32 *** .11 *</cell><cell cols="3">.68 *** .47 *** .43 ***</cell><cell>-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>7. Likability</cell><cell cols="4">4.34 1.67 .45 *** .12 *</cell><cell cols="4">.61 *** .57 *** .48 *** .71 ***</cell><cell>-</cell><cell></cell><cell></cell></row><row><cell>8. Aliveness</cell><cell cols="9">3.83 1.84 .45 *** .20 *** .47 *** .51 *** .40 *** .66 *** .69 ***</cell><cell>-</cell><cell></cell></row><row><cell>9. Nurturance</cell><cell cols="11">3.70 1.77 .47 *** .21 *** .53 *** .61 *** .45 *** .64 *** .82 *** .74 *** -</cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* p &lt; .05.** p &lt; .01.*** p &lt; .001. PAS-HE = Perfect Automation Schema, High Expectations</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Brett Sheeran for assistance with preparing and video-recording the Nonhumanoid robot in Expt. 3. This work was supported by the Air Force Office of Scientific Research [FA9550-20-1-0347].</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>programmed the sequences used by the humanoid robots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare no competing interests.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">English text to speech voices (n.d</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Acapela</forename><surname>Group</surname></persName>
		</author>
		<ptr target="https://www.acapela-group.com/voices/repertoire/uk-english-text-to-speech-voices/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Asking for help from a gendered robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Jessica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scassellati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 36th Annual Conference of the Cognitive Science Society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The (fe)male robot: How robot body shape impacts first impressions and trust towards robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernotat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyssel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sachse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Soc Robot</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="477" to="489" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Why should we gender? The effect of robot gendering and occupational stereotypes on human trust and perceived competency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction</title>
		<meeting>the 2020 ACM/IEEE International Conference on Human-Robot Interaction<address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Gender representation and humanoid robots designed for domestic use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Erwin-Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Soc Robot</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="261" to="265" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Human-agent teaming for multirobot control: A review of human factors issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Human-Machine Systems</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="13" to="29" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Trusting automation: Designing for responsivity and resilience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum Factors</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="165" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Preventing antisocial robots: A pathway to artificial empathy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Christov-Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Reggente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schoeller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pluimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iacoboni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Damasio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kaplan</surname></persName>
		</author>
		<idno type="DOI">10.1126/scirobotics.abq3658</idno>
	</analytic>
	<monogr>
		<title level="j">Sci Robot</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">80</biblScope>
			<biblScope unit="page">3658</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploring influencing variables for the acceptance of social robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>De Graaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Allouch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot Auton Syst</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1476" to="1486" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Embodiment in socially interactive robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mataric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations Trends Robot</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="251" to="356" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting the trustworthiness of novel partners in economic exchange</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Desteno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pizarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dickens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1549" to="1556" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Challenging the binary: Gender/sex and the bio-logics of normalcy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Z</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shattuck-Heidorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am J Hum Biol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">23623</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gender stereotypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ellemers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu Rev Psychol</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="275" to="298" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">S)he&apos;s got the look: Gender stereotyping of robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyssel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Appl Soc Psychol</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2213" to="2230" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">NAO</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Humanoid robotics: A reference</title>
		<editor>Goswami, A., Vadakkepat, P.</editor>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effects of robot facial characteristics and gender in persuasive human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Ghazali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Barakova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Markopoulos</surname></persName>
		</author>
		<idno type="DOI">10.3389/frobt.2018.00073</idno>
	</analytic>
	<monogr>
		<title level="j">Front Robot AI</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">73</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Introduction to mediation, moderation, and conditional process analysis: A regression-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Hayes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>Guilford Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Third Edition</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Trust in automation: Integrating empirical evidence on factors that influence trust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bashir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum Factors</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="434" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Investigating gender differences in the meaning of household chores and child care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kroska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Marriage Family</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="456" to="473" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Keep an eye on the task! how gender typicality of tasks influence human-robot interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kuchenbrandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>H√§ring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eichberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyssel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Andr√©</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Soc Robot</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="417" to="427" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The gap between human&apos;s attitude towards robots in general and human&apos;s expectation of an ideal everyday life robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kuhnert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ragni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lindner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th IEEE International Symposium on Robot and Human Interactive Communication</title>
		<meeting><address><addrLine>RO-MAN; New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1102" to="1107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Service robots: A systematic literature review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.3390/electronics10212658</idno>
		<ptr target="https://doi.org/10.3390/electronics10212658" />
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2658</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Trust in automation: Designing for appropriate reliance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>See</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum Factors</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="80" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">How do huntergatherer children learn social and gender norms? A meta-ethnographic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lew-Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Reckin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Crist√≥bal-Azkarate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ellis-Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cross-Cult Res</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="255" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An integrative model of organizational trust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Schoorman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad Manage Rev</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="709" to="734" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Designing embodied cues for dialog with robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A mass-produced sociable humanoid robot: Pepper: The first machine of its kind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot Autom Mag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robot&apos;s gendering trouble: A scoping review of gendering humanoid robots and its effects on HRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Perugia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lisy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J of Soc Robotics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1725" to="1753" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The content of our cooperation, not the color of our skin: An alliance detection system regulates categorization by coalition and race, but not sex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pietraszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cosmides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tooby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">88534</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Check your stereotypes at the door: an analysis of gender typecasts in social human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Social Robotics</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="554" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Ir)relevance of gender? On the influence of gender stereotypes on learning with a robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Reich-Stiebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Eyssel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction</title>
		<meeting>the 2017 ACM/IEEE International Conference on Human-Robot Interaction<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="166" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robot gendering: Influences on trust, occupational competency, and preference of robot over human</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m">CHI Conference on Human Factors in Computing Systems (CHI EA &apos;20</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A review of eye gaze in virtual agents, social robotics and HCI: Behaviour generation, user interaction and perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ruhland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Andrist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Badler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">I</forename><surname>Badler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="299" to="326" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Persuasive robotics: The influence of robot gender on human behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Norton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<meeting>the IEEE/RSJ International Conference on Intelligent Robots and Systems<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2563" to="2568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">When stereotypes meet robots: The double-edge sword of robot gender and personality in human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Hum Behav</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="75" to="84" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Physical Anthropomorphism (but not Gender Presentation) Influences Trust in Household Robots</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Holbrook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umesh</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">P</forename><surname>Maglio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Testing Effects of Robot Condition on Trust to Physically Carry‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Testing Exploratory Measures of Assertiveness‚Ä¶‚Ä¶</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m">Testing Interactions Between Individual Differences in Assessments of Automated Systems and Robot Conditions on Trust Outcomes.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶3</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m">Testing Interactions Between Individual Differences in Assessments of Automated Systems and Robot Conditions on Appraisal Outcomes.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶.‚Ä¶5</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Descriptive Statistics and Correlations for Perfect Automation Schema Subscales, Trust Outcomes, and Appraisal Outcomes (Pooling Robot Conditions)</title>
		<idno>‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶.‚Ä¶‚Ä¶.‚Ä¶‚Ä¶6</idno>
	</analytic>
	<monogr>
		<title level="m">Table S1</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Testing Effects of Robot Condition on Sympathy‚Ä¶</title>
		<imprint>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m">Testing Interactions Between Participants&apos; Gender Bias and Gendered Humanoids on Trust Outcomes</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Interactions Between Gender Bias and Feminine Humanoid on Trust in Care of Objects and Agents‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S1</forename><surname>Figure</surname></persName>
			<affiliation>
				<orgName type="collaboration">‚Ä¶‚Ä¶‚Ä¶...‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶..11</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Testing Interactions Between Gender Bias and Gendered Humanoids on Appraisal Outcomes (Experiment 3)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ . .</forename><surname>References‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">All datasets, analysis syntax, materials and pre-registrations for these studies may be</title>
		<ptr target="https://osf.io/378rq/References" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cues of violent intergroup conflict diminish perceptions of robotic personhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Holbrook</surname></persName>
		</author>
		<idno type="DOI">10.1145/3181674</idno>
		<ptr target="https://doi.org/10.1145/3181674" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans Interact Intell Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Individual differences in human-machine trust: a multi-study look at the perfect automation schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Guznov</surname></persName>
		</author>
		<idno type="DOI">10.1080/1463922X.2018.1491071</idno>
	</analytic>
	<monogr>
		<title level="j">Theor Issues Ergon Sci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Measuring individual differences in the Perfect Automation Schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Merritt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Unnerstall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum Factors</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="740" to="53" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
