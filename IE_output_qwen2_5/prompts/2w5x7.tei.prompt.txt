You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Goal-driven information search biases create polarization and extremism during the accumulation of qualitative evidence Key spheres of public life have exhibited fast-growing polarization and extremism (P&E) around issues such as the economy, environment, and sociopolitical outcomes 
(Baldassarri & Gelman, 2008;
Wilson et al., 2020)
. Rising P&E has driven political violence around the world 
(Kleinfeld, 2022;
Yousef, 2023
), yet they are not limited to political spheres.
Far from it, they are common even in seemingly apolitical settings such as conflict among committees and boards, or fans of different pop stars and musicians, brands, and sports teams 
(Shi et al., 2017)
.
The pervasiveness of these tensions seems to suggest that there is something in our basic cognitive functions or modern culture that give predispose us toward P&E. For example, 
Baron & Roper (1976)
 show that even when making perceptual decisions (which are mundane and non-political), opinions become polarized over time. Likewise, recent work by 
Kvam et al. (2022)
 showed that merely asking people to choose between two options, across a wide variety of contexts, leads to retaining samples of information that are more polarized and extreme than the "true" information in the environment.
As frequently as they emerge, polarization and extremism are simultaneously extremely difficult to eradicate. Their resilience in the face of interventions can be attributed to several factors: we are biased to seek out confirming evidence 
(Festinger, 1957;
Westerwick et al., 2017)
, group norms and values reinforce polarization by providing a clear identity 
(Tajfel, 1978;
Tajfel & Turner, 1986)
, interpersonal benefits 
(Hogg & Turner, 1985;
Suhay, 2015)
 and pride 
(Lewis, 2008)
, and social media structures exacerbate P&E by promoting more sensationalized news, creating tight networks of ingroups, and by promoting more extreme, biased and outrage-expressing information 
(Foer, 2017;
Klein, 2020;
Benkler et al., 2018)
.
Perhaps most concerning is the idea that P&E are a direct consequence of rational inference strategies that people use to make (speeded) decisions 
(Kvam et al., 2022)
. As we outline below, the goal of information search during choice is to resolve a dilemma by selecting one option over the other -not necessarily to become well-informed on the issue at hand.
Choice is what we call a "high variance" task, meaning that the decision process is resolved more readily by high-variance information that is more likely to tip the balance in one direction or another, rather than lower-variance information that does not clearly distinguish among available response options. This is because high-variance information pushes a decision maker toward one end of the belief spectrum or the other, making it easy to reject one of the options in favor of the other.
By contrast, information search during other tasks -like assigning a value or rating to each option -require a person to respond with a precise value rather than tip the balance far in one direction or the other. We refer to these tasks as "low variance" tasks, because a person is most likely to stop and providing a (comparative) rating when they receive consistent information about its value or informational content. As a result, the stopping conditions for low-variance tasks can diverge sharply from high-variance tasks like choice. In this paper, we explore in detail the differences between high-variance and low-variance tasks in order to better understand how the goals we pursue, such as choice, drive the beliefs we form. By creating ecologically valid information environments and allowing people to freely sample information about their options pursuant to an assigned goal, we show that choice exacerbates P&E while tasks like rating can actually reduce them.


Definitions
Before wading deeper into the driving factors behind polarization and extremism, it helps to define what we mean by these terms, as researchers have conceptualize them in diverse ways. For example, one can think of polarization as increasing social divisions in support for government policies or partisan ideologies 
(Fiorina & Abrams, 2008)
 or perhaps as an increased emotional animosity towards people from the other party 
(Iyengar et al., 2019)
. Instead, by "polarization," we refer to a set of beliefs or information that exhibits a multi-polar pattern across people, such that there is a "gap" in the middle ground relative to the true / representative distribution of opinions or information (i.e., there are few people with moderate beliefs, even though the true information environment has a preponderance of moderate beliefs). This type of distribution is shown at the top-right of 
Figure 1
. A polarized set of information or a polarized person will tend away from the center of the true information spread and instead cluster into opposing subgroups.


Figure 1
Diagram of how each of the conditions (right) is predicted to affect information sampling from the environment (left).
Extremism refers to people with beliefs at the tails of the distribution of beliefs or information. Naturally, the prevalence of extremists will increase as the variance of this distribution increases -simply because there are more people in the tail end of the distributions.
The prevalence of extremism is therefore defined in terms of the variance or position of a piece of information relative to the center, a measure which we refer to as extremeness. The more extreme the opinion or piece of information, the further its distance from the center. Put together, a set of opinions or beliefs is extreme (exhibits extremeness) if they have high variance relative to the true / representative distribution of opinions or information.
To clarify, we do not assume that the center of information spread over every topic is the "correct" opinion, and our work does not make a normative argument across all contexts/topics.
Rather, we index departures from the true information as polarization and extremeness. As such, both definitions are in reference to a "true" or unbiased information / opinion distribution.
In the experiments we present below, a key goal is to delineate exactly what this unbiased distribution is. The first two studies are aimed at deriving a reference distribution against which we can compare the information that people collect and the opinions that they form about the stimuli. Specifically, Study 1 gathers reasons/information for which one might consider one option over another and Study 2 elicits ratings of how each piece of information makes people likely to choose an option for all possible information-option pairs. These likelihood ratings are then used in Study 3 to create a "true" distribution against which we could gauge how polarized or extreme the information participants gathered was.
To make polarization and extremeness concrete, we formalize them in terms of quantitative metrics representing a comparison between the observed distribution of information and the reference distribution of information. More formally, polarization is the difference between the true distribution of true information and the distribution of information sampled by the participant. It is measured by the Kullback-Leibler distance (KLD) between two probability distributions and mathematically formalized as:
KLD[p(y)||p(x)] = N i p(y i ) log n p(y i ) p(x i )
(1)
where p(y i ) describes the probability density of the real information distribution and p(x i ) is a nonparametrically estimated probability density of sampled data. The indices i : N represent each of points on the probability distributions where their divergence is calculated. For individual data points, we simply calculate the (negative) log likelihood −LL = − log(x||p(x)), quantifying how (un)likely a given data point is for an expected distribution.
Extremeness is defined as the ratio of the variance of the information sampled by participants to the variance of the true information distribution, hereby referred to as variance ratio. That is, V(sampled information)/ V(true information) where, sampled information is the average balance of evidence one might obtain for a particular sample size. The balance of evidence in the studies below is calculated as the estimated log odds of choosing one option over the other given the observed sequence of information a participant collected. Log odds for each piece of information in regard to each option was calculated by taking the likelihood ratings (or probability ratings, p) from Study 2, described below.
Put together, these formalize two concepts that are critical to understanding how beliefs are formed and maintained. Understanding the polarization and extremeness of information people sample allows us to better capture how and why they form polarized beliefs and take extreme actions.


Rationally polarized
As outlined above, confirmation bias, group norms, interpersonal benefits, and social media algorithms partially reveal why we see widespread polarization and extremeness. But they do not provide an account for (1) how people get polarized in the first place, and crucially,
(2) why we observe polarization and extremeness in even the most basic perceptual tasks. For instance, 
(Coenen & Gureckis, 2021)
 found that even in a simple task of drawing cards from a deck and guessing, if the deck has more red or black cards, participants ended up with samples that were not representative of the original deck. Instead, people stopped information sampling and made their choices based on unrepresentative samples. The samples they retained were polarized -they either had a higher proportion of red cards or black cards than that in the real deck (which had an even 50/50 proportion).
This finding points to a more basic cognitive process that might produce polarized and extreme beliefs, which is the process of gathering new information. As opposed to social processes that impact supposedly objective individual-level beliefs, the basic process of forming even perceptual beliefs may drive a level of polarization and extremism. To test this possibility, 
Kvam et al. (2022)
 reanalyzed several older studies on perceptual decision-making and replicated the same finding: on different kinds of basic perceptual tasks, when people are compelled to choose between two options, their sampled information pools were more polarized and extreme than the true information distribution (supplementary material, 
Kvam et al., 2022)
.
So why do people's beliefs become polarized and extreme when gathering information to make choices between options? In making choices, people need to make a compromise between the speed and the accuracy of the choice. If a person completely prioritizes accuracy, they would forever continue sampling information and their beliefs would asymptotically approach the information in the environment (assuming perfect belief updating). On the other hand, if one completely prioritizes time (that is, minimizing the time required to make any decision), they would end up not bothering to sample information at all, and would simply make choices based on their prior knowledge. Most decisions are somewhere in the middle, balancing accuracy and speed to make efficient but effective decisions. Established models of decision theory resolve this trade-off using the general framework of random walk / diffusion processes 
(Ratcliff et al., 2016;
Busemeyer et al., 2019;
Brunton et al., 2013)
. This approach suggests that to optimize the speed-accuracy tradeoff, people (and animals) collect information to a pre-specified threshold of favorability, after which they choose the option favored by the information and move onto the next task 
(Bogacz et al., 2006)
. These models are based originally on the sequential probability ratio test (P. L. 
Smith & Ratcliff, 2015)
, where the relative strength of evidence for the options available determines changes in belief relative to the threshold(s) 
(Wald & Wolfowitz, 1949;
Edwards, 1965)
. As illustrated in 
Figure 1
, a decision-maker using this approach iteratively samples information that supports either option A or option B until the relative balance of evidence between A and B crosses the threshold of choice. When that happens (and in this example, the evidence supports option A), the decision-maker selects option A and stops searching for new information.
When choosing between two options, a decision-maker is incentivized to rationally engage in the above-outlined sequential sampling strategy where the main aim is to cross a threshold and make a decision. Crucially, in this information sampling task, extreme pieces of information are overrepresented because it only takes a few extreme pieces of information for the weight of evidence to swing to one or the other threshold 
(Figure 1
). At the same time, moderate information does not move the balance of evidence much and is thus under-sampled.
As a consequence, this decision process creates a polarized distribution of evidence, rather than a distribution that reflects the true information in the decision-maker's environment 
(Kvam et al., 2022;
Kvam, 2024)
 However, choice is not the only task that drives information sampling. In other scenarios, the goal might instead be to estimate the difference between two options or to provide independent assessments of potential prospects. In contrast to threshold sampling in the choice-task, people whose goal is to evaluate the difference between options might instead be driven to seek precision. In this case, a person will perform best when they have low-variance information that allows them to minimize the error in their comparison between the two options. We therefore refer to this as a comparison task (previously referred to as an estimation task in 
Kvam et al., 2022)
: the goal is to evaluate and respond to the relative goodness of two options, as opposed to selecting one over the other.
Likewise, asking participants to rate each option independently may lead to different patterns of information search or weighting. Incentivizing independent ratings may lead to a focus on understanding each option as opposed to contrasting them against one another. This is illustrated in the literature on preference reversals in risky choice 
(Lichtenstein & Slovic, 1971;
Tversky et al., 1990)
, where participants arrive at different apparent preferences depending on


Figure 2
Diagram of the three studies and how they were used to inform one another.
whether they evaluate each option independently or make decisions between pairs of options.
Instead of sampling differences, people who are asked to evaluate options independently might instead focus on positive and negative aspects of each option to form a holistic evaluation of each one. Like evaluating the magnitude of differences, such a process might focus on reducing variance of the evaluations. We refer to this as a rating task: the goal is to arrive at an overall evaluation of an individual option and assign it a holistic rating, rather than compare it against any other options -though participants may naturally do so when multiple options are on screen 
(Hsee et al., 1999)
 Unresolved issues and project rationale
Each of these tasks requires a person to sample and incorporate new information into their beliefs. However, there are several key limitations to existing studies examining how response goals or task structure relate to information sampling (e.g., 
Coenen & Gureckis, 2021;
Kvam et al., 2022)
. First, contentious issues in real life involve several criteria or dimensions on which options are evaluated. For example, when considering two materials to mine, it's not only their respective energy output that matters, but also their environmental impact and ease of extraction/transportation. Naturally, these different factors lie on different and largely non-comparable dimensions, making them difficult to compare objectively. However, people can still arbitrate and prioritize between them. In the current research, we factored in this ecologically valid facet of real-life information spaces.
Second, information in real life usually pertains to only one option or another, rather than to both simultaneously. It is relatively rare to see information presented as "A is X better than B" -instead, information about A and B is presented separately, and the comparison is left up to the decision-maker to construct. Even in cases where a comparison is drawn, information about competitors is often vague or nonspecific. Advertisers might present a comparison as "Product A is x% better than the leading brand" rather than specifically referring to whatever B
is, making the relative-comparison information impoverished relative to the specific information about individual product features. As a result, much of the information in our environments inform our beliefs or preferences about only one option at a time. descriptions of an option that need to be interpreted. Even when this information is presented, a simple "gist" or summary may be stored in place of the detailed quantitative descriptions a decision-maker is presented with 
(Brainerd & Reyna, 1990;
Reyna & Brainerd, 1991)
.
Eventually, this information must be turned into a trigger for a decision or evaluation -meaning that its persuasive value or impact on beliefs might still be similar to quantitative information. 


Table 1
Representative examples of issues under each category of dilemma.


Category Representative example Affect-Rich
Pursue gene therapy or immunotherapy to save aliens from a deadly virus.


Affect-Poor
Mining for the mineral Xenon in Location A or B. Politically Charged Allowing immigrant aliens into the city or not. Risky Settling in city A or B based on earthquake frequency.


Investment
Investing in flood prevention infrastructure now or spend money later on flood response.


Study 1: Collecting judgment criteria
The three studies we ran aimed at eliciting ecologically valid reasons for favoring or disfavoring available choice options (Study 1, quantifying how these reasons affected people's beliefs and attitudes about their options (Study 2), and then using this to characterize what types of information people sampled while pursuing choice, comparison, or rating goals (Study 3).
All three used a set of 40 dilemmas, each with a pair of options for actions to take in response to the description. These dilemmas used an alien group in the vignette to reduce prior biases that participants may bring if interacting with more real-world scenarios. Across dilemmas, we varied the domain of decision and affective content in order to obtain patterns of behavior that generalized across many important types of decisions. Examples of five categories of decision problems are shown in 
Table 1
, and presented in full in supplementary materials.
Study 1 aimed to elicit ecologically valid pieces of evidence on which people could make their judgments across the 40 unique dilemmas. To do so, the study drew responses from a participant pool and conducted a qualitative analysis to retain the pieces of information most frequently mentioned. This approach aimed to attenuate systematic researcher bias in stimulus choice and improved the quality and plausibility of the information presented to participants in study 3. In total, 30 participants from the University of Florida undergraduate student pool were recruited (M = 19.33, SD = 2.32). The sample included 20 participants who identified as female and 10 as male.
Participants were presented with 40 dilemmas each. For each dilemma, they were given a short description of the type of dilemma being faced, then asked to describe three possible reasons which might help them evaluate the two option (for example, mining at Location A or B; see the supplement for the full list). In total, we gathered approximately 90 pieces of information on which to evaluate options in each dilemma. After collecting these reasons, we conducted a qualitative analysis with the help of two undergraduate research assistants and retained the 12 most frequently mentioned criteria for each dilemma. In this qualitative analysis, we merged similar information criteria together. For example, if, when evaluating the choice of mining Materials A and B, one participant mentioned "cheap to mine" while another participant mentioned "low cost" then these responses were coded as the same piece of information and the count for that piece of information was incremented. Additionally, we retained criteria such that half of them were positive attributes (for example, "material A/B is environmentally friendly") while the other half were negative ("material A/B is dangerous to extract"). This allowed us to account for valence effects of the information units and examine the effects of negative versus positive information. We retained 40 (dilemmas) x roughly 12 (criteria) for approximately 480 unique criteria/information pieces in total.
At the conclusion of this study, the criteria/pieces of information for each dilemma were added to an "evidence bank" from which participants in subsequent studies could sample. This allowed us to randomly sample from participant-generated information in each dilemma, providing an ecologically-based approach to supplying participants with qualitative information to consider.


Study 2: Rating judgement criteria
The next step in crafting an experiment and model of qualitative information sampling was to understand the impact that each criterion/piece of information had on participants' beliefs or preferences. Because each piece of information generated by the participants in Study 1 could be somewhat vague, Study 2 sought to quantify the persuasiveness of each one by gathering ratings from an independent set of participants.
To elicit these quantitative metrics for all the criteria and all the dilemmas, we presented new participants with each dilemma accompanied by a single piece of information. We then measured how likely a person was to choose one option or another based on the single piece of information, allowing us to assess how it impacted their beliefs or preferences. As we describe below, this change in choice probability can then be transformed into how "persuasive" a piece of information is by transforming the probability difference into a shift in log-odds of selecting one option over the other. As the optimal strategy in many environments, log-odds form the basis of most dynamic models of decision-making 
(Wald & Wolfowitz, 1949;
P. L. Smith & Ratcliff, 2015)
 and are thought to correspond directly to the evidence that participants consider when making their choices. This transformation therefore provides a quantitative metric for comparing different pieces of information and evaluating how the strength of information relates to information sampling during decision-making or other judgment tasks.
In addition to the shift in beliefs, we also assessed how extreme, persuasive, and positive/negative (that is, the direction and extent of valence) participants perceived each piece of information to be. This allowed us to examine the general relationships between extremeness and persuasiveness, as well as how they varied between positive pieces of information versus negative ones.


Method
A total of 207 participants were recruited from the undergraduate psychology subject pool at the University of Florida. We removed data for 27 participants because they either requested it or did not finish the study (Final N = 180, Age mean = 19.02, SD = 1.73). The sample included 120 participants who identified as women, 57 as men, 2 as nonbinary, and 1 who preferred not to answer.
Participants rated each piece of information on how extreme and persuasive it was on scales from 0 (not at all) to 100 (extremely). They also indicated how negative or positive the criteria were on a scale from -100 (extremely negative) to 100 (extremely positive). Lastly, ratings on how likely each criterion/piece of information (independently, on its own) was to lead participants to choose one option or another were also noted on a scale from 100 (certain to choose this option) to 0 (certain to choose the opposing option) -we refer to these as likelihood ratings. Each participant was shown each of the 40 dilemmas one-by-one. Each dilemma was repeated twice, such that participants saw one piece of information for each of the choice options on separate trials.


Results
Although the primary purpose of this study was to generate distributions of likelihood ratings for each of the pieces of information from Study 1, there are some interesting analyses to run on the relationships between different types of ratings. Specifically, we examined the relationships among likelihood ratings, persuasiveness ratings, positivity/negativity, and extremeness of each piece of information. We present these briefly before returning to the log-odds analysis that enables the focal tests of this paper.
Correlations between all focal variables are depicted in 
Figure 3
. Since likelihood ratings were captured on a scale from 0 to 100, scores below 50 meant that the person disliked the displayed option given the piece of information, but would still favor an alternative (i.e., the piece of information would encourage them to choose another option). We transformed the scale to factor in the implication that the closer a rating was to zero, the more likely a person was to choose something versus remain neutral. Thus, we converted the scale so that it ranged from 50-100 instead of 0-100 so that scores would reflect the extent to which a piece of information persuaded people to make a choice-either the option shown or an alternative. To do so, all scores below 50 were inverted such that an original score of 40 would become a transformed rating of 60, a score of 20 would be come a transformed rating of 80, and so on.
We refer to these as the "transformed likelihoods" and the untransformed values as "raw likelihoods" below. Correlations between these variables are depicted in 
Figure 3
. These likelihood ratings quantify the support that each qualitative piece of information lends to the given options on the same scale.
In general, the relationships were strongest between valence (positivity and negativity) and raw likelihood, indicating that positive information made participants more likely to choose


Figure 3
Correlations among variables measured in Study 2.
an option and negative information made them more likely to choose another option -as we should expect. Likewise, ratings of persuasiveness were strongly related to likelihood of choice based on that piece of information. Perhaps the most interesting relationship was between extremeness and persuasiveness (r =.58), which suggests that extreme information is also the most persuasive -a finding which forms the basis of our predictions about when people will stop collecting information and make their choices 
(Figure 1
).


Quantifying evidence
The problem with having an ecologically-valid (and therefore, heavily qualitative) bank of criteria/information is that it is unknown how much each piece of information influences a participant's decision process (for example, how much more likely is a person to choose mining in location A after reading that "Mine A causes low environmental damage"). Study 2 addresses this issue by ensuring that each piece of information that participants could consider for each option and each dilemma had accompanying quantitative ratings. This approach was based on work on information distortion 
(DeKay et al., 2009)
, where independent ratings form a baseline from which to quantify expected belief change based on each piece of evidence participants consider. These ratings allowed us to numerically estimate the expected change in belief that would occur if any given reason or piece of information were presented to participants.
Formally, the change in choice probability was translated into the log-odds change associated with each piece of information. The transformation from probability rating p to log odds LO was:
LO = log p 1 − p
(2)
This allowed us to take the judgments for pieces of information and add them together even though the changes in probability are not additive nor linear. The cumulative change in beliefs across multiple pieces of information should, theoretically, be proportional to the sum of their log odds 
(Chan & Darwiche, 2005;
Ashinoff et al., 2022;
Kvam & Pleskac, 2016)
. This transformation therefore allowed us to take separate evaluations of separate pieces of information and predict what their cumulative effect should be in terms of the balance of evidence. Also note that the same piece of information can confer different likelihoods to different options. For example, "Banning weapon sales reduce mass shooting incidents" might move the balance of evidence towards "Ban the weapon" by +0.4 but "Not banning weapon sales reduce mass shooting incidents" might only move it towards "Don't ban the weapon" by +0.1 simply because some information might be more persuasive for some options. Since we collected likelihood ratings independently for each option-information pair, we are able to model this widespread aspect of information where the same information can translate to supporting different (even opposite) beliefs 
(Plous, 1991;
Nyhan & Reifler, 2010)
 based on one's prior inclinations 
(Cook & Lewandowsky, 2016)
.
Furthermore, the log-odds values allowed us to not only calculate the balance of evidence that people retained in Study 3 but also to assess how information was truly distributed in the information environment of each dilemma. Doing so was important because in the current research, polarization and extremeness are defined in relation to the true underlying information distribution. Thus, with data from Study 2, it was finally possible to compute polarization and extremeness scores for each participant and condition even with qualitative information. Evaluating how different experimental manipulations affected these metrics, as well as the overall patterns of information sampling, was the main goal of Study 3.


Study 3: Manipulating information search bias
In the focal study of this paper, we allowed participants to sample information freely as they pursued one of three assigned goals: choice, comparison, or rating. This new study was set up to explore how sampling multidimensional information about options separately and considering qualitative rather than quantitative information affected patterns of information search across the three conditions. We already proved through simulations 1 that the mathematically optimal (and therefore, the rational) strategy to finish each task leads to differing levels of P&E -heightening for choices and decreasing for comparisons and ratings.
We focused on two main outcomes: how many pieces of information participants sampled (in total), and how extreme the information they sampled was upon conclusion of the information search process. The latter was measured in terms of how different the distribution of information was relative to a random sample (KLD / log-likelihood), how extreme participants' views should be based on the information they sampled (variance), and a measure we did not preregister that describes the degree of bimodality in the sample of information they collected.
At the end of the survey, participants' trait-dogmatism and need for structure scores were measured 
(Altemeyer, 2002;
Neuberg & Newsom, 1993)
. Dogmatism is the inclination of a person to maintain beliefs even in presence of countervailing evidence and has been connected to reduced information sampling 
Schulz et al. (2020)
. Need for structure, on the other hand, has been connected to the threshold parameter in dynamic decision making 
Evans et al. (2017)
. The PNS is further divided into two subscales: a desire for structure (liking structure and unambiguity) and a reaction to lack of structure (disliking the absence of structure).
With the data from Studies 1 and 2, it is possible to extend previous findings to a task where qualitative information about each option was sampled separately, as shown in 
Figure 2
.
Based on this previous work and the simulations presented above (1), we predicted that (1) the choice condition will result in more polarized distributions of information, relative to the comparison and rating conditions;
(2) that the variance of the information people collect in the decision condition will be greater than the other conditions; and (3) that people in the decision condition will collect less information than in the rating or comparison conditions.
In addition to these predictions about information sampling, we also anticipated -based on previous results 
(Schulz et al., 2020)
 -that dogmatism will be related to lower information sampling and greater polarization (higher KLD), while the two subscales of need for structure will predict information sampling in opposing directions. Specifically, we expect that desire for structure will predict lower thresholds and thus less information sampling and greater polarization, while reaction to lack of structure will correspond to greater information sampling and less polarization. These hypotheses are pre-registered at https://osf.io/ueg6q/?view_only=af1c8f029106451eb81ad58552c3c22e.


Method
The procedure for Study 3 corresponded closely to previous work by 
Kvam et al. (2022)
, allowing it to serve as a conceptual replication and extension of the effect of choice goals on information search. The addition of independent samples (separately informing participants about their options), qualitative information, and addition of the rating condition extend the generality of the effects under investigation and should clarify or qualify the conditions under which they appear to manifest. Participants were presented with the same alien world paradigm described above: they were instructed to help a friendly alien civilization resolve the types of dilemmas shown in 
Table 1
. The 40 dilemma/trials included 10 affect-poor, 8 affect-rich, 11 politically charged, 4 risky, 5 investment, and 2 attention-check dilemmas in each condition. All dilemma descriptions are included in the supplementary materials. Participants were randomly assigned to one of the three conditions -choice, comparison, or rating -and had the freedom to sample as much or as little information as they wanted before entering their judgments.


Procedure and Participants
At the end of the survey, participants' dogmatism and personal need for structure scores were collected using Qualtrics. Dogmatism was measured by a 7-point Likert scale 
(Altemeyer, 2002)
 with 20-items (al pha = 0.89,). Personal need for structure 
(Neuberg & Newsom, 1993)
 was measured by a 6-point Likert scale, with 12 items (α = 0.81). We additionally collected demographic information related to age, gender, income, and education, as well as political orientation and perceived social status.


Analyses
All analyses were conducted in a Bayesian way, using MCMC sampling to create a posterior distribution of parameter estimates that describes the uncertainty around estimates of different effects. Where possible, these Bayesian analyses used hierarchical/mixed-effects modeling to account for individual-level variance, and uninformative group-level priors to allow the data to have maximal influence over our conclusions. The code for the analyses as well as the original data files are provided on the study's OSF page (osf.io/2f8qc).
As outlined above, we tested for two features of bias in information sampling: the overall shape of the distribution of information that participants sampled (unimodal vs bimodal), which we refer to as polarization and operationalize with the negative log-likelihood of the observed data given the true sampling distribution; and the variance of sampled information, which we refer to as extremeness. These preregistered analyses were carried out as described. In addition, we included a third analysis that was aimed at better understanding the shape of the distribution of sampled information -namely, the bimodality coefficient 
(Pfister et al., 2013;
. This was intended to supplement the polarization analysis based on likelihoods and give insight into how the true distributions of information differed from the that of sampled information, as opposed to merely measuring the degree of difference.
Likewise, we computed the variance of the observed distribution of evidence samples for each condition and divided it by the variance of the true distribution -this provided our measure of extremeness. It can be quantified as such:
Extremeness = Var(sampled information) Var(true information)
(3)
Both polarization and extremeness were calculated based on the balance of evidence reached in each trial by each participant. An example of how balance of evidence is calculated for a particular trial is shown in 
Figure 2:
 (1) the probability of choosing an option after seeing a single piece of evidence/information is converted to a change in log-odds (Study 2); (2) the summed log odds of all pieces of evidence a participant saw is used to compute their final state at the end of the sampling process for the trial (Study 3); and (3) the summed log odds were used to compute likelihoods, variance, and bimodality metrics presented below. With approximately 80 participants in each condition, 40 trials resulted in well over 2,000 trials per condition from which to calculate polarization and extremeness even when we removed trials where participants did not sample at all.


Figure 4
After sampling some information about the dilemma, participants were to either choose one of the two options (Left; Choice condition), estimate the extent to which one option was better than the other (Middle; Comparison condition), or indicate the extent to which they liked the two options separately (Right; Accumulation condition) Specifically, to calculate divergence or likelihood (KLD), we first generated the "expected" distribution of information on each trial. This was computed by first identifying the number of samples from each option on each trial, then generating 1000 sets of random draws from the stimulus for each human trial. For example, if a participant sampled 3 pieces of information for option A and 4 for option B before making their response, the simulation randomly sampled 3 pieces of information for option A and 4 for option B (from the overall set of 12 pieces of information available for that particular dilemma) one thousand times and stored the log odds of the likelihood ratings from each simulation run. These ratings served as the true distribution of information (bottom-middle of 
Figure 2
) in relation to which we were able to calculate the likelihood of the observed data (using Equation 1) and extremeness (using Equation 3).
The divergence metric was computed by taking the total log odds from the information that participants sampled on each trial (a single value) and computing the density of the expected distribution at the location of the observed data. This gave us a probability density value describing the likelihood of the observed data given a random sample from the true distribution, Pr(observed | true). This was then transformed into a negative log-likelihood, essentially giving us a model-fit metric of how well the distribution created by a random sample accounted for the observed data 1 .
Calculating the negative log-likelihood of the observed data on each trial allowed us to calculate the overall negative log-likelihood of any subset of the observed data given the expected distributions, allowing us to compare divergence across participants and conditions.
To control for individual differences in divergence -and ensure that the results were not driven by a few individuals -we then ran a mixed-effects Bayesian ANOVA that treated participants as random factors and condition as a fixed factor. Lastly, we also ran a Bayesian regression predicting individual-level divergence with individual differences in dogmatism, need for structure, and political ideology. Below, we present the results of these analyses.


Transparency and Openness
Data are provided at osf.io/2f8qc. We provide the raw data as well as processed data file.
The processed data files can be derived from the raw data as detailed in the readme file. The results reported in the following section depend on both the raw data and the processed data.
We used R, JASP, and MATLAB to generate results -the code is available on the OSF repository. We also preregistered our research design and hypotheses. This was done after some of the data had been collected but before any analyses were conducted or any data was seen by the researchers. These can be accessed using the pregistration link at osf.io/ueg6q. As new issues or ideas were added to the project, we deviated from the preregistration slightly -those deviations are listed below.


Deviations from preregistration
There were a few key differences between the study we ran and the preregistered version of the experiment. First, our data removal criteria were initially too strict, and had initially filtered over 40% of responses. Instead, we relaxed a criterion regarding non-click trials (where participants that did not sample any information on more 10 percent of the trials were removed) so that we simply threw out particular trials rather than throwing out all the data for participants with a few non-click trials. This resulted in far more data for analysis while preserving the integrity of the data set.
Second, we added one analysis to our results that was not preregistered. In addition to the K-L Divergence / log-likelihood ratio -which measures the difference between the expected and observed distributions of sample -we wanted a measure that could provide information on the shape of the observed distributions. With likelihoods alone, it was hard to tell why a particular sample diverged from the expected distribution. For example, even if the sampled information distributions were more tightly centered (higher peak, and therefore, less polarized) than the true distribution, KLDs could have been high, which would lead to incorrectly inferring high polarization when the exact opposite was true. To preemptively correct for this, we also quantified polarization as the degree of bimodality using the bimodality coefficient BMC 
(Ellison, 1987)
. The BMC measures the degree of bimodality in a set of samples by comparing the kurtosis k and skewness s of the sample distribution and correcting for sample size n:
BMC = s 2 + 1 k + 3•(n−1) 2 (n−2)•(n−3) .
(4)
To examine the effects of task order on information sampling, we asked participants to complete one additional condition upon conclusion of the main task. This allowed us to explore how starting in a choice, comparison, or rating condition affected performance in subsequent conditions -for example, if starting in a rating condition led to greater information sampling in a subsequent choice condition. For brevity, we report only the amount of information sampling (number of pieces of information sampled) for the first condition to avoid contamination from order effects reported below. Analyses of the second condition each participant completed are reported in the "Exploratory analyses" subsection.


Results
All analyses were carried out in MATLAB, R (R Core Team, 2021) and JASP (JASP Team, 2023). In the results that follow, BF refers to the Bayes Factor to include a predictor in the model. BF values greater than 3 correspond to weak support for including the factor, those greater than 10 constitute moderate support, and those greater than 30 correspond to strong support. Conversely, a BF smaller than 0.33 gives weak support to exclude the factor from the model, and smaller than 0.10 corresponds to moderate support for the null (exclude factor), and smaller than 0.033 corresponds to strong support for the null / excluding the factor. In classical terms, a BF greater than or equal to 3 is often treated similar to statistical significance (p < 0.05), but generally has more desirable properties like quantifying the degree of support both for and against the null 
(Wagenmakers, 2007
 overwhelming support for the hypothesis that information sampling increased in the latter condition. Likewise, the Bayes factor for the comparison between choice and rating conditions was over 10,000, indicating strong support for a difference in information sampling between these conditions. There was no apparent difference between comparison and rating conditions, and the Bayes factor for the comparison between these conditions was inconclusive with a value of 1.28. In terms of raw information sampling, both the comparison and rating conditions elicited greater information search than choice.


Figure 5
Distribution of information sampled in the choice (left), comparison (middle), and rating (right) conditions, compared to the information that we would expect from a random sample of information that is matched on sample size (dotted black lines).


Polarization and extremeness
For each of these measures, we report a mean estimate, a 95% highest density interval 
[HDI]
, and a Bayes factor [BF] quantifying the degree of support for or against the comparison.
We calculated the measures globally for the three conditions as well as modeled them hierarchically so that we accounted for individual-level variances.
The values for each condition along with the 95% HDI -or in the case of the BMC, the  
Table 2
 Metrics for polarization and extremeness. KLD = the negative log likelihood of the observed data given the expected distribution, BMC = bimodality coefficient, HDI = highest-density interval of Bayesian posterior distribution, CI = confidence interval obtained from a bootstrapping procedure to estimate the uncertainty of the bimodality coefficient. While divergence is the most efficient way to contrast two distributions, it does not tell us how exactly the distribution of samples in the choice distribution differed from those of the other conditions (or the expected distribution). Is the divergence in the middle of the distribution or at the tails? To better understand the shape of the sampled information, our bimodality coefficient analysis supplemented the divergence analysis. The bimodality coefficient quantifies the degree of bimodality in the data -allowing us to clarify why and how the choice condition diverged from the true information as opposed to merely quantifying the degree of divergence.
Because the BMC is computed using the raw (measured) skewness and kurtosis (Equation 4), it is a point-estimate and there is not an inherent measure of its uncertainty. To get a measure of uncertainty, we calculated a bootstrapped 95% CI by drawing 20,000 resampled data sets of the exact same size. For each of these resampled data sets, we drew the same number of data points as there were in each distribution -in this case, n = 2093 for the choice condition, n = 2269 for the comparison condition, and n = 2361 for the rating condition. These samples were drawn with replacement, allowing us to understand the effect of shuffling the data set while retaining the same sample size. Once this was done, we calculated the 2.5 and 97.5 percentiles of the 20,000 samples to obtain a 95% CI on the BMC for each condition.
The result is shown on the right of 
Table 2
 To test the extremeness of the information collected in the three conditions, we carried out the variance-ratio analysis described above. Values greater than 1 indicated that the information collected was more extreme than the true environment while values less than 1 indicated less extreme information than the true environment. The choice condition again showed greater variance than either the comparison condition or the rating condition: with a standard deviation averaging M = 0.051 (95% HDI = [0.049, 0.054]) higher than the comparison condition and M = 0.033 (95% HDI = [0.030, 0.035]) higher than the rating condition. This provides strong evidence that choice tasks resulted in the most extremeness in sampled information, followed by rating and comparison conditions. Compared to a true representative sample of information from the environment, the choice condition was not substantially different (HDI included 1), while the comparison condition and rating condition resulted in less extreme information (HDI was below and excluded 1) than we would expect from a random sample.
The latter finding is perhaps just as interesting as the outcomes of the choice condition.
Not only are the estimation and rating condition manipulations able to counteract the effect of choice, but they can even yield patterns of information search that are substantially more precise (low-variance) than the true information distribution. We can infer from this that the pattern of information search when participants are asked to rate each option separately tends to favor stopping when the information is unusually certain -exemplifying the concept of a low-variance information search strategy.
A visual depiction of the distributions resulting from each condition is provided in 
Figure 1
. Although not as distinctive as the quantitative tests, the visual properties of these distributions line up with the results shown in 
Table 2
: namely, that the choice condition has the more widely dispersed pattern of information, while comparison and rating conditions have distributions more closely concentrated around zero.


Individual Differences
Turning to individual differences, we evaluated factors that may predict polarization.
The idea is to characterize individuals who are particularly strongly disposed toward extreme or polarized information sampling. As before, we use the trial-level negative log-likelihood as the measure of polarization, averaging its value within participants to get an individual-level mean divergence score. We regressed this divergence score on dogmatism, personal need for structure (2 subscales: Desire for Structure and Reaction to Lack of Structure), and political ideological inclinations in the economic and social spheres (liberal-conservative). Overall model comparisons showed that the best fitting model is one that only includes dogmatism as the predictor (BF model = 4.52), but it only marginally predicts divergence when controlling for the other factors (BF inclusion = 0.69; 
Table 3
).
Next, we evaluated if the same individual differences predict how much information people seek out. The dogmatism-only model again predicted information sampling (BF model =  
Table 4
 shows. In other words, even after controlling for political ideologies (in the social and economic spheres) and personal need for structure, each unit increase in trait dogmatism predicted sampling approximately 20% fewer pieces of information (-1.21) than the average (5.4).


Exploratory analyses -order effects
To test how initial goals could carry over into subsequent behaviors, we asked participants to complete a second condition following the main task. Because the main task was run between subjects, this yielded a total of 6 possible sequences of conditions: choice then comparison, choice then rating, comparison then choice, comparison then rating, rating then choice, or rating then comparison.
To evaluate the interactions between condition and order, we ran a mixed-effects Bayesian ANOVA. This compared different models, including main effects of condition only, main effect of order only, and a model with both main effects and an interaction. The mixed-effects component allowed us to disentangle the effects of shuffling individual participants around between conditions from the effects of taking a condition first or second.
Overall, the most-favored model was the one with only condition as the only predictor (BF = Likewise, analyzing the data from both conditions did not change any of the conclusions we drew for polarization or extremeness. We provide the code for carrying out these analyses on the Open Science Framework, but the results are essentially the same as those presented in 
Table 2
.


Discussion
This set of studies aimed to evaluate people's information sampling behavior in choice, comparison, and rating tasks to identify how these varying goals affect beliefs. Despite no differences in the underlying distribution of information they were sampling from, participants' decisions about when to keep sampling and when to stop sampling led to differences among conditions in the patterns of information collected and considered. Overall, we found that participants sampled less information when their goal was to choose between options. The information that they collected in the choice task led them to be more polarized and more extreme than the information they collected when completing a comparison or rating task.
Conversely, the rating and comparison conditions resulted in a distribution of information that had lower polarization (and, non-significantly, lower bimodality) and lower extremeness than we might expect from random information sampling. More specifically, they actually reduced the variance or extremeness of beliefs that participants formed relative to the true information in their environment. As a result, participants in these conditions were forming more precise, low-variance beliefs than those in the choice condition. This suggests that these sampling-goal interventions can work to increase how informed people are (increased information sampling) as well as reduce the degree of polarization and extremism among a set of decision makers.
Beyond the information search biases induced by different conditions, this paper provides one of the first investigations into how people search for and accumulate qualitative information. Some value-based choice paradigms will present distinct options and base the rate of accumulation on participants' own ratings of the options 
(Lee & Usher, 2023;
Edmunds et al., 2020;
Krajbich et al., 2012)
, but not of the attributes under consideration. In work on information distortion, it is common to collect attribute ratings as a way to understand how information is (mis)interpreted or distored as it is integrated into an overall opinion about the available choice options 
(Bond et al., 2007;
DeKay et al., 2009;
DeKay, 2015)
. Our work takes this a step further, using independent attribute ratings to make an inference about the persuasiveness or extremeness of each piece of information as it is collected. This naturally creates much more noise in the resulting distributions of information due to disagreement between participants on how much weight an individual piece of information should carry.
However, estimating and quantifying the impact of qualitative information -as we did here -is necessary to understand the structure of information search in ecologically valid settings 
(Kihlstrom, 2021)
.


Theoretical inspirations and contribution to literature
As 
Heft (2001)
 argues, it is more appropriate to create research designs which factor in active human-environment interactions, centering ecological validity as a crucial facet of good design. Our work follows that suggestion by creating a task in which participants were able to do self-directed information sampling. They were able to sample information about either option as many or as few times as they wished, and take as much time as they wanted in giving their responses. Besides the self-directed nature of the task, the project also attempts to incorporate ecological validity by providing qualitative information -originally generated by our participants -on multiple criterion in the trial. Indeed much of our real-life information spaces are filled with that sort of information. From product reviews and political campaign ads to TV news and small-scale gossip, the world of information is often qualitative and subjective.
Finally, the very process by which we quantified the qualitative pieces of information -getting likelihood-to-choose ratings from a participant pool -adds to the project's ecological validity.
Incorporating qualitative information quantified as such and allowing participants to sample on their own accord, thus, aims to include Heft's recommendations on a socioecological approach to research.
This research also involves mathematical modeling and simulations to formally specify the theoretical argument, operationalize polarization and extremism, and to generate some of the results. To address psychology's replication crisis, as well as to generate a more robust science, many have recommended computational/theoretical modeling for inducing theory-building 
(Guest & Martin, 2021;
van Rooij, 2019)
. The current research implements these suggestions and actually carries out a strong test of formal psychological theories using well-specified models. For instance, on the theoretical level, our major hypothesis that polarization and extremism is reduced in a comparison task and rationally created in a choice task comes from a mathematical model of information search under these two tasks 
(Kvam et al., 2022)
. Devoid of mathematical modeling, the implications of theories remain hidden. Therefore, modeling conventions instruct researchers to derive model-implied behavior through simulations even before testing the phenomenon of interest empirically. We followed this convention, generating model-implied behavior through simulations as depicted in 1. On the operationalization front, polarization and extremism are clearly defined in mathematical notation (Equations 1 and 4).
Besides computationally modeling our explanandum and crafting the empirical study such that it has high ecological validity, our project identifies a novel way to reduce polarization and extremeness -instead of making people choose between options, having them rate the preferability of each option comparatively or independently turned out to reduce both polarization and extremism. While 
Kvam et al. (2022)
 point out that a comparison task ("how much better is A than B") attenuates polarization and extremism, and while the task indeed induced markedly lower P&E and extinguishing extremeness completely, it did not fully remove polarization. As such, the rating task offers another alternative to choice tasks for the goal of reducing P&E beyond the comparison task. Concretely, these two novel tasks may be useful in elections to reduce the widespread societal divisions and tensions between social groups especially during election cycles. Lastly, we also contribute a novel way to operationalize polarization -using the Bimodality coefficient. Existing measures of polarization rely on feeling thermometers, mean differences measured on Likert-scales 
(Jost et al., 2022)
, and K-L divergence 
(Kvam et al., 2022)
, but quantifying bimodality allows us to paint a richer picture of exactly how the distributions differ.


Individual differences
We also tested whether variation in polarization and sampling behavior is explained by individual differences in political ideological inclinations (liberal/conservative), cognitive need for structure and a tendency towards dogmatism. Mainly, we found that dogmatic people -those who are steadfast in their worldviews and patterns of thinking --explore the information space minimally by under-sampling relative to less dogmatic people. This can often (though not always) be a problem because dogmatic people feel more superior about their beliefs 
(Toner et al., 2013)
 and are also more likely to spread their opinions in chains of communication 
(Navarro et al., 2018)
. Thus, contentious issues might end up being unduly influenced by dogmatic actors within social networks and these actors might not correct their non-representative views because every time they sample new information, they sample fewer pieces than others, continuing the cycle of misinformation.


Limitations and Future Directions
The attribute rating and information accumulation paradigms used here are closely related to those commonly used to study information distortion during decision-making 
(Bond et al., 2007;
DeKay et al., 2009)
. However, our findings in the comparison and rating conditions Another key contribution our paradigm makes is to the diversity of voting procedures.
First-past-the-post or single-vote systems used in most U.S. elections correspond closely to the choice condition, while the comparison and rating conditions correspond more closely to what we would call score voting procedures 
(Brams & Fishburn, 2002)
. In these methods of voting, rather than simply picking their favorite, participants assign a numerical rating to each candidate, and the candidate with the highest aggregate rating wins the election. incentives result in more cautious decisions and greater information search 
(Heitz, 2014;
Reed, 1973;
Vickers & Packer, 1982)
. These can therefore produce more careful and representative information search in choice conditions 
(Kvam et al., 2022)
. However, it is unclear what the trigger for a rating or comparison might be -it may be the case that these responses are driven by racing accumulators 
(Heathcote & Matzke, 2022)
 or by another type of sampling process where a response is generated by comparing the estimated error against a criterion 
(Yeung & Summerfield, 2012)
. How to manipulate these criteria to produce greater search or more representative information sampling is an open question.
Likewise, the interaction between prior biases and information search is an open question. Our simulations suggest that bias will primarily determine the allocation of decision-makers to options, but not the shape of the conditional distributions of responses 
(Kvam et al., 2022)
. However, if information is distorted during choice, comparison, or rating, then such a story is likely too simplistic to capture how people's biases drive the information search process. In particular, it is unclear exactly how bias should interact with the stopping rules for comparison and rating conditions -in large part because the exact rules remain a mystery.
Our studies were careful to make the choice options relatively balanced -that is, there was no "correct" or "incorrect" option in any given choice pair. However, the rate at which participants are able to identify superior choice options is clearly an important question relevant to the debate between choice, comparison, and rating incentives. Follow-up studies should explore, through both simulations and experiments, how well each set of task instructions allow participants to find the "best" option when there is an objectively defined answer. If choice incentives allow participants to more frequently identify the best option, then it may not always be desirable to use comparison or rating instructions.
In these studies, we also sought to balance the proportions of negative and positive information in the information environment. However, this may not reflect the ecological structure of the world. Research on the evaluative information ecology typically shows that most information in the world is positive (vs. negative) 
(Koch et al., 2016;
Alves et al., 2017)
.
Thus, it may be interesting to create a true information distribution that still favors each choice equally, but that features more positive (vs. negative) pieces of information about each choice.
Continuing to "factor in" all these sources of variance that exist in the world, in order to model the ways that decision makers interact dynamically with them, would allow us to iteratively build toward the real decisions that people make and the information search goals that maximize their efficacy.


Constraints on Generality
Although several dilemmas used in the study bare resemblance to real-world issues, many of the trials deliberately avoided descriptions that would tie them closely to real-world issues. This was done to reduce prior or start point bias and draw focus to information sampling bias, which was the main focus of this paper. However, it may naturally affect the generalizability of these results. More pertinent to generalizability, all three of our studies included undergraduate student samples at the University of Florida. Future work will benefit from checking for cohort effects. Older participants may integrate information slower and/or be more cautious in general (thereby deploying wide thresholds in the choice condition), which may yield different results. Another boundary condition to evaluate is how these tasks influence information sampling for highly partisan people. While our sample had some ideologically extreme participants, they were in the minority. Highly opinionated people may draw even more polarized and extreme samples in the choice condition while also not being influenced too much by the comparison/rating interventions.
The hypotheses and predictions we made here were derived from well-tested formal theories of cognition that apply to a wide range of phenomena, meaning that they should be relatively robust 
(Forster, 2000;
Turner & Smaldino, 2022;
Donkin et al., 2022)
. Furthermore, these results replicate and extend a stable effect discovered in a well-powered initial study 
(Kvam et al., 2022)
 and the sample sizes here also yield high power, meaning that they are unlikely due to simple noise. There are also multiple metrics we examined -including overall sample volume, likelihoods, variance, and higher-order statistical moments of the resulting distributions -which all point to the same conclusions 
(Table 2)
. Given the strong theoretical basis and methodological characteristics of our studies, we suggest that the results are likely to be highly robust and generalizable compared to a typical psychological "effect" 
(Yarkoni, 2022)
.


Conclusion
The pattern of information search that is incentivized by making a choice clearly follows a "high variance" strategy -capitalizing on information that tips the balance of evidence sharply toward one option or the other to rapidly trigger a response. By contrast, rating and comparison tasks can be characterized as "low variance" strategies -where precise (moderate) information is most expedient to stopping information sampling and giving a response. These diverging incentives can instead drive information search toward greater sampling and more careful responses. Harnessing these task goals as interventions offers the opportunity to create more informed voters and reduce (political) polarization. This paper provides another step toward an ecological understanding of the impact of information search goals -and, we hope, toward addressing contemporary problems like polarization and extremism that threaten the social fabric of our societies.
A
sample of 250 participants (Mean age = 19.70, SD = 3.29) were recruited from the University of Florida psychology student pool (171 people participated in the study in 2022 and another participated in 2024). The sample included 156 participants who identified as women, 76 as men, 3 as trans, 1 as none of the three, and 1 who preferred not to answer, besides a few who didn't respond.


95% CI -are shown inTable 2. On all three measures, the choice condition was the highest values -indicating that information search in this condition resulted in the most polarized,extreme, and bimodal sets of information. For the divergence score, the divergence was greater in the choice condition than in the comparison condition (M di f f = 0.107, 95% HDI = [0.097, 0.116]) and the rating condition (M di f f = 0.085, 95% HDI = [0.075, 0.094]), indicating that information search in the choice condition was substantially divergent from the true underlying information-spread.


. Overall, bimodality was highest in the choice condition, lower in the comparison condition, and lowest in the rating condition. The difference in BMC between choice and comparison conditions excluded zero (M = 0.0212, 95% HDI = [0.0108, 0.0322]) as did the comparison between choice and rating conditions (M = 0.0164, 95% HDI = [0.0053, 0.0276]). This indicates that the choice condition yielded a more bimodal distribution of information than the comparison or rating conditions. Ultimately, it tells the same story as the analysis based on log odds: the distribution of evidence collected by participants in the choice condition, despite coming from the same underlying information environment, resulted in greater polarization.


raise a critical question: is information distorted in the same way during other tasks as it is during choice? Information distortion may be an adaptive response to the choice condition, as the inertia generated by an initial piece of information can accelerate a decision-maker toward a choice in favor of one option or the other -that is, a biased interpretation of incoming information may yield faster (if biased) decisions. Yet, no such incentive is present in the comparison and rating conditions. It may be possible to reduce or eliminate the subjective distortion of information that arises in sequential decision paradigms -such as those used in information distortion -by setting different goals. These same manipulations may help to better understand the representations of incoming information and how they are altered by current beliefs or preferences, dissociating choice-motivated distortion from state-dependent interpretations of incoming information.


Various efforts have promoted this as a fair, interpretable, and viable alternative to the way elections are currently carried out (W. D. Smith, 2023), but our results reveal additional insights relevant to the debate. Specifically, they suggest that score voting procedures would increase information search (yielding more informed voters) as well as reduce the prevalence of polarization and extremeness in elections where they are implemented. Given the present state of polarization worldwide and in the U.S., we suspect this is a possibility worth exploring, even if only in small-scale interventions or local elections. On the side of more basic science, an exploration of other cognitive factors governing information sampling might help refine and extend our understanding of the role of information search goals. It is well-established in the evidence accumulation literature that accuracy


). Lastly, the Highest Density Interval (HDI) is the Bayesian equivalent to confidence intervals; typically, if the 95% HDI for an estimate does not include a particular value (say, 0), we can conclude that the null is not among the most credible values for that parameter.Before turning to the information participants collected, it is informative to look simply at how much information they collected in each condition. In the choice condition, participants, on average, collected 4.78 pieces of information (95% HDI = [4.56, 5.01]) about each option,
while collecting 6.22 pieces (95% HDI = [5.96, 6.48]) in the comparison condition and 5.75
pieces (95% HDI = [5.53, 5.97]) of information in the rating condition. The Bayes factor for the
comparison between the choice and comparison conditions was over 10,000, indicating
Amount of information sampled.


Table 3
3
Predicting polarization (operationalized as divergence) with individual differences.
95% Credible Interval


Table
Information sampling (number of information-gathering clicks) and individual differences
95% Credible Interval
Coefficient
BF inclusion
Beta SD Lower
Upper
Intercept
1.00
5.43 0.31
4.87
6.03
Dogmatism
15.06 −1.21 0.49 −1.92
0.00
PNS_DFS
0.32
0.09 0.27 −0.06
0.85
PNS_RLS
0.32
0.09 0.26 −0.10
0.85
Economic ideology
0.24 −0.02 0.09 −0.29
0.09
Social ideology
0.23 −0.01 0.08 −0.24
0.13
8.05), which was favored strongly over all models including order as a predictor (maximum BF
< 0.01). This indicates that the order in which conditions were presented did not have a
particularly strong impact on information sampling -only the condition itself.


Note that the expected log-likelihood ratio forms the basis of the KLD
(Kullback & Leibler, 1951)
. This method allows us to quantify divergence at the individual trial level, rather than attempting to approximate the integral of comparisons between observed and expected distributions across the entire space.














Dogmatic behavior among students: Testing a new measure of dogmatism




B
Altemeyer








The Journal of Social Psychology




142


6
















Why good is more alike than bad: Processing implications




H
Alves






A
Koch






C
Unkelbach








Trends in cognitive sciences




21


2
















The effects of base rate neglect on sequential belief updating and real-world beliefs




B
K
Ashinoff






J
Buck






M
Woodford






G
Horga








PLOS Computational Biology




18


12


1010796














Partisans without constraint: Political polarization and trends in american public opinion




D
Baldassarri






A
Gelman








American Journal of Sociology




114


2
















Reaffirmation of social comparison views of choice shifts: Averaging and extremity effects in an autokinetic situation




R
S
Baron






G
Roper








Journal of Personality and Social Psychology




33


5


521














Network propaganda: Manipulation, disinformation, and radicalization in american politics




Y
Benkler






R
Faris






H
Roberts








Oxford University Press












The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks




R
Bogacz






E
Brown






J
Moehlis






P
Holmes






J
D
Cohen




10.1037/0033-295X.113.4.700






Psychological Review




113


4
















Information distortion in the evaluation of a single option




S
D
Bond






K
A
Carlson






M
G
Meloy






J
E
Russo






R
J
Tanner








Organizational Behavior and Human Decision Processes




102


2
















Gist is the grist: Fuzzy-trace theory and the new intuitionism




C
J
Brainerd






V
F
Reyna








Developmental Review




10


1
















Voting procedures. Handbook of social choice and welfare




S
J
Brams






P
C
Fishburn








1














Rats and humans can optimally accumulate evidence for decision-making




B
W
Brunton






M
M
Botvinick






C
D
Brody








Science




340


6128
















Cognitive and neural bases of multi-attribute, multi-alternative, value-based decisions




J
R
Busemeyer






S
Gluth






J
Rieskamp






B
M
Turner








Trends in Cognitive Sciences




23


3
















A distance measure for bounding probabilistic belief change




H
Chan






A
Darwiche








International Journal of Approximate Reasoning




38


2
















The distorting effects of deciding to stop sampling information




A
Coenen






T
Gureckis




10.31234/osf.io/tbrea


















Rational irrationality: Modeling climate change belief polarization using bayesian networks




J
Cook






S
Lewandowsky








Topics in cognitive science




8


1
















Predecisional information distortion and the self-fulfilling prophecy of early preferences in choice




M
L
Dekay








Current Directions in Psychological Science




24


5
















Distortion of probability and outcome information in risky decisions




M
L
Dekay






D
Patiño-Echeverri






P
S
Fischbeck








Organizational Behavior and Human Decision Processes




109


1
















Observing effects in various contexts won't give us general psychological theories




C
Donkin






A
Szollosi






N
R
Bramley








Behavioral and Brain Sciences




45
















Accumulation is late and brief in preferential choice




C
E
Edmunds






D
Bose






C
F
Camerer






T
L
Mullett






N
Stewart




10.31234/osf.io/sa4zr






PsyArXiv
















Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing




W
Edwards




10.1016/0022-2496(65






Journal of Mathematical Psychology




2


2
















Effect of seed dimorphism on the density-dependent dynamics of experimental populations of atriplex triangularis (chenopodiaceae)




A
M
Ellison








American Journal of Botany




74


8
















Need for closure is associated with urgency in perceptual decision-making




N
J
Evans






B
Rae






M
Bushmakin






M
Rubin






S
D
Brown








Memory & cognition




45


7


















L
Festinger




A theory of cognitive dissonance




Stanford university press




2












Political polarization in the american public




M
P
Fiorina






S
J
Abrams








Annu. Rev. Polit. Sci




11


1
















World without mind




F
Foer












Random House








Key concepts in model selection: Performance and generalizability




M
R
Forster








Journal of mathematical psychology




44


1
















Assessing bimodality to detect the presence of a dual cognitive process. Behavior research methods




J
B
Freeman






R
Dale








45














How computational modeling can force theory building in psychological science




O
Guest






A
E
Martin




10.1177/1745691620970585








Perspectives on Psychological Science




16


4
















Winner takes all! what are race models, and why and how should psychologists use them?




A
Heathcote






D
Matzke








Current Directions in Psychological Science




31


5
















Ecological psychology in context: James gibson, roger barker, and the legacy of william james's radical empiricism




H
Heft








Psychology Press












The speed-accuracy tradeoff: history, physiology, methodology, and behavior




R
P
Heitz








Frontiers in Neuroscience




8


150














Interpersonal attraction, social identification and psychological group formation




M
A
Hogg






J
C
Turner








European Journal of Social Psychology




15


1
















Preference reversals between joint and separate evaluations of options: A review and theoretical analysis




C
K
Hsee






G
F
Loewenstein






S
Blount






M
H
Bazerman








Psychological bulletin




125


5


576














The origins and consequences of affective polarization in the united states. Annual review of political science




S
Iyengar






Y
Lelkes






M
Levendusky






N
Malhotra






S
J
Westwood








22














JASP (Version 0.18.0)[Computer software




Jasp Team




















Cognitive-motivational mechanisms of political polarization in social-communicative contexts




J
T
Jost






D
S
Baldassarri






J
N
Druckman








Nature Reviews Psychology




1


10
















Ecological validity and "ecological validity




J
F
Kihlstrom








Perspectives on Psychological Science




16


2
















Why we're polarized




E
Klein








Profile Books












The rise in political violence in the united states and the damage to our democracy




R
Kleinfeld






















A general valence asymmetry in similarity: Good is more alike than bad




A
Koch






H
Alves






T
Krüger






C
Unkelbach








Journal of Experimental Psychology: Learning, Memory, and Cognition




42


8


1171














The attentional drift-diffusion model extends to simple purchasing decisions




I
Krajbich






D
Lu






C
Camerer






A
Rangel




10.3389/fpsyg.2012.00193






Frontiers in Psychology




3














On information and sufficiency. The annals of mathematical statistics




S
Kullback






R
A
Leibler








22














The Tweedledum and Tweedledee of dynamic decisions: Discriminating between diffusion decision and accumulator models




P
D
Kvam








Psychonomic Bulletin & Review
















Rational inference strategies and the genesis of polarization and extremism




P
D
Kvam






A
Alaukik






C
E
Mims






A
Martemyanova






M
Baldwin








Scientific Reports




12


1
















Strength and weight: The determinants of choice and confidence




P
D
Kvam






T
J
Pleskac




10.1016/j.cognition.2016.04.008






Cognition




152
















Value certainty in drift-diffusion models of preferential choice




D
G
Lee






M
Usher








Psychological Review




130


3


790














Self-conscious emotions: Embarrassment, pride, shame, and guilt




M
Lewis








Handbook of emotions


New York, NY, US




The Guilford Press










3rd ed








Reversals of preference between bids and choices in gambling decisions




S
Lichtenstein






P
Slovic








Journal of Experimental Psychology




89


1
















When extremists win: Cultural transmission via iterated learning when populations are heterogeneous




D
J
Navarro






A
Perfors






A
Kary






S
D
Brown






C
Donkin








Cognitive Science




42


7
















Personal need for structure: Individual differences in the desire for simpler structure




S
L
Neuberg






J
T
Newsom








Journal of Personality and Social Psychology




65


1


113














When corrections fail: The persistence of political misperceptions




B
Nyhan






J
Reifler








Political Behavior




32


2
















Good things peak in pairs: a note on the bimodality coefficient




R
Pfister






K
A
Schwarz






M
Janczyk






R
Dale






J
B
Freeman








Frontiers in psychology




4


700














Biases in the assimilation of technological breakdowns: Do accidents make us safer




S
Plous








Journal of Applied Social Psychology




21


13
















R: A language and environment for statistical computing




R Core Team












Computer software manual












Austria
Vienna
















Diffusion decision model: Current issues and history




R
Ratcliff






P
L
Smith






S
D
Brown






G
Mckoon








Trends in Cognitive Sciences




20


4
















Speed-accuracy trade-off in recognition memory




A
V
Reed








Science




181


4099
















Fuzzy-trace theory and framing effects in choice: Gist extraction, truncation, and conversion




V
F
Reyna






C
J
Brainerd








Journal of Behavioral Decision Making




4


4
















Dogmatism manifests in lowered information search under uncertainty




L
Schulz






M
Rollwage






R
J
Dolan






S
M
Fleming








Proceedings of the National Academy of Sciences




117


49
















Cultural fault lines and political polarization




Y
Shi






K
Mast






I
Weber






A
Kellum






M
Macy








Proceedings of the 2017 acm on web science conference


the 2017 acm on web science conference


















Diffusion and random walk processes. International encyclopedia of the social & behavioral sciences




P
L
Smith






R
Ratcliff








6














The case for score voting




W
D
Smith








Constitutional Political Economy




34


3
















Explaining Group Influence: The Role of Identity and Emotion in Political Conformity and Polarization




E
Suhay




10.1007/s11109-014-9269-1






Political Behavior




37


1
















Differentiation between social groups: Studies in the social psychology of intergroup relations




H
E
Tajfel








Academic Press












An integrative theory of group conflict




H
E
Tajfel






J
C
Turner








The Social Psychology of Intergroup Relations


















Feeling superior is a bipartisan issue: Extremity (not direction) of political views predicts perceived belief superiority




K
Toner






M
R
Leary






M
W
Asher






K
P
Jongman-Sereno








Psychological Science




24


12
















Mechanistic modeling for the masses




M
A
Turner






P
E
Smaldino








Behavioral & Brain Sciences




45














The causes of preference reversal




A
Tversky






P
Slovic






D
Kahneman








The American Economic Review


















Psychological science needs theory development before preregistration




I
Van Rooij










Psychonomic Society












Effects of alternating set for speed or accuracy on response time, accuracy and confidence in a unidimensional discrimination task




D
Vickers






J
Packer




10.1016/0001-6918(82






Acta Psychologica




50


2
















A practical solution to the pervasive problems ofp values




E.-J
Wagenmakers








Psychonomic Bulletin & Review




14


5
















Bayes solutions of sequential decision problems




A
Wald






J
Wolfowitz








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






35














Confirmation biases in selective exposure to political online information: Source bias vs. content bias




A
Westerwick






B
K
Johnson






S
Knobloch-Westerwick








Communication Monographs




84


3
















Polarization in the contemporary political and media landscape




A
E
Wilson






V
Parker






M
Feinberg








Current Opinion in Behavioral Sciences




34
















The generalizability crisis




T
Yarkoni








Behavioral and Brain Sciences




45


1














Metacognition in human decision-making: confidence and error monitoring




N
Yeung






C
Summerfield








Philosophical Transactions of the Royal Society B: Biological Sciences




367
















Political violence experts warn that american democracy is in danger ahead of 2024 election




O
Yousef























"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]