You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Everyday decision-making can often rely on habitual behavior, but sometimes demands deliberative planning. Habits provide a computationally cheap problem-solving strategy, but they cannot flexibly adapt to changes in the environment. Planning, on the other hand, provides greater flexibility at a greater computational cost. The tension between habits and plans is particularly useful for understanding the processes underlying development changes in decision-making across the lifespan such as the emergence of flexible planning during adolescence 
(Decker, Otto, Daw, & Hartley, 2016)
, and its' subsequent decline in older adulthood 
(Eppinger, Walter, Heekeren, & Li, 2013)
.
The distinction between habits and plans has been formalized within a reinforcement learning framework 
(Daw, Niv, & Dayan, 2005;
Dolan & Dayan, 2013;
Sutton & Barto, 1998)
 which has also been invoked to understand changes in decision-making across the lifespan 
(Raab & Hartley, 2018)
. Within this framework, habits are operationalized as a form of "model-free control", and plans are operationalized as a form of "model-based control".
Model-free control is a modern form of Thorndike's law of effect 
(Thorndike, 1911)
: actions leading to rewards are more likely to be repeated. This is implemented by updating cached reward predictions based on trial and error. Critically, these cached predictions require interaction with the environment, and therefore cannot quickly adapt to environmental changes, such as decreases in the value of a particular decision. Model-based control uses an internal model of the environment, akin to a "cognitive map" 
(Tolman, 1948)
, that specifies the reward and state transition structure. This model allows for prospective simulation 
(Doll, Duncan, Simon, Shohamy, & Daw, 2015)
 of sequential decision paths, and permits flexible adaptation in response to environmental changes by updating the model. Flexible decision-making is a critical skill throughout the lifespan. This is why recent research has focused on methods to boost model-based control within the individual. Efforts to increase model-based control using incentives have been successful 
(Kool, Gershman, & Cushman, 4 2017)
, and this is also true for people with elevated symptoms and traits of psychopathology 
(Patzelt, Kool, Millner, & Gershman, 2019a)
. These findings demonstrate the possibility of boosting model-based control in older adults. Indeed, normative aging is associated with modelbased learning deficits such as a failure to maintain stable task representations 
(Hämmerer et al., 2018
) and a diminished capacity to integrate uncertainty into decision-making 
(Eppinger et al., 2013;
Nassar et al., 2016
).
In the current investigation, we use a sequential decision-making task to ask a critical question about the pliability of model-based control in older adulthood: can we use incentives to boost model-based control in older adults? In the next two sections, we review prior research on modelbased control across the lifespan and introduce a theoretical framework for understanding the factors governing arbitration between model-free and model-based controllers. We then report two behavioral experiments comparing younger and older adults using a parametric estimate of model-based control under different incentive conditions.


Model-based control across the lifespan
Research into model-based control shows that it follows a developmental arc throughout the lifespan. Decker and colleagues 
(Decker et al., 2016)
 demonstrated the apparent absence of model-based control during childhood (ages 8-12), its' emergence during adolescence (ages 13-17), and a further bolstering of model-based control during early adulthood (ages 18-25). This study is complemented by the work of Eppinger and colleagues (2013), who investigated modelbased control in younger versus older adults using a very similar task. They showed that older adults have model-based deficits which are acutely evident during decisions following unexpected rewards. Whereas younger adults tended to explore the task structure in this state of uncertainty, older adults did not explore the task structure, demonstrating a perseverative response pattern characterized by lower model-based control. The developmental trajectory of model-based control provides an empirical and computational foundation for theoretical accounts of cognitive 5 processes that are tuned differently across various developmental stages 
(Hartley & Somerville, 2015;
Raab & Hartley, 2018)
.
Across developmental studies of model-based control, the sequential decision-task used to measured model-based control was developed by Daw and colleagues 
(Daw, Gershman, Seymour, Dayan, & Dolan, 2011)
, and we refer to this as the Daw two-step task. The task measured model-based control as a trait within the individual that remained consistent throughout the course of the game. It was then hypothesized that state dynamics may exist that allow modelbased control to adaptively fluctuate with changes in the person's situation or environment. This hypothesis was tested in a series of experiments by Kool and colleagues 
(Kool, Cushman, & Gershman, 2016;
 where they demonstrated state-dependent fluctuations in model-based control.
In a novel two-step task design, Kool and colleagues introduced an experimental manipulation to incentivize adaptive boosts in model-based control . During the course of the game, some trials were "low stakes" (subjects earned the presented reward) and some tasks were "high stakes" (reward was multiplied by 5). This manipulation demonstrated that model-based control could be boosted within the individual. Moreover, recent work using the same task showed model-based deficits could be improved across a range of transdiagnostic symptoms and traits of psychopathology 
(Patzelt et al., 2019a)
. This suggests that incentives might also boost model-based control in aging adults and lead to more flexible decision-making strategies.


Metacontrol framework
As mentioned above, model-free and model-based control confer different costs and benefits. The experiments of 
Kool and colleagues (2017)
 suggest that arbitration between these two modes of control occurs via a metacontrol cost-benefit analysis. A metacontroller arbitrates between the lower cost (but potentially lower reward) model-free controller, and higher cost (but potentially higher reward) model-based controller (schematized in 
Figure 1
). To illustrate, boosting 6 model-based control in the Daw two-step task does not lead to greater reward, and therefore the metacontroller will prefer the resource cheap model-free strategy. In contrast, the metacontroller will engage model-based control on the Kool two-step task, because this will lead to greater reward. This metacontrol framework helps explain why it is advantageous to increase modelbased control in response to incentives on the Kool two-step task.
The metacontrol cost-benefit analysis also provides a framework for predicting how aging adults may respond to incentives in the two-step task. Aging is associated with declines in cognitive function 
(Luszcz, 2011)
, and it has been argued that this is due to selective engagement of cognitive resources due to their greater cost in older adults 
(Hess, 2014)
. In turn, this predicts that engagement of model-based control will be associated with greater costs in older adults.
Taken together with the work of Eppinger and colleagues 
2013
, we expect older adults to show model-based deficits, and impairments in their ability to increase model-based control in response to large incentives due to the higher costs of model-based control. If we find that older adults show model-based deficits on the Kool two-step task and/or impairments in responding to incentives, it would suggest older adults may have trouble accurately estimating the costs associated with model-based control. However, if we find the older adults can boost model-based control in response to incentives, it suggests interventions targeting model-based control may help increase goal-directed behavior in older adults.


Experiment 1


Methods


Participants
We used the TurkPrime crowdsourcing platform 
(Litman, Robinson, & Abberbock, 2017)
 to recruit participants from Amazon Mechanical Turk (AMT; Seattle, WA). Participants completed the Kool two-step task ) and a computer adaptive IQ test (CAT; 
Raven, 2000)
. They were compensated $11 (plus a possible bonus between $0 and $2.50) and provided informed consent. The study and experimental protocols followed ethical guidelines and were approved by the Committee on the Use of Human Subjects (CUHS), the Institutional Review Board (IRB) for Harvard University. A subset of 377 young adults (<= age 30) and 47 older adults (>= age 56) were selected from a larger study conducted on AMT that examined relationships between psychopathology and model-based control 
(Patzelt et al., 2019a)
; and separately, psychopathology and mental effort 
(Patzelt, Kool, Millner, & Gershman, 2019b)
. All participants were required to have U.S. residency, 90% approval rating, and 100 completed Mechanical Turk Human Intelligence Tasks. We recruited an additional 298 older adults (age >=56) from AMT and 16 were excluded for non-response on >20% of trials. In addition, participants from both younger and older adults were excluded if their computational model parameters were not estimable (N = 5), or they did not provide their gender (N = 2). Thus, the final sample was 374 younger adults (M = 26.38, SD = 2.85) and 315 older adults (M = 61.46, SD = 4.91).


Sequential decision task
Participants performed 200 trials of the two-step task developed by Kool and colleagues . This allowed us to measure increases in model-based control when comparing high stakes to low stakes 
(Figure 2A/B
). Participants randomly started in one of two first-stage states and chose one of two rocket ships (which were randomly mapped to response keys). Following this choice, the participant deterministically transitioned to either a red or purple alien planet. Upon arriving on the alien planet, the participant received a reward indicated by alien treasure. The amount of reward obtained at each planet changed randomly and gradually over the task, independently for each planet (a Gaussian random walk between 0 and +9 with SD = 2). If the participant did not respond, no reward was delivered and the task proceeded to the next trial. Each trial was randomly assigned to one of the two stakes conditions.
In the "high stakes" condition, the participant received 5 times the alien treasure reward (5x multiplier; 
Figure 1A
). In the "low stakes" condition, the participant received the displayed alien treasure reward.


Computational model
We modeled the two-step task using a dual-process reinforcement learning model that captures the mixture of model-based and model-free control exhibited in decision-making on sequential decision tasks 
(Daw et al., 2011;
Kool et al., 2016;
. The model free algorithm is SARSA( ) 
(Sutton & Barto, 1998)
, which updates the state-action pair (s,a) at step i and trial t in the following manner:
( , ) ← ( , ) + , ,
( , )
where the prediction error is defined as:
, = , + ( +1, , +1, ) − ( , , , ).
The learning rate is represented by . This captures the rate at which the participant incorporates reward feedback (i.e. low  leads to slow incorporation and high  leads to quick incorporation) and , ( , ) is an eligibility trace updated in the following way:
, ( , ) ← −1, ( , , , ) + 1.
The eligibility trace allows step 1 values to be partially updated following step 2 outcomes.


9
The model-based strategy uses a learned transition function to compute values, rather than retrieving state-action values from a cache (as used in the model-free approach):
( , ) = ( | ) ( ) + ( | ) ( )
where ( | ) is the probability of transitioning to state SB after choosing action aj, and ( ) and ( ) are the immediate reward estimates at the second-step states (note that these are not dependent on actions since there is no second-step action).
The mixture of model-free and model-based control is governed by a weighting parameter w:
( , ) = ( , ) + (1 − ) ( , )
The w parameter was fit independently for the low stakes and high stakes conditions, which allowed for comparison of model-based control across stakes.
Finally, the probability of choosing action a given state s on a trial is given by a softmax function:
` ( , ) = ( [ ( , , )+ • ( )+ • ( )]) ∑ ′ ( [ ( , , ′ )+ • ( ′ )+ • ( ′ )])
, where we have included two parameters to capture additional variance: motor stickiness  (pressing the same key twice), and stimulus stickiness  (choosing the same stimulus twice independent of its value).  represents the inverse temperature parameter that controls choice stochasticity. Lower values of  promote exploration and higher values promoting exploitation.
Parameters were optimized using maximum a posteriori estimation with empirical priors 
(Gershman, 2016;
. See  for expanded details concerning task design and computational model-fitting.
Kool and colleagues  compared various model formulations of the Kool two-step task and found that the stake-dependent mixture model outperformed other approaches which allowed other parameters to vary (e.g., choice inverse temperature). They showed that the change in model-based control due to stakes cannot be completely explained by other model parameters.


Bayesian analysis of model-based control
We used Bayesian linear regression to estimate the interaction between model-based control across high-and low-stakes and younger-versus older-adults. Whereas classic When the posterior is centered around 0, it is both plausible and highly probable (due to the large density over 0) that the IV(s) predict no change in the DV. Therefore, we report the posterior probability that the regression coefficient is less than or greater than 0, to indicate the probability that the interaction of stakes x age group is associated with changes in model-based control. We used the brms package (42) with the default prior σ ~ student-t(3,0,10) and regressed stakes x age group onto model-based control (w) while controlling for gender.


Results


Model-based control, stakes, and reward rate
We replicated previous studies using the Kool two-step task 
Patzelt et al., 2019a)
, showing that model-based control was greater during high stakes than low stakes, with a posterior probability >0.99 that the regression coefficient was greater than zero.
Similarly, increasing reward rate was associated with increases in model-based control, with a posterior probability >0.99 that the regression coefficient was greater than 0.


Model-based control: stakes x age group
We did not find appreciable evidence for an interaction between stakes and younger versus older adults. 
Figure 3A
 shows that both age groups had non-overlapping credible intervals and the posterior probability distribution for this interaction contained zero (76% < 0, 24% > 0), indicating there is a high probability that stakes x age group is unlikely to be associated with changes in model-based control. Moreover, we did not replicate the 
Eppinger et al. (2013)
 finding of model-based deficits in older adults, the main effect of age group regressed onto model-based control produced a posterior probability distribution roughly centered around 0 (40% < 0, 60% > 0).
. We hypothesized this divergence with Eppinger and colleagues might be due to a lower mean age in the older adults compared to the Eppinger study where older adults were ~69 years old. Thus, we restricted our sample to 77 older adults above the age of 65 (M = 68.61, SD = 3.38), but still found weak evidence of an association between age group and model-based deficits (stakes x age group interaction; 71% < 0, 29% > 0).


Discussion
In this study we asked if older adults would increase model-based control in response to incentives. We used a sequential decision-making task  with incentives to increase model-based control, and a sample of younger 
(M = 26.38,
SD = 2.85)
 and older adults (M = 61.46, SD = 4.91). Contrary to our expectations, we found that older adults did not show the same model-based deficits found by 
Eppinger and colleagues (2013)
.
Furthermore, older adults increased model-based control in response to incentives. This divergence could not be explained by differences in ages between our sample and that of 
Eppinger et al. (2013)
. We next consider the possibility that older adult MTurk workers might differ in other population characteristics.
A recent review 
(Chandler & Shapiro, 2016)
 of studies using MTurk populations suggests that our findings in older adults may be due to increased cognitive aptitude or computer literacy. Moreover, as Chandler and Shapiro note, many MTurk workers have completed several online studies, perhaps increasing their ability to perform on cognitive paradigms. Finally, sequential decision tasks have been increasingly deployed online by our lab 
(Kool et al., 2016;
Kool, Gershman, & Cushman, 2018;
Patzelt et al., 2019a)
 and others 
(Gillan, Kosinski, Whelan, Phelps, & Daw, 2016)
. Thus, we hypothesized older adults on MTurk may not show model-based deficits because, 1) they have greater technological skill, or 2) they are not naïve to sequential decision-making tasks.


Experiment 2
In Experiment 2, we sought to recruit a sample of older adults that would be naïve to the sequential decision tasks and the cognitive paradigms commonly used on MTurk. We also added a debriefing question "Have you ever done a game similar to this?". These changes allowed us to increase the probability of recruiting a sample more representative of older adults in the general population. Again, we asked if older adults would show model-based deficits, and if they would increase model-based control in response to incentives. We recruited a naïve sample through the Turkprime crowdsourcing platform of 56 older adults (M = 66.30, SD = 6.42), where one participant was excluded due to previous experience with a similar task. Of note, we began with the same age cutoff of 56 years old, but raised this to 65 or older to try and match the mean age of 
Eppinger et al., (2013)
.


Results and Discussion
Like experiment 1, we found both stakes and average reward rate were positively associated with increases in model-based control (posterior probability >0.99 that coefficient is greater than 0). The age group factor (younger versus older adults) was not associated with deficits in model-based control, with the posterior probability distribution indicating large uncertainty about the presence of an association (24% < 0, 76% > 0). In contrast to experiment 1, 
Figure 3B
 demonstrates an interaction whereby older adults did not boost model-based control in response to incentives (relative to younger adults) and the posterior probability distribution did not include zero (99% < 0, 1% > 0). These results indicate strong evidence that experimentally naïve older adults fail to increase model-based control in response to incentives.
Differences in the results between experiments 1 and 2 could not be attributed to differences in mean age.


General discussion
In two experiments, we asked if older adults would show a boost in model-based control in response to incentives. In Experiment 1, we did not find the expected pattern of model-based deficits in older adults 
(Eppinger et al., 2013)
. We recruited younger and older adults from
Amazon Mechanical Turk and found that older adults (1) boosted model-based control in response to incentives, and (2) did not show model-based deficits. We next hypothesized that older adults on MTurk had greater technological and/or cognitive aptitude due to experience with sequential decision tasks and/or other cognitive paradigms on the Amazon Mechanical Turk crowdsourcing platform.
Therefore, in experiment 2 we recruited a naïve sample of older adults. Like experiment 1, we found that older adults did not show model-based deficits, but in contrast to experiment 2, they were impaired in boosting model-based control in response to large incentives. The findings across both experiments suggest that incentives can boost model-based control in older adults, but that this may require previous experience with sequential decision-making paradigms, and in particular subjects may need previous experience with the incentive structure in order to learn it adequately.
Prior research on the effect of incentives on physical activity and cognition in older adults has yielded mixed results. For example while some have found incentives increase physical activity 
(Finkelstein, Brown, Brown, & Buchner, 2008)
, others have found both peer networks and incentives do not increase physical activity 
(Kullgren et al., 2014)
. 
Kullgren and colleagues (2014)
 hypothesize their null effect may be due to sample characteristics, such as the older adults in their study being highly educated, primarily white, and in good health. Our study may have faced similar limitations with differences in the populations. For example, MTurk older adults may be more technologically adept, have higher levels of education, or have greater cognitive ability than the naïve sample. However, another study demonstrated older adults can increase memory retrieval speed in response to incentives 
(Touron, Swaim, & Hertzog, 2007)
, suggesting that the effect in experiment 1 may not be solely attributable to practice effects or general non-naiveté of cognitive tasks.
There are two findings that suggest the lack of incentive effect in Experiment 2 is a specific deficit in using incentives to dynamically engage model-based control. First, older adults did not show model-based deficits overall, which indicates that they were engaged with the task and the deficit was specific to incentives. Second, model-based control and average reward rate were positively correlated in both younger and older adults. Together, these findings suggest that younger and older adults were both motivated and engaged with the task, but older adults in experiment 2 expressed deficits in their response to incentives.


Limitations
Our study was limited in several ways. First, we are unable to fully disentangle factors that account for differences in model-based control in older adults between experiment 1 and experiment 2. These include general cognitive ability and previous practice with decisionmaking paradigms. Second, we are unable to determine what component of the metacontroller in older adults might be defective. Their inability to boost model-based control in response to incentives may be due to a biased cost-benefit analysis and/or a deficit in the model-based controller. Third, we are unable to answer if older adults in experiment two would increase model-based control on the Kool two-step task following further practice or experience with other cognitive paradigms.


Conclusions
We studied the possibility of boosting model-based control in older adults using a sequential decision-making task across two experiments. Whereas older adults recruited from MTurk increased model-based control in response to incentives, a naïve sample of older adults did not. Our study provokes an outstanding question: can we use repeated practice with sequential decision tasks to improve goal-directed decision-making in older adults, or are the deficits expressed in experiment two trait-like and unchanging? If older adults who show deficits in their response to incentives can be trained to increase model-based control, then interventions targeting this process may hold promise for increasing cognitive ability or goaldirected decision-making. For the older adults that responded to incentives, such as the experiment 1 sample, providing incentives may be an effective approach to enhance goaldirected behavior. The first panel is a coefficient plot containing 95% of the posterior probability density around the mean for the age factor; younger and older adults both increase modelbased control in response to incentives. The second panel is the posterior probability distribution of age group x stakes interaction, which includes zero and therefore indicates lack of strong evidence for an effect. B. The first panel is a coefficient plot containing 95% of the posterior probability density around the mean for the age factor; younger and older adults both increase model-based control in response to incentives; younger adults increase model-based control in response to incentives but older adults do not (in contrast to experiment 1). The second panel is posterior probability distribution that does not include zero, and this suggests high confidence in the presence of an age group x stakes interaction.
(
frequentist) linear regression analysis typically conducts binary inference testing in the form of rejecting (or accepting) the null hypothesis, Bayesian linear regression
(Baldwin & Larson, 2016;
Gelman et al., 2013)
 provides an uncertainty distribution about the strength of the relationship(s) between independent and dependent variables. Specifically, frequentist linear regression provides a point estimate of the regression coefficients, whereas Bayesian regression provides a full posterior distribution, often summarized by the mean or median and the 95% highest posterior density (HPD) credible intervals around the mode, therefore indicating uncertainty about the regression coefficients.


Figure 2 :
2
A. At the start of each trial, participants informed about the stakes, and then made a choice between two rockets. This choice deterministically transitioned the participant to a red or purple planet and they received an alien treasure reward. B. State transition structure of the novel two-step task. Rewards changed gradually over trials on the task according to a








Acknowledgements
This project was partially supported by a training grant from the NIH Blueprint for Neuroscience 






Financial Disclosures
The authors report no biomedical financial interests or potential conflicts of interest.
 










An introduction to using Bayesian linear regression with clinical data




S
A
Baldwin






M
J
Larson








Behaviour Research and Therapy




98


















10.1016/j.brat.2016.12.016














Conducting Clinical Research Using Crowdsourced Convenience Samples




J
Chandler






D
N
Shapiro








Annual Review of Clinical Psychology




12


















10.1146/annurev-clinpsy-021815-093623














Model-based influences on humans' choices and striatal prediction errors




N
D
Daw






S
J
Gershman






B
Seymour






P
Dayan






R
J
Dolan








Neuron




69


6


















10.1016/j.neuron.2011.02.027














Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control




N
D
Daw






Y
Niv






P
Dayan




10.1038/nn1560








Nature Neuroscience




8


12
















From creatures of habit to goaldirected learners: Tracking the developmental emergence of model-based reinforcement learning




J
H
Decker






A
R
Otto






N
D
Daw






C
A
Hartley








Psychological Science




27


6


















10.1177/0956797616639301














Goals and habits in the brain




R
J
Dolan






P
Dayan




10.1016/j.neuron.2013.09.007








Neuron




80


2
















Model-based choices involve prospective neural activity




B
B
Doll






K
D
Duncan






D
A
Simon






D
Shohamy






N
D
Daw




10.1038/nn.3981








Nature Neuroscience




18


5
















Of goals and habits: Age-related and individual differences in goal-directed decision-making




B
Eppinger






M
Walter






H
R
Heekeren






S.-C
Li








Frontiers in Neuroscience




7


19
















10.3389/fnins.2013.00253














A randomized study of financial incentives to increase physical activity among sedentary older adults




E
A
Finkelstein






D
S
Brown






D
R
Brown






D
M
Buchner




10.1016/j.ypmed.2008.05.002








Preventive Medicine




47


2


















A
Gelman






J
B
Carlin






H
S
Stern






D
B
Dunson






A
Vehtari






D
B
Rubin




Bayesian data analysis


Boca Raton, FL




CRC Press








3rd ed.








Empirical priors for reinforcement learning models




S
J
Gershman




10.1016/j.jmp.2016.01.006








Journal of Mathematical Psychology




71
















Characterizing a psychiatric symptom dimension related to deficits in goal-directed control




C
M
Gillan






M
Kosinski






R
Whelan






E
A
Phelps






N
D
Daw




10.7554/eLife.11305


















Older adults fail to form stable task representations during model-based reversal inference




D
Hämmerer






P
Schwartenbeck






M
Gallagher






T
H B
Fitzgerald






E
Düzel






R
J
Dolan








Neurobiology of Aging




74


















10.1016/j.neurobiolaging.2018.10.009














The neuroscience of adolescent decision-making




C
A
Hartley






L
H
Somerville








Current Opinion in Behavioral Sciences




5


















10.1016/j.cobeha.2015.09.004














Selective Engagement of Cognitive Resources: Motivational Influences on Older Adults' Cognitive Functioning




T
M
Hess




10.1177/1745691614527465








Perspectives on Psychological Science




9


4
















When Does Model-Based Control Pay Off?




W
Kool






F
A
Cushman






S
J
Gershman








PLOS Computational Biology




12


8


















10.1371/journal.pcbi.1005090














Competition and Cooperation Between Multiple Reinforcement Learning Systems




W
Kool






F
A
Cushman






S
J
Gershman








Understanding Goal-Directed Decision Making: Computations and Circuits


R. W. Morris, A. M. Bornstein, & A. Shenhav
















Cost-benefit arbitration between multiple reinforcement learning systems




W
Kool






S
J
Gershman






F
A
Cushman








Psychological Science




28


9


















10.1177/0956797617708288














Planning Complexity Registers as a Cost in Metacontrol




W
Kool






S
J
Gershman






F
A
Cushman




10.1162/jocn_a_01263


















A Mixed-Methods Randomized Controlled Trial of Financial Incentives and Peer Networks to Promote Walking Among Older Adults




J
T
Kullgren






K
A
Harkins






S
L
Bellamy






A
Gonzales






Y
Tao






J
Zhu






J
Karlawish




10.1177/1090198114540464








Health Education & Behavior




41


1_suppl
















TurkPrime.com: A versatile crowdsourcing data acquisition platform for the behavioral sciences




L
Litman






J
Robinson






T
Abberbock




10.3758/s13428-016-0727-z








Behavior Research Methods




49


2
















Executive function and cognitive aging




M
Luszcz








Handbook of the psychology of aging


K. Schaie & S. Willis


San Diego, CA




Elsevier










7th ed.








Age differences in learning emerge from an insufficient representation of uncertainty in older adults




M
R
Nassar






R
Bruckner






J
I
Gold






S
C
Li






H
R
Heekeren






B
Eppinger




10.1038/ncomms11609








Nature Communications




7
















Incentives Boost Modelbased Control Across a Range of Severity on Several Psychiatric Constructs




E
H
Patzelt






W
J
Kool






A
J
Millner






S
J
Gershman




10.1016/j.biopsych.2018.06.018








Biological Psychiatry




85


5
















The transdiagnostic structure of mental effort avoidance




E
H
Patzelt






W
Kool






A
J
Millner






S
J
Gershman




10.1038/s41598-018-37802-1








Scientific Reports




9


1


1689














The Development of Goal-Directed Decision-Making




H
A
Raab






C
A
Hartley




R. 21
















Understanding Goal-Directed Decision Making: Computations and Circuits


W. Morris, A. M. Bornstein, & A. Shenhav




Elsevier




New York














10.1016/B978-0-12-812098-9.00013-9














The Raven's Progressive Matrices: Change and Stability over Culture and Time




J
Raven




10.1006/cogp.1999.0735








Cognitive Psychology




41


1
















Reinforcement learning: An introduction




R
S
Sutton






A
G
Barto








MIT Press


Cambridge, MA












Animal intelligence: Experimental studies




E
L
Thorndike








Routledge


Abingdon, UK












Cognitive maps in rats and men




E
C
Tolman




10.1037/h0061626








Psychological Review




55


4
















Moderation of older adults' retrieval reluctance through task instructions and monetary incentives




D
R
Touron






E
T
Swaim






C
Hertzog








Journals of Gerontology -Series B Psychological Sciences and Social Sciences




3


62
















10.1093/geronb/62.3.P149














Figure 1: A. Schematic showing how a metacontroller compares the computational cost against the reward benefit for model-based and model-free controllers. This cost-benefit analysis produces a weighting parameter (w) that expresses the probability of selecting model-based control




MBcontrol













"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]