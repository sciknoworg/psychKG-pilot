You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
In recent years, artificial agents (e.g. Siri, Alexa, Google Assistant) have started appearing more commonly in our houses. They are able to perform a huge number of autonomous activities: playing our favorite music, reminding us to take a pill or helping us to reach a friend's place. However, since these artificial agents are not embodied, they are not able to manipulate the physical world. In the near future, also robots will take part in our everyday life, as useful supportive assistants at home or at work 
[1]
. Thanks to their embodiment, robots not only will comply with our requests, but also will act directly on our environment and manipulate it 
[2]
. Therefore, it appears crucial to understand whether robots as social companions can affect basic cognitive mechanisms in humans. Some evidences showed that the mere presence of a robot influenced the behavior of a human partner, leading her/him to follow robot's recommendation in a decision-making task 
[3]
, or even to afford a greater peri-personal space 
[4]
. Beyond the mere presence, the actions of a robotic agent actually have an impact on human's behavior. For example, when performing a target discrimination task with the iCub robot, participants' attentional orienting was biased by robot's gaze direction similarly to when human eyes are presented 
[5,
6]
. Similar findings have been shown also for joint actions. For instance, when performing a joint Simon task 
[7,
8]
, participants coordinated their actions with a non-humanoid robot, however this was true only when they believed that the robot was controlled by a human being 
[9]
.
Together, these findings demonstrated that robots are able to modify humans' cognitive mechanisms, such as decision-making and joint attention, in a similar fashion as they occur in human-human interaction. However, other mechanisms of human cognition are still poorly investigated in HRI; one of this is Sense of Agency (SoA). SoA has been defined as the feeling of control that we experience over our own actions and their outcomes 
[10]
. Given its pivotal role in the embodied nature of the Self, disruption of SoA may lead to unpleasant consequences, like the misrecognition of ourselves as the authors of our thoughts, feelings and actions. For instance, disruption of SoA has been reported in schizophrenia patients, who find difficult to distinguish between self-and externally generated events 
[11,
12]
.
In the context of HRI, Ciardo and colleagues demonstrated that SoA over self-generated actions is reduced when performing a task with a robotic agent 
[13]
. Specifically, when participants performed costly actions (i.e. losing a various amount of points) together with a robot, they rated their SoA lower compared to when they performed the same task alone. However, although interesting, these results have been obtained with explicit measures only, thus it remains unclear whether the social presence of a robot can affect SoA in humans also at an implicit level.
One of the most common implicit measure to investigate SoA is based on recording variations in time perception related to action effects (see 
[14]
 for a review). The typical result is to perceive the time interval between a self-voluntary action and its sensory consequence (e.g. a tone) as shorter in time than its actual duration. This effect is known as Intentional Binding (IB) 
[15]
, and it occurs only when people perform self-voluntary actions. Indeed, if the same action-effect chain is produced either by other people or by involuntary movements, then the IB effect is not reported 
[16,
17]
. In terms of SoA in a social context, Sahaï and colleagues 
[18]
 showed that IB for self-generated actions does not differ whether people perform the task alone or interact with another human, but it decreases when they interact with a computer.


Aim
In the present study, we aimed to investigate whether the social presence of the robot can affect SoA in humans by using an implicit measure. To this end, participants were asked to perform an IB task 
[19,
20]
 alone (Individual Condition) or with the Cozmo robot (Anki Robotics) (Social Condition). Notably, both participants and Cozmo performed the task by executing the action, i.e. the keypress, at the time of their own choice. We hypothesized that, if the social presence of the robot can actually influence participants' SoA, inducing a reduction of SoA as in Ciardo et al. 
[13]
, then participants' performance is expected to differ across conditions. Specifically, in Social blocks participants would be better in judging the position of the clock-hand compared to the Individual blocks. As a consequence, smaller or null IB was expected in the Social compared to the Individual Condition.


Materials and Methods


Participants
Seventeen right-handed young adults (mean age =22.47, sd= 3.14, 5 males) have been recruited to take part in the study. Sample size has been estimated according to previous experiments 
[19,
20]
 and to a priori power analysis indicating that a sample size of N = 12 was needed in order to detect a medium effect size [Cohen's d for repeated measures (Dz) = 0.63, alpha (one-tailed) =.05 and power = 0.80] for within-subjects comparisons. The study has been conducted in accordance with the ethical standards laid down in the 2013 Declaration of Helsinki and have been approved by the local ethical committee (Comitato Etico Regione Liguria). All participants gave written informed consent prior to the experiment. They received an honorarium of 10 € per hour for their participation. The experimental session lasted around 60 minutes. At the end of the experiment, participants were debriefed about the purpose of the study.


Apparatus and stimuli
The experimental setup consisted of a mobile Android device with the standard Cozmo application running in 'SDK enabled option' 
[21]
; one computer connected with Cozmo through the Android Debug Bridge (cosmosdk.anki.com/docs/adb.html) 
[22]
; one 21' inches screen (1920 x 1080 pixels) to display the task; two keyboards to collect responses during the experiment. Participants and Cozmo were seated side by side at approximately 60 cm away from the computer screen. A keyboard was placed in front of the participants and in front of Cozmo (see 
Figure 1
). Stimuli presentation, response collection, and the Cozmo robot were controlled with OpenSesame (see 
[13]
 for the procedure of how to integrate Cozmo).


Procedure
Participants were asked to perform the Intentional Binding task alone (Individual condition) or with Cozmo (Social Condition). They were presented with an image of the clock (10.6 ° visual angle) with a red rotating clock-hand. Each trial started with a black fixation dot on a white background for 1000 ms, followed by the image of a clock with a static clock-hand for 500 ms. Then, the clock-hand started to rotate randomly from one of the 12 five-minutes positions of the clock, in order to complete a unique full rotation in 2560 ms. At the end of each trial, participants were asked to report the position of the clock-hand at the time of the event of interest (either keypress or tone play). The task comprised four different type of blocks: two types of Baseline blocks (tone or action), and two types of Operant blocks (tone or action) (see 
Table 1
). For both the Individual and the Social Condition, each block was repeated twice; following the procedure of 
[23]
, only the Baseline-Tone block was performed once, since no action was required.


Block type Task Baseline-tone(BT)
A tone (440 Hz, 700 ms) is played at a random time while the clock-hand (length= 170 pixels) is rotating. Participants have to judge at which time on the clock the sound event occurs. No action is required.


Baseline-action (BA)
Participants have to press the spacebar at any moment while the clock-hand is rotating. They have to report the position of the clock-hand when they act. No auditory feedback occurs.


Operant-tone (OT)
Participants have to press the spacebar at the time of their own choice while the clock-hand is rotating. 250 ms after the keypress, the tone (440 Hz, 700 ms) is presented while the clock-hand is still rotating. Participants have to judge at which time on the clock the sound event occurs.


Operant-action (OA)
Participants have to press the spacebar at any moment during the clock-hand rotation. 250 ms after the keypress, the tone (440 Hz, 700 ms) is presented while the clock-hand is still rotating. Participants have to report the position of the clock-hand when they act. 
Table 1
. The Baseline and the Operant blocks.
At the beginning of each block, participants were informed whether they were performing the task alone (Individual Condition) or with Cozmo (Social Condition). If the block belonged to the Individual condition, Cozmo moved away from its keyboard and entered into the sleep mode. When a block of the Social Condition started, Cozmo was programmed to wake up and reach the keyboard. In those blocks belonging to the Social Condition, participants were instructed that if they wanted they could let Cozmo do the task alone in their place. Cozmo was programmed to tap the bar during the clock-hand rotation at a random time. The task comprised 14 blocks of 24 trials each, for a total number of 336 trials. Blocks were randomly assigned to either Individual (7 blocks) or Social Condition (7 blocks). Therefore, once in the Individual and once in the Social Condition each participant performed 1 BT, 2 BA, 2 OT and 2 OA blocks. In order to prevent any habituation effect, both Individual and Social blocks were presented in a random order within participants. A practice session of the entire task (i.e. 14 trials, one per condition) was administered. 


Data analysis
Our dependent measures were the percentages of human's and Cozmo's responses in the Social blocks and the judgment error (JE) in reporting the critical event across the Individual and the Social Blocks. To this aim, in raw data only Social blocks were considered; then, the percentages of responses for each agent were estimated only for those trials in which an action occurred and compared with a chi-square test. JEs were estimated as the difference between the position of the clock-hand reported by participants and the actual onset of the critical event (i.e. action or tone play). For Social blocks, JE was estimated only for those trials in which participants acted. Then, for each block we calculated the average JE and its standard deviation; trials in which the JE deviated more than ± 2.5. SD from the participants' mean were excluded from the analysis. After the outliers' removal, participants with a total number of valid trials lower than 24 were excluded from the subsequent analysis. According to this criterion, for action blocks four participants were excluded, whereas, for tone blocks, data of seven participants were not analyzed. Therefore, for 14 participants in action blocks, and for 10 participants in tone blocks, IB effect was estimated as the difference between the mean JE for the Baseline (Individual condition) and the mean JE for the corresponding Operant block (Social condition).
Given that JEs were not normally distributed, Wilcoxon signed-rank tests were used to compare JEs and IB across conditions (Individual, Social) and Block Types (Baseline, Operant). The threshold for level of significance was set at p< .05, rank-biserial correlation coefficient (rb) is reported as an index of the effect size. 95% confidence intervals of the means are reported.


Results
In Social Blocks, participants acted in the 75.3% of trials (95% CI [73.5%, 77%]), letting Cozmo to perform the task in their place the remaining 24.7% of trials (95% CI [23%, 26.5%]). This difference was statistically significant from chance (χ 2 = 4.468, p< .001). Interestingly, Human/Cozmo action ratio was constant across all the Social blocks in which an action was required (see 
Figure 2
).   


Discussion
In this experiment, we sought to determine whether the social presence of the robot might influence SoA for self-generated actions. To this end, we employed an Intentional Binding experiment as an implicit measure to investigate SoA. As in the standard versions of the IB task where participants knew they always were the initiator of the action 
[23]
, we let participants choose whether they wanted to press the spacebar, of let Cozmo press in their place. We predicted that, if the social presence of the robot can actually have an impact on human's SoA, participants' performance would be different across conditions, i.e. they would judge better the occurrence of self-voluntary actions when doing the task with the robot compared to when they perform the task alone.
Otherwise, if the robot does not influence humans' SoA, participants' performance in Social Condition would have mirrored the one in Individual Condition. Overall participants let Cozmo responding only in the 30% of the Social trials. This trend in responses was constant across different block types, suggesting a general attitude toward a robot. It may be possible that they perceived the social condition as a competition between themselves and the robot. If this has been the case, then participants may have been triggered to act faster than Cozmo, resulting into a lower percentage of Cozmo trials. Another possible explanation is that given the nature of the robot we used, i.e. Cozmo, participants might have perceived the robot as not competent enough to perform the task, thus they took the responsibility of the task and acted above the level of chance. Future studies should investigate these possibilities by addressing how individual differences in attitude towards the robot and perceived competence may affect the possibility to let it act. In line with previous studies 
[16,
23]
, when participants performed the task alone (Individual Condition) JEs for action events were smaller for the Baseline than for the Operant blocks, whereas, when the critical event was a tone, JEs were smaller for the Operant than for the Baseline blocks. The reversed pattern can be explained by the fact that the direction of the IB effect depends on when the critical event occurred on the temporal line in the Operant blocks.
When the critical event was the action (i.e. the keypress), since it preceded the sensory effect (i.e. the sound) on the temporal line, the actual occurrence of the action was bounded to the occurrence of the tone, leading to perceive the temporal interval between the action and the sensory outcome as longer. Thus, participants reported the action as delayed compared to a condition in which it did not produce any sensory outcome. In operant blocks, in which participants had to judge when the sound occurred, given that the tone followed the keypress on the temporal line, its occurrence was bound to the preceding event (i.e. the action). Therefore, participants perceived the temporal interval between the action and the sensory outcome as shorter. Thus, in operant blocks participants reported the tone earlier compared to when the sound is passively presented. Our results showed that the presence of the robot affected JEs only when the critical event is an action, as indicated by the lack of IB in the Social condition only. The robot did not affect JEs when the critical event was a tone. Interestingly, previous studies showed that a lack of IB is typically reported for unintentional self-generated actions 
[15,
24]
. In our Social condition for action blocks, the lack of IB was driven by a reduction in JEs both in the Baseline and in the Operant blocks, suggesting that when the robot was also in charge to perform the task, participants were better in reporting when their own action occurred. These latter results can be due to a well-known phenomenon in psychology named social facilitation, i.e. the fact that in the presence of a social companion, humans' performance is enhanced 
[25]
.
Our results suggest that the social presence of Cozmo had a double effect. Indeed, on one hand the presence of the robot led to an improvement in the evaluation of selfgenerated actions. On the other hand, it might bring to a reduction of self-agency, similarly to what occurred in human-human cooperative contexts 
[26]
.


Conclusions
In the present study, we raised the question of whether a robot, as a social companion, can have an influence on human's SoA. According to our results, participants were better in judging the occurrence of their own actions when Cozmo was also in charge to perform the task, confirming that the social presence of the robot actually influences human's agency. On the other side, in action blocks a lack of IB in Social condition compared to Individual condition correspond to a reduction of SoA. Future studies should provide further evidences about the influence of robots on human's SoA, in order to build new robotic agents well-tailored on human's cognition.
Figure 1 .
1
Experimental setup.


Figure 2 .
2
Percentages of responses in each Social condition.


Figure 3 .
3
Panel (A): Mean JEs for Baseline and Operant block as a function of condition (Individual, Social) when the critical event was the action (action blocks). Panel (B): Mean JE for Baseline and Operant block as a function of condition (Individual, Social) when the critical event was the tone (tone blocks).


Action blocks. Results showed that when participants performed the task alone, JEs were smaller in the Baseline (M= -28.250, SD=33.39, 95% CI [-43.94, -12.43]) than in the Operant blocks (M= 26.829, SD=112.61, 95% CI [-30.16, 83.67]), W= 13.00, p= .011, rb= -.75. However, this was not true for the Social Condition, as no differences occurred in JEs between the Baseline (M= -15.257, SD= 38.08, 95% CI [-35.58, 4.19]) and the Operant blocks (M= 5.082, SD= 68.73, 95% CI [-30.775, 41.468]), W=25.00, p= .091, rb= -.524 (see Figure 3, Panel A). Moreover, results showed that JEs marginally differed across conditions for Baseline blocks only, W= 21.00, p= .049, rb= -.60 (Individual: M= -28-250, SD= 33.39, 95% CI [-43.94, -12.43]; Social: M= -15.257, SD= 38.08, 95% CI [-35.58, 4.19]). No differences in JEs across conditions occurred for Operant blocks, W= 49.00, p= .855, rb= -.07 (Individual: M= 26.829, SD= 112.61, 95% CI [-30.16, 83.67]; Social: M= 5.082, SD= 68.73, 95% CI [-30.775, 41.468]). Finally, the comparison between IB effects across conditions showed a larger IB in the Individual (M= 55.080, SD= 106.30, 95% CI [2.10, 107.29]) compared to the Social Condition (M= 20.339, SD= 39.45, 95% CI [0.44, 39.52]), W= 85.00, p= .042, rb= .619. No differences JEs occurred across conditions both for Baseline, W= 21.00, p= .049, rb= -.60 (Individual: M= 44.68, SD= 44.63, 95% CI [18.66, 70.85]; Social: M= 23.61, SD= 38.95, 95% CI [1.58, 45.48]), and Operant blocks, W= 49.00, p= .855, rb= -.07
Tone blocks. Results showed that when participants performed the task alone, JEs were
larger in the Baseline (M= 44.68, SD= 44.63, 95% CI [18.66, 70.85]) then in the Oper-
ant blocks (M= -42.02, SD= 89.45, 95% CI [-96.03, 9.91]), W= 55.00, p= .002, rb= -
.75. This was the case also for the Social Condition, with larger JEs in the Baseline (M=
23.61, SD= 38.95, 95% CI [1.58, 45.48]) compared to Operant blocks (M= -59.52, SD=
105.6, 95% CI [-119.99, -0.04]), W= 48.00, p= .037, rb= -.75) (see Figure 3, Panel B).
(Individual: M= -42.02, SD= 89.45, 95% CI [-96.03, 9.91]; Social: M= -59.52 , SD= 105.6 95% CI [-119.99, -0.04]). No differences in the IB effect occurred across condi- tions, W= 30.00, p= .846, rb= .091 (Individual: M= -86.70, SD= 71.69, 95% CI [- 128.43, -46.03]; Social: M= -83.13, SD= 99.11 95% CI [-142.26, -24.25]).




















Interacting in time and space: Investigating human-human and human-robot joint action




S
Glasauer






M
Huber






P
Basili






A
Knoll






T
Brandt








19 th International Symposium on Robot and Human Interactive Communication


















Embodied artificial agents for understanding human social cognition




A
Wykowska






T
Chaminade






G
Cheng








Philosophical Transaction B




371


20150375














Differences in effect of robot and screenagent recommendations on human decision-making




K
Shinozawa






F
Naya






J
Yamato






K
Kogure








International Journal of Human-Computer Studies




62


2
















The Effect of presence on humanrobot interaction




W
A
Bainbridge






J
Hart






E
S
Kim






B
Scassellati








Proceedings of the 17th IEEE International Symposium on Robot and Human Interactive Communication


the 17th IEEE International Symposium on Robot and Human Interactive Communication
Munich, Germany, Au










Technische Universität München






gust 1-3








Neuroscientifically-grounded research for improved human-robot interaction




K
Kompatsiari






J
Pèrez-Osorio






D
De Tommaso






G
Metta






A
Wykowska








Proc


null


















Ieee/Rsj






Int




Conf. on Intelligent Robots and Systems (IROS)


Madrid, Spain




IEEE
















On the role of eye contact in gaze-cueing




K
Kompatsiari






F
Ciardo






V
Tikhanoff






G
Metta






A
Wykowska








Scientific Reports




14


1


17842














Representing others' actions: Just like one's own? Cognition




N
Sebanz






G
Knoblich






W
Prinz








88














Response coordination emerges in cooperative but not competitive joint task




F
Ciardo






A
Wykowska








Frontiers in Psychology




9


1919














When humanoid robots become human-like interaction partners: corepresentation of robotic actions




A
Stenzel






E
Chinellato






M
A
Tirado Bou






A
P
Pobil






M
Lappe






R
Liepelt








Journal of Experimental Psychology: Human Perception and performance




38


5
















Philosophical conception of the self: implication for cognitive science




S
Gallagher








Trends in Cognitive Science




4


1
















Looking for the agent: an investigation into consciousness of action and self-consciousness in schizophrenic patients




E
Daprati






N
Franck






N
Georgieff






J
Proust






E
Pacherie






J
Dalery








Cognition




65


7186














Multiple aspects in the sense of agency




S
Gallagher








New Ideas in Psychology




30
















Reduced sense of agency in humanrobot interaction




F
Ciardo






D
De Tommaso






F
Beyer






A
Wykowska








Social Robotics. ICSR 2018


Ge S. et al.


Cham




Springer




11357












Sense of agency in the human brain




P
Haggard








Nature Reviews Neuroscience




18


4
















J: Voluntary action and conscious awareness




P
Haggard






S
Clark






Kalogeras








Nature Neuroscience




5
















Intentional action: conscious experience and neural prediction




P
Haggard






S
Clark








Consciousness and Cognition




12
















Awareness of Somatic Events Associated with a Voluntary Action




M
Tsakiris






P
Haggard








Experimental Brain Research




149
















Action co-representation and the sense of agency during a joint Simon task: comparing human and machine co-agents




A
Sahaï






A
Desantis






O
Grynszpan






E
Pacherie






B
Berberian








Consciousness and Cognition




67
















Sense of agency in joint actions: influence of human and computer coactors




S
S
Obhi






P
Hall








Experimental Brain Research




211
















Subjective agency and awareness of shared actions




L
Strother






K
A
House






S
S
Obhi








Consciousness and Cognition




19
























Cozmo SDK Installation for Windows






last accessed 2019/5/22












Android
Debug Bridge










last accessed 2019/5/22








P: Sense of Agency and Intentional Binding in Joint Actions




S
S
Obhi






Hall








Experimental Brain Research




22
















TMS stimulation over the inferior parietal cortex disrupts prospective sense of agency




V
Chambon






J
W
Moore






P
Haggard








Brain Structure and Function




220


6
















Social Facilitation




R
B
Zajonc








Science




3681
















Beyond self-serving bias: diffusion of responsibility reduces sense of agency and outcome monitoring




F
Beyer






N
Sidarus






S
Bonicalzi






P
Haggard








Social Cognitive and Affective Neuroscience




1


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]