[
  {
    "topic_or_construct": [
      "forecasting accuracy"
    ],
    "measured_by": [
      "Brier score"
    ],
    "justification": "\u201cFor the scorable forecasts, Brier scores were calculated\u2026 The Brier score, B, is a proper scoring rule equal to the squared deviation between probabilities assigned to forecasts and outcomes.\u201d"
  },
  {
    "topic_or_construct": [
      "forecasting accuracy"
    ],
    "measured_by": [
      "correct classification rate"
    ],
    "justification": "\u201cTo use a perhaps more intuitive scoring rule, the correct classification rate was 94%.\u201d"
  },
  {
    "topic_or_construct": [
      "discrimination skill"
    ],
    "measured_by": [
      "normalized discrimination index"
    ],
    "justification": "\u201cUsing another standard metric, the normalized discrimination index (Yaniv et al., 1991), which computes discrimination over uncertainty\u2026 was found that 76% of outcome variance was explained by the forecasts.\u201d"
  },
  {
    "topic_or_construct": [
      "forecast discrimination"
    ],
    "measured_by": [
      "area under the receiver-operator characteristic curve (AUC)"
    ],
    "justification": "\u201cDiscrimination in both groups was very good. For instance, the slight difference in area under the receiver-operator characteristic curve (0.96 for MEA forecasts and 0.93 for non-MEA forecasts)\u2026.\u201d"
  }
]