[
  {
    "topic_or_construct": [
      "Preference for single- vs. double-blind review"
    ],
    "measured_by": [
      "7-point preference scale (1 = strongly prefer single-blind, 7 = strongly prefer double-blind)"
    ],
    "justification": "\u201cOverall, when asked to rate their preference on a 1 (strongly prefer single-blind) to 7 (strongly prefer double-blind) point scale, respondents reported a preference for double-blind review\u2026\u201d"
  },
  {
    "topic_or_construct": [
      "Perceived fairness of the review process"
    ],
    "measured_by": [
      "7-point fairness rating scale (1 = very unfair, 7 = very fair)"
    ],
    "justification": "\u201cRate each review process according to its fairness (1 = very unfair, 7 = very fair).\u201d"
  },
  {
    "topic_or_construct": [
      "Reviewer evaluation of abstract quality"
    ],
    "measured_by": [
      "9-point abstract rating scale (1 = Poor, 9 = Excellent)"
    ],
    "justification": "\u201cIn both conditions, reviewers rated each abstract on a nine-point scale from 1 (Poor) to 9 (Excellent).\u201d"
  },
  {
    "topic_or_construct": [
      "Overall judged talk quality"
    ],
    "measured_by": [
      "Composite of ratings on significance, methods, results, innovation, uniqueness"
    ],
    "justification": "\u201cThey independently rated each talk on its significance, methods, results, innovation, and uniqueness, which we, in turn, used to form a composite measure of overall judged quality.\u201d"
  },
  {
    "topic_or_construct": [
      "Overall poster quality"
    ],
    "measured_by": [
      "Average of five 7-point ratings (visual presentation, methodological quality, interpretation appropriateness, significance, originality)"
    ],
    "justification": "\u201cThey rated the posters on a 7-point scale using the following 5 dimensions\u2026 In the end\u2026 we averaged across the dimensions to arrive at an overall rating for each poster.\u201d"
  }
]