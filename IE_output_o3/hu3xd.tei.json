[
  {
    "topic_or_construct": [
      "gaze fixations",
      "eye-movement behaviour"
    ],
    "measured_by": [
      "Pupil Core mobile eye-tracker"
    ],
    "justification": "\u201cEye-trackers (Pupil Core eye trackers from Pupil Labs) were attached to the participants\u2026 Using the recording software \u2026 the eye tracker outputs the gaze \u2026 fixation data.\u201d"
  },
  {
    "topic_or_construct": [
      "hand\u2013object touch events",
      "phasing of manipulation actions"
    ],
    "measured_by": [
      "microswitch touch sensors embedded in gloves"
    ],
    "justification": "\u201cGloves contained a microswitch under the index finger to accurately record touching events\u2026 allowing accurate phasing of the cooperative manipulation based on the moments of touching and untouching.\u201d"
  },
  {
    "topic_or_construct": [
      "3-D hand movement trajectories"
    ],
    "measured_by": [
      "five-view FLIR camera array with YOLOv5 detection and Unscented Kalman Filter tracking"
    ],
    "justification": "\u201cUsing the recorded camera images of all five cameras, a custom trained \u2026 YOLOv5 model detects the hands \u2026 Subsequently, a triangulation algorithm transforms these \u2026 and the 3D AABBs are tracked using a modified Unscented Kalman Filter.\u201d"
  }
]