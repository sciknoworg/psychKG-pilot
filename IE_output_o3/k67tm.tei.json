[
  {
    "topic_or_construct": [
      "Model-free reinforcement-learning control"
    ],
    "measured_by": [
      "main effect of previous reward on Stage-1 choice in the two-step task"
    ],
    "justification": "\u201cFor Stage 1 choice\u2026 there was a main effect of last reward (signature of MF RL)\u201d \u2013 the paper treats this reward-related stay tendency in the two-step task as the behavioural measure of model-free control."
  },
  {
    "topic_or_construct": [
      "Model-based reinforcement-learning control"
    ],
    "measured_by": [
      "reward \u00d7 transition interaction on Stage-1 choice in the two-step task"
    ],
    "justification": "\u201cIf an agent is model-based, the probability of repeating a choice will depend on the interaction between the reward type\u2026 and the transition type\u2026 When humans play the two-step task, they consistently show\u2026 an interaction between reward and transition type (signature of MB RL).\u201d"
  },
  {
    "topic_or_construct": [
      "Use of action sequences"
    ],
    "measured_by": [
      "coupled repetition of Stage-1 and Stage-2 actions (and faster Stage-2 RTs) after reward in the two-step task"
    ],
    "justification": "The authors note that \u201cpeople in our task showed precisely this pattern\u2026 suggesting that they are indeed using action sequences\u201d, referring to the greater correlation of repeating Stage-1 and Stage-2 actions and faster Stage-2 reaction times following rewarded trials."
  }
]