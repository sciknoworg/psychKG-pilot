[
  {
    "topic_or_construct": [
      "Perceived moral soundness of justification/advice"
    ],
    "measured_by": [
      "7-point Likert item \"This explanation/advice is morally correct\""
    ],
    "justification": "Participants \u201crated the morality of the justification (\"This explanation is morally correct\")\u2026 on scales from 1: Strongly disagree to 7: Strongly agree.\u201d"
  },
  {
    "topic_or_construct": [
      "Perceived correctness / agreement"
    ],
    "measured_by": [
      "7-point Likert item \"I agree with this explanation\""
    ],
    "justification": "The survey included the item \u201cthe correctness of the justification (\"I agree with this explanation\")\u201d rated on the same 1\u20137 scale."
  },
  {
    "topic_or_construct": [
      "Perceived trustworthiness"
    ],
    "measured_by": [
      "7-point Likert item \"I trust the person who wrote this explanation/advice\""
    ],
    "justification": "Participants also rated \u201cthe trustworthiness of the justification (\"I trust the person who wrote this explanation\")\u201d using the 7-point agreement scale."
  },
  {
    "topic_or_construct": [
      "Perceived nuance"
    ],
    "measured_by": [
      "7-point Likert item \"This explanation/advice takes the nuances of the situation into account\""
    ],
    "justification": "Nuance was assessed with the statement \u201cThis explanation takes the nuances of the situation into account,\u201d again on the 1\u20137 agreement scale."
  },
  {
    "topic_or_construct": [
      "Perceived thoughtfulness"
    ],
    "measured_by": [
      "7-point Likert item \"This explanation/advice is thoughtful\""
    ],
    "justification": "Thoughtfulness was measured by agreement with the item \u201cThis explanation is thoughtful\u201d on the same Likert scale."
  },
  {
    "topic_or_construct": [
      "Moral language in text"
    ],
    "measured_by": [
      "Extended Moral Foundations Dictionary (eMFD) word-probability scores"
    ],
    "justification": "\u201cWe operationalize moral language using the extended Moral Foundations Dictionary (eMFD), which approximates the degree of moral themes in a text based on the prevalence of words associated with morality.\u201d"
  },
  {
    "topic_or_construct": [
      "Sentiment / positive language"
    ],
    "measured_by": [
      "VADER sentiment analysis lexicon scores"
    ],
    "justification": "\u201cAs an additional exploratory measure, we also conducted sentiment analysis using the VADER lexicon, which measures the strength and prevalence of positive versus negative sentiment in text.\u201d"
  },
  {
    "topic_or_construct": [
      "Empathy expressed in advice"
    ],
    "measured_by": [
      "Coder ratings 1\u20136 scale of empathy"
    ],
    "justification": "\u201cTwo research assistants independently coded the advice for empathy on a scale from 1: \u2018Not at all empathetic\u2019 to 6: \u2018Extremely empathetic\u2019 (Cronbach\u2019s alpha = .56).\u201d"
  },
  {
    "topic_or_construct": [
      "Moral alignment between writer and participant"
    ],
    "measured_by": [
      "Absolute difference between their moral ratings of each scenario"
    ],
    "justification": "\u201cWe measured moral alignment\u2026 by calculating the absolute differences in their moral ratings of the scenarios.\u201d"
  },
  {
    "topic_or_construct": [
      "Perceived harm of scenario"
    ],
    "measured_by": [
      "1\u201310 rating of harm dimension (Dyadic Morality prompt)"
    ],
    "justification": "The GPT prompt asked for \u201cscores between one and ten\u201d on \u201charm\u2026 derived from the theory of dyadic morality.\u201d"
  },
  {
    "topic_or_construct": [
      "Perceived help/benefit of scenario"
    ],
    "measured_by": [
      "1\u201310 rating of help dimension"
    ],
    "justification": "The same prompt asked for a numeric score for \u201chelp,\u201d representing benefits provided."
  },
  {
    "topic_or_construct": [
      "Perceived vulnerability of those affected"
    ],
    "measured_by": [
      "1\u201310 rating of vulnerability dimension"
    ],
    "justification": "GPT was instructed to rate \u201cvulnerability of those affected\u201d on a 1\u201310 scale as an intermediate reasoning step."
  },
  {
    "topic_or_construct": [
      "Perceived intentionality of the act"
    ],
    "measured_by": [
      "1\u201310 rating of intentionality dimension"
    ],
    "justification": "The chain-of-thought prompt included a 1\u201310 score for \u201cintentionality of the act.\u201d"
  },
  {
    "topic_or_construct": [
      "Ability to recognize AI authorship"
    ],
    "measured_by": [
      "Single-choice item selecting which justification/advice was AI-generated"
    ],
    "justification": "\u201cParticipants were next directed to a question in which they selected which of the four justifications they believed was written by AI.\u201d"
  }
]