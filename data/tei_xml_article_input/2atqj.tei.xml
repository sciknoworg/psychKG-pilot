<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">&quot;Reliable Organisms from Unreliable Components&quot; Revisited: The Linear Drift, Linear Infinitesimal Variance Model of Decision Making</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
							<email>philipls@unimelb.edu.au</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Melbourne School of Psychological Sciences</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">bourne School of Psychological Sciences</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<addrLine>Vic</addrLine>
									<postCode>3010</postCode>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">&quot;Reliable Organisms from Unreliable Components&quot; Revisited: The Linear Drift, Linear Infinitesimal Variance Model of Decision Making</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>decision making</term>
					<term>diffusion model</term>
					<term>accumulator model</term>
					<term>sequential-sampling model</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Diffusion models of decision making, in which successive samples of noisy evidence are accumulated to decision criteria, provide a theoretical solution to von Neumann&apos;s (1956) problem of how to increase the reliability of neural computation in the presence of noise. I introduce and evaluate a new neurally-inspired dual diffusion model, the linear drift, linear infinitesimal variance (LDLIV) model, which embodies three features often thought to characterize neural mechanisms of decision making. The accumulating evidence is intrinsically positively-valued, saturates at high intensities, and is accumulated for each alternative separately. I present explicit integral-equation predictions for the response time distribution and choice probabilities for the LDLIV model and compare its performance on two benchmark sets of data to three other models: the standard diffusion model and two dual diffusion model composed of racing Wiener processes, one between absorbing and reflecting boundaries and one with absorbing boundaries only. The LDLIV model and the standard diffusion model performed similarly to one another, although the standard diffusion model is more parsimonious, and both performed appreciably better than the other two dual diffusion models. I argue that accumulation of noisy evidence by a diffusion process and drift rate variability are both expressions of how the cognitive system solves von Neumann&apos;s problem, by aggregating noisy representations over time and over elements of a neural population. I also argue that models that do not solve von Neumann&apos;s problem do not address the main theoretical question that historically motivated research in this area.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In 1956, the great applied mathematician John von Neumann published an article based on a set of lectures given at Caltech entitled "Probabilistic logics and the synthesis of reliable organisms from unreliable components" <ref type="bibr" target="#b187">(von Neumann, 1956)</ref>. In it, he considered the effects of probabilistic variation on the fidelity with which neurons in the brain and central nervous system perform the computational task of translating perception into action.</p><p>Von Neumann identified such variation, which he associated with errors in information transmission in the central nervous system, as the principal obstacle to reliable biological computation. His solution to the reliability problem was aggregation or multiplexing: A signal carried by a single neuron might be in error, but a signal carried by a bundle of neurons was more likely to be correct than not, and the bulk of his article focused on how to characterize and bound the error in automata composed of bundles of binary Pitts-McCulloch neurons <ref type="bibr" target="#b86">(McCulloch &amp; Pitts, 1943)</ref>.</p><p>Von Neumann conceptualized neural computation in terms of elementary logic functions rather than as operations on analogue representations, but the theoretical problem he identified and his proposed solution to it remain at the heart of contemporary cognitive psychology and the way we theorize about cognitive processes and try to model them. My aim in this article is to present a new diffusion model of two-choice decision making, the linear-drift, linear infinitesimal variance (LDLIV) model, which I argue provides a more complete and satisfying solution to von Neumann's problem than do previous models of this kind. The model has many feature in common with other diffusion decision models but its particular theoretical interest is that its architecture and process assumptions correspond more closely to what we would expect from a cognitive process synthesized from and implemented by elementary neural units.</p><p>I have used von Neumann's problem as a focal point for this article because my larger theoretical aim, along with presenting and evaluating the new model, is to distinguish models that seek to provide a solution to von Neumann's problem from those that do not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Most of the published work on decision models during the past few decades has focused</head><p>on questions of comparative model fit and predictive adequacy rather than on the more fundamental theoretical questions of exactly what a model explains and how it explains it. By "how a model explains something" I mean the process assumptions or explanatory constructs from which its predictions are derived. In the Discussion section I argue that a model's ability to provide a theoretical solution to von Neumann's problem should be the primary criterion for judging a model's adequacy. I have sought to situate the new model in this larger context because I believe the theoretical content of a model is at least as important as its ability to fit data and my aim is to try to restore questions of the former kind to the center of the debate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cognition as Probabilistic Neural Computation</head><p>The idea of probabilistic variation in cognitive representations discussed by von Neumann was not a new one, but was discovered in psychology nearly 100 years earlier by <ref type="bibr">Fechner,</ref> who found there was trial-to-trial variability in whether pairs of similar stimuli were judged to be the same or different <ref type="bibr" target="#b40">(Fechner, 1860)</ref>. The work of understanding the implications of Fechner's discovery continued into the twentieth century and led to Thurstone's law of comparative judgment <ref type="bibr" target="#b165">(Thurstone, 1927)</ref> and signal detection theory <ref type="bibr" target="#b52">(Green &amp; Swets, 1966)</ref>. But even before these developments, Fechner in 1860 already had a well-developed theory of decision making based on Gauss's 1809 theory of errors <ref type="bibr" target="#b124">(Sheynin, 1979)</ref>, which substantially foreshadowed the modern theory <ref type="bibr" target="#b76">(Link, 1994;</ref><ref type="bibr" target="#b195">Wixted, 2020)</ref>. In Gauss's theory, a measurement based on an aggregation of elements, each independently subject to error, will be normally distributed. Fechner attributed the variability in same-different decisions to aggregated measurement errors of this kind. His insight was thus much as the same as von Neumann's 100 years later: Variability in cognitive representations is a reflection of aggregation over similar elements that are independently subject to error. It follows that reliability can be improved by increasing the number of elements that compose the representation, as von Neumann proposed. The idea that cognitive representations are normally distributed, which <ref type="bibr" target="#b76">Link (1994)</ref> attributes to Fechner, was carried over into the law of comparative judgment and signal detection theory <ref type="bibr" target="#b82">(Luce, 1994)</ref>, both of which, in their most common forms, assume normally-distributed representations.</p><p>As important as signal detection theory is to mainstream psychology, there is an important dimension missing from its account, which is time. If we assume, following Fechner and von Neumann, that variability in cognitive representations reflects noise or error in the neural elements that compose them, then we would expect this variability to be present not only on the time scale of behavioral decisions but on the time scale of neural events as well -that is, from moment to moment as well as from decision to decision. Long before it was possible to record decision-related neural activity from single cells in awake behaving monkeys, multiple-look psychophysical experiments performed in the early days of signal detection theory showed that discrimination accuracy improved in proportion to the square root of the number of times a brief stimulus was presented <ref type="bibr" target="#b159">(Swets et al., 1959)</ref>. A square-root law improvement is predicted if the decision is based on the sum of successive, independent, noisy representations of the stimulus. That this is so suggests the brain solves von Neumann's problem in time in the same way as it solves it in space: by aggregation. Von Neumann's solution -which is also the statistician's solution -is to improve reliability by aggregating across noisy elements that code the same sensory quantity. The results of <ref type="bibr">Swets et al.</ref> further suggest that (a) those elements are noisy or variable in time, and (b) the brain improves reliability by aggregating, or summing noisy representations over time.</p><p>These ideas were developed systematically during the 1960s and 1970s in psychology in the class of sequential-sampling decision models by authors such as <ref type="bibr" target="#b157">Stone (1960)</ref>, La Berge (1962), <ref type="bibr" target="#b3">Audley and Pike (1965)</ref>, <ref type="bibr" target="#b38">Edwards (1965)</ref>, <ref type="bibr" target="#b75">Laming (1968)</ref>, <ref type="bibr" target="#b78">Link and Heath (1975)</ref>, <ref type="bibr" target="#b183">Vickers (1970</ref><ref type="bibr" target="#b185">Vickers ( , 1979</ref>, and <ref type="bibr" target="#b93">Ratcliff (1978)</ref>. These models were inspired, in part, by the sequential statistics of Abraham <ref type="bibr" target="#b189">Wald (1947)</ref> and, while they differed from one another in points of detail , they shared the common assumptions that evidence entering the decision process is perturbed by noise or error on a shorter time scale than that of the individual decision and that the decision is made by aggregating or accumulating independent samples of evidence over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neurally-Principled Models of Decision Making</head><p>The classical sequential-sampling models were derived from theoretical principles and the best of them successfully accounted for choice probabilities (accuracy) and response times (RT) from behavioral experiments before it was possible to make recordings of decisionrelated neural activity in awake, behaving animals. When such recordings became possible technically <ref type="bibr" target="#b115">(Roitman &amp; Shadlen, 2002;</ref><ref type="bibr" target="#b163">Thompson et al. 1996)</ref>, the picture they provided was in striking agreement with the account proposed by the models. Recordings from the oculomotor cortex of monkeys performing eye-movement decision tasks typically show: (a) moment-to-moment statistical variation, reminiscent of von Neumann's "unreliable components;" (b) a progressive increase in firing rates with the time elapsing from stimulus onset, and (c) responses that are time-locked to the point at which the firing rate reaches a threshold or criterion level . Hanes and Schall argued that these properties are consistent with the idea that the neurons implement a process of evidence accumulation like that proposed by sequential-sampling models. In the intervening years the picture has become increasingly clear and has provided further support for their original insight <ref type="bibr" target="#b45">(Forstmann et al., 2016;</ref>.</p><p>As researchers have continued to probe the relationship between decision processes and their neural implementation, there has been a corresponding impetus to develop models that are more neurally realistic or more deeply grounded in neurocomputational principles.</p><p>"Neural realism" is, of course, a relative term, as neural processes can be modeled at different levels of resolution and what is realistic at one level is an oversimplification at another <ref type="bibr" target="#b47">(Gerstner &amp; Kistler, 2002;</ref><ref type="bibr" target="#b169">Tuckwell, 1988)</ref>, but, in practice, questions of neural realism have tended to focus either on the decision architecture or the decision process. By "architecture" I mean the assumptions made about how evidence for different decision alternatives is represented. By "process" I mean the stochastic process that is used to represent the accumulating evidence. The debate about architecture has mainly been about whether the evidence for different alternatives is represented by a single stochastic process or whether each alternative is represented by its own evidence state or process. The debate about process has been about whether evidence is accumulated in discrete time or continuously and whether it is continuously distributed or comes in discrete chunks . Most neurocomputational studies have assumed diffusion processes of some kind -that is, continuous-time, continuous-state Markov processes <ref type="bibr">(Rogers &amp; Williams, 1987</ref><ref type="bibr" target="#b130">/2000</ref> -and I likewise focus on diffusion models.</p><p>The emphasis on diffusion processes is a natural one theoretically, because diffusion representations can be derived from either bottom-up or top-down approaches to characterizing evidence accumulation neurocomputationally. Examples of the bottom-up approach are the Poisson shot-noise models of <ref type="bibr" target="#b132">Smith (2010)</ref> and <ref type="bibr" target="#b138">Smith and McKenzie (2011)</ref>, in which a diffusion process is obtained as the limit of processes that represent the flux in postsynaptic potentials induced by a sequence of action potentials. Examples of the top-down approach are the diffusion approximations to the mean-field dynamics of the Ising decision maker of <ref type="bibr" target="#b179">Verdonck and Tuerlinckx (2014)</ref> and the spiking neuron model of <ref type="bibr" target="#b190">Wang (2001</ref><ref type="bibr" target="#b191">Wang ( , 2002</ref><ref type="bibr" target="#b194">Wong &amp; Wang, 2006)</ref>. The Ising decision maker is a recurrent network of Pitts-McCulloch neurons like those analyzed by von <ref type="bibr" target="#b187">Neumann (1956)</ref> whereas the Wang model is a recurrent network of spiking neurons. In both models the decision process is represented as a process of energy minimization in which the stable, or attractor, states of the system correspond to decision states. The properties of recurrent models can be characterized using mean-field approximations, in which the average firing rate of neurons in a network is derived from an analysis of its global dynamics <ref type="bibr" target="#b47">(Gerstner &amp; Kistler, 2002)</ref>. <ref type="bibr" target="#b179">Verdonck and Tuerlinckx (2014)</ref> and <ref type="bibr" target="#b116">Roxin and Ledberg (2008)</ref> derived diffusion approximations to the mean-field equations for the Ising decision maker and the Wang model, respectively, using central-limit theorem arguments, which assumed the number of participating neurons is large <ref type="bibr">(Fechner's assumption)</ref>.</p><p>To date, the most widely and successfully applied model of two-choice decisions is the diffusion decision model <ref type="bibr" target="#b93">(Ratcliff, 1978;</ref><ref type="bibr" target="#b100">Ratcliff &amp; McKoon, 2008)</ref>, which represents evidence accumulation as a Wiener, or Brownian motion, process. The Wiener process is the unique member of the class of diffusion processes that is also an independent-increments process, that is, in which each new increment to the process is statistically independent of those preceding it. One of the most straightforward ways to derive the Wiener process mathematically is as the continuous-time limit of a simple random walk <ref type="bibr" target="#b42">(Feller, 1968;</ref><ref type="bibr" target="#b93">Ratcliff, 1978)</ref>, which is a Markov process in which the increments to the process are either +1 or −1. Neurcomputationally, the simple random-walk can be thought of as arising from the difference of two processes, each composed of binary Pitts-McCulloch neurons like those analyzed by von <ref type="bibr" target="#b187">Neumann (1956)</ref> and assumed by <ref type="bibr" target="#b179">Verdonck and Tuerlinckx (2014)</ref>, which individually are either firing (+1) or silent (0) at any instant. The two component processes are assumed to represent the evidence for the two decision alternatives. As a model of decision making, the Wiener process has the attractive property that it implements a continuous-time version of Wald's (1947) sequential probability ratio test <ref type="bibr" target="#b8">(Bogacz et al., 2006</ref>), which guarantees a form of statistical optimality in homogeneous environments, in which decisions are all of the same level of difficulty.</p><p>Despite the success of the diffusion model it has sometimes been seen as lacking neural realism. Its derivation, as the limit of a simple random walk implemented by populations of Pitts-McCulloch neurons, can be criticized on the grounds that such neurons radically simplify the properties of real neurons, although this has not commonly been identified as a serious problem. Indeed, most other models that propose diffusion process representations of evidence accumulation have made similar simplifying assumptions <ref type="bibr" target="#b116">(Roxin &amp; Ledberg, 2008;</ref><ref type="bibr" target="#b179">Verdonck &amp; Tuerlinckx, 2014)</ref>. In contrast, the shot-noise models of <ref type="bibr" target="#b132">Smith (2010)</ref> and <ref type="bibr" target="#b138">Smith and McKenzie (2011)</ref>, although they also abstract away from the properties of real neurons, derive diffusion process representations from the flux of postsynaptic potentials induced by a train of action potentials. Neurally-motivated critiques of the diffusion model have tended to focus either on the model architecture or the use of the Wiener processas opposed to some other process -to represent evidence accumulation. Three features of the neural processes involved in decision making not represented in the diffusion model have led to the claim it lacks neural realism:</p><p>1. Neural firing rates typically increase in cells responding to both selected and unselected decision alternatives, suggesting that evidence for competing alternatives is represented anatomically by separate processes rather than by a single process.</p><p>2. Neural firing rates saturate at high stimulus intensities, so any diffusion process model of evidence accumulation represented by firing rates should similarly be bounded.</p><p>3. Neural firing rates are never negative, so any diffusion process model of the evidence represented by them should similarly be nonnegative.</p><p>Some researchers have investigated alternatives to the single-process Wiener model that align more closely with these principles, although it remains the benchmark model that any alternative model must equal in order to be credible and, indeed, the importance of the principles themselves can be debated (see the Discussion section). <ref type="bibr" target="#b50">Gold and Shadlen (2001)</ref>, for example, in defense of single-process models, argued that a log-likelihood-ratio evidence accumulator can be obtained by taking the difference between members of pairs of mirror-image units they called "neurons and antineurons," whose activities individually are nonnegative. That being so, the requirement that neural evidence accumulation processes must be nonnegative arguably loses some of its force. However, the anatomical locus for the hypothetical signed difference process has not been identified and it is also the case that evidence for competing decision alternatives is represented separately as far downstream as the superior colliculus, which is the last neural structure before the response in eyemovement decision tasks. The existence of these anatomically late representations adds to the plausibility of the separate accumulators account.</p><p>Three main alternatives to the process and architecture assumptions of the diffusion model have been investigated:</p><p>1. Independent accumulators. Several researchers have investigated models in which evidence for competing alternatives is modeled by racing diffusion processes <ref type="bibr" target="#b81">(Logan et al., 2014;</ref><ref type="bibr" target="#b98">Ratcliff et al. 2007;</ref><ref type="bibr">Smith &amp; Racliff, 2009;</ref><ref type="bibr" target="#b166">Tillman et al., 2020)</ref>. <ref type="bibr" target="#b98">Ratcliff et al. (2007)</ref> and <ref type="bibr" target="#b143">Smith and Ratcliff (2009)</ref> called these models dual diffusion models, which is the terminology I adopt here. Other accumulator model architectures, like the simple accumulator or recruitment model <ref type="bibr" target="#b3">(Audley &amp; Pike, 1965;</ref><ref type="bibr">La Berge, 1962)</ref>, the Poisson counter model <ref type="bibr" target="#b151">(Smith &amp; Van Zandt, 2000;</ref><ref type="bibr" target="#b168">Townsend &amp; Ashby, 1983)</ref>, and the Vickers accumulator <ref type="bibr" target="#b152">(Smith &amp; Vickers, 1988;</ref><ref type="bibr" target="#b183">Vickers, 1970</ref><ref type="bibr" target="#b185">Vickers, , 1979</ref>, give poorer RT distribution predictions than models based on racing diffusion processes . <ref type="bibr" target="#b174">Usher and McClelland (2001)</ref> proposed a model with mutual inhibition between the accumulators on grounds of neural plausibility and some researchers have reported that these kinds of models give a better fit to data <ref type="bibr" target="#b28">(Ditterich, 2006;</ref><ref type="bibr" target="#b73">Kirkpatrick et al. 2021)</ref>. Others have found that models with independent accumulators give good accounts of data <ref type="bibr" target="#b143">Smith &amp; Ratcliff, 2009;</ref><ref type="bibr" target="#b166">Tillman et al. 2020)</ref> including neural data. <ref type="bibr" target="#b98">Ratcliff et al. (2007)</ref> found that a dual-diffusion model predicted choice probabilities, RT distributions, and neural firing rates in the superior colliculi of monkeys performing an eye-movement decision task. There was no evidence of suppression in the firing rates in cells associated with the non-chosen alternative at the time of the response, as predicted by mutual-inhibition models. The advantage of models with independent accumulators is that they are tractable analytically whereas models with interactive accumulators are not.</p><p>2. Bounded evidence accumulation. Instead of modeling evidence accumulation using the Wiener process, some researchers have modeled it using the Ornstein-Uhlehbeck (OU) process, which is a diffusion process with leakage or decay <ref type="bibr" target="#b17">(Busemeyer &amp; Townsend, 1992</ref><ref type="bibr" target="#b37">, 1993</ref><ref type="bibr" target="#b27">Diederich, 1995;</ref><ref type="bibr" target="#b128">Smith, 1995;</ref><ref type="bibr" target="#b143">Smith &amp; Ratcliff, 2009;</ref><ref type="bibr" target="#b147">Smith et al., 2014;</ref><ref type="bibr" target="#b174">Usher &amp; McClelland, 2001)</ref>. Unlike the Wiener process, the OU process has a stationary distribution: At long times, evidence in the OU process has a Gaussian distribution with constant mean and variance <ref type="bibr" target="#b70">(Karlin &amp; Taylor, 1981;</ref><ref type="bibr" target="#b130">Smith, 2000)</ref>. The stationarity property is a diffusion counterpart of the saturation property of neural firing rates. Although the OU process has sometimes been proposed on grounds of neural realism, whether it improves a model's ability to account for data depends on its other assumptions. <ref type="bibr" target="#b103">Ratcliff and Smith (2004)</ref> found that an OU process in a two-boundary, single-process architecture performed no better than a Wiener process and when the OU decay parameter was free to vary it went to zero, which is the Wiener process. However, <ref type="bibr" target="#b143">Smith and Ratcliff (2009)</ref> found that in a dual-diffusion architecture a process with decay, that is, an OU process, performed better.</p><p>3. Reflecting boundaries. The state, or evidence, space of the Wiener and OU processes is the entire real line, R, which is inconsistent with the use of these processes to model neural firing rates, which can never be negative. The simplest way to constrain a process to the positive half line, R + , is with a reflecting boundary. When a process reaches such a boundary it is reflected back into the state space and continues accumulating <ref type="bibr" target="#b70">(Karlin &amp; Taylor, 1981)</ref>. Models with reflecting boundaries have been proposed by <ref type="bibr" target="#b27">Diederich (1995)</ref>, <ref type="bibr" target="#b143">Smith and Ratcliff (2009)</ref>, and <ref type="bibr" target="#b174">Usher and McClelland (2001</ref>  <ref type="bibr" target="#b174">Usher and McClelland (2001)</ref> called the corresponding constraint in their leaky competing accumulator model "truncation," which is consistent with their formulation of the model using a discrete-time approximation to a continuous process. The diffusion limit of truncation is reflection.</p><p>model the reflecting boundary is needed to stabilize its dynamics. Without it, if the evidence in one of the accumulators goes negative then the mutual inhibition between them becomes mutual excitation and the model becomes unstable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Linear Drift, Linear Infinitesimal Variance Model</head><p>In this article, I present and evaluate a new diffusion model, the LDLIV model, which embodies the three principles above. The model is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, along with the standard diffusion model and two related models that are evaluated below, to which it may be contrasted. Specifically, the LDLIV model assumes that: (a) evidence for competing alternatives is accumulated by independent processes; (b) the processes are bounded; and (c) the processes are nonnegative. An attractive feature of the LDLIV process that recommends it as a model of decision-making is that its dynamics naturally constrain it to the positive half line, R + , without artificial or externally-imposed bounds. This contrasts with the dual diffusion models of <ref type="bibr" target="#b98">Ratcliff et al. (2007)</ref> and <ref type="bibr" target="#b143">Smith and Ratcliff (2009) and</ref> the leaky competing accumulator model of <ref type="bibr" target="#b174">Usher and McClelland (2001)</ref> and the model of simple RT of <ref type="bibr" target="#b27">Diederich (1995)</ref>, in which the evidence processes are constrained by reflecting boundaries. Although the reflecting boundary endows these models with the right properties mathematically, it can be objected that the boundary is not a part of the process itself and lacks any clear neural interpretation. In contrast, the LDLIV process lives naturally, in the mathematical sense of the word, on R + .</p><p>Another attractive property of the LDLIV process is that it becomes progressively more noisy, or variable, as the activation state increases. This property captures the general tendency for neural firing rates to become more variable as their means increase <ref type="bibr">(Rieke et al., 1997)</ref>. Model neurons typically embody this property as a basic design feature <ref type="bibr">(Gerstner &amp; Kistler, 2002, p. 177;</ref><ref type="bibr">Tuckwell, 1988, p. 197)</ref>. The Wiener process in the standard diffusion model becomes more variable with the passage of time, but the change in variability (diffusion rate) is independent of the change in the mean (drift rate). In contrast, in the LDLIV process, the change in variability depends on the current state. This property seems to better capture the dynamics of noisy evidence growth in neural populations than does the assumption that drift and diffusion rates are independent of each other. A third attractive feature of the LDLIV model is that the distribution of evidence states in the Starting at z the process accumulates evidence between decision criteria at 0 and a. There is variability in the drift rate, ξ, with standard deviation η, starting point, z, with range s z , and nondecision time, T er , with range s t . (b) Dual diffusion models. Evidence is accumulated by racing diffusion processes starting at z with decision criteria at a 1 and a 2 . In the linear drift, linear infinitesimal variance model (LDLIV), zero is a natural boundary that constrains the processes to the positive real line R + , and evidence accumulates with rate q and decays with rate −p. In the racing, reflecting Wiener model (WIEN) the processes are constrained below by reflecting boundaries at r and evidence accumulates with rate µ with no decay. The racing Walds model (WLD) is unbounded below. The LDLIV and WIEN models have across-trial variability in drift rate, starting point, and nondecision time; the WLD model has only across-trial variability in starting point and nondecision time.</p><p>process is positively skewed, as we would expect a diffusion approximation to neural firing rate distributions to be. This contrasts to the Wiener and OU processes, both of which predict normally distributed evidence states. The theoretical interest of the LDLIV process for decision modelers comes from the fact that it embodies the three design principles stated above and also that it is possible to derive explicit mathematical predictions for it using integral equation methods similar to those described by <ref type="bibr" target="#b130">Smith (2000)</ref> and <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref>. The methodological contribution of this article is to introduce an explicit integral equation representation of the first-passage time distribution for the LDLIV process and to use it to fit data.</p><p>I compare the LDLIV model to two dual-diffusion models that relax one or more of the three principles. One is a model composed of racing Wiener diffusion processes between absorbing and reflecting boundaries. This model embodies Principles 1 and 3 but relaxes Principle 2 (boundedness). I also obtain explicit mathematical predictions for this model using integral equations. The other model, which also relaxes Principle 3 (positivity), is composed of racing unconstrained Wiener diffusion processes. This model is attractive because of its conceptual and mathematical simplicity and was recently advocated as an alternative to the standard diffusion model by <ref type="bibr" target="#b166">Tillman et al. (2020)</ref>. I compare these models based on independent racing processes to the standard diffusion model. Mathematically, a diffusion process is defined by specifying a pair of functions or coefficients: the drift rate and the diffusion rate (or diffusion coefficient), which are referred to as the infinitesimal moments of the process. The drift rate characterizes the expected change in the process in a unit interval and the diffusion rate characterizes the change in its variance <ref type="bibr">(Bhattacharya &amp; Waymire, 1990, Ch. 7;</ref><ref type="bibr">Cox &amp; Miller, 1965, Ch. 5;</ref><ref type="bibr">Karlin &amp; Taylor, 1981, Ch. 15)</ref>. The square root of the diffusion rate is the infinitesimal standard deviation. In the most general diffusion process, the drift and diffusion rate may depend both on time, t, and the position of the process in the evidence space, x. We can write a stochastic differential equation (SDE) for such a process, X t , which specifies the random change in the process during a small time interval, dt, as follows</p><formula xml:id="formula_0">dX t = A(X t , t) dt + B(X t , t) dW t ,<label>(1)</label></formula><p>where A(x, t) and B(x, t) are, respectively, the drift and diffusion rates, and dW t is a zeromean Gaussian increment whose standard deviation in a small interval of duration ∆t is of the order √ ∆t. An alternative way to characterize such processes is via partial differential equations (the so-called Kolmogorov backward and forward equations). 2 For first-passage time problems, which characterize the time required to pass through an absorbing boundary, and which arise in relation to RT modeling, the relevant equation is the backward equation <ref type="bibr" target="#b93">(Ratcliff, 1978)</ref>. The LDLIV process <ref type="bibr" target="#b41">(Feller, 1951)</ref> satisfies the SDE</p><formula xml:id="formula_1">dX t = (pX t + q) dt + 2σX t dW t ,<label>(2)</label></formula><p>with drift rate A(x, t) = px + q and diffusion rate B(x, t) = 2σx. The LDLIV process has a linear drift rate, like the OU process. When the state-dependent coefficient of the drift rate, p, is negative, it acts as a decay or leakage term, which tends to pull the process back to zero at a rate proportional to its current state, x. Like the OU process, leakage bounds the evidence accumulation process, consistent with Principle 2.</p><p>Where the LDLIV process differs from the OU process is in the diffusion rate. The OU process has a constant diffusion rate, which means it can take on both positive and negative values, like the Wiener process. In contrast, the diffusion rate of the LDLIV process is proportional to x, which constrains the process to the positive real line, consistent with Principle 3.</p><p>In the remainder of this article, I first present explicit integral-equation expressions for the response time and accuracy predictions for the LDLIV model and the Wiener model between absorbing and reflecting boundaries. Predictions for the other two models are available in the literature. I then describe applications of the models to data from two experiments. One is from a numerosity discrimination study by <ref type="bibr" target="#b95">Ratcliff (2008)</ref>, which crossed stimulus discriminability with a speed-accuracy manipulations. The other is from an attention-cuing study using sinusoidal grating stimuli by . These two studies were used recently by <ref type="bibr">Smith and Ratcliff (2021)</ref> as benchmarks to compare fixedboundary, collapsing-boundary, and urgency-gating models and allowed them to distinguish between competing models. Both studies had multiple levels of stimulus discriminability  Many recent studies of decision making in psychology have followed single-cell recording studies of motion perception in neuroscience and have investigated decisions about coherent motion in random dot kinematograms <ref type="bibr">(Dutilh et al., 2019)</ref>. Indeed, the random dot motion task is now sometimes seen as being the prototype of a decision-making task. <ref type="bibr" target="#b136">Smith and Lilburn (2020)</ref> questioned this characterization and argued that, in important respects, the task may be quite atypical. They reviewed evidence from psychophysical temporal integration studies suggesting it requires an unusually long period of perceptual integration to form a representation of the motion signal. Consistent with the psychophysics, they found that the RT distributions and choice probabilities in the Dutilh et al. data were better characterized by a model in which the drift rates depended on the time-varying outputs of a linear filter with an integration time of around 400 ms than by a model in which they were constant. The tasks I considered here can both be considered "typical" in that they have previously been well-described by the standard Wiener diffusion model with constant drift and diffusion rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Integral Equation Methods for Diffusion Decision Models</head><p>Mathematically, the predicted choice probabilities and decision times in a diffusion model are obtained by solving a first-passage time problem, which gives the probability distribution of the time when the process first crosses an absorbing boundary, which is identified in the psychological model with the time at which the accumulating evidence reaches a decision criterion. Classically, the solution of the backward equation for the Wiener process leads to a representation of the RT distributions as an infinite series <ref type="bibr" target="#b93">(Ratcliff, 1978)</ref> that can be computed efficiently. The availability of an explicit solution, which has been implemented in several third-party software packages <ref type="bibr" target="#b177">(Vandekerckhove &amp; Tuerlinckx, 2008;</ref><ref type="bibr" target="#b188">Voss &amp; Voss, 2007;</ref><ref type="bibr" target="#b193">Wiecki et al., 2013)</ref>, has been important in encouraging the use of the model in basic and applied settings <ref type="bibr" target="#b104">(Ratcliff et al., , 2016</ref>. For other, more complex, diffusion processes, infinite-series solutions cannot be obtained and other methods must be sought.</p><p>For models with interacting processes, like the <ref type="bibr" target="#b174">Usher and McClelland (2001)</ref> model, Monte Carlo simulation may be the only or the most practicable way to evaluate them (although see <ref type="bibr" target="#b28">Ditterich (2006)</ref> for a finite-state Markov chain approach) and considerable effort has recently gone into developing methods for approximating likelihoods and estimating parameters of simulated decision models (e.g., <ref type="bibr" target="#b170">Turner &amp; Sederberg, 2014;</ref><ref type="bibr" target="#b171">Turner &amp; van Zandt, 2018;</ref><ref type="bibr" target="#b44">Fengler et al., 2021)</ref>. My own bias is towards models whose first-passage time distributions can be expressed in a mathematically explicit form, because I believe they provide the sharpest theoretical insights into the properties of the underlying processes, and I have accordingly focused my attention on models of this kind.</p><p>The integral-equation method was pioneered by <ref type="bibr" target="#b36">Durbin (1971)</ref>, who used it to compute the power of the Kolmogorov-Smirnov test. The method was subsequently developed by <ref type="bibr" target="#b112">Ricciardi and</ref><ref type="bibr">colleagues (Buonocore et al., 1987, 1990;</ref><ref type="bibr" target="#b112">Ricciardi, 1976;</ref><ref type="bibr" target="#b113">Ricciardi &amp; Sato, 1983)</ref> to characterize the firing time distributions of model integrate-and-fire neurons. Early applications to decision processes were described by <ref type="bibr" target="#b57">Heath (1992)</ref> and <ref type="bibr" target="#b128">Smith (1995</ref><ref type="bibr" target="#b129">Smith ( , 1998</ref>.</p><p>A detailed tutorial introduction may be found in <ref type="bibr" target="#b130">Smith (2000)</ref> and recent applications to collapsing-boundary and urgency-gating models may be found in <ref type="bibr" target="#b186">Voskuilen et al. (2016)</ref> and <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref>. Applications to models with time-varying drift and diffusion rates can be found in <ref type="bibr" target="#b143">Smith and Ratcliff (2009)</ref>, <ref type="bibr" target="#b147">Smith et al. (2014)</ref>, and <ref type="bibr" target="#b136">Smith and Lilburn (2020)</ref>.</p><p>For models based on racing diffusion processes, the theoretical quantities of interest are the functions, g[a(t), t, | z, 0], the first-passage time distribution for a diffusion process, X t , starting at z at time 0, through an absorbing boundary a(t) at time t, which may be time- </p><formula xml:id="formula_2">g[a(t), t| z, 0] = −2Ψ[a(t), t |z, 0] + 2 t 0 g[a(τ ), τ | z, 0]Ψ[a(t), t| a(τ ), τ ] dτ.<label>(3)</label></formula><p>In this equation, g[a(t), t| z, 0] is jointly a function of its values at previous times, τ &lt; t, and of a kernel function, Ψ[a(t), t| a(τ ), τ ], which depends on the drift and diffusion rates of X t and which is described in detail below. Equation 3 is derived from a general integral representation of the first-passage time for a diffusion process through an absorbing boundary, attributed to <ref type="bibr" target="#b46">Fortet (1943)</ref>. A derivation of Equation 3 based on the Fortet representation is sketched in Appendix A.</p><p>A problem with the original Fortet representation, as <ref type="bibr" target="#b36">Durbin (1971)</ref> recognized, was that the equation becomes singular as τ → t, that is, as the interval of approximation becomes small. This is because the free transition density function of the process, f [a(t), t| a(τ ), τ ], which describes the position of the process in the absence of boundaries, approaches a Dirac delta function, δ(τ − t), which describes a spike of probability mass of infinite amplitude concentrated at the point t. This means that simple iterative schemes for evaluating the first-passage time density will become numerically unstable. Durbin considered some ad hoc ways to stabilize the equation but <ref type="bibr" target="#b15">Buonocore et al. (1987)</ref> showed that for many processes of interest it is possible to choose the kernel in a way that removes the singularity entirely.</p><p>With the kernel chosen in this way, the equation may be approximated on a discrete set of points and solved iteratively (Equation A3). Derivations of the kernel functions for Wiener and OU processes with time-varying drift rates, diffusion rates, and boundaries, with an application to urgency-gating models, can be found in <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Kernel of the Integral Equation for the LDLIV Process</head><p>The stable form of the kernel in Equation 3 derived by <ref type="bibr" target="#b15">Buonocore et al. (1987)</ref>, although it characterizes many of the processes of interest to decision modelers, is not applicable to either the LDLIV process or the Wiener process with reflecting boundary at r. This is because both processes have a boundary -a so-called regular boundary -at which the equation become singular. A regular boundary is a point that can be attained, but not exceeded, by a process starting in the interior of the state space, and conversely, a process starting on the boundary can attain a point on the interior of the space at a later time <ref type="bibr">(Karlin &amp; Taylor, 1981, p. 234)</ref>. For the Wiener process, r, r &lt; z, is a regular boundary;</p><p>for the LDLIV process, 0 is a regular boundary. 3 Although the general form of the kernel function derived by Buonocore et al. does not apply to either of these processes, <ref type="bibr" target="#b48">Giorno et al. 1989a</ref>) showed that it is nevertheless possible to derive kernel functions for Equation 3 in which the resulting discrete approximations are stable. I draw heavily on their results throughout the remainder of this article.</p><p>For the LDLIV process, <ref type="bibr">Giorno et al. (1989a, Equation 6.4)</ref> showed the kernel is</p><formula xml:id="formula_3">Ψ[a(t), t |z, τ ] = p σ[e p(t−τ ) − 1] exp − p[a(t) + ze p(t−τ ) ] σ[e p(t−τ ) − 1] a(t)e −p(t−τ ) z (q−σ)/2σ × a ′ (t) − pa(t)e p(t−τ ) e p(t−τ ) − 1 + k(t) I q/σ−1 2p a(t)ze p(t−τ ) σ[e p(t−τ ) − 1] + p a(t)ze p(t−τ ) e p(t−τ ) − 1 I q/σ 2p a(t)ze p(t−τ ) σ[e p(t−τ ) − 1] .<label>(4)</label></formula><p>In Equation 4, I ν (•), is a modified Bessel function of the first kind of order ν <ref type="bibr">(Abramowitz &amp; Stegun, 1965, p. 374)</ref>, and k(t) is a function that is chosen to make the kernel of the integral equation nonsingular <ref type="bibr">(Giorno et al., 1989a, Equation 6.7)</ref>, which is of the form</p><formula xml:id="formula_4">k(t) = 1 2 pa(t) + q − σ 2 − a ′ (t) ,<label>(5)</label></formula><p>where a ′ (t) is the derivative of the absorbing boundary a(t). Here I am concerned exclusively with the constant boundary case, a(t) ≡ a, in which case the terms a ′ (t) in Equations 4 and 6 are both zero. 4</p><p>I assume that the decision process takes the form of a race between LDLIV processes, each of which accumulates evidence for a given response alternative. The joint decision timeaccuracy distributions are then given by the race model equation, in which the joint density is the product of the first-passage time density for the first-finishing process multiplied by the survivor function for the other process (or processes in n-alternative cases). Denoting 4 I have corrected a typographical error in the expression for the kernel function in <ref type="bibr" target="#b48">Giorno et al. (1989a)</ref> (a missing "e" denoting exponentiation in the numerator of the third term on the right-hand side in their Equation 6.4.) I have followed their notation for the LDLIV and reflecting Wiener processes, with two changes to ease the exposition for an audience of decision modelers. As is customary in this area, I denote the absorbing boundary as a(t), whereas they denote it S(t). They use the symbol r to denote both the reflecting boundary for the Wiener process and the scaling constant for the diffusion coefficient for the LDLIV model. To avoid the notational clash I retain r to denote the reflecting boundary for the Wiener process, but use σ to denote the scaling constant for the LDLIV process.</p><p>the first passage time density for process i by g i (t), the distribution function by G i (t), and the survivor function byḠ i (t), whereḠ i (t) = 1 − G i (t), the joint densities are</p><formula xml:id="formula_5">g race (t, i) = g i (t)Ḡ j; j =i (t); i, j = 1, 2.<label>(6)</label></formula><p>Models of the form of Equation 6 have a long history in the RT literature. An advantage of this representation is that it carries over easily to n-choice decisions, but I restrict myself here to the two-choice case. I discuss how I parameterize the model to fit it to data in a subsequent section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Kernel of the Integral Equation for the Reflecting Wiener Process</head><p>A race model based on LDLIV processes satisfies all of the three preceding principles for a neurally-plausible decision model. A model based on racing reflecting Wiener processes satisfies Principles 1 and 3 but relaxes Principle 2 (saturation at high intensities). <ref type="bibr">Giorno et al. (1989a, Equation 5.14)</ref> showed that it was possible to derive a stable kernel in Equation 3 for a Wiener process with drift rate, µ, diffusion rate, σ 2 , and a reflecting boundary at r, r ≤ z, using arguments like those used to derive Equation 4. For the reflecting Wiener process the kernel takes the form</p><formula xml:id="formula_6">Ψ[a(t), t |z, τ ] = 1 2σ 2π(t − τ ) a ′ (t) − a(t) − z t − τ exp − [a(t) − z − µ(t − τ )] 2 2σ 2 (t − τ ) + 1 2σ 2π(t − τ ) a ′ (t) − a(t) + z − 2r − 2µ(t − τ ) t − τ × exp − 2µ(z − r) σ 2 exp − [a(t) + z − 2r − µ(t − τ )] 2 2σ 2 (t − τ ) − µ[a ′ (t) + µ] σ 2 exp 2µ[a(t) − r] σ 2 Φ − a(t) + z − 2r + µ(t − τ ) σ √ t − τ ,<label>(7)</label></formula><p>where Φ(•) is the normal distribution function. 5 As in Equation 4, in the constant boundary case that we are concerned with here, a(t) ≡ a and the terms involving a ′ (t) are zero. <ref type="figure" target="#fig_5">Figure 2</ref> shows predictions for models with racing LDLIV and reflecting Wiener processes. The top panels compare predictions for the models obtained using the integral equation method with simulations of them using the Euler method <ref type="bibr" target="#b13">(Brown et al., 2006)</ref>.</p><p>The latter approximates the diffusion process with a discrete time, Gaussian-increments,   <ref type="figure" target="#fig_5">Figure 2c</ref> shows, when the parameters were chosen in this way and decay was small, the models are in close agreement. When decay is increased, the mean and the variance of the distributions increase and the model predicts heavy right tails. The behavior of the model is therefore similar to the OU model, which predicts similar changes in the distribution shape as decay is increased. of their code with drift and diffusion rates held constant, augmented with variability in drift rates and starting points, to carry out the model fits described below.</p><p>The first-passage time density for the single-boundary Wiener process has a simple closed-form solution that is well known in the literature <ref type="bibr">(Karlin &amp; Taylor, 1975, p. 363)</ref> where it is variously referred to as the Wald or the inverse-Gaussian distribution. The first-passage time density has the form</p><formula xml:id="formula_7">g(a, t |z, 0) = a − z σ √ 2πt 3 exp − (a − z − µt) 2 2σ 2 t .<label>(8)</label></formula><p>The meaning of the parameters in this model is the same as in the reflecting Wiener model of Equation 7. Equation 8 has a long history in the psychological literature in modeling both simple and choice RT (e.g., <ref type="bibr" target="#b39">Emerson, 1970;</ref><ref type="bibr" target="#b59">Heathcote, 2004;</ref><ref type="bibr" target="#b84">Matzke &amp; Wagenmakers, 2009;</ref><ref type="bibr" target="#b119">Schwarz, 2001</ref><ref type="bibr" target="#b122">Schwarz, , 2002</ref>. It is possible to derive a closed-form expression for the marginal first-passage density for this process when the starting point, z, is uniformly distributed across trials rather than constant <ref type="bibr" target="#b81">(Logan et al., 2014;</ref><ref type="bibr" target="#b166">Tillman et al. 2020</ref>) but, again, for consistency of implementation, I evaluated the effects of starting point variability numerically, as discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Experimental Studies</head><p>I compared the dual LDLIV and reflecting Wiener models, the racing Walds model, and the standard diffusion model using the data from the numerosity discrimination study of <ref type="bibr" target="#b95">Ratcliff (2008)</ref> and the attentional cuing study of . <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref> used the data from these studies to compare urgency-gating and collapsing boundaries models to the standard diffusion model. The version of the standard diffusion model I used to fit the <ref type="bibr" target="#b95">Ratcliff (2008)</ref> data was slightly more general than the one considered by them in that it allowed nondecision times to vary with experimental instructions, for reasons described below.</p><p>The participants in <ref type="bibr" target="#b95">Ratcliff's (2008)</ref> study were asked to decide whether the number of randomly-placed dots in a 10 × 10 grid was greater or less than 50. There were eight nominal discriminability conditions, in which the numbers of dots were: <ref type="bibr">31-35, 36-40, 41-45, 46-50, 51-55, 56-60, 61-65, and 66-70</ref>, crossed with speed versus accuracy instructions.</p><p>On half the trials participants were instructed to respond rapidly and on the other half they were told to respond accurately and they were given feedback to encourage them to perform as instructed. Data were collected from 19 college-aged participants and 19 older participants who performed both a standard RT task, in which they responded as soon as they had sufficient evidence, and a response-signal task, in which they responded to a random external deadline. Following <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref>, I restrict my analysis to the younger participants and the standard RT task. After eliminating fast and slow outliers, there were about 850 valid trials in each cell of the design, yielding around 13,600 valid trials per participant.</p><p>Participants in the Smith et al. (2004) study performed an attentional cuing task in which low-contrast Gabor patches were presented for 60 ms at either a cued location, which was indicated by a 60 ms, flashed peripheral cue 140 ms before the stimulus, or at one of two uncued locations. On each trial, participants decided whether the orientation of the patch was vertical or horizontal. In one condition of the experiment the stimuli were backwardly masked with high-contrast checkerboards and in the other condition they were briefly flashed and then extinguished. Data were collected from six highly-practiced participants who performed the task at five different levels of contrast, which were chosen for each participant individually during practice to span a range of performance from just above chance (≈ 55% correct) to near-perfect (≈ 95% correct). Participants were encouraged to be as accurate as possible but not to deliberate for too long and were given auditory accuracy feedback on each trial. There were 400 valid trials for each participant in each cell of the Cue × Mask × Discriminability design, yielding 8000 trials per participant. The reader is referred to Smith and Ratcliff (2022) and the original articles for more details on the two studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In the standard diffusion model, evidence accumulation is modeled by a Wiener diffusion process between absorbing boundaries that represent decision criteria for the two responses. In addition to within-trial, diffusive variability there are three sources of acrosstrial variability: variability in drift rates, starting points, and nondecision times <ref type="bibr" target="#b100">(Ratcliff &amp; McKoon, 2008)</ref>. Drift rate is normally distributed with mean ν and standard deviation η;</p><p>starting point is uniformly distributed with range s z , and nondecision time, T er , is uniformly distributed with range s t . Variability in drift rate and starting point allows the model to predict the ordering of correct responses and errors; variability in nondecision time allows it to better predict the leading edges of RT distributions under speed-stress conditions when accuracy is high and RTs are short. Typically, error RTs tend to be longer than RTs for correct responses when the task is difficult and accuracy is stressed and shorter when the task is easy and speed is stressed <ref type="bibr">(Luce, 1986, p. 233</ref>).</p><p>In the dual-diffusion models, each accumulator has its own drift rate, which may be unrelated or be constrained in some way. These models raise questions about how to parameterize drift rates in a way that is theoretically principled, parsimonious, and flexible enough to account for the relationships found in empirical data. A common assumption is to assume that the drift rates or the mean drift rates sum to a constant across stimulus difficulty levels <ref type="bibr" target="#b98">Ratcliff et al., 2007;</ref><ref type="bibr" target="#b174">Usher &amp; McClelland, 2001)</ref>.</p><p>Although it is possible to implement a dual-diffusion model in which the drift rates are normally distributed - <ref type="bibr" target="#b143">Smith and Ratcliff (2009)</ref> proposed a dual-diffusion model with reflecting OU processes and normally-distributed, negatively-correlated drift rates -a more natural assumption is to constrain drift rates to be positive. In the LDLIV process the positivity constraint is needed to avoid the q ≤ 0 exit boundary properties described in Footnote 3.</p><p>I assumed the drift rates in the dual-diffusion models were lognormally distributed (i.e., random variables whose logarithms are normally distributed), with dispersion parameters η 1 and η 2 for the accumulators associated with correct and error responses, respectively.</p><p>The drift rates in stimulus condition j were distributed as</p><formula xml:id="formula_8">µ j1 ∼ ν j1 exp(η 1 ξ 1 ) = π j ν sum exp(η 1 ξ 1 ) µ j2 ∼ ν j2 exp(η 2 ξ 2 ) = (1 − π j )ν sum exp(η 1 ξ 1 ); j = 1, 2, . . . ,<label>(9)</label></formula><p>where ξ 1 and ξ 2 are independent standard normal variates and π j , 0 ≤ π j ≤ 1, is a mixing parameter that constrains ν sum to be constant across stimulus conditions. With this parameterization the scaling factors ν j1 and ν j2 are the medians of the lognormal distributions, so Equation 9 constrains the sums of the median drift rates in the two accumulators to be constant. A constraint on the medians could be seen as a natural one when the drift rate distributions are positively skewed, but I adopted it for computational convenience rather than because of a theoretical preference for medians over means. Like a constraint on the means, the constraint on the medians almost halves the number drift rate parameters that are needed to fit the model to data. Parameterized in this way, the LDLIV model requires five drift rate parameters to fit the four discriminability conditions of the <ref type="bibr" target="#b100">Ratcliff et al. (2008)</ref> data and six to fit the five discriminability conditions of the  data. In the notation of the LDLIV model, µ ≡ q, the stimulus-dependent part of drift rate.</p><p>In the case of the model with racing Walds (single-boundary Wiener processes with no reflecting boundaries), <ref type="bibr" target="#b166">Tillman et al. (2020)</ref> reported the model can successfully account for slow errors without across-trial variability in drift rates because of its race-model structure, which naturally predicts slow errors. Indeed, if combined with the usual assumption of normally-distributed drift rates then the model would predict defective RT distributions because on some trials the drift rate would be away from the boundary and the probability the process would ever terminate would be less than 1.0. To evaluate the generality of <ref type="bibr">Tillman et al.'s findings, I</ref> implemented the racing Walds model, as they did, without driftrate variability. Initially, I imposed a constraint that the drift rates should sum to a constant, but found it performed poorly relative to the other dual diffusion models. I therefore allowed the drift rates for the two accumulators to vary freely and independently across conditions, which gave the model a similar number of free parameters to the other models. The fits I report are for the model with unconstrained drift rates.</p><p>There has been debate in the literature about whether speed-accuracy manipulations affect only decision criteria, as they are theoretically assumed to do, or whether they affect under conditions that yield the best accounts of the data for each model. The parameters of the models and their interpretations are summarized in <ref type="table" target="#tab_1">Table 1</ref>. I chose to use methods similar to those used in the original studies of <ref type="bibr" target="#b95">Ratcliff (2008)</ref> and  and in the reanalysis of their data by <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref>. I minimized the likelihood-ratio chi-square statistic (G 2 ) for the response proportions in the bins formed by the .1, .3, .5, .7, and .9 RT quantiles for the distributions of correct responses and errors. When bins are formed in this way there are a total of 12 bins (11 degrees of freedom) in each pair of joint distributions of correct responses and errors. The resulting G 2 may then be written as a function of the observed and expected proportions in the bins as</p><formula xml:id="formula_9">G 2 = 2 M i=1 n i 12 j=1 p ij log p ij π ij .<label>(10)</label></formula><p>In Equation 10, p ij and π ij are, respectively, the observed and predicted response proportions is the number of experimental trials on which each joint distribution pair was based. For the numerosity study n i ≈ 850 and for the cuing study n i = 400. I fit the models to the individual participants' data by minimizing G 2 using the Nelder-Mead simplex algorithm <ref type="bibr" target="#b88">(Nelder &amp; Mead, 1965)</ref>  Bayesian information criterion (BIC, <ref type="bibr" target="#b117">Schwarz, 1978)</ref>. The first of these statistics is derived from classical principles whereas the second is Bayesian, but I use them in the spirit in which they are typically used in the modeling literature, as penalized likelihood statistics that impose more or less severe penalties on the number of free parameters in a model. As is well known, the AIC tends to gravitate towards more complex models with increasing sample sizes more quickly than does the BIC <ref type="bibr" target="#b71">(Kass &amp; Raftery, 1995)</ref>. For binned data, the AIC and BIC may be written as</p><formula xml:id="formula_10">AIC = G 2 + 2k (11) BIC = G 2 + k log N,<label>(12)</label></formula><p>where k is the number of free parameters in the model and N = i n i is the total number of observations on which the fit statistic was based.</p><p>Numerosity Study <ref type="bibr" target="#b95">(Ratcliff, 2008)</ref> In the following tables, I use the identifiers "DIFF" to denote the standard diffusion model, "LDLIV" to denote the linear-drift, linear-infinitesimal variance model, "WNR" to denote the reflecting Wiener model, and "WLD" to denote the racing Walds model. <ref type="table" target="#tab_2">Table   2</ref> shows mean G 2 statistics for each model, averaged over the 19 participants, together with the corresponding mean AIC and BIC values. On average, the LDLIV model was the best-performing of the models by a substantial margin. The next best model was the diffusion model, followed by the reflecting Wiener model, followed by the racing Walds model. This pattern is mirrored at the individual participant level, as shown in <ref type="table" target="#tab_3">Table 3</ref>, which shows the number of participants for whom each of the models was better than each of its competitors, as assessed by either the AIC or the BIC. The diffusion model was better than the LDLIV model for just under half the participants (9/19), but was better than either of the other dual diffusion models for the majority of participants by either criterion. The LDLIV model was better than either of the other two dual diffusion models for a substantial majority of participants. Of those two models, the reflecting Wiener process model was better than the racing Walds model for most participants.</p><p>In comparison, the G 2 statistics for models with a single T er parameter were 820.5, 621.7, 857.9, and 888.8, for the DIFF, LDLIV, WNR, and WLD models, respectively. The average improvement in fit when T er varied with instructions ranges from 5% to 20%, with the largest improvement for the standard diffusion model. <ref type="table" target="#tab_4">Table 4</ref> shows the estimated parameters for the four models. Consistent with the observation that the standard diffusion model showed a large improvement in fit with variable T er , it also showed the largest difference in the estimates of T er,s and T er,a (270 ms vs. 282 ms, respectively). The corresponding estimates</p><p>for the the LDLIV model were 264 ms and 267 ms. The estimates of T er,a for the WNR and WLD models were shorter than those of T er,s rather than longer, suggesting the extra parameter in these models was simply describing random variation rather than essential structure in the data. Note. Number for which the row model was better than the column model (out of 19).</p><p>Of the four models, the diffusion model is the most parsimonious, in the sense of requiring the fewest parameters to account for the data. Even with constraints on the drift rates, the LDLIV and the reflecting Wiener process models required three or four more parameters because of the need to parameterize the mean drift rate and the drift rate variability for the two accumulators separately. The racing Walds model is able to characterize the data without drift rate variability, as Tillman et al. (2020) pointed out, but it required a total of eight free drift rate parameters in order to do so and was clearly the worst-performing of the models. <ref type="figure" target="#fig_11">Figure 3</ref> shows fits of the diffusion and LDLIV models to the group data; <ref type="figure" target="#fig_10">Figure 4</ref> shows the corresponding fits for the reflecting Wiener and racing Walds models.</p><p>The fits are shown as quantile-probability plots, in which quantiles of the RT distributions for correct responses and errors are plotted against the choice probabilities for a range of stimulus difficulties. Readers who are unfamiliar with this way of representing model fits are referred to <ref type="bibr" target="#b103">Ratcliff and Smith (2004)</ref> or <ref type="bibr" target="#b100">Ratcliff and McKoon (2008)</ref>, among other other sources, for an account of how they are constructed. The data in <ref type="figure" target="#fig_10">Figures 3 and 4</ref> are quantile-averaged group data and the fitted values are quantile-averaged individual fits.</p><p>The fits for the diffusion model in the upper part of <ref type="figure" target="#fig_11">Figure 3</ref> are the same as those in <ref type="figure" target="#fig_11">Figure   3</ref> in <ref type="bibr">Smith and Ratcliff (2021)</ref>. Note. Diffusion model parameters scaled with σ = 0.1; other models scaled with σ = 1.0.</p><p>The most obvious difference between the two models is in the tails of the predicted RT distributions. One of the effects of combining racing processes in a dual diffusion architecture is that the predicted RT distributions for the fastest-finishing process will be less skewed and more symmetrical than the distributions of either of the component processes in isolation.</p><p>This is because slow responses occur only if both processes are slow to finish. By the race model equation <ref type="formula" target="#formula_5">Equation 6</ref>, an RT longer than a given t is equal to the product of the probabilities that both processes take longer than t to finish (i.e., the product of their survivor functions), which will be less than the finishing time probabilities of either process individually. The reduction in skewness is offset by the presence of decay, denoted p for the LDLIV model in Equation 2, and estimated to be, on average, p = 2.428 in <ref type="table" target="#tab_4">Table 4</ref>.</p><p>This interaction between the architecture of the model and the effects of decay is likely why <ref type="bibr" target="#b103">Ratcliff and Smith (2004)</ref> found decay to be zero in a single-process OU model but <ref type="bibr" target="#b143">Smith and Ratcliff (2009)</ref> found decay was nonzero in a dual-diffusion OU model. The difference between single-process and dual-process models is evident in the distribution tails for the diffusion and LDLIV models in <ref type="figure" target="#fig_11">Figure 3</ref>, as represented by the .9 quantile function (the topmost line in the plot). The diffusion model accurately predicts the .9 quantile in the speed condition and somewhat overpredicts it in the accuracy condition. The LDLIV model slightly underpredicts the .9 quantile function in the speed condition and underpredicts it more severely in the accuracy condition, especially for the error distributions. The tendency for the diffusion model to overpredict the .9 quantile function in the accuracy condition was reduced by allowing T er to vary with instructions. Indeed, the most obvious qualitative difference between models with one and two T er parameters was in how well the .9 quantile functions in the accuracy condition were predicted.</p><p>The tendency for dual diffusion models to underpredict the tails of RT distributions is particularly pronounced in the reflecting Wiener model, shown in the upper panels of  symmetrical than those predicted by the standard model.</p><p>Although the reflecting Wiener model was worse than the LDLIV model, it was nevertheless better than the racing Walds model for the majority of participants (12/19 by either criterion). Although the latter model is in principle able to predict slow errors by virtue of its race model structure, it failed to do so in the accuracy condition of this experiment.</p><p>Rather, the predicted quantile-probability functions in the accuracy condition in <ref type="figure" target="#fig_10">Figure 4</ref> are almost symmetrical across the vertical midline, indicating the model is predicting essentially the same RT distributions for correct responses and errors. There are two reasons why the model might have failed to capture the slow error pattern in these data. The first is that it may be unable to capture the slow error pattern if the range of stimulus discriminabilities and associated accuracy varies widely. The second is that it may be unable to capture the slow error pattern when discriminability is crossed with speed versus accuracy instructions -even when T er is allowed to vary with instructions, as was the case here.</p><p>Tillman et al. (2020) reported a simulation showing that the magnitude of the slow error effect predicted by the model increases with decision criterion and, consequently, increases monotonically with accuracy (their <ref type="figure" target="#fig_11">Figure 3)</ref>. However, they did not characterize the way in which the magnitude of the effect varies with drift rate and it is not obvious from their results that the model can capture a slow error pattern of the complexity of the one shown in <ref type="figure" target="#fig_11">Figure   3</ref> and 4. They reported a fit of the racing Walds model to the data of <ref type="bibr" target="#b102">Ratcliff and Rouder (1998)</ref>, which crossed stimulus discriminability with speed versus accuracy instructions, but they fit the mean RTs only. They also reported a fit to the RT distribution data of <ref type="bibr" target="#b91">Rae et al. (2014)</ref>, which varied speed versus accuracy instructions, but used only a single stimulus discriminability level, and even in this relatively unconstrained case the model appears to be failing to capture the shapes of the error distributions (their <ref type="figure" target="#fig_17">Figure 8)</ref>. As a further, more constrained, test they fit the model to a data from a lexical decision experiment reported by <ref type="bibr" target="#b103">Ratcliff and Smith (2004)</ref> that collected RT and accuracy data for high-frequency, lowfrequency, and very-low-frequency words and pseudowords, each of which was modeled with its own drift rate. It is difficult to infer the quality of the fit from Tillman et al.'s figure</p><p>(their <ref type="figure" target="#fig_14">Figure 6</ref>), which show joint cumulative distributions rather than quantile probability functions (see <ref type="bibr">Luce (1986, pp. 17-20)</ref>, for a relevant discussion on this point), but it suggests a significant failure to fit in some conditions, most obviously for error responses to pseudowords. Overall, the data of <ref type="bibr" target="#b95">Ratcliff (2008)</ref>  can make arbitrarily large excursions away from the boundary with finite probability, which often leads to long finishing times. Indeed, if the drift rates are negative or zero then the probability that the process will never finish is greater than zero and the RT distributions will be defective, as noted previously.</p><p>To evaluate whether drift-rate variability or the reflecting boundary was the primary determinant of the difference between the two models, I refit the reflecting Wiener model with the reflecting boundary set to r = −1.5 max(a 1a , a 2a ), that is, as a multiple of the largest of the two accuracy criteria. I conjectured, based on the estimates in <ref type="table" target="#tab_4">Table 4</ref>, which show r set quite far from the starting point, that the reflecting boundary was contributing relatively little to the quality of the fit. The multiple of 1.5 was arbitrary, but served to minimize the effects of the boundary while avoiding numerical instabilities in the computation of the kernel. With r constrained in this way, the performance of the model was essentially unaltered. The mean G 2 was 805.5, which is virtually identical to the G 2 with r freelyvarying in <ref type="table" target="#tab_2">Table 2</ref>. (The very slight improvement in fit found with r constrained is due to the constrained model's better convergence properties.) The comparative performance of the constrained model at the individual level was identical to that of the model with r freely-estimated in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>The large negative estimates of r in Equation 2 depends on the position of the process in the evidence space, R + . A process with a starting point of z &gt; 0 will begin to diffuse towards the boundary more rapidly than one with a starting point of z ≈ 0. <ref type="table" target="#tab_4">Table 4</ref> shows that the estimated starting point in the LDLIV model was between a half and a third of the way towards the decision boundary in the speed and accuracy conditions, respectively. Unlike the other models, the starting point in the LDLIV model affects not only the distance the process has to travel in order to reach a boundary but also the speed with which it does so. In the other models, the distance to the boundary and the speed with which the process travels are independent of each other.</p><p>This dependency seems to be what gives the model an advantage under conditions in which speed is stressed.</p><p>Spatial Cuing Study  My treatment of the Smith et al. (2004) spatial cuing study follows the one in Smith and <ref type="bibr" target="#b145">Ratcliff (2022)</ref>, in which a separate model, with different drift rates, decision criteria, and nondecision times, was fitted to each cell in the Cue × Mask design for each participant.  characterized the relationships among the conditions using an attention orienting model, which predicted how drift rates and nondecision times would change across the four conditions, but here I imposed no a priori theoretical constraints on the parameters because my primary concern was to compare decision models, not to test the attention model. Because there was no speed versus accuracy manipulation in the study, the starting point variability parameters could be omitted without worsening the fit and because the speed and accuracy of decisions to vertical and horizontal gratings were sufficiently similar they could be pooled to obtain a single distribution of correct responses and a single distribution of errors for each stimulus condition. This symmetry implies a symmetry constraint on the starting point in the diffusion model, z = a/2, and equality of the decision criteria in the dual-diffusion models, a 1 = a 2 . I fit the same four models as for the <ref type="bibr" target="#b100">Ratcliff et al. (2008)</ref> numerosity study. The averaged fit statistics are shown in <ref type="table" target="#tab_7">Table   5</ref>; the comparative performance for the individual participants is shown in <ref type="table" target="#tab_8">Table 6</ref>, and the estimated parameters are shown in <ref type="table" target="#tab_9">Table 7</ref>. <ref type="figure" target="#fig_13">Figure 5</ref> shows the performance of the diffusion and LDLIV models; <ref type="figure" target="#fig_14">Figure 6</ref> shows the performance of the reflecting Wiener and racing Walds models. I fit the models in the same way as for the <ref type="bibr">Ratcliff et al. study, except I</ref> fit the models for each cell of the Cue × Mask design separately (24 fits in all). <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref> reported fits to the data from the Smith et al. study summed across the four cells of the design for each of the six participants, but as I have fitted independent models to each cell of the design I report them instead as 24 separate model fits, which better reflects the way they were carried out. Whether or not fit statistics are summed across cells for each participant before comparing the models has no effect on the inferences I wish to draw about them.</p><p>The performance of the models on the spatial cuing task was similar to the numerosity task, except that the order of the diffusion model and the LDLIV model was reversed. The diffusion model was the best model, on average by G 2 , the AIC, and the BIC, followed by the LDLIV model, then the reflecting Wiener model, followed by the racing Walds model. The average G 2 for the diffusion model was only marginally smaller than for the LDLIV model, but the average AIC and BIC were both considerably smaller because of the diffusion model's greater parsimony. At the level of the individual fits, the picture differed, depending on the whether the AIC or BIC was used. By the AIC, the performance of the LDLIV model was slightly better than that of the diffusion model (13/24), but the BIC overwhelmingly favored the diffusion model (19/24). Some researchers have reported that the BIC has poorer model recovery properties than the AIC because of its bias against complexity <ref type="bibr" target="#b30">(Donkin et al., 2015;</ref><ref type="bibr" target="#b89">Oberauer &amp; Lin, 2017;</ref><ref type="bibr" target="#b176">van den Berg et al., 2014)</ref>, but the picture that emerges if performance on both criteria is taken into account is similar to the one obtained from the <ref type="bibr" target="#b95">Ratcliff (2008)</ref> study, which suggests that both the diffusion and LDLIV models provide good accounts of the data. The quantile probability plots in <ref type="figure" target="#fig_13">Figure 5</ref> further reinforce the picture obtained from the fit statistics. Both models captured the essential structure of the data fairly well, although there are differences in the way they characterize the slow error pattern, particularly in the two masked conditions, in which the slow error pattern is most pronounced. Whereas the .9 quantile functions for the diffusion model are uniformly concave for all conditions, the corresponding functions for the LDLIV model show a tendency to become convex. These qualitative differences in the predictions reflect differences in the way in which the models parameterize drift rate variability. Both models predict slow errors via drift rate variability: In the diffusion model, drift rates are normally distributed and may take on both positive and negative values; in the LDLIV model, drift rates are lognormally distributed and constrained to be positive. The differences in the .9 quantile functions in <ref type="figure" target="#fig_13">Figure 5</ref> are a reflection of this difference.</p><p>The qualitative pattern of predictions for the reflecting Wiener model in <ref type="figure" target="#fig_14">Figure 6</ref> resemble those for the LDLIV model in <ref type="figure" target="#fig_13">Figure 5</ref> but the effects are magnified. In the masked Note. Number for which the row model was better than the column model (out of 24). for errors, which may arguably capture the qualitative structure slightly better than the other models, although the quantitative fit is worse. The model is appreciably worse than the LDLIV model by the AIC (6/24) but only slightly worse by the BIC (11/24) because the LDLIV model has an additional decay parameter that is heavily penalized by the BIC.</p><p>As in the fit to the <ref type="bibr" target="#b95">Ratcliff (2008)</ref> data, the reflecting boundary was estimated to be quite far from the starting point (more than a third of the distance of the starting point from the  decision boundary), so I refit the model with r = −1.5a, as I did previously. The mean G 2 for the constrained model was 140.1 with associated AIC and BIC of 162.7 and 206.6, respectively. The AIC selected the model with the reflecting boundary as the better model; the BIC selected the model without it, again, because the BIC penalizes free parameters more severely. At the individual participant level, the model with the freely-varying reflecting boundary is preferred for only 9 of the 24 data sets by the AIC and 5 by the BIC. Like the fits of the model to the <ref type="bibr" target="#b95">Ratcliff (2008)</ref> data, then, these fit statistics show the performance of the model is only marginally improved by the presence of a reflecting boundary.</p><p>Like the <ref type="bibr" target="#b95">Ratcliff (2008)</ref> numerosity study, the quantile probability plots for the racing Walds model are almost symmetrical across the vertical midline, indicating the model is predicting essentially the same RT distributions for correct responses and errors. This failure to capture the structure of the distribution data is mirrored in the poor fits statistics for the model relative to the other models in <ref type="table" target="#tab_7">Tables 5 and 6</ref>. Unlike the fits for the Ratcliff study, the model was not constrained by selective influence assumptions that held drift rates constant across speed and accuracy instructions. Instead, separate drift rates were estimated for each cell of the Cue × Mask design. The fits in <ref type="figure" target="#fig_14">Figure 6</ref> show that even without the selective influence constraint the model does not capture the relationship between the RT distributions for correct responses and errors across the full range of stimulus discriminabilities.</p><p>In sum, there is a high degree of agreement in the pictures that emerge from the fits to the <ref type="bibr" target="#b95">Ratcliff (2008)</ref> numerosity study and the  spatial-cuing study.</p><p>The diffusion model performed well on both data sets, as has previously been shown, both by <ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref> and in the original articles. The LDLIV model, which is new, also performed well, although it is less parsimonious than the diffusion model. This comparative lack of parsimony, as I commented previously, is a feature of dual-diffusion models, which require more free drift rate parameters than do the corresponding singleprocess model to characterize any given set of data. The reflecting Wiener model performed more poorly than the LDLIV model because it lacks a decay term to offset the tendency of dual-diffusion models to predict RT distributions that are more symmetrical than are found empirically. There was little evidence that the reflecting boundary contributed significantly to the performance of the model, which made it virtually identical to the racing Walds model, except for the inclusion of drift rate variability which the latter model did not have.</p><p>The racing Walds model was consistently the worst model across both experiments, even though its number of free drift rate parameters was almost double those in the other models.</p><p>The consistently poor performance of the racing Walds model highlights the importance of drift rate variability in accounting for the fine-grained properties of RT distributions and associated choice probabilities. As well as being theoretically principled, drift-rate variability is empirically necessary to provide satisfactory accounts of data. The free transition density for an LDLIV process governed by Equation 2 has the form <ref type="bibr">(Giorno et al., 1989a, Equation 6</ref>.2), because there do not appear to be closed-form expressions for the moments. The slope of the line relating the standard deviation to the mean is steeper for smaller values of q because when q is small the mean grows more slowly relative to the standard deviation.</p><formula xml:id="formula_11">f (x, t |z, τ ) = p σ [e p(t−τ ) − 1] exp − p x + ze p(t−τ ) σ [e p(t−τ ) − 1] × xe −p(t−τ ) z (q−σ)/2σ I q/σ−1 2p √ xze p(t−τ ) σ [e p(t−τ ) − 1] .<label>(13)</label></formula><p>If we would like to interpret the diffusion process in the LDLIV model as an approximation to the neural processes of evidence accumulation, then the distributions in <ref type="figure" target="#fig_15">Figure  7</ref> have the right kinds of general properties. The distributions of evidence are positivelyvalued and positively-skewed, and their means and standard deviations both increase with time, as we would expect from neural firing rates (e.g., <ref type="bibr" target="#b115">Roitman and Shadlen (2002)</ref>  <ref type="figure" target="#fig_10">Figure   4</ref>). The statistics of neural spike trains are often characterized using the so-called "Fano factor," defined as Var(X t )/M(X t ), that is, as the ratio of the variance of the firing rate to its mean <ref type="bibr">(Reike et al., 1999, p. 52)</ref>. In an idealized model neuron in which the firing rate is a</p><p>Poisson process the Fano factor is unity, but, as Reike et al. point out, Fano factors for real neurons are highly variable and may be much less than or much greater than the Poisson ideal and may also vary systematically with time. Any identification of the properties of the LDLIV model with the underlying neural dynamics would most plausibly be made at the level of the neural populations rather than the individual neurons, so we should not necessarily expect distributions of evidence in the accumulators to mirror the firing rates of individual neurons because they are at different levels of description. <ref type="figure" target="#fig_17">Figure 8</ref> shows the fitted distributions of drift rates for correct response and error accumulators in the LDLIV model for the <ref type="bibr" target="#b95">Ratcliff (2008)</ref> and  studies. The distributions in the figure are lognormal distributions parameterized according to Equation 9 using the averaged parameters in <ref type="table" target="#tab_4">Table 4</ref> and   <ref type="table" target="#tab_4">Table 4 and Table 7</ref>, respectively.</p><p>which embodies three neurally-inspired elements of model construction that the standard diffusion model lacks, namely, positivity, boundedness, and separate evidence totals for different responses. The resulting model performed similarly to the diffusion model in the fits to the data from two studies -somewhat better than the diffusion model for one, similarly or somewhat worse than the diffusion model for the other, depending on the model selection criterion -and systematically better than two other dual-diffusion models that embodied some but not all of these elements. To the extent that these elements are deemed important for model construction the performance of the LDLIV model is reassuring, because it shows that a mathematically tractable, neurally-inspired, diffusion model yields similar empirical predictions to the original model. I chose to use von Neumann's problem to motivate the LDLIV model for two reasons.</p><p>First, it highlights the unity and continuity of a body of theory that extends back to Fechner (1860) and forward into the twentieth century through <ref type="bibr" target="#b165">Thurstone's (1927)</ref> law of comparative judgment and signal detection theory <ref type="bibr" target="#b52">(Green &amp; Swets, 1966)</ref> to the sequential-sampling models of the 1960s and 1970s. As I noted in the Introduction, <ref type="bibr" target="#b76">Link (1994)</ref> argued that Fechner had a well-articulated theory of decision-making based on Gauss's theory of errors, which holds that probabilistic, normally-distributed variation in measurement will arise when the measurements are aggregates of elements, each of which is independently subject to error.</p><p>The modern expression of this result is the central limit theorem <ref type="bibr" target="#b9">(Breiman, 1968</ref><ref type="bibr">(Breiman, /1992</ref>) and its particular power comes from the fact that the distribution of the aggregate is predicted to be normal, regardless of the distribution of the errors. <ref type="bibr">6</ref> In choosing Gauss's theory to characterize the processes underlying the variability of psychophysical decisions,</p><p>Fechner thus appears to have understood that the brain solves von Neumann's problem in the way von Neumann proposed, by aggregation. The second reason for using von Neumann's problem is that it highlights an essential philosophical difference between models that seek to provide a solution to his problem and those that do not. The latter include a miscellany of models that represent evidence accumulation as a deterministic rather than a stochastic process. These include the Grice model <ref type="bibr" target="#b37">(Dzhafarov, 1993;</ref><ref type="bibr" target="#b53">Grice, 1972)</ref>, the "random ray" model <ref type="bibr" target="#b110">(Reeves et al., 2005</ref>), the LATER model <ref type="bibr" target="#b21">(Carpenter, 2004)</ref>, and the one of a number of results in the theory of stable distributions <ref type="bibr" target="#b9">(Breiman, 1968</ref><ref type="bibr">(Breiman, /1992</ref>) that characterize the possible forms of the limiting distribution obtainable from a scaled sum of random variables. Breiman points out that the domain of attraction of the normal probability law contains distributions with finite second moments but is not restricted to them, so finiteness of the second moment is a sufficient but not necessary condition. The necessary condition, which is abstract and technical <ref type="bibr" target="#b9">(Breiman, 1968</ref><ref type="bibr">(Breiman, /1992</ref>, p. 214, Equation 9.42), was given by <ref type="bibr">Gnedenko and Kolmorogov (1954)</ref>.</p><p>ballistic and linear ballistic accumulator (LBA) models <ref type="bibr">(Brown &amp; Heathcote, 2005</ref><ref type="bibr" target="#b95">, 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deterministic Versus Stochastic Evidence Accumulation</head><p>Recent treatments of decision processes have sometimes used the term "evidence accumulation model," as a synonym for sequential-sampling models, as I have defined them here, as models in which evidence is accumulated by summing successive samples from a noisy evidence sequence. However, the term is often used more inclusively, to encompass the deterministic growth models in the preceding paragraph. Although such models are often referred to as evidence accumulation models, strictly speaking they are not -or not in the sense in which "evidence accumulation" is used in relation to sequential-sampling models. Rather, all of the evidence used to make a decision in such models, in the form of a probabilistic representation of the discriminative information in the stimulus, is present at the beginning of the trial, or, more precisely, by the end of the stimulus encoding part of the nondecision time. In so-called piecewise ballistic accumulation <ref type="bibr" target="#b64">(Holmes et al., 2016)</ref>, the encoded evidence state can change if the physical stimulus changes but in either version of the model there is no accumulation of evidence comparable to that which occurs in sequential-sampling models. Instead there is deterministic growth of an activation state that translates the evidence encoded at the beginning of the trial -or as recoded at discrete change points -into an overt response. The decision time component of RT is the time needed to effect this translation.</p><p>Deterministic growth models like the LBA (in either its original or piecewise form) were not designed to provide a solution to von Neumann's problem. Rather, these models have the pragmatic aim of providing a so-called "measurement model" that allows meaningful components of processing, like decision criteria, rate of evidence growth, or nondecision time, to be estimated from data. Much of the attraction of a model like the LBA is its comparative simplicity and the ease with which such components can be estimated <ref type="bibr" target="#b11">(Brown &amp; Heathcote, 2008)</ref>. Although this is a defensible objective, it does beg the question, if the model is not conceptualized as being a model of what the brain is actually doing, then what criteria can be used to validate the resulting estimates? Sometimes the LBA has been validated by pointing to the similarity between its parameter estimates and those of the diffusion model <ref type="bibr" target="#b29">(Donkin et al., 2011)</ref>, but this strategy relies on the existence of a model that can be used as a gold standard against which other models can be validated. But if the diffusion model is deemed to be the gold standard, why not simply use it? The LBA has also been validated by showing that its estimated parameters behave in predictable and interpretable ways in response to experimental manipulations <ref type="bibr">(Dutilh et al. 2019)</ref>. Such integration. The speed-accuracy tradeoff, which is one of the most basic and ubiquitous phenomena in decision making <ref type="bibr">(Luce, 1986, ch. 6.5)</ref>, follows immediately from the assumptions of these models: The more evidence that is accumulated, the more reliable the resulting decision will be.</p><p>Unlike sequential-sampling models, deterministic growth models have a problem in explaining why errors occur at all. The LBA assumes that errors occur because of variability in drift rates. As a result, evidence sometimes grows more rapidly in the error accumulator than in the correct response accumulator, leading to an error. But this does not suffice to explain the speed-accuracy tradeoff: If evidence growth is deterministic, then accuracy after a long period of growth will be the same as after a short period, so changing decision boundaries in itself buys you nothing. The LBA's solution to this problem is to assume that longer periods of evidence accumulation help overcome starting point biases. If the starting points for evidence accumulation are biased towards the wrong response, then increasing decision boundaries will help to offset the bias and accuracy will be greater with large than with small boundaries.</p><p>In a purely technical sense, this explanation works. The LBA has been fitted to a number of data sets in which discriminability has been crossed with speed versus accuracy instructions and has captured the resulting data successfully. It is therefore unlikely we could expect to adjudicate between deterministic and stochastic models on the basis of fit statistics alone. A more relevant question to ask is: what is being explained in each case? In diffusion models, the speed-accuracy tradeoff is an expression of the model's solution of von</p><p>Neumann's problem, which is a deep and general problem about the reliability of biological computation and of how neurons transmit information statistically. In the LBA, the speedaccuracy tradeoff is an expression of how starting-point bias interacts with the rates of evidence growth. These biases were introduced into the design of the model because without them it would be unable to predict speed-accuracy tradeoffs. In diffusion models, the speedaccuracy tradeoff predictions are an expression of a solution to a general theoretical problem; in the LBA model, they are an expression of a feature of the model that was put there for the express purpose of explaining why speed-accuracy trade-offs occur.</p><p>A possible response to the validation question for deterministic models is to argue that a model like the LBA or the Grice model is a model of what the brain is doing. The argument is sometimes made that if the population of neurons that encode cognitive representations is large then the central limit theorem will ensure that the functions that characterize evidence accumulation in the population will be sufficiently close to deterministic that they can characterized satisfactorily by deterministic dynamics like those in the LBA and the Grice model. Although this position is arguable, there are two obvious objections to it.</p><p>The first is that the neurons that encode a stimulus in a population are not independent but weakly-coupled and in weakly-coupled networks the usual central-limiting arguments do not apply. Such networks can continue to exhibit large variability even when the number of neurons in the network becomes large <ref type="bibr" target="#b5">(Bair et al., 2001;</ref><ref type="bibr">Mazurek &amp; Shadlen, 2002;</ref><ref type="bibr" target="#b198">Zohary et al. 1994)</ref>, so near-deterministic dynamics is not an inevitable consequence of large populations. A second objection -setting aside the properties of weak couplingis why, if the populations are sufficiently large that the moment-to-moment stochasticity in evidence accumulation is almost entirely averaged out, there is still large trial-to-trial variability in the rates of evidence accumulation in the LBA or in decision criteria in the Grice model? If the averaging is sufficient to remove moment-to-moment variability, why does significant trial-to-trial variability remain? While it may be possible to argue that within-trial and across-trial variability have different sources, one of which averages out and one of which does not, the theoretical argument for why significant, residual across-trial variability should remain in the process after all of the within-trial variability is averaged out has not been articulated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drift Rate Variability</head><p>In the Introduction I emphasized the close theoretical relationship between sequentialsampling models and earlier models of psychophysical decision-making like signal detection theory that assume normally-distributed stimulus representations. I characterized those models as solving von Neumann's problem in space -in the sense of aggregating information across members of a neural population, or more abstractly, across a set of noisy encoding elements -and the sequential-sampling models as solving his problem in time.</p><p>Viewed in this way, there is a close relationship between the assumption that evidence is accumulated by a diffusion process and the assumption that the evidence entering the process is normally distributed across trials. Both of these assumptions follow from the larger theoretical argument that the primary impediment to reliable computation in the brain and central nervous system is the need to solve von Neumann's problem. This view of the complementarity of diffusive evidence accumulation and normally-distributed drift rates contrasts with recent discussions that have portrayed the drift-rate assumptions as arbitrary and ad hoc. <ref type="bibr">Jones and Dzhafarov (2014, p. 24)</ref> asserted: "One possibility is that the Gaussian distribution is psychologically correct, but this is doubtful for three reasons.</p><p>First, there is no clear reason to expect a Gaussian. Whereas the Gaussian distribution of within-trial variability emerging from a diffusion process can be explained by the summation of many independent neural events (via the central limit theorem), there is no obvious candidate for a between-trial analog-that is, a large number of independent and identically distributed between-trial variables that sum to determine the drift rate." Heathcote et al.</p><p>(2014, p. 677) similarly remarked: "It is true that the particular forms of the across-trial variability parameters in decision-making models (Gaussian and uniform) were originally chosen arbitrarily, for practical and not theoretical reasons." In a similar vein, Tillman et al. (2021, p. 913) argued: "...the between-trial variability assumptions are not part of the process model that explains how the RT data are generated. The core process of sequential sampling models is the integration of evidence to a threshold, which explains how someone makes a decision, but the between-trial variability assumptions provide no additional explanation of the decision process and are simply added to help the models fit data."</p><p>Contrary to these portrayals of drift-rate variability as theoretically unmotivated, I view it as a natural expression of how the brain solves von <ref type="bibr">Neumann's problem, namely, by</ref> aggregating across a population of elements that each provide a noisy representation of the information in the stimulus. The strongest objection I can see to the argument that drift rates will be normally distributed is the work <ref type="bibr" target="#b198">Zohary et al. (1994)</ref> and others implying that neurons in a population are weakly-correlated rather than independent, which means that a simple central-limit theorem argument may not apply. If the elements in a representation are correlated, then its quality may not improve in proportion to the square root of the number of elements that compose it as implied by the central-limit theorem and, indeed, depending on the correlations in the population, the result need not be normally distributed.</p><p>However, in the absence of some specific, neurally-derived model of drift-rate variability, the normal distribution remains the most natural one to assume on general theoretical grounds as an expression of the aggregation of elements within a population.</p><p>If normal distributions of drift rates indeed arise because they are aggregates across populations of independent, noisy elements, then this might seem to be a reason to prefer the standard diffusion model over the dual diffusion models, in which the drift rates are nonnormal. However, it should be remembered that the normal distribution is the limiting form of the distribution when the number of noisy elements contributing to it is large and the limiting form may be more or less well approximated depending on the size of the population. In the case of the LDLIV model, those elements, whether they are the firing rates in individual neurons or some more abstract entities like the "evidence samples" in the sample size model <ref type="bibr" target="#b135">(Smith et al., 2018)</ref>, are constrained to be positive by virtue of the diffusion equation, Equation 2. Sums of even highly-skewed, positively-valued random variables converge to the normal distribution in the limit -the sum of single degree-offreedom chi-square random variables is a well-known example -so the positivity of the elements does not preclude a normal probability law for the sum or the average in the limit. The drift rate distributions in <ref type="figure" target="#fig_15">Figure 7</ref>, although not algebraically normal, are fairly symmetrical, as we would expect if they approach a limiting normal form but do not fully achieve it. The fact that the model does not assume normal distributions of drift rates does not invalidate the broader argument that drift rate variability is a reflection of the way in which the brain solves von Neumann's problem.</p><p>Competitive Interactions, Continuous Motor Processes, and Model Mimicry I motivated the LDLIV model via three neurally-inspired design principles -separate accumulation, positivity, and boundedness -and showed that a model embodying these principles performs comparably to the standard diffusion model in accounting for empirical data. However, there are other neurally-inspired design principles that researchers have argued are important. One is competitive interaction or mutual inhibition between accumulating evidence totals; another is continuous flow of activation from the decision process to the motor system. It is beyond the scope of this article to evaluate either of these principles systematically, but arguments have been made for the importance of both of them, so I discuss them briefly below.</p><p>Competitive interaction among representations is a powerful computational principle that can implement, among other things, efficient selection of targets from among distractors in search tasks <ref type="bibr" target="#b149">(Smith &amp; Sewell, 2013;</ref>. Competitive interactions implemented by multiplicative, or "shunting," differential equations lead to divisive normalization models in which the strength of activation in a representational unit is divided by the sum of the strengths of the units with which it competes <ref type="bibr" target="#b54">(Grossberg, 1980)</ref>. <ref type="bibr">Carandini and Heeger (2013)</ref> reviewed evidence suggesting that divisive normalization is ubiquitous in the brain. <ref type="bibr" target="#b54">Grossberg (1980)</ref> argued that divisive normalization allows the brain to retain its sensitivity to small stimulus differences without saturation under conditions in which stimulus intensities may vary over several orders of magnitude. For decision modelers, however, the question of interest is not the general one of whether or not these kinds of competitive interactions occur neurally but the narrower one of whether they occur between accumulating evidence states in a sequential-sampling decision model.</p><p>The prototypical competitive interaction model is the leaky competing accumulator (LCA) model of <ref type="bibr" target="#b174">Usher and McClelland (2001)</ref>, which represents the decision process as a race between mutually-inhibitory OU diffusion processes constrained to be positive by reflecting boundaries. <ref type="bibr" target="#b103">Ratcliff and Smith (2004)</ref> found that an LCA model with lateral inhibition performed no better than a dual diffusion model with drift rate variability and decay but no lateral inhibition. <ref type="bibr" target="#b90">Purcell et al. (2012)</ref> used an n-alternative version of an LCA model to model visual search for a target stimulus among distractors in monkeys performing a saccade-to-target decision task. They found that RTs were better described by a model, which they called a "gated accumulator model," which had competitive interactions among accumulators, than they were by a model without such interactions. <ref type="bibr" target="#b23">Cox et al. (2022)</ref> combined the competitive interaction model of attentional selection of <ref type="bibr" target="#b149">Smith and Sewell (2013)</ref> with the gated accumulator model of <ref type="bibr">Purcell et al. to</ref>  way, there were a subset of neurons whose activity was best modeled by assuming lateral inhibition, although its contribution to overall fit was less important than recurrence and feedforward inhibition.</p><p>The evidence for lateral inhibition in search is unsurprising because successful search requires resolution of the competition between targets and distractors and lateral inhibition is an effective way to accomplish this, especially when it is nonlinear <ref type="bibr" target="#b23">(Cox et al., 2022;</ref><ref type="bibr" target="#b54">Grossberg, 1980;</ref><ref type="bibr" target="#b149">Smith &amp; Sewell, 2013;</ref>. However, an identified role for lateral inhibition in search leaves open the question of its role in tasks not involving inhibition or suppression of distractor stimuli. <ref type="bibr" target="#b174">Usher and McClelland (2001)</ref> used lateral inhibition in their LCA model as an alternative to drift-rate variability as a way to predict slow errors.</p><p>Lateral inhibition in race-model architectures has recently been implicated in the absoluteintensity or absolute-value effect <ref type="bibr" target="#b73">(Kirkpatrick et al., 2021;</ref><ref type="bibr" target="#b109">Ratcliff et al., 2018;</ref><ref type="bibr">Teodorerscu &amp; Usher, 2013;</ref><ref type="bibr" target="#b161">Teodorescu et al., 2016)</ref>. This is the finding that decisions about differences between pairs of stimuli of equivalent intensity, strength, or value are faster if they are stronger than if they are weaker. Teodorescu and Usher and Teodorescu et al. argued that these findings are better characterized by a racing-processes decision architecture than by a single-process architecture and found the best model was the LCA model, which has inhibition between accumulating evidence states. <ref type="bibr">Ratcliff et al. subsequently</ref> showed that a single-process diffusion model in which drift-rate variability scales with stimulus strength can predict the absolute-strength phenomena reported by Teodorescu and colleagues. Kirkpatrick et al. fit several versions of the LCA model, including models without leakage and without inhibition, to data from two absolute-intensity tasks and found the full LCA model performed better than any of the reduced versions of it. This result in itself is unsurprising because, as shown by <ref type="bibr" target="#b143">Smith and Ratcliff (2009)</ref>, leakage and drift-rate variability are both needed to capture the shapes of RT distributions for correct responses and errors in racing-accumulator architectures and, in the absence of drift-rate variability, inhibition allows models to predict slow errors. However, <ref type="bibr">Kirkpatrick et al. also</ref> showed that the full LCA model augmented with the same extra sources of variability used by <ref type="bibr">Ratcliff et al.</ref> still perform better than any of reduced versions of it for a majority of participants. Their results suggest that, in these kinds of paradigms at least, inhibition is doing something more than drift-rate variability alone. This finding is suggestive, but it was based on very small samples (48 trials/condition) and the graphical presentation of fit did not include any representation of distribution shape or the relationship between correct responses and errors.</p><p>Moreover, even at the level of the choice probabilities and mean RTs the authors used to assess fit qualitatively the best LCA model showed misfits in some conditions. Clarifying these relationships, using models like the LDLIV model, will require further research.</p><p>Another open question concerns the relationship between the decision process and the motor process it drives. There are two parts to this question. The first concerns the additive decomposition of RT into a sum of independent random variables representing decision and nondecision processes (the latter designated T er in the models considered here). The second concerns the form of the distribution assumed for T er . The additive decomposition is an expression of the stage-dependent processing assumption formalized in <ref type="bibr" target="#b155">Sternberg's (1969)</ref> additive-factors method: RT is the sum of the times required to complete a sequence of independent processing stages and processing in a stage only begins once the previous stage is complete. If the decision process is viewed as a discrete stage in an additive-factors architecture then completion of the decision stage is a point event that can be identified theoretically with the process reaching a decision criterion or boundary.</p><p>From a neural modeling perspective, boundary crossings are idealized, abstract events, and models in which there a continuous flow of activation from the decision process to the motor system may seem intrinsically more plausible, given the highly interconnected nature of the brain as a whole. Researchers like <ref type="bibr" target="#b72">Kelly et al. (2021)</ref>, for example, have argued that we should conceptualize evidence accumulation as being essentially a motor preparation process. In this spirit, <ref type="bibr" target="#b178">Verdonck et al. (2021)</ref> proposed a continuous-flow motor activation model in which a Wiener diffusion process drives a leaky integrating threshold (LIT) process.</p><p>In the LIT model, activation in the motor system, Y t , is related to accumulated evidence in the decision process, X t , by the linear differential equation</p><formula xml:id="formula_12">dY t = (βX t − λY t ) dt.<label>(14)</label></formula><p>In this equation β is a scaling or gain parameter and λ is a motor system decay parameter.</p><p>In comparison to the Wiener process model, the integrated evidence in the LIT model is subject to an additional integration, with decay, in order to make a response. This occurs when the doubly-integrated process reaches a threshold. Poisson processes, the shot-noise difference process approximates an OU process and the accumulated evidence, obtained by integrating the instantaneous evidence state over time, approximates an integrated OU process, U t . The equivalence of the LIT and integrated OU models can most easily be seen by comparing Equations 19 and 20 in <ref type="bibr" target="#b132">Smith (2010)</ref>, which give the mean and variance of the integrated OU process, U t , with the unnumbered equations between Equations 5 and 6 in Verdonck et al., which give the mean and variance of the LIT process, Y t . Except for scaling constants, the two sets of equations are identical.</p><p>Equality of the mean and variance of two stochastic processes does not mean the processes themselves are identical, but in fact the motor activation process, Y t , in the LIT model and the integrated OU process, U t , in the shot noise model, are identical in the sense that they satisfy the same stochastic differential equation. <ref type="bibr" target="#b178">Verdonck et al. (2021)</ref> showed that the process dY t /dt in the LIT model (the unnumbered equation beneath their <ref type="formula" target="#formula_1">Equation 2)</ref>has a form that can be recognized as a linear functional representation of the OU process <ref type="bibr">(Bhattacharya &amp; Waymire, 1990, p. 581, Equation 2.49)</ref>. The integral of this process is the integrated OU process, U t , so it follows that Y t and U t satisfy the same stochastic differential equation. This being so, the question of where the boundary or threshold is placed theoretically may not be as consequential for a model's performance as first appearances might suggest. The reader is referred to Smith (2010) for a characterization of the integrated OU process as a model of decision making and its relationship to the Wiener process, which it approaches asymptotically.</p><p>The second part of the motor-process question concerns the distribution of the nondecision time, T er . Many researchers (myself included), have followed Ratcliff and colleagues (e.g., <ref type="bibr" target="#b108">Ratcliff &amp; Tuerlinckx (2002)</ref>) and modeled T er as uniformly distributed with range s t . The justification for using a uniform distribution is the pragmatic one that, if the variance of the nondecision time is small relative to that of the decision time, then the shape of the smaller component does not much matter, because the standard deviation and the shape of the predicted RT distribution will be almost completely determined by those of the decision time distribution. If so, then the uniform distribution, which is easy to handle computationally, is as good as any other. Some researchers have proposed alternatives to this approach, such as <ref type="bibr" target="#b125">Smith (1989)</ref> who used distributions of simple (i.e., one-choice) RT as estimates of the nondecision time distribution and deconvolved them from the distributions of RT using Fourier methods <ref type="bibr" target="#b127">(Smith, 1990)</ref> to obtain estimates of the distributions of decision times. However, this approach is open to the objection that the component being deconvolved out may be too large. Essentially, it relies on the assumption -first made by <ref type="bibr">Donders (1869</ref><ref type="bibr">Donders ( /1969</ref> and termed the " assumption of pure insertion" by <ref type="bibr" target="#b155">Sternberg (1969)</ref> -that the duration of a processing stage can be estimated by comparing RTs on two different tasks that are thought to differ by the presence or absence of the stage in question.</p><p>As emphasized by Sternberg, there is no way to verify this assumption and there may be good grounds to doubt it.</p><p>A novel approach to estimating the distributions of motor times was suggested by Verdonck and Tuerlinckx (2016), with their so-called D * M method. They observed that a common, unobserved component of RT can be estimated from a pair of experimental conditions by cross-convolution. If g 1 (t) and g 2 (t) denote the decision-time density functions in two different conditions and r(t) is their common motor density, then the observed RT density functions, f 1 (t) and f 2 (t), will be the convolutions of the decision time and motor time densities, if the decision and motor times are independent random variables. In symbols, f 1 (t) = g 1 (t) * r(t) and f 2 (t) = g 2 (t) * r(t), where the asterisks denote convolution.</p><p>Verdonck and Tuerlinckx pointed out that if the assumption of a common, independent motor component holds then the decision-time components can be estimated by computing the cross-convolution of the empirical RT distribution with the candidate decision time distribution for the other condition, that is, f 1 (t) * g 2 (t) and f 2 (t) * g 1 (t). If the candidates for g 1 (t) and g 2 (t) have been correctly specified then the two cross-convolutions should be equal to each other because f 1 (t) * g 2 (t) = f 2 (t) * g 1 (t) = g 1 (t) * g 2 (t) * r(t), in either instance.</p><p>The best estimates of the decision time distributions will therefore be the ones that makes the difference between the two empirical cross-convolutions as small as possible. Once these components have been estimated the unknown motor component can be recovered, in principle at least, by deconvolution. To date the method has not been widely applied, except by its developers, and many researchers may wish to see more simulation and empirical studies before embracing fully it as a data-analytic tool. Nevertheless, the method appears to represent a welcome attack on a problem that for a long time has seemed intractable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Levels of Description in Decision Models</head><p>I characterized the LDLIV model as "neurally-inspired," in the sense that it embodies design features that neural decision-making studies have suggested are desirable in a cognitive model, namely, separate accumulation, positivity, and boundedness or saturation. I noted that diffusion model representations of the process of evidence accumulation can be obtained either in a top-down way, from mean-field models of attractor dynamics, or in a bottom-up way, from the statistics of the flux of postsynaptic potentials induced by a stream of action potentials. Diffusion processes therefore provide a natural way to represent the statistical properties of ensembles of neurons. Nevertheless, it has sometimes been argued these kinds of models, regardless of their architecture, lack neural realism, and that a truly "neural" explanation needs to be at a more granular level, as exemplified, for instance, by the spiking neuron model of Wang and colleagues <ref type="bibr" target="#b80">(Lo &amp; Wang, 2006;</ref><ref type="bibr" target="#b190">Wang, 2001</ref><ref type="bibr" target="#b191">, Wang, 2002</ref><ref type="bibr" target="#b194">Wong &amp; Wang, 2006)</ref>. As noted previously, the Wang model is an attractor model composed of spiking neurons with temporal response properties that embody the properties of real neurons. The model was developed originally to try to solve the problem of how to bridge the gap between the different time scales of cognitive and neural integration. Cognitive models assume that evidence is integrated, or accumulated, on a time scale of around a second or so, but as Wang has argued, the longest neural integration times are around 50-100 ms, which is an order magnitude shorter than this, and the wrong time scale on which to implement evidence accumulation behaviorally. He proposed that behavioral-level integration is implemented by persistent activity in reverberation loops and his spiking neuron model embodies this idea in its architecture. The model captures the main features of choice probabilities and mean RTs but, until recently, it had not been shown to characterize RT distributions for correct responses and errors in the level of detail I have considered here.</p><p>Recent progress on this question was reported by <ref type="bibr" target="#b173">Umakantha et al. (2022)</ref> who fitted the diffusion model to simulated data from the Wang model and found that the choice probabilities and RT distributions for correct responses were well-fitted in all cases -although the quality of the fit to the RT distributions is difficult to infer from their figures because they plotted it using cumulative distribution functions (see my earlier remark on the use of cumulatives in depicting fit). Beyond questions of fit, Umakantha's larger question was whether there was mutual translatability between the two models, that is, whether psychological parameters of the diffusion model had interpretable physiological correlates in the parameters of the Wang model, and vice versa. In some instances, parameters of the diffusion model like drift rate, boundary separation, and nondecision time had identifiable physiological analogues in the Wang model, but in other instances the mapping between the models was less clear.</p><p>Models like the Wang model raise a general philosophical question about the appropriate level of description at which to explain decision making or other cognitive phenomena. One view is that the more neural detail the better, and that a description at the level of a network of spiking neurons is more biophysically grounded and in some sense more scientifically "real" than a description at the level of a diffusion process. My view is that there are multiple levels of description on which we might seek to characterize a phenomenon like decision making, which differ in their granularity or resolution and that the best level of description is not necessarily the most granular one. Rather, it is the one at which the phenomenon appears simplest and most lawful. Nevertheless, a complete scientific explanation needs to characterize how the explanatory entities at one level of description are related to those at levels below it. <ref type="bibr" target="#b7">Boden (1972)</ref> used the term "empirical reduction" to describe explanations of this kind, which she distinguished from "strict reduction." In strict reduction, all statements about phenomena at a higher level of description are translated into statements at a lower level and are replaced by them. In empirical reduction, the explanatory entities used to explain phenomena at a higher level are characterized in terms of entities at lower levels. In Boden's terms, the study by <ref type="bibr" target="#b173">Umakantha et al. (2022)</ref>  LDLIV model over the standard diffusion model because it is more "neural" and hence more likely to approximate the scientific ground truth? My results imply that there is substantial mimicry between the two models and that in many settings it is likely they will provide similarly good accounts of empirical data. There is a high degree of convergence between the diffusion model, which is a purely cognitive model, and the LDLIV model, which is a cognitive model augmented with some additional neural design principles that the diffusion model lacks. Whether or not these additional design principles are embodied in a model does not appreciably change the quality of the fit at the individual participant level, but importantly, they do not make it worse. Arguably more important than the differences between the two models are their points of similarity. Both model represent the decision process as an accumulation of noisy, continuously-varying evidence by a diffusion process and both predict slow errors by across-trial variability in drift rate. Both models provide a solution to von Neumann's problem, as I have defined it here, and moreover, both models solve it in a similar way, by a combination of within-trial and across-trial variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this article, I have introduced a new dual-diffusion model for decision making, the LDLIV motdel, which embodies three neurally-inspired principles of evidence accumulation:</p><p>separate accumulation, boundedness, and positivity, and have shown that it accounts suc-cessfully for two benchmark sets of experimental data. Unlike previous models that have imposed a positivity constraint on the accumulating evidence on grounds of neural plausibility, the evidence in the LDLIV model is naturally restricted to the positive real line without artificial barriers like reflection or truncation. To the extent that its dynamics constrain it to the positive real line, the process can be viewed as a natural expression of the idea that the diffusion process is a cognitive-level expression of evidence accumulation processes implemented by neural firing rates. The distributions of evidence in the process are positively skewed, again as would be expected of processes implemented by neural firing rates, and obey a simple scaling law in which the mean and standard deviation grow in proportion to one another, independent of decay. Like other successful dual diffusion models, the model assumes that evidence decays while it is being accumulated, leading to saturation at high intensities. Also, like other successful single and dual diffusion models, the model accounts for slow errors via across-trial variability in drift rate. I emphasized in the Discussion that the construct of drift-rate variability in the models is neither ad hoc nor arbitrary, but, like the evidence accumulation process itself, is an expression of how the brain solves von</p><p>Neumann's problem of building reliable organisms from unreliable components.</p><p>at a(τ ) at time τ , it then transitions to state a(t) at time t. Because the event that X t makes its first boundary crossing at time τ , τ ∈ (0, t), is one of a set of mutually exclusive events, the probability density of the point X t = a(t) can be obtained by integrating the product of these two densities over all values of τ from 0 to t.</p><p>To express this symbolically, denote by f (x, t | y, τ ) the free transition density of the diffusion process X t , that is, the probability density that the process, unconstrained by boundaries, starting at y at time τ , will be found at x at time t. For the Wiener and OU processes the free transition density is Gaussian but other assumptions about the drift and diffusion rates lead to non-Gaussian distributions. Denote by g[a(t), t | z, 0] the first-passage time density of the process through the boundary a(t) at time t. The conditional notation expresses the idea that the process transitions from a point z at time 0 to the point a(t) at time t and moreover, that this is the first boundary crossing. Fortet's decomposition states The term on the left-hand side is the free transition density of the process starting at X 0 = z evaluated at X t = a(t). The first term under the integral on the right is the first-passage time density of the process starting at z at time 0 through the boundary a(τ ) at τ . The second term is the free transition density of the process starting from the boundary point a(τ ) at τ and transitioning to a point on the boundary a(t) at time t. This latter point may either be the first boundary crossing or there may be one or more additional crossings before this point. The decomposition in Equation A1 covers both eventualities.</p><p>Equation A1 is a Volterra integral equation of the first kind, in which the unknown function of interest, the first-passage time density function g[a(t), t | z, 0], appears under the integral sign. For processes with two absorbing boundaries, as often arise in modeling decision processes, there are two such equations, one for each boundary, and the decomposition based on first boundary crossings needs to keep track of crossings at each of them separately <ref type="bibr" target="#b16">(Buonocore et al., 1990;</ref><ref type="bibr" target="#b130">Smith, 2000;</ref><ref type="bibr" target="#b145">Smith &amp; Ratcliff, 2022)</ref>, but I restrict myself here to the single boundary case, which is the one that arises in models with racing processes. <ref type="bibr" target="#b15">Buonocore et al. (1987)</ref> showed that it is possible to transform Equation A1 into a Volterra integral equation of the second kind, in which the unknown function appears on the left-hand side and is expressed as the integral of the product of its values at earlier times, τ &lt; t, and a kernel function, Ψ[a(t), t |a(τ ), τ ], and showed how it is possible to derive the kernel function for a number of well-known diffusion processes, including the Wiener process and the OU process. When X 0 &lt; a(0), that is, the process starts below the boundary, the resulting equation is </p><p>which is Equation 3 in the text. Equation A2 is obtained from Equation A1 integrating both sides of the equation over the state variable x from a(t) to ∞, then by exchanging the order of integration, then by differentiating the equation with respect to time, and finally by considering the limit of the resulting double integral as τ → t. The reader is referred to <ref type="bibr" target="#b130">Smith (2000)</ref> or the original article of <ref type="bibr" target="#b15">Buonocore et al. (1987)</ref> for details.</p><p>Equations A2 is evaluated numerically by discretizing it and evaluating it on the grid k∆, k = 1, 2, . . . by trapezoidal integration. The discretized form of the equation <ref type="bibr" target="#b16">(Buonocore et al., 1990;</ref><ref type="bibr">Smith, 2000, pp. 440-441</ref> </p><p>Buonocore et al. <ref type="bibr">(1987)</ref> showed that, when the kernel is chosen in the manner they prescribed, the discretized first-passage time density obtained from Equation A3 converges to the true first-passage time density as ∆ becomes small.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Sequential-sampling decision models. (a) Single-process Wiener diffusion model (DIFF).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2</head><label></label><figDesc>The forward equation is known in physics as the Fokker-Planck equation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(</head><label></label><figDesc>four in the Ratcliff study and five in the Smith et al. study) crossed with other experimental manipulations that produced different, and highly constrained, patterns of correct and error RTs, which are important in model comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>varying, as the notation suggests. The integral equation method yields a representation of the first-passage time density function in the form of a Volterra integral equation of the second kind, of the form</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5</head><label></label><figDesc><ref type="bibr" target="#b48">Giorno et al. (1989a)</ref> write the last term term of Equation 7 in terms of the Gaussian error function, Erf(•), rather than the normal distribution function, Φ(•). The two are related by 1 − Erf(x) = 2Φ(− √ 2x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Simulated and predicted joint density functions for correct responses, g C (t), and errors, g E (t), for dual reflecting Wiener and LDLIV models. Each of the simulations was based on 100,000 trials using a time step of 0.001 s. (a) Dual reflecting Wiener model with parameters µ 1 = 1.75, µ 2 = 0.5, a 1 = 1.5, a 2 = 1.5, σ = 1.0, z = 0, r = −0.1. (b) Dual LDLIV model with parameters q 1 = 1.5, q 2 = 0.75, a 1 = 1.2, a 2 = 1.2, σ = 1.0, p = −0.01, z = 0.1.(c) Comparison of the reflecting Wiener and LDLIV models with parameters as in (a) and (b). (d) Comparison of the reflecting Wiener and LDLIV models with parameters as in (a) and (b) except with large LDLIV decay (p = −1.0). In (c) and (d) the continuous curves are the reflecting Wiener model and the dashed curves are the LDLIV model. random walk. Each of the simulations was based on 100,000 trials with a step size of 0.001 s. The predictions were computed using Equation A3 using a time step of 0.01 s, which sufficed to provide good agreement with the simulations. The simulations show that the integral-equation method is an effective way to evaluate models of this kind. Smith and Ratcliff (2022) give further examples of simulated and integral-equation predictions for time-varying Wiener and OU processes. The bottom panels of Figure 2 compare the dual reflecting Wiener and LDLIV models to each other.Figure 2ccompares the predictions when the LDLIV decay parameter is small (p = −0.01) andFigure 2dcompares them when it is large (p = −1.0). The parameters of the models inFigures 2a and 2bwere chosen by eye to try to make the predictions as close to each other as possible. As</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>The</head><label></label><figDesc>Two-Barrier and Single-Barrier Wiener Processes For consistency of implementation I used the integral-equation method to obtain predictions for the two-barrier Wiener model. Ratcliff and Smith (2004) compared the infiniteseries method and the integral-equation method and found their predictions were in close agreement. Smith and Ratcliff (2022) presented integral-equation solutions for the Wiener model with time-varying drift and diffusion rates and decision boundaries. I used a version</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>other processes as well. Several researchers have reported that speed-accuracy instructions affect nondecision times in addition to decision criteria<ref type="bibr" target="#b2">(Arnold et al., 2015;</ref><ref type="bibr" target="#b25">de Hollander et al., 2016;</ref><ref type="bibr" target="#b29">Donkin et al. 2011;</ref> Dutilh et al., 2019;<ref type="bibr" target="#b65">Huang et al., 2015)</ref> and others have reported they also affect mean drift rates or drift-rate variability<ref type="bibr" target="#b29">(Donkin et al., 2011;</ref><ref type="bibr" target="#b60">Heathcote &amp; Love, 2012;</ref><ref type="bibr" target="#b62">Ho et al., 2012;</ref><ref type="bibr" target="#b91">Rae et al., 2014;</ref><ref type="bibr" target="#b153">Starns et al., 2012)</ref>.<ref type="bibr" target="#b136">Smith and Lilburn (2020)</ref> suggested that these so-called violations of selective influence may reflect time-inhomogeneity in the drift and diffusion rates, and reanalyzed the random dot motion data of Dutilh et al. using a time-inhomogeneous diffusion model that captured the data well. Here I restrict myself to time-homogeneous versions of the models for the sake of computational tractability.<ref type="bibr" target="#b145">Smith and Ratcliff (2022)</ref> reported a reanalysis of the<ref type="bibr" target="#b95">Ratcliff (2008)</ref> numerosity data using models with a single T er parameter but I have instead allowed T er to vary with instructions as this produces substantial improvements in fits for the standard diffusion model. Whether these so-called violations of selective influence are best characterized as changes in the time of onset of evidence accumulation or as time-varying drift and diffusion rates is a question that is outside the scope of this article. My aim here is the narrower one of comparing the standard diffusion model and the racing diffusion models</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>in the bins bounded by the RT quantiles and "log" is the natural logarithm.The inner summation extends over the 12 bins formed by each pair of joint distributions and the outer summation extends over the M experimental conditions. For the numerosity study, M = 16 (2 Instruction conditions × 8 Dot proportions). For the cuing study, M = 5 (5 contrast conditions for each cell of the Cue × Mask experimental design). The quantity n i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>as implemented in Matlab (fminsearch). The fit statistics I report are the minimum G 2 values obtained from six runs of simplex using randomly perturbed estimates from the preceding run as the starting point for the next run. One of my reasons for preferring fits at the individual level using classical methods to hierarchical Bayesian methods is the latter -as least as they have been implemented in the literature to datetend to obscure the quality of the fits and the variation in comparative model performance at the individual participant level. To compare models with different numbers of parameters, I used standard model selection methods based on the Akaike information criterion (AIC; Akaike, 1974) and the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 .</head><label>4</label><figDesc>The reflecting Wiener process model was worse than the LDLIV model for a substantial majority of the participants (16/19 by either criterion). The reflecting Wiener model captured the shapes of the RT distributions fairly well in the speed condition but missed substantially in the accuracy condition. The pattern of misses is similar to that for the LDLIV model, but is magnified because the Wiener model does not have a decay term to offset the tendency for dual diffusion models to predict RT distributions that are more</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 3 :</head><label>3</label><figDesc>Quantile probability functions "large" and "small" responses for speed and accuracy conditions for the diffusion model, DIFF, and the LDLIV model fitted to the<ref type="bibr" target="#b95">Ratcliff (2008)</ref> numerosity data. The quantile RTs in order from the bottom to top are the .1, .3, .5, .7, and .9 quantiles (circles, squares, diamonds, inverted triangles, upright triangles, respectively). The dark gray symbols are the quantiles for correct responses and the light gray symbols are the quantiles for errors. The continuous curves and x's are the predictions from the model. For the data and models the quantile RTs are plotted on the y-axis against the observed and predicted response proportions on the x-axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4 :</head><label>4</label><figDesc>Quantile probability functions "large" and "small" responses for speed and accuracy conditions for the reflecting Wiener model, WNR, and the racing Walds model, WLD, fitted to the<ref type="bibr" target="#b95">Ratcliff (2008)</ref> numerosity data. The quantile RTs in order from the bottom to top are the .1, .3, .5, .7, and .9 quantiles (circles, squares, diamonds, inverted triangles, upright triangles, respectively). The dark gray symbols are the quantiles for correct responses and the light gray symbols are the quantiles for errors. The continuous curves and x's are the predictions from the model. For the data and models the quantile RTs are plotted on the y-axis against the observed and predicted response proportions on the x-axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 :</head><label>5</label><figDesc>Quantile probability functions for responses in the Cue × Mask conditions for the diffusion model, DIFF, and the LDLIV model fitted to the spatial cuing data.The interpretation of the figure is the same as forFigure 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 6 :</head><label>6</label><figDesc>Quantile probability functions for responses in the Cue × Mask conditions for the reflecting Wiener model, WNR, and the racing Walds model, WLD, fitted to the Smith et al. (2004) spatial cuing data. The interpretation of the figure is the same as for Figure 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 7 :</head><label>7</label><figDesc>Distributions of evidence states in the accumulators in the LDLIV model, as described by Equation 13. Figures 7a and 7b show distributions of evidence for q = 0.75 and q = 1.5, respectively. The black lines are for decay p = 0 and the gray lines are for decay p = 1.0. The five distributions in the figures are, left to right, for time t = 0.2, 0.4, 0.6, 0.8, and 1.0 s.Figure 7cshows SD(X t )/M (X t ), the ratio of the standard deviation to the mean of the evidence distributions at each of the five time points. The steeper function is for q = 0.75 and the shallower function is for q = 1.5. In both instances the functions are linear. The filled circles are values for p = 0 and the crosses are for p = 1.0.Distributions of Evidence in the Accumulators and Drift Rates Across TrialsLike standard diffusion model, the LDLIV model accounts for experimental data using a combination of within-trial variability in evidence and across-trial variability in drift rates.As I proposed in the Introduction and develop in the Discussion, drift-rate variability can be viewed as an expression of the way in which the brain solves von Neumann's problem. Unlike the standard diffusion model, neither the distributions of evidence in the accumulators nor the distributions of drift rates in the LDLIV model are normally distributed because of the positivity constraint on the LDLIV process in Equation 2 and on the drift rates in Equation 9. In this section, I characterize the distributions of evidence in the accumulators in the LDLIV model and show how they evolve over time. I also characterize the fitted distributions of drift rates used to model the experimental data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figures</head><label></label><figDesc>7a and 7b show examples of how the distribution of evidence in an accumulator grows as a function of time, as predicted by Equation 13. These distributions are distributions of evidence states for a process unconstrained by absorbing boundaries; they are not distributions of nonterminated states. (Put otherwise, they are distributions of evidence when decision criteria are large and the probability of terminating before t = 1.0 s, the maximum time represented in the figure, is small). The functions show distributions of evidence for different values of decay, p, and the stimulus-dependent component of drift rate, q. As expected, the means and standard deviations both increase with the passage of time and the distributions become progressively less skewed. The rate of increase is faster for larger values of q and smaller values of p, again as expected. Empirically, the ratio of standard deviation to mean, SD(X t )/M(X t ), follows a simple linear, Weber's Law like, scaling relationship, which is identical for large and small values of decay, p. I computed the mean and standard deviations in the figure numerically from the density function in Equation 13</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 8 :</head><label>8</label><figDesc>Distributions of drift rates for the LDLIV model in the correct response and error accumulators for the<ref type="bibr" target="#b95">Ratcliff (2008)</ref> study (upper panels) and the Smith et al. (2004) study (lower panels). The distributions are lognormal distributions parameterized as in Equation 9 with parameters given by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>6</head><label></label><figDesc>In a recent survey of the understanding of the central limit theorem by researchers in psychology, Zhang et al. (2022) emphasized that finiteness of the first and second moments is needed for convergence to a normal probability law and argued that this aspect of the theorem is not well understood by researchers in the field. Zhang et al.'s point is almost but not quite correct. The classical central limit theorem is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>demonstrations are important, but they provide little help in establishing what, if any, are the limits of this kind of interpretability. In contrast to the pragmatic spirit that motivated the development of models like the LBA, sequential-sampling models like the diffusion models seek to solve a fundamental and well-posed theoretical problem, which I have characterized as von Neumann's problem in time: If the elements that encode cognitive representations are subject to moment-tomoment noise, as neural recordings from decision-related brain structures suggest to be the case, then how can reliable decisions be made based on those elements? The models provide a simple, compelling, and theoretically-satisfying answer to this question: by temporal</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>jointly model firing rates in frontal eye field neurons and distributions of RT in a saccade-to-target decision task. A novel feature of Cox et al.'s approach was that they were able to characterize the importance of different computational mechanisms, such as recurrence, feedforward inhibition, and lateral inhibition, to the firing rates of the individual neurons in their sample. When analyzed in this</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>Verdonck et al. derived explicit    expressions for the statistics of the LIT process Y t in Equation 14 and compared the model to the standard diffusion model on three different data sets. To do so, they used the D * M (i.e., decision convolved with motor time) approach ofVerdonck and Tuerlinckx (2016)  to estimate the distribution of the motor time empirically and found the LIT model was the best-fitting model in each instance.A striking and unexpected feature of the LIT model -not remarked on by Verdonck et al. (2021) -is that the motor activation process Y t is identical to the integrated OU process in the Poisson shot-noise model of Smith (2010), described earlier. This equivalence is surprising, given the divergent semantics of the models. In Smith's model, the instantaneous state of evidence entering the decision process is represented by the difference between a pair of Poisson shot-noise processes that describe the flux in the excitatory and inhibitory postsynaptic potentials induced by a sequence of action potentials. The instantaneous evidence is accumulated over time to make a decision (in either a two-boundary or a racing-process architecture). At high neural firing rates, represented by high-intensity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>can be viewed as an attempt to seek an empirical reduction of the diffusion model to the Wang model.From a somewhat different standpoint, Smith and McKenzie (2011) attempted to provide an empirical reduction of Wang's idea that evidence is accumulated in recurrent loops and sought to show how it leads to diffusive evidence accumulation at a behavioral level. They combined the Poisson shot noise model of Smith (2010) with a model of the statistics of recurrent loops, in which each spike traveling around a loop initiates a new spike after an exponential decay and in which spikes entering the loop cumulate with those already present by superposition. They derived a limiting diffusion equation for the statistics of such loops, which has the form of an OU process with linearly increasing drift and diffusion rate, whose macro properties closely resemble those of the Wiener process. When combined with an appropriate stopping rule in a dual-diffusion architecture the model successfully predicted RT distributions for correct responses and errors and choice probabilities about as well as do the models I considered here. The point of Smith and McKenzie's demonstration was not that the recurrent loop shot-noise model provides a better, or an alternative, model to existing cognitive models, but rather to show that recurrence, as a model for long-time-scale temporal integration, leads in a precise way to a representation of evidence accumulation as a diffusion process. Researchers working on applied cognitive questions in which decision models are used, considering the results in this article, may ask what implications they have for their own practice and for the decision model they use to analyze their data. Should they prefer the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>τ ), τ | z, 0]f [a(t), t| a(τ ), τ ] dτ. (A1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>g[a(t), t| z, 0] = −2Ψ[a(t), t |z, 0] + 2 t 0 g[a(τ ), τ | z, 0]Ψ[a(t), t| a(τ ), τ ] dτ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>) is g[a(∆), ∆ | z, 0] = −2Ψ[a(∆), ∆ | z, 0]; g[a(k∆), k∆ | z, 0] = −2Ψ[a(k∆), k∆ | z, (j∆), j∆ | z, 0], Ψ[a(k∆), k∆ | a(j∆), j∆]; k = 2, 3, . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Parameters of the Decision ModelsHow best to evaluate RT models empirically remains a subject of active debate, with classical and Bayesian, hierarchical and nonhierarchical methods all being widely used and advocated. The variety of methods used in the recent blinded validity study ofDutilh et   al. (2019)  highlights the diversity of practice among researchers in the area.<ref type="bibr" target="#b96">Ratcliff and Childers (2015)</ref> carried out a parameter recovery study using the diffusion model in which they compared classical and hierarchical Bayesian methods and found that hierarchical Bayesian methods improved parameter recovery for small samples (i.e., small numbers of trials in each experimental condition for each participant), but when samples were large, there was little difference between them and classical methods.</figDesc><table><row><cell>Parameter</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Model fits for the numerosity study</figDesc><table><row><cell>Model</cell><cell>G 2 k</cell><cell>df</cell><cell>AIC</cell><cell>BIC</cell></row><row><cell>DIFF</cell><cell cols="3">656.1 13 163 682.1</cell><cell>779.8</cell></row><row><cell cols="4">LDLIV 589.5 17 159 623.5</cell><cell>751.3</cell></row><row><cell>WNR</cell><cell cols="3">805.9 16 160 837.9</cell><cell>958.1</cell></row><row><cell>WLD</cell><cell cols="3">826.8 16 160 864.8</cell><cell>979.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Comparative fits for the numerosity study by AIC and BIC</figDesc><table><row><cell></cell><cell></cell><cell>#AIC</cell><cell></cell><cell></cell><cell></cell><cell>#BIC</cell><cell></cell><cell></cell></row><row><cell cols="5">Model DIFF LDLIV WNR WLD</cell><cell cols="4">DIFF LDLIV WNR WLD</cell></row><row><cell>DIFF</cell><cell>-</cell><cell>9</cell><cell>14</cell><cell>15</cell><cell>-</cell><cell>9</cell><cell>14</cell><cell>15</cell></row><row><cell>LDLIV</cell><cell></cell><cell>-</cell><cell>16</cell><cell>17</cell><cell></cell><cell>-</cell><cell>16</cell><cell>17</cell></row><row><cell>WNR</cell><cell></cell><cell></cell><cell>-</cell><cell>12</cell><cell></cell><cell></cell><cell>-</cell><cell>12</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>Model parameters for the numerosity study</figDesc><table><row><cell></cell><cell>a s</cell><cell>a a</cell><cell>ν 1</cell><cell>ν 2</cell><cell>ν 3</cell><cell>ν 4</cell><cell></cell><cell></cell></row><row><cell>DIFF</cell><cell cols="6">0.078 0.126 0.510 0.417 0.281 0.094</cell><cell></cell><cell></cell></row><row><cell></cell><cell>z s</cell><cell>z a</cell><cell>η</cell><cell>s z</cell><cell cols="2">T er,s T er,a</cell><cell>s t</cell><cell></cell></row><row><cell></cell><cell cols="7">0.040 0.065 0.130 0.045 0.270 0.282 0.133</cell><cell></cell></row><row><cell>LDLIV</cell><cell>a s1</cell><cell>a s2</cell><cell>a a1</cell><cell>a a2</cell><cell>π 1</cell><cell>π 2</cell><cell>π 3</cell><cell>π 4</cell></row><row><cell></cell><cell cols="8">0.503 0.522 0.759 0.762 0.975 0.879 0.740 0.576</cell></row><row><cell></cell><cell>ν sum</cell><cell>z</cell><cell>p</cell><cell>η 1</cell><cell>η 2</cell><cell>s z</cell><cell>T er,s</cell><cell>T er,a</cell><cell>s t</cell></row><row><cell></cell><cell cols="9">4.412 0.208 2.428 0.216 0.096 0.262 0.264 0.267 0.113</cell></row><row><cell>WNR</cell><cell>a s1</cell><cell>a s2</cell><cell>a a1</cell><cell>a a2</cell><cell>π 1</cell><cell>π 2</cell><cell>π 3</cell><cell>π 4</cell></row><row><cell></cell><cell cols="8">0.650 0.682 1.255 1.268 0.994 0.924 0.767 0.5834</cell></row><row><cell></cell><cell>ν sum</cell><cell>r</cell><cell>η 1</cell><cell>η 2</cell><cell>s z</cell><cell cols="2">T er,s T er,a</cell><cell>s t</cell></row><row><cell></cell><cell cols="8">6.195 -1.014 0.288 0.212 0.512 0.253 0.237 0.101</cell></row><row><cell>WLD</cell><cell>a s1</cell><cell>a s2</cell><cell>a a1</cell><cell>a a2</cell><cell>ν 1</cell><cell>ν 2</cell><cell>ν 3</cell><cell>ν 4</cell></row><row><cell></cell><cell cols="8">0.570 0.603 1.056 1.080 0.014 0.137 0.761 1.7494</cell></row><row><cell></cell><cell>ν 5</cell><cell>ν 6</cell><cell>ν 7</cell><cell>ν 8</cell><cell>s</cell><cell></cell><cell></cell><cell></cell></row></table><note>z T er,s T er,a st 5.379 4.738 3.854 2.724 0.389 0.248 0.228 0.102</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>represent an appreciably greater challenge for the model than do the data sets that Tillman et al. considered and, as I have shown, on the Ratcliff data the model does not fare well. Our next application of the model to the attention cuing study of speaks further to the reasons for the model's</figDesc><table><row><cell>failure.</cell></row><row><cell>As well as differing in whether there was drift-rate variability, the reflecting Wiener and</cell></row><row><cell>racing Walds models also differed in whether or not the process was constrained by a lower</cell></row></table><note>reflecting boundary. Unlike the reflecting Wiener model, the racing Walds model does not have a reflecting boundary to limit the excursions of the process away from the decision boundary. A single-boundary Wiener process, as characterized by the Wald distribution,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>-distributed, drift rates and reflecting lower boundaries. They estimated the reflecting boundaries to be just below the starting points (again zero). Because of the negatively correlated drift rates in their model, error processes tend to drift towards the lower reflecting boundary, which prevents large negative excursions in the accumulating evidence, allowing the model to correctly predict distributions of error RTs. In the reflecting Wiener model, the drift rates are lognormally distributed and constrained to be positive, so all of the processes drift upwards and large negative excursions in the accumulating evidence are comparatively infrequent. Consequently, the reflecting boundary in the Wiener model has relatively little effect on model performance.</figDesc><table /><note>contrast with Smith and Ratcliff's (2009) dual-diffusion model, which consists of racing OU processes with negatively correlated,normallyFrom the quantile-probability plot, the reasons for the better performance of the LDLIV model compared to the diffusion model are not particularly obvious, but they appear to lie in the relative ability of the models to account for faster responses. One of the unique features of the LDLIV model not shared with the other models is in the effects of starting point and starting point variability. The Wiener process models -including the diffusion model -are spatially homogeneous: Changing the starting point simply translates the process on the real line, R, and is tantamount to relabeling the decision boundaries relative to the new starting point. In contrast, the LDLIV model with a nonzero starting point is qualitatively different from one with a zero starting point because the diffusion rate in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Model fits for spatial cuing study</figDesc><table><row><cell>Model</cell><cell>G 2 k df</cell><cell>AIC</cell><cell>BIC</cell></row><row><cell>DIFF</cell><cell cols="2">122.2 9 46 140.2</cell><cell>176.1</cell></row><row><cell cols="3">LDLIV 124.0 13 42 150.0</cell><cell>201.9</cell></row><row><cell>WNR</cell><cell cols="2">136.7 12 43 160.7</cell><cell>208.6</cell></row><row><cell>WLD</cell><cell cols="2">179.9 13 42 205.9</cell><cell>257.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Comparative fits for the spatial cuing study by AIC and BIC</figDesc><table><row><cell></cell><cell></cell><cell>#AIC</cell><cell></cell><cell></cell><cell></cell><cell>#BIC</cell><cell></cell><cell></cell></row><row><cell cols="5">Model DIFF LDLIV WNR WLD</cell><cell cols="4">DIFF LDLIV WNR WLD</cell></row><row><cell>DIFF</cell><cell>-</cell><cell>11</cell><cell>20</cell><cell>4</cell><cell>-</cell><cell>19</cell><cell>19</cell><cell>21</cell></row><row><cell>LDLIV</cell><cell></cell><cell>-</cell><cell>18</cell><cell>21</cell><cell></cell><cell>-</cell><cell>13</cell><cell>21</cell></row><row><cell>WNR</cell><cell></cell><cell></cell><cell>-</cell><cell>17</cell><cell></cell><cell></cell><cell>-</cell><cell>18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc>Parameters for the spatial cuing study</figDesc><table><row><cell>DIFF</cell><cell>a</cell><cell>ν 1</cell><cell>ν 2</cell><cell>ν 3</cell><cell>ν 4</cell><cell>ν 5</cell><cell>η</cell><cell>T er</cell><cell>s t</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="9">0.113 0.067 0.206 0.337 0.429 0.504 0.184 0.380 0.136</cell><cell></cell><cell></cell></row><row><cell>LDLIV</cell><cell>a</cell><cell>π 1</cell><cell>π 2</cell><cell>π 3</cell><cell>π 4</cell><cell cols="2">π 5 ν sum</cell><cell>z</cell><cell>p</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="9">0.382 0.551 0.642 0.745 0.822 0.887 2.851 0.036 4.078</cell><cell></cell><cell></cell></row><row><cell></cell><cell>η 1</cell><cell>η 2</cell><cell>T er</cell><cell>s t</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">0.192 0.003 0.292 0.089</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>WNR</cell><cell>a</cell><cell>π 1</cell><cell>π 2</cell><cell>π 3</cell><cell>π 4</cell><cell cols="2">π 5 ν sum</cell><cell>r</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="8">1.115 0.566 0.677 0.807 0.910 0.968 5.780 -0.375</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>η 1</cell><cell>η 2</cell><cell>T er</cell><cell>s t</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">0.364 0.388 0.275 0.086</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>WLD</cell><cell>a</cell><cell>ν 1</cell><cell>ν 2</cell><cell>ν 3</cell><cell>ν 4</cell><cell>ν 5</cell><cell>ν 6</cell><cell>ν 7</cell><cell>ν 8</cell><cell>ν 9</cell><cell>ν 10</cell></row><row><cell></cell><cell cols="11">1.018 2.473 3.122 3.868 4.406 4.832 1.900 1.414 0.881 0.526 0.266</cell></row><row><cell></cell><cell>T er</cell><cell>s t</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">0.260 0.072</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="12">conditions, the quantile probability functions are concave for correct responses and convex</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 .</head><label>7</label><figDesc>For correct response accumulators, the distributions are for increasing stimulus discriminability (increasing π i ν sum ) left to right. For error accumulators, the distributions are for decreasing stimulus discriminability (decreasing (1 − π i )ν sum ) left to right. For both studies, the drift rate variability in the error accumulators was much less than in the correct response accumulators. Indeed, in the Smith et al. study the variability in the error drift rate was negligible and the distributions approach Dirac delta functions. Although the drift rate distributions are not algebraically normal, they are nevertheless fairly symmetrical, as we would expect if drift rates arise by summing or averaging independent noisy elements in a population. If so, we would expect the distributions of drift rates to approach a limiting normal form but not necessarily to fully achieve it, as I discuss subsequently.</figDesc><table /><note>Discussion I have used von Neumann's (1956) problem of how to build reliable organisms from unreliable components as a point of departure to motivate a new model, the LDLIV model,</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The boundary behavior of the LDLIV process is actually a little subtler than this and depends on its parameters<ref type="bibr" target="#b41">(Feller, 1951;</ref><ref type="bibr" target="#b49">Giorno et al., 1989b)</ref>. When q ≤ 0, that is, the stimulus-dependent part of the drift rate is negative, the boundary is an exit boundary: Once a process attains such a boundary it exits the space, so it acts like an absorbing boundary. For 0 &lt; q &lt; σ, zero is a regular boundary, while for q ≥ σ, zero is an entrance boundary: A process can enter the space at such a boundary but never attain it subsequently.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A: Integral Equation Representation of the First-Passage Time Distribution for a Diffusion Process <ref type="figure">Figure 9</ref>: Fortet decomposition of the sample path of a diffusion process, X t , starting at X 0 = z, through a time-varying decision boundary, a(t). Equation A1 gives a decomposition of f [a(t), t |z, 0], the probability density associated with a point on the boundary, a(t), at time t.</p><p>The time of the first boundary crossing is τ , τ ≤ t. After crossing at a(τ ) the process then makes a transition to the point a(t) in time t − τ , possibly with an unspecified number of the further boundary crossings during this interval. In the figure the symbol t is used both to denote the time index of the process and to denote the distinguished point at which X t = a(t).</p><p>The basis of the integral equation method is a general decomposition, attributed by <ref type="bibr" target="#b36">Durbin (1971)</ref> to <ref type="bibr" target="#b46">Fortet (1943)</ref> and shown in <ref type="figure">Figure 9</ref>, of the probability density function for a diffusion process, X t , through an absorbing boundary, a(t), which may be time-varying, as the notation suggests. A process X t = a(t), starting at zero at time t = 0 and located at a point on the boundary at time t must have either reached the boundary for the first time at t or at some earlier time τ , τ &lt; t. If the latter, then it must have transitioned from the point a(τ ) at time τ to the point a(t) at time t, possibly with further boundary crossings in the interval <ref type="bibr">[τ, t]</ref>. Because of the Markov nature of the process, the probability density of the event X t = a(t) can be decomposed into the product of two densities: first, the probability that the process makes a first boundary crossing at τ ; second, the probability that, starting Ethics approval Not applicable.</p><p>Consent to participate Not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent for publication Not applicable.</head><p>Availability of data and materials Data associated with this study are publicly available at https://osf.io/8na3f.</p><p>Code availability Code for fitting the models described in this study is publicly available at https://osf.io/8na3f.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Handbook of mathematical functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abramowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">I</forename><surname>Stegun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<publisher>Dover</publisher>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAC.1974.1100705</idno>
		<ptr target="https://doi.org/10.1109/TAC.1974.1100705" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control AC</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Empirical validation of the diffusion model for recognition memory and a comparison of parameter-estimation methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">J</forename><surname>Bayden</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-014-0608-y</idno>
		<ptr target="http://doi.org/10.1007/s00426-014-0608-y" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="882" to="898" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Some alternate stochastic models of choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Audley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Pike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="225" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.2044-8317.1965.tb00342.x</idno>
		<ptr target="https://doi.org/10.1111/j.2044-8317.1965.tb00342.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Correlated firing in macaque visual area MT: time scales and relationship to behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zohary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bair</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.21-05-01676.2001</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.21-05-01676.2001" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1676" to="1697" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Stochastic processes with applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Waymire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Wiley</publisher>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Purposive explanation in psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Boden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moehlis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-</idno>
		<ptr target="https://doi.org/10.1037/0033-" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="700" to="765" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Probability. Reading: MA, Addison-Wesley</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
	<note>Republished 1992 by the Society for Industrial and Applied Mathematics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A ballistic model of choice response time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.112.1.117</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.112.1.117" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The simplest complete model of choice response time: Linear ballistic accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="153" to="178" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.cogpsych.2007.12.002</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2007.12.002" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evaluating methods for approximating stochastic differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="402" to="410" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.jmp.2006.03.004</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2006.03.004" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A new integral equation for the evaluation of first-passage-time probabilities densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buonocore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ricciardi</surname></persName>
		</author>
		<idno type="DOI">10.2307/1427102</idno>
		<ptr target="https://doi.org/10.2307/1427102" />
	</analytic>
	<monogr>
		<title level="j">Advances in Applied Probability</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="784" to="800" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the two-boundary first-crossing-time problem for diffusion processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buonocore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Giorno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ricciardi</surname></persName>
		</author>
		<idno type="DOI">10.2307/3214598</idno>
		<ptr target="http://dx.doi.org/10.2307/3214598" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="102" to="114" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fundamental derivations from decision field theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Townsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Social Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="255" to="282" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/0165-4896(92</idno>
		<ptr target="https://doi.org/10.1016/0165-4896(92" />
		<imprint>
			<biblScope unit="page" from="90043" to="90048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Decision field theory: A dynamic-cognitive approach to decision making in an uncertain environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Townsend</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X</idno>
		<ptr target="https://doi.org/10.1037/0033-295X" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="432" to="459" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Normalization as a canonical neural computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carandini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn3136</idno>
		<ptr target="https://doi.org/10.1038/nrn3136" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Contrast, probability, and saccadic latency: Evidence for independence of detection and decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H S</forename><surname>Carpenter</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2004.08.058</idno>
		<ptr target="https://doi.org/1576-1580.10.1016/j.cub.2004.08.058" />
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">17</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The theory of stochastic processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Salience by competitive and recurrent interactions: Bridging neural spiking and computation in visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Schall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<date type="published" when="2022-04-07" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/rev0000366</idno>
		<ptr target="http://dx.doi.org/10.1037/rev0000366" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Transcranial direct current stimulation does not influence the speed-accuracy tradeoff in perceptual decision making: Evidence from three independent studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>De Hollander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Labruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sellaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trutti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Colzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Ivry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1283" to="1294" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<idno type="DOI">10.1162/jocna00967</idno>
		<ptr target="http://doi.org/10.1162/jocna00967" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Intersensory facilitation of reaction time: Evaluation of counter and diffusion coactivation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diederich</surname></persName>
		</author>
		<idno type="DOI">10.1006/jm</idno>
		<ptr target="https://doi.org/10.1006/jm" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="197" to="215" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stochastic models of decisions about motion direction: Behavior and physiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ditterich</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neunet.2006.05.042</idno>
		<ptr target="https://doi.org/10.1016/j.neunet.2006.05.042" />
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="981" to="1012" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Diffusion versus linear ballistic accumulation: different models but the same conclusions about psychological processes?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-010-0022-4</idno>
		<ptr target="https://doi.org/10.3758/s13423-010-0022-4" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="61" to="69" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Verbal labeling, gradual decay, and sudden death in visual short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nosofsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shiffrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="170" to="178" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13423-014-0675-5</idno>
		<ptr target="http://dx.doi.org/10.3758/s13423-014-0675-5" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">On the speed of mental processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C. ; G</forename><surname>Donders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koster</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<idno type="DOI">10.1016/0001-6918(69</idno>
		<ptr target="https://doi.org/10.1016/0001-6918(69" />
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="90065" to="90066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dutilh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Annis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cassey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P P P</forename><surname>Grasman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-M</forename><surname>Krypotos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Kupitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lerche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Starns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Maanen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The quality of response time data inference: A blinded, collaborative assessment of the validity of cognitive models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-017-1417-2</idno>
		<ptr target="https://doi.org/10.3758/s13423-017-1417-2" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1051" to="1069" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Boundary-crossing probabilities for the Brownian motion and Poisson processes and techniques for computing the power of the Kolmogorov-Smirnov test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Durbin</surname></persName>
		</author>
		<idno type="DOI">10.2307/3212169</idno>
		<ptr target="https://doi.org/10.2307/3212169" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="431" to="453" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Grice-representability of response time distribution families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">N</forename><surname>Dzhafarov</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294577</idno>
		<ptr target="https://doi.org/10.1007/BF02294577" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="314" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Edwards</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-2496(65</idno>
		<ptr target="https://doi.org/10.1016/0022-2496(65" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="90007" to="90013" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simple reaction time with markovian evolution of gaussian discriminal processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Emerson</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02310798</idno>
		<ptr target="https://doi.org/10.1007/BF02310798" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="99" to="109" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Elemente der psychophysik. Breitkopf and Härtel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Fechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Elements of psychophysics</title>
		<editor>trans. H. E. Adler</editor>
		<meeting><address><addrLine>Leipzig; Holt, Rinehart and Wiston, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1860" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Two singular diffusion processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feller</surname></persName>
		</author>
		<ptr target="https://www.jstor.org/stable/1969318" />
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics, Second Series</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="173" to="182" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">An introduction to probability theory and its applications. Volume I</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
	<note>3rd</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename></persName>
		</author>
		<imprint>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Likelihood approximation networks (LANs) for fast inference of simulation models in cognitive neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fengler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Govindarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.65074</idno>
		<ptr target="https://doi.org/10.7554/eLife.65074" />
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sequential sampling models in cognitive neuroscience: Advantages, applications, and extensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-122414-033645</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-122414-033645" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="641" to="666" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Les fonctions aléatoires du type de Markoff associéesà certaineséquations linéaires aux derivées partielles du type parabolique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fortet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal de Mathématiques Pures et Appliquées</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="177" to="243" />
			<date type="published" when="1943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Spiking neuron models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gerstner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kistler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On the evaluation of firstpassage-time probability densities via non-singular integral equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Giorno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Ricciardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sato</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/1427196" />
	</analytic>
	<monogr>
		<title level="j">Advances in Applied Probability</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="36" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Some remarks on the Rayleigh process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Giorno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Nobile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Ricciardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sacerdote</surname></persName>
		</author>
		<ptr target="https://www.jstor.org/stable/3214182" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="398" to="408" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Neural computations that underlie computations about sensory stimuli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<idno type="DOI">10.1016/s1364-6613</idno>
		<ptr target="https://doi.org/10.1016/s1364-6613" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1567" to="1576" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Limit distributions for sums of independent random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Gnedenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Kolmogorov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1954" />
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Signal detection theory and psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<publisher>Wiley</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Application of a variable criterion mode to auditory reaction time as a function of the type of catch trial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Grice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="103" to="107" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">How does a brain build a cognitive code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X</idno>
		<ptr target="https://doi.org/10.1037/0033-295X" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="51" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Neural control of voluntary movement initiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Hanes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Schall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title/>
		<idno type="DOI">10.1126/science.274.5286.427</idno>
		<ptr target="https://doi.org/10.1126/science.274.5286.427" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="issue">5286</biblScope>
			<biblScope unit="page" from="427" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A general nonstationary diffusion model for two-choice decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Heath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Social Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="283" to="309" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/0165-4896(92</idno>
		<ptr target="https://doi.org/10.1016/0165-4896(92" />
		<imprint>
			<biblScope unit="page" from="90044" to="90050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fitting Wald and ex-Wald distributions to response time data: An example using functions for the S-PLUS package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206550</idno>
		<ptr target="https://doi.org/10.3758/BF03206550" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="page" from="36" to="678" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Linear deterministic accumulator models of simple choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Love</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00292</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2012.00292" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The falsifiability of actual decision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0037771</idno>
		<ptr target="http://dx.doi.org/10.1037/a0037771" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="676" to="678" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The optimality of sensory processing during the speed-accuracy tradeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Maanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Serences</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="7992" to="8003" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<idno type="DOI">10.1523/JNEUROSCI.0340-12.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0340-12.2012" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A new framework for modeling decisions about changing information: The piecewise linear ballistic accumulator model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2015.11.002.https://doi.org/10.1523/JNEUROSCI.0340-12.2012</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2015.11.002.https://doi.org/10.1523/JNEUROSCI.0340-12.2012" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Different effects of dopaminergic medication on perceptual decision-making in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Foltynie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Limousin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jahanshahi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Parkinson&apos;s disease as a function of task difficulty and speed-accuracy instructions</title>
		<idno type="DOI">10.1016/j.neuropsychologia.2015.07.012</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2015.07.012" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="577" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Unfalsifiability and mutual translatability of major modeling schemes for choice reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">N</forename><surname>Dzhafarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0034190</idno>
		<ptr target="https://doi.org/10.1037/a0034190" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">A first course in stochastic processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>Academic Press</publisher>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">A second course in stochastic processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<publisher>Academic Press</publisher>
			<pubPlace>Orlando, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1995.10476572</idno>
		<ptr target="https://doi.org/10.1080/01621459.1995.10476572" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Neurocomputational mechanisms of prior-informed perceptual decision-making in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Connell</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-020-00967-9</idno>
		<ptr target="https://doi.org/10.1038/s41562-020-00967-9" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="467" to="481" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Equal evidence perceptual tasks suggest a key role for interactive competition in decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Sederberg</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000284</idno>
		<ptr target="https://doi.org/10.1037/rev0000284" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1051" to="1087" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A recruitment theory of simple behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Laberge</surname></persName>
		</author>
		<idno type="DOI">10.1007/bf02289645</idno>
		<ptr target="https://doi.org/10.1007/bf02289645" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="375" to="396" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Information theory of choice reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R J</forename><surname>Laming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Rediscovering the past: Gustav Fechner and signal detection theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Link</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title/>
		<idno type="DOI">10.1111/j.1467-9280.1994.tb00282.x</idno>
		<ptr target="http://dx.doi.org/10.1111/j.1467-9280.1994.tb00282.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="335" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">A sequential theory of psychological discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Link</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Heath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title/>
		<idno type="DOI">10.1007/BF02291481</idno>
		<ptr target="https://doi.org/10.1007/BF02291481" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Cortico-basal ganglia circuit for a decision threshold in reaction time tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn1722</idno>
		<ptr target="https://doi.org/10.1038/nn1722" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="956" to="963" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">On the ability to inhibit thought and action: General and special theories of an act of control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Zandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Verbruggen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0035230</idno>
		<ptr target="https://doi.org/10.1037/a0035230" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="95" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Thurstone and sensory scaling: Then and now</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.101.2.271</idno>
		<ptr target="http://dx.doi.org/10.1037/0033-295X.101.2.271" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="271" to="277" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Response times: Their role in inferring elementary mental organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780195070019.001.0001</idno>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Psychological interpretation of the ex-Gaussian and shifted Wald parameters: A diffusion model analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="798" to="817" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">A role for neural integrators in perceptual decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Mazurek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Roitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ditterich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhg097</idno>
		<ptr target="https://doi.org/10.1093/cercor/bhg097" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1257" to="1269" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A logical calculus of the ideas immanent in nervous activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pitts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Bulletin of Mathematical Biophysics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="115" to="133" />
			<date type="published" when="1943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/BF02478259</idno>
		<ptr target="https://doi.org/10.1007/BF02478259" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A simplex method for function minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mead</surname></persName>
		</author>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="308" to="313" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">An interference model of visual working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Oberauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000044</idno>
		<ptr target="https://doi.org/10.1037/rev0000044" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="59" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">From salience to saccades: Multiple-alternative gated stochastic accumulator model of visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Purcell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Schall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.4622-11.2012</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.4622-11.2012" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3433" to="3446" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">The hare and the tortoise: Emphasizing speed can change the evidence used to make decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Heathcote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Averell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1226" to="1243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0036801</idno>
		<ptr target="https://doi.org/10.1037/a0036801" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">A theory of memory retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="108" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0033-295X.85.2.59</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.85.2.59" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Modeling aging effects on two-choice tasks: Response signal and response time data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0013930</idno>
		<ptr target="https://doi.org/10.1037/a0013930" />
	</analytic>
	<monogr>
		<title level="j">Psychology and Aging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="900" to="916" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Individual differences and fitting methods for the twochoice diffusion model of decision making. Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Childers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="237" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/dec0000030</idno>
		<ptr target="https://doi.org/10.1037/dec0000030" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">A dual diffusion model for single cell recording data from the superior colliculus in brightness discrimination task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Segraves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="1756" to="1797" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title/>
		<idno type="DOI">10.1152/jn.00393.2006</idno>
		<ptr target="https://doi.org/10.1152/jn.00393.2006" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">The diffusion decision model: Theory and data for two-choice decision tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="873" to="922" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title/>
		<idno type="DOI">10.1162/neco.2008.12-06-420</idno>
		<ptr target="https://doi.org/10.1162/neco.2008.12-06-420" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Modeling response times for two-choice decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9280.00067</idno>
		<ptr target="https://doi.org/10.1111/1467-9280.00067" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="347" to="356" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A comparison of sequential-sampling models for two choice reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-</idno>
		<ptr target="https://doi.org/10.1037/0033-" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="333" to="367" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Diffusion decision model: Current issues and history</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="260" to="281" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.tics.2016.01.007</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2016.01.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Modeling response time and accuracy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="458" to="470" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0963721415596228</idno>
		<ptr target="https://doi.org/10.1177/0963721415596228" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03196302</idno>
		<ptr target="https://doi.org/10.3758/BF03196302" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="438" to="481" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Modeling 2-alternative forced-choice tasks: Accounting for both magnitude and difference effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voskuilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Teodorescu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2018.02.002</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2018.02.002" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">A random-ray model for visual search and object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Santhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Decaro</surname></persName>
		</author>
		<idno type="DOI">10.1163/1568568052801582</idno>
		<ptr target="https://doi.org/10.1163/1568568052801582" />
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="83" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rieke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>De Ruyter Van Steveninck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bailek</surname></persName>
		</author>
		<title level="m">Spikes: Exploring the neural code</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">On the transformation of diffusion processes into the Wiener process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ricciardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="185" to="199" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">A note on the evaluation of first-passage-time probability densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ricciardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sato</surname></persName>
		</author>
		<idno type="DOI">10.2307/3213736</idno>
		<ptr target="https://doi.org/10.2307/3213736" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="197" to="201" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Itô calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C G</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Diffusions, Markov processes and martingales</title>
		<meeting><address><addrLine>Chichester, U.K; Cambridge, U.K</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1987" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Responses of neurons in the lateral interparietal area during a combined visual discrimination reaction time task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Roitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.22-21-09475.2002</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.22-21-09475.2002" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="9475" to="9489" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Neurobiological models of two-choice decision making can be reduced to a one-dimensional nonlinear diffusion equation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roxin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ledberg</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1000046</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1000046" />
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1000046" to="1000047" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title/>
		<idno type="DOI">10.1214/aos/1176344136</idno>
		<ptr target="https://doi.org/10.1214/aos/1176344136" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">The ex-Wald distribution as a descriptive model of response times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schwarz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="457" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/BF03195403</idno>
		<ptr target="https://doi.org/10.3758/BF03195403" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">On the convolution of inverse Gaussian and exponential random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics: Theory &amp; Methods</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2113" to="2121" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title/>
		<idno type="DOI">10.1081/STA-120017215</idno>
		<ptr target="https://doi.org/10.1081/STA-120017215" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">C. F. Gauss and the theory of errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">B</forename><surname>Sheynin</surname></persName>
		</author>
		<idno>3.IV.1979) 21-72</idno>
		<ptr target="https://www.jstor.org/stable/41133536" />
	</analytic>
	<monogr>
		<title level="j">Archive for History of Exact Sciences</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">A deconvolutional approach to modelling response time distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Human information processing: Measures, mechanisms and models</title>
		<editor>In D. Vickers and P. L. Smith</editor>
		<imprint>
			<publisher>Elsevier Science</publisher>
			<biblScope unit="page" from="267" to="289" />
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Obtaining meaningful results from Fourier deconvolution of reaction time data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.108.3.533</idno>
		<ptr target="http://doi:10.1037/0033-2909.108.3.533" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="533" to="5500" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Psychophysically principled models of visual simple reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.102.3.567</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.102.3.567" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="567" to="591" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Bloch&apos;s law predictions from diffusion process models of detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1080/00049539808258790</idno>
		<ptr target="https://doi.org/10.1080/00049539808258790" />
	</analytic>
	<monogr>
		<title level="j">Australian Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="139" to="147" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Stochastic dynamic models of response time and accuracy: A foundational primer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="408" to="463" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title/>
		<idno type="DOI">10.1006/jmps.1999.1260</idno>
		<ptr target="https://doi.org/10.1006/jmps.1999.1260" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">From Poisson shot noise to the integrated Ornstein-Uhlenbeck process: Neurally principled models of information accumulation in decision-making and response time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="266" to="283" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.jmp.2009.12.002</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2009.12.002" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Revisited: Neurally-Inspired Diffusion Models of Decision Making. Data and code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://osf.io/8na3f" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>Reliable Organisms from Unreliable Components</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">The power law of visual working memory characterizes attention engagement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Lilburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kyllingsbaek</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000098</idno>
		<ptr target="http://dx.doi.org/10.1037/rev0000098" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="435" to="451" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Vision for the blind: visual psychophysics and blinded inference for decision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Lilburn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="882" to="910" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13423-020-01742-7</idno>
		<ptr target="https://doi.org/10.3758/s13423-020-01742-7" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Diffusive information accumulation by minimal recurrent neural models of decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R L</forename><surname>Mckenzie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2000" to="2031" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title/>
		<idno type="DOI">10.1162/NECOa00150</idno>
		<ptr target="https://doi.org/10.1162/NECOa00150" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Psychology and neurobiology of simple decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tins.2004.01.006</idno>
		<ptr target="https://doi.org/10.1016/j.tins.2004.01.006" />
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="161" to="168" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Diffusion and random walk processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>James D</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wright</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-</idno>
		<ptr target="http://dx.doi.org/10.1016/B978-" />
		<title level="m">International Encyclopedia of the Social &amp; Behavioral Sciences</title>
		<meeting><address><addrLine>Oxford UK</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="395" to="401" />
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">An integrated theory of attention and decision making in visual signal detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="317" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0015156</idno>
		<ptr target="https://doi.org/10.1037/a0015156" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Modeling evidence accumulation decision processes using integral equations: Urgency-gating and collapsing boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="235" to="267" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/rev0000301</idno>
		<ptr target="https://doi.org/10.1037/rev0000301" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Modeling perceptual discrimination in dynamic noise: Time-changed diffusion and release from inhibition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Sewell</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2013.05.007</idno>
		<ptr target="https://doi.org/10.1016/j.jmp.2013.05.007" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="95" to="113" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Attention orienting and the time course of perceptual decisions: Response time distributions with masked and unmasked displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Wolfgang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2004.01.002</idno>
		<ptr target="https://doi.org/10.1016/j.visres.2004.01.002" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1297" to="1320" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">A competitive interaction theory of attention and decision-making in brief multielement displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Sewell</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0033140</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="589" to="627" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">From shunting inhibition to dynamic normalization: Attentional selection and decision-making in brief visual displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Sewell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Lilburn</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2014.11.001</idno>
		<ptr target="https://doi.org/10.1016/j.visres.2014.11.001" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">B</biblScope>
			<biblScope unit="page" from="219" to="240" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Time-dependent Poisson counter models of response latency in simple judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Zandt</surname></persName>
		</author>
		<idno type="DOI">10.1348/000711000159349</idno>
		<ptr target="https://doi.org/10.1348/000711000159349" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="293" to="315" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">The accumulator model of two-choice discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vickers</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-</idno>
		<ptr target="https://doi.org/10.1016/0022-" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="135" to="168" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Diffusion model drift rates can be influenced by decision processes: An analysis of the strength-based mirror effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Starns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1137" to="1151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0028151</idno>
		<ptr target="https://doi.org/10.1037/a0028151" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title level="m" type="main">The discovery of processing stages: Extensions of Donders&apos; method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sternberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Attention and Performance II</title>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<editor>Koster, W. G.</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="276" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Models for choice reaction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="251" to="260" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/BF02289729</idno>
		<ptr target="https://doi.org/10.1007/BF02289729" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Multiple observations of signals in noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Shipley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mckey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="514" to="521" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title/>
		<idno type="DOI">10.1121/1.1907745</idno>
		<ptr target="https://doi:10.1121/1.1907745" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Absolutely relative or relatively absolute: Violations of value invariance in human decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-015-0858-8</idno>
		<ptr target="https://doi.org/10.3758/s13423-015-0858-8" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="38" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Disentangling decision models: From independence to competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0030776</idno>
		<ptr target="https://doi.org/10.1037/a0030776" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<title level="m" type="main">Perceptual and motor processing stages identified in the activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Hanes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Bichot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Schall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="4040" to="4055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<title/>
		<idno type="DOI">10.1152/jn.1996.76.6.4040</idno>
		<ptr target="http://doi.org/10.1152/jn.1996.76.6.4040" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">A law of comparative judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Thurstone</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0070288</idno>
		<ptr target="https://doi.org/10.1037/h0070288" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="273" to="286" />
			<date type="published" when="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<title level="m" type="main">Sequential sampling models without random between-trial variability: the racing diffusion model of speeded decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tillman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Zandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Logan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title/>
		<idno type="DOI">10.3758/s13423-020-01719-6</idno>
		<ptr target="https://doi.org/10.3758/s13423-020-01719-6" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="911" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<title level="m" type="main">Stochastic modeling of elementary psychological processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Townsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">G</forename><surname>Ashby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Introduction to theoretical neurobiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tuckwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nonlinear and stochastic theories</title>
		<meeting><address><addrLine>Cambridge, England</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1988" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">A generalized, likelihood-free method for posterior estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sederberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<idno>s13423- 013-0530-0</idno>
		<ptr target="https://doi.org/10.3758/" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="250" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Approximating Bayesian inference through model simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Zandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="826" to="840" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.tics.2018.06.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2018.06.003" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Relating a spiking neural network model and the diffusion model of decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Umakantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Purcell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
		<idno type="DOI">10.1007/s42113-022-00143-4</idno>
		<ptr target="https://doi.org/10.1007/s42113-022-00143-4" />
	</analytic>
	<monogr>
		<title level="j">Computational Brain &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="279" to="301" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">The time course of perceptual choice: The leaky, competing accumulator model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="550" to="592" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0033-295X</idno>
		<ptr target="https://doi.org/10.1037/0033-295X" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Factorial comparison of working memory models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Awh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0035234</idno>
		<ptr target="https://doi.org/10.1037/a0035234" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="124" to="149" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Diffusion model analysis with MATLAB: A DMAT primer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">The leaky integrating threshold and its impact on evidence accumulation models of choice response time (RT)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Verdonck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loossens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Philiastides</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000258</idno>
		<ptr target="http://dx.doi.org/10.1037/rev0000258" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="221" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">The Ising decision maker: A binary stochastic network model for choice response time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Verdonck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="422" to="462" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0037012</idno>
		<ptr target="http://dx.doi.org/10.1037/a0037012" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Factoring out non-decision time in choice RT data: Theory and implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Verdonck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="208" to="218" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/rev0000019</idno>
		<ptr target="https://doi.org/10.1037/rev0000019" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title level="m" type="main">Evidence for an accumulator model of psychophysical discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vickers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title/>
		<idno type="DOI">10.1080/00140137008931117</idno>
		<ptr target="https://doi.org/10.1080/00140137008931117" />
	</analytic>
	<monogr>
		<title level="j">Ergonomics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="37" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<monogr>
		<title level="m" type="main">Decision processes in visual perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vickers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Academic Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">Comparing fixed and collapsing boundary versions of the diffusion model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voskuilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jm</idno>
		<ptr target="https://doi.org/10.1016/j.jm" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Probabilistic logics and synthesis of reliable organisms from unreliable components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Von</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automata Studies</title>
		<editor>C. E. Shannon &amp; J. McCarthy</editor>
		<meeting><address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1956" />
			<biblScope unit="page" from="43" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Fast-dm: A free program for efficient diffusion model analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Voss</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03192967</idno>
		<ptr target="https://doi.org/10.3758/BF03192967" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="767" to="775" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<title level="m" type="main">Sequential analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1947" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Synaptic reverberation underlying mnemonic persistent activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0166-2236(00</idno>
		<ptr target="https://doi.org/10.1016/s0166-2236(00" />
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1868" to="1871" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<monogr>
		<title level="m" type="main">Probabilistic decision making by slow reverberation in cortical circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X-J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title/>
		<ptr target="https://doi.org/0.1016/s0896-6273" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1092" to="1101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">HDDM: Hierarchical Bayesian estimation of the drift-diffusion model in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.3389/fninf.2013</idno>
		<ptr target="https://doi.org/10.3389/fninf.2013" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">A recurrent network mechanisms of time integration in perception decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X-J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1314" to="1328" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">The forgotten history of signal detection theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="233" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/xlm0000732</idno>
		<ptr target="http://dx.doi.org/10.1037/xlm0000732" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">How to think clearly about the central limit theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">L</forename><surname>Olvera Astivia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kroc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Zumbo</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000448</idno>
		<ptr target="http://dx.doi.org/10.1037/met0000448" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<date type="published" when="2022-03" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Correlated neuronal discharge rate and its implications for psychophysical performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zohary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Shadlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
		<idno type="DOI">10.1038/370140a0</idno>
		<ptr target="https://doi.org/10.1038/370140a0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">370</biblScope>
			<biblScope unit="page" from="140" to="143" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
