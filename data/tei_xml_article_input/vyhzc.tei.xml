<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating Reliability in Nested Group Settings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Solan</surname></persName>
						</author>
						<title level="a" type="main">Evaluating Reliability in Nested Group Settings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>inter-rater reliability</term>
					<term>paired informants</term>
					<term>self-reported assessment</term>
					<term>mixed models</term>
					<term>informants agreement</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The foundation of decision-making relies on assessing the reliability of different sources of information. Therefore, the methods used to evaluate Interrater Reliability (IRR) are of significant importance. There are many approaches aimed at calculating the IRR based on the agreement among raters, including Cohen&apos;s Kappa, Fleiss&apos; Kappa, Intraclass Correlation Coefficient (ICC), Krippendorff&apos;s Alpha, and Bland-Altman analysis. These methods primarily assume that the proportion of observed agreement versus chance probability can be directly derived in a statistical manner. However, in certain cases, such as where informants are organized into nested groups, deriving the observed agreement versus chance probability is not straightforward. The main challenge arises in scenarios such as selfreported assessments by parents, where each nested group of paired informants reports on a different subject, each exhibiting different symptoms. This may result in varying levels of chance probability for each item and for each group. The objective of this study was to present a novel approach capable of addressing any scenario, including nested groups, through the application of a mixed-effect model. This model assesses IRR by utilizing the area generated by the random effects of individual curves, accounting for all sources of randomness. We demonstrate the power of the new approach to estimate the IRR both in a simulation and by applying it on a public available datasets. This approach can also be used to assess the IRR of aggregated indices that have induced bias, yielded from various combinations of items with different chance probabilities.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>A principal methodology in clinical diagnosis is grounded in interrater agreement among informants who evaluate various outcomes associated with the same phenomenon. For instance, when two parents assess their child's behavior, their level of agreement can either enhance or compromise the validity of the assessments. The general notion is that a balanced consensus, which incorporates diverse perspectives, can enhance validity. However, excessive agreement may raise concerns about copied responses, and low levels of agreement might suggest random answers, both of which can lead to diminished validity <ref type="bibr" target="#b8">(Carstensen et al., 2008;</ref><ref type="bibr" target="#b5">Berchtold, 2016)</ref>. Thus, given the answers of two informants, what methods can be employed to evaluate the validity of these assessments? Beyond Kappa and ICC</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interrater agreement</head><p>Traditionally, interrater reliability, also known as interrater agreement, has been tackled using metrics like the kappa coefficient <ref type="bibr">(Cohen,1960)</ref> and <ref type="bibr" target="#b6">Bland-Altman (Bland &amp; Altman, 1986</ref>). Cohen's kappa statistic is a measure for evaluating interrater agreement beyond chance on both dichotomous and multiple response categories <ref type="bibr" target="#b3">(Bakeman &amp; Gottman, 1986;</ref><ref type="bibr" target="#b22">Simon, 2006)</ref> and has undergone various extensions <ref type="bibr">(De Vries, 2015)</ref>. It addresses the limitations of percent agreement by considering the possibility of chance agreement between raters, thus offering a more accurate assessment of interrater reliability. However, when examining the scenario above, two parents evaluating their child's symptoms, the current methodology encounters significant limitations. These limitations arise because the agreement refers to a group of nested paired informants, where each group refers to a different subject, resulting in chance agreements not being drawn from the same distribution. This complexity making it challenging to accurately assess and compare simultanisaly the observed agreement for each item across different pairs. To the best of our knowledge, there is no existing framework that offers a comprehensive solution combining paired-informant agreement within this context 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Purpose of the Present Study</head><p>The objectives of this study is to demonstrate a novel framework that produces more accurate estimations of IRR in the context of nested groups and, consequently, offer a more precise quantification of true individual performance compared to previous approaches, such as ICC and Kappa. In the following sections, we present a simulation that mimics real-world scenarios in which informants are organized into nested pairs. We then introduce a new framework based on the mixed binomial model, applied to public data, and use the simulation outcomes to compare the performance of four different models in inferring true agreement. Finally, we discuss how clinicians can utilize this framework to assess the true level of agreement between parents and mitigate bias in the agreement of aggregated indices .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>2 While the model was specifically designed for the unique case of nested paired informants, its application can be generalized across various scenarios to assess validity based on agreement level. The performance of this model in broader contexts will be the subject of future evaluations. Beyond Kappa and ICC</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Study</head><p>In our study, the methodology employed focuses on a comprehensive simulation designed to rigorously test and validate the novel approach for assessing Interrater Reliability (IRR). The simulation aims to replicate the scenario of two informants (two parents) assessing the level of symptoms their child exhibits. In this scenario, the informants respond to exactly the same items and report on the frequency of the symptoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulated Dataset Strategy</head><p>The simulation data is generated synthetically but is grounded on data extrapolated from an empirical dataset of field observations. This empirical dataset serves a dual purpose: first, it provides a realistic baseline of features, such as occurrence probabilities; second, it provides a standard for comparison to evaluate how accurately the simulated data reflects real-world conditions. We refer to this foundational dataset as the "source dataset" throughout our study. Upon analyzing the source dataset, we extract critical features that are integral to the fidelity of our simulation-essentially creating a distilled blueprint of real-world phenomena. Utilizing these extracted features, we then generate a synthetic dataset, sometimes termed a "simulated dataset". This dataset is an artificial construct, designed to emulate the statistical properties and dynamics observed within the source dataset. In the following section, we will outline the processes and methodologies employed to generate the simulation dataset based on aggregated features from the empirical data, detailing the transformation from observed reality to simulated scenarios for the purpose of our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical Data</head><p>As mentioned earlier, the main scenario addressed in this study involves the assessment by two informants (i.e., parents) reporting on a third reference (i.e., child). In an intensive study conducted in Boston, Chicago, and San Antonio <ref type="bibr" target="#b2">(Angel et al., 2007)</ref>, low-income families were assessed regarding their children's well-being in the post-welfare reform era. From the comprehensive ICPSR-4701 dataset, we extracted two simplified datasets that included 1,987 parents who completed the CBCL assessment. The Child Behavior Checklist (CBCL) is a widely used tool for assessing emotional and behavioral problems in children. It has been validated in various populations, including children with developmental disabilities and autism spectrum disorders, showing its utility in clinical and research settings for identifying a range of psychopathological issues. The researchers of ICPSR-4701 used two versions of CBCL, one for parents who responded regarding the behavior of their young children aged 2-3 years, and one for parents with older children aged 4-18 years. These two datasets, which we named CBCL/2-3 and CBCL/4-18 respectively were further split into two subtypes: (1) a single-informant dataset, which was a collection assessment that was completed by a single parent (CBCL/2-3_1 and CBCL/4-18_1 consisted of 329 and 1246 single parent reports, respectively), and (2) a paired-informant dataset, which was a collection assessment that was completed by both parents regarding their child's behavior (CBCL/2-3_2 and CBCL/4-18_2 consisted Beyond Kappa and ICC of 145 and 61 paired parent reports, respectively). The CBCL/2-3, used for assessing children aged 2 to 3, comprises 99 items <ref type="bibr" target="#b1">(Achenbach et al., 1987)</ref>, while the CBCL/4-18, for children aged 4 to 18, includes 118 items <ref type="bibr" target="#b0">(Achenbach et al., 1983)</ref>. Each item's score corresponds to a response rated on a three-point Likert scale: 0 ('Not True'), 1 ('Somewhat or Sometimes True'), and 2 ('Very True or Often True'). If an item is not answered by the informant, it is considered missing and excluded from the analysis. Overall, the items in both assessments described different possible child behavior events that might have occurred at home or during school, and the informants were asked to state, to the best of their knowledge, whether their children had ever exhibited these behavior events in the last two weeks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical Data Characteristics</head><p>As a first step toward simulating paired-informant behavior, we started by simplifying the outcome variable representation by transforming the assessment item score values from ordinal variables (3 categories) into two states, where State 1 corresponded to any reported event ('Somewhat or sometimes true' or 'Very true') and state 0 corresponded to a nonevent ('Not true'). By transforming all item scores into their Boolean form, we could calculate the probability pi for each item i, indicating informants' tendency to report the existence of an event (state 1) for item i. The entire vector of values</p><formula xml:id="formula_0">2−3= [ 1,2−3 , 2,2−3 , 3,2−3 … ,2−3 ]</formula><p>; m=99, represent the list of probabilities extracted from the empirical data CBCL/2-3_1, serving as foundational metrics for subsequent analyses.</p><formula xml:id="formula_1">4−18= [ 1,4−18 , 2,4−18 , 3,4−18 … ,4−18 ]</formula><p>; m=118 was extracted in a similar way. Agreement Ai was calculated using equation 3 for each of the two-informant datasets (CBCL/2-3_2 and CBCL/4-18_2) by comparing the reported state of each of the informants. For that purpose, we calculated a 2X2 confusion matrix for each item i. <ref type="figure" target="#fig_0">Figure 1</ref> presents an example of a confusion matrix of the first item in assessment CBCL/2-3_2 and the terminology we used. The number of paired informants who agreed about the answers and provided identical responses is shown on the diagonal of the matrix. On the off diagonal, we find the total counts of paired informants who disagreed. We use the notion of true positive (TP) to indicate the element in the matrix that counts the number of paired informants who agreed about the existence of an event, and true negative (TN) indicates the total agreement on nonevents (both informants reported 0). The false positive (FP) and false negative (FN) are on the off-diagonal element that indicates the number of informants who disagreed on item i.</p><p>The true positive rate (TPR) and true negative rate (TNR) are defined as follows:</p><p>(1) = + + +</p><p>(2) = + + + and the total agreement of item i is defined as: Beyond Kappa and ICC</p><p>(3) = + (4) = 1 −</p><p>The next section will demonstrate how a straightforward simulation, based on simple assumptions and few parameters that were extracted from the data characteristics, replicates the main effects of agreement among paired informants. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Design and Construction</head><p>The primary objective of our simulation was to examine the spectrum of agreement between pairs of informants who evaluated the same subject using the same assessment instrument. We sought to construct a variety of cases which would encompass the entire continuum of possible agreements. On one end of this continuum lies the scenario of pure chance, where the informants' responses are completely random, reflecting no agreement whatsoever. On the opposite end, we have cases of perfect alignment, where informants provide identical responses, indicating full agreement. In the next section we will demonstrate how a simple simulation, called "the three coins experiment", will reproduce the entire range of observations between these two scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Three Coins Experiment: Modeling Informants Agreement</head><p>The Three Coins Experiment is a conceptual model created to simulate the process of reaching an agreement between two evaluators assessing a child's condition. This model is comparable to a situation in which the result is contingent on flipping three coins. Each coin has distinct probabilities of landing heads or tails, and each plays a crucial role in influencing the final consensus. The first coin represents the 'true state' of child j -whether a particular behavior is present (head = 1) or absent (tail = 0). The state of this coin is akin to the actual condition we aim to assess. The outcome of this coin flip is the reality that our informants attempt to observe. Given m items, reflect m reported states of the child. The variable pi ( = 1. . ) controls the probability of the coin when simulating the state of item i to be head (1) or tail (0). To avoid any possible dependency between pi and the final agreement, pi was calculated from the real-world distribution of the datasets 4−18 and 2−3 . Thus the probability of the first coin (simulating the true state of child j in item i) of the first experiment (CBCL/2-3) is (1) = 2−3 ( ). Subsequently, two additional coins (coins 2 and 3) are tossed; each one represents an informant's ability to assess the true state of the child j for item i. Coin 2 has a probability <ref type="bibr">(2)</ref> and coin 3 has a probability (3) of landing on heads, for simplicity, we assume that (2) = <ref type="bibr">(3)</ref> . Conversely, the probabilities 1− <ref type="bibr">(2)</ref> and 1−</p><p>( <ref type="formula">3)</ref>represent the chances of each informant incorrectly copying the child's state in its opposite form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Box 1</head><p>A pseudocode of the 3 coins simulation Note. The pseudocode presents a simulation involving three states represented by coins, each associated with distinct probability-driven outcomes. Coin 1 determines the Child State, while Coins 2 and 3, influenced by specific parameters, establish the Parent 1 and Parent 2 final states (PAR1 and PAR2 respectively). The simulation concludes by calculating the agreement between the two parent states, showcasing the alignment of their respective outcomes.</p><p>Box 1 outlines the simulation's pseudocode, consists of four steps as follows: (1) The child's state is set using coin 1; (2) Parent 1 assesses the child's state with probability (2) using coin 2;</p><p>(3) Similarly, are compared to determine the agreement between the parents. <ref type="table" target="#tab_0">Table 1 presents a sample from the  simulation results, formed as a response table,</ref> summarizing the results of coin 2 (PAR1) and coin 3 (PAR2) for each paired informant j, across all items i. <ref type="table" target="#tab_0">Table 2 is a pivot table derived from Table 1</ref>, presenting the agreement between the parents across all items for all paired informants.  Please note that in the simulation, the probabilities of coins 2 and 3, ( ) , were calculated using the following formula:</p><formula xml:id="formula_2">(5) ( ) = (1 − ) • • ( , 0, σ) • ( , 0, σ); = 2,3 ; = 2−3|4−18 ( )</formula><p>To comprehend the formula, one should consider that the agreement between two informants is influenced by the predictability of a child's behavior, a principle based on statistical probability and consistency. When a child's behavior is highly predictable, occurring either very frequently or very rarely, it becomes easier to forecast future behavior. This scenario is linked to lower variance, thereby fostering greater agreement between informants. On the contrary, less predictable behavior is associated with higher variance, which can lead to reduced informant agreement. In this context, the simulation applies this relation by tying the likelihood of copying child j true state for item i (probabilities</p><p>(2) and (3) ) to the Bernoulli variance which has the following form: pi (1-pi). When the probability pi of a child's specific behavior is either high (close to 1) or low (close to 0), the likelihood of a mistake is minimized. However, when this probability nears 0.5, the variance reaches its maximum, indicating a peak in unpredictability. Along with variance, several additional parameters are utilized to depict the overall behavior pattern. One such parameter is β, which represents a fixed effect influencing the group's general propensity toward either a high or low likelihood of errors in copying the child's behavior (it is assumed that β ranges from 0 to 1). λ(j,0,σ) is a variable that mimics a random effect captured from a distribution with a mean of zero and a standard deviation (SD) of σ, which varies the likelihood of errors for each pair of informants, denoted by j. Additionally, γ(i,0,σ) is another random variable that induces specific fluctuations in the likelihood of error for each item, denoted by i, with a mean of 0 and an SD of σ. Let's now compute the theoretical curve of disagreement between the parents for any given item i, denoted as . To calculate the disagreement, we aim to ascertain the probability that coin2 and coin3 will land on opposing sides. This is accomplished using the formula for two coins with probabilities 1 and 2 of landing heads. Thus, 2 • 1 (1 − 2 ) represents the probability that the two coins will fall on opposite sides. In our scenario, • 1 =</p><p>(2) and • 2 = (3) denote the probabilities of coin2 and coin3 landing heads, respectively. Equation 6, present the total disagreement, in which = 4−18 ( ) for the first experiemnt and = 2−3 ( ) in the second experiement. When calcualting the theroteical disagreeemnt we will set both λ and γ equal to one.</p><formula xml:id="formula_3">(6) = 2 • (2) • (1 − (3) ) = 2 • 2 • • (1 − ) • (1 − 2 • • (1 − )) ; , = 1</formula><p>Given the observations from the two datasets, CBCL/2-3_2 and CBCL/4-18_2, β can be determined to fit the observations by minimizing the square root of the error between the theoretical disagreement Di (based on Equation 6) and the observed disagreement for item i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Evaluation Design</head><p>The objective of the subsequent step is to identify a model capable of accurately evaluating the true agreement between each pair of informants, surpassing metrics such as Kappa. The Kappa metric necessitates first determining the expected chance probability and the actual agreement 0 , as outlined in Equation 7. In this scenario, with two paired informants, there is no straightforward method to calculate these metrics, as each paired informants refer to a different subject (I.e., Child). Similar problem occurs also in self-reported assessments. To address these limitations, two assumptions were made: (1) The chance probability for two informants to agree on item i is ( ) 2 , which serves as a good approximation but does not exactly match as found in the Kappa equation. (2) The probability of actual agreement, 0 , for a single instance of Beyond Kappa and ICC two informants responses can be estimated through quadratic regression analysis of the data presented in <ref type="table" target="#tab_1">Table 2</ref>'s columns, compared against .Given these assumptions, we found that the Generalized Linear Mixed Models (GLMMs) framework can be a good candidate to generate the required outcome. Thus, our subsequent goal was to identify a specific model capable of elucidating the data within the framework of GLMMs, by applying it into the real-world datasets CBCL/4-18 and CBCL/2-3. The analysis was performed using the lme4 package, employing the default Nelder-Mead optimizer <ref type="bibr" target="#b4">(Bates et al., 2014)</ref>. We predict that, as indicated by Equation 6, a model featuring a quadratic fixed effect of the response reporting probability ( ) and utilizing the data from Table 2 will clarify the relationship between the disagreement rate and for each item i. <ref type="figure">Figure 2</ref> presents four simulation runs of 200 families, illustrating the observed average disagreement for each item (red dots) compared to the simulation's average disagreement outcomes (blue dots) in two scenarios: one with no random effects ( = 1, = 1) and the other with the random effect for each of the two datasets. The dashed blue curve illustrates the theoretical lines from the simulation based on the fitted β, with β values of 0.55 for CBCL/2-3 and 0.45 for CBCL/4-18, respectively. The upper dashed blue curve in the figures represents the full random state while the lower blue line that is merged with the x-axis represents full agreement. <ref type="table" target="#tab_2">Table 3a</ref> and 3b showcases the top six link GLMM function models with quadratic relation between the probability and the disagreement based on equation 6 assumptions. The functions were fit to the source dataset, ranked according to their data fit quality as reflected by the Akaike Information Criterion (AIC). These models vary in their random effects but share identical fixed effects. In both independent datasets (CBCL/4-18 and CBCL/2-3), the functions display identical model structures. <ref type="table">Table 4</ref> details the parameters of the two leading models, highlighted in bold, from <ref type="table" target="#tab_2">Table 3a</ref> and 3b. From the table we can learn that in the winning models the random effects consist of both intercept and slope per paired ID and intercept per item (see <ref type="figure">Figure 3</ref>, which visualizes the winning model trajectories). Typically, random effects are of no direct interest to clinicians, as they represent variability in the outcome that is not being specifically controlled in the model. However, in this specific case, since the model's fixed effect captured the probability effect of the entire population, by neutralizing the fixed effect, random effects can help interpret results and understand the sources of individual variability between informants. To capture solely the random effect, we used the area under the curve (AUC) approach by subtracting the fixed effect AUC from the informant-pair trajectory AUC <ref type="figure" target="#fig_6">(Figure 4)</ref>. We call the outcome enclosed by the two curves (the fixed effect curve in purple and the paired informant random Beyond Kappa and ICC effect curve in blue), the Random Effect Area (REA). For each informant pair, we calculated the REA index to sort the paired informants by their true agreement variability. Beyond Kappa and ICC</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Outcome</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>Simulation results on two datasets Notes. This figure illustrates the outcomes of simulations conducted on two distinct datasets: CBCL/2-3 (left) and . The red points in the graph represent observed data, while the blue dots signify data generated from the simulation. The upper blue dotted line depicts the theoretical curve under purely random conditions, and the middle curve represents the theoretical line of disagreement observed in each experiment, as determined by Equation 6, after β was fitted with observations to achieve the lowest squared error. Panels A and B showcase the results of the simulation when random effects are excluded. Conversely, Panels C and D depict the outcomes of the same simulation when random effects are incorporated, highlighting the impact of randomness on the data . The exact measure of how we calculated the REA can be found in the supplementary materials. The informants who tended to disagree above the average appear with a positive REA at the top of the table, while the informants who tended to agree more than average appear at the bottom of the table with a negative REA. Notes. id refers to the informant's ID, aligning with the household ID in the dataset, and item indicates the item ID number. The term (1+p|item) represents random effects for both slopes and intercepts for each item, while (1|item) indicates random effects for intercepts only. The notation (0+p|item) specifies random effects for slopes only. In both tables, the second model was chosen (highlighted in bold) due to its lower number of parameters and statistical significance. Beyond Kappa and ICC <ref type="figure" target="#fig_6">Figure 4</ref> shows three examples of paired informants (3 pairs of parents) and the REA table values, each from one of the groups (tend to disagree in the top table, tend to agree in the bottom table, and close to average in the middle table). Each example consists of 118 states (each state has 3 possible values: "no agreement", "agreement on nonevent", "agreement on event") corresponding to 118 item in the assessment ordered by their probability(from left to right), in which the highest probability reaches 0.6 (dashed vertical line). The binomial model fits each individual trajectory based on these states, and the trajectory above 0.6 is an extrapolation of both the fixed effect and the random effects. In the context of clinical practice, large REA values may indicate that one or both informants randomly selected the items, while significant negative values could suggest that the two informants copied from each other. These insights can be derived by comparing the REA values against population norms and standard deviations. In other words, while Kappa metric is expressed versus the chance probability of agreement (see equation 8) the suggested metric REA is measured compared to the average agreement probability of the group which can be later interpreted using the Kappa scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 4</head><p>Details of the parameters of the optimal p2bidiit model for both datasets. Equation 8 illustrates the translation of the Kappa equation into terms of disagreement, where, given , can be evaluated from the individual curve F of the PI by applying = ( ). Similarly, can be directly derived from the random curve G, where = ( ) = ( − ). Graph visualizing the winning mixed model p2bidbit trajectories of dataset CBCL/2-3 based on its random and fixed coefficients.</p><p>Note. The trajectories of individual paired informants appear in blue, while the fixed effect appears in red.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Evaluation</head><p>In the final section, we aim to compare the performance of the proposed REA model with other models, such as Kappa and ICC. We assume that in this scenario of nested groups, REA will have the best performance. From <ref type="figure">Figure 2</ref>, we can learn that the simulation data closely mirrors the real data, indicating that the simulation can be used as a reliable ground truth to identify which models best explain the observed outcomes. To compare the models, we will employ the simulation synthetic data for which the expected ranking among paired informants (PI) is already known and is based on their individual level of agreement that is govern by the random effect λ(j,0,σ), allowing us to compare each model's ranking against the ground truth. In other words, the list of paired informants can be ranked by their λj values from high (indicating a tendency to disagree) to low (indicating a tendency to agree), serving as our benchmark. The model that best correlated with the benchmark will be declared the winning model. To ensure that the observed correlations were not merely coincidental, the simulation and its outputs were generated repeatedly. During each iteration, the model assessed the rankings and then logged the correlation with the ground truth, calculating both the average and its standard deviation, as shown in <ref type="figure" target="#fig_7">Figure 5</ref>. Furthermore, this experimental approach allows for simulations across a range of scenarios, incorporating varying numbers of paired informants (PIs) and items, to scrutinize their influence on the correlation results. <ref type="figure" target="#fig_7">Figure 5a</ref> illustrates the correlation results as a function of the number of pairs, while <ref type="figure" target="#fig_7">Figure 5b</ref> displays the correlation as a function of the number of items. The models evaluated include the Random Effects Area (REA), <ref type="bibr">Kappa, Intraclass Correlation Coefficient (ICC)</ref>, and the trivial model-a straightforward approach focusing solely on the percentage of total agreement. As demonstrated by both graphs, the new model, REA, outperformed both the trivial model and the classical models, Kappa and ICC. This methodical approach enables us to thoroughly evaluate our model's predictive accuracy and its ability to differentiate between random and fixed effects, thus determining its efficacy in a controlled experimental environment. As mentioned in previous sections, we anticipated that the fixed effect model would incorporate a quadratic relationship with p, alongside its random effects indicated by intercepts and slopes that can be used to calculate the area under curve. REA Beyond Kappa and ICC Another outcome of the proposed model is how to evaluate the agreement of broadband / category indices. Previous approaches linearly combined disagreement between paired informants across the items included in the category. The primary challenge with this approach is the introduction of significant bias into the outcomes, influenced more by the distribution of items with either low or high predictability values-those items with pi values at the extreme ends-rather than the genuine effect of agreement. Initially, employing a straightforward analysis, the CBCL item was dissected into 9 distinct categories. Bartlett's test for homogeneity of variances then pointed out a non-homogeneous variance across these categories, signaling a significant discrepancy with a p-value of less than 0.0001. This apparent variance, however, dissipated after adjusting for the probability variance among itemsdistinguishing between rare and frequently occurring items-based purely on their standard deviation (intercept). Consequently, the effect that was once prominent became negligible, leading to a nonsignificant result in Bartlett's test. This adjustment highlights the importance of considering item frequency in evaluating agreement, ensuring that the analysis reflects true agreement effects rather than artifacts of item predictability. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Performance by number of PIs and Items</head><p>Note. <ref type="figure">Figure A</ref>  <ref type="figure">Figure B</ref> shows the correlation results based on the number of IPs. The graphs collectively reveal a clear trend indicating that the performance of each model is influenced by the number of pairs and items. A notable increase in correlation is observed with the increase in the number of items, alongside a more gradual improvement with the increase in the number of pairs. The GLMM consistently outperforms other models in simultaneously identifying λj and γi, especially as the number of items grows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>depicts the correlation between the models' prediction and the benchmark in relation to the number of items in the simulated assessment while</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B A Beyond Kappa and ICC</head><p>Last, we refit all the models, but this time we transformed all models into a linear form; instead of p as the independent variable, we used entropy (H), where = • Ln ( ) . <ref type="table" target="#tab_2">Table 5 demonstrates that  on the same two datasets as in Table 3</ref>, a linear model that used entropy as the independent variable instead of a quadratic model that used p 2 achieved better fitness. The main reason is that we reduced the number of free parameters from 7 to 6. As we can expect, the models that won based on the two datasets had the same random effects as before. The entropy model was simplified and thus had an advantage over the previous models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5</head><p>Level of fitness for 5 Entropy based model agreements (from highest to lowest fit). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. CBCL/2-3_2 Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Agreement among informants is an important property for increasing the internal reliability of a clinical diagnosis and thereby achieving a better prognosis. To accurately assess the frequency of symptoms using assessments or diagnostic tools, it is important that the results are valid, reproducible, and highly reliable. In recent years, the examination of agreement among multiple informants has garnered growing interest <ref type="bibr" target="#b12">(De Los Reyes et al., 2015;</ref><ref type="bibr" target="#b23">Stratis &amp; Lecavalier, 2015;</ref><ref type="bibr" target="#b15">Gresham et al., 2018;</ref><ref type="bibr" target="#b19">Romano et al., 2018;</ref><ref type="bibr" target="#b10">Cheng et al., 2018;</ref><ref type="bibr" target="#b21">Schwab et al., 2020;</ref><ref type="bibr" target="#b20">Santos et al., 2020;</ref><ref type="bibr" target="#b18">Parker et. al 2016</ref><ref type="bibr" target="#b17">Parker et. al ,2020</ref>. A significant limitation of these approaches is their failure to compare the observed agreement between informants against what would be expected by chance. Consequently, items reporting symptoms more frequently are often more contentious than those reporting less frequent symptoms. This issue likely arises because the scenarios involving paired informants in assessment are inadequately addressed by traditional inter-rater reliability (IRR) models, such as kappa and ICC. The problem intensifies when aggregating several items into a single index <ref type="bibr" target="#b14">(Duhig et al., 2000;</ref><ref type="bibr" target="#b7">Carneiro et al., 2020)</ref>, where the ratio of high-to low-frequency items primarily determines the overall level of agreement, rather than Beyond Kappa and ICC psychological factors. Furthermore, existing guidelines do not adequately address the clinical issue of how to manage potential discrepancies among multiple raters in a home setting <ref type="bibr" target="#b9">(Caye et al., 2017)</ref>.</p><p>This work expands the scope of conventional interrater reliability by introducing a multi-source randomness model tailored to assess the chance probabilities when multiple sources, such as nested paired informants, provide assessments regarding the same subject for different items. Our model diverges from traditional measures like the kappa coefficient and ICC, by offering a means to simultaneously evaluate the chance agreement that may arise from both the subjectivity of the paired informants and the particularities of the assessment items. This approach effectively mitigates the persistent challenge of bias due to chance agreement, providing a robust tool to accurately gauge the true concordance among raters. To showcase the model's capability in deducing interrater reliability, we commenced with the '3-coins' simulation designed to emulate behavior akin to that observed in experimental datasets. Subsequently, employing the dataset produced by this simulation, we were able to ascertain which model possesses a superior aptitude for uncovering hidden variables. These variables simulate the propensity of paired informants or items to either agree or disagree in their responses.</p><p>The implications of these results are twofold. Firstly, they present a general approach capable of outperforming classical models such as Kappa and ICC in estimating inter-rater reliability amidst multiple sources of noise. Secondly, They highlight a clinical implication of the method: the ability to assess the level of agreement of an individual PI against population norms based on just two assessments, one from each informant. It has also been shown that using aggregated indices with items that carry different levels of entropy may lead to bias in the index readings. This fact, already predicted by information theory, explains why previous studies using indices that aggregated items with varied values of entropy contained intrinsic bias. The bias results from the number of items with low versus high entropy and cannot be attributed to clinical states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental materials</head><p>The entire code (R notebooks) and data are accessible as part as the supplemental materials to allow reproduce analyses and review of the study.</p><p>https://osf.io/qfcwr/?view_only=cea0b74b51f84a1db8f85fb6d7377e70 A short clip that explains the motivation for this paper is available here: Motivation: https://youtu.be/cwroiLNDxBY</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>A confusion matrix (CM). The table presents the CM of the first item in assessment CBCL/2-3_2 Note. True positive (TP) to indicate the element in the matrix that counts the number of paired informants who agreed about the existence of an event, and true negative (TN) indicates the total agreement on nonevents (both informants reported 0). The false positive (FP) and false negative (FN) are on the offdiagonal element that indicates the number of informants who disagreed on item i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Init:Simulation #1: pi = 4−18 ( ) ; i=1..99 Simulation #2: pi = 2−3 ( ) ; i=1..118 Run each simulation separately:Start: coin 1 (Child state): for j=1 to n: #(number of children) for i = 1 to m: #(number of items) throw coin1 with Probability pi store the outcome in C[j,i] coin 2 (Parent 1's Assessing the Child's State): for j=1 to n: #(number of children) for i=1 to m: #(number of items) calc prob: (2) = pi(1-pi) β (j) (i) throw coin2 with Probability (2) : if head PAR1[j,i] = C[j,i] else PAR1[j,i] = -C[j,i] coin 3 (Parent 2's Assessing the Child's State): [j,i] = C[j,i] else PAR2[j,i] = -C[j,i] Calculate agreement: Agreement = (PAR1 == PAR2) Beyond Kappa and ICC Parent 2 assesses the child's state with probability (3) using coin 3; (4) The outcomes of steps 2 and 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4</head><label>4</label><figDesc>Random Effect Area Note: Left: List of paired-informant (PI) IDs ordered by their Random Effect Area (REA) values from largest to smallest. Left: Three examples of 3 paired informants from the table (marked in blue), their states for each of the 118 items and the trajectory for each of these examples and how it is transformed into an REA value.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5</head><label>5</label><figDesc>Figure 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Simulation Results for Informant Responses. This table displays the outcomes of simulations for each item across paired informants.</figDesc><table><row><cell>Paired Informants</cell><cell>Item No</cell><cell>Informant1</cell><cell>Informant2</cell></row><row><cell>ID (1..n)</cell><cell>(1..m)</cell><cell>response (PAR1)</cell><cell>response (PAR2)</cell></row><row><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>1</cell><cell>2</cell><cell>1</cell><cell>0</cell></row><row><cell>1</cell><cell>3</cell><cell>0</cell><cell>0</cell></row><row><cell>1</cell><cell>4</cell><cell>0</cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Simulation Agreement table. the actual agreement across m items and n paired informants.</figDesc><table><row><cell></cell><cell>PI 1 Agreement</cell><cell>PI 2 Agreement</cell><cell>PI 3 Agreement</cell><cell>…</cell><cell>PI n Agreement</cell></row><row><cell>Item 1</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell>Item 2</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell></cell><cell>0</cell></row><row><cell>Item 3 . . .</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell></cell><cell>1</cell></row><row><cell>Item m</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell></cell><cell>0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="6">Comparison of fitness levels in six mixed-effects models on agreement data, ranked from highest to</cell></row><row><cell>lowest fit</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">A. CBCL/2-3_2 Dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model name</cell><cell>Df</cell><cell cols="2">Fixed effect Random</cell><cell>AIC</cell><cell>Pr(&gt;Chisq)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>effect</cell><cell></cell><cell></cell></row><row><cell>p2bidiit</cell><cell>9</cell><cell>p+I(p^2)</cell><cell>(1+p|id)+(1+p|item)</cell><cell>15574</cell><cell></cell></row><row><cell>p2bidbit</cell><cell>7</cell><cell>p+I(p^2)</cell><cell>(1+p|id)+(1|item)</cell><cell>15574</cell><cell>&lt; 2e-16 ***</cell></row><row><cell>p2iidiit</cell><cell>5</cell><cell>p+I(p^2)</cell><cell>(1|id)+(1|item)</cell><cell>15757</cell><cell>&lt; 0.002 **</cell></row><row><cell>p2iid</cell><cell>4</cell><cell>p+I(p^2)</cell><cell>(1|id)</cell><cell>15764</cell><cell></cell></row><row><cell>p2sidiit</cell><cell>5</cell><cell>p+I(p^2)</cell><cell>(0+p|id)+(1|item)</cell><cell>15963</cell><cell></cell></row><row><cell>p2sidsit</cell><cell>5</cell><cell>p+I(p^2)</cell><cell>(0+p|id)+(0+p|item)</cell><cell>15969</cell><cell></cell></row><row><cell cols="2">B. CBCL/4-18_2 Dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model name</cell><cell>Df</cell><cell cols="2">Fixed effect Random</cell><cell>AIC</cell><cell>Pr(&gt;Chisq)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>effect</cell><cell></cell><cell></cell></row><row><cell>p2bidbit</cell><cell>9</cell><cell>p+I(p^2)</cell><cell>(1+p|id)+(1+p|item)</cell><cell>6405</cell><cell>0.0117 *</cell></row><row><cell>p2bidiit</cell><cell>7</cell><cell>p+I(p^2)</cell><cell>(1+p|id)+(1|item)</cell><cell>6410</cell><cell>&lt; 2e-16 ***</cell></row><row><cell>p2iidiit</cell><cell>5</cell><cell>p+I(p^2)</cell><cell>(1|id)+(1|item)</cell><cell>6449</cell><cell>&lt; 2e-12 ***</cell></row><row><cell>p2iid</cell><cell>4</cell><cell>p+I(p^2)</cell><cell>(1|id)</cell><cell>6497</cell><cell></cell></row><row><cell>p2sidiit</cell><cell>5</cell><cell>p+I(p^2)</cell><cell>(0+p|id)+(1|item)</cell><cell>6600</cell><cell></cell></row><row><cell>p2sidsit</cell><cell>5</cell><cell>p+I(p^2)</cell><cell>(0+p|id)+(0+p|item)</cell><cell>6621</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Private scholar zsolan@gmail.com</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>I would like to express my deepest gratitude to my wife, Dr. Maly Solan, whose unwavering support and inspiration were my guiding lights throughout this journey.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Manual for the child behavior checklist and revised child behavior profile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Achenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Edelbrock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
	<note>No Title</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Empirically based assessment of the behavioral/emotional problems of 2-and 3-year-old children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Achenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Edelbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of abnormal child psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="650" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Welfare, children, and families: A three-city study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Chase-Lansdale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.3886/ICPSR04701.v7</idno>
		<ptr target="https://doi.org/10.3886/ICPSR04701.v7" />
		<imprint>
			<date type="published" when="2007" />
			<publisher>Inter-University Consortium for Political and Social Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Observing interaction. An introduction to sequential analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bakeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Gottman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fitting linear mixed-effects models using lme4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mächler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v067.i01</idno>
		<ptr target="https://doi.org/10.18637/jss.v067.i01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Test-retest: agreement or reliability?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berchtold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methodological Innovations</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">2059799116672875</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistical methods for assessing agreement between two methods of clinical measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8476</biblScope>
			<biblScope unit="page" from="307" to="310" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Meta-analysis on parent-teacher agreement on preschoolers&apos; emotional and behavioural problems. Child Psychiatry and Human Development, online ahead of print</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rescorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dias</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10578-020-01044-y</idno>
		<ptr target="https://doi.org/10.1007/s10578-020-01044-y" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical models for assessing agreement in method comparison studies with replicate measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Carstensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Gurrin</surname></persName>
		</author>
		<idno type="DOI">10.2202/1557-4679.1107</idno>
		<ptr target="https://doi.org/10.2202/1557-4679.1107" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Biostatistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evaluating parental disagreement in ADHD diagnosis: Can we rely on a single report from home</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Rohde</surname></persName>
		</author>
		<idno type="DOI">10.1177/1087054713504134</idno>
		<ptr target="https://doi.org/10.1177/1087054713504134" />
	</analytic>
	<monogr>
		<title level="j">Journal of Attention Disorders</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="561" to="566" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Understanding parent-teacher agreement of the Strengths and Difficulties Questionnaire (SDQ): Comparison across seven European countries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Keyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bitfoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Carta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koç</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goelitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Otten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lesinskiene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mihova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kovess-Masfety</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Methods in Psychiatric Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1589</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The validity of the multi-informant approach to assessing child and adolescent mental health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De Los Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A G</forename><surname>Drabick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Burgers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rabinowitz</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0038498</idno>
		<ptr target="https://doi.org/10.1037/a0038498" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="858" to="900" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using pooled kappa to summarize interrater agreement across many items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Kanouse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Teleki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Field methods</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="272" to="282" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Interparental agreement on internalizing, externalizing, and total behavior problems: A meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Duhig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Renk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Phares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychology: Science and Practice</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="435" to="453" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cross-informant agreement of children&apos;s social-emotional skills: An investigation of ratings by teachers, parents, and students from a nationally representative sample</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Gresham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Metallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cassidy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology in the Schools</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="208" to="223" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Correlation and agreement: overview and clarification of competing concepts and measures. Shanghai Archives of Psychiatry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">M</forename><surname>Tu</surname></persName>
		</author>
		<idno type="DOI">10.11919/j.issn.1002-0829.216045</idno>
		<ptr target="https://doi.org/10.11919/j.issn.1002-0829.216045" />
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="115" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using multiple agreement methods for continuous repeated measures data: A tutorial for practitioners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Inácio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Stevens</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12874-020-01022-x</idno>
		<ptr target="https://doi.org/10.1186/s12874-020-01022-x" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Research Methodology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">154</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Application of mixed effects limits of agreement in the presence of multiple sources of variability: Exemplar from the comparison of several devices to measure respiratory rate in COPD patients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pinnock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mccloughan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Drost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Mantoani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Macnee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mckinstry</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0168321</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0168321" />
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cross-informant agreement on mental health outcomes in children with maltreatment histories: A systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weegar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Babchishin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Violence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Parent-teacher agreement on children&apos;s externalizing behaviors: Results from a community sample of Portuguese elementary-school children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Farrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Da Agra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Children and Youth Services Review</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Agreement among student, parent and teacher ratings of school inclusion: A multitrait-multimethod analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schwab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zurbriggen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Venetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of School Psychology</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Including omission mistakes in Cohen&apos;s kappa and an analysis of the coefficient&apos;s paradox features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="765" to="77" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Informant agreement for youth with autism spectrum disorder or intellectual disability: A meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Stratis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lecavalier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Autism and Developmental Disorders</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1026" to="1041" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
