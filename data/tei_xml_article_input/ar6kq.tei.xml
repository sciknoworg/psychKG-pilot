<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rational metareasoning and the plasticity of cognitive control</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Falk</forename><surname>Lieder</surname></persName>
							<email>falk.lieder@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Helen Wills Neuroscience Institute</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amitai</forename><surname>Shenhav</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Cognitive, Linguistic, and Psychological Sciences</orgName>
								<orgName type="institution" key="instit1">Brown Institute for Brain Science</orgName>
								<orgName type="institution" key="instit2">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Musslick</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Princeton Neuroscience Institute</orgName>
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Hoy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Katarina Slama</surname></persName>
						</author>
						<title level="a" type="main">Rational metareasoning and the plasticity of cognitive control</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T12:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>The human brain has the impressive capacity to adapt how it processes information to high-level goals. While it is known that these cognitive control skills are malleable and can be improved through training, the underlying plasticity mechanisms are not well understood. Here, we develop and evaluate a model of how people learn when to exert cognitive control, which controlled process to use, and how much effort to exert. We derive this model from a general theory according to which the function of cognitive control is to select and configure neural pathways so as to make optimal use of finite time and limited computational resources. The central idea of our Learned Value of Control model is that people use reinforcement learning to predict the value of candidate control signals of different types and intensities based on stimulus features. This model correctly predicts the learning and transfer effects underlying the adaptive control-demanding behavior observed in an experiment on visual attention and four experiments on interference control in Stroop and Flanker paradigms. Moreover, our model explained these findings significantly better than an associative learning model and a Win-Stay Lose-Shift model. Our findings elucidate how learning and experience might shape people&apos;s ability and propensity to adaptively control their minds and behavior. We conclude by predicting under which circumstances these learning mechanisms might lead to self-control failure.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The human brain has the impressive ability to adapt how it processes information and responds to stimuli in the service of high level goals, such as writing an article <ref type="bibr" target="#b0">[1]</ref>. The mechanisms underlying this behavioral flexibility range from seemingly simple processes, such as inhibiting the impulse to browse your Facebook feed, to very complex processes such as orchestrating your thoughts to reach a solid conclusion. Our capacity for cognitive control enables us to override automatic processes when they are inappropriate for the current situation or misaligned with our current goals. One of the paradigms used to study cognitive control is the Stroop task, where participants are instructed to name the hue of a color word (e.g., respond "green" when seeing the stimulus RED) while inhibiting their automatic tendency to read the word ("red") <ref type="bibr" target="#b1">[2]</ref>. Similarly, in the Eriksen flanker task, participants are asked to report the identity of a target stimulus surrounded by multiple distractors while overcoming their automatic tendency to respond instead to the distractors. Individual differences in the capacity for cognitive control are highly predictive of academic achievement, interpersonal success, and many other important life outcomes <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>While exerting cognitive control improves people's performance in these tasks, it is also effortful and appears to be intrinsically costly <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. The Expected Value of Control (EVC) theory maintains that the brain therefore specifies how much control to exert according to a rational cost-benefit analysis, weighing these effort costs against attendant rewards for achieving one's goals <ref type="bibr" target="#b6">[7]</ref>. In broad accord with the predictions of the EVC theory, previous research has found that control specification is contextsensitive <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> and modulated by reward across multiple domains <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, such as attention, response inhibition, interference control, and task switching. While previous theories account for that fact that people's performance in these task is sensitive to reward <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>, it remains unclear how these dependencies arise from people's experience. Recently, it has been proposed that the underlying mechanism is associative learning <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. Indeed, a number of studies have demonstrated that cognitive control specification is plastic: whether people exert cognitive control in a given situation, which controlled processes they employ, and how much control they allocate to them is learned from experience. For instance, it has been demonstrated that participants in visual search tasks gradually learn to allocate their attention to locations whose features predict the appearance of a target <ref type="bibr" target="#b16">[17]</ref>. Furthermore, it has been shown that people learn to exert more cognitive control after their performance on a control-demanding task was rewarded <ref type="bibr" target="#b9">[10]</ref> and learn to exert more control in response to potentially controldemanding stimuli that are associated with reward than to those that are not <ref type="bibr" target="#b10">[11]</ref>.</p><p>These studies provide evidence that people can use information from their environment (e.g., stimulus features) to learn when to exert cognitive control and how to exert control, and it has recently been suggested that this can be thought of in terms of associative learning <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. Other studies suggested that cognitive control can be improved through training <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>. However, achieving transfer remains challenging <ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref>, the underlying learning mechanisms are poorly understood, and there is currently no theory that could be used to determine which training regimens will be most effective and which real-life situations the training will transfer to. Developing precise computational models of the plasticity of cognitive control may be a promising way to address these problems and to enable more effective training programs for remediating executive dysfunctions and enabling people to pursue their goals more effectively.</p><p>In this article, we extend the EVC theory to develop a theoretical framework for modeling the function and plasticity of cognitive control specification. This extension incorporates recent theoretical advances inspired by the rational metareasoning framework developed in the artificial intelligence literature <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>. We leverage the resulting framework to derive the Learned Value of Control (LVOC) model which can learn to efficiently select control signals based on features of the task environment. The LVOC model can be used to simulate cognitive control (e.g., responding to a goalrelevant target that competes with distractors) and, more importantly, how it is shaped by learning. According to the LVOC model, people learn the value of different cognitive control signals (e.g., how much to attend one stimulus or another). A key strength of this model is that it is very general and can be applied to phenomena ranging from simple learning effects in the Stroop task to the acquisition of complex strategies for reasoning and problem-solving. In order to demonstrate the validity and generality of this model, we show that it can capture the empirical findings of five cognitive control experiments on the plasticity of visual attention <ref type="bibr" target="#b16">[17]</ref>, the interacting effects of reward and task difficulty on the plasticity of interference control <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, and the transfer of such learning to novel stimuli <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. Moreover, the LVOC model outperforms alternate models of such learning processes that rely only on associative learning or a basic win-lose-stayshift strategy. Our findings shed light on how learning and experience might shape people's ability and propensity to adaptively control their minds and behavior, and the LVOC model predicts under which circumstances these mechanisms might lead to selfcontrol failure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Formalizing the function of cognitive control At an abstract level, all cognitive control processes serve the same function: to adapt neural information processing to achieve a goal <ref type="bibr" target="#b27">[27]</ref>. At this abstract level, neural information processing can be characterized by the computations being performed, and the extent to which the brain achieves its goals can be quantified by the expected utility of the resulting actions. From this perspective, an important function of cognitive control is to select computations so as to maximize the agent's reward rate (i.e., reward per unit time). This problem is formally equivalent to the rational metareasoning <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b28">28]</ref> problem studied in computer science: selecting computations so as to make optimal use of the controlled system's limited computational resources (i.e., to achieve the highest possible sum of rewards with a limited amount of computation).</p><p>Thus, rational metareasoning suggests that the specification of cognitive control is a metacognitive decision problem. In reinforcement learning <ref type="bibr" target="#b29">[29]</ref>, decision problems are typically defined by a set of possible actions, the set of possible states, an initial state, the conditional probabilities of transitioning from one state to another depending on the action taken by the agent, and a reward function. Together these five components define a Markov decision process (MDP <ref type="bibr" target="#b29">[29]</ref>). In a typical application of this framework the agent is an animal, robot, or computer program, actions are behaviors (e.g., pressing a lever), the state characterizes the external environment ℰ (e.g., the rat's location in the maze), and the rewards are obtained from the environment (e.g., pressing a lever dispenses cheese). In general, the agent cannot observe the state of the environment directly; for instance, the rat running through a maze does not have direct access to its location but has to infer this from sensory observations. The decision problems posed by an environment that is only partially observable can be modelled as a partially observable MDP (POMDP <ref type="bibr" target="#b30">[30]</ref>). For each POMDP there is an equivalent MDP whose state encodes what the agent knows about the environment and is thus fully observable; this is known as the belief-MDP <ref type="bibr" target="#b30">[30]</ref>.</p><p>Critically, the belief-MDP formalism can also be applied to the choice of internal computations <ref type="bibr" target="#b25">[26]</ref> -such as allocating attention <ref type="bibr" target="#b31">[31]</ref> or gating information into working memory <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref> -rather than only physical actions. In the rational metareasoning framework, the agent is the cognitive control system whose actions are control signals that specify which computations the controlled systems should perform. The internal state of the controlled systems is only partially observable. We can formally define the problem of optimal cognitive control specification as maximizing reward the in the metalevel MDP M = , ( , , , ,</p><p>where is the set of possible information states, comprising beliefs about the external environment (e.g., the choices afforded by the current situation) and beliefs about the agent's internal state (e.g., the decision system's estimates of the choices' utilities), ( denotes the initial information state, is the set of possible control signals that may be discrete (e.g., "Simulate action 1.") or continuous (e.g., "Increase the decision threshold by 0.175." or "Suppress the activity of the word-reading pathway by 75%."), is a transition model, and is the reward function that cognitive control seeks to maximize. The transition model specifies the conditional probability of transitioning from belief state to belief state ′ if the control signal is by ( , , ′). The meta-level reward function combines the utility of outcome (of actions resulting from control signal in belief state ) with the computational cost associated with exerting cognitive control:</p><formula xml:id="formula_1">, = − cost , ,<label>(2)</label></formula><p>where is the outcome of the resulting action, is utility function of the brain's reward system, and cost( , ) is the cost of implementing the controlled process.</p><p>Within this framework, we can define a cognitive control strategy : → as a mapping from belief states ∈ to control signals ∈ . The optimal cognitive control strategy ⋆ is the one that always chooses the computation with the highest expected value of computation (EVOC):</p><formula xml:id="formula_2">⋆ : ↦ argmax D EVOC , .<label>(3)</label></formula><p>The EVOC is the expected sum of computational costs and benefits of performing the computation specified by the control signal and continuing optimally from there on:</p><formula xml:id="formula_3">EVOC , = L ⋆ , = , + L ⋆ ( QRS ) | Q = , V = , ,<label>(4)</label></formula><p>where L ⋆ is known as the Q-function of the optimal control strategy ⋆ , and L ⋆ ( QRS ) is the expected sum of meta-level rewards of starting ⋆ in state QRS .</p><p>In summary, cognitive control specification selects the sequence of cognitive control signals that maximizes the expected sum of rewards of the resulting actions minus the cost of the controlled process. The optimal solution to this problem is given by the optimal control policy ⋆ . So far, we have assumed that the cognitive control system chooses one control signal at a time, but could also be a vector comprising multiple control signals (e.g., one that increases the rate at which evidence is accumulated towards the correct decision by via an attentional mechanism and a second one that adjusts the decision threshold). Furthermore, overriding a habit by a well-reasoned decision also requires executing a coordinated sequence of cognitive operations for planning and reasoning. Instead of specifying each of these operations by a separate control signal, the cognitive control system might sometimes use a single control signal to instruct the decision system to execute an entire planning strategy. The rational metareasoning framework allows us to model cognitive strategies as options <ref type="bibr" target="#b34">[34]</ref><ref type="bibr" target="#b35">[35]</ref><ref type="bibr" target="#b36">[36]</ref><ref type="bibr" target="#b37">[37]</ref>. An option is a policy combined with an initiation set and a termination condition <ref type="bibr" target="#b37">[37]</ref>. Options can be treated as if they were elementary computations and elementary computations can be interpreted as options that terminate after the first step. With this extension, the optimal solution to the cognitive control specification problem becomes</p><formula xml:id="formula_4">⋆ = arg max Y∈ Q ⋆ ( , ),<label>(5)</label></formula><p>where the set of options may include control strategies and elementary control signals.</p><p>Critically, this rational metareasoning perspective on cognitive control covers not only simple phenomena, such as inhibiting a pre-potent automatic response in the Stroop task, but also more complex ones, such as sequencing one's thoughts so as to follow a good decision strategy, and very complex phenomena such as reasoning about how to best solve a complex problem.</p><p>The LVOC model of the plasticity of cognitive control specification The computations required to determine the expected value of control may themselves be costly and time consuming. Yet, in some situations cognitive control has to be engaged very rapidly, because maladaptive reflexes, impulses, and habitual responses have to be inhibited before the triggered response has been executed. In such situations, there is simply not enough time to compute the expected value of control on the fly. Fortunately, this may not be necessary because an approximation to the EVOC can be learned from experience. We therefore hypothesize that the cognitive control system learns to predict the context-dependent value of alternative control signals. By understanding how this learning occurs, we might be able to explain the experience-dependent changes in how people use their capacity for cognitive control which we will refer to as the plasticity of cognitive control specification. In addition to these systematic, experience-driven changes cognitive control is also intrinsically variable. To model the plasticity and the variability of cognitive control, this section develops a model that combines a novel feature-based learning mechanism with a new control specification mechanism that explores promising control signals probabilistically to accelerate learning which of them is most effective.</p><p>The previous section characterized the problem of cognitive control specification as a sequential meta-decision problem. This makes reinforcement learning algorithms <ref type="bibr" target="#b38">[38]</ref> a natural starting point for exploring how the cognitive control systems learns the EVOC from experience. Approximate Q-learning appears particularly suitable because the optimal control strategy can be expressed in terms of the optimal Q-function (Equations 3-5). From this perspective, the plasticity mechanisms of cognitive control specification serve to learn an approximation to the value Q ( , ) of selecting control signal in state based on one's experience with selecting control signals = ( S , ⋯ , Q ) in states = ( S , ⋯ , Q ) and receiving the meta-level rewards = ( S , ⋯ , Q ).</p><p>Learning an approximate Q-function Q from this information could enable the cognitive control system to efficiently select a control strategy by comparing learned values rather than reasoning about their effects.</p><p>Learning the optimal meta-level state-value function ⋆ can be challenging because the value of each control signal may depend on the outcomes of the control signals selected afterwards. Furthermore, the state space of the meta-level MDP has a very high dimensionality as it comprises all possible states that the controlled system could be in. To overcome these challenges, a neural system like the brain might learn a linear approximation to the meta-level state value function instead of estimating each of its entries separately. Concretely, the cognitive control system might learn to predict the value of selecting a control strategy (e.g., focusing on the presenting speaker instead of attending to an incoming phone call) by a weighted sum of features of the internal state and the current context (e.g. being in a conference room). For instance, the value Q ⋆ ( , ) of choosing control signal in the internal state can be predicted from the features V ( ), the implied control signal intensities , their interactions with the features, that is V ⋅ c , and their costs through Bayesian linear regression <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40]</ref>. Concretely, the EVOC of selecting control signal in state is approximated by the Learned Value of Control (LVOC),</p><formula xml:id="formula_5">LVOC , ; = ( + V h ⋅ V i VjS + k l ⋅ k m kjS + V,k h×l ⋅ V ⋅ k m kjS i VjS − cost( ) − o ⋅ ,<label>(6)</label></formula><p>where the weight vector includes the offset ( , the weights V h of the states' features, the weights (l) of the control signal intensities, the weights V,k h×l of their interaction terms, the weight <ref type="bibr">(o)</ref> of the response time , and cost( ) is the intrinsic cost of control which scales with the amount of cognitive control applied to the task.</p><p>The optimal way to update the weights based on experience in a stationary environment is given by Bayesian linear regression. Our model therefore maintains and continues to update the posterior distribution on the weight vector given its experience S,⋯,Q up until the present time , that is</p><formula xml:id="formula_6">( | S,⋯,Q ) ∝ ( S,⋯,QuS ⋅ Q ,<label>(7)</label></formula><p>where each experience c = ( c , c , c , c , cRS ) comprises the state, the selected control signal, the reward, the response time, and the next state. For more details, see the SI.</p><p>If the value of control is initially unknown, the optimal way to select control signals is to balance exploiting previous experience to maximize the expected immediate performance with exploring alternative control allocations that might prove even more effective. Our model solves this dilemma by an exploration strategy similar to Thompson sampling: It draws samples from the posterior distribution on the weights and averages them, that is</p><formula xml:id="formula_7">S , ⋯ , V ∼ ( | S,⋯,Q ), = 1 ⋅ c V cjS . (8)</formula><p>According to the LVOC model the brain then selects a control signal by maximizing the EVOC predicted by the average weight , that is Q ≈ arg max l LVOC Q , ; . Together, Equations 6-9 define the LVOC model of the plasticity of cognitive control. The LVOC model extends the EVC theory <ref type="bibr" target="#b6">[7]</ref> which defines optimal control signals in terms of the EVOC (Equation 3), by proposing two mechanisms through which the brain might be able to approximate this normative ideal: learning a feature-based, probabilistic model of the EVOC (Equations 6-7) and selecting control signals by sampling from this model (Equations 8-9). This model is very general and can be applied to model cognitive control of many different processes (e.g., which location to saccade to vs. how strongly to inhibit the word-reading pathway) and different components of the same process (e.g., rate of evidence accumulation towards the correct decision vs. the decision threshold). The LVOC model's core assumptions are that the brain learns to predict the EVOC of alternative control specifications from features of the situation and the control signals, and that the brain then probabilistically selects the control specification with the highest predicted value of control. Both of these components could be implemented by many different mechanisms. For instance, instead of implementing Bayesian regression, the brain might learn to predict the EVOC through the rewardedmodulated associative plasticity mechanism outlined in the SI. We are therefore not committed to the specific instantiation we used for the purpose of the simulations reported below (Equations 7-9).</p><p>The LVOC model instantiates the very general theory that the brain learns how to process information via metacognitive reinforcement learning. This includes not only the plasticity of cognitive control but also how people might discover cognitive strategies for reasoning and decision-making and how they learn to regulate their mental activities during problem solving. As a proof of concept, the following sections validate the LVOC model against five experiments on the plasticity of attention and interference control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative models: Associative learning and Win-Stay Lose-Shift</head><p>In principle, the control-demanding behavior considered in this paper could result from simpler mechanisms than the ones proposed here. In this section, we consider two simple models that we use as alternatives to compare against the more complex LVOC model. The first model relies on the assumption that the plasticity of cognitive control can be understood in terms of associative learning <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. We therefore evaluate our model against an associative learning model based on the Rescorla-Wagner learning rule <ref type="bibr" target="#b41">[41]</ref>. This model forms stimulus-control associations based on the resulting reward. The association },l between a stimulus and a control signal is strengthened when it is accompanied by (intrinsic or extrinsic) reward and weakened otherwise. Concretely, the association strengths involving the chosen response were updated according to the Rescorla-Wagner rule, that is</p><formula xml:id="formula_8">},l = },l + ⋅ − } ⋅ },l } ,<label>(10)</label></formula><p>where is the learning rate, is the reward and the indicator variable } is 1 when the stimulus was present and else. Given the learned associations, the control signal is chosen probabilistically according to the exponentiated Luce's choice rule, that is each control signal is selected with probability</p><formula xml:id="formula_9">= exp ( },l ) exp ( },l ) l . (11)</formula><p>The second alternative model is based on previous research suggesting that people sequentially adjust their strategy through a simple Win-Stay Lose-Shift mechanism <ref type="bibr" target="#b42">[42]</ref>. This mechanism starts with a random strategy on the first trial, and on each subsequent trial it either repeats the previous strategy when it was successful or switches to a different strategy when the current strategy failed. Here, we apply this idea to model how the brain learns which control signal to select. Concretely, our WSLS model repeats the previous control signal (e.g., "Attend to green.") when it leads to a positive outcome (Win-Stay) and randomly selects a different control signal (e.g., "Attend to red.") otherwise (Lose-Shift).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulations of learning and transfer effects in cognitive control paradigms</head><p>To evaluate the proposed models, we used them to simulate the plasticity of attentional control in a visual search task <ref type="bibr" target="#b16">[17]</ref> as well as learning and transfer effects in Stroop and Flanker paradigms <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>. <ref type="table" target="#tab_1">Table 1</ref> summarizes the simulated phenomena and how the LVOC model explains each at a conceptual level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning to control visual attention</head><p>Previous research has shown that how people allocate their attention is shaped by learning <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>. For instance, Lin and colleagues <ref type="bibr" target="#b16">[17]</ref> had participants perform a visual search task in which they gradually learned to allocate their attention to locations whose color predicted the appearance of the target <ref type="figure">(Figure 1a)</ref>. In this task, participants viewed an array of four rotated letters (one T and three L's), each encompassed by a different colored circle. They were instructed to report the orientation of the T. The circles appeared before the letters allowing participants to allocate their attention by saccading to a promising location before the letters appeared. In the training phase, the target always appeared within the green circle, but in the test phase it was equally likely to appear in any of the four circles.</p><p>Visual search entails sequentially allocating cognitive control to different locations based on their visual features. Since attention is can be understood as an instance of cognitive control, this problem is naturally modeled as a meta-level MDP. We therefore applied our LVOC theory to predict the dynamics and consequences of learning which locations to attend to based on their features (the colored circles) in this paradigm. Since the stimuli were presented along a circle, approximating locations people might naturally attend around a clock, we assumed that the control signal ∈ {1,2,3, … ,12} specifies which of 12 locations to attend, the state Q encodes which of the 12 locations were highlighted by a colored circle (see <ref type="figure">Figure 1a</ref>), the circles' colors, the unknown position of the target, and the list of locations that have already been inspected on the current trial. Since, the set of possible control signals is small, our simulation assumes that the brain always finds the control signal that maximizes the predicted EVOC (Equation 9).</p><p>The features ( , ) encode only observable aspects of the state that are relevant to the value of the control signal . Concretely, our simulations assumed that the features encode whether the attended location was highlighted by a colored circle, the color of that circle (one binary indicator variable for each possible color), its position (by one binary indicator variable for each of the four possible locations), and whether or not it has been attended before. To capture people's prior knowledge that attending a location a second time is unlikely to provide new information, we set the prior on the weight of the last feature to −1; this captures the well-known inhibition of return mechanism in visual attention <ref type="bibr" target="#b43">[43]</ref>. For all other features the mean of the prior on the weights was 0. Based on the results reported by <ref type="bibr" target="#b16">[17]</ref>, we modeled reaction times as the sum of a non-decision time of 319ms and a decision-time of 98ms per attended location. Our simulation assumed that people incur a fixed cost ( , = cost c = −1 for all ∈ 1,2,3,4 ) every time they deploy their attention to a location. For simplicity, we assume that in this simple task people always search until they find the target and that when they attend to a location they always recognize the presence/absence of the target and respond accordingly. Hence, the intuition that people should try to find the target with as few saccades as possible follows directly from the objective of maximizing the sum of meta-level rewards. Applied to this visual search task, the LVOC model offers a mechanism for how people learn where to allocate their attention based on environmental cues in order to find the target as quickly as possible.</p><p>Our associative learning model assumed that finding the target yields an intrinsic reward of +1 and no reward or cost otherwise. The responses were saccades to one of the 12 locations. The stimuli S comprised indicator variables for each of the four colors, the absence of a circle, and whether the location had been inspected before, and one feature that was always 1. To capture the inhibition of return, the reward associations with the stimulus-feature indicating that a location had been attended previously were initialized by −1. All other association strengths were initialized as 0 and the learning rate of the Rescorla-Wagner model to the data from <ref type="bibr" target="#b16">[17]</ref> using maximum-likelihood estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning and transfer effects in inhibitory control</head><p>In Stroop and Flanker paradigms, the cognitive control strategy is defined by a single control signal ∈ [0,1] serves to bias processing away from an automatic mechanism. Following the classic model by Cohen and colleagues <ref type="bibr" target="#b44">[44]</ref>, we assume that control signals determine the relative contribution of the automatic versus the controlled process to the drift rate at which evidence is accumulated towards the controlled response <ref type="bibr" target="#b45">[45]</ref>: are the drift rates of the controlled and the automatic process respectively, and = 1 when the trial is congruent or −1 when the trial is incongruent. The drift rates, in turn, affect the response and response time according to a drift-diffusion model <ref type="bibr" target="#b45">[45]</ref>. When the decision variable exceeds the threshold + , then the response agrees with the controlled process (equivalent to the correct response for these tasks). When the decision variable falls below -, the response is incorrect. To capture sources of error outside of the evidence accumulation process (e.g., motor execution errors), our simulation assumes that people accidentally give the opposite of their intended response on a small fraction of trials (˜• •™ &lt;0.05).</p><formula xml:id="formula_10">= ⋅ DYOE•ŽY•••' + 1 − ⋅ ⋅ '"•Y"'••D ,<label>(12)</label></formula><p>We model the selection of continuous control signals as a gradient ascent on the EVOC predicted by Thompson sampling (Equations 8-9). Concretely, continuous control signals are selecting by repeatedly applying the update rule c ← + ⋅ LVOC , ;</p><p>until the change in the Euclidean norm of the control signal intensity vector is less than l . This mechanism starts from the control signal deployed on the previous trial and thereby captures the inertia of control specification and the resulting reconfiguration cost <ref type="bibr" target="#b45">[45]</ref>, consistent with the task-set inertia hypothesis <ref type="bibr" target="#b46">[46]</ref>. Furthermore, it predicts that control intensities are adjusted gradually and continually, thereby allowing control to be exerted while the optimal control signal is still being determined. This feature of our model makes the intuitive prediction that time pressure might reduce the magnitude of control adjustment [cf. <ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b49">49]</ref>.</p><p>We model the cost associated with a continuous control signal as the sum of the control cost required to exert that amount of control (cost( )) and the opportunity cost of executing the controlled process ( ⋅ ), that is cost , = ⋅ + cost , <ref type="bibr" target="#b13">(14)</ref> where is the opportunity cost per unit time <ref type="bibr" target="#b0">1</ref> , is the duration of the controlled process, and cost is the intrinsic cost of exerting the control signal . While the first term captures that goal-directed control processes, such as planning, can take significantly longer than automatic processes, such as habits, the second term captures that due to interference between overlapping pathways the cost of a control signal increases with its intensity <ref type="bibr" target="#b12">[13]</ref> even when control intensity accelerates the decision process <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b50">50]</ref>. Following <ref type="bibr" target="#b45">[45]</ref>, we model the intrinsic cost of control as the implementation cost</p><formula xml:id="formula_12">cost = exp c ⋅ + c ,<label>(15)</label></formula><p>where is the control signal, c specifies how rapidly control cost increases with control intensity, and c determines the lowest possible cost. <ref type="bibr" target="#b1">2</ref> The monotonic increase of control cost with control signal intensity expressed by this equation models that the more intensely you focus on one process, say color-naming, the less you are able to do other valuable things, such as verbal reasoning. This cognitive opportunity cost of control is a consequence of overlap between neural pathways serving different functions <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b52">52]</ref>.</p><p>In all of our simulations, the number of samples drawn from the posterior distribution on the weights was = 2. For simplicity, we modeled control allocation in each trial of the Stroop and Flanker tasks simulated below as an independent, nonsequential, metacognitive control problem. The opportunity cost of time ( in Equation 14) was set to $8/h [cf. 51]. Model parameters were fitted by maximum likelihood estimation using Bayesian optimization <ref type="bibr" target="#b54">[54]</ref>. The drift rates of the controlled and the automatic process (Equation 12) were determined from people's response times on neutral trials. The model's prior precision on the weights was set to assign 95% confidence to the EVOC of a stimulus lying between the equivalent of ±5 cents per second.</p><p>In the color-word Stroop task by Krebs et al. <ref type="bibr" target="#b10">[11]</ref> the participant's task was to name the font color of a series of color words which were either congruent or incongruent with the word itself <ref type="figure" target="#fig_6">(Figure 2a</ref>). For two of the four colors, giving the correct response yielded a monetary reward whereas responses to other two colors were never rewarded. Our simulation of this experiment assumed that people represent each stimulus by a list of binary features that encode the presence of each possible color and each possible word independently but do not encode their combinations. To capture the contribution of the experiment's financial incentives for correct responses, we assumed that the utility ( ) in Equation 2 is the sum of the financial reward and the intrinsic utility of getting it right <ref type="bibr" target="#b55">[55]</ref>, that is correct =  <ref type="figure" target="#fig_6">Figure 2b</ref>-c. To enable a fair comparison, we gave the associative learning model and the Win-Stay Lose-Shift model degrees of freedom similar to those of the LVOC model by adding parameters for the intrinsic reward of being correct, the probability of response error, and the noise of the drift-diffusion process. In addition, the Rescorla-Wagner model was equipped with a learning rate parameter. Each model was fitted using maximumlikelihood estimation using the Bayes adaptive direct search algorithm <ref type="bibr" target="#b56">[56]</ref>.</p><p>In the Flanker task by Braem et al. <ref type="bibr" target="#b9">[10]</ref>, participants were instructed to name the color of a central square (the target) flanked by two other squares (distractors) whose color was either the same as the color of the target (congruent trials) or different from it (incongruent trials) <ref type="figure">(Figure 3a)</ref>. On a random 25% of the trials, responding correctly was rewarded and on the other 75% of the trials it was not. Our simulation assumed that people predict the EVOC from two features that encode the presence of conflict and congruency respectively: The conflict feature was +1 when the flankers and the target differed in color and zero otherwise. Conversely, the value of the congruency feature was +1 when the flankers had the same color as the target and zero else. To capture that people exert more cognitive control when they detect conflict <ref type="bibr" target="#b57">[57]</ref>, the prior mean on these weights was +1 for the interaction between control signal intensity and incongruence and −1 for the interaction between control signal intensity and congruence. Providing our model with these features instantiates our assumption that in the Flanker task perception is easy but response inhibition can be challenging. In other words, our model assumes that errors in the Flanker arise from the failure to translate three correct percepts into one correct response by inhibiting the automatic responses to the other two. Furthermore, the incongruency feature can also be interpreted as a proxy for the resulting response conflict that is widely assumed to drive the within-trial adjustment of control signals in the Flanker task <ref type="bibr" target="#b57">[57]</ref>.</p><p>Our simulation assumed that people only learn on trials with feedback. The effect of control was modelled as inhibiting the interference from the flankers according to</p><formula xml:id="formula_13">= •'Ž©•• + 1 − ⋅ ⋅˜• 'OEª•Ž¥ ,</formula><p>18 where = 1 if the distractors are congruent and = −1 when they are incongruent. The drift rates for accumulating information from the target ( •'Ž©•• ) and the distractors (˜• 'OEª•Ž¥ ) were assumed to be identical. Their value was fit to the response time for color naming on rewarded neutral trials reported in <ref type="bibr" target="#b10">[11]</ref>, and the non-decision time was 300ms. The perceived reward value of the positive feedback was determined by distributing the prize for high performance (EUR 10) over the 168 rewarded trials of the experiment ( = 7.5 US cents per correct response). Braem et al. <ref type="bibr" target="#b9">[10]</ref> found that the effect of reward increased with people's reward sensitivity. To capture individual differences in reward sensitivity, we modelled people's subjective utility by</p><formula xml:id="formula_14">correct = ¬ + •OE•Ž•OE¥•D , 19 wrong = − •OE•Ž•OE¥•D , 20</formula><p>where for ≥ 0 is the payoff and ∈ 0,1 is the reward sensitivity. The reward sensitivity was set to 1, and the intrinsic reward of being correct ( cOE•Ž•OE¥•D ), the standard deviation of the noise ( ), the threshold of the drift-diffusion model ( ), the implementation cost parameters ( c , c ) were fit to the effects of reward on the reaction times on congruent trials <ref type="figure">(Figure 3c</ref>), the average reaction time, and the effect of reward sensitivity on conflict adaptation reported by <ref type="bibr" target="#b9">[10]</ref>. The probability of accidentally giving the opposite of the intended response was set to zero.</p><p>To enable a fair comparison between LVOC model and the two simpler models, we equipped the associative learning model and the Win-Stay Lose-Shift model with the same assumptions and degrees of freedom as the LVOC model. Equivalently to the LVOC model of this task, they included a bias against exerting control was instantiated by an association of -1 between either stimulus feature and control exertion. The effect of control was modeled using the same drift-diffusion model with same set of free parameters, and like the LVOC model they also included a free parameter for the intrinsic reward of being correct and the probability of response error. Furthermore, these models included a free parameter for the cost of exerting control that is equivalent to two parameters of the LVOC model's implementation and reconfiguration cost parameters, because their control signal was either 1 or 0. Furthermore, the Rescorla-Wagner model included an additional parameter for its learning rate, giving it the same number of parameters as the LVOC model. Experiment 2 by Bugg et al. <ref type="bibr" target="#b7">[8]</ref> asked participants to name the color of Stroop stimuli like those used by Krebs et al. <ref type="bibr" target="#b10">[11]</ref>. Critically, some of the color words were printed in color that appeared on congruent trials 80% of the time whereas other color words were printed in a color that appeared on incongruent trials 80% of the time <ref type="figure">(Figure   4a</ref>). Each word was written either in cursive or standard font. We modeled the stimuli by four binary features indicating the presence of each of the four possible words (1 if the feature is present and 0 otherwise), and a fifth feature indicating the font type (0 for regular and 1 for cursive). The non-decision time was set to 400ms. Since there were no external rewards for good performance, the utility of correct/incorrect responses was  <ref type="figure">Figure 4b</ref> and <ref type="figure">Figure 4c</ref>. Given these parameters, the drift rate for color naming and reading where determined to match the reaction times on unrewarded neutral trials reported in <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phenomenon</head><p>Explanation of the LVOC model Lin et al. (2016), Exp. 1</p><p>In the training block, participants learn to find the target increasingly faster when it always appears in a location with a certain color. In the test block, participants are significantly slower on trials that violate this regularity.</p><p>People learn to predict the value of attending to different locations from their color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Krebs et al. (2010), Exp. 1</head><p>People come to name the color of incongruent words faster and more accurately for colors for which performance is rewarded.</p><p>People learn to predict the value of increasing control intensity from the color of the word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Braem et al. (2012), Exp. 1</head><p>On a congruent Flanker trial, people are faster when the previous trial was rewarded and congruent than when it was unrewarded and congruent, but the opposite holds when the previous trial was incongruent. These effects are amplified in people with high reward sensitivity.</p><p>People learn to exert more control on incongruent trials. Thus, rewarded incongruent trials tend to reinforce higher control signals while rewarded congruent trials tend to reinforce low control signals. Thus, people increase control after the former and lower control after the latter. People become faster and more accurate at naming the color of an incongruently colored word when it is usually incongruent than when it is usually congruent.</p><p>People learn that exerting more control is more valuable when the color or word is predictive of incongruence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bugg et al. (2011), Exp. 2</head><p>People are faster at naming animals in novel, incongruently labelled images when that species was mostly incongruently labelled in the training phase than when it was mostly congruently labelled.</p><p>People learn that exerting more control is more valuable when the semantic category of the picture is predictive of incongruence. Finally, Bugg et al. <ref type="bibr" target="#b8">[9]</ref> presented their participants with pictures of animals overlaid by animal names <ref type="figure">Figure 4d</ref>). The participants' task was to name the animal shown in the picture. Critically, for some animals, the picture and the word were usually congruent whereas for other the picture and the word were usually incongruent. The training phase was followed by a test phase that used novel pictures of the same animal species. We modelled this picture-word Stroop by representing each stimulus by a vector of binary indicator variables. Concretely, our representation assumed one binary indicator variable for each word (i.e., BIRD, DOG, CAT, FISH) and one indicator variable for each image category (i.e., bird, dog, cat, fish). The non-decision time was set to 400ms.  <ref type="figure">Figure 4e</ref>-f. Given these parameters, the drift rate for word reading was fit as above and the drift rate for picture naming was fit to a response time of 750ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We found that our model correctly predicted the learning effects observed in five different cognitive control experiments by virtue of its fundamental assumption that people reinforcement-learn to predict the value of potential control signals and control signal intensities from situational features (see <ref type="table" target="#tab_1">Table 1</ref>). The following sections describe these findings in detail.  Plasticity of attentional control in visual search Lin et al. <ref type="bibr" target="#b16">[17]</ref> had participants perform a visual search task for which the target of attention could either be predicted (training and predictable test trials) or not (unpredictable test trials) <ref type="figure">(Figure 1a)</ref>. For this task, given its core reinforcement learning assumption <ref type="table" target="#tab_1">(Table 1</ref>), the LVOC model predicts that 1) people should learn to attend to the circle with the predictive color and thus become faster at finding the target over the course of training, 2) continue to use the learned attentional control strategy in the test block and hence be significantly slower when the target appears in a circle of a different color during the test block, and 3) gradually unlearn their attentional bias during the test block <ref type="figure">(Figure 1c</ref>). As shown <ref type="figure">Figure 1b</ref>, all three predictions were confirmed by Lin and colleagues <ref type="bibr" target="#b16">[17]</ref>.</p><p>We compared the performance of LVOC to two plausible alternative models of these control adjustments: a Win-Stay Lose-Shift model and a simple associative learning model based on the Rescorla-Wagner learning rule. We found that the Win-Stay Lose-Shift model failed to capture that people's performance improved gradually during training, and it also failed to capture the difference between people's response times to predicted versus unpredicted target locations in the test block (see <ref type="figure">Figure 1d</ref>). As <ref type="figure">Figure   1e</ref> shows, the fit of the associative learning model (estimated learning rate: 0.0927) captures that after learning to exploit the predictive regularity in the training block participants were significantly slower in the test block. However, this simple model predicted significantly less learning induced improvement and significantly slower reaction times than was evident from the data by <ref type="bibr" target="#b16">[17]</ref>. A quantitative model comparisons using the Bayesian Information Criterion <ref type="bibr" target="#b58">[58,</ref><ref type="bibr" target="#b59">59]</ref> provided very strong evidence that the LVOC model explains the data by <ref type="bibr" target="#b16">[17]</ref> better than the Rescorla-Wagner model or the Win-Stay Lose-Shift model (BIC ±²³´= 1817.8, BIC µ ¶ = 9763.2, BIC ¶•±• = 3449.9). This reflects that our model was able to accurately predict the data from <ref type="bibr" target="#b16">[17]</ref> without any free parameters being fitted to those data. In conclusion, findings suggest that the LVOC model correctly predicted essential learning effects observed by <ref type="bibr" target="#b16">[17]</ref> and explains these data significantly better than a simple associative learning model and a Win-Stay Lose-Shift model.</p><p>To more accurately capture both the slow improvement in the training block and the rapid unlearning in the test block simultaneously, the LVOC model could be extended by including a mechanism that discounts what has been learned or increases the learning rate when a change is detected <ref type="bibr" target="#b60">[60,</ref><ref type="bibr" target="#b61">61]</ref>. Next, we evaluate the LVOC model against empirical data on the plasticity of inhibitory control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Plasticity of Inhibitory Control</head><p>We found that our model can capture reward-driven learning effects in Stroop and Flanker tasks, as well as how people learn to adjust their control allocation based on features that predict incongruence and the transfer of these learning effects to novel stimuli. In each case, the LVOC model captured the empirical phenomenon more accurately than either a simple Win-Stay Lose-Shift model or a simple associative learning model. The following two sections present these results in turn. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reward-driven plasticity in interference control</head><p>People learn to allocate more control on rewarded trials To determine whether our integrated theory captures the reward-modulated plasticity of cognitive control specification, we used the LVOC model to simulate two sets of experiments that examined the influences of reward on cognitive control. Krebs et al. <ref type="bibr" target="#b10">[11]</ref> found that participants in a color-word Stroop task learned to respond faster and more accurately to incongruently colored color words when their color predicted that performance would be rewarded than when it predicted that performance would not be rewarded. We found that our model can capture these effects with reasonable parameter values (see <ref type="table" target="#tab_4">Table 2</ref>). <ref type="figure" target="#fig_6">Figure 2</ref> shows that our model captures Krebs et al.'s finding that people learn to exert more control on trials with rewarded colors than on trials with unrewarded colors even though they were interspersed within the same block. Concretely, our model captured that people become faster (541 ± 7ms ms vs. 691 ± 8ms; (959998) = −14.6, &lt; 10 uS¹ ) and more accurate (4.9 ± 0.02% errors vs. 11.8 ± 0.03% errors; 959998 = −164.7, &lt; 10 uS¹ ) when the color of the word is associated with reward. Critically, the qualitative effects observed in this experiment follow logically from the core assumption of the LVOC model (see <ref type="table" target="#tab_1">Table 1</ref>).</p><p>We compared the LVOC's model performance to that of an associative learning model with equivalent parameters (see Methods); the maximum likelihood estimates of these parameters were = 0.0447 for the learning rate, •OE•Ž•OE¥•D = 0.1811 for the intrinsic reward, º = 0.1525 for the noise of the drift-diffusion process, and •ŽŽYŽ = 0.1799. While the Rescorla-Wagner model was able to qualitatively capture the effect of potential reward on reaction time and error rate, its quantitative fit was far worse than the fit of the LVOC model (see <ref type="figure" target="#fig_6">Figure 2b</ref> and <ref type="figure" target="#fig_6">Figure 2c)</ref>; thus, a quantitative model comparison controlling for the number of parameters provided very strong evidence for the LVOC model over the <ref type="bibr">Rescorla-Wagner</ref>  1333.9). We also fitted the Win-Stay Lose-Shift model and its parameter estimates were</p><p>•OE•Ž•OE¥•D = for the intrinsic reward, º = for the noise of the drift-diffusion process, and •ŽŽYŽ = 0.07). We found that the WSLS model was unable to capture the effect of reward on response times and error rates (see <ref type="figure" target="#fig_6">Figure 2b</ref> and <ref type="figure" target="#fig_6">Figure 2c)</ref>  Reward accelerates trial-by-trial learning of how to allocate control Braem et al. <ref type="bibr" target="#b9">[10]</ref> found that participants in their Flanker task allocated more cognitive control after rewarded incongruent trials than after rewarded congruent trials or unrewarded trials. As <ref type="figure">Figure 3b</ref> shows, the LVOC model can capture this reward-induced conflict-adaptation effect with a plausible set of parameters (see <ref type="table" target="#tab_4">Table 2</ref>). Our model correctly predicted that people's responses on congruent trials are faster when they are preceded by rewarded congruent trials than when they are preceded by rewarded incongruent trials. The predicted difference (7 ms) was smaller than the empirically observed difference (27 ms) but it was statistically significant ( 99 = 37.99, &lt; 10 uS¹ ). According to our model, people learn to exert more control on incongruent trials than on congruent trials. Furthermore, being rewarded for exerting a low level of control reduces the control intensity on the subsequent trial, whereas being rewarded for exerting a high level of control increases the control intensity on the subsequent trial. Thus, our model predicts that control intensity should increase after rewarded incongruent trials but decrease after rewarded congruent trials. On congruent trials, more control leads to slower responses because it inhibits the facilitating signal from the flankers (Equation 18). This suggests that our model's metacognitive reinforcement learning mechanism correctly predicts the findings of Braem et al. <ref type="bibr" target="#b9">[10]</ref> (see <ref type="figure">Figure 3</ref> and <ref type="table" target="#tab_1">Table 1</ref>).</p><p>The LVOC model's learning increases with the magnitude of the reward. Consequently, the LVOC model predicts that the effect shown in <ref type="figure">Figure 3b</ref> should increase with people's reward sensitivity. Concretely, as we increased the reward sensitivity parameter from 0 to 1, the predicted reward-driven effect of conflict monotonically increased from 0.6ms to 8.0ms ( (102) = 4.77, &lt; 0.0001). Consistent with this prediction, Braem and colleagues <ref type="bibr" target="#b9">[10]</ref> found that the magnitude of rewarddriven conflict adaptation effect increased with people's reward sensitivity, suggesting that the reward experienced for exerting cognitive control was the driving force of their adjustments. The significant positive correlation between people's reward sensitivity and the magnitude of their conflict adaptation effect reported by <ref type="bibr" target="#b9">[10]</ref> confirms our model's prediction. Our model captures all of these effects because it learns to predict the expected rewards and costs of exerting control from features of the situation and probabilistically chooses the control signal that achieves the best cost-benefit tradeoff.</p><p>We compared the LVOC's fit to these behaviors with the associative learning and Win-Stay Lose-Shift models. Even though the associative learning model had the same number of parameters as the LVOC model, its fit was substantially worse than the fit of the LVOC model (mean squared errors: MSE µ ¶ = 3.33 vs. MSE ±²³´= 1.35), and its best fit <ref type="figure">(Figure 3d</ref>) failed to capture the qualitative effect shown in <ref type="figure">Figure 3c</ref>. Finally, we evaluated a Win-Stay Lose-Shift model. This model was equipped with the same set of parameters as our Rescorla-Wagner model except for the learning rate parameter. We found that the Win-Stay Lose-Shift model was unable to capture the data by Braem et al. <ref type="figure">Figure 3e</ref>) because it stays with the controlled process forever once it has been rewarded for using it (MSE ¶  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transfer of learning effects in interference control</head><p>The expected value of computation depends not only on the rewards for correct performance but also on the difficulty of the task. In easy situations, such as the congruent trials of the Stroop task, the automatic response can be as accurate, faster, and less costly than the controlled response. In cases like this, the expected value of exerting control is less than the EVOC of exerting no control. By contrast, in more challenging situations, such as incongruent Stroop trials, the controlled process is more accurate and therefore has a positive EVOC as long as accurate performance is sufficiently important. Therefore, on incongruent trials the expected value of control is larger than the EVOC of exerting no control. Our model thus learns to exert control on incongruent trials but not on congruent trials. Our model achieves this by learning to predict the EVOC from features of the stimuli. This predicts that people should learn to exert more control when they encounter a stimulus feature (such as a color or word) that is predictive of incongruence than when they encounter a feature that is predictive of congruence (see <ref type="table" target="#tab_1">Table 1</ref>). Consistent with our model's predictions, Bugg and colleagues <ref type="bibr" target="#b7">[8]</ref> found that people learn to exert more control in response to stimulus features that predict incongruence than stimulus features that predict congruence. Their participants performed a color-word Stroop task with four colors and their names printed either in cursive or regular font. Our model captured the effects of congruency-predictive features on control allocation with a plausible set of parameters (see <ref type="table" target="#tab_4">Table 2</ref>). As shown in <ref type="figure">Figure   4a</ref>-b, the LVOC model predicted that responses should be faster (655 ± 9 ms vs. 722 ± 11 ms; 49 = 5.39, &lt; 0.0001) and more accurate (2.85 ± 0.2% errors vs. 4.3 ± 0.3% errors; 49 = 5.01, &lt; 0.0001) on incongruent trials if the word was predictive of incongruence than when it was not. To their surprise, Bugg and colleagues observed that adding an additional feature (font) that conveyed the same information about congruence as the color, did not enhance learning. This is exactly what our model predicted because the presence of a second predictive feature reduces the evidence for the predictive power of the first one and vice versa -this is directly analogous to a phenomenon from the Pavlovian literature known as blocking, whereby an animal fails to learn an association between a stimulus and an outcome that is already perfectly predicted by a second stimulus <ref type="bibr" target="#b62">[62]</ref>.</p><p>Since our model learns about the predictive relationship between features and the EVOC, it predicts that all learning effects should transfer to novel stimuli that share the features that were predictive of the expected value of control in the training trials (see <ref type="table" target="#tab_1">Table 1</ref>). A separate study by Bugg and colleagues <ref type="bibr" target="#b8">[9]</ref> confirmed this prediction. They trained participants in a picture-word Stroop task to associate particular images of certain categories (e.g., cats and dogs) with incongruence and associated particular images of other categories (e.g., fish and birds) with congruence. As expected, participants learned to exert more control when viewing the stimuli associated with incongruence. More importantly, these participants also exerted more control when tested on novel instances of the category associated with incongruence (e.g., cats) than on novel instances of the category associated with congruence (e.g., fish). This finding provides strong evidence for the feature-based learning mechanism that is at the core of our model of the plasticity of cognitive control and is entirely accounted for by our model. As shown in <ref type="figure">Figure 4e</ref> and <ref type="figure">Figure 4f</ref>, our model correctly predicted the positive and the negative transfer effects reported by <ref type="bibr" target="#b8">[9]</ref> with reasonable parameters (see <ref type="table" target="#tab_4">Table 2</ref>): The model's responses were faster (685 ± 2 ms vs. 709 ± 3 ms; 99 = −8.13, &lt; 0.0001) and more accurate (3.2 ± 0.1% errors vs. 4.8 ± 0.3% errors; 99 = −5.06, &lt; 0.0001) on incongruent trials if the word was predictive of incongruence than when it was not (positive transfer). Conversely, on congruent trials, the predicted responses were slightly slower when the features wrongly predicted incongruence (530 ± 0.1ms vs. 527 ± 0.2ms, 99 = 9.28, &lt; 0.0001; negative transfer).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Building on previous work modeling the specification of cognitive control in terms of meta-decision making <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b63">63,</ref><ref type="bibr" target="#b64">64]</ref> and reinforcement learning <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b65">[65]</ref><ref type="bibr" target="#b66">[66]</ref><ref type="bibr" target="#b67">[67]</ref>, we have illustrated that at least some of the functions of cognitive control can be characterized using the formal framework of rational metareasoning <ref type="bibr" target="#b24">[25]</ref> and meta-level Markov decision processes <ref type="bibr" target="#b25">[26]</ref>. Concretely, modeling the function of cognitive control as a meta-level MDP allowed us to derive the first formal computational model of how people learn to specify continuous control signals and how these learning effects transfer to novel situations. This model provides a unifying explanation for how people learn where to attend, the interacting effects of reward and incongruence on interference control, and their transfer to novel stimuli.</p><p>Our simulations of learning in Stroop and Flanker paradigms illustrate that the LVOC model can account for people's ability to learn when and how intensely to engage controlled processing and inhibit automatic processing. We further found that the LVOC model correctly predicted the learning curve in the visual attention experiment by Lin et al. <ref type="bibr" target="#b16">[17]</ref> without any free parameters. Critically, all of our model's qualitative predictions follow directly from our theory's core assumption that people reinforcement-learn to predict the value of alternative control signals and control signal intensities from stimulus features (see <ref type="table" target="#tab_1">Table 1</ref>). None of our model's auxiliary assumptions about the cost of control, the reward of being correct, the drift-diffusion model, the details of learning and control signal selection, and the corresponding parameters summarized in <ref type="table" target="#tab_4">Table 2</ref> are necessary to derive these qualitative predictions; instead they only serve to increase the quantitative accuracy of those predictions.</p><p>While the LVOC model is more complex than basic associative learning and the Win-Stay Lose-Shift mechanism, neither of these simpler models was able to capture human learning in the simulated visual search, Stroop, and Flanker paradigms. This suggests that the complexity of the LVOC model may be currently warranted to capture how people learn when to exert how much cognitive control. Furthermore, the LVOC model's sophistication may be necessary to explain more complex phenomena such as how people learn to orchestrate their thoughts to solve complex problems and acquire sophisticated cognitive strategies. Recent work has indeed shown that the learning mechanism instantiated by the LVOC model can also capture aspects of how people learn how to plan <ref type="bibr" target="#b68">[68]</ref> and to flexibly and adaptively choose between alternative cognitive strategies <ref type="bibr" target="#b53">[53]</ref>. Testing whether people learn to select sequences of control signals in the way predicted by our model is an interesting direction for future research.</p><p>The LVOC model integrates control specification and strategy selection learning The model developed in this article builds on two previous theories: the EVC theory, which offered a normative account of control specification <ref type="bibr" target="#b6">[7]</ref>, and the rational metareasoning theory of strategy selection <ref type="bibr" target="#b53">[53]</ref>, which suggested that people acquire the capacity to select heuristics adaptively by learning a predictive model of the execution time and accuracy of those heuristics. The LVOC model synergistically integrates these two theories: it augments the EVC theory with the metacognitive learning and prediction mechanisms identified by <ref type="bibr" target="#b53">[53]</ref>, and it augments rational metareasoning models of strategy selection with the capacity to specify continuous control signals that gradually adjust parameters of the controlled process (see SI, Section 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical predictions</head><p>All else being equal, the proposed learning rules (see Equation 7 and SI Equations 1-7, <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> predict that people's propensity to exert cognitive control should increase when the controlled process was less costly (e.g., faster) or generated more reward than expected <ref type="bibr" target="#b17">[18]</ref>. The experience that less controlled (more automatic) processing was more costly or less rewarding than expected should also increase our propensity to exert cognitive control <ref type="bibr" target="#b69">[69]</ref><ref type="bibr" target="#b70">[70]</ref><ref type="bibr" target="#b71">[71]</ref>. Conversely, if a controlled process performed worse than expected or if an automatic process performed better than expected, people's propensity to exert cognitive control should decrease <ref type="bibr" target="#b72">[72]</ref>.</p><p>At a more detailed level, our theory predicts that the influence of environmental features on control allocation generalizes across contexts, to the extent that their features are similar. Thus, adding or removing features to the internal predictive model of the EVOC should have a profound effect on the degree to which observed performance of the controlled process in Context A changes people's propensity to select it in Context B, and vice versa. This mechanism can account for empirical evidence that suggests a role for feature-binding in mechanisms of task switching <ref type="bibr" target="#b73">[73]</ref><ref type="bibr" target="#b74">[74]</ref><ref type="bibr" target="#b75">[75]</ref><ref type="bibr" target="#b76">[76]</ref> . These studies suggest that participants associate the task that they perform on a stimulus with the features of that stimulus. Once they are asked to engage in a new task on that stimulus, the old (associated) task interferes, leading to switch costs.</p><p>Furthermore, our theory predicts that increasing the rewards and punishments for the outcomes of the controlled or automatic processes should increase the speed at which people's control allocation adapts to new task requirements, because the resulting weight updates will be larger; this becomes especially apparent when the updates are rewritten in terms of prediction errors (see <ref type="figure">Supplementary Information, Equations 13-14)</ref>. Finally, when the assumptions of the internal model are met and its features distinguish between the situations in which each controlled process performs best, then control signal selection should become increasingly more adaptive over time <ref type="bibr" target="#b77">[77,</ref><ref type="bibr" target="#b78">78]</ref>. But in situations where the internal model's assumptions are violated, for instance because the value of control is not additive and linear in the features, then the control system's plasticity mechanisms may become maladaptive.</p><p>This prediction has been confirmed in a recent experiment with a novel colorword Stroop paradigm comprising two association phases and a test phase <ref type="bibr" target="#b79">[79]</ref>. In the first association phase, participants learned that color naming was rewarded for certain colors whereas word reading was rewarded for the other colors. In the second association phase, participants learned that color-naming was rewarded for certain words whereas word-reading was rewarded for other words. Critically, in the test phase, naming the color was rewarded if either the word or the color had been associated with color naming (SINGLE trials); but when both the color and the word were associated with color naming then participants had to instead read the word (BOTH trials). This non-linear relationship between stimulus-features and control demands caused mal-transfer from SINGLE trials to BOTH trials that significantly interfered with participants' performance (resulting in participants incorrectly engaging in color-naming, the more controldemanding task which in that context was also less rewarding). The LVOC model may thus be able to explain the puzzling phenomenon that people sometimes overexert cognitive control even when it hurts their performance, such as when upon seeing a nonurgent email on a topic you have learned to be careful about you cannot help but compose the perfect response in your mind while trying to finish the talk you have to give in 5 minutes.</p><p>According to the LVOC model, control allocation is a process of continuing gradual adjustment (Equation 13). This means that the control intensity for a new situation starts out with the control intensity from the previous situation and is then gradually adjusted towards its optimal value (Equation 13)-just like in anchoring-andadjustment <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b80">80]</ref>. This might provide a mechanism for commonly observed phenomena associated with task set inertia and switch costs <ref type="bibr" target="#b46">[46]</ref>. Since control adjustment takes time, this mechanism predicts that increased time pressure could potentially lead to decreased control adjustment, thereby biasing people's control allocation to its value on the previous trial and thus decreasing their cognitive flexibility. Finally, thinking about the neural implementation of the LVOC model leads to additional neural predictions as detailed in the Supplementary Information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Avenues for future research</head><p>We view rational metareasoning as a general theoretical framework for modeling the allocation and plasticity of cognitive control. As such, it could be used to develop unifying models of different manifestations of cognitive control, such as attention, response inhibition, and cognitive flexibility. Furthermore, rational metareasoning can also be used to connect existing models of cognitive control <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b63">63,</ref><ref type="bibr" target="#b64">64,</ref><ref type="bibr" target="#b77">77,</ref><ref type="bibr" target="#b78">78,</ref><ref type="bibr" target="#b81">81,</ref><ref type="bibr" target="#b82">82]</ref>. Interpreting previously proposed mechanisms of control allocation as approximations to rational metareasoning and considering how else rational metareasoning could be approximated might facilitate the systematic evaluation of alternative representations and computational mechanisms and inspire new models. While our computational explorations have focused on which control signal the cognitive control system should select, future work might also shed light on how the cognitive control system monitors the state of the controlled system by viewing the problem solved by the cognitive control system as a partially observable MDP. Concretely, the function of cognitive monitoring could be formulated as a meta-level MDP whose computational actions include sensing operations that update the cognitive control system's beliefs about the state of the monitored system.</p><p>Future work should further evaluate the proposed computational mechanism and its neural implementation by performing quantitative model comparisons against simpler models across a wider range of cognitive control phenomena. We will investigate the performance of the proposed metacognitive learning mechanism and evaluate it against alternative mechanisms (e.g., temporal difference learning mechanisms with eligibility traces <ref type="bibr" target="#b29">[29]</ref>).</p><p>Another interesting direction will be to use the learning models to investigate the plasticity of people's cognitive control skills. We are optimistic that this line of work will lead to better quantitative models of control plasticity that can be used to develop interventions to improve people's executive functions via a combination of cognitive training and augmenting environments where people's automatic responses are maladaptive with cues that prime them to employ an appropriate control signal. In addition, future work may also explore model-based metacognitive reinforcement learning <ref type="bibr" target="#b83">[83]</ref> as a model of the plasticity of cognitive control specification. Model-based hierarchical reinforcement learning approaches <ref type="bibr" target="#b36">[36]</ref>, such as option models <ref type="bibr" target="#b37">[37]</ref>, could be used to integrate the learning mechanisms for the value of individual control signals with the strategy selection model to provide an account of how the brain discovers control strategies. This might explain how people learn to adaptively coordinate their thoughts and actions to pursue increasingly more challenging goals over increasingly longer periods of time.</p><p>Finally, the rational metareasoning framework can also be used to model how people reason about the costs and benefits of exerting mental effort and to delineate selfcontrol failure from rational resource-preservation through a normative account of effort avoidance <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b84">84]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Our simulation results suggested that the LVOC model provides a promising step towards a mathematical theory of cognitive plasticity that can serve as a scientific foundation for designing cognitive training programs for improving people's executive functions. This illustrates the utility of formalizing the function of cognitive control in terms of rational metareasoning. Rational metareasoning provides a unifying framework for modeling executive functions, and thus opens up exciting avenues for future research. We are optimistic that the connection between executive functions and metareasoning will channel a flow of useful models and productive ideas from artificial intelligence and machine learning into the neuroscience and psychology of cognitive control.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>•¤••ŽOE'• + •OE•Ž•OE¥•D , 16 wrong = − •¤••ŽOE'• + •OE•Ž•OE¥•D , 17 where the monetary reward •¤••ŽOE'• was 10 cents on rewarded trials and zero otherwise. The non-decision time was set to 300ms. The implementation cost parameters ( c and c in Equation 15), the probability of accidental response flips (˜• •™ ), the intrinsic reward •OE•Ž•OE¥•D of responding correctly (Equations 16-17), and the noise parameter of the drift diffusion model (Equation 12) were fit to the empirical data shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>± •OE•Ž•OE¥•D . The implementation cost parameters ( c and c ), the probability of accidental response flips (˜• •™ ), the intrinsic reward of being correct ( •OE•Ž•OE¥•D ), and the standard deviation of the noise ( ) were fit to the empirical data shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>The implementation cost parameters ( c and c ), the intrinsic reward of being correct ( •OE•Ž•OE¥•D ), the standard deviation of the noise ( ), and the probability ofresponse flips (˜• •™ ) were fit to the empirical data shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>a) Visual search task of Lin et al. (2016) Figure 1: Learning to control the allocation of attention. a) Visual search task used by Lin et al. (2016). b) Predictions of the LVOC model. c) Human data from Experiment 1 of Lin et al. (2016). d) Fit of Win-Stay Lose-Shift model. e) Fit of Rescorla-Wagner model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>LVOC model captures that in the paradigm by Krebs et al. (a) people learn to exert more cognitive control on stimuli whose features predict that performance will be rewarded which manifests in faster responses (b) and fewer errors (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>•±• = 19.4). Taken together with the previous results, this suggests that the simple mechanisms assumed by the associative learning model and the Win-Stay Lose-Shift model are insufficient to explain the complexity of cognitive control plasticity, but the LVOC model can capture it. Metacognitive reinforcement learning captures the effect of reward on learning from experienced conflict observed by Braem et al. (2012). a) Illustration of the Flanker task by Braem et al. (2012). b) Fit of LVOC model. c) Human data by Braem et al. (2012). d) Fit of Rescorla-Wagner model. e) Fit of Win-Stay Lose-Shift model. The LVOC model captures that people learn to adjust their control intensity based on features that predict incongruence. a) Color-Word Stroop paradigm by Bugg et al. (2008). b-c) LVOC model captures that people learn to exploit features that predict incongruency to respond faster and more accurately on incongruent trial. d) Picture-Word Stroop paradigm by Bugg, Jacoby, and Chanani (2011). e-f) The LVOC model captures that the learning effects enabling people to respond more quickly and more accurately to incongruently labelled images of animals whose labels are usually incongruent transfer to novel images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>where DYOE•ŽY•••' and '"•Y"'••D</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The core assumption of the LVOC model explains the learning effects observed in five different cognitive control experiments.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>model (BIC ±²³´= 45.3 vs. BIC µ ¶ =</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Simulation of Exp. 1 by Krebs et al. (2010)</cell><cell>0.35</cell><cell cols="2">Simulation of Exp. 1 by Krebs et al. (2010)</cell></row><row><cell></cell><cell>650</cell><cell>People LVC Rescorla-Wagner</cell><cell></cell><cell>0.3</cell><cell>People LVC Rescorla-Wagner</cell></row><row><cell>Reaction Time (ms)</cell><cell>500 550 600</cell><cell>Win-Stay Lose-Shift</cell><cell>Error Rate (ms)</cell><cell>0.1 0.15 0.2 0.25</cell><cell>Win-Stay Lose-Shift</cell></row><row><cell></cell><cell>450</cell><cell></cell><cell></cell><cell>0.05</cell><cell></cell></row><row><cell></cell><cell>400</cell><cell>potential reward</cell><cell>no reward</cell><cell>0</cell><cell>potential reward</cell><cell>no reward</cell></row><row><cell></cell><cell></cell><cell>Trial Type</cell><cell></cell><cell></cell><cell>Trial Type</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>because its control signals are uninformed by the stimulus presented on the current trial. Consequently, a formal model comparison provided strong evidence for the LVOC model over the Win-Stay Lose-Shift model (BIC ±²³´= 45.3 vs. BIC ¶•±• = 2454.8).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Model parameters used in the simulations of empirical findings.</figDesc><table><row><cell></cell><cell>c</cell><cell>c</cell><cell></cell><cell></cell><cell>•OE•Ž•OE¥•D</cell><cell>˜••™</cell></row><row><cell>Krebs, et al. (2010)</cell><cell>1.60</cell><cell>−0.01</cell><cell>3</cell><cell>0.05</cell><cell>1.60¢</cell><cell>3.5%</cell></row><row><cell>Braem et al. (2012)</cell><cell>4.17</cell><cell>−2</cell><cell>2.75</cell><cell>5</cell><cell>4.17¢</cell><cell>0.8%</cell></row><row><cell>Bugg et al. (2008)</cell><cell>1.95</cell><cell>−2.1</cell><cell>2.65</cell><cell>3.01</cell><cell>3.89¢</cell><cell>0.4%</cell></row><row><cell>Bugg et al. (2011)</cell><cell>5</cell><cell>−2</cell><cell>2.75</cell><cell>3</cell><cell cols="2">18.00¢ 0.8%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In many real-world scenarios and some experiments, the opportunity cost is time-varying. This can be incorporated into our model by adding a learning mechanism that estimates from experience<ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b85">85]</ref>.<ref type="bibr" target="#b1">2</ref> This framework can easily be extended to also other sources of control costs, such as reconfiguration costs<ref type="bibr" target="#b45">[45]</ref>.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Visualization: FL, SM Writing -Original Draft Preparation: FL, AS, SM Writing -Review &amp; Editing: FL, AS, TLG, SM</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests statement:</head><p>The authors declare no competing interests.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Executive Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diamond</surname></persName>
		</author>
		<idno type="DOI">:10.1146/annurev-psych-113011-143750</idno>
	</analytic>
	<monogr>
		<title level="j">Annu Rev Psychol</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="135" to="168" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Studies of interference in serial verbal reactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Stroop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol. Psychological Review Company</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">643</biblScope>
			<date type="published" when="1935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">High self-control predicts good adjustment, less pathology, better grades, and interpersonal success</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Tangney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Baumeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Boone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Pers. Wiley Online Library</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="271" to="324" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A gradient of childhood self-control predicts health, wealth, and public safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Moffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Arseneault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Hancox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Harrington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci. National Acad Sciences</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="2693" to="2698" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The intrinsic cost of cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X1300109X</idno>
	</analytic>
	<monogr>
		<title level="j">Behav Brain Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="697" to="705" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A labor/leisure tradeoff in cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0031048</idno>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Gen</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="131" to="141" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Expected Value of Control: An Integrative Theory of Anterior Cingulate Cortex Function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">:10.1016/j.neuron.2013.07.007</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron. Cell Press</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="217" to="240" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiple levels of control in the Stroop task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bugg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Jacoby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Toth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mem \&amp; Cogn. Springer</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1484" to="1494" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Why it is too early to lose control in accounts of item-specific proportion congruency effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bugg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Jacoby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chanani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Hum Percept Perform. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">844</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reward modulates adaptations to conflict</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Braem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Verguts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Roggeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Notebaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="324" to="332" />
			<date type="published" when="2012" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The influence of reward associations on conflict processing in the Stroop task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Krebs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Boehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Woldorff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="341" to="347" />
			<date type="published" when="2010" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Cognitive Control as Cost-Benefit Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Wiley Handb Cogn Control. John Wiley \&amp; Sons</publisher>
			<biblScope unit="page" from="167" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Toward a rational and mechanistic account of mental effort</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musslick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu Rev Neurosci</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deciding How To Decide: Self-Control and Meta-Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sokol-Hessner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2015.08.013</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grounding cognitive control in associative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Abrahamse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Braem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Notebaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Verguts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Bull. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page">693</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Creatures of habit (and control): a multi-level learning perspective on the modulation of congruency effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Egner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front Psychol. Frontiers Media SA</title>
		<imprint>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Decomposing experience-driven attention: Opposite attentional effects of previously predictive cues. Attention, Perception, \&amp; Psychophys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z-L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="2185" to="2198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Video game training enhances cognitive control in older adults</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Anguera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boccanfuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Rintoul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Al-Hashimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Faraji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Janowich</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature12486</idno>
	</analytic>
	<monogr>
		<title level="j">Nature. Nature Publishing Group</title>
		<imprint>
			<biblScope unit="volume">501</biblScope>
			<biblScope unit="page" from="97" to="101" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">How useful is executive control training? Age differences in near and far transfer of task-switching training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev Sci. Wiley Online Library</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="978" to="990" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow? Some field experiments to reduce crime and dropout in Chicago</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Pollack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Is working memory training effective? A metaanalytic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Melby-Lervåg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hulme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev Psychol. US: American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page">270</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Is working memory training effective?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shipstead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Redick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Engle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Bull. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">628</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Functional integration and inference in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0301-0082(02)00076-X</idno>
	</analytic>
	<monogr>
		<title level="j">Prog Neurobiol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="113" to="143" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Putting brain training to the test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hampshire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Grahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stenton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature. Nature Research</title>
		<imprint>
			<biblScope unit="volume">465</biblScope>
			<biblScope unit="page" from="775" to="778" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Principles of metareasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wefald</surname></persName>
		</author>
		<idno type="DOI">:10.1016/0004-3702(91)90015-c</idno>
	</analytic>
	<monogr>
		<title level="j">Artif Intell</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="361" to="395" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Selecting Computations: Theory and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tolpin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence: Proceedings of the Twenty-Eighth Conference</title>
		<editor>de Freitas N, Murphy K</editor>
		<imprint>
			<biblScope unit="volume">866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Oregon 97339 USA OR -Uncertainty in Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corvallis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>AUAI Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An integrative theory of prefrontal cortex function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.neuro.24.1.167</idno>
	</analytic>
	<monogr>
		<title level="j">Annu Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="167" to="202" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Computational rationality: A converging paradigm for intelligence in brains, minds, and machines. Science (80-)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advancement of Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="page" from="273" to="278" />
			<date type="published" when="2015" />
			<publisher>American Association for</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Planning and acting in partially observable stochastic domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Cassandra</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0004-3702(98)00023-X</idno>
		<ptr target="https://doi.org/10.1016/S0004-3702(98)00023-X" />
	</analytic>
	<monogr>
		<title level="j">Artif Intell</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="99" to="134" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention as a decision in information space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gottlieb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Balan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2010.03.001</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="240" to="248" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">How to set the switches on this thing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2012.05.011</idno>
	</analytic>
	<monogr>
		<title level="j">Curr Opin Neurobiol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1068" to="1074" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 21</title>
		<editor>Koller D, Schuurmans D, Bengio Y, Bottou L</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1689" to="1696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Motivation of extended behaviors by anterior cingulate cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Holroyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="122" to="128" />
			<date type="published" when="2012" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hierarchical control over effortful behavior by rodent medial frontal cortex: A computational model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Holroyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcclure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page">54</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Model-based hierarchical reinforcement learning and human action control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos Trans R Soc B Biol Sci. The Royal Society</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0004-3702(99)00052-1</idno>
	</analytic>
	<monogr>
		<title level="j">Artif Intell</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="181" to="211" />
			<date type="published" when="1999" />
			<publisher>Elsevier Science Publishers Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Q-Learning</surname></persName>
		</author>
		<idno type="DOI">10.1007/bf00992698</idno>
	</analytic>
	<monogr>
		<title level="j">Mach Learn. Kluwer Academic Publishers</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The Bayesian Linear model with Unknown Variance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kunz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bayes Estimates for the Linear Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D V</forename><surname>Lindley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afm</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">:10.2307/2985048</idno>
	</analytic>
	<monogr>
		<title level="j">J R Stat Soc Ser B. Blackwell Publishing for the Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rescorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Class Cond II Curr Res theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="64" to="99" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The selection of strategies in cue learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Restle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">329</biblScope>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Inhibition of return</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci. Elsevier</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="138" to="147" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On the control of automatic processes: a parallel distributed processing account of the Stroop effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dunbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page">332</biblScope>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A computational model of control allocation based on the Expected Value of Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musslick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2nd Multidisciplinary Conference on Reinforcement Learning and Decision Making</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Shifting intentional set: Exploring the dynamic control of tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Allport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Styles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hsieh</surname></persName>
		</author>
		<editor>Umilta C, Moscovitch M</editor>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="421" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Empirical Evidence for Resource-Rational Anchoring and Adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qjm</forename><surname>Huys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon Bull \&amp; Rev</title>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The anchoring bias reflects rational use of cognitive resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qjm</forename><surname>Huys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon Bull \&amp; Rev</title>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reward Reduces Conflict by Enhancing Attentional Control and Biasing Visual Cortical Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Padmala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pessoa</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn\_a\_00011</idno>
	</analytic>
	<monogr>
		<title level="j">J Cogn Neurosci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="3419" to="3432" />
			<date type="published" when="2011" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Reward pays the cost of noise reduction in motor and cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tt-J</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maj</forename><surname>Apps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Batla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stamelou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Jarman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr Biol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1707" to="1716" />
			<date type="published" when="2015" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multitasking versus multiplexing: Toward a normative account of limitations in the simultaneous execution of control-demanding behaviors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn Affect \&amp; Behav Neurosci. Springer</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Automatic Processing: A Graph-Theoretic Approach to the Analysis of Serial vs. Parallel Processing in Neural Network Architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musslick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ozcimder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mma</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Willke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 38th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1547" to="1552" />
		</imprint>
	</monogr>
	<note>Controlled vs</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Strategy selection as rational metareasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">762</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bayesian Optimization with Exponential Convergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T ;</forename><surname>Lozano-Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2809" to="2817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Acquisition of decision making criteria: reward rate ultimately beats accuracy. Attention, Perception, \&amp; Psychophys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Balci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Holmes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="640" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Acerbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6780-practical-bayesian-optimization-for-model-fitting-with-bayesian-adaptive-direct-search.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1834" to="1844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Conflict monitoring and cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Braver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Barch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev. Department of Psychology</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="624" to="652" />
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note>mmb@cnbc.cmu.edu;</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raftery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bayes Factors</surname></persName>
		</author>
		<idno type="DOI">:10.2307/2291091</idno>
	</analytic>
	<monogr>
		<title level="j">J Am Stat Assoc. American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann Stat. Institute of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Rational regulation of learning dynamics by pupil-linked arousal systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Rumsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heasly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1040" to="1046" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Nat Neurosci</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Functionally dissociable influences on learning rate in a dynamic environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Mcguire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Kable</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="870" to="881" />
			<date type="published" when="2014" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Predictability, surprise, attention, and conditioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Kamin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Punishm aversive Behav</title>
		<imprint>
			<biblScope unit="page" from="279" to="296" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Speed/Accuracy Trade-Off between the Habitual and the Goal-Directed Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keramati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dezfouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piray</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1002055</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol. Public Library of Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">:10.1038/nn1560</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci. Nature Publishing Group</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1704" to="1711" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Cost-benefit arbitration between multiple reinforcement-learning systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Cushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="283" to="328" />
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Adaptive effort investment in cognitive and physical tasks: A neurocomputational model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Verguts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vassena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Silvetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front Behav Neurosci. Frontiers Media SA</title>
		<imprint>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Enhancing Metacognitive Reinforcement learning using reward structures and feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 39th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Post-error adjustments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Danielmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ullsperger</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2011.00233</idno>
	</analytic>
	<monogr>
		<title level="j">Front Psychol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Information theory of choice-reaction times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Drj</forename><surname>Laming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
			<publisher>Academic Press</publisher>
			<pubPlace>Oxford, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Optimizing the use of information: strategic control of activation of responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gratton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Donchin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Gen</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="480" to="506" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Automaticity in skill acquisition: Mechanisms for reducing interference in concurrent performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Carr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Hum Percept Perform. American Psychological Association</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">686</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Task-switching and long-term priming: Role of episodic stimulus--task bindings in task-shift costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Waszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Allport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn Psychol</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="361" to="413" />
			<date type="published" when="2003" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Semantic generalization of stimulus-task bindings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Waszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Allport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon Bull \&amp; Rev. Springer</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1027" to="1033" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">The costs and benefits of cross-task priming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Waszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hommel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mem \&amp; Cogn. Springer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1175" to="1186" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Outsourcing control to the environment: effects of stimulus/response locations on task selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Bryck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Res. Springer</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">When to use which heuristic: A rational solution to the strategy selection problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tl ;</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Noelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Warlaumont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoshimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matlock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Jennings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Conference of the cognitive science society</title>
		<meeting>the 37th Annual Conference of the cognitive science society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Algorithm selection by rational metareasoning as a model of human strategy selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Plunkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27</title>
		<meeting><address><addrLine>Cortes C, Lawrence ND</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Learning to (mis)allocate control: maltransfer can lead to self-control failure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bustamante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Musslick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 3rd Multidisciplinary Conference on Reinforcement Learning and Decision Making</title>
		<editor>Brunskill E, N. Daw</editor>
		<meeting><address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Reinterpreting anchoring-andadjustment as rational use of cognitive resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Huys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">The variable nature of cognitive control: a dual mechanisms framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Braver</surname></persName>
		</author>
		<idno type="DOI">:10.1016/j.tics.2011.12.010</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="106" to="113" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Measuring, monitoring, and maintaining memories in a partially observable mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Suchow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Integrated architectures for learning, planning, and reacting based on approximating dynamic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh international conference on machine learning</title>
		<meeting>the seventh international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="216" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Why self-control seems (but may not be) limited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Inzlicht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Schmeichel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Macrae</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2013.12.009</idno>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci. Elsevier Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="127" to="133" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Tonic dopamine: opportunity costs and the control of response vigor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Joel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00213-006-0502-4</idno>
	</analytic>
	<monogr>
		<title level="j">Psychopharmacology (Berl). Interdisciplinary Center for Neural Computation</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<biblScope unit="page" from="507" to="520" />
			<date type="published" when="2007" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
		<respStmt>
			<orgName>The Hebrew University of Jerusalem</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m">Author Contributions: Conceptualization: FL, TLG, AS Data Curation: FL, SM, AS Formal Analysis: FL, SM Funding Acquisition: TLG Investigation: FL Methodology: FL, AS, SM Project Administration: FL, TLG Resources: FL, SM, AS Software: FL, SM, AS Supervision: TLG</title>
		<meeting><address><addrLine>AS, FL Validation: FL</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
