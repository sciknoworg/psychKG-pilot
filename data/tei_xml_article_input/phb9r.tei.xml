<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Thoughts of God and acceptance of artificial intelligence: A replication</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2024-07-08">July 8, 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Don</forename><forename type="middle">A</forename><surname>Moore</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliana</forename><surname>Schroeder</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erica</forename><forename type="middle">R</forename><surname>Bailey</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Gershon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
						</author>
						<title level="a" type="main">Thoughts of God and acceptance of artificial intelligence: A replication</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-07-08">July 8, 2024</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>We report our attempts to replicate results by Karataş and Cutright (2023), in which thoughts of God increased people&apos;s receptivity to advice from artificially intelligent advisors. We attempt faithful replications of the five online studies from the paper all with larger sample sizes than the originals. We fail to find evidence consistent with the claims of Karataş and Cutright. Our results suggest that if the original effect exists, it is too small to have been detected by the original studies.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In November of 2022, ChatGPT was released for widespread commercial use. This powerful large language model embodied the most advanced form of artificial intelligence (AI) that many people had been able to interact with. Many users reported being profoundly affected by their first contact with this alien intelligence. It made people think about the power to create intelligent agents and human fallibility.</p><p>Researchers and technologists are eager to understand why and when people avoid these algorithms despite their (often) superior recommendations relative to human advisors <ref type="bibr">(Meehl, 1954;</ref><ref type="bibr">Dietvorst et al., 2015;</ref><ref type="bibr">Logg et al., 2019)</ref>. In this vein, recent research reports that thinking about God can enhance people's acceptance of algorithmic recommendations. <ref type="bibr" target="#b0">Karataş and Cutright (2023)</ref> suggest that one way to increase adoption of algorithmic recommendation is to increase God salience. To investigate this, they presented eight experiments in which they experimentally manipulated the salience of God and measured its effects on people's openness to advice from AI systems.</p><p>Their results are interesting and important enough that we sought to understand them better. We began with a p-curve analysis that examined the p-values reported in the original studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>p-curve analysis</head><p>God + AI 2 A p-curve analysis tests the evidentiary value in a set of studies using the p-values associated with the critical hypothesis test in each <ref type="bibr" target="#b1">(Simonsohn et al., 2014)</ref>. <ref type="bibr" target="#b0">Karataş and Cutright (2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Results from the p-curve app v.4.06, using the reported p-values from the eight key hypothesis tests in</head><p>The results of our p-curve analysis presented in <ref type="figure">Figure 1</ref> suggest that the original studies had an average of 9% power to detect the effects they report. The original studies were underpowered. We were therefore inspired to undertake replications. We replicated their five studies conducted with online samples. <ref type="table" target="#tab_0">Table 1 presents the disclosure table for our p-curve</ref> analysis, and also presents the results of our replication attempts. In the interests of full disclosure, we also report a conceptual replication of Study 1 and an initial attempted replication of Study 5 that included an error in the survey materials. We predict that the algorithm aversion… will be weaker among participants who are reminded of God."</p><p>Chi2(1) = 4.46, p = .035, r = .15, 95% CI <ref type="bibr">[.01, .28]</ref>, N = 201</p><p>Chi2(1) = 0.36, p = .547, r = .02, 95% CI <ref type="bibr">[-.05, .11]</ref>, N = 593</p><p>2b "Consumers will exhibit lower algorithm aversion…under the salience of God-related thoughts."</p><p>Chi2(1) = 6.80, p = .009, r = .14, 95% CI <ref type="bibr">[.03, .24]</ref>, N = 349</p><p>Chi2(1) = 0.79, p = .375, r = .03, 95% CI <ref type="bibr">[-.03, .09]</ref>, N = 1,036</p><p>2c "Salience of God-related concepts will weaken algorithm aversion…"</p><p>Chi2(1) = 8.91, p = .003, r = .16, 95% CI <ref type="bibr">[.06, .26]</ref>, N = 350 N/A 2d "The salience of God will reduce algorithm aversion."</p><p>Chi2(1) = 4.09, p = .043, r = .15, 95% CI <ref type="bibr">[.004, .28], N = 191</ref> N/A 3 "People will exhibit algorithm aversion to a lesser extent when they are reminded of God."</p><p>Chi2(1) = 4.12, p = .042, r = .11, 95% CI <ref type="bibr">[.004, .21]</ref>, N = 340</p><p>Chi2(1) = .003, p = .96, r = .002, 95% CI <ref type="bibr">[-.06, .07</ref>], N = 881 4 "Participants who are shown a religious quote about the perfection of God will exhibit algorithm aversion to a lesser extent than those who are shown a non-religious quote."</p><p>Chi2(2) = 7.16, p = .028, r = .14, 95% CI <ref type="bibr">[.05, .23]</ref>, N = 458 N/A 5 "The main prediction in this study is that the salience of God weakens algorithm aversion…We also aim to rule out the alternative explanation that the "mysterious" nature of algorithms' decision making, which might make people perceive algorithms as God-like, drive the effect. Specifically, we predict that the effect will be obtained both when the decision making process of algorithms are described as mysterious and when it is described as non-mysterious."</p><p>F(1, 236) = 9.25, p = .003, r =.19, 95% CI <ref type="bibr">[.07, .31]</ref>, N = 240 F(1, 880) = .098, p = .76, r = .01, 95% CI <ref type="bibr">[-.06, .08,]</ref>, N = 882 5 (Typo Versio n)</p><p>As above F(1, 236) = 9.25, p = .003, r =.19, 95% CI <ref type="bibr">[.07, .31]</ref>, N = 240 F(1, 876) = 6.71, p = .009, r = .09, 95% CI <ref type="bibr">[.02, .15]</ref>,</p><formula xml:id="formula_0">N = 879</formula><p>Data, code, preregistrations, and materials for all replication studies and analyses are available at: https://researchbox.org/2472&amp;PEER_REVIEW_passcode=ECZKIB</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direct Replication of Study 1 Method</head><p>This study was preregistered at: https://aspredicted.org/XHN_76L</p><p>Participants. As preregistered, we recruited 800 U.S. participants from Prolific Academic. A total of 1,035 respondents opened the survey, but 168 of them quit before being assigned to an experimental condition. Of the remaining 867, we excluded 67 because they did not complete the survey 1 , 40 because they had duplicate Internet Protocol (IP) addresses, and 5 because they failed an initial attention check. Our final sample included 755 participants (Mean age = 44.70 years, (SD = 14.52), 391 women, 353 men, and 11 nonbinary individuals, 65.17% White, 14.17% Black or African American, 9.40% Asian, 6.23% Hispanic or Latino/a, 5.03% Other).</p><p>Procedure. The survey randomly assigned participants to one of two prime conditions, a God condition or a control condition. In both conditions, participants were asked to complete a writing task. As in the original study, participants in the god salience condition were asked, "Please take some time to write about the role or impact of God, however you define God, in your life. Please provide a specific example to help explain your answer. What was the situation? When did it take place and where? How did you feel? Please be as detailed about this experience as possible, so that we may understand it." Participants in the control condition were asked, "Please take a few minutes to write about all of the things that you have done last night and today. Please be as detailed as possible (e.g., woke up, brushed teeth, went to work, etc.)."</p><p>Following the writing task, participants read, "Algorithms are a set of steps that a computer can use to accomplish a task. Thanks to rapid progress in computer science and technology, algorithms can now be used to accomplish a wide range of tasks." They were then presented with the same set of 24 tasks from the original study and asked to, "Please use the sliders to indicate how likely you are to follow the recommendation a computer algorithm (which is specialized in each of the tasks below) over the recommendation of an equally effective human counterpart to perform the task."</p><p>For each of the tasks, they answered on a slider scale ranging from 0 to 100. In the original study, participants read that "0 represents a very strong preference for the algorithm; 100 represents a very strong preference for the human; and 50 represents being indifferent between an algorithm and a human." But in our study we randomly assigned participants to either a condition in which 100 represented a very strong preference for the human (as in the original study) or to a condition in which 100 represented a very strong preference for the algorithm (opposite of the original study). That is, we randomized the polarity of the scale.</p><p>Participants then rated the same 24 tasks in terms of objectivity, consequentialness, and the importance of considering the unique characteristics of the situation or the individual in making a decision. They then completed a manipulation check that assessed the extent to which they thought about God during the study (1 = not at all, 5 = a great deal). Finally, participants reported gender, age, race/ethnicity, strength of belief in god (0 = not at all believe, 100 = strongly believe), and their religious affiliation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deviations From Original Study</head><p>We used the same Qualtrics survey that was generously supplied to us by the original authors. From that survey, we altered five things: (1) we necessarily changed the consent form, (2) we preregistered to exclude participants who did not complete the survey, (3) as noted above, we randomized the scale direction of the key dependent variable, (4) for the prime questions, we wrote code that prevented participants from copy-pasting their written responses from another source (e.g., ChatGPT), and (5) whereas in the original control condition asked participants to write about what they had done today, we asked control-condition participants to report on what they had done last night and today. We did this because our study launched in the morning on the East Coast, and we worried that early-in-the-day participants might not yet have enough to report about what happened to them "today."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Manipulation Check. As in the original study, participants in the God condition (M = 2.49, SD = 1.59) were significantly more likely to report thinking about God than those in the control condition (M = 1.69, SD = 1.27), mean difference = 0. Main Analysis. To compute the key dependent variable, we averaged each participant's algorithm vs. human preferences across the 24 tasks, always ensuring that higher numbers represented a stronger preference for the human over the algorithm. As preregistered, we regressed this variable on (1) prime condition (coded as 0.5 = control condition and -0.5 = god condition), (2) scale response direction condition (coded as 0.5 = higher scale numbers represented preference for the human and -0.5 = higher scale numbers represented preference for the algorithm), and (3) the interaction between those two variables.</p><p>Participants in the God condition were slightly less likely to prefer the human over the algorithm (M = 53.94, SD = 17.16) than were participants in the control condition (M = 55.00, SD = 16.02), but this difference was far from significant, b = 1.06, SE = 1.20, t(751) = 0.88, p = .380, d = 0.064. This effect size (d = 0.064) is 61% smaller than the size of the effect observed in the original study (d = 0.164). The replication had 2.35 times the sample size of the original study and used the same subject population, yet failed to replicate the original result. <ref type="bibr">2</ref> We did observe a significant main effect of scale response direction, b = 3.65, SE = 1.20, t(751) = 3.03, p = .003, indicating that participants tended to give higher numbers on the response scale, regardless of what those higher numbers meant. The interaction between prime condition and scale response direction condition was not significant (p = .414).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conceptual Replication and Extension of Study 1</head><p>In addition to conducting a direct replication of Study 1, we also conducted a conceptual replication and extension of Study 1 which we report below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>This study was preregistered at: https://aspredicted.org/Y47_RW5</p><p>Participants. As preregistered, we recruited 450 U.S. participants from Prolific, and verified human responses using a Captcha at the beginning of the survey. As in the original study, we excluded participants who failed an attention check or did not complete the survey, resulting in a final sample of 449 participants (Mean age = 37.82 years, (SD = 12.86), 250 women, 193 men, 6 nonbinary individuals; 57.68% White, 21.60% Black or African American, 16.70% Asian, 11.80% Hispanic or Latino/a, 2.45% Other).</p><p>Procedure. In this conceptual replication and extension of Study 1, we randomly assigned participants to one of three conditions: a God salience condition, a control condition as in the original, and an awe condition which we added in this study. The first two conditions used the same wording as the original study. The awe condition asked participants, "Please take a few minutes to think about a particular time, fairly recently, when you encountered a natural scene that caused you to feel awe. This might have been a sunset, a view from a high place, or any other time you were in a natural setting that you felt was beautiful." In all conditions, participants were asked to write 5-8 sentences.</p><p>Following the writing task, participants completed the mediator items from the original paper used in subsequent studies, the original dependent variable from Study 1, and an exploratory outcome variable described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Primary Measures</head><p>Small Self. Participants completed a measure of small self using responses to the following items: "Right now, I feel small," "I feel the presence of something greater than me," "I feel like I am in the presence of something grand," and "I feel part of some greater entity" (α = .79).</p><p>Human Imperfection. Participants completed a measure of human imperfection using responses to the following items: "We are all imperfect in many ways," "All people have flaws," "There is no perfect person," and "We all make mistakes" (α = .92).</p><p>State Authenticity. We also added an exploratory measure of state authenticity. To measure state authenticity, we used a set of face-valid items as in prior research. Specifically, participants responded to the following prompt, "Right now, I feel…" with the following three items: "authentic," "like myself," and "fake"* (* = reverse-coded; α = .82)</p><p>AI Recommendation. Participants were given a set of 23 tasks. They were asked to indicate their likelihood of following the recommendation of a computer algorithm relative to the recommendation of "an equally effective human counterpart," using the wording from the original study.</p><p>Manipulation Check. At the end of the survey, participants completed a manipulation check which measured the extent to which they thought about God during the study (1 = Not at all, 5 = A great deal). Finally, participants reported their religious affiliation, strength of belief in God, and demographic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deviations from original study</head><p>Due to a typo, the participants in this study answered 23 instead of 24 tasks (we did not include the item "weather prediction" in the recommendation dependent variable). In addition, we added an additional experimental condition-the awe manipulation described above. Further, we added an additional dependent variable, state authenticity, as described above. Finally, we measured God belief as in the original study in the demographics section of the survey. In addition to this measure, we also added a measure of religiosity using responses to the following item, "Overall, how religious do you consider yourself to be?" Participants responded on a 7-point scale where 1 = Not religious at all and 5 = Extremely religious.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Means, standard deviations, and t-tests between conditions for the set of outcome variables (recommendation, small self, human imperfection, and state authenticity) are presented in <ref type="table" target="#tab_3">Table  S2</ref>. For brevity, here we describe the results for the main hypothesized relationship-that is, the effect of condition on adoption of AI recommendations.</p><p>We first examined the effect of condition on the adoption of AI recommendations across the set of tasks using a one-way ANOVA. Note that the wording of the text is that higher values represent a preference for human (vs. AI) recommendations. The main effect was small and statistically insignificant, F(2, 446) = 2.67, p = .071, η 2 = 0.01.</p><p>We then compared our dependent variable-preference for human recommendations-across the three conditions using t-tests. First, we compared the preference for human recommendations relative to AI recommendations between the original two conditions from Study 1 (God salience and control condition). We found no significant difference between preferences for human recommendations in the God salience condition (M = 62.83, SD = 16.03) relative to the control condition (M = 59.81, SD = 13.93; mean difference = 3.02, 95% CI of mean difference <ref type="bibr">[-0.42, 6</ref>.47], t(279) = 1.73, p = .085; Cohen's d = 0.20, 95% CI of d <ref type="bibr">[-0.03, 0.43]</ref>). Note that these means are in the opposite direction of those reported by <ref type="bibr">Karataş and Cutright (2023, Study 1)</ref>.</p><p>We then compared the God salience condition to the awe condition. There was a small statistically significant difference between preference for human recommendations in the . This suggests that the awe condition, relative to the god salience condition, decreased preference for human recommendations (i.e., increased the preference for AI recommendations). There was no significant difference between the awe relative to the control condition (p = .721, Cohen's d = -0.04). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional and Exploratory Analyses</head><p>We confirmed that the manipulation was successful by examining the effect of condition on whether participants indicated they thought about God during the survey. An ANOVA suggests that the main effect of condition is statistically significant and medium, F(2, 446) = 34.22, p &lt; .001; η 2 = 0.13). As expected, participants the god salience condition reported thinking about God significantly more (M = 3.10) relative to participants in the control condition (M = 1.96; mean difference = 1.14, 95% . This suggests that the God salience manipulation successfully increased thoughts of God in line with a successful manipulation. There was no significant difference between the awe and control conditions (p = .384).</p><p>In exploratory analyses, we tested for an interaction between God belief and condition (God salience vs. control) on preference for human (relative to AI) recommendations. The effect of God condition (relative to control condition) by God belief was statistically non-significant and positive (beta = 0.04, 95% CI of beta [-0.04, 0.12], t(292) = 0.91, p = .363; Std. beta = 0.05, 95% CI of standard beta <ref type="bibr">[-0.06, 0.17]</ref>).</p><p>Similarly, we tested an interaction between religiosity and condition (God salience vs. control) on preference for human (relative to AI) recommendations.  <ref type="figure" target="#fig_0">Figure 2</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direct Replication of Study 2a</head><p>Karataş and Cutright's (2023) Study 2a found that asking participants to write thoughts about God increased their likelihood of selecting a fund recommended by a robo-advisor (over a human financial advisor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>This study was preregistered at https://aspredicted.org/TBY_14V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants.</head><p>As preregistered, we recruited 600 U.S. participants from Prolific. 745 individuals opened the survey; as preregistered, we excluded participants who did not complete the survey (n = 142 3 ) or failed an initial attention check (n = 6), had duplicate Internet Protocol (IP) addresses (n = 4), or had duplicate Prolific IDs (n = 0), resulting in a final sample of 593 individuals (Mean age = 40.91 years, (SD = 14.35), 284 women, 298 men, 11 nonbinary/other individuals; 261 Christian, 13 Jewish, 5 Buddhist, 270 agnostic, atheist, or "irreligious," 39 other religion) who completed the survey in exchange for $0.40.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure.</head><p>After reading the consent form, completing an attention check question ("What is the fifth word in the following sentence?"), and entering their Prolific ID, participants were randomly assigned to either the God condition ("Please take some time to write about the role or impact of God, however you define God, in your life") or the control condition ("Please take a few minutes to write about all of the things you have done today").</p><p>Participants then read, "imagine that you decided to invest in a mutual fund to grow your savings. You are considering to invest in one of the two stocks, Omega and Kappa." They read that the two funds have "comparable levels of risk", "performed comparably during the year", and "yielded similar returns." Participants viewed a chart of Omega's and Kappa's cumulative returns (see survey PDF on ResearchBox for chart). Next they read, "You come across an expert human financial advisor suggesting Kappa and a robo-advisor (i.e., an algorithm that provides financial advice without human supervision) recommending Omega. Both the financial advisor and the robo-advisor have a comparable history of recommending winning mutual funds and 90 out of 100 funds they recommended in the past yielded an average of 30% annual return." Finally, participants answered the question: "Which mutual fund would you invest in?" Omega (recommended by robo-advisor) or Kappa (recommended by human advisor). The name and recommendation of the funds was randomly counterbalanced, such that half of the participants instead saw Omega recommended by the human advisor and Kappa by the robo-advisor.</p><p>At the end of the survey, participants reported their gender, age, strength of belief in God (0 = not at all believe, 100 = strongly believe), and their religious affiliation. Note that there was no manipulation check in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deviations from original study</head><p>We used the same Qualtrics survey that was generously supplied to us by the original authors. From that survey, we altered these things: (1) we necessarily changed the consent form, (2) for the prime questions, we wrote code that prevented participants from copy-pasting their written responses from another source (e.g., ChatGPT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Of the 323 participants assigned to the control condition, 173 (53.56%) selected the fund recommended by the human advisor and 150 (46.44%) selected the fund recommended by the robo-advisor. Of the 270 participants assigned to the God condition, 137 (50.74%) selected the fund recommended by the human advisor and 133 (49.25%) selected the fund recommended by the robo-advisor. The preregistered chi-square test (1, N = 593) = 0.36, p = .547, showed that the experimental condition did not have a statistically significant effect on participants' choices. This effect size, r = .02, is 16% of the original effect size of r = .15.</p><p>We preregistered five additional exploratory analyses, none of which showed statistically significant results (see analysis code and output on Research Box).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direct Replication of Study 2b</head><p>Karataş and Cutright's (2023) Study 2b found that asking participants to write thoughts about God increased their likelihood of selecting a song recommended by an algorithm (over a human musician).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>This study was preregistered at https://aspredicted.org/16C_RCH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants.</head><p>As preregistered, we recruited 1,050 U.S. participants from Prolific Academic. 1,234 individuals opened the survey; as preregistered, we excluded participants who did not complete the survey (n = 184 4 ) or failed an initial attention check (n = 4), had duplicate Internet Protocol (IP) addresses (n = 14), or had duplicate Prolific IDs (n = 0), resulting in a final sample of 1,032 individuals (Mean age = 41.32 years, (SD = 13.64), 511 men, 504 women,17 nonbinary/other individuals) who completed the survey in exchange for $1.00.</p><p>Procedure. After reading the consent form, completing a captcha, completing an attention check question ("What is the fifth word in the following sentence?"), and entering their Prolific ID, participants were randomly assigned to either the God condition ("Please take some time to write about the role or impact of God, however you define God, in your life") or the control condition ("Please take a few minutes to write about all of the things you have done today").</p><p>Following the writing task, participants were then told to evaluate a song and read the following information:</p><p>"The objective of this final part of the survey is to understand the appeal of favorite Turkish songs to the general US population. As part of this, you will first pick three songs from a list that best fit your music taste. Next, based on your music taste, you will be shown two songs from the "Top 100: Turkey" chart list of AppleMusic, and you will be asked to listen to and evaluate the song that you choose. One of the two songs will be recommended by an algorithm specifically designed for recommending songs based on one's music taste. The other song will be recommended by a musician, who is a knowledgeable expert in picking songs that match one's music taste. Past surveys showed that both the algorithm and the human expert are equally successful in recommending music based on the listeners' inputs."</p><p>Participants were told that, "for the algorithm and the musician to pick a song for you" they must select three songs from a list of 15 popular songs. After selecting, participants viewed a screen: "Please wait… the algorithm and the musician are picking songs that you'll like!"</p><p>Next, participants read that, based on the three songs they initially selected, the algorithm and musician had selected two songs for them: Huyu Suyu and Baka Baka (both by artist Emir Taha). The order was counterbalanced regarding which song was ostensibly selected by the human versus algorithm, and which song was presented first (four orders in total).</p><p>Participants were told to "select the song that you think you will like more."</p><p>Subsequently, they were given the opportunity to listen to each song and rate how much they "like this song" and "would be willing to explore similar songs" on a 1 to 7 Likert scale ranging from "strongly disagree" to "strongly agree."</p><p>Last, participants reported their gender, age, strength of belief in god (0 = not at all believe, 100 = strongly believe), and their religious affiliation. Note that there was no manipulation check in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deviations from original</head><p>We used the same Qualtrics survey that was generously supplied to us by the original authors. From that survey, we altered these things: (1) we necessarily changed the consent form, (2) for the prime questions, we wrote code that prevented participants from copy-pasting their written responses from another source (e.g., ChatGPT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results.</head><p>Of the 535 participants assigned to the control condition, 332 (62.06%) selected the song recommended by the human musician and 203 (37.94%) selected the song recommended by the algorithm. Of the 497 participants assigned to the God condition, 295 (59.36%) selected the song recommended by the human musician and 202 (40.64%) selected the song recommended by the algorithm. The preregistered chi-square test (1, N = 1,032) = 0.68, p = .410, showed that the experimental condition did not have a statistically significant effect on participants' choices. This effect size, r = .03, was 21% of the original effect size, r = .14.</p><p>We preregistered six additional exploratory follow-up analyses, but given the non-significant main results, did not conduct them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direct Replication of Study 3</head><p>Karataş and Cutright's (2023) Study 3 found that asking participants to write thoughts about God increased their preference for using an algorithm (over a human dentist) to make a hypothetical dental decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>This study was preregistered at: https://aspredicted.org/YZ9_THH</p><p>Participants. As preregistered, we recruited 1,000 U.S. participants from Prolific Academic. A total of 1,159 respondents opened the survey, but 154 of them quit before completing the dependent variable. 5 Of the remaining 1,005, we excluded 10 because they had duplicate Internet Protocol (IP) addresses, and 113 because they failed at least one of two attention check. Our final sample included 881 participants (Mean age = 41.61 years, (SD = 13.68), 446 men, 425 women, and 10 nonbinary individuals), which was 504 more than in the original study.</p><p>Procedure. Participants were randomly assigned to one of two prime conditions, a god condition or a control condition. In both conditions, participants were asked to complete a writing task. As in the original study, participants in the god salience condition were asked, "Please take some time to write about the role or impact of God, however you define God, in your life. Please provide a specific example to help explain your answer. What was the situation? When did it take place and where? How did you feel?" Participants in the control condition were asked, "Please take a few minutes to write about the things that you have done yesterday."</p><p>Following the writing task, participants completed a battery of measures designed to assess (1) feelings of smallness (e.g., "Right now, I feel small"), (2) beliefs about human fallibility (e.g., "All people have flaws"), (3) their current feelings, assessed by asking them to rate the extent to which they were feeling 20 different emotions (e.g., "Interested", "Upset"), and (4) their beliefs about the extent to which the world is deterministic (e.g., "The future has already been determined by fate"). Measures (1), (2), and (4) used a scale anchored at 1 = Strongly disagree and 7 = Strongly agree, whereas Measure (3) used a scale anchored at 1 = Not at all and 5 = Extremely. Embedded in the determinism scale was an attention check that read, "Please select neither agree or disagree for this statement."</p><p>After completing those measures, participants were asked to move on to a different task in which they were asked to imagine a scenario in which they visit the dentist to get treatment for dental pain. The scenario read:</p><p>Imagine that you visited a dentist after experiencing dental pain for a while. After the initial examination, the dentist detects a tooth with a decaying root because it has not been treated for a long time. Now, you have to decide one of the two treatment options:</p><p>1. root canal treatment 2. an implant.</p><p>While root canal is a treatment that involves removal of the infected pulp and nerve, and cleansing and filling of the root canal, an implant involves the extraction of the natural tooth and the replacement of the root with a long-lasting metal post.</p><p>To help you in your final decision, imagine that you get a recommendation-about whether to have a root treatment or an implant. There are two possibilities as to where this recommendation comes from. Either a dentist evaluates the results of your examination and uses his/her judgment and experience to compare your case to 6 patients who faced the same decision and the results of their treatment. Or a computer-based program evaluates the results of your examination and uses an algorithm to compare your case with patients who faced the same decision and the results of their treatment.</p><p>In the past, the dentist and the computer algorithm shown the same accuracy in making recommendations. In both cases, 93% of patients were happy with the recommendation provided by both the dentist and the algorithm.</p><p>Both the dentist and the algorithm compared your case to past cases by considering (1) your gum structure, (2) the structure and healthiness of your jaw bones,</p><p>the bacterial composition and activity around the decay, (4) your history of dental issues, and (5) demographics such as your gender and age. Now, you need to decide whether to have a root treatment or an implant.</p><p>Participants then answered three questions designed to assess what the authors referred to as "dental risk". Specifically, they indicated their level of agreement with three statements (1 = Strongly disagree, 7 = Strongly agree): (1) It is likely that will be negative health consequences in this situation 7 , (2) If there are negative health consequences, these consequences will be significant, and (3) If I lose my health by choosing the wrong treatment, I will be able to cope with it very well. The last item was reverse coded, and then the responses to the three statements were averaged.</p><p>On the next page, the participants were presented with the critical dependent variable. They were asked to choose between two treatments, an implant or a root canal. One treatment was recommended by the dentist and the other was recommended by the algorithm, counterbalanced across participants. Participants were told that "the dentist and the algorithm are equally competent. Also, total costs of the two treatments are equal." They then indicated their preference by choosing between the two procedures.</p><p>Participants then reported their gender, age, religious affiliation, and strength of belief in God (0 = not at all believe, 100 = strongly believe). Finally, as a second attention check, participants were asked, "Which of the following is true about the dental treatment scenario that you just read?" The correct answer was "The dentist and the algorithm were equally accurate in their recommendations."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deviations From Original Study</head><p>We used the same Qualtrics survey that was generously supplied to us by the original authors.</p><p>From that survey, we altered two things: (1) we added a consent form to the start of the survey, and (2) for the prime questions, we wrote code that prevented participants from copy-pasting their written responses from another source (e.g., ChatGPT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Main Analysis. As preregistered, we used OLS to regress participant's choice of the dental option recommended by the algorithm on (1) prime condition (coded as 1 = God condition and 0 = control condition) and (2) whether the algorithm recommended the implant or the root canal (coded as 1 = algorithm recommended the root canal and 0 = algorithm recommended the implant).</p><p>Participants in the God condition (35.3%) were not more likely than participants in the control condition (35.1%) to prefer the option recommended by the algorithm, b = .001, SE = .032, t(878) = 0.04, p = .968. This effect size (.02 percentage points) is 98% smaller than the effect observed in the original study (10.8 percentage points). This replication had 2.59 times the sample size of the original study and the same online platform, yet did not obtain the same result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional Analyses</head><p>In the original study, the authors found a significant effect of God prime on feelings of smallness and beliefs in human imperfection. We replicated the former 8 , b = .617, SE = .104, t(878) = 5.95, p &lt; .001, but not the latter, b = .077, SE = .055, t(878) = 1.40, p = .162. The authors found a significant effect of god prime on deterministic beliefs. We observed a smaller, marginally significant result, b = .170, SE = .091, t(878) = 1.86, p = .063. Importantly, none of these variables correlated significantly positively with whether participants chose the algorithm's recommended dental option: rs = .038, -.053, and .031, respectively.</p><p>In the original study, there were no significant effects of God prime on positive mood, negative mood, or dental risk perceptions. Similarly, we found no significant effects of God prime on positive mood, b = .103, SE = .065, t(878) = 1.59, p = .112, negative mood, b = .012, SE = .038, t(878) = 0.32, p = .752, or dental risk perceptions, b = -.089, SE = .071, t(878) = -1.26, p = .207.</p><p>Finally, the original authors reported a marginally significant interaction between the priming manipulation and whether or not the participant reported having a religious affiliation, such that the priming effect was significant only among those who did not have a religious affiliation. We observed no such moderation, and in fact it trended in the opposite direction: b = .060, SE = .065, t(878) = 0.91, p = .361.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direct Replication of Study 5</head><p>Karataş and Cutright's (2023) fifth study reported that writing thoughts about God increased participants' preference for using an algorithm (over a human expert) to make a hypothetical investment decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>This study was preregistered at: https://aspredicted.org/G5N_YRH</p><p>Participants. As preregistered, we recruited 1,000 U.S. participants from Prolific. A total of 1,115 respondents opened the survey, but 107 of them quit before completing the dependent variable. 9 Of the remaining 1,008, we excluded 14 because they had duplicate Internet Protocol (IP) addresses, and 109 because they failed (or failed to complete) the attention check. 10 Our final sample included 882 participants (Mean age = 40.35 years, (SD = 13.82), 474 men, 386 women, and 22 nonbinary individuals), which was 601 more than in the original study.</p><p>Procedure. This experiment employed two critical manipulations. The first assigned participants to read an article that either suggests that AI is mysterious (titled "The 'black box' of artificial intelligence") or that suggests that AI is non-mysterious (titled "The myth of the 'black box' of artificial intelligence"). Participants read that they would be asked questions about the article later in the survey. After reading the article, participants were randomly assigned to one of two prime conditions, a God condition or a control condition. In both conditions, participants were asked to complete a writing task. As in the original study, participants in the god salience condition were asked, "Please take some time to write about the role or impact of God, however you define God, in your life. Please provide a specific example to help explain your answer. What was the situation? When did it take place and where? How did you feel? Please be as detailed about this experience as possible, so that we may understand it." Participants in the control condition were asked, "Please take a few minutes to write about all of the things that you did yesterday. Please be as detailed as possible (e.g., woke up, brushed teeth, went to work, etc.)."</p><p>Following the writing task, participants were asked to move on to a different task in which they were asked to imagine a scenario in which they had to choose which of two stocks to invest in, The scenario read: Participants were then asked to "Please indicate below your relative preference of investment in the two funds," on a slider scale ranging from 0 to 100.</p><formula xml:id="formula_2">Imagine</formula><p>Within this scenario, there were two between-subjects manipulations. First, as in the original study, we manipulated whether the robo-advisor recommended Omega or Kappa. Second, in the original study, the scale was always presented such that higher numbers represented a greater preference for the stock that was recommended by the human expert. In our replication, we counterbalanced the direction of this scale, so that for approximately half of the participants higher numbers represented a preference for the stock recommended by the human and for the other half higher numbers represented a preference for the stock recommended by the algorithm. For our analysis, we coded the scale so that higher numbers represented a preference for the stock recommended by the human expert.</p><p>On the next page, the participants were asked to indicate their extent of agreement with four statements about the article presented at the beginning of the survey, on a scale ranging from 1 = "Strongly disagree" to 7 = "Strongly agree". Those statements were: (1) The information in the article was believable;</p><p>(2) I enjoyed reading the article;</p><p>(3) The article was a good fit for the tech magazine or blog; and, (4) After reading the article, it is uncertain to me how AI systems make decisions. Participants then moved on to two subsequent pages. On the first they were asked, "To what extent do AI systems remind you of God or a higher power in how they work?" (1 = "Not at all", 7 = "To a very great extent"). On the second they were asked, as an attention check, "What was the title of the article you read?", and the options were "The 'black box' of artificial intelligence (AI)" and "The myth of the 'black box' of artificial intelligence (AI)".</p><p>Participants then indicated their gender, age, religious affiliation, and strength of belief in god (0 = not at all believe, 100 = strongly believe).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>As above, except among participants who read that the robo-advisor was recommending Kappa, for which they could indicate a preference by moving the slider response scale toward 100. Those participants confusingly saw a scale in which the top of the scale read "Omega" while "Kappa" appeared at the bottom of the scale. This error represented a deviation from our preregistered research plan. This study was preregistered at: https://aspredicted.org/737_DYZ</p><p>Participants. As preregistered, we recruited 1,000 U.S. participants from Prolific. A total of 1,139 respondents opened the survey, but 131 of them quit before completing the dependent variable. 11 Of the remaining 1,008, we excluded 9 because they had duplicate Internet Protocol (IP) addresses, and 120 because they failed (or failed to complete) the attention check. 12 Our final sample included 879 participants (Mean age = 41.56 years, (SD = 14.21), 437 men, 424 women, and 17 nonbinary individuals).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Main Analysis. As preregistered, we used OLS to regress participant's preference for the stock recommended by the human expert on (1) mysteriousness condition (coded as .5 for the mysterious article and -.5 for the non-mysterious article, (2) prime condition (coded as .5 = God condition and -.5 = control condition), (3) the interaction between (1) and (2), (4) whether the algorithm recommended Omega or Kappa (coded as .5 = Kappa and -.5 = Omega), and (5) the direction of the scale (coded as .5 = higher numbers associated with the human expert's recommendation and -.5 = higher numbers associated with the algorithm's recommendation).</p><p>Participants in the God condition (M = 48.0, SD = 23.3) were significantly less likely than participants in the control condition (M = 52.0, SD = 22.0) to prefer the option recommended by the human expert, b = -3.46, SE = 1.53, t(872) = -2.26, p = .024. Despite its statistical significance, this effect size (d = .175) is only 44% that in the original study (d = .394).</p><p>However, differential attrition impairs our ability to draw confident causal conclusions. In particular, 68 (51.9%) of the quitters came from the God prime condition, while only 42 (32.1%) came from the control prime condition. The remaining 21 (16.0%) quit before being assigned to a prime condition. We could not directly observe whether this also happened in the original study, but it doesn't seem like it, as roughly half of the participants in the original study were assigned to the god prime condition (49%). The differential attrition we observed in our replication undermines random assignment, and therefore the validity of the experiment.</p><p>This regression also yielded a significant effect of scale ordering, b = 4.86, SE = 1.52, t(872) = -3.19, p = .001, indicating, as in our first replication, that participants were more likely to provide higher numbers on the scale, regardless of what those higher numbers meant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional Analyses</head><p>In the original study, the authors reported a significant effect of belief in God on preference for the human-recommended stock, as well as a significant interaction between the priming condition and participants' belief in God, such that the priming effect was larger for those who reported a stronger belief in god. We replicated neither of these results, as belief in God did not predict participants' preference for the human-recommended stock, b = .003, SE = .018, t(870) = 0.16, p = .876, and nor was there a significant interaction between belief in God and the priming condition, b = -.016, SE = .035, t(870) = -0.45, p = .651. Indeed, the interaction was not even in the same direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>The results of our replication attempts leave us more skeptical of the empirical support for the theory presented by <ref type="bibr">Karataş and Cutright.</ref> We acknowledge the fact that our replications do appear directionally consistent with the Karataş and Cutright results. This fact draws attention to the fact that the effect size estimates in our replications all overlap with zero, raising questions about the true effect size. We do not claim that the true effect of God-salience on AI acceptance is zero, but our results do imply that if the effect does, in fact, exist, that it is very small. What we can say, therefore, is that the original studies lacked the power to detect the effect, if it exists, of God salience on AI acceptance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Interaction between Religiosity and Condition (God Salience vs. Control) on Preference for Human (vs. AI) Recommendations in the Conceptual Replication of<ref type="bibr" target="#b0">Karataş and Cutright (2023)</ref> Study 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table><row><cell>Study</cell><cell>Primary Hypothesis (Quoted from</cell><cell>Original Result</cell><cell>Replication Result</cell></row><row><cell>No.</cell><cell>Original Preregistration)</cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>"The salience of God will weaken</cell><cell>F(1, 319) = 12.91, p</cell><cell>t(754) = 0.88, p =</cell></row><row><cell>(direct</cell><cell>algorithm aversion…across different</cell><cell>&lt; .001, r = .19, 95%</cell><cell>.38, r = .03, 95%</cell></row><row><cell>replicat</cell><cell>tasks."</cell><cell>CI [.089, .30], N =</cell><cell>CI [-.04, .10], N =</cell></row><row><cell>ion)</cell><cell></cell><cell>321</cell><cell>755</cell></row><row><cell>1</cell><cell>As above</cell><cell>F(1, 319) = 12.91, p</cell><cell>t(278.79) = -1.78,</cell></row><row><cell>(conce</cell><cell></cell><cell>&lt; .001, r = .19, 95%</cell><cell>p = .077, r = -.10,</cell></row><row><cell>ptual</cell><cell></cell><cell>CI [.089, .30], N =</cell><cell>95% CI [-.008,</cell></row></table><note>Disclosure table for p-curve analysis. Effect sizes are reported in r.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>God salience condition (M = 62.83, SD = 16.03) relative to the awe condition (M = 59.27, SD = 12.47; mean difference = 3.56, 95% CI of mean difference [0.24, 6.88], t(264.10) = 2.11, p = .036; Cohen's d = 0.25, 95% CI of d [0.02, 0.48])</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 . Descriptive Statistics and Pairwise Contrasts Preference for Human (vs. AI) Recommendations</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell>M (SD)</cell><cell>Control</cell><cell>God Salience</cell></row><row><cell>Control</cell><cell>59.81 (13.93)</cell><cell></cell><cell></cell></row><row><cell cols="2">God Salience 62.83 (16.03)</cell><cell>t = 1.73, d = 0.20</cell><cell></cell></row><row><cell>Awe</cell><cell>59.27 (12.47)</cell><cell>t = 0.36, d = 0.04</cell><cell>t = 2.11, d = 0.25 *</cell></row><row><cell></cell><cell></cell><cell>Small Self</cell><cell></cell></row><row><cell></cell><cell>M (SD)</cell><cell>Control</cell><cell>God Salience</cell></row><row><cell>Control</cell><cell>3.44 (1.39)</cell><cell></cell><cell></cell></row><row><cell cols="2">God Salience 3.86 (1.62)</cell><cell>t = 2.39, d = 0.28 *</cell><cell></cell></row><row><cell>Awe</cell><cell>4.48 (1.27)</cell><cell>t = 6.91, d = 0.79 ***</cell><cell>t = 3.66, d = 0.43 ***</cell></row></table><note>* p &lt; .05, ** p &lt; .01, *** p &lt; .001</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>The effect of God condition (relative to control condition) by God belief was statistically significant and positive (beta = 3.47, 95% CI of beta[0.90, 6.04], t(293) = 2.66, p = .008; Std. beta = 0.15, 95% CI of standard beta [0.04, 0.26]; see</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>that you decided to invest in a mutual fund to grow your savings. You are considering investing in one of the two stocks: Kappa and Omega.The chart below shows the performance of the two funds during the five months of 2022.</figDesc><table><row><cell>You learned that an expert human financial advisor is recommending Kappa and a</cell></row><row><cell>robo-advisor (i.e., an algorithm that provides financial advice without human</cell></row><row><cell>supervision) is recommending Omega.</cell></row><row><cell>Both the financial advisor and the robo-advisor have a comparable history of</cell></row><row><cell>recommending winning mutual funds, and 90 out of 100 funds they recommended in</cell></row><row><cell>the past yielded an average of 30% annual return.</cell></row><row><cell>Please indicate below your relative preference of investment in the two funds?</cell></row><row><cell>• (0: "I would invest all my money in Omega (recommended by the</cell></row><row><cell>robo-advisor);"</cell></row><row><cell>• 50: "I would invest half of my money in Omega and half in Kappa;"</cell></row><row><cell>• 100: "I would invest all my money in Kappa (recommended by the human</cell></row><row><cell>expert))</cell></row><row><cell>As the chart clearly demonstrates, the two funds have comparable levels of risk and</cell></row><row><cell>they performed comparably during the year (i.e., they yielded the exact same</cell></row><row><cell>cumulative return of 20%).</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In our preregistration, we wrote that we would exclude participants who failed to complete the survey "as indicated by a Qualtrics Progress score less than 100." But it was clear from the data that participants with a Progress score of 96 or higher did effectively complete the survey (i.e., they answered every single question), and so we included every participant with a Progress score higher than 95.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">As in the original study, (1) the effect of prime did not significantly interact with God belief strength (p = .753), and (2) God belief strength was directionally but not significantly higher in the God condition (M = 60.2, SD = 42.0) than in the control condition (M = 55.4, SD = 43.3), t(749.46) = 1.54, p = .125.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Of the participants who left the survey, 38 were assigned the control condition, 100 were assigned to the God condition, and 4 did not get an assignment to condition before they left the survey. All but two participants left before completing the writing task.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Of the participants who left the survey, 67 had been assigned the control condition, 112 had been assigned to the God condition, and 5 did not get an assignment to condition before they left the survey. All but seven participants left before completing the writing task.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">There was differential attrition, as 113 of these 154 quitters (77.3%) came from the God prime condition. We could not directly observe whether this also happened in the original study, but the fact that only 44% of the original study participants were in the God prime condition (vs. 56% in the control condition) strongly suggests that it did. Of course, differential attrition of this magnitude undermines random assignment, and therefore the validity of any experiment.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">This statement contains a typo, as it is missing "there" from "It is likely that [there] will be…". This typo was present in both the original and in the replication. All bolded words were bolded within the survey itself.6  This typo was in both the original survey and the replication.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">It is possible that this "feelings of smallness" result may represent a demand or conversational norm artifact, as some participants in the God prime condition may interpret the smallness questions as asking whether they feel small relative to God (since they were just asked about god on the previous page), whereas those in the control condition had no such referent.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">As detailed below, the attention check required people to recall the title of an article they read during the survey. But because participants in different conditions read different (and differently titled) articles, the attention check may be more difficult for some participants rather than others. And indeed, participants in the non-mysterious article condition were much more likely to fail the attention check (97 of 502; 19.3%) than were participants in the mysterious condition (12 of 489; 2.5%).9  There was differential attrition, as 62 (58%) of the quitters came from the God prime condition, while only 19(18%) came from the control prime condition. The remaining 26 (24.2%) quit before being assigned to a prime condition. We could not directly observe whether this also happened in the original study, but it doesn't seem like it, as roughly half of the participants in the original study were assigned to the God prime condition (49%). The differential attrition we observed in our replication undermines random assignment, and therefore the validity of the experiment.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">As detailed below, the attention check required people to recall the title of an article they read during the survey. But because participants in different conditions read different (and differently titled) articles, the attention check may be more difficult for some participants rather than others. And indeed, participants in the non-mysterious article condition were much more likely to fail the attention check (97 of 502; 19.3%) than were participants in the mysterious condition (12 of 489; 2.5%).11 There was differential attrition, as 62 (58%) of the quitters came from the God prime condition, while only 19(18%) came from the control prime condition. The remaining 26 (24.2%) quit before being assigned to a prime condition. We could not directly observe whether this also happened in the original study, but it doesn't seem like it, as roughly half of the participants in the original study were assigned to the God prime condition (49%). The differential attrition we observed in our replication undermines random assignment, and therefore the validity of the experiment.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deviations From Original Study</head><p>We used the same Qualtrics survey that was generously supplied to us by the original authors. From that survey, we altered two things: (1) we added a consent form to the start of the survey, and (2) as mentioned above, we manipulated whether higher numbers on the scale represented a preference for the human expert's recommended stock (as in the original study) or a preference for the algorithm's recommended stock.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Main Analysis. As preregistered, we used OLS to regress participant's preference for the stock recommended by the human expert on (1) mysteriousness condition (coded as .5 for the mysterious article and -.5 for the non-mysterious article, (2) prime condition (coded as .5 = God condition and -.5 = control condition), (3) the interaction between (1) and (2), (4) whether the algorithm recommended Omega or Kappa (coded as .5 = Kappa and -.5 = Omega), and (5) the direction of the scale (coded as .5 = higher numbers associated with the human expert's recommendation and -.5 = higher numbers associated with the algorithm's recommendation).</p><p>Participants in the God condition (M = 53.3, SD = 22.8) were not significantly less likely than participants in the control condition (M = 53.8, SD = 22.8) to prefer the option recommended by the human expert, b = -.39, SE = 1.54, t(872) = -0.25, p = .800. This effect size (d = 0.021) is 5.3% the size of the effect observed in the original study (d = 0.394).</p><p>This regression also yielded a significant effect of scale ordering, b = 4.09, SE = 1.53, t(876) = 2.68, p = .008, suggesting that participants were more likely to provide higher numbers on the scale, regardless of what those higher numbers meant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional Analyses</head><p>In the original study, the authors reported a significant effect of belief in God on preference for the human-recommended stock, as well as a significant interaction between the priming condition and participants' belief in God, such that the priming effect was larger for those who reported a stronger belief in god. We replicated neither of these results, as belief in God did not predict participants' preference for the human-recommended stock, b = -.002, SE = .017, t(874) = -0.09, p = .931, and nor was there a significant interaction between belief in God and the priming condition, b = -0.031, SE = 0.036, t(874) = -0.88, p = .38. Indeed, the interaction was not even in the same direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Direct Replication of Study 5 (Typo Version)</head><p>This replication of Study 5 employed the same method as above, except the survey contained an error in which the survey presented some participants with inconsistent information. We report it here in the interest of full disclosure.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Thinking about God increases acceptance of artificial intelligence in decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karataş</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Cutright</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2218961120</idno>
		<ptr target="https://doi.org/10.1073/pnas.2218961120" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="volume">120</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">P-Curve: A Key to the File Drawer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="534" to="547" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<ptr target="https://www.p-curve.com/app4/" />
		<imprint>
			<date type="published" when="2024-01-18" />
		</imprint>
	</monogr>
	<note>P-curve app 4.06</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
