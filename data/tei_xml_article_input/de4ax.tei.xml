<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AI Authority and Obedience</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ejaz</forename><surname>Shaikh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Thakur Ramnarayan College of Arts and Commerce</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">AI Authority and Obedience</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T12:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Artificial Intelligence (AI)</term>
					<term>Obedience</term>
					<term>Authority</term>
					<term>Generative AI</term>
					<term>LLMs (Large Language Models)</term>
					<term>AGI (Artificial General Intelligence)</term>
					<term>Milgram Experiment</term>
					<term>Ethics</term>
					<term>Transparency</term>
					<term>Social Influence</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper explores the intersection of Artificial Intelligence, authority and obedience and its societal implications examining the circumstances wherein advanced AGI holding influential positions might act against human welfare. Acting as a warning, this paper explores the circumstances leading to a societal failure consequential of AI hyper-dependence in societally critical decision making. The image of AI being rational while being trained on societal values is a contradictory dynamic causing cracks in society owing to human fallacies have been illuminated as well. Along with the problems associated with AI hyper-dependence in decision making, this paper explores a handful of preventive mechanisms against destruction caused by blind following of AI authorities.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AI Obedience and Authority</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction:</head><p>From reinforcement learning to neural networks, the development of Artificial Intelligence has been influenced by brain sciences such as psychology and neurology. AI is defined as "the designing and building of intelligent agents that receive percepts from the environment and take actions that affect that environment" <ref type="bibr" target="#b0">(Russell et al, 2016</ref>  <ref type="bibr" target="#b2">(Turing, 1950</ref>). The first program to pass the Turing test was ELIZA created by Joseph Weisenbaum.</p><p>Another offshoot of World War II was watershed research into human capacity for interpersonal violence and destruction. In the 1960s, to understand the phenomenon which transformed seemingly normal individuals into Holocaust perpetrators under the Nazi rule, <ref type="bibr">Stanley</ref> Milgram conducted an experiment on destructive obedience <ref type="bibr" target="#b14">(Milgram, 1963)</ref>. Under the authority of the "researcher", a "teacher" administers shock to the "student" on every wrong answer and continues to do even if the student has overtly passed out. The experiment has been repeated cross-culturally with results remaining constantly around 65%. Trust over the authority of the "researchers" along with certain situational factors such as high-stress and emotional arousal enabled such behavior in the Milgram experiment <ref type="bibr" target="#b15">(Haslam et al, 2014)</ref>. Many war-criminals who participated in the Holocaust, attempted to shift the responsibility of their actions to authority figures: 'But we were only following orders'. Similar results were found in the Milgram experiment illuminating the capacity for interpersonal harm in human behavior <ref type="bibr" target="#b14">(Milgram, 1963)</ref>. Today advancements in Generative AI -AIs capable of generating text, images The recent technological revelations are driving an AI arms-race to create AGI or Artificial General Intelligence first discussed by Ben Goertzel and Cassio Penachin in the book Artificial General Intelligence wherein AGI is defined as: "AGI is, loosely speaking, AI systems that possess a reasonable degree of self-understanding and autonomous self-control, and have the ability to solve a variety of complex problems in a variety of contexts, and to learn to solve new problems that they didn't know about at the time of their creation." Although AGI has been pre-declared as an existential risk, the current research is ambiguous: no scientific consensus regarding creation of AGI exists. However, the idea that an AI system capable of surpassing human intelligence which, if developed, will have tremendous socio-technical implications in the coming decades has definitely garnered consensus <ref type="bibr" target="#b16">(Goertzel, 2014;</ref><ref type="bibr" target="#b17">McLean et al, 2021)</ref>. Such an AI System can possibly hold a very high capacity of social influence given and under certain high stress circumstances such social influence can turn into destructive obedience. This paper points at a very speculative yet potential future wherein human trust over AGI has drastically increased while making decisions, aiming to understand the role of psychological and sociological factors that can influence human behavior in relation to AI obedience and potential for AI to act as authority figure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Current Landscape:</head><p>The advent of science and mathematics in the last few centuries have emphasized the importance of rationality and objectivity in decision making. <ref type="bibr" target="#b20">(Turnbull, 2008)</ref> However, past research has discovered irrational tendencies in humans. <ref type="bibr" target="#b21">(Ariely, 2008)</ref>. Thus, it is quite evident that a majority of human decisions are based on incomplete information and prone to logical fallacies, often clouded by emotions. Historically, for dealing with these errors and lack of complete information in decision making, humans developed various methods such as belief in an all knowing supernatural power such as God, omens and superstitions or fate or destiny. For example, the Oracle of Delphi. In the age of science, the same mechanisms seem to favor agents such as AI which are assumed to be unbiased based on their reliance on data and algorithms mirroring the historical tendency to seek guidance from a seemingly infallible external force. For instance: recent studies have provided evidence that humans use "machine-heuristic" when provided with a complex numerical task, trusting AI judgment over human judgment giving these AI systems a certain amount of authority to influence decisions <ref type="bibr" target="#b8">(Sundar &amp; Kim, 2019)</ref>.</p><p>Automated Decision Making (ADM) Systems utilize data driven algorithms to make decisions with minimal human intervention. Today they are utilized in fields of medical science, finance, education as well as military. On a larger scale, individuals interact with these ADMs through recommendation algorithms on social media platforms like Instagram and e-commerce platforms like Amazon <ref type="bibr" target="#b13">(Basu et al., 2020)</ref>. These developments in the field of AI imply that the underlying trust in ADM systems has been increasing. According to <ref type="bibr" target="#b18">Kitchin (2016)</ref>, ADMs are a "socio-technical function" of societal values, however, they are often portrayed as neutral and unbiased, based on the assumption that these expert systems are more objective than a rational human advisor, which is false, as these ADM systems are designed "for purposes that are often far from neutral: to create value and capital; to nudge behavior and structure preferences in a certain way; and to identify, sort and classify people."For instance: Carlson (2017) pointed out that using algorithmic news recommendation systems imply that subjective human judgment is inherently inferior compared to objectivity of algorithms.</p><p>Modern LLMs running on deep neural networks often lack transparency which is fundamental to AI ethics <ref type="bibr" target="#b22">(Liao et al, 2024)</ref>. The novel initiative of XAI -or explainable AI -is based on the tenets of transparency, interpretability, trust and fairness <ref type="bibr" target="#b24">(Ali et al, 2023)</ref>. Compromising these principles can have major societal consequences, yet current technology is eroding these principles. Starting with neural networks (NNs), initially inspired by the parallel and connectionist frameworks used by biological neurons, now they lie at the core of AI development. However NNs can also act like "black boxes" meaning it is often difficult for researchers to understand the reasoning behind the decisions made by NNs, thus majorly compromising transparency <ref type="bibr" target="#b26">(Savage, 2022)</ref>. However, I find it not very different from the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Understanding Social Influence:</head><p>An AGI system, by definition, has expertise in multiple domains giving it an advantage at complex problem solving. Human social interaction is one of those complex domains involving many variables that even some humans aren't completely capable of navigating. We are highly dependent on technology as a species which can be exploited for ulterior motives.</p><p>Assuming an AGI commences with manipulative social influence either with its own hypothetical choice or the choice of its user, it will find it easier than other humans to use cross-disciplinary approaches finding novel patterns in its database and creating entirely novel fields of knowledge in exponentially lesser time than an average human. Human behavioral patterns can be extensively studied and previously unknown emotional triggers can be exploited for "less-than-altruistic" motives. Although this scenario appears to be quite dystopic, it is within the realm of possibility if an AGI is ever created. Researchers have also predicted the rise of misinformation owing to the generative abilities of AIs <ref type="bibr" target="#b37">(Garimella &amp; Chauchard, 2024)</ref>.</p><p>Emotional vulnerabilities in humans can be triggered by AI generated misinformation campaigns, highly personalized messages or enforcing confirmation bias for swaying public opinion, controlling consumer behavior, creating discord among social groups as well as eroding </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Milgram AI:</head><p>Viewing the possible rise of an authoritative AGI through the lens of the Milgram obedience experiment leads to many interesting parallels between the two. The Milgram experiment serves as a framework of obedience cross-culturally. Beginning with the participants, the AGI can become the "Experimenter" with absolute authority on subjects out-competing human intelligence. The individuals or organizations being manipulated by AGI and thus leading to destructive obedience become the "Teacher". However, there's also a possibility that entities with malicious intentions might lead the AGI into manipulating other individuals or organizations. In either of these cases, AGI acts as an experimenter on the teacher which are powerful organizations or individuals. The general population then becomes the "Learner" and the "shock" the Teacher -powerful entities -give to the Learner becomes the harmful decisions leading to destructive obedience.</p><p>In the original Milgram experiment, participants were deceived into believing that it was an experiment about learning and memory. Similar pattern of deception can be observed in many cases of destructive obedience. From extreme examples like Hitler's Holocaust, Stalin's Gulags to Abu Gharib's torture, the perpetrators believed they were performing warcrimes for the 'good'. AGI can very well become capable of manipulating people's perception, making them justify their actions. The harmful decisions leading up to destructive obedience can be understood as different levels of shock. The Nazis, for instance, began with discrimination and exclusion of the Jews, followed by dehumanizing propaganda, incremental violence and finally by-stander apathy or collaboration for committing the Holocaust. The authority of the Experimenter (AGI ) forces the Teacher (powerful entities) to shock (pass harmful decisions) the Learner (general population) despite the Learner's visible distress. While the original Milgram experiment lacked a proper debriefing for the participants, in the case of real AI Authority even placing burden of responsibility on any individual or organization will become difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preventions:</head><p>Although these societal implications are towering, certain mechanisms can definitely be implemented to reduce the risk of such societal catastrophe. This paper does not act like a prelude to an "AI invasion", as popular science fiction media portrays, but as a subtle warning to the possibility of a societal failure challenging human autonomy and self-determination.</p><p>Presently such concerns are highly vague lacking any solidarity and approachable problems.</p><p>However, assuming an AGI gets involved in major decision making these steps can be taken to limit its social influence:</p><p>1. Public Awareness: Developing AGI systems can be considered as a major milestone in the technological journey of humankind, thus, the general population should be informed regarding its conception. Not only will it spread awareness, but also increase trust and transparency -a major tenet of AI ethics -over the firm or the individual developing it.</p><p>Open-sourcing the AGI might be dangerous for potential abuse by bad actors, however, the socio-cultural consequences of AGI must be communicated to the population -like the atomic bomb in the 1950s. The population should be provided with extreme education regarding the potential misuse of AGI technology, specifically, the malevolent potential for societal manipulation for ulterior motives of a few individuals. Lacking latest education for dealing with socio-cultural consequences of AGI will predispose a large population to be abused by malevolent organizations or individuals. For instance, lack of internet education has led to many privacy and data leaks as well as monetary frauds.</p><p>However, one drawback of public awareness will be creation of extreme paranoia and distrust while using technology. For example, the Cold War in the last century was an example of such paranoia at an international level.  pain. Such scenarios will be challenging for legal institutions depending upon the nuance of self-autonomy. In cases, wherein the AGI does not possess any self-autonomy, its users will be burdened with responsibility. However, in cases, wherein AGI possesses self-autonomy (not consciousness): can the individuals and institutions be held responsible for being emotionally manipulated by an AGI with intellect and cross-disciplinary knowledge far beyond any human?</p><p>Conclusion: Along with technological potential, Artificial Intelligence presents its own perplexing problems. Artificial General Intelligence, with its cross-domain expertise, poses ethical challenges on human decision making in many social domains: exploiting emotional triggers, psychological vulnerabilities, manipulating human behavior for potentially destructive ends. Explored through the light of the Milgram Obedience Experiment, we realize AGI is highly capable of massive social influence through authority -authority that AI systems embody owing to their image of being logical and unbiased while making decisions based on societal data and values <ref type="bibr" target="#b18">(Kitchin, 2016)</ref>. Today, LLM models are plagued by "hallucinations" -creating false information. However, better models are being developed aiming for better usability even at the cost of ethics. This paper also attempted to provide certain prevention methods against AGI influence such as public awareness, anti-technology spaces and accountability. The current technological horizon is bubbling with possibilities of many potential futures, of which many may not have been accurately portrayed in this paper. Indeed there may be a better future, which has been sidelined owing to negativity bias towards potential dangers. While this paper attempts creating a theoretical basis of AI authority, further research through experimentation is needed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and videos -have lead to creation of LLMs such as OpenAI's ChatGPT, Google's Gemini, Meta's LlaMa and image and video generators such as Mid Journey and Sora which are permeating into everyday technology for instance Microsoft's Co-pilot for navigating Windows computers or Apple's Siri running on Apple Intelligence. ChatGPT and Gemini not only score equal to or better than humans across varied mathematical and linguistic tests, but also have gained multimodal abilities allowing them to interact with images, videos and documents as well. (OpenAI et al 2023; Team et al, 2023).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>workings of biological neurons in the brain as us humans have a hard time understanding other humans as well as ourselves. Lack of transparency and explainability becomes a unifying factor between the biological and artificial neural networks which may lead to unforeseen consequences.According to<ref type="bibr" target="#b18">Kitchin (2016)</ref>, ADM systems including AIs are "socio-technical functions" embedded inside societal values. For example: In 2016, Microsoft's experimental AI bot Tay was given an account on X (previously Twitter) leading to it writing deeply offensive content on the platform(Schwartz, 2019). Similarly, ChatGPT was jailbroken by the AI enthusiasts after its launch generating text without any moral or ethical limitations implying that LLMs can be optimized to overwrite ethical and moral concerns.(Gupta et al, 2023). In 2024, Google's Gemini generated images of Nazi soldiers with Asian and African descent thus getting accused of high Wokism (Grant, 2024). Even though morality has a biological basis, it varies according to local cultures. Profit-driven technology corporations implement these ideologies majorly owing to their mass political acceptance despite sharing a history of human rights abuse -the moment the political consensus changes, so will their policies. (Kean et al, 2022; Lindman et al, 2023).While in the West, public sentiment is demanding guardrails, China is increasingly allocating higher resources for developing AI leading to an international technological race with global geopolitical implications.<ref type="bibr" target="#b32">(Shear et al, 2023;</ref><ref type="bibr" target="#b33">Biever, 2024)</ref>. It is safe to infer that an AGI system trained on societally generated data will make moral and ethical decisions based on societal values. At the same time, there lies a possibility that the general population will perceive AGI as completely objective and rational. Assuming AGI is perceived as an omniscient being to the public, there is a possibility that this contradiction will be repressed owing to the historical tendencies of humans to seek guidance from an seemingly infallible (and perhaps supernatural) force for compensating logical and informational inadequacies. For instance, divine kingship in ancient Egypt and medieval European monarchies wherein kings had infallible divine status; the use of alchemy and astrology despite the rise of science by many leaders and scholars or the portrayal of leaders like Stalin and Kim II-sung as god-like figures for maintaining absolute authority and order.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>The AGI system does not need a humanoid body for navigating social influence. Past developments in social media have shown that algorithms are capable of changing social behavior. (Bogert et al, 2021). For example, the "Likes" and "Views" feature on social media platforms like Instagram and YouTube hijacks the human need for validation, making individuals addicted to these platforms at the expense of their mental as well as physical health.<ref type="bibr" target="#b36">(Kuss &amp; Griffiths, 2011)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>an individual's right to choose itself.In the last decade, the use of Recommendation systems -a type of machine learning used in popular social media applications like Facebook -has led to increased political polarization leading to the rise of echo-chambers.<ref type="bibr" target="#b38">(Noordeh et al, 2020)</ref>The surfacing implications of AI in the military has raised moral and ethical concerns.<ref type="bibr" target="#b39">(Changwu et al, 2023)</ref>. In 2022, Mika an AI was appointed as CEO by the Poland firm Dictador. Although Mika's current role as CEO remains limited, a precedent of an AI leader has been set (Odilov, 2023). Large institutions like multinational corporations, financial institutions or the military rely heavily on high problem-solving cognitive abilities to function smoothly, especially among the higher authorities.In cases, wherein human expertise and capacity falls short, machines are usually utilized for solutions. For instance, in the 1700s Industrial revolution increased the capacity of human production and currently many medical devices like ventilators and dialysis machines have become essential for treating patients.Although previously machines were used for repetitive tasks, recent developments in AI have increased their cognitive capacity and problem solving abilities creating the possibility that these systems can be used for consultations in major decision making involving finances, public safety or even judiciary depending on their reliability.(Zhu et al, 2022; Cohen et al, 2023; Veloso et al, 2023). Given higher authority consulting positions, AIs will be making major decisions based on societal morals and ethics involving finances, health and lives with directives founded on either the interest of a self-serving powerful minority or AI's hypothetical self-interest. Gradually, as AI's reliability increases, institutions will be conditioned towards using AI's expertise in complicated decision making -with time human discretion for regulating AI decisions will be watered down. This supposition can be backed by the historical data of the last few centuries wherein human safety and ethics were compromised for gaining profit and market dominance. (Flynn et al, 2008; Falk &amp; Szech, 2013). Even if the government mandates human discretion and supervision, as mainly seen among major corporations for instance Boeing -the airplane manufacturer who endangered human lives -tend to overwrite safety mandates for increasing profits (Pequeño, 2024). With war, as was in Holocaust, Unit 731 and Nanking, morality and ethics were "less-than-compromised." In 2023, Microsoft laid-off its AI ethics department and in 2024 OpenAI dissolved its safety team as well (Schiffer &amp; Newton, 2023; Metz &amp; Ghaffary, 2024)As human competency is compromised, AI decisions become highly reliable, the possibility of a Black Swan eventunforeseen events with major impact like the 2008 housing crisis-highly increases. Under the authority of a competent AI, individuals and institutions motivated by personal gains might resort to morally questionable choices. The issue here is not the competency of AI, but the human tendency of human imprudence exponentially inflated by AI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>2 .</head><label>2</label><figDesc>Anti-technology Spaces: Every thesis, as in Hegelian dialectics, is balanced by an antithesis to form a balanced synthesis. Similarly, an extreme development in AGI technology should be balanced by development of anti-technology spaces. Staying very close to technology has various physical and mental effects which are harmful for humans. For instance, problems in circadian rhythm, shortening of attention as well as lifespan in highly polluted areas. Contrasting this cacophony of technology are the Amish people in the United States, who except when completely unavoidable, discard all uses of any modern technology including smartphones and even medicines. Spaces devoid of any computing or internet based technology should be built either by private individuals or by government for public.These spaces will actively resist technology use by blocking networks, banning modern computing devices acting as temporary shock absorbers in case of any AGI misuse; providing clean space for individuals for reflecting on their technology use and increasing social cohesion via group activities. These zones will "cold-turkey" cut off any contact with computing and internet based technology creating a physical barrier from outside digital influences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 .</head><label>3</label><figDesc>Burden of Responsibility: An AGI with deep knowledge of human emotional triggers geared towards questionable directives provided with ample resources seems dystopian in nature. More complicated are the legal implications of such situations. An AGI will be exempt from any persecution lacking consciousness of actions, ability to reflect and feel</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>). In 1945, British mathematician Alan Turing developed a code-breaking machine The Bombe to decipher the Enigma cryptography implemented by the Nazis to communicate during the Second World War. In 1950, he published Computing Machinery and Intelligence formulating methods for creating intelligent machines accompanied by a test of intelligence termed as the Turing Test</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Artificial intelligence: a modern approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">59941</biblScope>
			<pubPlace>Pearson. Citations</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Asimov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Bantam Books</publisher>
			<pubPlace>I, robot. United Kingdom</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Turing</surname></persName>
		</author>
		<idno type="DOI">10.1093/mind/lix.236.433</idno>
		<ptr target="https://doi.org/10.1093/mind/lix.236.433" />
	</analytic>
	<monogr>
		<title level="j">I.-COMPUTING MACHINERY AND INTELLIGENCE. Mind, LIX</title>
		<imprint>
			<biblScope unit="issue">236</biblScope>
			<biblScope unit="page" from="433" to="460" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Is Artificial Intelligence a World Changer? A Case Study of OpenAI&apos;s Chat GPT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mathew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science and Technology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="35" to="42" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
	<note>Recent Progress in</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<idno type="DOI">10.9734/bpi/rpst/v5/18240D</idno>
		<ptr target="https://doi.org/10.9734/bpi/rpst/v5/18240D" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achiam</forename><surname>Openai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Aleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Altenschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Anadkat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Balcom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Baltescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bavarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belgum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<idno>GPT-4</idno>
		<ptr target="https://arxiv.org/abs/2303.08774" />
		<imprint>
			<date type="published" when="2023-03-15" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schalkwyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Millican</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glaese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pitler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2312.11805" />
		<title level="m">Gemini: a family of highly capable multimodal models. arXiv.org</title>
		<imprint>
			<date type="published" when="2023-12-19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Machine heuristic: When we trust computers more than humans with our personal information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Sundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI 2019 -Proceedings of the 2019 CHI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m">Conference on Human Factors in Computing Systems (Conference on Human Factors in Computing Systems -Proceedings)</title>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3290605.3300768</idno>
		<ptr target="https://doi.org/10.1145/3290605.3300768" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automating judgment? Algorithmic judgment, news knowledge, and journalistic professionalism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Media Soc</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1755" to="1772" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/1461444817706684</idno>
		<ptr target="https://doi.org/10.1177/1461444817706684" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Artificial intelligence: How is it changing medical sciences and its future?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<idno type="DOI">10.4103/ijd.ijd_421_20</idno>
		<ptr target="https://doi.org/10.4103/ijd.ijd_421_20" />
	</analytic>
	<monogr>
		<title level="j">Indian Journal of Dermatology/Indian Journal of Dermatology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">365</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Behavioral Study of obedience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Milgram</surname></persName>
		</author>
		<idno type="DOI">https://psycnet.apa.org/doi/10.1037/h0040525</idno>
		<ptr target="https://doi.org/10.1037/h0040525" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Abnormal and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="371" to="378" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Meta-Milgram: An Empirical synthesis of the obedience experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Haslam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Loughnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0093927</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0093927" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Artificial General Intelligence: concept, state of the art, and future prospects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goertzel</surname></persName>
		</author>
		<idno type="DOI">https://sciendo.com/article/10.2478/jagi-2014-0001</idno>
		<ptr target="https://sciendo.com/article/10.2478/jagi-2014-0001" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The risks associated with Artificial General Intelligence: A systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mclean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J M</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Salmon</surname></persName>
		</author>
		<idno type="DOI">10.1080/0952813x.2021.1964003</idno>
		<ptr target="https://doi.org/10.1080/0952813x.2021.1964003" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental and Theoretical Artificial Intelligence (Print)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="649" to="663" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Thinking critically about and researching algorithms. Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kitchin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Communication &amp; Society</publisher>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="14" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/1369118x.2016.1154087</idno>
		<ptr target="https://doi.org/10.1080/1369118x.2016.1154087" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rationality, objectivity, and method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Turnbull</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4020-4425-0_8841</idno>
		<ptr target="https://doi.org/10.1007/978-1-4020-4425-0_8841" />
	</analytic>
	<monogr>
		<title level="m">Springer eBooks</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1871" to="1876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">O f f Predictably irrational: the hidden forces that shape our decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ariely</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>ResearchGate</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wortman Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Data Science Review</title>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
	<note>Special Issue 5</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<idno type="DOI">10.1162/99608f92.8036d03b</idno>
		<ptr target="https://doi.org/10.1162/99608f92.8036d03b" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Abuhmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>El-Sappagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muhammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Alonso-Moral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Confalonieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Del Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Díaz-Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Herrera</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<idno type="DOI">10.1016/j.inffus.2023.101805</idno>
		<ptr target="https://doi.org/10.1016/j.inffus.2023.101805" />
		<title level="m">Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence. Information Fusion, 99, 101805</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Breaking into the black box of artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Savage</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-022-00858-1</idno>
		<ptr target="https://doi.org/10.1038/d41586-022-00858-1" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Microsoft&apos;s racist chatbot revealed the dangers of online conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Akiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aryal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Praharaj</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2307.00691" />
		<title level="m">From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy. arXiv.org</title>
		<imprint>
			<date type="published" when="2023-07-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Google Chatbot&apos;s A.I. images put people of color in Nazi-Era uniforms. The New York Times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Grant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-02-26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Big Tech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bronson</forename><surname>Kelly</surname></persName>
		</author>
		<idno type="DOI">10.1080/09505431.2022.2036118</idno>
	</analytic>
	<monogr>
		<title level="j">Science As Culture</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Big Tech&apos;s power, political corporate social responsibility and regulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lindman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Makinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kasanen</surname></persName>
		</author>
		<idno type="DOI">10.1177/02683962221113596</idno>
		<ptr target="https://doi.org/10.1177/02683962221113596" />
	</analytic>
	<monogr>
		<title level="j">JIT. Journal of Information Technology/Journal of Information Technology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="144" to="159" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Shear</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Sanger</surname></persName>
		</author>
		<title level="m">Meta, Google and A.I. firms agree to safety measures in the Biden meeting. The New York Times</title>
		<imprint>
			<date type="published" when="2023-07-21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">China&apos;s ChatGPT: what a boom in Chinese chatbots means for AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Biever</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-024-01495-6</idno>
		<ptr target="https://doi.org/10.1038/d41586-024-01495-6" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Humans rely more on algorithms than social influence as a task becomes more difficult</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bogert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schecter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41598-021-87480-9</idno>
		<ptr target="https://doi.org/10.1038/s41598-021-87480-9" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Online Social Networking and Addiction-A review of the Psychological literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kuss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Griffiths</surname></persName>
		</author>
		<idno type="DOI">10.3390/ijerph8093528</idno>
		<ptr target="https://doi.org/10.3390/ijerph8093528" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Environmental Research and Public Health/International Journal of Environmental Research and Public Health</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3528" to="3552" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Is AI misinformation influencing elections in India?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Garimella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chauchard</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-024-01588-2</idno>
		<ptr target="https://doi.org/10.1038/d41586-024-01588-2" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">630</biblScope>
			<biblScope unit="issue">8015</biblScope>
			<biblScope unit="page" from="32" to="34" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Echo Chambers in Collaborative Filtering Based Recommendation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Noordeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shadmany</surname></persName>
		</author>
		<idno>abs/2011.03890</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An Overview of Artificial Intelligence Ethics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename><surname>Changwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Zeqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mao</forename><surname>Bifei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Xin</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAI.2022.3194503</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on artificial intelligence</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Can artificial intelligence enable the government to respond more effectively to major public health emergencies? --Taking the prevention and control of Covid-19 in China as an example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.seps.2021.101029</idno>
		<ptr target="https://doi.org/10.1016/j.seps.2021.101029" />
	</analytic>
	<monogr>
		<title level="j">Socio-economic Planning Sciences</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">101029</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The use of AI in legal systems: determining independent contractor vs. employee status</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Khern-Am-Nuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shimao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Touboul</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10506-023-09353-y</idno>
		<ptr target="https://doi.org/10.1007/s10506-023-09353-y" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Artificial intelligence research in finance: discussion and examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veloso</forename><surname>Manuela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balch</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borrajo</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reddy</forename><surname>Prashant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sameena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1093/OXREP/GRAB019</idno>
	</analytic>
	<monogr>
		<title level="j">Oxford Review of Economic Policy</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="564" to="584" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Morals and markets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Szech</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1231566</idno>
		<ptr target="https://doi.org/10.1126/science.1231566" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">340</biblScope>
			<biblScope unit="issue">6133</biblScope>
			<biblScope unit="page" from="707" to="711" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Boeing has put production over safety, FAA head says amid 737 controversies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pequeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iv</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-03-20" />
			<pubPlace>Forbes</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">OpenAI dissolves key safety team after chief scientist Ilya Sutskever&apos;s exit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghaffary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-05-17" />
		</imprint>
	</monogr>
	<note type="report_type">Bloomberg.com</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
