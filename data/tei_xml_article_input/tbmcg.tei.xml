<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On logical inference over brains, behaviour, and artificial neural networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Donders</roleName><forename type="first">Olivia</forename><surname>Guest</surname></persName>
							<email>olivia.guest@donders.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Donders Institute for Brain, Cognition, and Behaviour</orgName>
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Donders Centre for Cognitive Neuroimaging</orgName>
								<orgName type="laboratory">Language and Computation in Neural Systems Group</orgName>
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Donders Centre for Cognitive Neuroimaging</orgName>
								<orgName type="laboratory">Language and Computation in Neural Systems Group</orgName>
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Max Planck Institute for Psycholinguistics</orgName>
								<orgName type="laboratory">Language and Computation in Neural Systems Group</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><forename type="middle">H</forename><surname>Forbes</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iris</forename><surname>Van Rooij</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Britta</forename><forename type="middle">U</forename><surname>Westner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><forename type="middle">J</forename><surname>Wills</surname></persName>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Institute for Brain, Cognition and Behaviour</orgName>
								<orgName type="institution">Radboud University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On logical inference over brains, behaviour, and artificial neural networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1007/s42113-022-00166-x</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cognitive computational neuroscience</term>
					<term>cognitive science</term>
					<term>logic</term>
					<term>philosophy of science</term>
					<term>scientific inference</term>
					<term>metascience</term>
					<term>metatheory</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In the cognitive, computational, and neuro-sciences, practitioners often reason about what computational models represent or learn, as well as what algorithm is instantiated. The putative goal of such reasoning is to generalize claims about the model in question, to claims about the mind and brain, and the neurocognitive capacities of those systems. Such inference is often based on a model&apos;s performance on a task, and whether that performance approximates human behavior or brain activity. Here we demonstrate how such argumentation problematizes the relationship between models and their targets; we place emphasis on artificial neural networks (ANNs), though any theory-brain relationship that falls into the same schema of reasoning is at risk. In this paper, we model inferences from ANNs to brains and back within a formal framework-metatheoretical calculus-in order to initiate a dialogue on both how models are broadly understood and used, and on how to best formally characterise them and their functions. To these ends, we express claims from the published record about models&apos; successes and failures in first-order logic. Our proposed formalisation describes the decision-making processes enacted by scientists to adjudicate over theories. We demonstrate that formalising the argumentation in the literature can uncover potential deep issues about how theory is related to phenomena. We discuss what this means broadly for research in cognitive science, neuroscience, and psychology; what it means for models when they lose the ability to mediate between theory and data in a meaningful way; and what this means for the metatheoretical calculus our fields deploy when performing high-level scientific inference.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reasoning about what our models contribute to our research is core to the computational neuro-and cognitive sciences. How do we relate the behaviour of our models with psychological and neural data? In this paper, we address how common metascientific syllogisms -specifically ones that seem to be imported from the neighbouring fields of artificial intelligence and machine learning -can be viewed from a formal lens. Herein, we specify and characterize reasoning in the field of cognitive computational neuroscience using formal logic in order to dissect the implications both of the reasoning itself and of what such a formal treatment grants us metascientifically.</p><p>The field of cognitive computational neuroscience, as well as its surrounding academic environns, has no doubt been radically changed by the onslaught of powerful computation, combined with the ease with which models can be constructed and applied to data, e.g., services and tools such as Keras, which provides an accessible deep-learning Python library that takes advantage of graphical processing units and high performance computing services <ref type="bibr" target="#b6">(Chollet &amp; Others, 2015)</ref>. A deep artificial neural network (ANN) model -a model composed of more than two layers of individual units, which compute a summation and typically nonlinear transformation of the output of upstream units -can be created and easily trained using, e.g., back-propagation. Such an ANN can be then used as a model for brain and behaviour. However, this progress in accessibility of computational tools and resources also has had ramifications for how we construct logical arguments and conceive of inference within science. This is especially true for the logical inference rules we apply in the metatheoretical decision-making processes within the cognitive, computational, and neurosciences, which includes determining which theories and models are useful and which are less so (cf. <ref type="bibr" target="#b64">Rich, de Haan, Wareham, &amp; van Rooij, 2021)</ref>. Importantly, "[ANNs are] intended to duplicate from the neural system [the] abstract computational or information processing capacity." <ref type="bibr">(Chirimuuta, 2021, p. 772)</ref> To wit, given that we as a field "are [often] relying on these models as proxies for theories" <ref type="bibr">(Leeds, Seibert, Pyles, &amp; Tarr, 2013, p.</ref> 3), they deserve careful theoretical scrutiny. To make clear the difference between our formalisation (i.e., our model) and the literature (i.e., the phenomenon), we dub our formalisation of the collection of both currently formal and informal inferences rules over theories, our "metatheoretical calculus". In other words, metatheoretical calculi are proposed formalisations, i.e., models, of the way we think, created explicitly to help us reason about how we think, to facilitate communication on how we evaluate our thoughts, and to allow for improvements to both.</p><p>As we shall discuss herein, many of the same metatheoreitcal reasoning problems faced by the original conception of connectionism persist in cognitive computational neuroscience. As such, even though nobody disputes that connectionism has "undoubted merits" <ref type="bibr" target="#b3">(Broadbent, 1985)</ref>, the way we reason about such models will likely benefit from a comprehensive formal analysis, i.e., our metatheoretical calculus. Thus, allowing us to problematise our framings of our modelling endeavours, e.g., question what mechanistic understanding ANNs can provide. Notwithstanding, it is clear that ANNs as a modeling "framework can pave the way to new categories of scientific questions" <ref type="bibr">(Barak, 2017, p. 4</ref>), provided we bear in mind that "it is not enough to know how similar a given model is to the brain: we also need to know why." <ref type="bibr">(Truzzi &amp; Cusack, 2020, p. 1)</ref> This article joins the chorus of many other calls for better theory and metatheory (e.g., <ref type="bibr" target="#b13">Bowers et al., 2022;</ref><ref type="bibr" target="#b17">Firestone, 2020;</ref><ref type="bibr" target="#b20">Funke et al., 2020;</ref><ref type="bibr" target="#b21">Geirhos, Meding, &amp; Wichmann, 2020;</ref><ref type="bibr" target="#b28">Jonas &amp; Kording, 2017;</ref><ref type="bibr" target="#b44">Ma &amp; Peters, 2020</ref>)but we clarify, extend, and substantiate the argument a) by describing, and formalizing, the discursive pattern of inferences found in the cognitive computational (neuro)sciences, by using a formal logical framework we dub a metatheoretical calculus, b) by demonstrating how behaviour, as evidenced in the literature in the form of natural language statements, when formalised can comprise a common logical fallacy, and c) by analysing the consequences of our metatheoretical calculus on how scientists working in the cognitive (neuro)sciences discuss and frame inferences in experimental and theoretical settings. We conclude by offering a synthesis on scientific reasoning and the desiderata for improving our inferential practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The current state of cognitive computational neuroscience</head><p>Cognitive computational neuroscience (CCN) can be conceptualized as the field of scientific inquiry that aims to provide "mechanistic explanations for how the nervous system processes information to support [cognition and behaviour]" <ref type="bibr">(Kietzmann, McClure, &amp; Kriegeskorte, 2019, p. 2)</ref>. A mechanistic explanation involves describing how holistic properties of a complex system emerge from the causal interactions of its constituent parts <ref type="bibr" target="#b16">(Falkenburg &amp; Schiemann, 2019;</ref><ref type="bibr" target="#b29">Kaplan, 2011)</ref>. To reach this goal of producing useful mechanistic explanatory theories for brain, cognition, and behaviour, CCN uses various types of formal(isable) and computational techniques -both as cognitive models and as statistical tools to uncover signal within brain activity (cf., <ref type="bibr" target="#b7">Cichy &amp; Kaiser, 2019;</ref><ref type="bibr" target="#b31">Kay, 2018)</ref>. Herein, we evaluate the cases in which ANNs instantiate, or stand in for, theories that furnish us with mechanistic understanding or explanation at the level of the nervous system.</p><p>A series of mainstream methodological techniques used in CCN that were developed originally by another subfield of cognitive science, specifically mathematical psychology (see <ref type="bibr" target="#b52">Navarro, 2021;</ref><ref type="bibr" target="#b70">Shepard &amp; Chipman, 1970)</ref>, have shown that computing correlations over correlations can provide useful insights in terms of the structure and relationships between and within stimulus representations and between and within different organisms and models (cf., <ref type="bibr" target="#b13">Dujmović, Bowers, Adolfi, &amp; Malhotra, 2022)</ref>. For example, we "correlate a brain region's RDM [representational dissimilarity matrix; a second-order isomorphism of internal representations] with an RDM based on one or multiple stimulus parameters (or with an RDM predicted by a computational model), [to obtain] the correlation between the two RDMs." <ref type="bibr">(Kriegeskorte et al., 2008, p. 367)</ref> Based on the discovery of such correlations over correlations, CCN proposes a theoretical position about the contents of brain states, e.g., "our IT-geometry-supervised deep representation fully explains our IT data" (emphasis added; Khaligh-Razavi &amp; <ref type="bibr">Kriegeskorte, 2014, p. 24)</ref>, or that using ANNs "explains brain activity deeper in the brain [and such models] provide a suitable computational basis for visual processing in the brain, allowing to decode feed-forward rep-resentations in the visual brain." (emphasis added; <ref type="bibr">Ramakrishnan, Scholte, Lamme, Smeulders, &amp; Ghebreab, 2015, p. 371)</ref>. Furthermore, some propose that "[t]o the computational neuroscientist, ANNs are theoretical vehicles that aid in the understanding of neural information processing" (emphasis added; van Gerven &amp; Bohte, 2017, p. 1). This betrays very strong assumptions in CCN about the explanatory virtue of correlational results and how metatheoretical inferences are drawn. This specific belief system involving correlation could be seen as the result of importing the <ref type="bibr">Turing test (Turing, 1950)</ref> from computer science and philosophy of mind to CCN, without bearing in mind that the Turing test is not per se useful for furthering a mechanistic understanding, but rather for elucidating functional roles. The Turing test, in its most abstract form, evaluates if an engineered system, like a chatbot, can converse in such a way as to pass as human, i.e., can an algorithm convince a human judge that it is indistinguishable from a human? If yes, then the machine is said to have passed the Turing test and on that -functional, correlational, but not mechanistic -basis be human-like. The insights from the engineering-oriented Turing test, can lead CCN astray if we do not methodically take into account the principle of multiple realizability <ref type="bibr" target="#b18">(Fodor &amp; Pylyshyn, 1988;</ref><ref type="bibr" target="#b59">Putnam, 1967;</ref><ref type="bibr" target="#b61">Quine, 1951)</ref>: dramatically different substrates, implementations, mechanisms, can nonetheless perform the same input-output mappings (i.e., can correlate with each other without being otherwise "the same").</p><p>Given the above discourse, what do scientists need to bear in mind when in the driving seat of these "theoretical vehicles"? How, and what do these ANNs "explain"how, and why do they aid in "understanding"? What sort of "new framework" <ref type="bibr" target="#b35">(Kriegeskorte, 2015)</ref> are ANNs providing us with in CCN? Calculating the correlations between our models and our empirical observations is necessary for evaluating and refining our theoretical accounts -but it is not sufficient <ref type="bibr" target="#b65">(Roberts &amp; Pashler, 2000)</ref> without awareness and caution when we theorize about the scientific repercussions of such modelling work. This is especially so when the focus of CCN is to hone our mechanistic understanding by "explain[ing] rich measurements of neuronal activity and behavior in animals and humans by means of biologically plausible computational models that perform real-world cognitive tasks." <ref type="bibr">(Kriegeskorte &amp; Douglas, 2018, fig.</ref> 2) We will return to this point in the Discussion section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lest we be hoisted by our own petard</head><p>The inference rules that we deploy in the computational, neuro-, and cognitive sciences, as well as CCN specifically, to decide which theories are plausible, are supported by data, or deserve attention and consideration are often left implicit Furthermore, such inferences can even be drawn automatically and unconsciously <ref type="bibr" target="#b63">(Reverberi, Pischedda, Burigo, &amp; Cherubini, 2012)</ref>. By formalising these rules into a metathe-oretical calculus we can charactise transparently the mechanism by which we frame and propel our research "forwards," and by which we come to agreement about what we know in CCN. An ongoing trend in CCN, as already touched on, is using ANN models to make strong claims about what the brain, and by extension the whole human organism, is and does. From the classical connectionist approach: "[the] match between model and [human] performance <ref type="bibr">[...]</ref> suggests that the representations and processes in the model may provide a good analog to those in the human semantic system" (emphasis added; <ref type="bibr">Rogers et al., 2004, p. 229)</ref> and the model can learn the task "suggest[ing] that infant sequential statistical learning is underpinned by the same domain-general learning mechanism that operates in auditory statistical learning and, potentially, also in adult artificial grammar learning." (emphasis added; <ref type="bibr">Mareschal &amp; French, 2017, p. 8)</ref> However, it must be noted that the points herein are not dependent on the waxing and waning status of ANNs within the computational sciences generally. On the contrary, these issues apply to all types of metatheorising over formal and computational modelling (cf. <ref type="bibr" target="#b24">Guest &amp; Martin, 2021</ref>) that might be deploying malformed, or at least formally unexamined, inference rules. In the next few sections, we will explicate specific cases of how our reasoning within CCN is sub-par and we will typify how we (mis)use models to mediate between theory and data.</p><p>Inference rules in (mis)use "[T]here are no logical forms or scientific truths in nature. Knowledge is [humanity's] construct." <ref type="bibr">(Wald, 1975, p. 1)</ref> In this section, we present a metatheoretical calculus to capture sentences as found in the wild, in the CCN literature. As mentioned, a metatheoreitcal calculus is a proposed formalisation of the current discursive trends seen in a field of study, serving as a model of the way we think about our theories, the relevant oberservations, and the computational models that mediate between the two. We grant our metatheoretical calculus the right to be a formal model worthy of capturing some aspects of how we think about CCN, but, to presage what is to come, we will show how and why it reaches a paradox. Formalisation this way, we propose, is a useful exercise because inter alia "sentence meanings are poised to be automatically inferentially promiscuous" (Quilty-Dunn, 2020, p. 171).</p><p>A widely deployed inference rule 1 to motivate and rationalize the use of ANNs within CCN can be readily observed in the literature as what appears to be -i.e., can be form- nally captured in a metatheoretical calculus as -modus ponens (MP). MP has the form:</p><formula xml:id="formula_0">P → Q, P ⊢ Q,</formula><p>which can be read as: if P then Q; P is true; therefore Q is true. It is commonly deployed thus (using phraseology from <ref type="bibr" target="#b62">Ramakrishnan et al., 2015)</ref>:</p><p>If ANNs are correlated with fMRI data, then ANNs are "a suitable computational basis" for the brain. (P → Q)</p><p>ANNs are correlated with fMRI data. (P) Therefore, ANNs are "a suitable computational basis" for the brain. <ref type="bibr">(⊢ Q)</ref> This is also the case where animals are used as models (using phraseology from <ref type="bibr" target="#b37">Kriegeskorte et al., 2008)</ref>:</p><p>If monkey IT is correlated with human IT, then the same "behaviourally important categorical distinctions" exist in both species. (P → Q)</p><p>Monkey IT is correlated with human IT. (P) Therefore, the same "behaviourally important categorical distinctions" exist in both species. (⊢ Q)</p><p>Generalizing the syllogism, we get the following conditional to which we, as a field, apply MP:</p><p>If the model correlates with human behavioural and/or neuroimaging data, then the model does what humans do. (P → Q)</p><p>The model correlates with human behavioural and/or neuroimaging data. (P) Therefore, the model does what humans do. (⊢ Q)</p><p>In other words, the field (by virtue of using MP) is asserting (based on what is presented as empirical evidence) that P is true. We, as a field, are also asserting that the conditional (P → Q) is a useful and/or verisimilar formulation of what we believe about the brain and behaviour (see <ref type="figure">Figure 1a)</ref>. To presage the next section, this is in fact a type of "pizza problem" <ref type="bibr" target="#b24">(Guest &amp; Martin, 2021</ref>) -while superficially formal(ised) and seemingly sensible, it is in fact unfounded and goes against our expressed empirical and theoretical understanding of cognition. Additionally, by the same token we have granted ourselves the ability to express ourselves and derive truths using MP, we also (by definition) could deploy modus tollens (MT); see <ref type="figure">Figure 1</ref>. MT has the form:</p><formula xml:id="formula_1">P → Q, ¬Q ⊢ ¬P</formula><p>Thus, in this case, MT (see <ref type="figure">Figure 1b</ref>) would take the form:</p><p>If the model correlates with human behavioural and/or neuroimaging data, then the model does what humans do. (P → Q)</p><p>The model does not do what humans do. (¬Q) Therefore, the model does not correlate with human behavioural and/or neuroimaging data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(⊢ ¬P)</head><p>For example, we could deploy MT in the case of ANNs' visual object recognition diverging greatly from people's, e.g., when ANNs encounter (i.e., when we engineer) adversarial images as input <ref type="bibr" target="#b73">(Szegedy et al., 2014)</ref>. Adversarial images are collections of pixels that do not look at all to a human observer like the class label(s) returned by the ANN. They typically look (to a human) like totally unrelated images of scenes or objects. Something encoded in the pixels, but imperceptible to humans, has been perturbed and so, e.g., a photo of what is "obviously" a panda is classified as a gibbon by the ANN; or, e.g., an image of something abstractlooking (like stripes or some other texture or repeating pattern) is classified as a specific object or scene (for more examples see: <ref type="bibr" target="#b14">Dujmović, Malhotra, &amp; Bowers, 2020)</ref>.</p><p>When the models, in such adversarial cases, fail to classify images like a human, we do not conclude that this makes ANNs by definition unhuman-like. We do not construct this MT-based syllogism, even though nothing explicitly stops us since we happily deploy MP above (see <ref type="figure">Figure 1</ref>):</p><p>If the model correlates with human classification on photorealistic stimuli, then the model is impervious to adversarial images. (P → Q)</p><p>The model is not impervious to adversarial images (¬Q) Therefore, the model does not correlate with human classification on photorealistic stimuli. (⊢ ¬P)</p><p>Instead, we tend to conclude that either the way the ANN has been trained, or otherwise designed, is dramatically different to humans (for example, <ref type="bibr" target="#b14">Dujmović et al., 2020;</ref><ref type="bibr" target="#b21">Geirhos et al., 2020;</ref><ref type="bibr" target="#b41">Linzen &amp; Leonard, 2018)</ref> or alternatively that indeed there is potentially something human-like about the (mis)classification of adversarial images (for example, <ref type="bibr" target="#b15">Elsayed et al., 2018;</ref><ref type="bibr" target="#b82">Zhou &amp; Firestone, 2019)</ref>. In other words, instead of MT, scientists claim that ANNs that diverge from human performance need only to be modified somehow. They need to be further "aligned" with brain and behaviour data <ref type="bibr" target="#b56">(Peterson, Abbott, &amp; Griffiths, 2016)</ref> and/or they need to further "incorporate" cognitive mechanisms <ref type="bibr" target="#b43">(Luo, Roads, &amp; Love, 2020)</ref>. Thus, it is widely accepted that "to achieve human level performance, [such models] will need to [incorporate] characteristics of natural intelligence" <ref type="bibr">(McClelland &amp; Botvinick, 2020, p. 25)</ref>. Once "updated" in these ways, ANNs will, for example, "not be subject to adversarial [images] that seem so bizarre to humans, and will show the same set of strengths and weakness[es] (visual illusions) that characterize human vision." <ref type="bibr">(Dujmović et al., 2020, p. 13)</ref> We often entertain models that can do things that humans cannot. For example, we employ models with superhuman memory or that can learn statistical dependencies that are outside the scope of human perception (viz., all ANN, but especially deep, recurrent, and convolutional architectures can learn beyond human capacity in certain circumstances and tasks, ergo the logic and benefit of applying such systems in machine learning). But we do not take this capacity as evidence that the model is failing to approximate human behaviour. Similarly, any model that can reproduce a pattern of neural activity is likely to be able to produce a pattern of activation that the human brain does not or cannot produce. Yet, this inconsistency is not an impediment to our field's logical inference practice. Even though Q can, and often does, fail to be true, we, as a field, do not formulate its relationship to P in terms of MT. This is prima facie untenable -a heightening of contradictions within CCN's metatheoretical calculus -given the rules of formal logic. If MT is dis-preferred, predominantly avoided, treated similarly to how negative evidence is treated in scientific inference, why is MP accepted?</p><p>Affirming the consequent Herein, we have presented a metatheoretical conditional statement that we in CCN subscribe to:</p><p>If the model correlates with human behavioural and/or neuroimaging data, then the model does what humans do. (P → Q)</p><p>The structure of this argument is inappropriate in two important, related ways. First, it is inappropriate because we propose that nobody explicitly believes this about complex systems like the brain. So even though the CCN literature often deploys MP based on this, the conditional is not how we, as a field, evaluate models more broadly. Correlation of our models to data, i.e., a good fit, is necessary but not sufficient <ref type="bibr" target="#b65">(Roberts &amp; Pashler, 2000)</ref>. CCN is an outlier in terms of the centrality of seemingly malformed premises and ill-posed arguments within the rhetoric provided to support why ANNs are useful models. In other words, modelsin cognitive science generally -are evaluated with more metatheoretical awareness than merely checking if they correlate with data, or have the highest r-squared. Theoretical contributions definitionally must be evaluated not primarily on their predictive power (which makes sense for statistical data models), but on their explanatory virtue. Computational and/or formal models in cognitive science are indeed often juxtaposed to a swathe of empirical evidence to show they can recapitulate behavioural or neuroimaging data <ref type="bibr" target="#b24">(Guest &amp; Martin, 2021)</ref>. But imagine if we only evaluated cognitive models based on the amount of variance explained (viz., rsquared or AIC/BIC), or if correlation was the only criterion for identity? How many things would we confuse with the brain or as the arbiter of behaviour (cf. Meijer, 2021, for an example with cryptocurrency and rodents)? Thus, inferences to "models doing what humans do" (i.e., our Q) based on such correlations are not permitted due to lacking theoretical and empirical support. In other words, as we shall explain, P → Q is a problematic construction if it is not explicitly tethered to or embedded in the context where the inference is taking place.</p><p>The nature of our inferences can be improved if we take a few steps back and consider our theorising before asserting correlation is a stand-in for causation or explanation. For example, consider what "explain" means in these extracts: "computational models from computer vision and neuroscience can explain the [inferior temporal cortex] representational geometry in human and monkey" (emphasis added; Khaligh-Razavi &amp; <ref type="bibr">Kriegeskorte, 2014, p. 23)</ref> or "intermediate model layers best explain primary auditory cortical responses, while deeper layers best explain voxels in non-primary areas." (emphasis added; Kell, Yamins, Shook, Norman-Haignere, &amp; McDermott, 2018, p. 631) Correlation is typically highly conceptually distinct from explanation, but here it is identically used (cf., <ref type="bibr" target="#b11">Cummins, 2000)</ref>.</p><p>This brings us to the second reason that the conditional presented is malformed: it is not an appropriate description, model, of the empirical evidence and theories we have at our disposal. Thus, it neither describes the status of (meta)theoretical claims we, as a field, make with respect to models (i.e., the high-level calculus we use to evaluate theory), at least outside CCN, nor is it backed-up by any evidence. Importantly, when we speak about our scientific findings we have to do so in ways that are consistent with our field's beliefs and assumptions. Alternatively, if we disagree with the beliefs and assumptions of our field, we must do so explicitly and in a clear and transparent way.</p><p>Based on the above, we in CCN are implicitly affirming the consequent within the metatheoretical calculus we have provided. The proper relationship between P and Q is the converted (i.e., the order is swapped) conditional to that which is described (see <ref type="figure">Figure 1c and d</ref>):</p><p>If the model does what people do, then the model correlates with human behavioural and/or neuroimaging data. (Q → P)</p><p>What we previously called MP is not MP -it is affirming the consequent:</p><p>The model correlates with human behavioural and/or neuroimaging data. (P) Therefore, the model does what humans do. (⊢ Q)</p><p>If we want to computationally model in CCN we could explicitly propose: if our model is capturing something mechanistic <ref type="bibr" target="#b10">(Craver &amp; Kaplan, 2020;</ref><ref type="bibr" target="#b30">Kaplan &amp; Craver, 2011)</ref>, as well as its functional role, about the brain and behaviour (Q), then we collect evidence (i.e., correlate the model with empirical observations) to test, support, and improve our model (P). Converting, flipping the order of, this manifestation of the conditional demonstrates not only that P → Q could lead to a fallacy, but also highlights that it is unlikely that we affirm the consequent so brazenly in other, broader, scientific contexts (compare the four panels in <ref type="figure">Figure 1)</ref>. In other words, Q → P highlights the metascientific relationship between P and Q. The "sense" of Q is not contained in the "sense" of P <ref type="bibr" target="#b72">(Sundholm, 1994)</ref> -but vice versa. The potential presence of this fallacy in, or of readers automatically drawing this inference from, influential papers in the literature indicates a likely confusion between types of inference (cf. <ref type="bibr" target="#b1">Blokpoel, Wareham, Haselager, Toni, &amp; van Rooij, 2018)</ref>, a misunderstanding of the evidentiary role correlation plays, and a lack of formalized thought on the relationship between model and observation.</p><p>In this way, ill-posed argumentation is unwittingly permitted during (meta)scientific inference in CCN. The "state of affairs" in CCN does not "obtain", i.e., it can never be a true statement about the world <ref type="bibr" target="#b72">(Sundholm, 1994)</ref>. That is to say, the empirical universe that we collect observations from is not set up, as far as we know, to support P → Q; see <ref type="table">Table 1</ref>, for a synopsis of the authors' claims. And so the literature containing these "curious shadowy" <ref type="bibr" target="#b67">(Russell, 1918)</ref> syllogisms will never obtain, i.e., will never make P → Q a verisimilar proposition, description, of the causal relationship -it will always be falsified. The only way we can envisage a state of affairs in CCN obtaining is if we explicitly commit to Q → P (recall <ref type="figure">Figure 1)</ref>. This issue is not uniquely explainable by claiming that we do not know how to use formal logic, or specifically that we affirm the consequent. A big part of this, we propose, is a loss of clarity between materially licensed <ref type="bibr" target="#b55">(Norton, 2003)</ref> induction, using what we know about computers and cognition, and inferences, including inductive ones, which otherwise do not obtain <ref type="bibr" target="#b72">(Sundholm, 1994</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How we fall(acy)</head><p>"And if thou gaze long into an abyss, the abyss will also gaze into thee." <ref type="bibr" target="#b54">Nietzsche (1886)</ref> Metatheoretical considerations Typical (meta)theories in CCN take on forms such as "the brain does what the ANN model does because the ANN model was trained on the same type of data as the brain" or "cognition works this way because the ANN model learned to approximate task performance." Through this, we propose CCN permits, leaves the door open to, a logical fallacyaffirming the consequent -to be deployed when interpreting computational modelling successes (MP), but not failures (MT).</p><p>We, the authors, wish to warn against overextending, or indeed wrongly deploying, these types of syllogisms. To close the door on this possibility, we must scrutinise how we discuss our work. "Although these models have been developed with engineering goals rather than neurocognitive plausibility in mind, recent neuroimaging studies have shown a remarkable correspondence between the layers of [ANNs] and activation patterns in the visual system." (emphasis added; Devereux, Clarke, &amp; Tyler, 2018) This is not a fallacy; it is a statement about the current state of research in CCN. However, overextending the above can result in assuming that the close match between model layers and observations from imagining the brain implies "neurocognitive plausibility" -a phrase commonly used to mean that the model mechanistically, not just functionally, matches the brain. Similar arguments, open to overextending, can be found in many sub-areas of CCN, such as that ANNs are "a novel biologically feasible computational framework for studying the neural basis of language." (emphasis added; <ref type="bibr" target="#b22">Goldstein et al., 2021)</ref> The problem is that we do not yet know, or agree on, what the brain's mechanisms are -this is the stated goal of CCN -and so we cannot claim that something is more or less "plausible" without conceptually engineering <ref type="bibr" target="#b4">(Chalmers, 2020;</ref><ref type="bibr" target="#b42">Love, 2021)</ref> "plausibility", thus shutting the door to it functioning as a weasel word <ref type="bibr" target="#b27">(Jason, 1988)</ref>. Importantly, CCN does not only deploy neural networks as (neuro)cognitive models, but also uses ANNs as black box models (cf. <ref type="bibr" target="#b34">Kietzmann et al., 2019)</ref>, performing in both cases similar (meta)theorising -for example, "[t]he fact that recognizable features of stimulus images could be reconstructed with a simple linear model [what we have generalised to statement P in this paper] indicates that the latent space represents properties that are also represented in brain activity <ref type="bibr">[Q]</ref>." (emphasis added; Seeliger, Güçlü, Ambrogioni, Güçlütürk, &amp; van Gerven, 2018, p. 781) Similarly, "computer vision recognition systems may serve as viable proxies for theories of intermediate visual object representation." (emphasis added; <ref type="bibr">Leeds et al., 2013, p. 1)</ref> Notwithstanding, there is more mindful phraseology in the broader connectionist literature, e.g., "[t]he close match between model and [observations] suggests that the representations and processes in the model may provide a good analog to those in the human semantic system" (emphasis added, <ref type="bibr">Rogers et al., 2004, p. 229)</ref>; as well as in CNN, e.g., "[t]he categorical and continuous aspects of the representation are both consistent between man and monkey, suggesting that a code common across species may characterize primate IT." (emphasis added, <ref type="bibr" target="#b37">Kriegeskorte et al., 2008, p.</ref> 1138) The use of "may" makes the syllogism probabilistic modus ponens in a clear way, which might not leave the door open to accidentally affirming the consequent. Importantly, however, this is only true in a fully formal setting and natural language can still lead to affirming the consequent <ref type="bibr" target="#b9">Collins, Krzyanowska, Hartmann, Wheeler, &amp; Hahn, 2020;</ref><ref type="bibr" target="#b60">Quilty-Dunn, 2020;</ref><ref type="bibr" target="#b63">Reverberi et al., 2012)</ref>. Avoiding affirming the consequent can also be subserved by the clarification that ANNs "may simply rely on brute-force memorization and interpolation to learn how to generate the appropriate linguistic outputs in light of prior contexts" (Goldstein et al., 2021) -something which does appear to be true in certain contexts <ref type="bibr" target="#b81">(Zhang, Bengio, Hardt, Recht, &amp; Vinyals, 2016)</ref>. Others solve this by carefully couching their findings as explicitly correlational where applicable, hand-inhand with conceptually analysing the capacity under study (e.g., <ref type="bibr" target="#b40">Lindsay &amp; Miller, 2018;</ref><ref type="bibr" target="#b53">Nicholson &amp; Prinz, 2020)</ref>. Either way, leaving our syllogisms ambiguous -this includes not explaining that it is Q → P and not P → Q -leads to, or at least does not protect from affirming the consequent. The consequent and antecedent in our writings must be explicitly "the right way round" exactly because confusion exists.</p><p>Relatedly, data from the brain is not inherently mechanistically informative in and of itself, keeping in mind that CCN is about uncovering mechanisms. Just like behavioural data, neuroimaging and other types of brain data (e.g., single-cell recordings) do not constitute a mechanism. However, such data, as holds for all types, can indubitably aid in adjusting our mechanistic understanding during theory building. An understanding of mechanism is gifted to us by theoretical proposals for such mechanisms, for which we then collect evidence. Recall it is "if the model captures human capacity, then the model approximates human data" (Q → P; see section "Affirming the consequent") and not vice versa -</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Key concept</head><p>Function Obtaining, the property of a syllogism or argument, when expressed within a formal system, to be true* given the particular world the argument it is situated in, is a vital property of metatheorising and relating models to phenomena.</p><p>Whether our metatheoretical calculus (the relationship we propose between models and observations) obtains is a function of how we relate our models to the cognitive and neural systems we wish to understand and describe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impediments to inference</head><p>Proposed solutions The literature explicitly or implicitly applies deductive argument forms to inductive reasoning; the relationship between model, explanandum, and explanans is inconsistent or obscure.</p><p>Focus on precise formulation of the relationships between models and the phenomena they are trying to capture, i.e., focus on obtaining.</p><p>ANNs are useful models for the brain, behaviour, and cognitive capacities; both as proof-of-concept models, and as mechanistic models.</p><p>In terms of mechanism, ANNs may or may not resemble the cognitive and neural systems that their behavior or performance approximates. However, models must relate to the phenomenon they purport to explain in ways that obtain. The models resemble the phenomena because they indeed somehow capture (our beliefs about) the essence of the phenomena, and not vice versa, i.e., models are not capturing the essence because they are correlated with the phenomenon. We often deploy a metatheoretical calculus that constructs syllogisms or arguments that do not obtain in CCN. Models often relate to their phenomena in ways that do not respect the causal structure we already commit to as a field, will never obtain. When the causal arrow that mediates the relationship between model and phenomenon is the wrong way round, the empirical universe cannot be truth-making for that relationship, by definition.</p><p>We must ask ourselves:</p><p>• do our beliefs about complex systems, such as the principle of multiple realizablity, ever make our metascientific calculus true as described herein?</p><p>• is the world populated by cognitive and neuroscientific observations set-up to be truth-making for the causal relationship between a given model and the world?</p><p>The way to rectify the relationships between models and phenomena, e.g., between ANNs and cognitive capacities, is to express the relationships explicitly and with directionality. Additionally, probabilistic inference is subject to the same constraints, because it has the same stipulations about how causal relationships may obtain, i.e., if the empirical universe is not setup to ever make their premises be true. <ref type="table">Table 1</ref> The authors make the following core claims about modelling work in CCN. *The meaning of truth here is merely formalism within the given system, in our case formal logic. This is not to imply any notion of truth other than that fully inside a formalized system. causation implies correlation and not vice versa. These types of data, in fact all data, support (or not) our theoretical proposals, but they do not constitute them. Data are useful for building theories, but they are not sufficient in and of themselves to form a theoretical account. Data is collected with the intention to support some theoretical position, and thus is imbued with theoretical assumptions. However, and for that reason, data are not identical to a theory. Q → P obtains, while P → Q does not, and results in a fallacy when modus ponens is applied.</p><p>Another possibility is that a common belief in the field could be that a model approximating (through multiple extensions or expressions, including model behavior, processing, or output) or quantitatively predicting (again via multiple extensions) human behavior or neural data is equivalent to "providing an explanatory model." This has in it the spirit of modelling natural phenomena in order to better understand them, however, the question then becomes, what would that mean for an ANN to be an explanatory model of brain computation? If one thinks that an ANN (and its behavior, performance, or processing patterns) constitute an explanatory model of 'how the brain does x,' then what does that belief entail? If we charitably assume that what our field considers to be explanatory are mechanisms that are extensions of the causal structure of a natural phenomenon (a la <ref type="bibr" target="#b10">(Craver &amp; Kaplan, 2020;</ref><ref type="bibr" target="#b30">Kaplan &amp; Craver, 2011)</ref>), then, it implies that thinkers in the field believe that some essential property, or properties, of ANNs explain how the brain does X because they serve as mechanisms. What could those properties be? How are they mechanistic? To begin to answer both questions, we would encourage the field to name these properties explicitly and conceptually analyze whether they constitute mechanisms. For example: Contemporary deep learning ANN typically form tessellated linear mappings, or diffracted hyperplanes, between input and output spaces. Diffraction makes the mappings appear nonlinear, and the degree of tessellation is a function of the input space and the depth or number of layers. Functions like RELU or softmax on outer layers force discontinuity on the output space, thereby creating the non-linearity between input and output space. In this sense, the output is a nonlinear transformation of the input space. By analogy, is the claim then that how the brain does a computation, or "does x" is by performing a nonlinear transformation of an input? That must be true. But, because this generic statement (just a description of the defining properties of a deep ANN) indeed describes everything the brain does, it does not explain what the brain computes, nor how it does so. It is sadly rendered trivial. In other words, if ANN are to ever offer a mechanistic explanation of brain computation, much work must be done to determine whether that mechanism can be anything other than logistic regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Functionalism versus mechanism-ism</head><p>What do "mechanism" and "functional role" mean in the context of modelling in CCN, and in neuro-, cognitive computational sciences generally? Importantly, we do not doubt that all relevant types of data do indeed give us "a key opportunity to test [and refine] several planks of the deep learning hypothesis" <ref type="bibr" target="#b68">(Saxe, Nelli, &amp; Summerfield, 2020)</ref> or indeed any relevant theories or hypotheses. However, there are other "planks" (as <ref type="bibr">Saxe et al., 2020, also note)</ref>. How that data is used metatheoretically matters as much as, e.g., what statistics we can compute between and within observations and ANNs. In other words, we have to form metatheoretical syllogisms that involve this data and their relationship to our models. Analysing and understanding these syllogisms is key to doing science openly, coherently and consistentlywe shut the door to formal logical fallacies. Let us, therefore examine the reasons why P → Q does not obtain.</p><p>Functional role can be seen as the high-level description in terms of how inputs are transformed into outputs, e.g., describing the capacity of children to perform addition as "children perform addition". Mechanism is the way in which a function is implemented in a physical substrate, e.g., humans can perform addition mentally or using a calculator. Functional role and mechanism are confusing without a given level of analysis or context. For example, "a computer programme has functional transparency if it is possible to know the algorithm that the programme instantiates" <ref type="bibr">(Chirimuuta, 2021, p. 780)</ref>. However, that is not how code works in practice at lower levels of analysis. Much like when understanding cognition we might not understand what individual neurons are doing we do not (need to) know how our, e.g., R code is turned into machine code and what algorithms the hardware is using -mutatis mutandis for what algorithms the electronics below the hardware level is using, and the physics below that, etc. For example, speculative execution <ref type="bibr" target="#b38">(Lampson, 2006)</ref> means that as a user, we do not actually know what CPU-level algorithm is being used to instantiate our code-level algorithm. Speculative execution, present in modern CPUs, predicts which instructions, e.g., post conditional branching, could be needed in the near future and executes them. This by definition means that the actual algorithm carried out by the hardware may be different to what we might think, given branches are treated in ways that might not be obvious to the programmer unaware of speculative execution at the CPU-level. Such principles from computer science and engineering can be, if done carefully, imported into how we carve neuroscientific nature at its joints. That is to say, functional transparency is a very useful concept once we delimit the context or layer of analysis of interest (cf. <ref type="bibr" target="#b29">Kaplan, 2011;</ref><ref type="bibr" target="#b58">Potochnik &amp; Sanches de Oliveira, 2019;</ref><ref type="bibr" target="#b83">Zipser &amp; Andersen, 1988)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A broken metaphor is right twice a day</head><p>[A] single connectionist model can simulate results that imply mutually exclusive psychological processes. Thus, results consistent with a connectionist model should not be taken as evidence for the model. [ANNs] can retard the discovery of the information that a subject uses in a task. <ref type="bibr">(Massaro, 1988, p. 219)</ref> In <ref type="figure">Figure 2</ref>, we can see a visual depiction of a variant of the same fallacy we have described herein. Let us frame this example two different ways. First, there are two clocks with identical appearances (as shown on the left in <ref type="figure">Figure 2</ref>) and functional roles: a mantelpiece clock that indicates the time of day. However, the two clocks are implemented using dramatically divergent mechanisms: clockwork (top right) and digitally (bottom right). This exemplifies a typical case of multiple realizability, both types of mechanism (can) give rise to identical behaviours, while having no mechanistic similarity. One can learn about the time of day by looking at either clock, but one cannot learn about the internals of the one clock by looking at the other "wrong" clock.</p><p>Ignoring the principle of multiple realizability, risks (if not ensures) confusing the explanandum (what we are attempting to explain; human cognition) and the explanans (our explanation; our model). Recall, our degenerate syllogism: if the ANN model behaves like human cognition, then the model is cognition. Importantly, it might be the case the model is exactly like human cognition, but we cannot safely conclude that from the premise given multiple realizability. The same goes for the clock in <ref type="figure">Figure 2</ref>, we can, for example, set the explanandum to the digital clock and the explanans to the clockwork clock. If we apply the same syllogism, we get: if the clockwork clock behaves like the digital clock, then the clockwork clock is a digital clock. This is deeply problematic and readily falsifiable -mutatis mutandis for vice versa. For more directly scientific confusions between model and phenomemnon, explandum and explanans, consider the motion of objects under gravity and Newtonian mechanics. P → Q in this case, takes the form: if Newtonian mechanics behaves like physical objects, then Newtonian mechanics is physical objects. None of these syllogisms obtain exactly because models can be multiply realized, and because models are different qualitatively to phenomena.</p><p>To really hammer home how multiple realizability relates to our modelling case in CCN -specifically how it demonstrates that the reasoning in use is flawed -we propose a complimentary, augmented way of looking at <ref type="figure">Figure 2</ref>. Instead of seeing two possible options for instantiating a clock, we can conceptualize one clock, e.g., the clockwork one, as the real empirical clock and the, e.g., digital clock, as the "computational" model. In such a scenario, it should be readily obvious that conclusions with respect to understanding the clockwork mechanism of the "empirical" clock, bar behaviour, cannot be safely drawn by looking at the mechanisms. Importantly, unlike the idealized engineered clock example we do not know in non-engineered complex systems, like the brain, what the specification of the behaviour is with full certainty. We merely can take a view supported by our theory-laden data -we cannot ever know the ground truth of the brain's specification in the same way we can of a timepiece. Therefore, parallels between mechanisms, also known as substrates or implementations, even when they give rise to identical behaviours, e.g., clockwork and digital clocks, cannot be safely drawn without further constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(Un)licensed analogies</head><p>All modelling, especially theoretical, cognitive, neuroscientific modelling, as found in CCN, can be seen as drawing analogies between models and empirical phenomena. However, to draw inductive inferences (like argument from anal- <ref type="figure">Figure 2</ref>. A clock can be "behaviourally" (i.e., externally) identical to another clock, completely independently to each clock's implementation. This serves as a very simple example of why multiple realizability is important when understanding complex systems. (Credit: The mantelpiece clock icon is by EmojiOne (CC BY SA 4.0). The cogs icon is by Team Redux (Open Font License). The microchip icon is by Dave Gandy (CC BY 4.0).) ogy) from models to phenomena under study to organisms under study and back we must do so cautiously, transparently, and perhaps most importantly -since induction has no "universal schemas" <ref type="bibr" target="#b55">(Norton, 2003)</ref> -in a way traceable to agreed upon facts. That is to say, if we know the melting point of one sample of a chemical element, we can generalize this knowledge to all instances of that element. In contrast, if we know the melting point of one piece of wax, generalizing to all wax is not licensed. We are licensed in the first case, but not the second, not from the logical form of the inference itself, but "from facts pertinent to the matter of the induction" <ref type="bibr">(Norton, 2003, p. 4</ref>): a chemical element is taken to be homogenous, while wax can be composed of various substances with differing melting points.</p><p>Turning our attention back to the specific type of induction relevant here, argument from analogy: what does this mean for our conditional "if our model correlates with neurocognitive data (P), then our model can do everything else the human organism does (Q)"? Argument from analogy has the form (Salmon, 2013):</p><p>X has properties α, β, γ, etc.</p><p>Y has properties α, β, γ, etc., and also an additional property ω.</p><p>Therefore, X has property ω as well.</p><p>To demonstrate our P → Q is a false analogy, recall the example in <ref type="figure">Figure 2</ref> with the clocks. We can reformulate "if a clockwork clock behaves like a digital clock (P), then the clockwork is the same as a digital clock (Q)" to the following false analogy -an induction that is not licensed by the facts:</p><p>Digital clocks display the time.</p><p>Clockwork clocks display the time, and require manual winding.</p><p>Therefore, digital clocks require manual winding. This is an example of an argument from analogy, which must be licensed by material facts if we want it to locally obtain <ref type="bibr" target="#b55">(Norton, 2003)</ref>. In the case of CCN:</p><p>ANNs correlate with fMRI data.</p><p>Brains correlate with fMRI data, and instantiate the biological mechanisms for cognition.</p><p>Therefore, ANNs instantiate the biological mechanisms for cognition.</p><p>Both these inductions for clocks and brains are not licensed because the principle of multiple realizability makes it unsafe to argue from analogy because it is the mode through which the conditional becomes false, and the argument rendered unsound.</p><p>Importantly, recall how we correctly avoid MT in CCN, we realize the analogy between model and human somewhere has become scientifically useless. When a model fails to categorize an adversarial image, we say the similarity between it and humans has ended, and not that ANNs are holistically so different to be completely inappropriate models. We notice our P → Q is unsound (the premises false) because we rested on an inductive inference that was not licensed, i.e., a false analogy. Thus, within CCN when we make metatheoretical decisions we should be able to answer for ourselves: is this induction licensed, is this a sensible analogy, given multiple realizability, given that we do not (yet) know the mechanisms of the brain?</p><p>When I think about you, I adjust my calculus Affirming the consequent is a repercussion of entering a universe that is not truth-making for our inference P → Q: what is described as a useful inference from models to brains does in fact not obtain. Nonetheless, it is likely the case that when we invite, if not commit, the fallacy, we do so because we actually believe it is MP, not because we are aware it is a fallacy. Thus, an alternative explanation for why our field has the propensity to permit minimally accidentally hinting at the fallacy is that it is forced to operate in a world where no explanation obtains. In other words, one cannot make inferences to the best explanation, or abduction, if every possible choice for explanation does not (currently) obtain. Abduction only works if we have a selection of good explanations to work from. We may simply not yet be in such a state of affairs in CCN. However, we may be able to arrive at such a state -and importantly, abduction has the same logical form as affirming the consequent <ref type="bibr" target="#b19">(Frankfurt, 1958;</ref><ref type="bibr" target="#b57">Plutynski, 2011)</ref>.</p><p>The authors oppose prescriptivism as a remedy to our afflictions, logical or otherwise. Notwithstanding, we propose the following steps for consistent reasoning in CCN, to adjust our syllogisms, both internally (to avoid affirming the consequent) and externally (to obtain). a) Create a metatheoretical calculus explicitly of our projects or papers and evaluate the logical consistency of our premises and arguments, especially keeping track of causal, e.g., versus rhetorical or temporal, relationships between model and observation; and bearing in mind that theories imply data, and not vice versa (i.e., the Duhem-Quine thesis, <ref type="bibr" target="#b25">Harding, 1975)</ref>. b) Explicitly discriminate between functional role and mechanism during theorizing, taking context and multiple realizability into account. c) Couch our metatheoretical calculus in terms of abduction over the path function such that it obtains. The path function from <ref type="bibr" target="#b24">Guest and Martin (2021)</ref> can serve as a rudimentary basis for all this if a (fully) formal approach is not (yet) beneficial, as can the questions and example answers in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Herein, we propose that our interdiscipline, CCN, needs to (re)evaluate the contribution of the new flavour of connectionism that purports to use deep ANNs to derive and refine our theoretical explanations and understandings of the brain (cf. <ref type="bibr" target="#b5">Chirimuuta, 2021;</ref><ref type="bibr" target="#b23">Guest, Caso, &amp; Cooper, 2020;</ref><ref type="bibr" target="#b46">Martin &amp; Doumas, 2019</ref>. To this end, a series of core questions need to be asked when we carry out such work, as shown in <ref type="table">Table 2</ref>.</p><p>The way we have operationalized the issues found in the literature currently indicates the possible misapplication of logic resulting in affirming the consequent. Alternatively, this might be due to a deeper difference in ideological or ontological perspectives with respect to what CCN aims to uncover, how mechanism is seen by CCN scholars, or indeed how success of a model is interpreted, known as the successto-truth inference <ref type="bibr" target="#b78">(Vickers, 2019;</ref><ref type="bibr" target="#b80">Wray, 2013)</ref>.</p><p>Cognitiva (meta)scientia redux "[T]he extent of the match between a model representation and the neural data is appraised solely based on the correlation between the empirical dissimilarity structures constructed with neural recordings and model representations." <ref type="bibr">(Tacchetti, Isik, &amp; Poggio, 2017, p. 11)</ref> Potential question</p><p>Example answer How does the model mediate from theories to data and back again?</p><p>It allows us to test if our assumptions, especially simplifying assumptions, about cognition and neural systems can lead to behaviour, including internal representations, that correlate with those of target natural systems. How do our field's models bridge levels of analysis, and are these bridges scientifically useful?</p><p>The model captures important aspects of function (based on these tasks, neural readouts, etc.) and mechanism (based on these proposed causally interacting components). What do the models we develop in CCN offer in the context of psychology, cognitive science, and neuroscience in general?</p><p>The model allows us to explore the repercussions of our assumptions about representations and input-output mappings, especially ones that correlate with those of our observations from the brain, cognition, and behaviour. <ref type="table">Table 2</ref> Questions and example responses we could ask and answer for ourselves when engaging in metatheorising, thinking about what our modelling work contributes, within CCN.</p><p>Misapplication of such metatheoretical logic, as we have expounded on herein, contributes to overpromising and underdelivering, impeding the progress of CCN as much as it does the fields that touch on AI generally. We do not argue that ANNs do not make highly useful models within CCN and the neuro-and cognitive sciences more broadly. Although "machine learning provides us with ever-increasing levels of performance, accompanied by a parallel rise in opaqueness" (Barak, 2017, p. 5), we do not believe using machine learning this way is the only source of lack of transparency and of lack of "open theorizing" <ref type="bibr" target="#b24">(Guest &amp; Martin, 2021)</ref> within CCN. Interdisciplines, like cognitive science, strive to properly allow for the scientific exchange of ideas and methods within and between their constituent participating disciplines. We wish to facilitate dialogue on how to theorize usefully when importing ideas to CCN from other related fields. An example of a maladaptively imported idea is that of the Turing test <ref type="bibr" target="#b76">(Turing, 1950)</ref>, which involves understanding and contextualising the principle of multiple realizability. The Turing test sets out to differentiate the human(-like machine) from an algorithm, essentially a chatbot. Through behavioural probing, e.g., asking questions in natural language, the person performing the test attempts to ascertain if the agent (machine or person) answering is responding meaningfully differently to a person. If the machine can "trick" us into thinking it is a human, it is said to have passed the Turing test. The Turing test is very useful if we want to engineer algorithms that can exchange details with people seamlessly. However, if we take this test and use it to infer more than perhaps Alan Turing intended, that the machine indeed is a person (our P → Q), we have slipped into affirming the consequent and false analogy.</p><p>As we have shown, it is not unusual if formally treated to discern or derive fallacies in the CCN literature such as cum hoc ergo propter hoc (i.e., with the fact, therefore because of the fact, or "correlation does not imply causation"), begging the question, confirmation bias, false analogy -the root of these informal fallacies is the formal fallacy of affirming the consequent. The Turing test and similar functional role-based analogies allow us to stumble into a formal fallacy if we stray far from engineering systems and towards understanding human cognition. Ultimately, the lack of attention to the high potential for (mis)application of formal logic in CCN betrays its current theoretical underdevelopment. This is the case regardless of what the reasons are for this lack of (meta)theoretical aptitude. If we accept that a "theory is a scientific proposition [...] that introduces causal relations with the aim of describing, explaining, and/or predicting a set of phenomena" <ref type="bibr">(Guest &amp; Martin, 2021, p. 794)</ref>, then the field-level theory that much of CCN work is based on has logical inconsistencies, namely manifesting as the formal fallacy of affirming the consequent. The ablity to critically evaluate this was granted to us in part by the metatheoretical calculus, the formal model of the discourse, we built herein.</p><p>Based on our analyses, we propose that CCN as a subfield needs to reevaluate itself and take heed of calls for "cross field fertilization" <ref type="bibr" target="#b0">(Barak, 2017)</ref>, especially in terms of theory. Our unique perspective here is to underline and explain why metatheorising, specifically in the domain of formal logic, is just as important to consider -if not more so than methodological, computational, and theoretical issues in CCN since risking committing a formal fallacy in how we in-terpret our results is destructive to the whole enterprise. Just because a model correlates with brain and behaviour data, it is not sufficient for us to infer that the model is performing cognition: correlation does not imply cognition. We, (meta)scientists who contribute to CCN, must rethink how we reason about our work -by looking inwards, to understand how to move the subfield into a coherent state, and outwards, to learn how to perform metascientific reasoning from other established fields, like the super-field of cognitive science or the adjacent subfield of mathematical psychology.</p><p>If we do not examine the overarching principles that govern our science, we are ignoring the missing pieces to the puzzle (or indeed pizza; see figure 1, <ref type="bibr" target="#b24">Guest &amp; Martin, 2021)</ref> of why the field itself might not progress in our intended ways. The goals of CCN involve looking at the lower-level mechanisms that give rise to neuroscientific findings and intelligent agents' behaviours (cf. <ref type="bibr" target="#b34">Kietzmann et al., 2019;</ref><ref type="bibr" target="#b71">Shiffrin, Bassett, Kriegeskorte, &amp; Tenenbaum, 2020</ref>). If we allow flawed inference rules to govern CCN in a way that overlooks mechanism by ignoring the principle of multiple realizability (or if we permit the use of rules that are indeed formally fallacious) then we lead ourselves astray. To avoid this, we must as a field explicitly engage with the principle of multiple realizability, with theory-building, and with the metatheoretical inferences we draw based on our work, especially modelling work. The theoretically important stages of modelling work must not be forgotten, especially within the connectionist paradigm, and involve "exploring the effects of [experimental manipulations] on the model's behaviour, and finally extracting implications of the simulation work for cognitive-level theory." <ref type="bibr">(Guest et al., 2020, p. 290)</ref> However, it remains to be seen if indeed "ANNs and [biological neural networks] belong to the same family of direct-fit models" (i.e., models that use brute-force optimisation to map input to output, <ref type="bibr">Hasson, Nastase, &amp; Goldstein, 2019, p. 417)</ref> and how such comparisons contribute to our understanding of cognition. Having a good grasp of the formal(izable) rules we use to reason, which are shaped by and in turn shape the ways in which we think about our science, will lead to a better understanding of cognition and the brain mechanisms that realize it -the core goals of the cognitive and neuro-sciences.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We embed the arguments within first-order logic as we interpret them from the literature; we do not advocate applying deductive inference rules to problems of induction.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recurrent neural networks as versatile tools of neuroscience research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Barak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep analogical inference as the origin of hypotheses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blokpoel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wareham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Haselager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Van Rooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Problem Solving</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">others (2022). Deep problems with neural network models of human vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bowers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dujmović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Montero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Biscione</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A question of levels: Comment on mcclelland and rumelhart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Broadbent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">What is conceptual engineering and what should it be? Inquiry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Chalmers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Prediction versus understanding in computationally enhanced neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chirimuuta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="767" to="790" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Others</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep neural networks as scientific models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Cichy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="317" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">We might be wrong, but we think that hedging doesnt protect your reputation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">13281348</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Krzyanowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conditionals and testimony</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page">101329</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Are more details better? on the norms of completeness for mechanistic explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Craver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The British Journal for the Philosophy of Science</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Explanation and cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cummins</surname></persName>
		</author>
		<editor>F. Keil &amp; R. Wilson</editor>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="117" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Integrated deep visual and semantic attractor neural networks predict fmri pattern-information along the ventral object processing pathway</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Devereux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Tyler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The pitfalls of measuring representational similarity using representational similarity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dujmović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bowers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Adolfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Malhotra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">What do adversarial images tell us about human vision? bioRxiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dujmović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bowers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08195</idno>
		<title level="m">Adversarial examples that fool both computer vision and time-limited humans</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Falkenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schiemann</surname></persName>
		</author>
		<title level="m">Mechanistic explanations in physics and beyond</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Performance vs. competence in humanmachine comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Firestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">43</biblScope>
			<biblScope unit="page">2656226571</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Connectionism and cognitive architecture: A critical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fodor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">W</forename><surname>Pylyshyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="3" to="71" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Peirce&apos;s notion of abduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Frankfurt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="593" to="597" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Funke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Borowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Stosio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.09406</idno>
		<title level="m">The notorious difficulty of comparing human and machine perception</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Beyond accuracy: quantifying trial-by-trial behaviour of cnns and humans by measuring error consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Meding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16736</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Thinking ahead: spontaneous next word predictions in context as a keystone of language in humans and machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Aubrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On simulating neural damage in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Guest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Brain &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">289321</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">How computational modeling can force theory building in psychological science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Guest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
		<idno type="PMID">33482070</idno>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page">1745691620970585</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Can theories be refuted?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Essays on the duhemquine thesis</title>
		<imprint>
			<publisher>Springer Science &amp; Business Media</publisher>
			<date type="published" when="1975" />
			<biblScope unit="volume">81</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Direct-fit to nature: an evolutionary perspective on biological (and artificial) neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Nastase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hedging as a fallacy of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informal Logic</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Could a neuroscientist understand a microprocessor?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Kording</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1005268</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Explanation and description in computational neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="373" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The explanatory force of dynamical and mathematical models in neuroscience: A mechanistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Craver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of science</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="601" to="627" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Principles for models of neural information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page" from="101" to="109" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A task-optimized neural network replicates human auditory behavior, predicts brain responses, and reveals a cortical processing hierarchy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Kell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">N</forename><surname>Shook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Norman-Haignere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Mcdermott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="630" to="644" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep supervised, but not unsupervised, models may explain it cortical representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Khaligh-Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1003915</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Deep neural networks in computational neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Kietzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcclure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>Oxford Research Encyclopedia of Neuroscience</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep neural networks: a new framework for modeling biological vision and brain information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of vision science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="417" to="446" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cognitive computational neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Douglas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1148" to="1160" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Matching categorical object representations in inferior temporal cortex of man and monkey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bodurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Esteky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Bandettini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1126" to="1141" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Lazy and speculative execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lampson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Microsoft Research OPODIS</title>
		<imprint>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Comparing visual representations across human fmri and computational vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Leeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Seibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Pyles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Tarr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">2525</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">How biological attention mechanisms improve task performance in a large-scale visual system model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Distinct patterns of syntactic agreement errors in recurrent networks and humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Linzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leonard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.06882</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Levels of biological plausibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<date type="published" when="1815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">The costs and benefits of goal-directed attention in deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Roads</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02342</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A neural network walks into a lab: towards using deep nets as models for human behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peters</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.02181</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">TRACX2: a connectionist autoencoder using graded chunks to model infant visual statistical learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mareschal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<date type="published" when="1711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Predicate learning in neural systems: using oscillations to discover latent structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Doumas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="77" to="83" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Tensors and compositionality in neural systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A A</forename><surname>Doumas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">375</biblScope>
			<date type="published" when="1791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Capital: volume iii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marx</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1894" />
			<publisher>International Publishers</publisher>
			<pubPlace>NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Some criticisms of connectionist models of human performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Massaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of memory and language</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="234" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Deep learning: Implications for human learning and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>PsyArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Neurons in the mouse brain correlate with cryptocurrency price: a cautionary tale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meijer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="page">174569162097476</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Deep neural network models of object recognition exhibit human-like limitations when performing visual search tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Prinz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Beyond good and evil</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nietzsche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Apophthegms and Interludes)). Friedrich Nietzsche Internet Archive (marxists.org)</title>
		<imprint>
			<date type="published" when="1886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A material theory of induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Norton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="647" to="670" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.02164</idno>
		<title level="m">Adapting deep network features to capture psychological representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Four problems of abduction: A brief history. HOPOS: The Journal of the International Society for the History of</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plutynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="248" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Patterns in cognitive phenomena and pluralism of explanatory styles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Potochnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sanches De Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">13061320</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Psychological predicates. Art, mind, and religion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Putnam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Polysemy and thought: Toward a generative theory of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quilty-Dunn</surname></persName>
		</author>
		<idno type="DOI">10.1111/mila.12328</idno>
		<idno>doi: 10.1111/mila.12328</idno>
		<ptr target="http://dx.doi.org/10.1111/mila.12328" />
	</analytic>
	<monogr>
		<title level="m">Mind amp; Language</title>
		<imprint>
			<date type="published" when="2020-12" />
			<biblScope unit="page">158185</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Main trends in recent philosophy: Two dogmas of empiricism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">V</forename><surname>Quine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Philosophical Review</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="43" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Convolutional neural networks in the brain: an fmri study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scholte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lamme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghebreab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="371" to="371" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Deduction without awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Reverberi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pischedda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cherubini</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.actpsy.2011.09.011</idno>
		<idno>doi: 10.1016/j.actpsy .2011.09.011</idno>
		<ptr target="http://dx.doi.org/10.1016/j.actpsy.2011.09.011" />
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">244253</biblScope>
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">How hard is cognitive science?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>De Haan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wareham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Van Rooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
		<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">How persuasive is a good fit? a comment on theory testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pashler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">358367</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Structure and deterioration of semantic memory: a neuropsychological and computational investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Ralph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Garrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bozeat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mc-Clelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Patterson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page">205</biblScope>
		</imprint>
	</monogr>
	<note>Psychological review</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Introduction to logic and critical thinking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<editor>Routledge. Salmon, M. H.</editor>
		<imprint>
			<date type="published" when="1918" />
		</imprint>
	</monogr>
	<note>Cengage Learning</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">If deep learning is the answer, what is the question?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Generative adversarial networks for reconstructing natural images from brain activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Seeliger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Güçlü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ambrogioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Güçlütürk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Van Gerven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="775" to="785" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Second-order isomorphism of internal representations: Shapes of states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">117</biblScope>
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The brain produces mind by modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Bassett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">47</biblScope>
			<biblScope unit="page">2929929301</biblScope>
			<date type="published" when="2020-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Existence, proof and truth-making: A perspective on the intuitionistic conception of truth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sundholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topoi</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="126" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Invariant recognition drives neural representations of action sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Isik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1005859</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Understanding cnns as a model of the inferior temporal cortex: using mediation analysis to unpack the contribution of perceptual and semantic features in random and trained networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Truzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cusack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Computing machinery and intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Creative Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Editorial: Artificial neural networks as models of neural information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Gerven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bohte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Computational Neuroscience</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Towards a realistic success-to-truth inference for scientific realism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vickers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="571" to="585" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wald</surname></persName>
		</author>
		<title level="m">Introduction to dialectical logic</title>
		<imprint>
			<publisher>John Benjamins Publishing</publisher>
			<date type="published" when="1975" />
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Success and truth in the realism/anti-realism debate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Wray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">190</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1719" to="1729" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Humans can decipher adversarial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Firestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A back-propagation programmed network that simulates response properties of a subset of posterior parietal neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Andersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="issue">6158</biblScope>
			<biblScope unit="page" from="679" to="684" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
