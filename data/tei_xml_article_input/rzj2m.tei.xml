<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Finally, I summarize the empirical and theoretical lessons learned and lay out a road-map for future research on generalization in Chapter 8</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Schulz, E</roleName><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Meder</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Konstantinidis, E</roleName><forename type="first">E</forename><surname>Schulz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
						</author>
						<title level="a" type="main">Finally, I summarize the empirical and theoretical lessons learned and lay out a road-map for future research on generalization in Chapter 8</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Schulz</term>
					<term>E.</term>
					<term>Speekenbrink</term>
					<term>M.</term>
					<term>&amp; Krause</term>
					<term>A. (2017b). A tutorial on Gaussian process regression with a focus on exploration-exploitation scenarios. bioRxiv</term>
					<term>(pp. 095190) Cognitive Science Society Cognitive Science Society Wu</term>
					<term>C. M.</term>
					<term>Schulz</term>
					<term>E.</term>
					<term>Speekenbrink</term>
					<term>M.</term>
					<term>Nelson</term>
					<term>J. D.</term>
					<term>&amp; Meder</term>
					<term>B. (submitted). Exploration and generalization in vast spaces</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The research presented in this thesis is based on a selection of papers that I have worked on during my doctoral studies.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To my grandparents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>First and foremost I would like to thank my supervisor Maarten Speekenbrink, who is likely the most encouraging and intelligent person I know. Thank you for literally leaving your door always open, for meeting me every day, for always being up for a chat about science in general and psychology in particular. You are not only a great supervisor but also a good friend. I would also like to thank my second supervisor David Shanks for being someone I have always looked up to, someone who has helped me to appreciate the beauty of psychology.</p><p>Thanks to Philip Treleaven, Yonita Carter, and the UK Centre for Doctoral Training in Financial Computing and Analytics for funding this research.</p><p>I have also benefited greatly from 4 "unofficial supervisors". I would like to thank Samuel Gershman for hosting me during my time at Harvard and for having been an incredible collaborator throughout. Thanks also to Joshua Tenenbaum for hosting me at MIT and for all his excitement about the projects presented here. Andreas Krause also helped me greatly during my time at ETH Zürich and beyond by teaching me about the mathematical underpinnings of this thesis. Björn Meder has hosted me on countless occassions at the Max-Planck Institute in Berlin and always seems to ask the right "Wait but why"-question at the time.</p><p>I have been happy to meet many inspiring and smart people throughout my PhD. This thesis is the product of having collaborated with Dominik Bach, <ref type="bibr">David Duvenaud, Zoubin Ghahramani, Sam Gershman, Jose Miguel Hernández Lobato, Quentin Huys, Emmanouil Konstantinidis, Andreas Krause, Björn Meder, Jonathan Nelson, David Reshef, Joshua Tenenbaum, and Charley Wu.</ref> I would also like to thank my parents, Rainer and Carola Schulz, for their unconditional support and encouragement throughout my journey from a helpless undergraduate to a slightly less helpless postgraduate student, my brother for being the coolest teenager I know, and the rest of my family for always believing in me.</p><p>This journey has been considerably easier due to many great friends in London and abroad. Thank you Tarek Al-Zand and Stefan Irmscher for being my oldest friends, Neil Bramley for sharing a lot of this path with me, Chloe Bukata for life and board game advice, Leonardo Cohen for letting me eat his rice crackers, Saoirse Connor Desai for buying me a tooth brush in Mexico, Will Crichton for literature conversations on St. Patrick's day, Ishita Dasgupta for collaborating on projects not included in this thesis, Pedro Miguel Esperanca Grillo for appreciating Bayesian stats, Tobias Gerstenberg for always making me feel welcome, Tom Hardwicke for promoting open science, Adam Harris for many helpful comments at the Lord John Russell, Abby Ipser for being small, Lara Kirfel for taking the Victoria line once, Dave Lagnado for reminding everyone that science is fun, Brad Love for shooting ideas at me, Philip Newall for hosting workshops, Paula Parpart for having 4 careers and still attending board game nights, Sarah Potratz and Christian Schnürch for buying a new couch, Benjamin Riedel for not taking himself too seriously, Kazys Simutis for keeping his calms, Deepesh Vadher for yelling "Sun" that one time, Sebastian Weichwald for being a walking mandala, and everyone else I have forgotten.</p><p>Thanks also to four eras of 2 Finsbury Park Road housemates who have helped to make London feel like home.</p><p>Finally, I would like to thank Cora Schefft for being there.</p><p>v Abstract How do humans generalize from observed to unobserved data? How does generalization support inference, prediction, and decision making? I propose that a big part of human generalization can be explained by a powerful mechanism of function learning. I put forward and assess Gaussian Process regression as a model of human function learning that can unify several psychological theories of generalization.</p><p>Across 14 experiments and using extensive computational modeling, I show that this model generates testable predictions about human preferences over different levels of complexity, provides a window into compositional inductive biases, and -combined with an optimistic yet efficient sampling strategy-guides human decision making through complex spaces.</p><p>Chapters 1 and 2 propose that, from a psychological and mathematical perspective, function learning and generalization are close kin. Chapter 3 derives and tests theoretical predictions of participants' preferences over differently complex functions. Chapter 4 develops a compositional theory of generalization and extensively probes this theory using 8 experimental paradigms.</p><p>During the second half of the thesis, I investigate how function learning guides decision making in complex decision making tasks. In particular, Chapter 5 will look at how people search for rewards in various grid worlds where a spatial correlation of rewards provides a context supporting generalization and decision making. Chapter 6 gauges human behavior in contextual multi-armed bandit problems where a function maps features onto expected rewards. In both Chapter 5 and Chapter 6, I find that the vast majority of subjects are best predicted by a Gaussian Process function learning model combined with an upper confidence bound sampling strategy. Chapter 7 will formally assess the adaptiveness of human generalization in complex decision making tasks using mismatched Bayesian optimization simulations and finds that the empirically observed phenomenon of undergeneralization might rather be a feature than a bug of human behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Listing of figures</head><p>2.1 Example of Shepard's rule of generalization. As the distance between two stimuli grows, the probability to generalize one stimuli onto the same response as the other decreases exponentially. The dark red circle on the bottom left and the light red circle on the bottom right are the observed stimuli. The circles between the two stimuli are new observations. The dark red line marks the probability of a same responses as to the dark red circle. The light red line marks the probability of a same responses as to the light red circle. . . . . . . . . . . . . . . 10 2.2 Carroll's original paradigm (taken from the original publication). Stimulus distance is marked by a "V". Response distance is marked by a vertical slash. . . . <ref type="bibr" target="#b49">DeLosh et al. (1997)</ref>. When learning a quadratic function, participants' extrapolation lines fall between the true function and straight lines fitted to the closest training points. . . . . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results of extrapolation experiment conducted by</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Example of performing</head><p>Bayesian linear and cubic regression. Green lines indicate predictions for different sampled posterior weights. Dots mark empirical observations. Yellow lines mark the current mean posterior predictions. The red triangle shows the prediction for the newly presented stimuli x ⋆ = 3. . . . . . 3.2 Different gradients of functional generalization as induced by setting the lengthscale λ = {0.5, 1, 2}. The correlation is assessed as the mean correlation between two points in dependency of their mutual distance. For bigger λ-parameters, the correlation decays more slowly leading to broader generalization. . . . . . . . 34 3.3 Green lines indicate predictions for different sampled posterior weights. Dots mark empirical observations. Yellow lines mark the current mean of the GP (λ was set to 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.16</head><p>Screenshots of Experiment 6. The height of the blue bar indicates the input. The height of the orange bar marks the prediction and can be adjusted by using the slider. After the prediction was submitted, the actual output, marked by the height of the red bar, appeared and participants were told the absolute difference between their prediction and the actual outcome. . A.1 Model recovery results, where data was generated by the specified generating model using individual participant parameter estimates. The recovery process used the same cross-validation method used in the model comparison. I report the predictive accuracy of each candidate recovery model (bars including standard error) and the number of simulated participants best described (icon array). For both generating and recovery models, I used UCB sampling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1</head><p>Parameter estimates of factors influencing predictability judgments extracted from a mixed-effects regression analysis. Conditional pseudo-r 2 = 0.30. . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Average correlation between factors and participants' predictability judgments</head><p>r and importance as assessed by a random forest permutation algorithm. . . . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Base</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This chapter motivates the study of function learning to construct a theory of human generalization, introduces Gaussian Process regression as the main algorithm of this thesis, and lays out a roadmap of the chapters ahead.</p><p>1.1 The quest for a universal law "Has psychology any hope for achieving a law that is comparable in generality (if not predictive accuracy) to Newton's universal law of gravitation?" Roger Shepard asked in 1987 in the light of the tercentenary of Newton's Principia. Indeed, the quest for universal psychological laws has been as old (and perhaps even older) as psychology itself. Willhelm Wundt tried to find the "elements of thoughts and what rules they adhere to" <ref type="bibr" target="#b242">(Wundt, 1896)</ref>. Herman Ebbinghaus lived a life of solitude collecting data only on himself in the attempt to find the "elements of a general theory of learning" <ref type="bibr" target="#b52">(Ebbinghaus, 1885)</ref>. And even today, the quest for generalized theories seems to be as timely and appropriate as ever with researchers assessing different unifying principles of cognition such as simplicity <ref type="bibr" target="#b34">(Chater &amp; Vitányi, 2003)</ref>, free energy <ref type="bibr" target="#b61">(Friston, 2010)</ref>, or Bayesian sampling <ref type="bibr" target="#b176">(Sanborn &amp; Chater, 2017)</ref>, others proposing ways of "how to grow a mind" <ref type="bibr" target="#b221">(Tenenbaum et al., 2011)</ref>, or yet even more ambitious goals such as Google DeepMind's agenda to "solve intelligence and then use it to solve everything else" <ref type="bibr" target="#b201">(Simonite, 2016)</ref>.</p><p>Back in 1987, Shepard argued that psychology's first general law should be a law of generalization as any object or situation experienced by an individual is unlikely to recur in exactly the same form and context. Today, 30 years later,  point out that current theories of reinforcement learning cannot account for the fact that the "data are relatively sparse and, indeed, precisely the same situation may never be encountered twice". Whereas Shepard proposed an exponential similarity function in psychological space,  propose a non-parametric representational mechanism guiding reinforcement learning. Yet, the overarching question remains the same: "How do humans and other animals know what to do or think in novel situations?". This question in turn immediately leads to other related questions such as "How are people able to learn and search for rewards in scenarios where not all options can be exhaustively explored?" or "What allows us to perceive and a draw inferences from patterns as efficiently as we do?". Shepard's assertion seems to be as valid as ever: the core principle guiding decision making and cognitive inferences is the ability to generalize beyond encountered observations (see also <ref type="bibr" target="#b220">Tenenbaum &amp; Griffiths, 2001</ref>, for a similar argument).</p><p>The aim of this thesis is to develop an empirically grounded and mathematically refined theory of human generalization. The main argument of this thesis is that if we want to study generalization, then -really-what we have to study is function learning. Put differently, the main premise of this thesis is that function learning, i.e. the ability to learn a mapping from inputs to outputs that generalizes to novel input-output pairs, can explain a big chunk of human generalization. If this is indeed true, then finding an expressive model of human function learning will shed light on some of our most fundamental psychological questions and would be applicable across many domains of cognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Generalization as function learning</head><p>I will define generalization as the ability to generate and act according to predictions for new observations based on underlying commonalities, i.e. as the ability to make predictive inferences about unobserved outcomes. At the core of this definition is the assumption that generalization can be achieved by learning about an underlying function that allows for generating predictions for both observed and novel inputs. This is different to other forms of induction that, given a few examples, extract a global rule (for example, <ref type="bibr" target="#b96">Holyoak, 1985)</ref>, as the rule does not necessarily have to be extracted all at once (functions can be learned piece-wisely) and predictions also come with a quantification of uncertainty (it is a case of Bayesian induction, so to say). It also goes beyond generalization in the "Shepardian" sense as novel observations do not only produce the same response as the most similar previously observed exemplar, but rather map onto a rich behavioral repertoire based on functional inferences. Function learning allows for global inferences which generalize to novel instances.</p><p>The presented results will be heavily based on the theory and application of Gaussian Process regression . Gaussian Process regression is a nonparametric Bayesian approach towards regression problems that -instead of assuming a particular parametric form a priori-acts as a universal function approximator which can capture human behavior with mathematical elegance and computational ease <ref type="bibr" target="#b234">(Williams &amp; Rasmussen, 1996)</ref>. It is also based on prior research on human function learning <ref type="bibr" target="#b136">(Lucas et al., 2015)</ref> and can be extended to different psychological domains.</p><p>The focus of this thesis will be on simple function learning tasks first, that is the question of how people learn, complete, make judgments about, and predict functional patterns.</p><p>Afterwards, Gaussian Process-based function learning will be extended to self-directed function learning scenarios in which participants have to both learn the mapping between inputs and outputs and make choices based on expectations generated by that mapping in order to gain rewards.</p><p>The main questions of this thesis are threefold:</p><p>1. What does it mean for a theory of generalization to be grounded in function learning?</p><p>2. How do people utilize functional generalization to search for rewards?</p><p>3. How do insights gained from human function learning behavior generalize to other domains?</p><p>Gaussian Process regression provides a useful tool to address all of these questions. First, as different forms of generalization can be encoded directly into Gaussian Process regression models, and as these forms can also be combined explicitly <ref type="bibr" target="#b51">(Duvenaud et al., 2013)</ref>, it can be used to derive a compositional theory of functions in which smaller parts are combined to explain complex structural patterns. Second, as Gaussian Process regression is also a common tool for problems involving the optimization of unknown functions <ref type="bibr" target="#b204">(Snoek et al., 2012)</ref>, it is an informative method to assess how humans approach tasks incorporating both function learning and the search for rewards. Third, as a mechanism of generalization can theoretically be applied to many other psychological domains, from learning causal relata from observations <ref type="bibr" target="#b98">(Hoyer et al., 2009)</ref> to inferring people's intentions from their actions <ref type="bibr" target="#b229">(Wang et al., 2012)</ref>, a final question will be how much a theory of generalization grounded in function learning itself generalizes to other tasks, i.e. in what sense the proposed model can indeed be seen as a universal law, a psychological process model, or just a window into an empirically observed phenomenon. "It is not sufficient to think in terms of the discrete response to the discrete stimulus; what is being learned by these subjects is a mediating function, a set of rules or programs for transmuting an entire range of stimuli into a range of responses." <ref type="bibr">Douglas Carroll, 1963</ref> 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From generalization to function learning</head><p>This chapter argues for function learning as a mechanism of generalization and summarizes psychological studies on function learning.</p><p>Important effects and theories are explained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Shepard's rule of generalization</head><p>Roger Shepard was among the first psychologists to study human generalization <ref type="bibr" target="#b194">(Shepard, 1957</ref><ref type="bibr" target="#b195">(Shepard, , 1958</ref>. During the 1950s, operant conditioning was among the most popular theories of human and animal behavior, such that many scientists believed that a universal law of psychology should start with a law of how stimuli become associated with different responses <ref type="bibr" target="#b232">(Watson et al., 1958;</ref><ref type="bibr" target="#b202">Skinner, 1945)</ref>. However, <ref type="bibr" target="#b165">Pavlov (1941)</ref> already observed that dogs would not only salivate at the sound of a bell that had preceded feeding on multiple trials before, but also at other stimuli, in particular sounds that were similar in pitch to the original sound. Afterwards, many behaviorists were interested in the so-called "gradient of stimulus generalization", i.e. how similar two different stimuli had to be in order to produce the same response. For example, <ref type="bibr" target="#b88">Guttman &amp; Kalish (1956)</ref> found that pigeons' ability to discriminate between different spectra of color along the wave-length continuum was predictive of the animals' response rate during extinction, showing a continuous gradient of generalization. This study led to a line of research investigating the factors that influence the gradient curve of generalization (see <ref type="bibr" target="#b97">Honig &amp; Urcuioli, 1981</ref>, for a thorough review). <ref type="bibr" target="#b194">Shepard (1957)</ref> proposed a theory of generalization to explain how similar stimuli can lead to the same response. The main idea behind his model was that the probability that a response to one stimulus will be generalized to another stimulus is a function of the distance between the two. "Generalization" in Shepard's theory is measured by means of confusion error (i.e., how often a particular stimulus leads to different responses), while "distance" is defined as a comparison between stimuli in a pre-defined psychological space.</p><p>For example, in one of his first experiments, <ref type="bibr" target="#b195">Shepard (1958)</ref> used colored circles of uniform size and a constant red hue but with varying brightness and saturation and randomly assigned numerical responses from "one" through "nine" to these stimuli. When participants had to learn the labels of the different stimuli by being presented with a stimuli, guessing the label, and then observing the actual label, Shepard found that the probability of misclassification decreased with the distance between a stimulus' brightness and saturation. Later on, using further experimental evidence from both human and non-human subjects, Shepard hypothesized that the probability of generalization g(d) will fall off exponentially with the distance d between two stimuli scaled by a constant μ</p><formula xml:id="formula_0">g(d) = exp ( − 2d μ ) . (2.1)</formula><p>An example of Shepard's rule of generalization is shown in <ref type="figure" target="#fig_108">Figure 2</ref>.1. This plot shows that the probability of generalizing a response to a new stimulus from an old one (the ones shown left and right) decreases exponentially with their psychological distance.</p><p>2.2 Carroll's idea to study function learning Douglas Carroll, a PhD-student at Harvard at the time when Shepard had just taken up a faculty position there, wondered whether Shepard's theory of generalization really explained all there was to human generalization. Had a universal law of generalization finally been discovered? And "what would happen when a large number of stimuli are associated with a large number of responses in complex learning situations"?</p><p>Carroll's idea was that only determining a "gradient of stimulus generalization" cannot explain the richness of behavior we observe in both humans and other animals. In particular, Shepard's idea was that a novel stimulus would lead to the same response as the closest seen stimulus so far. However, often times people (and other animals too) can provide a completely novel responses to a previously unobserved stimulus indicating a much  As the distance between two s muli grows, the probability to generalize one s muli onto the same response as the other decreases exponen ally. The dark red circle on the bo om le and the light red circle on the bo om right are the observed s muli. The circles between the two s muli are new observa ons. The dark red line marks the probability of a same responses as to the dark red circle. The light red line marks the probability of a same responses as to the light red circle.</p><p>richer behavioral repertoire. Indeed, looking closer at the results presented in <ref type="bibr" target="#b195">Shepard (1958)</ref>, there was some variance unexplained within the "colored dots"-task of which Carroll thought that "one might suppose that, lurking within this large individual variability, there could be something over and above generalization in the Hullian sense" <ref type="bibr" target="#b29">(Carroll, 1963)</ref>.</p><p>The studies described in Carroll's doctoral thesis entitled "Functional Learning: The Learning of continuous functional mappings relating stimulus and response continua" <ref type="bibr" target="#b29">(Carroll, 1963)</ref> mark the first psychological experiments directly probing human function learning. They originated precisely from the intention to address questions about human generalization that Shepard had seemingly left unanswered.</p><p>In his experimental paradigm, Carroll assessed how participants associate continuous inputs with continuous outputs in a task that he referred to as "subjective curve fitting". His <ref type="figure" target="#fig_108">Figure 2</ref>.2: Carroll's original paradigm (taken from the original publica on). S mulus distance is marked by a "V". Response distance is marked by a ver cal slash.</p><p>experiments asked people to first associate an input, marked as the horizontal distance from the left side of a paper and a letter "V", with a response marked as the horizontal distance from the left side of a paper and a vertical slash (see <ref type="figure" target="#fig_108">Figure 2</ref>.2).</p><p>For the underlying functions connecting stimuli to responses, <ref type="bibr">Carroll used -unknown</ref> to participants-either a positive linear, a quadratic, or a random function. Moreover, after the initial learning stage in which participants only had to learn the association between inputs and outputs, Carroll asked participants to produce responses (i.e., to draw a new vertical dash onto the paper) given both previously seen but also novel input dimensions. Carroll's model of human generalization was inspired by an idea put forward by von <ref type="bibr" target="#b228">Neumann et al. (1941)</ref> that treats curve fitting as an attempt to explain as much variance as possible (measured by an "index of continuity" which is mathematically equivalent to minimizing least squares). By this definition, participants learn an association between a stimulus S and a response R by fitting a function f such that as much of the variance between S and R is explained as possible by using as few parameters p i as necessary.</p><formula xml:id="formula_1">R = f(p 0 , p 1 , • • • , p k , S) (2.2)</formula><p>The function f then can be used to generate responses that can be very different from the seen responses so far.</p><p>As an infinite number of possible functions are possible, Carroll focused on simple polynomials * . His experiments showed that participants were indeed able to learn S-R combinations better if these were governed by an underlying function instead of just a random mapping such as the ones originally applied by Shepard. Moreover, linear functions were easier to learn than non-linear functions. Most importantly, however, instead of simply mapping the response to a novel stimulus to the response of the closest stimulus experienced so far, participants were indeed able to correctly extrapolate to stimuli they had not previously encountered, an empirical indicator of a facet of human behavior that goes beyond generalization as defined by operant conditioning.</p><p>Thus, Carroll's was the first ever published theory on function learning and his model of human generalization went beyond simple stimulus-response-matching.</p><p>Carroll's theory belongs to the category of so-called rule-based accounts of function learning. These accounts propose that participants approach generalization by learning a set of fixed functional rules (for example, polynomial regression weights of a fixed order) and then try to find the best rule (for example, by optimizing the weights) in order to generalize from observed to unobserved data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Rule-based accounts of function learning and generalization</head><p>During the 1970s, <ref type="bibr" target="#b18">Brehmer (1971)</ref>   <ref type="bibr" target="#b18">Brehmer (1971)</ref> never mentions the discussion about psychological rules of generalization, but rather only talks about how participants learn different functional rules. Thus, his work seems to mark the time when psychologists began to study function learning for its own sake without direct implications for rules of human generalization † .</p><p>The results of Brehmer's experiments showed again that participants were able to learn linear functions better than non-linear ones. Furthermore, linear functions with a positive trend were easier to learn than linear functions with a negative trend. Surprisingly, there was no reliable difference between the U-shaped and inverse U-shaped functions. In a later study <ref type="bibr" target="#b20">(Brehmer et al., 1974)</ref>, participants had to learn different functions while also providing verbal reports. The results led <ref type="bibr" target="#b19">Brehmer (1976)</ref> to postulate a hierarchical model of functional hypothesis testing, according to which participants start out expecting a linear function with a positive trend and adjust their hypothesis if the encountered evidence is strong enough.</p><p>One of the first studies that assessed how well participants can control (instead of only † Historically, this could also be due to the fact that generalization was then broadly discussed among psychologists studying categorization, where Shepard's ideas ultimately led to Nosofsky's Generalized Context Model <ref type="bibr" target="#b157">(Nosofsky, 1986)</ref>. learn) the output of different functions was conducted by <ref type="bibr" target="#b7">Berry &amp; Broadbent (1984)</ref>. Within a paradigm called the "sugar factory" participants had to learn how a continuous value called "work force " relates to the amount of sugar a factory can produce. Moreover, participants had to later produce a given value of sugar per trial, thereby having to control the output of sugar over time. These experiments also assessed whether participants are better at controlling linear than exponential functions and found significant task improvements when a non-linear function was "linearized" before the task started. This led to the belief that participants generally have problems controlling non-linear functions such that <ref type="bibr" target="#b7">Berry &amp; Broadbent (1984)</ref> suggested to present non-linear functions in a linear way to make control easier in applied settings. This led to a line of research investigating how participants control complex systems (see <ref type="bibr" target="#b161">Osman, 2010</ref>, for an extensive review). <ref type="bibr" target="#b115">Koh &amp; Meyer (1991)</ref> let participants learn associations between a stimulus' length and the duration of a response where the underlying function was either a power law function, a logarithmic function, or a linear function with a positive slope. They found a systematic response bias during the early stages of learning for the logarithmic and linear functions but not the power-law function. However, this bias gradually disappeared as training progressed. <ref type="bibr" target="#b115">Koh &amp; Meyer (1991)</ref> therefore proposed an adaptive regression model similar to that of <ref type="bibr" target="#b19">Brehmer (1976)</ref> but with the additional constraint that stimulus-response pairs are treated as a power function. This idea was explicitly conceived by the way participants seem to generalize cross-modally in psycho-physics experiment <ref type="bibr" target="#b196">(Shepard, 1981)</ref>.</p><p>A general problem for rule-based accounts of function learning is that the class of possible models a participant can represent might be extremely large or -possibly-infinite.</p><p>Thus, it is not a priori clear why only a particular set of parametric shapes should be considered. This means that it is not at all obvious how participants acquire knowledge of un-derlying rules, nor how they manage to assess all possible rules given some functional data.</p><p>Therefore, psychologists during the 1990s tried to overcome the problem of having to predefine a parametric set of functions by using models that only learn associatively, i.e. based on simple input-output similarities. Interestingly, the resulting similarity-based accounts of function learning are again very close to Shepard's original theory of generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Similarity-based accounts of function learning</head><p>Similarity-based accounts of generalization in function learning propose that people learn functions by associating inputs with outputs: if input x is paired with output y, then inputs similar to x should produce outputs that are similar to y. <ref type="bibr" target="#b27">Busemeyer et al. (1997)</ref> formalized this intuition using a connectionist model (Associative-Learning Model; ALM) in which inputs activate an array of hidden units representing a range of possible input values; each hidden unit is activated in proportion to its similarity to the current input. Learned associations between the hidden units and the response units map the similarity-based activation pattern to output predictions. More specifically, when a cue value, x(t), is presented, it activates input node X i from the set of n input nodes according to a Gaussian similarity function:</p><formula xml:id="formula_2">a i [x(t)] = 1 exp ( X i − ψ x (x(t))/σ ) . (2.3)</formula><p>where ψ is a transformation function and σ scales the distance between the two values.</p><p>This means that inputs are related to each other by how far apart they are and then produce similar outputs as compared to the seen output for previously observed nearby inputs.</p><p>The output of the response node is governed by a weighted sum of associations for which the weights are estimated by a simple delta-rule of learning <ref type="bibr" target="#b217">(Stone, 1986)</ref>. The Associative Learning Model contains 3 free parameters. The first one is simply the learning rate of the delta-rule α and therefore is not so important for the discussion about generalization here.</p><p>However, <ref type="bibr" target="#b27">Busemeyer et al. (1997)</ref> called the other two scaling parameters, σ 1 and σ 2 , "the generalization gradients for the physical continuum used to display the stimuli and the generalization criterion for the output". Thus, this part of the Associative Learning Model explicitly ties back to Shepard's original law but within a function learning context. However, this also means that such a model, even though it is able to learn how participants respond to stimuli they have previously encountered, naturally has problems accounting for the way participants generalize to novel inputs. If new inputs are assessed based on how close they are to previously observed inputs, then what is going to happen if a new input is far away from the experienced input space? <ref type="bibr" target="#b49">DeLosh et al. (1997)</ref> conducted several studies focusing on extrapolation. As the title "Extrapolation: the sine qua non for abstraction in function learning" suggests, <ref type="bibr" target="#b49">DeLosh et al. (1997)</ref> propose that extrapolation, i.e. generating predictions for novel inputs, should be the yardstick to measure the performance of different function learning models. What is interesting about this proposal, is that generalization to new observed points is now used to compare different models of function learning, whereas, previously, function learning was conceived specifically as a mechanism of generalization. To put this differently, one could argue that learning step-wisely within an interpolation set already involves generalization as points have to be observed for the first time at some point during training. Nonetheless, <ref type="bibr" target="#b49">DeLosh et al. (1997)</ref> brought the discussion about generalization back into research on human function learning. In their experiments, participants had to learn the relation between scales of possible stimulus magnitudes which ranged from from 0 to 100 as indicated by an unfilled horizontal bar labeled numerically in 10-point increments. However, to allow for extrapolation trials during the transfer phase of the experiment, the magnitudes presented during training were limited to values between 30 and 70, and the test trials contained both stimuli from within that range but also extrapolation trials that were either smaller than 30 or larger than 70. The underlying functions were either linear, exponential, or quadratic. <ref type="bibr" target="#b49">DeLosh et al. (1997)</ref>'s results showed again that linear functions are easier to learn than exponential functions, which in turn are easier to learn than quadratic functions. More importantly however, something unexpected occurred during extrapolation trials. Even though participants were generally able to extrapolate all of the functions, extrapolation was worse than interpolation and turned out to be more linear than expected. This "linearity bias" even affected cases for which the underlying function had been non-linear; for example, when trained on a quadratic function, participants' average predictions fell between the true function and straight lines fitted to the closest training points as seen in <ref type="figure" target="#fig_108">Figure 2</ref>.3.  <ref type="bibr">(1997)</ref>. When learning a quadra c funcon, par cipants' extrapola on lines fall between the true func on and straight lines fi ed to the closest training points.</p><p>That participants tend to extrapolate functions linearly is nowadays recognized as an established phenomenon <ref type="bibr" target="#b107">(Kalish et al., 2004;</ref><ref type="bibr" target="#b123">Kwantes &amp; Neal, 2006)</ref>. Thus, although similarity-based models are more flexible than rule-based parametric accounts, they face the problem of having to explain how participants generalize beyond the encountered input space. One possible solution to this problem is to combine the more powerful similaritybased function approximation techniques with the extrapolative abilities of simple rules.</p><p>This leads to so-called hybrid accounts of function learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Hybrid accounts of function learning</head><p>Hybrid accounts of function learning normally contain an associative learning process that acts on explicitly-represented rules. One such hybrid model, the Extrapolation-Association Model (EXAM) put forward by <ref type="bibr" target="#b27">Busemeyer et al. (1997)</ref>, assumes similarity-based interpolation, but extrapolates using simple linear rules. The model does this by falling back onto a parametric representation of the underlying function whenever generalization to points outside of the input space is required. EXAM effectively captures the human bias towards linearity, and predicts human extrapolations for a variety of functions. However, it does not account for participants' ability to extrapolate non-linear functions <ref type="bibr" target="#b12">(Bott &amp; Heit, 2004)</ref> and also has problems explaining other effect, such as the knowledge partitioning effect. This effect is based on the observation that participants' functional knowledge can be partitioned into distinct subsets based on a provided context. For example <ref type="bibr" target="#b133">, Lewandowsky et al. (2002)</ref> showed that fire fighters learn two distinct relationships between wind speed, ground slope, and the rate at which a fire spreads, depending on whether the fire was labeled as a "standard forest fire", or a "back burn" fire set to mitigate damage from future fires. As EXAM generates uni-modal predictions for any given input, it cannot account for this partitioning effect.</p><p>A hybrid model that can explain this knowledge partitioning effect is the population of linear experts model (POLE; <ref type="bibr" target="#b107">Kalish et al., 2004)</ref>. This model approximates functions using piece-wise linear representations and captures the knowledge partitioning effect by approximating partitioned functions with different locally linearized models ‡ . Moreover, it also explains the order-of-difficulty effects collected and put forward by <ref type="bibr" target="#b142">McDaniel et al. (2009)</ref>, i.e. that some functions are easier to learn than others. However, it is unclear if a combination of linear functions is able to explain human function learning in more complex and naturalistic settings, especially given that participants are able to learn in non-linear settings as well (see <ref type="bibr" target="#b12">Bott &amp; Heit, 2004)</ref>. Additionally, <ref type="bibr" target="#b28">Byun (1995)</ref> assessed whether participants can learn more complex functions using either a systematically-increasing sequence of stimulus magnitudes during training, or a randomly-organized sequence of the same magnitudes.</p><p>These training sequences facilitated learning of non-monotonic quadratic and cyclic functions, with systematic sequences producing better performance later on. Thus, participants seem to be able to learn more complex than linear functions if the learning procedure is simplified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Function learning everywhere?</head><p>The studies described so far have shown how the study of human generalization has inspired the study of function learning. However, generalization more broadly and function learning in particular are also important in many other psychological domains. Even though many of these studies do not mention the terms "function learning" or "generalization" directly, some of them have nonetheless come up with related theories and discovered related phenomena. ‡ Any differentiable function can be represented in locally linear terms Another area explaining how people make sense of and generalize from functional structure are investigations of human forecasting. Within studies about forecasting, participants are normally confronted with multiple data points at once and then have to predict future or otherwise left-out points. At least 4 different factors that can influence the way in which participants forecast visually presented data have been established (see <ref type="bibr" target="#b9">Bolger &amp; Harvey, 1998;</ref><ref type="bibr">Goodwin &amp; Wright, 1993, for detailed reviews)</ref>. First, participants have a tendency to dampen trends when generating forecasts from noisy data. This means that their forecasts lie below upward trend lines but above downward ones. Therefore, it appears that forecasters tend to underestimate the steepness of functions <ref type="bibr" target="#b0">(Andreassen &amp; Kraus, 1990;</ref><ref type="bibr" target="#b113">Keren, 1983)</ref>. Trend damping is greater for downward than for upward trended data, especially when the data representation format is visual rather than in a data table <ref type="bibr" target="#b89">(Harvey &amp; Bolger, 1996)</ref>. Second, forecasts tend to overestimate functions lacking a trend <ref type="bibr" target="#b53">(Eggleton, 1982)</ref>, i.e. sometimes people perceive a linear trend where there is none. Thirdly, participants seem to deliberately attach random noise to their forecasts, and add more noise to forecasts from noisier data series. This means that their forecasts appear to represent the way the series will appear once the outcome has occurred instead of a smooth prediction line <ref type="bibr">(Harvey Teresa Ewart Robert West, 1997)</ref>. Finally, forecasts for independent series should lie on the series mean, but instead they have been found to lie between the mean and the last revealed data point <ref type="bibr" target="#b53">(Eggleton, 1982)</ref>, a finding very similar to the results of the more traditional function learning paradigms.</p><p>A related paradigm which is also heavily based on function learning is multiple cue probability learning (MCPL, <ref type="bibr" target="#b121">Kruschke &amp; Johansen, 1999;</ref>. In MCPL tasks, participants are shown an array of cues that are probabilistically related to an outcome and have to learn the underlying function mapping the cues' features to ex-pected outcomes. One well-known paradigm of such studies is the "Weather Prediction Task" . In this task, participants predict the state of the weather ("rainy" or "fine") based on a set of "tarot cards". <ref type="bibr" target="#b73">Gluck et al. (2002)</ref> found that participants broadly seem to use three different strategies to learn within this task. The first is an optimal multi-cue strategy, in which they respond to each pattern on the basis of associations of all cues with each outcome, thus learning the function reasonably well. The second is a one-cue strategy, in which they respond on the basis of presence or absence of a single cue, disregarding all other cues. Finally, the third strategy is a singleton strategy, in which they learn only about the four patterns that have only one cue present and all others absent.</p><p>Function learning has also been discussed in the reinforcement learning literature. Already in <ref type="bibr" target="#b231">Watkins (1989)</ref>, different methods on how to generalize expected rewards over continuous or large state spaces are discussed and possible function approximators such as neural networks or the so-called "Cerebellar Model Articulation Computer", a hash function to retrieve values over spaces, are introduced. <ref type="bibr" target="#b218">Sutton (1996)</ref> proposed generalization by function learning as a method to further improve reinforcement learning algorithms.</p><p>Nowadays, deep neural networks, a powerful methods of function approximation and generalization, aid reinforcement learning models to reap rewards in complex tasks such as playing Atari games <ref type="bibr" target="#b148">(Mnih et al., 2015)</ref> or Go <ref type="bibr" target="#b199">(Silver et al., 2016)</ref>.</p><p>Psychologically, <ref type="bibr" target="#b137">Ludvig et al. (2008)</ref> recently proposed linear value function approximations for generalization across time in order to predict future rewards. Finally, Gershman &amp; Daw (2017) argue for a kernel-based approximation of the value function that maps past episodes onto future expected values. Again, all of these proposals essentially propose function learning as a tool for generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Discussion</head><p>Studies involving participants' understanding and representation of functions were originally inspired by fundamental questions about laws of human generalization and are nowadays scattered around different psychological sub-fields. Whereas original theories of human function learning focused on generalization explicitly and postulated rule-based mechanisms, later studies promoted similarity-based learning algorithms and frequently studied function learning without explicit claims about generalization. The current state of the science are hybrid accounts that were introduced to explain how people generalize to unobserved data. Within the field of subjective forecasting, a list of possible "forecasting biases" has been put forward, some of which seem to mirror established findings within the more traditional function learning literature. Multiple cue probability learning paradigms ask participants to make predictions based on multi-variate functions. Here too it has been found that participants tended to learn in a linear way but can adapt to non-linear functions if necessary. Within reinforcement learning approaches, function learning can be seen as a mechanism of value function approximation and generalization and has been put forward as a proposal within the framework of episodic reinforcement learning.</p><p>These studies show that function learning is important for various psychological domains. Moreover, the topics described here are only the ones that directly mention the term "function". Beyond that, there are also plenty of other branches of psychological research that -in one way or another-can be conceptualized as function learning. For example, multi-attribute decision making <ref type="bibr" target="#b22">(Bröder &amp; Schiffer, 2003)</ref> requires participants to learn to associate different features with expected outcomes, pattern completion paradigms <ref type="bibr" target="#b110">(Kanizsa et al., 1976)</ref> ask participants to extrapolate a pattern from seen points, and gener-alization across environments <ref type="bibr" target="#b69">(Gershman &amp; Niv, 2015)</ref> requires participants to extrapolate from features of the current environment to novel ones. That function learning is seen a separate subfield of psychology is mostly due to historical developments and practical con- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation</head><p>Let me first define the set-up of learning a function more formally before then discussing how it relates to generalization. If f denotes an (unknown) function which maps inputs</p><p>x to outputs y, f : X → Y, then function learning is the task to learn about f as well as possible provided the current input-output observations D = {X, y}. Learning about f can progress by the 3 following ways.</p><p>In a single function learning scenario, the task is to find the best model of f given the current data D. This is normally required in tasks that focus on either forecasting or pattern completion (as all of the data is revealed at once) and the representation of f is used to generate summaries of the presented patterns or to generalize the underlying function to novel input points. Somewhat misleadingly, psychology normally defines interpolation as generating predictions for input points within a provided set during the learning stage and extrapolation as generating predictions for input points from outside the learning set. However, generalization can technically already happen when generating predictions for input points within a learning set which have not been observed previously, i.e. there is a difference between interpolative judgments that require functional knowledge as compared to a more simplistic cued recall. I will nonetheless adhere to the traditional distinction between interpolation and extrapolation in this thesis. A sequential function learning task is made of a sequence of multiple single function learning tasks such that a participant is confronted with input-output pairs, i.e. the data D, step-wisely and -conventionally-has to generate predictions at every step. After making a prediction, the participant is shown the next data points, supposedly updates her underlying model, and so forth. This process makes up the key assumption of models used in the more traditional function learning tasks such as the ones described in Chapter 2 * .</p><p>The other variant of function learning differs from the previously described two variants in the way data points are selected. Whereas in single and sequential function learning tasks, the participant receives data points either randomly or in a way pre-determined by the experimentalist (for example, presented from left to right, etc.), in self-directed function learning tasks participants have to actively select input points (and then observe the output for the selected input points) in order to either learn about or optimize the underlying function f as well as possible <ref type="bibr" target="#b87">(Gureckis &amp; Markant, 2012)</ref>. This requires participants to form expectations about the usefulness of different possible observations given their current representation of f, then to select the input they think promises to be be maximally useful, observe the output, update their model, and so forth. This thesis will particularly focus on function exploration-exploitation tasks in which participants are asked to produce the highest sum of outputs over trials. This in turn asks for a delicate trade off between exploration, that is to sample unknown points in order to learn more about the underlying function, and exploitation, that is to sample points that are expected to produce high outputs.</p><p>To summarize, the following two ingredients are needed to characterize all function learning scenarios: 1. A model of f that is used to learn and generalize about f's shape.</p><p>2. A sampling strategy to select inputs based on the current knowledge of f.</p><p>The difference between 1 and 2 also maps onto the distinction between belief and sampling models, central to theories in statistics <ref type="bibr" target="#b134">(Lindley, 1956)</ref>, active learning <ref type="bibr" target="#b156">(Nelson, 2005)</ref>, and philosophy of science <ref type="bibr" target="#b41">(Crupi &amp; Tentori, 2014)</ref>.</p><p>Whereas all variants of function learning need to address what kind of model participants utilize to represent the underlying function, assessing which sampling strategy describes participants best will only be prevalent in studies concerning function explorationexploitation. The next sections will first describe how to find a useful mathematical model of how participants learn about f before one particular sampling strategy to optimize unknown functions is introduced.</p><p>3.2 Linear regression: the weight space view I begin by considering the most frequent approach to model unknown functions: linear regression (here defined as Bayesian linear regression). This can also be seen as a Bayesian variant of the rule-based approaches described in Chapter 2 and seems to capture the way in which participants generalize to unseen input spaces reasonably well.</p><p>As an example, I will use the set of stimulus-response pairs presented in <ref type="table" target="#tab_5">Table 3</ref>.1. These contain observations of stimuli (inputs) x t and responses (outputs) y t at different time points t. The running example will also include having to make a new prediction of the value of y given a new stimuli x ⋆ = 3. In linear regression, it is assumed that the outputs are <ref type="table" target="#tab_5">Table 3</ref>.1: Observa ons for the func on learning example. Inputs x t and corresponding outputs y t observed at mes t = 1, . . . , 6. t x t y t 1 0.9 0.1 2 3.8 1.2 3 5.2 2.1 4 6.1 1.1 5 7.5 1.5 6 9.6 1.2 a linear function of the inputs with additional noise:</p><formula xml:id="formula_3">y t = f(x t ) + ε t (3.1) = β 0 + β 1 x t + ε t , (3.2)</formula><p>where the noise term ε t follows a normal distribution</p><formula xml:id="formula_4">ε t ∼ N (0, σ 2 ε ) (3.3)</formula><p>with mean 0 and variance σ 2 ε . This can also be written in matrix algebra as</p><formula xml:id="formula_5">y t = x ⊤ t w + ε i (3.4)</formula><p>defining the vectors</p><formula xml:id="formula_6">x t =   1 x t   , w =   β 0 β 1   . (3.5)</formula><p>To predict the output for x ⋆ , one needs to estimate the weights from the previous observa-</p><formula xml:id="formula_7">tions X t =          1 0.9 1 3.8 . . . . . . 1 9.6          , y t =          0.1 1.2 . . . 1.2          . (3.6)</formula><p>In a Bayesian set-up, this is done through the posterior distribution over the weights. If a Gaussian prior over the weights p(w) = N (0, Σ) is used and likelihood is also Gaussian</p><formula xml:id="formula_8">p(y t |X t , w) = N (X ⊤ t w, σ 2 ε I), then the posterior distribution is p(w|y t , X t ) ∝ p(y t |X t , w)p(w) = N ( 1 σ 2 ε A −1 t X t y t , A −1 t ) (3.7)</formula><p>where</p><formula xml:id="formula_9">A t = Σ −1 + σ −2 ε X t X ⊤ t .</formula><p>As inference here is performed over the weights (i.e., one tries to find the best estimate for the β-weights), this is also sometimes referred to as "the weight space view of regression". To predict the output y ⋆ at a new test point x ⋆ , the error term can be ignored and the focus is on the expected value which is provided by the function</p><formula xml:id="formula_10">f, predicting f ⋆ = y ⋆ − ε ⋆ = f(x ⋆ ).</formula><p>In the predictive distribution of f ⋆ , the uncertainty regarding the weights is averaged out</p><formula xml:id="formula_11">p(f ⋆ |x ⋆ , X t , y t ) = ∫ p(f ⋆ |x ⋆ , w)p(w|X t , y t )dw = N ( 1 σ 2 ε x ⊤ ⋆ A −1 t X t y t , x ⊤ ⋆ A −1 t x ⋆ ) (3.8)</formula><p>A good prediction is the mean of this predictive distribution and comparing the mean to that in (3.7), one can simply multiply the posterior mean of w with the new input x ⋆ , resulting in the prediction 0.56 + 3 × 0.12 = 0.92.</p><p>Bayesian linear regression suffers from the same drawbacks as the rule-based accounts of function learning introduced before: it assumes that encountered functions have indeed a linear shape. However, adaptive generalization makes it necessary to learn about nonlinear dependencies as well. One straight-forward adjustment is to use a projection of the inputs x onto a "feature space" by using a function φ(x). A common projection is to use polynomials, resulting in polynomial regression. For example, in cubic regression, which assumes a function f(x) = β 0 + β 1 x + β 2 x 2 + β 3 x 3 , this results in a Bayesian equivalent of the most complex model put forward by <ref type="bibr" target="#b29">Carroll (1963)</ref>. Deriving the posterior for this model is similar to the linear regression described before, with the only difference that the input matrix X t is replaced by its projection (3.9)</p><formula xml:id="formula_12">Φ t = φ(X t ) =          1 0.9</formula><p>In the aforementioned example, this would result in the prediction</p><formula xml:id="formula_13">f ⋆ = −0.67 + 0.98 × 3 − 0.13 × 3 2 + 0.01 × 3 3 = 1.37.</formula><p>Projecting input variables onto a feature space offers considerably more flexibility and allows one to encode functions of many different shapes. Therefore, it is not a surprise that this method was put forward by earlier theories of human function learning <ref type="bibr" target="#b29">(Carroll, 1963;</ref><ref type="bibr" target="#b20">Brehmer et al., 1974)</ref> † .</p><p>However, this flexibility is also a drawback. There are infinitely many projections possible and one has to choose one either a priori or by model comparison within a set of possible projections. Especially if the task is to learn about a completely unknown function, which is a problem people frequently face in the real world, this approach will not be feasible as there is little guidance as to which projections should be included. From a psychologi- † Of course the frequentist proposals of function learning models at that time also went hand in hand with statistical advances in computing regression weights <ref type="bibr" target="#b244">(Zellner, 1962;</ref><ref type="bibr" target="#b95">Hoerl &amp; Kennard, 1970)</ref>, an interdependency that is frequently found in the history of psychology <ref type="bibr" target="#b72">(Gigerenzer, 1991)</ref>   cal perspective, if the aim is to find universal rules of generalization based on the parametric Bayesian regression approach, then one would have to test out many different parameterizations and how they combine, distinguishing between idiosyncratic and nomothetic parametric rules. Gaussian Process regression, which I will introduce next, offers a principled solution to the problem of choosing between many functional forms as the projections are chosen implicitly, effectively letting the observed data directly contribute to the decision about model complexity. Moreover, the properties of the chosen kernel function directly correspond to a gradient of generalization in function space. Nonetheless, I will return to the problem of assessing how different subparts are combined in Chapter 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The function space view</head><p>In the weight space view of the previous section, the focus has been on distributions over </p><formula xml:id="formula_14">y = f(x) + ε (3.10) with ε ∼ N (0, σ 2 ε ).</formula><p>Note that this is similar to the assumption made in linear regression, i.e. that an observation consists of an independent "signal" term f(x) and a "noise" term ε.</p><p>Different in Gaussian Process regression, however, is that the assumption that the signal term is also a random variable which follows a particular distribution. This distribution is subjective in the sense that the distribution reflects the uncertainty regarding the function.</p><p>The uncertainty regarding f can be reduced by observing the output of the function at different input points. The noise term ε reflects the inherent randomness in the observations.</p><p>In Gaussian Process regression, the function f(x) is taken to be distributed as a Gaussian Process:</p><formula xml:id="formula_15">f(x) ∼ GP (m(x), k(x, x ′ )) .</formula><p>(3.11)</p><p>A Gaussian Process GP is defined by a mean and a covariance function. The mean function m(x) reflects the expected function value at input x: </p><formula xml:id="formula_16">m(x) = E[f(x)],<label>(3.</label></formula><formula xml:id="formula_17">k(x, x ′ ) = E [(f(x) − m(x))(f(x ′ ) − m(x ′ ))] (3.13)</formula><p>The function k is normally called the kernel of the Gaussian Process <ref type="bibr" target="#b103">(Jäkel et al., 2007)</ref>.</p><p>Commonly, the choice of an appropriate kernel is based on assumptions such as smoothness and likely patterns to be expected in the data. One very popular choice of a kernel function is the radial basis function kernel, which is defined as</p><formula xml:id="formula_18">k(x, x ′ ) = σ 2 f exp ( − ∥x − x ′ ∥ 2 2λ 2 ) . (3.14)</formula><p>The radial basis function provides an expressive kernel to model smooth functions. It models the correlation between points in dependency of their distance.</p><p>As in Shepard's universal law of generalization, the radial basis function kernel models this dependency as a exponential function. The two hyper-parameters λ (called the lengthscale) and σ 2 f (the signal variance) can be varied to increase or reduce the correlation between points and consequentially the smoothness of the resulting function from a mathematical perspective. However, from a psychological perspective, λ could also be called the "gradient of functional generalization" as it determines how quickly the correlation between points decays as their distance grows longer and thereby how similar a function will be at two different points given their mutual distance.  The correla on is assessed as the mean correla on between two points in dependency of their mutual distance. For bigger λ-parameters, the correla on decays more slowly leading to broader generaliza on.</p><p>This also means that, theoretically, observations are expected to look more similar to the overall mean as their distance to the observed points grows longer. A radial basis function kernel therefore operationalizes Shepard's exponential rule of generalization in function space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Sampling functions from a GP</head><p>Although Gaussian Processes are continuous, sampling a function from a Gaussian Process is generally done by selecting a set of input points. Theoretically, a function can be represented as a vector of infinite size; however, as one only has to make predictions for finitely many points in practice, it is feasible to simply draw outputs for these points by using a multivariate normal distribution with a covariance matrix generated by the kernel. Let X ⋆ be a matrix with on each row i a new input point</p><formula xml:id="formula_19">x ⋆ i , i = 1, . . . , n.</formula><p>To sample a function, the covariances between all inputs in X ⋆ is first computed between all points and collected in a n × n matrix:</p><formula xml:id="formula_20">K(X ⋆ , X ⋆ ) =          k(x ⋆ 1 , x ⋆ 1 ) k(x ⋆ 1 , x ⋆ 2 ) . . . k(x ⋆ 1 , x ⋆ n ) k(x ⋆ 2 , x ⋆ 1 ) k(x ⋆ 2 , x ⋆ 2 ) . . . k(x ⋆ 2 , x ⋆ n ) . . . . . . . . . k(x ⋆ n , x ⋆ 1 ) k(x ⋆ n , x ⋆ 2 ) . . . k(x ⋆ n , x ⋆ n ).          (3.15)</formula><p>Choosing the usual prior mean function m(x) = 0, sample values of f at inputs X ⋆ from the GP are generated by sampling from a multivariate normal distribution</p><formula xml:id="formula_21">f ⋆ ∼ N (0, K (X ⋆ , X ⋆ )) (3.16)</formula><p>where the notation</p><formula xml:id="formula_22">f ⋆ = [f(x ⋆ 1 ), . . . , f(x ⋆ n )] ⊤ is used.</formula><p>Note that f ⋆ is a sample of the function values. To sample observations y ⋆ , an additional and independent sample of the noise term ε has to be added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Posterior predictions and generalization with GPs</head><p>Suppose observations D t = {X t , y t } have been collected and the goal is to make predictions for new inputs X ⋆ by drawing f ⋆ from the posterior distribution p(f|D t ). By definition, previous observations y t and function values f ⋆ follow a multivariate normal distribution.</p><p>This distribution can be written as</p><formula xml:id="formula_23">   y t f ⋆    ∼ N    0,    K(X t , X t ) + σ 2 ε I K(X t , X ⋆ ) K(X ⋆ , X t ) K(X ⋆ , X ⋆ )       (3.17)</formula><p>where I is an identity matrix (with 1's on the diagonal, and 0 elsewhere) and σ 2 ε is the assumed noise level of observations (i.e. the variance of ε). Using standard results, the con-</p><formula xml:id="formula_24">ditional distribution p(f ⋆ |X t , y t , X ⋆ ) is then a multivariate normal distribution with mean K(X ⋆ , X t )[K(X t , X t ) + σ 2 ε I] −1 y t (3.18)</formula><p>and covariance matrix</p><formula xml:id="formula_25">K(X ⋆ , X ⋆ ) − K(X ⋆ , X t )[K(X t , X t ) + σ 2 ε I] −1 K(X t , X ⋆ ) (3.19)</formula><p>Note that this posterior is also a GP with mean function</p><formula xml:id="formula_26">m t (x) = K(x, X t )[K(X t , X t ) + σ 2 ε I] −1 y t (3.20)</formula><p>and kernel</p><formula xml:id="formula_27">k t (x, x ′ ) = k(x, x ′ ) − K(x, X t )[K(X t , X t ) + σ 2 ε I] −1 K(X t , x ′ ) (3.21)</formula><p>To predict f ⋆ , the mean function in (3.20) can be used, or functions from the GP with this mean function and kernel (3.21) can be sampled as described in the previous section.  <ref type="table" target="#tab_5">Table 3</ref>.1 has been observed.  Notice how Gaussian Process regression does not predict the same response for x ⋆ = 3 as for the closest other observed value. Instead, it generalizes to this point by using the underlying kernel mapping the distance of the newly observed input points and all other points to an expectation of an underlying functional value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Switching back to the weight view</head><p>The mean function (3.20) can also be rewritten as</p><formula xml:id="formula_28">m t (x) = t ∑ i=1 w i k(x i , x) (3.22)</formula><p>where each x i is a previously observed input value in X t and the weights are collected in the</p><formula xml:id="formula_29">vector w = (K(X t , X t ) + σ 2 ε I) −1 y t .</formula><p>What this equation tells us is that Gaussian Process regression is equivalent to a rule-based regression model using basis functions k to project the inputs into a feature space. To make new predictions, every output y t is weighted by how similar the corresponding input x t was to the to be predicted point x by a similarity measure induced by the kernel. This results in a simple weighted sum to make predictions for new points. The posterior predictive mean then is a linear combination of the features. This means that a conceptually infinite parameter space boils down to a finite sum when making predictions. This sum only depends on the chosen kernel k and the data D t observed thus far <ref type="bibr" target="#b104">(Kac &amp; Siegert, 1947)</ref>. More importantly, this means that a specific gradient of functional generalization can be induced by an underlying kernel to define a regression that is both a rule-based and a similarity-based model of function learning. The shape and form of the kernel then directly implies a particular gradient of generalization. Thus, Gaussian Process regression offers a unifying bridge between the two psychological accounts of function learning. Moreover, this means that assessing which kernel (or process of kernel construction) describes human generalization will provide insights about psychological rules of generalization more broadly. Details for generating a prediction for x ⋆ = 3 given a radial basis function kernel with length scale λ = 1, and observation variance σ 2 ε = 0.01 are provided in <ref type="table" target="#tab_5">Table 3</ref>.2.  </p><formula xml:id="formula_30">w i = (K(X, X) + σ 2 ε I) −1 y i ; x ⋆ =3; t x t y t w t k(x t , x ⋆ ) w t k(x t , x ⋆ ) 1 0.9</formula><formula xml:id="formula_31">∑ 6 t=1 w t k(x t , x ⋆ ): -0.06</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Optimizing hyper-parameters</head><p>As the kernel normally contains hyper-parameters such as the length-scale λ and the signal variance σ 2 f , a point estimate of the hyper-parameters is frequently computed by maximizing the marginal (log) likelihood. This is similar to parameter estimation by maximum likelihood and is also referred to as type-II maximum likelihood (ML-II, cf .</p><p>Given the data D = {X, y} and hyper-parameters θ, the log marginal likelihood is</p><formula xml:id="formula_32">log p(y|X, θ) = − 1 2 y ⊤ K −1 y y − 1 2 log |K y | − n 2 log 2π (3.23)</formula><p>where K y = K(X, X) + σ 2 ε I is the covariance matrix of the noisy output values y. The marginal log likelihood can be viewed as a penalized fit measure, where the term 1 2 y ⊤ K −1 y y measures the data fit, that is how well the current kernel parametrization explains the dependent variable, and 1 2 log |K y | is a complexity penalization term. The final term n 2 log 2π is a normalization constant. The marginal likelihood is commonly maximized through a gradient-ascent based optimization using the partial derivatives w.r.t. ϑ:</p><formula xml:id="formula_33">∂ ∂θ j log p(y|X, θ) = 1 2 y ⊤ K −1 y − 1 2 tr ( K −1 ∂K ∂θ j ) (3.24) = 1 2 tr ( (αα ⊤ − K −1 ) ∂K ∂θ j ) (3.25) with α = K −1 y.</formula><p>This method optimizes the gradient of generalization given some empirical observations.</p><p>However, the goal of this thesis will sometimes be different from that. In particular, I will try to find a particular gradient, shape, or construction of a kernel to explain human behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Encoding smoothness</head><p>The radial basis function kernel is a special case of a general class of kernel functions called the Matérn kernel. The Matérn covariance between two points with distance</p><formula xml:id="formula_34">τ = |x − x ′ | is k ν (τ) = σ 2 2 1−ν Γ(ν) ( √ 2ν τ λ ) ν K ν ( √ 2ν τ λ ) (3.26)</formula><p>where Γ is the gamma function, K v is the modified Bessel function of the second kind, and λ and ν are non-negative covariance parameters with λ again encoding the gradient of smoothness as before. A GP with a Matérn covariance has sample paths that are ν − 1 times differentiable. When ν = p + 0.5, the Matérn kernel can be written as a product of an exponential and a polynomial of order p.</p><formula xml:id="formula_35">k p+0.5 (τ) = σ 2 f exp ( − √ 2ντ λ ) Γ(p + 1) (2p + 1) × p ∑ i=0 (p + i)! i!(p − i)! ( √ 8ντ λ ) p−i (3.27)</formula><p>Here, p directly determines how quickly the covariance between two points thins out in dependency of how far the two points are apart. If p = 0, then this leads to the Ornstein-</p><formula xml:id="formula_36">Uhlenbeck kernel k 0.5 (τ) = σ 2 f exp ( − τ λ ) , (3.28)</formula><p>which encodes the prior assumption that the function is extremely unsmooth <ref type="bibr">(rough)</ref> and that observations do not provide much information about points that are close to the points observed so far. As p → ∞ in the limit, the Matérn kernel becomes the radial basis function kernel introduced before. <ref type="figure" target="#fig_12">Figure 3</ref>.4 shows the gradient of functional generalization for both an Ornstein-Uhlenbeck (Matérn 1/2) and a radial basis function kernel.</p><p>Whereas the correlation for the Ornstein-Uhlenbeck kernel thins out very quickly but has fat tails, the correlation for the radial basis function kernel does not thin out that quickly but has thinner tails. ‡ . <ref type="figure" target="#fig_12">Figure 3</ref>.5 shows prior and posterior samples for both the Ornstein-Uhlenbeck and the radial basis function kernel. Notice how the prior samples are a lot more "rugged" for the former and much smoother for the latter. How encoding different prior smoothness assumptions leads to different posterior samples after having observed the same set of points as before can also be observed. In particular, expecting very rough functions a priori leads  to posteriors that do not generalize far beyond the encountered observations, whereas expecting smooth functions leads to posterior samples that generalize more broadly beyond the encountered points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Composing kernels</head><p>So far, I have only talked about Gaussian Process regression models that generate predictions which reverse back to the overall mean as the distance to the observed set grows longer.</p><p>Comparing these kind of kernels is similar to assessing different (more traditional) gradients of functional generalization. However, the assumption of decaying gradients might not     horizon. This is a frequently use data set for structure discovery algorithms and it is immediately clear that there is a pattern within this data. The CO2-concentration seems to increase over the years, there seems to be some periodicity by which at some times within each year the CO2 emission is higher, and this period may not be perfectly replicated every year.</p><p>Using a Gaussian Process regression framework, different kernels can be combined as building blocks in the attempt to explain these patterns.   (x − c)(x ′ − c), and the third one the sum between a linear kernel and the product between a radial basis function kernel and a periodic kernel, k(x, x</p><formula xml:id="formula_37">′ ) = σ 2 f exp ( − 2 sin 2 (π|x−x ′ |) λ 2 )</formula><p>. As the radial basis function kernel tends to reverse back to the mean over time, it does not capture the linear trend of the data. Therefore, adding a linear kernel to the radial basis function kernel already improves predictions. Finally, multiplying the radial basis function kernel with a periodic kernel to create a locally smoothed periodic kernel, which is then combined with an increasing trend by adding a linear kernel seems to predict the data best. This shows that the kernel can also be used to encode structural assumptions about the underlying function more explicitly, especially when one wants to explain more complex patterns than just generalizing over smooth functions (see <ref type="bibr" target="#b135">Lloyd et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Exploration-Exploitation</head><p>I have discussed Gaussian Process regression as a tool to be applied in single function learning or sequential function learning settings. However, as mentioned before, the third variant of function learning, self-directed function learning, requires participants to direct their own sampling behavior <ref type="bibr" target="#b87">(Gureckis &amp; Markant, 2012)</ref>. In particular, in an function exploration-exploitation scenario the goal is to find the input to a function that produces the maximum output</p><formula xml:id="formula_38">x max = arg max x∈D f(x) (3.29)</formula><p>as quickly as possible. where x max is the input that produces the highest output. Exploration here means to sample from more uncertain parts of the input space in order to gain more knowledge about the function that can be useful later on, whereas exploitation means choosing inputs that are likely to produce high outputs. One way to measure the quality of learning in a function exploration-exploitation scenario is to quantify regret <ref type="bibr" target="#b25">(Bubeck et al., 2012)</ref>. Regret is the difference between the output of the currently chosen argument and the best output possible, i.e. how much on every trial you could have chosen better</p><formula xml:id="formula_39">r(x) = f(x max ) − f(x). (3.30)</formula><p>The total regret is the sum of the regret over all trials, and the goal in an exploration-exploitation scenario is to minimize the cumulative regret:</p><formula xml:id="formula_40">R t = t ∑ u=1 r(x u ) (3.31)</formula><p>It can be shown that finding a strategy that chooses the inputs to minimize the expected cumulative regret is NP-hard <ref type="bibr" target="#b117">(Krause &amp; Guestrin, 2005)</ref>. That is, determining the sequence of queries (i.e. input choices) that leads to the lowest total regret is impossible for all but the most trivial cases. However, there is a greedy trick one can apply in this scenario, which starts by reinterpreting the function maximization -or regret minimization -problem as a multi-armed bandit task (see <ref type="bibr" target="#b215">Steyvers et al., 2009)</ref>. In a bandit task, there are multiple options (arms) with unknown probability of producing a reward and the goal is to choose the best arm in order to maximise the overall reward (the name stems from the one armed bandits that can be found in casinos). In the current situation, we can view the discretized input points as the arms of a multi-armed bandit, and the output of the function at those points as the unknown rewards that are associated to each arm. What distinguishes this situation from traditional bandit tasks is that the rewards of the arms are correlated in dependency of the underlying covariance kernel. Nevertheless, viewing the task as a multiarmed bandit allows to use sampling strategies that have been devised for traditional bandit tasks. One popular sampling strategy is called the upper confidence bound (UCB) algorithm. This algorithm relies on the following sampling strategy:</p><formula xml:id="formula_41">UCB t (x) = μ t−1 (x) + βσ t−1 (x), (3.32)</formula><p>where β is a free parameter that determines the width of the confidence interval, μ t−1 (x) and σ t−1 (x) are the predictive mean and standard deviation at a point x. For example, setting β = 1.96 results in a 95% confidence interval for a single value x given a Gaussian distribution. The UCB algorithm chooses the arm for which the upper confidence bound is currently the highest. The upper confidence bound is determined by two factors: the current estimate of the mean of f at a particular point (the higher the estimate, the higher the bound) and the uncertainty attached to that estimate (the higher the uncertainty, the higher the bound). Therefore, the UCB algorithm trades off naturally between expectation and uncertainty, that is exploitation and exploration. An example of how the UCB algorithm works, using the same data as before, is shown in <ref type="figure" target="#fig_12">Figure 3</ref>.8.  Even though the greedy UCB strategy is optimistically naïve (i.e., it inflates expectations by their uncertainties), it can be shown that its regret is sublinear, using an argument that relies on the submodularity and monotonicity of the overall information gain <ref type="bibr" target="#b212">(Srinivas et al., 2010)</ref>. Sublinear regret means that the regret per round goes down in expectation, thereby guaranteeing that the algorithm picks better points over time.</p><p>The Gaussian Process upper confidence bound sampling strategy is only one out of many Bayesian optimization sampling strategies <ref type="bibr" target="#b204">(Snoek et al., 2012;</ref><ref type="bibr" target="#b21">Brochu et al., 2010)</ref>. All of these optimization routines essentially use Gaussian Process regression as a model to represent and generalize the underlying function but apply different sampling strategies, that is different ways to map current expectations and their attached uncertainties, onto choices.</p><p>Therefore, functional generalization is also important when searching for rewards that can be predicted by context or other features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Past and present research utilizing Gaussian Process regression</head><p>Gaussian Process regression provides a concrete language for constructing and comparing priors over functions. As priors over functions can be explicitly encoded by the kernel, this means that the kernel can be used to describe expectations about functional regularities (e.g., linear trends, periodic patterns, etc.), thereby creating inductive biases that make generalization easier.</p><p>Previous work has begun to study what kind of kernels might describe human function learning and generalization. One experimental technique, known as iterated learning, estimates priors by simulating a Markov chain across multiple people-essentially a "game of telephone". Under certain assumptions, the Markov chain is guaranteed to converge to a stationary distribution, such that -asymptotically-it will generate samples from the prior . In a function learning version of this task, participants see a set of points, which they then have to remember and re-draw. The resulting points are presented to another participant, who is asked to repeat the same procedure. Iterating this procedure multiple times will reveal participants' priors over functions. <ref type="bibr" target="#b106">Kalish et al. (2007)</ref> showed that participants consistently converged to linear functions with a positive slope, even when the starting points came from a linear function with a negative slope, quadratic functions, or when they were generated at random. <ref type="bibr" target="#b136">Lucas et al. (2015)</ref> were the first to propose Gaussian Process regression as a model of human function learning. In their seminal work on Gaussian Process-based function learning, they explained the iterated learning results by postulating a GP with a mixture of experts kernel that is mostly dominated by a positively linear kernel generating functions with a linear upwards trend, but can also generate smooth non-linear extrapolations by utilizing a non-linear radial basis function kernel. Additionally, their proposed kernel contained negatively linear and quadratic components. Samples from the GP parameterized in this way tend to be linear lines with a positive slope. This parametrization was able to explain most of the findings explained in Chapter 2, such as the partitioning of the learning space, the mixture-like patterns of extrapolations, and the difficulty of learning some functions (e.g., exponential patterns) relative to others (e.g., linear patterns).</p><p>Going further, <ref type="bibr" target="#b238">Wilson et al. (2015)</ref> attempted to infer the "human kernel" by having participants generate extrapolations for different functions sampled from a radial basis kernel and fitting a non-parametric kernel (the spectral mixture defined by <ref type="bibr" target="#b237">Wilson &amp; Adams, 2013,</ref> which I will describe in detail in Chapter 5) to their extrapolations. This approach is actually quite close to the attempt of finding a functional gradient of generalization by reverse engineering what a gradient explaining human behavior looks like. The results showed that participants expected long-distance correlations between points. These correlations can be viewed as arising from a mixture between linear and radial basis components. In a second experiment, they showed that participants can effectively learn functions sampled from a mixture of a product of linear and spectral kernels. These results can be interpreted in two different ways. Either participants' functional gradient of generalization is adaptive to the situation at hand or there is something beyond just a gradient guiding participants' extrapolation judgments. I will further probe this difference in Chapter 5. <ref type="bibr" target="#b11">Borji &amp; Itti (2013)</ref> were the first to compare human behavior to that of Gaussian Processbased function optimization models within a uni-variate search task in which participants had to optimize unknown functions. Their results showed that participants sometimes outperform Bayesian optimization algorithms but overall generate similar queries and show similar regret as a Gaussian Process upper confidence bound sampling algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">The current proposal</head><p>To summarize, Gaussian Process regression as a model of generalization unites both rulebased and similarity-based accounts of function learning. The form and shape of the kernel of a Gaussian Process regression directly corresponds to assumptions about laws of generalization which might describe human behavior. My previous definition of generalization as the ability to generate and act according to predictions for new observations based on underlying commonalities directly leads (as it has historically too) to studying the psychology of function learning as a framework to discover human laws of generalization. Provided that Gaussian Process regression is a powerful method to assess different kinds of function learning, I propose to use it to study generalization. What this will mean concretely, is that I will use Gaussian Process regression to model human function learning, assess what kind of kernels and kernel parameterizations describe and predict behavior best, and then use the empirical results as indicators of psychological rules. For this, Gaussian Process is a vessel providing a window into human generalization. Thus, my proposal is similar to common approaches of Bayesian cognitive science <ref type="bibr" target="#b32">(Chater &amp; Oaksford, 2008;</ref><ref type="bibr" target="#b33">Chater et al., 2006)</ref> in that I do not restrict myself to one particular proposal (for example, one particular rule of generalization) and then assess the resulting restricted set to produce theoretical claims.</p><p>Instead, I used Gaussian Process regression as a unifying model of generalization that incor-porates as many different candidate rules as possible and then infer which one of those best explains human generalization.</p><p>With the framework of Gaussian Process regression in hand, I will now start to assess generalization across various paradigms.</p><p>"Theorems deduced which concern phenomena not already known must be submitted to carefully controlled experiments." <ref type="bibr">Clark Hull, 1935</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">From theory to behavior</head><p>This chapter derives characteristics influencing GP learning curves and assesses if participants' perceived predictability of intuitive functions are influenced by the same factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Better noisy than complex?</head><p>Previous research on human function learning has mostly focused on either single or sequential function learning tasks. Yet, there might be other aspects of function learning that can be derived from a formal theory of generalization.</p><p>Imagine having to pick between two different learning situations. The first one is relatively complex but not so noisy and the latter is relatively simple but noisy. Which one would you prefer Put differently, do you think it is easier to adapt to a system that is complex but not very noisy or to a system that is more noisy but in which observations generalize more broadly?</p><p>As it turns out, the theory of Gaussian Process regression can provide some guidance on what a sensible decision maker would prefer. Even though this guidance is not necessarily the only possible answer to this problem, it can nonetheless be informative about whether it is easier to learn in a simple yet noisy or a complex but deterministic system. Moreover, predictions that are directly derived from statistical learning theory can in this case be compared to participants' judgments about how well they think they can predict presented functions.</p><p>In order to asses this, I will first introduce the concept of Gaussian Process learning curves, which theoretically relate the expected generalization error of newly sampled input points to a function's smoothness (which in this case is just another measure of complexity), its attached noise, as well as the number of sample points previously observed. I will show that these theoretically derived learning curves predict that a rational learner should prefer to reduce complexity over noise, or taking the example from above, would rather choose to work for a noisy but currently simple start-up than for a deterministic but complex bank.</p><p>Afterwards, I will assess these predictions empirically by eliciting participants' predictability judgments, that is asking them how well they think they could generalize from given points sampled from different functions, to predict newly sampled points. I find that their judgments align well with the theoretical predictions derived from Gaussian Process learning curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Gaussian Process learning curves</head><p>Theoretically, learning curves relate the expected generalization error of a model to the amount of training data <ref type="bibr" target="#b159">(Opper &amp; Vivarelli, 1999;</ref><ref type="bibr" target="#b236">Williams &amp; Vivarelli, 2000;</ref><ref type="bibr" target="#b207">Sollich &amp; Halees, 2002)</ref>. They can be seen as a mathematical expression of a function's predictability, given assumptions about Gaussian Process-based priors over functions, the noise process, and the distribution of inputs. Intuitively, a function exhibits a higher predictability if it is easier to predict new input points that are randomly and uniformly chosen from the input space. If points are easier to predict, then the generalization error is lower as predictions will be closer to the underlying truth of the the actual function. Therefore, these two things, the predictability and the generalization error of a function, are two sides of the same coin (see also <ref type="bibr" target="#b75">Goerg, 2013)</ref>.</p><p>The learning curves for Gaussian Process regression can be used to derive a priori predictions about how different properties of functions such as smoothness, variance, and sample size influence their perceived predictability. In particular, factors that increase the generalization error should also lead to lower predictability judgments. </p><formula xml:id="formula_42">E(x) = ∫ f p(f) ∫ x⋆ L(f(x ⋆ ),f(x ⋆ )) dx ⋆ df, (4.1) wheref (x) = E[f(x ⋆ )|x, y]. (4.2)</formula><p>It is called the data-dependent error as it still depends on the position of the observed input points. The data-independent generalization error is defined as the expectation of E(x) with respect to a density p(x) on inputs with sample size n:</p><formula xml:id="formula_43">E(n) = ∫ x p(x)E(x) dx. (4.3)</formula><p>It is called the data-independent error as it does not depend on the observations directly, but rather provides an a priori expectation of the error after n sample points have been observed.</p><p>A learning curve is constructed by calculating the data-independent generalization error as a function of the sample size. While the learning curve is not analytically tractable (except for a few special cases), it is possible to derive a lower bound using the eigenfunction expansion of the covariance function:</p><formula xml:id="formula_44">k(x, x ′ ) = ∑ i λ i φ i (x)φ i (x), (4.4)</formula><p>where {λ i } is the spectrum of eigenvalues (decreasing as a function of i) and {φ i (x)} are the eigenfunctions.</p><p>As shown by <ref type="bibr" target="#b159">Opper &amp; Vivarelli (1999)</ref>, the generalization error for the squared-loss error function,</p><formula xml:id="formula_45">L(y,ŷ) = |y −ŷ| 2 , (4.5)</formula><p>can be lower-bounded by:</p><formula xml:id="formula_46">E(n) ≥ σ 2 ε N ∑ i=1 λ i σ 2 ε + nλ i , (4.6)</formula><p>where N is the number of non-zero eigenvalues. Loosely speaking, the eigenvalue spectrum summarizes how the correlation between the function values of two points changes as a function of their input distance, a mathematical translation of the previously shown functional gradient of generalization.</p><p>Smoother functions have eigenvalues that decay more slowly across the spectrum. Smooth functions have long-distance correlations, which makes it easier to learn and therefore leads to smaller generalization errors (as also shown in <ref type="figure" target="#fig_12">Figure 3</ref>.5).</p><p>The theoretical predictions of learning curves can be seen even more clearly when look-ing at covariance functions with power-law spectral decay * <ref type="bibr" target="#b207">(Sollich &amp; Halees, 2002)</ref>:</p><formula xml:id="formula_47">λ i ∝ i −r . (4.7)</formula><p>Asymptotically (E(n) ≪ σ 2 ε ), the learning curve scales as</p><formula xml:id="formula_48">E(n) ∝ ( σ 2 ε n ) − r−1 r . (4.8)</formula><p>This analysis shows that the most important factor influencing a Gaussian Process' learning curve is the smoothness of the covariance function (parametrized in terms of the spectral decay rate r). The generalization error depends polynomially on the variance but exponentially on smoothness. The implication is that noisy but smooth functions are easier to generalize and therefore to predict than deterministic but complex functions. This is intuitive, because smooth functions allow data to be more strongly aggregated across different input points (observing the function at one point provides more information about other points as seen in Chapter 3), whereas anything one can learn about a complex function is very local. Thus, the approximated learning curves predict that participants should choose simple but noisy over complex but less noisy function learning scenarios.</p><p>To create functions with different levels of smoothness, a flexible class of stationary covariance functions constructed from the modified Bessel function ) can be employed: the Matérn class introduced in the previous chapter. Let me briefly restate the Matérn class of covariance function for τ = |x − x ′ | here:</p><p>* The one-dimensional Ornstein-Uhlenbeck covariance function has this property, with r = 2.</p><formula xml:id="formula_49">k ν (τ) = σ 2 f 2 1−ν Γ(ν) ( √ 2ν τ λ ) ν K ν ( √ 2ν τ λ ) (4.9)</formula><p>where λ &gt; 0 is a length-scale parameter, K ν (•) is the modified Bessel function of order ν = p − 0.5 for integral p, and Γ(•) is the gamma function. I will refer to p as the order of the Gaussian Process.</p><p>When p = 1, Eq. 4.9 corresponds to the Ornstein-Uhlenbeck covariance function, which generates a process that is not mean square differentiable (see . This means that sampled functions will produce very rough outputs. When p &gt; 1, the process is p − 1 times mean square differentiable, becoming smoother with increasing p.</p><p>In the limit p → ∞, it is equivalent to a radial basis function kernel. I will use Matérn kernel functions of order up to 3 here as it is empirically hard to distinguish between functions of higher order (see <ref type="bibr" target="#b39">Cornford et al., 2002</ref>, for further discussion).</p><p>With these theoretical predictions in hand, I will now turn to an empirical exploration of the formally derived factors influencing a function's perceived predictability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment 1: Perceived predictability of functions</head><p>Participants will be asked to judge the predictability of provided functions (displayed as scatter plots), while the underlying smoothness, noisiness, and sample size are manipulated. This allows us to quantitatively measure the influence of these different factors on perceived predictability. Based on the analysis of learning curves described before, I derive the following 3 hypotheses:</p><p>1. Sample size and smoothness will correlate positively with perceived predictability, whereas noise variance will correlate negatively.</p><p>2. The effect of smoothness will be stronger than the effects of noise and sample size.</p><p>3. The approximate learning curve given a sample will be the most important factor influencing participants' predictability judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Participants</head><p>47 participants were recruited via prolificacademic.co.uk and received £1 for their participation. 27 participants were female and the overall age had a mean of 24 with a standard deviation of 5. The experiment took 8 minutes on average to be completed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Task</head><p>Participants were told they had to assess how well they could potentially predict different functions on a scale from 0 (not at all) to 100 (certainly). It was explained in detail to them that prediction means to assess a new input point uniformly sampled from the input range.</p><p>After passing three comprehension check questions, participants were sequentially shown 50 different samples of functions and had to indicate how well they thought they could predict a newly sampled point of that function. A screenshot of the experiment is shown in  .1: Screenshot of the predictability experiment. Dots were sampled uniformly from a func on whose order, variance, and sample size was sampled prior and unknown to par cipants. Par cipants had to indicate how well they thought they could predict this func on on a scale from 0 (not at all) to 100 (certainly).</p><p>created on the spot in JavaScript † , so no participant saw exactly the same function; only the different characteristics governing the generating process were manipulated. The lengthscale of the provided covariance function was fixed to λ = 1. It can be seen there that increasing smoothness results in higher perceived predictabil- ity, and increasing noise variance reduces perceived predictability. The overall effect of an increasing sample size on the perceived predictability seems relatively small. This finding has at least two potential explanations. First, it might be the case that participants overestimate the predictability with small sample sizes as they tend to infer smoother functions than the ones generating the data. Secondly, the equidistantly spaced inputs I presented to participants might permit easier prediction, since they cover more space overall. In order to quantitatively assess the influence of the different factors on participants' perceived predictability, I performed a mixed-effects regression with judgments nested within participants. The parameter estimates of the fixed effects are summarized in <ref type="table">Table 4</ref>.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Results</head><p>In agreement with the above qualitative characterization, both smoothness and noise variance have a significant effect on predictability. The effect of sample size, on the other increasing sample size reduces the effects of smoothness on predictability judgments. Thus, sample size does appear to be a modulator of perceived predictability. Therefore, hypothesis 1 can only be seen as partially confirmed.  Next, I calculated the correlations between each of the different factors and the predictability judgments for each participant individually and found that the averaged correlation between smoothness and perceived predictability (r = 0.36, p &lt; 0.01) was indeed greater than the correlation between noise and perceived predictability (r = −0.24, p &lt; 0.01) and between sample size and perceived predictability (r = 0.06, p &gt; 0.05).</p><p>Therefore, the second hypothesis was confirmed.</p><p>Finally, I examined whether the theoretical learning curve provides an accurate quantitative model of perceived predictability. As shown in <ref type="figure" target="#fig_26">Figure 4</ref>.3, the theoretical generalization error (binned for the plot, but not for the analysis) is a modest but significant predictor of perceived predictability (r = −34, p &lt; 0.01). On the one hand, this suggests that the model does not capture all of the essential determinants of predictability perception. On the other hand, however, a correlation coefficient essentially assumes a linear dependency between the two factors, whereas -theoretically-the effect of learning curves on judgments can be expected to be nonlinear. Therefore, the analysis above was repeated, but this time using an importance measure derived by a random forest random permutation method <ref type="bibr" target="#b1">(Archer &amp; Kimes, 2008)</ref>. Although this method is not often applied in psychology, it is frequently found in other areas such as genetics and biostatistics <ref type="bibr" target="#b13">(Boulesteix et al., 2012)</ref>. The random forest importance measure assesses for each entered variable separately by how much the predictive performance of a random forest regression decreases if this factor is randomly permuted and thereby rendered uninformative. The results of this procedure are also displayed in <ref type="table">Table 4</ref>.2 and show that the importance of the theoretically derived prediction error is indeed higher than that of the other three variables. Thus, the last hypothesis can be confirmed within limited constraints. of a function exerts a stronger influence on predictability than noise or sample size, consistent with both theoretically derived learning curves and the experimental data. This means that a smooth but noisy function is perceived as more predictable than a complex but neardeterministic function. Thus, it is -at least according to this theory-easier to learn in a noisy yet simple than a deterministic but complex system; generalizability is preferred over determinism.</p><p>Furthermore, I have shown that the model can quantitatively capture participants' predictability judgments, although it still leaves a fair amount of variance unexplained. One reason for the relatively low correlation between generalization error and predictability might be that the analysis assumed the covariance function is known. If participants use a different covariance function, this will change the form of the learning curves (although the qualitative predictions of the results reported here would remain the same; see <ref type="bibr" target="#b206">Sollich, 2005</ref>). In future work, it will be worthwhile to explore models that learn the covariance function parameters directly.</p><p>The answer to the question of how people perceive the predictability of a function is probably more nuanced than the account I have put forward here. Statistically speaking, the ability to learn a function of a given complexity improves with increasing sample size, and thus for a given level of complexity there is a sample size at which -intuitively-one would judge a function to be highly predictable. This means that, for example, the effect of smoothness on predictability might be relatively weaker than what I have found when tested at much larger samples sizes. At different levels of complexity and sample size, the human perception of the predictability of functions, as well as which factors drive that predictability, may vary.</p><p>Another drawback of the experiment presented here is that participants were never actually asked to generate predictions for a presented function, but only had to judge their perceived predictability. As elicited judgments about one's skills do not always fully correspond to one's actual abilities <ref type="bibr" target="#b164">(Paulhus et al., 1998)</ref>, the proposed measure of predictability will have to be validated further by letting participants choose between different functions and then asking them to generate predictions for newly observed points directly. This will bring predictability even closer to traditional approaches of experiments on human function learning <ref type="bibr" target="#b49">(DeLosh et al., 1997)</ref>. Unlike previous work on function learning, which has focused on interpolation and extrapolation performance, the work explored here represents a relatively novel facet of participants' perception of functions, the way in which they think a given function is predictable. I believe that this assay provides another rich source of information about function knowledge.</p><p>A different direction for future research is manipulating the way in which input points are sampled. One major difference between my current implementation of assessing participants' predictability and the theoretically-derived generalization error, is that I have sampled points equidistantly, whereas theoretically input points are assumed to either be sampled uniformly or normally at random. That points were displayed equidistantly could have caused the relatively small effect of sample size on predictability judgments as participants might have been more able to generalize functions between even a small number of equidistantly presented points. Thus, future experiments could try to assess how judgments differ if points are sampled from other distributions. Also, learning curves change as a function of whether inputs are sampled randomly or using self-directed exploration <ref type="bibr" target="#b173">(Ritter, 2007)</ref>.</p><p>While I have only considered a fairly simple family of covariance functions, evidence suggests that people can generalize over richer representations; for example, a single function may be partitioned into several different sub-functions <ref type="bibr" target="#b107">(Kalish et al., 2004)</ref>. It is possible to take this one step further and ask whether a functional gradient of generalization is indeed all there is to function learning or if perhaps it is made of simpler building blocks using a "function grammar" <ref type="bibr" target="#b51">(Duvenaud et al., 2013)</ref>. I will address this question in the next chapter.</p><p>"It is the task of our science to find the elements of thought and the rules they adhere to, how they connect." Wilhelm Wundt, 1896</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A compositional theory of generalization</head><p>This chapter develops a compositional theory of function learning and tests this theory within pattern completion, predictability, numerosity, change detection, and working memory tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Introduction</head><p>As machine learning algorithms get better across many tasks such as visual pattern classification <ref type="bibr" target="#b119">(Krizhevsky et al., 2012)</ref>, game playing <ref type="bibr" target="#b199">(Silver et al., 2016)</ref>, natural language understanding <ref type="bibr" target="#b37">(Collobert et al., 2011)</ref>, and image generation <ref type="bibr" target="#b77">(Goodfellow et al., 2014)</ref>, a main question becomes if there are still psychological findings and theories from which current algorithms could potentially benefit <ref type="bibr" target="#b126">(Lake et al., 2016)</ref>.</p><p>One frequently mentioned and almost indisputable area is people's ability to generalize broadly beyond encountered examples <ref type="bibr" target="#b178">(Schmidt, 2009)</ref>. For example, when having to judge what kind of tower blocks are stable, a neural network trained on 4 blocks can achieve a level of performance better than most human subjects, but again performs at chance level as soon as 5 instead of 4 blocks are used <ref type="bibr" target="#b131">(Lerer et al., 2016)</ref>. Whereas deep reinforcement learning algorithms can learn to play many Atari games better than even professional human players, they need more than a billion training epochs, whereas the biggest chunk of human learning in such games (for experienced players) happens within only the first few games <ref type="bibr" target="#b226">(Tsividis et al., 2017)</ref>. Whereas generative adversarial networks can produce coherent sentences and text <ref type="bibr" target="#b170">(Rajeswar et al., 2017)</ref>, human language production capacities go far beyond this, making it possible to write poems, novels, or even a PhD-thesis. What enables us to generalize so quickly and broadly beyond the encountered data?</p><p>One promising answer to this question is compositionality <ref type="bibr" target="#b79">(Goodman et al., 2008b)</ref>, the observation that often times more complex relations can be broken up into simpler elements and -even more importantly-that simple elements and rules about how they can be combined generate a grammar that can potentially be infinitely large <ref type="bibr" target="#b57">(Fodor, 2001)</ref>. As an example of a successful application of the human ability of compositional generalization to a machine learning problem, consider Lake et al. <ref type="formula">2015</ref> This chapter probes compositionality as a mechanism for generalization in human function learning. Doing so, I will define a compositional grammar of Gaussian Process kernels and rules of how they can be combined. This approach is then tested against two other models of Gaussian Process structure learning, first within relatively simple pattern completion tasks, but later also in more elaborate scenarios such as change detection and working memory paradigms. Results show that humans do indeed seem to possess compositional inductive biases and can generalize, perceive, and memorize compositional patterns better than non-compositional ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Compositionality as a core principle of generalization</head><p>Humans are seemingly able to adapt to a wide variety of structural forms <ref type="bibr" target="#b112">(Kemp &amp; Tenenbaum, 2009;</ref>; the space of such forms is essentially unbounded, raising the question of how an infinite variety of forms can be represented. A tractable approach to accomplish this is to define a compositional system that can build complex structures through the composition of simpler elements. For example, in functional programming languages, functional primitives can be combined to create more complex functions which can then be re-combined to create even more complex functions (Peyton <ref type="bibr" target="#b167">Jones, 1987)</ref>. Via re-combinations, compositionality leads to a large increase of productivity-an infinite number of representations can be constructed from a finite set of primitives <ref type="bibr" target="#b58">(Fodor, 1975;</ref><ref type="bibr" target="#b59">Fodor &amp; Pylyshyn, 1988)</ref>.</p><p>One source of evidence for compositionality in cognition comes from studies of rulebased concept learning. In these studies, the rules can be expressed as functions of logical primitives (e.g. <ref type="bibr" target="#b24">Bruner et al., 1956;</ref><ref type="bibr" target="#b198">Shepard et al., 1961)</ref>. By studying participants' mistakes and the relative learning difficulty of different concepts, researchers tried to unravel the primitives of symbolic thought and how these primitives are combined. This work has led to a rich set of theoretical ideas and empirical constraints on compositionality in concept learning <ref type="bibr" target="#b168">(Piantadosi et al., 2016;</ref><ref type="bibr" target="#b78">Goodman et al., 2008a;</ref><ref type="bibr" target="#b124">Lake et al., 2015;</ref><ref type="bibr" target="#b158">Nosofsky et al., 1994</ref>). <ref type="bibr" target="#b111">Kemp (2012)</ref> provided an exhaustive characterization of compositionality in logical domains, showing how a "conceptual universe" can be formed by a rule inference scheme based on minimal description length that explains logical reasoning data across a wide set of domains. Recently, <ref type="bibr" target="#b168">Piantadosi et al. (2016)</ref> showed how different sets of structural primitives, embedded in an approximate Bayesian inference framework, can predict distinct learning curves in rule-based concept learning experiments. Based on these and other studies, <ref type="bibr" target="#b126">Lake et al. (2016)</ref> argued that compositionality should be a core principle of algorithms "that learn and think like people."</p><p>Given the widespread theoretical and empirical support for compositionality in cognitive science, it is natural to ask whether humans make use of compositionality in their ability of generalization. With a few exceptions <ref type="bibr" target="#b70">(Gershman et al., , 2015b</ref>, prior work on function learning with GPs has assumed a fixed, non-compositional kernel * . Thus, the goal of this chapter is to formalize a compositional approach to function learning and compare it to alternative non-compositional approaches. This comparison is especially interesting when considering different variants of generalization as on the one hand generalization could just be driven by an exponentially decaying gradient of functional generalization or, on the other hand, by a compositional grammar of smaller parts.</p><p>I will probe these differences by positing two candidate kernel parameterizations that express conceptually different inductive biases. The first two learn about and generalize pattern by approximating the gradient directly. The latter accomplishes generalization by composing parts of a functional grammar. I will then present a series of experimental tests that pit these kernels against each other. The aim is to see if explaining functional generalization requires more than functional gradients, and -if so-whether and how a compositional theory of generalization can fill this theoretical gap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Generalization and structure learning with Gaussian processes</head><p>Broadly speaking, there are two approaches to parameterizing the kernel space: a fixed functional form with continuous parameters, or a combinatorial space of functional forms.</p><p>These approaches are not mutually exclusive; indeed, the success of the combinatorial approach depends on optimizing the continuous parameters for each form. Nonetheless, this distinction is useful because it allows to separate different forms of functional generalization. A function might have internal structure such that when this structure is revealed, the apparent functional complexity is significantly reduced. For example, a function com-posed of many piece-wise linear segments might have a long description length under a typical continuous parametrization (e.g., a radial basis function kernel), because it violates the smoothness assumptions of the prior. However, conditional on the change-points between segments, the function can be decomposed into independent parts each of which is welldescribed by a simple continuous parametrization (see <ref type="bibr" target="#b129">Lee &amp; Yuille, 2006</ref>, for a discussion of how this strategy is used by the brain in early vision). If internally structured functions are "natural kinds", then the combinatorial approach may be a good model of human generalization.</p><p>In the rest of this section, I describe three kernel parameterizations and their implications for human generalization. The first two are continuous, differing in their expressiveness.</p><p>The third one is combinatorial, allowing it to capture complex patterns by composing simpler kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Radial basis function kernel</head><p>As explained in Chapter 3, the radial basis function kernel is a commonly used kernel in many machine learning applications, embodying the assumption that the covariance between function values decays exponentially with input distance:</p><formula xml:id="formula_50">k(x, x ′ ) = σ 2 f exp ( − |x − x ′ | 2 2λ 2 ) , (5.1)</formula><p>where σ 2 f is a scaling parameter and λ is a length-scale parameter determining the speed of the decay over the distance between inputs. The radial basis function kernel can be seen as a direct operationalization of <ref type="bibr" target="#b197">(Shepard, 1987)</ref>'s universal rule of generalization within the function learning domain. It assumes that the same smoothness properties apply globally for all inputs and will provide a baseline to compare with more expressive kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Spectral mixture kernel</head><p>The second approach is based on the fact that any stationary kernel can be expressed as an integral using Bochner's theorem.</p><formula xml:id="formula_51">Letting τ = |x − x ′ | ∈ R P , then k(τ) = ∫ R P e 2πis ⊤ τ ψ(ds). (5.2)</formula><p>where ψ is a positive finite measure. The density S(s) of ψ is called the spectral density of k;</p><p>k and S are Fourier duals:</p><formula xml:id="formula_52">k(τ) = ∫ S(s)e 2πis ⊤ τ ds (5.3) S(s) = ∫ k(τ)e −2πis ⊤ τ dτ (5.4)</formula><p>Therefore, every kernel can also be represented by a distribution over the spectral density space. <ref type="bibr" target="#b237">Wilson &amp; Adams (2013)</ref> showed that the spectral density can be approximated by a mixture of Gaussians. The spectral density modeled with a single Gaussian is</p><formula xml:id="formula_53">φ(s, μ, σ 2 ) = 1 √ 2πσ 2 exp{− 1 2σ 2 (s − μ) 2 } (5.5) S(s) = 1 2 [φ(s) − φ(−s)] (5.6)</formula><p>The resulting kernel is given by</p><formula xml:id="formula_54">k(τ) = exp{−2π 2 τ 2 σ 2 } cos(2πτμ) (5.7)</formula><p>Extending this result to a mixture of Q Gaussians results in:</p><formula xml:id="formula_55">k(τ) = Q ∑ q=1 w q P ∏ p=1 exp{−2π 2 τ 2 p v (p) q } cos(2πτ p μ (p) q ) (5.8)</formula><p>where the qth component has the mean</p><formula xml:id="formula_56">μ q = (μ (1) q , . . . , μ (p) q ) and covariance matrix M q = diag(v (1) q , . . . .v (p) q )</formula><p>, where the inverse mean represents the component periods and the inverse standard deviation the length scales. The result is a non-parametric approach to Gaussian Process regression, in which complex kernels are approximated by mixtures of simpler ones. This approach is similar to assuming that participants learn about the gradient of functional generalization directly, by approximating the underlying correlational dependencies that have generated a given function. It is appealing when simpler kernels (e.g., the radial basis function) fail to capture functional structure. Its main drawback is that because structure is captured implicitly via the spectral density, the building blocks are psychologically less intuitive: humans appear to have preferences for linear <ref type="bibr" target="#b106">(Kalish et al., 2007)</ref> and periodic <ref type="bibr" target="#b12">(Bott &amp; Heit, 2004)</ref> functions, which are not straightforwardly encoded in the spectral mixture (though of course a mixture can approximate these functions). Since the spectral kernel has been successfully applied to reverse engineer human kernels <ref type="bibr" target="#b238">(Wilson et al., 2015)</ref>, it is a useful reference of comparison to more structured compositional approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Compositional kernel</head><p>As positive semi-definite kernels are closed under addition and multiplication, it is possible to create richly structured and interpretable kernels from well-understood base components. For example, by summing kernels, one can model the data as a sum of independent functions. Imagine a function that is linearly increasing over time but also shows some seasonal periodicity; then a combination of a linear and a periodic kernel added together might be a good description of that function (as described in Chapter 3). is to define a grammar over kernels that generates new kernels through summation or multiplication of simpler base kernels. <ref type="table" target="#tab_13">Table 5</ref>.1 summarizes the kernels used in this grammar.</p><p>Given a set of input-output pairs, the task facing the learner is to identify both the function and an underlying parse tree. As with the other kernel parameterizations, the parse tree can be chosen to maximize the marginal likelihood. ; the composi on operators are addi on and mul plica on. Adding a periodic and a linear kernel creates func ons with trends and seasonality. Mul plying a periodic kernel with a radial basis func on results in more localized periods than a standard periodic kernel would be able to capture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RBF LIN PER PER+LIN RBFxPER</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name Definition</head><p>Linear</p><formula xml:id="formula_57">k(x, x ′ ) = (x − θ 1 )(x ′ − θ 1 ) Radial basis function k(x, x ′ ) = σ 2 f exp ( − (x−x ′ ) 2 λ 2 ) Periodic k(x, x ′ ) = σ 2 f exp ( − 2 sin 2 (π|x−x ′ |θ) λ 2 )</formula><p>While other compositional grammars are possible -e.g., including a more diverse set of base kernels or other composition operators such as convolution or scaling-the proposed grammar is a useful starting point, since the components are intuitive and likely to be psychologically plausible. For tractability, the maximum number of combined kernels is fixed to be 3 and repetition of kernels are not allowed in order to restrict the complexity of the inference. The complete set of resulting kernels is shown in <ref type="table" target="#tab_13">Table 5</ref>.2. Slowly changing repeated pattern Linear + RBF + Periodic Linear trend plus local deviations plus repeated pattern Linear + Periodic × RBF Linear trend plus slowly changing repeated pattern Periodic + Linear × RBF Repeated pattern plus local deviations with increasing amplitude Linear × RBF × Periodic Slowly changing repeated pattern with increasing amplitude I will use this set of kernels as the proposed compositional function class. Given a particular task, the specific composition from the set is chosen that maximizes the marginal likelihood.</p><p>Comparing these different kernels with each other will provide insights into the way people extrapolate from experience in general and learn about functions in particular. If a radial basis function kernel describes participants' function learning well, then research on generalization should focus on finding the exact gradient of generalization, i.e. estimating λ in different tasks. If the spectral density kernel describes function learning well, this could imply that participants learn about structure implicitly and that one would have to extract the human kernel over different function learning tasks, comparing how general the distribution of the spectral density is † . If the compositional kernel explains human function learning best, then this means that participants are able to generalize more broadly and efficiently than what was previously thought.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experiment 2a: Pattern completions of compositional functions</head><p>The first experiment examines whether participants prefer compositional over non-compositional predictions of functions if the ground truth is indeed compositional. Even though this mainly reveals whether people make predictions in accordance with the underlying structure (i.e., it is not informative about inductive biases per se), Experiment 2b will examine the case where the ground truth is non-compositional. If people prefer compositions in both experiments, then that means that they have indeed strong compositional inductive biases for pattern completions. I used a "pattern completion" paradigm, motivated by prior research on pattern perception as a window into cognitive representations (e.g., <ref type="bibr" target="#b26">Buffart et al., 1981;</ref><ref type="bibr" target="#b109">Kanizsa, 1979)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants chose among 3 different completions of a partial one-dimensional function. ‡</head><p>The candidate completions were generated by the different structure learning approaches described before. The main hypothesis was that if participants have structured, compositional representations of functions, then they should prefer pattern completions generated from the compositional kernel.  <ref type="table" target="#tab_13">Table 5</ref>.2) that produced the best marginal likelihood (following Duvenaud et al., 2013).</p><p>The different mean predictions were then used to generate 3 plots (one for each kernel approach) that showed the given input as a blue curve and the new predictions (the extrapolation pattern) as a red curve. The procedure was repeated for 20 different compositions, each corresponding to a separate trial. § Most of these functions were generated from two composed kernels and contained either a linear or a periodic component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants were asked to select one of 3 extrapolations (pattern completions) they thought best completed a given function ( <ref type="figure" target="#fig_31">Figure 5</ref>.2). The position at which a kernel's predictions appeared was randomized on every trial. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Results and discussion</head><p>Participants chose the compositional completions on 69% of the trials, the spectral mixture completions on 17%, and the radial basis completions on 14% ( <ref type="figure" target="#fig_31">Figure 5</ref>.3).</p><p>Overall, the compositional completions were chosen significantly more often than the other two completions (χ 2 (N = 1040, df = 2) = 591.2, p &lt; 0.01). Moreover, assessing for each participant individually whether or not compositional completions were chosen more frequently than the other two based on a χ 2 (df = 2)-test, showed that 44 out 52 participants significantly preferred the compositional pattern completions (α = 0.05 significance level). The results thus support the hypothesis that participants prefer compositional pattern completions when the ground truth is compositional. when the ground truth is non-compositional (specifically, functions drawn from a GP with the spectral mixture kernel). If participants prefer compositional completions in this experiment, I can be more confident that the preference for such functions arises from an inductive bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Methods</head><p>Particpants 65 participants (mean age=30, SD = 9.84, 31 male) were recruited from Amazon's Mechanical Turk web service and received $0.5 for their participation. The experiment took 4 minutes on average to complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>The design was identical to the one used in Experiment 2a, apart from the fact that in this experiment the underlying functions were sampled (without any further selection) from a GP with the spectral mixture kernel parametrized with a randomly assigned number of components (sampled uniformly between 2 and 5). This time, only completions for the compositional and the spectral kernel were generated. I did not generate completions for the radial basis function kernel because in 35% of the cases on average these completions corresponded closely to predictions of the compositional kernel. This correspondence arose due to the fact that there was not much compositional structure for the compositional kernel to capture in samples from the spectral mixture kernel. Additionally, the RBF kernel can be seen as a special case of both the spectral mixture and the compositional kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>The procedure was as described in Experiment 2a, with the one difference that participants made choices between two (rather than three) completions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Results and discussion</head><p>As in Experiment 2a, participants chose compositional completions more frequently than non-compositional (spectral mixture) completions (68% vs.  If the proposal distribution is symmetric (the probability of proposing a new state x * from the current state x is the same as the probability of proposing x from x * ), then one psychologically plausible acceptance function is Barker's acceptance function <ref type="bibr" target="#b3">(Barker, 1965)</ref>:</p><formula xml:id="formula_58">A(x * , x) = π(x * ) π(x * ) + π(x) , (5.9)</formula><p>where π(x) ∝ P(x). Letting D indicate the training set, this leads to the following expression for the acceptance function:</p><formula xml:id="formula_59">A(k * , k) = p(k * |D) p(k * |D) + p(k|D) (5.10)</formula><p>which corresponds to Luce's choice rule, the most common model for discrete choice distributions in psychology. Thus, under fairly standard assumptions about the choice process, it is possible to elicit samples from the desired distribution, p(k|D), i.e. the posterior predic-tive distribution over kernels given the data. This means that MCMCP can be used to gain insights into a restricted distribution (under the assumption that predictions are based on the grammar) over compositional parts by assessing how frequently a given compositional prediction has been preferred over another one. I will therefore use empirical data to assess if participants' posterior distributions over different kernels approximates sensible compositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Experiment 3a: Compositional ground truth</head><p>In the first MCMCP experiment, the underlying functions were sampled from compositional kernels in order to see if the posterior over compositional completions converges to patterns that match the true underlying kernel. Using a MCMCP-like design provides the opportunity to check if the found restricted posterior predictive distribution corresponds well with the predictions generated by the compositional kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.1">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>Eight different functions were sampled from various compositional kernels. The input space was split into training and test sets, and then all kernel combinations were used to generate completions for the test set. I generated completions from all kernels shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>There were 8 blocks of 30 trials, where each block corresponded to a single extrapolation set.</p><p>The order of the blocks was randomized for each participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.2">Results and discussion</head><p>The average proportion of accepted kernels over the last 5 trials was calculated, as shown in In all cases, participants' subjective probability distribution over completions placed the greatest mass on the data-generating kernel (marked in red). Furthermore, I observed a strong rank correlation between an approximated posterior probability over completions ¶ and participants' subjective distribution (ρ = 0.91, p &lt; 0.01). Thus, participants approximately moved toward the true underlying posterior when the functions were generated from compositional kernels. ¶ As there is currently no reliable way to generate an exact posterior over compositional parts, the normalized marginal likelihood of each composition was used as a rough approximation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Experiment 3b: Real-world functions</head><p>The second MCMCP experiment assessed what structures people converged to when faced with real-world data, where the ground truth is unknown. The expectation was that real-world data is often intrinsically compositional (see <ref type="bibr" target="#b51">Duvenaud et al., 2013;</ref><ref type="bibr" target="#b85">Grosse et al., 2012)</ref>, and hence human inductive biases may be adapted to such functions. The input space was split into training (75% of the data) and test sets (25% of the data),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>and then all kernel combinations were fitted to the training set and used to generate completions for the test set. Proposals were sampled uniformly from this set. As periodicity in the real world is rarely ever purely periodic, I adapted the periodic component of the grammar by multiplying a periodic kernel with a radial basis function kernel, thereby locally smoothing the periodic part of the function. ** Apart from the different training sets, the procedure was identical to Experiment 3a.</p><p>‖ As shown in Chapter 3 ** See the following page for an example: http://learning.eng.cam.ac.uk/carl/mauna.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Airline Passengers</head><p>Gym Favored completions <ref type="figure" target="#fig_31">Figure 5</ref>.6: (Top) Real-world data sets used in Experiment 3b. Descrip ons and origin of the data were unknown to par cipants. (Bo om) Par cipants were shown the region in blue; most frequently selected comple ons are shown in red. Note that the periodic composi on has been adapted by mul plying it with a radial basis kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>Results (again taken from the last 5 trials) are shown in <ref type="figure" target="#fig_31">Figure 5</ref>.7, demonstrating that participants moved to intuitively plausible patterns. In particular, for both the volcano and the airline passenger data, participants moved to compositions resembling those found in previous analyses <ref type="bibr" target="#b51">Duvenaud et al. (2013)</ref>. The most frequently chosen completions for each data set are shown in <ref type="figure" target="#fig_31">Figure 5</ref>.7. The rank correlation between the subjective distributions and the approximated posterior over completions was significantly positive (ρ = 0.83, p &lt; 0.01), supporting the hypothesis that the compositional pattern completions capture human inferences about functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Experiment 4: Manual pattern completion</head><p>As so far participants were only asked to make choices between a discrete set of pattern completions, the next experiment will measure pattern completion in a less constrained task.</p><p>In Experiment 4, participants had to draw the pattern completions manually (see Cox et al., 2012, for related work), instead of choosing completions out of a provided set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9.1">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>On each round of the experiment, functions were sampled from the compositional grammar at random, the number of points to be presented on each trial was sampled uniformly between 100 and 200, and the noise variance was sampled uniformly between 0 and 25. Finally, the size of an unobserved region of the function (for completion) was sampled to be of a size between 5 and 50. Participants were asked to manually draw the function best   </p><formula xml:id="formula_60">q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q Wham! Volcano</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants were asked to draw lines into a cloud of dots that they thought best described the given data. To facilitate this process, participants placed black points into the cloud, which were then automatically connected by a black line based on a cubic Bezier smoothing curve (see <ref type="bibr" target="#b60">Forrest, 1972)</ref>. The smoothness of the Bezier curve was adapted online to fit the points provided by the participants, thereby making it possible to draw less smooth lines by placing points closer to each other † † . Participants were asked to place the first point on the left boundary and the final point on the right boundary of the graph. In between, participants were allowed to place as many points as they liked (from left to right) and could remove previously placed points. There were 50 trials in total. The dots were sampled from a function that was in turn sampled from a kernel chosen at random out of all possible combinations in the compositional grammar (as shown in <ref type="table" target="#tab_13">Table 5</ref>.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9.2">Results and discussion</head><p>The average root mean squared distance between participants' predictions (the line they drew) and the mean predictions of each kernel given the data was assessed, for both inter- † † Participants found this set-up to be very intuitive. The source code for this experiment can be found online at https://github.com/ericschulz/drawfunctions and extrapolation areas. No parameters were optimized in order to achieve better distance measures. As before, the parameters for the radial basis kernel and the number of components as well as the parameters for the spectral mixture kernel were optimized via the log marginal likelihood. I also generated predictions of the compositional kernel by choosing the composition that produced the best marginal log-likelihood given the presented dots.</p><p>Results are shown in <ref type="figure" target="#fig_31">Figure 5</ref>.9. The mean distance between the model predictions and participants' drawings were compared by performing a hierarchical t-test between the distances produced by the different models while accounting for the nestedness of distance measures within participants and trials; this is essentially the same as performing a mixed-effects regression. The mean distance between predictions and participants' drawings was significantly higher for the spectral mixture kernel than for the compositional kernel in both interpolation <ref type="formula" target="#formula_104">(</ref>  <ref type="bibr" target="#b49">DeLosh et al., 1997)</ref>, the difference in extrapolation judgments provides further evidence for the compositional kernel model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.10">Generating comparison functions</head><p>One potential concern with the previous experiments is that compositional and non-compositional functions may differ in terms of low-level perceptual characteristics, and these differences (rather than the hypothesized high-level structural differences) are driving the behavioral effects. To address this concern, a set of non-compositional functions whose low-level perceptual characteristics are matched with a set of compositional functions is required.</p><p>Thus, I generated 500 functions from both compositional and non-compositional kernels. The compositional functions were sampled randomly from the compositional grammar by first randomly sampling a kernel composition and then sampling a function from that kernel, whereas the non-compositional functions were sampled from the spectral mixture kernel, where the number of components was varied between 2 and 6 uniformly. Following Goerg (2013), I then calculated the standardized spectral entropy (or "forecastability") for each function:</p><formula xml:id="formula_61">Ω(f) = 1 − H(f) ln(2π) (5.11)</formula><p>where H(•) is the Shannon entropy (see Appendix A.1) of the function's normalized spec-</p><formula xml:id="formula_62">tral density S f .</formula><p>Forecastability can be seen as a measure of how well future output values of a function can be predicted. It takes values between 0% and 100%, representing the proportional reduction in entropy a given function achieves relative to white noise. Although forecastability technically assumes stationary functions, it has also been shown to produce reliable measures for non-stationary functions in practice <ref type="bibr" target="#b102">(Hyndman et al., 2015)</ref>. Of the 500 noncompositional functions generated, I selected those that had a forecastability of higher than 20%, but set the maximum predictability for the compositional kernel functions to be less than 40% and the minimum predictability for the spectral mixture kernel functions to be higher than 40%. This means that theoretically the functions generated from the spectral mixture kernel are more forecastable on average (i.e., contain lower entropy in their spectral density) than the functions sampled from the compositional kernel. Because of this forecastability advantage for non-compositional functions, behavior consistent with the compositional kernel predictions would then provide especially strong evidence for the compositional framework.</p><p>Afterwards, I verified that all of the functions were matched in terms of low level visual properties, as measured by a similarity measure based on the discrete wavelet Haar transform <ref type="bibr" target="#b152">Montero &amp; Vilar (2014)</ref>. The basic idea of this similarity measure is to replace the original series by its wavelet approximation coefficients at an appropriate scale, and then to measure similarity between the wavelet coefficients (see Appendix). This measure not only provides a state-of-the art similarity metric between two functions, but also has been used to model human behavior in visual integration tasks <ref type="bibr" target="#b56">(Field et al., 1993)</ref>. Each function was ranked based on its wavelet similarity to other functions and the top functions (20 compositional and 20 spectral) were selected from this set. These functions, which are used in the experiments reported below, are shown in Figures 5.10 and 5.11. Subsequently, I will refer to these functions as the "matched set."  error for a newly-sampled input point from within a (interpolation) set of points, more predictable functions should lead to lower generalization error for new inputs. This analysis identified several key factors determining the predictability of a function; specifically, predictability increases with sample size and smoothness, and decreases with noise.</p><p>In this section, I will assume that compositionality is another key factor influencing predictability. If inductive biases for functions are compositional, then I expect that such functions are perceived as more predictable. This will be now assessed by collecting both absolute and relative measures of subjective predictability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.11.1">Methods</head><p>Participants 50 participants (mean age=32, SD=7.2; 32 males) were recruited via Amazon Mechanical Turk and received $0.5 for their participation. The experiment took 9 minutes on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>On each trial, one of the "matched" functions defined above was randomly sub-sampled with a sample size n j drawn uniformly from {50, 60, . . . , 100}. Participants were asked to judge how well they thought they could predict a newly sampled input point for the function on a scale ranging from 0 (not at all) to 100 (very well). After judging the subjective predictability for all 40 of the matched functions in a randomized order, participants then had to make pairwise comparisons between compositional and non-compositional functions from -100 (function presented on the left is definitely easier to predict) to 100 (function presented on the right is definitely easier to predict). As with the absolute predictability judgments, the sample size n j was varied randomly, with the constraint that both functions had the same sample size and the position of the functions were counter-balanced over trials. Screenshots of the two tasks are shown in <ref type="figure" target="#fig_31">Figure 5</ref>.12.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.11.2">Results and discussion</head><p>As shown in <ref type="figure" target="#fig_31">Figure 5</ref>.13, compositional functions were perceived as more predictable (mean predictability judgment=55.92) than non-compositional functions (mean predictability judgment=37.88). This was confirmed by a hierarchical t-test with random effects for participants and items, t(31) = 8.35, p &lt; 0.001, d = 0.73. In, the predictability judgments for compositional judgments were more strongly correlated with sample size (r = 0.28, p &lt;  To analyze these results further, I fit a hierarchical regression model of subjective predictability (nested within participants) with two predictors: samples size and a dummy variable indicating whether or not a presented function was compositional. The fixed effect results of this analysis, summarized in <ref type="table" target="#tab_13">Table 5</ref>.3, demonstrate main effects of both compositionality and sample size. The relative predictability judgments tell a similar story ( <ref type="figure" target="#fig_26">Figure 5.14)</ref>. As with the absolute judgments, compositional functions were perceived to be more predictable relative to non-compositional functions (t(499) = 13.502, p &lt; 0.001, d = 0.63), and this difference increased with sample size (r = 0.14, p &lt; 0.001).</p><p>To understand how subjective predictability judgments match theoretical predictability, I approximated the generalization error using the average squared error for a randomly sam-   In summary, compositional functions were perceived as more predictable, even though they were generated to be theoretically less "forecastable" than the non-compositional functions sampled from the spectral mixture kernel. The generalization error produced by the compositional structure learning approach matched participants' predictability judgments more closely than any of the alternative models. Thus, in order to compare the compositional and non-compositional representations in terms of how they describe participants' learning and generalization within a historically more accurate setting, the next experiment will use a similar (yet slightly modified) paradigm as the one used by <ref type="bibr" target="#b29">Carroll (1963)</ref>.  The height of the orange bar marks the predic on and can be adjusted by using the slider. A er the predic on was submi ed, the actual output, marked by the height of the red bar, appeared and par cipants were told the absolute difference between their predic on and the actual outcome.</p><p>and 2 were sampled from the set of matched non-compositional functions. Each block consisted of 20 trials (input-output pairs). The input was uniformly sampled between 0 and 100, and the output was also transformed to range between 0 and 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.12.2">Results and discussion</head><p>Using a similar hierarchical t-test as before, participants' predictions were only marginally more accurate for the compositional functions than for the non-compositional functions (t(34) = 1.6, p &lt; 0.1, d = 0.18, see <ref type="figure" target="#fig_31">Figure 5</ref>.17). Performing a linear regression with the absolute difference between participants' predictions and the actual outputs as the dependent variable and a factor variable encoding whether or not the underlying function was compo-sitional as well as the trial number (how many predictions participants had made before) resulted in the model summarized in <ref type="table" target="#tab_13">Table 5</ref>.4.  effect turned out to be relatively small; perhaps this is because both compositional and noncompositional functions were non-linear, and these are notoriously hard to learn in the traditional function learning paradigm <ref type="bibr" target="#b28">(Byun, 1995)</ref>. Alternatively, this could also be ex-plained by the fact that the matched set was created to contain relatively similar functions.</p><p>To further disentangle the different models, sequential (i.e., trial-by-trial) predictions for the linear, compositional, spectral mixture and radial basis function kernels, were created. This allows to further assess how well each model's predictions for the n + 1 trial after having seen n outputs matched participants' predictions. As shown in <ref type="figure" target="#fig_31">Figure 5</ref>.18, the compositional kernel described participants' predictions best (r = 0.54, p &lt; 0.01) followed by the linear kernel (r = 0.21, p &lt; 0.01). The correlation for both the RBF kernel (r = 0.03) and the spectral mixture kernel did not differ significantly from zero (mean correlation:</p><formula xml:id="formula_63">r = 0.04, p &gt; 0.5).</formula><p>Importantly, the compositional kernel predicted participants' predictions significantly better than the linear kernel (t(45) = 9.38, p &lt; 0.001, d = 1.14). Additionally, more heuristic strategies such as matching the height of the input bar (r = 0.14, p &lt; 0.01) or entering as the next input the output of the previous trial (r = 0.15, p &lt; 0.01) did not predict participants' trial-by-trial behavior better than the compositional model.</p><p>Thus, the compositional kernel appears to provide the best account of trial-by-trial learning in this more traditional function learning paradigm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.13">Experiment 7: Assessing numerosity</head><p>In the next series of experiments, I will explore the broader implications of a compositional function representation for 3 domains of cognition: numerosity perception, change detection, and short-term memory. I will begin with a standard numerosity judgment task, in which participants estimate the number of dots appearing briefly on a screen. <ref type="bibr" target="#b246">Zhao &amp; Yu (2016)</ref> showed that, in the absence of explicit grouping cues, structured configurations of dots led to lower estimates compared to random configurations. This effect of structure on perceived numerosity appears to arise from the fact that dots belonging to structured con- figurations are more likely to be perceptually grouped together; these groups then become the units which are enumerated. In a related study, <ref type="bibr" target="#b245">Zhao et al. (2011)</ref> showed that the accuracy of numerosity judgments improves when statistical regularities are removed, indicating a direct relationship between statistical learning and numerosity perception.</p><p>If compositional functions are perceived as more "structured" than non-compositional functions (as suggested indirectly by the predictability experiment), then a natural hypothesis is that dot configurations generated from compositional functions will be perceived as less numerous.  <ref type="figure" target="#fig_31">Figure 5</ref>.19. <ref type="figure" target="#fig_31">Figure 5</ref>.20 shows the effect of the number of dots on participants' numerosity judgments, demonstrating that increasing the number of red dots led to greater underestimation of the actual number, consistent with the idea that perceived numerosity diminishes as structure becomes more discernible. Moreover, it can be seen that there is a difference between compositional and non-compositional functions, even though this difference was rather small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.13.2">Results and discussion</head><p>As I hypothesized that participants would underestimate the red dots if they were superimposed on more structured functions (functions sampled from a compositional kernel) as compared to relatively unstructured functions (sampled from the spectral mixture kernel) overall, I performed an aggregated comparison next. <ref type="figure" target="#fig_31">Figure 5</ref>.21 shows the direct Taken together, these results indicate that perceived numerosity is reduced to a greater extent by compositional functions compared to non-compositional functions, a finding that agrees with the results of <ref type="bibr" target="#b246">Zhao &amp; Yu (2016)</ref>: structural regularity distorts the units of perception, making them appear less numerous. Even though the non-compositional functions used here were in fact structured (as measured by forecastability), they produced a weaker effect on numerosity relative to compositional functions, arguably because their structure is less "intuitive" (i.e., they lack the inductive bias needed to easily perceive this structure).   <ref type="bibr" target="#b163">(Pashler, 1988;</ref><ref type="bibr" target="#b175">Rouder et al., 2011)</ref>. In a typical change detection paradigm, participants judge whether two stimuli presented rapidly in sequence are the same or different. It has been suggested that structured representations facilitate change detection by allowing a summary representation of the stimulus to be stored in short-term memory <ref type="bibr" target="#b16">(Brady &amp; Tenenbaum, 2013)</ref>. When the stimulus consists of multiple items, those items that are not assimilated into the summary representation are encoded as "outliers". However, because memory is capacity-limited, only a small number of outliers can be encoded. Thus, the summary representation frees up encoding resources for specific items. The more structure in the display that can be encoded, the more resources will be available for encoding specific items. Turk and received $0.5 for their participation. The experiment took 10 minutes on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.14.2">Procedure</head><p>Participants judged whether or not two consecutively displayed patterns were the same (by pressing "J") or different (by pressing "L"; see <ref type="figure" target="#fig_31">Figure 5</ref>.22). As in the numerosity ex-periment, the presented functions came from the matched set (20 compositional, 20 noncompositional, sampled without noise) and were displayed on the screen as 100 horizontally equidistant gray dots. On each trial, participants saw the original structure for 1000ms, followed by an inter-stimulus interval (500ms) and then a test probe (1000ms). Unbeknownst to participants, the probe had a 50% chance of being the same or different. pairs), respectively, and let f 1 and f 2 denote the corresponding functions. The task facing participants is to determine the posterior probability that the two functions are different:</p><formula xml:id="formula_64">P(f 1 ̸ = f 2 |D 1 , D 2 ) = P(D 1 , D 2 |f 1 ̸ = f 2 ) P(D 1 , D 2 |f 1 ̸ = f 2 ) + P(D 1 , D 2 |f 1 = f 2 ) , (5.12)</formula><p>where for simplicity we have assumed that the prior probability of change is 0.5. The change (f 1 ̸ = f 2 ) likelihood is given by: <ref type="bibr">13)</ref> and the no-change (f 1 = f 2 ) likelihood is given by:</p><formula xml:id="formula_65">P(D 1 , D 2 |f 1 ̸ = f 2 ) = ∫ f1 P(D 1 |f 1 )P(f 1 )df 1 ∫ f2 P(D 2 |f 2 )P(f 2 )df 2 ,<label>(5.</label></formula><formula xml:id="formula_66">P(D 1 , D 2 |f 1 = f 2 ) = ∫ f P(D 1 |f)P(D 2 |f)P(f)df. (5.14)</formula><p>This probabilistic model assumes that functions are encoded by a given kernel in short term memory and can make trial-by-trial predictions of performance on the change detection task. As in the other analyses, hyper-parameters were optimized with respect to the marginal likelihood for a given kernel. For the spectral kernel, the number of mixture components was treated as a free hyper-parameter (ranging from 1 to 6).</p><p>To allow for noise in the decision process, the binary response was modeled using a logistic function of the model predictions, with separate predictors for compositional and non-compositional predictions. The results of this logistic regression are summarized in <ref type="table" target="#tab_13">Table 5</ref>.6. The compositional model was a significant predictor of human change detection performance (β = 0.0122, p &lt; 0.001), whereas the spectral mixture model was only marginally predictive (p = 0.05). To show this result in a different way, I computed the point biserial correlation between the model predictions and human responses ( <ref type="figure" target="#fig_26">Figure 5.24)</ref>. The average correlation per participant for the compositional model was significantly higher than the average correlation for the spectral mixture model (r = 0.68 vs. r = 0.15, t(132) = 20.5, p &lt; 0.001, d = 3.54).</p><p>In summary, change is more easily detected in compositional functions compared to non-compositional functions, consistent with the idea that compositional functions are more efficiently encoded into a summary representation. Moreover, a GP theory of change detection, which equates compressing a function with storing it in short-term memory and thereby builds up a link between compressibility and generalization, showed that a compositional kernel allows to quantitatively predict human change detection performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.15">Experiment 9: Compositional chunking in short-term memory</head><p>The results of Experiment 8 suggested that change detection is facilitated by compositional summary representations. This has introduced the idea is that structural regularities lead to higher generalizability which in turn increases memory capacity due to making functions more compressible <ref type="bibr" target="#b15">(Brady et al., 2011;</ref><ref type="bibr" target="#b140">Mathy &amp; Feldman, 2012)</ref>. This also means that if multiple items can be chunked together, then a greater number of items can be stored in mem-ory <ref type="bibr" target="#b147">(Miller, 1956)</ref>. Chunking has been posited as the basis of exceptional expert memory <ref type="bibr" target="#b31">(Chase &amp; Simon, 1973;</ref><ref type="bibr" target="#b74">Gobet, 1998)</ref> and story comprehension <ref type="bibr" target="#b223">(Thorndyke, 1977)</ref>.</p><p>The next experiment pursues this idea further, asking whether compositional functions are more compressible (and hence more memorable) than non-compositional functions.</p><p>In order to do so, a standard short-term memory task is applied (the Sternberg paradigm; <ref type="bibr" target="#b214">Sternberg et al., 1966)</ref>, in which participants are shown a rapid sequence of items (functions) followed by an old/new judgment of a probe item. Additionally, this task allows to measure the interplay between compositionality and set size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.15.1">Methods</head><p>Participants 133 participants (mean age=31.05, SD=8.19, 71 male) were recruited via Amazon Mechanical Turk and received $0.5 for their participation. The experiment took 9 minutes on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants were shown between 2 and 6 functions sampled randomly from the matched set. Each function appeared on the screen for 1000ms. A 500ms inter-trial interval succeeded the final item, followed by a probe item. Participants were asked to judge as quickly as possible whether the probe item was old (i.e., appeared in the preceding set) or new.</p><p>There were 15 trials in total (3 trials for each set size). The probe was randomly selected to be either compositional or non-compositional, and probes were old on half of the trials. A schematic of the experiment is shown in <ref type="figure" target="#fig_31">Figure 5</ref>.25. Every s mulus was presented for 1000ms, followed by an inter-s mulus interval (500ms), and then a probe (speeded old/new judgment).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.15.2">Results and discussion</head><p>23 failed to respond correctly for more than half of the trials and were therefore excluded from further analysis. All trials that took longer than 5 seconds or less than 500ms were removed prior to analyzing the data.</p><p>Participants responded correctly on 77.8% of the compositional probes and on 66.7% of the non-compositional probes-a significant difference in accuracy (χ 2 (N = 1456, df = 1) = 14.252, p &lt; 0.001). 71 of 110 participants responded correctly more frequently to the compositional probes than to the non-compositional probes (χ 2 (N = 110, df = 1) = 9.3, p &lt; 0.01).</p><p>This result can be decomposed further into a 75% hit rate for compositional probes, compared to a 67% hit rate for the non-compositional probes (a significant difference between hit rates: χ 2 (N = 709, df = 1) = 5.19, p &lt; 0.05). 78 of 110 participants showed a higher hit rate for compositional probes as compared to non-compositional probes (χ 2 (N = 110, df = 1) = 19.2, p &lt; 0.01).</p><p>Finally, there was also a significant difference between the correct rejection rate (78% for compositional probes vs. 65% for non-compositional probes; χ 2 (N = 747, df = 1) = 8.87, p &lt; 0.01). 76 of 110 participants showed a higher correct rejection rate for compositional probes as compared to non-compositional probes (χ 2 (N = 110, df = 1) = 17.92, p &lt; 0.01).</p><p>To disentangle compositionality and set size, a logistic regression was run to predict the probability of a correct response from compositionality (i.e., compositional vs. noncompositional probe) and set size factors. As shown in <ref type="table" target="#tab_13">Table 5</ref>.7, the probability of responding correctly decreases with set size (β = −0.22), and compositional probes are more likely to be correctly identified (β = 1.24). Moreover, there was a significant interaction effect, whereby the compositional advantage decreases with set size (β = −0.18; <ref type="figure" target="#fig_31">Figure 5</ref>.26).</p><p>This might be due to an increased guessing rate at a higher level of difficulty that potentially obscures the compositional advantage.  framework that was applied to the change detection task. A participant is exposed to a study list (sequence of independent input-output datasets), denoted by D 1:N , generated by underlying functions f 1:N . The task is to compute the posterior probability that a new dataset (the test probe), denoted by D ′ , was generated by one of the functions in the study list:</p><formula xml:id="formula_67">P(f ′ ∈ f 1:N |Y) = N ∑ n=1 P(f ′ = f n |D n , D ′ ) (5.15) ∝ N ∑ n=1 P(f ′ = f n )P(D n , D ′ |f ′ = f n ). (5.16)</formula><p>Following the structure of the experiment, I will assume that the probability of an "old" trial, ∑ N n=1 P(f ′ = f n ), is 0.5. The marginal likelihood is given by:</p><formula xml:id="formula_68">P(D n , D ′ |f ′ = f n ) = ∫ f P(D n |f n = f)P(D ′ |f ′ = f)P(f)df. (5.17)</formula><p>The general optimization procedure is the same as described in the change detection model. The models' predictions for both the compositional and spectral mixture models were entered into a logistic regression to predict participants' old/new responses. Results of the logistic regression analysis are summarized in <ref type="table" target="#tab_13">Table 5</ref>.8. Only the compositional model was a significant predictor of responses (β = 0.054, p &lt; 0.001), whereas the spectral mixture model was not a significant predictor (β = 0.01, p = 0.07). responses. As shown in <ref type="figure" target="#fig_31">Figure 5</ref>.27, the compositional model produced a superior correlation compared to the non-compositional model (r = 0.35 vs. r = 0.09; t(262) = 9.97, p &lt; 0.001, d = 0.34). Moreover, assessing two more heuristic models, neither the mean squared distance between the probe and all functions in the set (r = 0.094), nor counting the number of types within the set and then stating new if the probe is of the same type as most functions within the set and old otherwise (r = 0.04) lead to higher correlations with participants' responses.</p><p>In conclusion, compositional functions are more easily remembered than non-compositional functions in a version of the Sternberg task. Participants' old/new judgments were well- captured by a Bayesian model of short-term memory that used a compositional kernel.</p><p>This Bayesian model was built under the assumption that a model that allows that assumes a particular function generalizes better than another, also manages to store this function more efficiently in short-term memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.16">Discussion</head><p>In been shown to be statistically efficient <ref type="bibr" target="#b243">(Xu et al., 2017)</ref>.</p><p>The approach described here also fits snugly with past attempts to model compositional structure in other cognitive domains. Of course, language (e.g., <ref type="bibr" target="#b36">Chomsky, 1957)</ref> and object perception (e.g., <ref type="bibr" target="#b8">Biederman, 1987)</ref> have long traditions of emphasizing compositionality.</p><p>More recently, these ideas have been extended to other domains. For example, Gershman et al. (2015b) showed how hierarchical motion perception could be understood as a kind of vector analysis, using compositional Gaussian processes to model the combination of motion flow fields. This approach has also been applied to decision making; Gershman et al. (2017) used GPs to model utility functions over tree-structured objects (e.g., meals in a restaurant). In both motion perception and decision making, simpler non-compositional models failed to explain human performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.16.2">Compositional generalization</head><p>The experiments described in this chapter establish the importance of compositional representations for functional pattern recognition and generalization. As the framework was restricted to a small number of components primarily for practical purposes, an important direction for future work will be to systematically investigate the boundaries of function composition. Fortunately, the GP formalism can accommodate a wide variety of compositional structures <ref type="bibr" target="#b51">(Duvenaud et al., 2013)</ref>, so I expect that this task can be accomplished without deviating too far from the analytical framework I have laid out here.</p><p>This work has probed in what sense (if any) human function learning can be seen as compositional within a single and sequential function learning tasks. However, composing structures learned across different tasks could provide even more powerful learning strategies across tasks. Future work could investigate the composition of structure across tasks (as for example shown by <ref type="bibr" target="#b101">Hwang et al., 2016)</ref>, for example in one-shot learning or trial-by-trial function learning experiments.</p><p>There are many other potential implications of compositional inductive biases for functions. For example, these inductive biases could shape active learning (i.e., tasks in which participants can choose the next data point). We believe that active learning model com-parisons constitute an interesting framework to pit the structured and unstructured approaches against each other <ref type="bibr" target="#b162">(Parpart et al., 2015)</ref>.</p><p>Related issues arise in reinforcement learning tasks, where agents must balance exploration and exploitation. Here, the compositional approach could be used to design nonparametric value function approximators, which have been proposed as cognitively and neurally plausible solutions to reinforcement learning problems .</p><p>New experiments will be required to discern whether reinforcement learning exploits compositional inductive biases. However, in order to assess the plausibility of a compositional function learning approach to reinforcement problems, I first have to assess whether the Gaussian Process regression approach towards human function learning is amenable to selfdirected function learning problems at all. This will be the focus of the next chapter. I investigate how people search for rewards in complex grid worlds. These grid worlds can be seen as a multi-armed bandit problem where every tile of the grid is an arm that can be sampled in order to produce and accrue an underlying reward. It will generally be participants' task to find rewards over multiple trials by sampling inputs that produce high outcomes. Within these tasks, inputs that are proximal to each other produce similar outputs, i.e. rewards are spatially correlated. As this results in similar rewards between nearby tiles, spatial correlation provides a context that can be utilized via function learning. Learning this underlying function while searching for rewards simplifies the task as one does not have to sample each option individually in order to make good decisions. Instead, learning a function enables generalization broadly beyond the visited places. This requires to sample from both currently less certain options in order to learn more about the underlying function and options that are promising to produce high reward. This frames the explorationexploitation trade-off, which is typically studied using the multi-armed bandit framework <ref type="bibr" target="#b2">(Auer et al., 2002)</ref>. The multi-armed bandit is a metaphor for a row of slot machines in a casino, where each slot machine has an independent payoff distribution. Solutions to the problem propose different policies for how to learn about which arms are better to play (exploration), while also efficiently playing known high-value arms to maximize reward (exploitation) <ref type="bibr" target="#b215">(Steyvers et al., 2009;</ref><ref type="bibr" target="#b4">Bechara et al., 1997)</ref>, with the common assumption that each arm of the bandit has its own reward distribution that needs to be learned independently.</p><p>In the real world, it is often infeasible to exhaustively explore all possibilities  and still humans and other animals are able to quickly learn in and adapt to unfamiliar environments, where the exact same situation is rarely encountered twice <ref type="bibr" target="#b128">(Lee et al., 2014)</ref>. This is in contrast to more traditional approaches to associative learning, which assume a finite set of states and actions, and then independently learn about the distribu-tion of rewards for each state <ref type="bibr" target="#b219">(Sutton &amp; Barto, 1998)</ref>. This approach falls short in more realistic scenarios with vast state spaces or a limited search horizon, where it is impossible to observe the outcomes of all possible states and actions <ref type="bibr" target="#b126">(Lake et al., 2016;</ref><ref type="bibr" target="#b239">Wilson et al., 2014)</ref>.</p><p>I propose that function learning provides a mechanism to generalize prior experience to unobserved states <ref type="bibr" target="#b222">(Tesauro, 1992)</ref>. The function learning approach relates different stateaction contexts to each other by approximating a global value function over all contexts,</p><p>including unobserved outcomes . This allows for generalization to vast and potentially infinite state spaces, based on a small, finite number of observations.</p><p>Additionally, the function learning approach can also scale to problems with complex sequential dynamics (e.g., games such as Go), and has been used in tandem with restricted search methods such as Monte Carlo tree search for navigating intractably large search trees <ref type="bibr" target="#b199">(Silver et al., 2016)</ref>. While restricted search methods have been proposed as models of human reinforcement learning <ref type="bibr" target="#b100">(Huys et al., 2015;</ref><ref type="bibr" target="#b208">Solway &amp; Botvinick, 2015)</ref>, here I focus on situations where a rich model of the structure of the environment can simplify planning and generalization <ref type="bibr" target="#b86">(Guez et al., 2013)</ref>.</p><p>I model this behavior using a Gaussian Process regression framework paired with different sampling strategies that trade off between exploration and exploitation. In two experiments, I show that people's search behavior is predicted well by a Gaussian Process function learning model paired with an optimistic sampling strategy. I conclude by arguing that participants' behavior in such tasks is surprisingly adaptive and that function approximation equips them with a powerful tool for generalization guiding them through complex spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Spatially correlated multi-armed bandits</head><p>The multi-armed bandit can be easily adapted to a function learning setting by adding spatial correlation to rewards and placing the arms either into a one-or a two-dimensional grid.</p><p>Each tile represents a playable arm of the bandit, which are initially blank and display the numerical reward value after an arm has been chosen. Traditionally, the goal in an multiarmed bandit task is to maximize cumulative payoffs by sequentially choosing one of the N-arms of the bandit that stochastically generate rewards <ref type="bibr" target="#b215">(Steyvers et al., 2009)</ref>, with learning happening independently for each arm. In the case applied here, because proximate arms generate similar rewards, there is an opportunity to form inductive beliefs about unobserved rewards by learning about an underlying value function. This allows to study how people generate beliefs about unobserved rewards and how this generalization influences their search behavior.</p><p>The spatially correlated multi-armed bandit is related to the optimal foraging context <ref type="bibr" target="#b118">(Krebs, 1980)</ref>, whereby a forager is not only guided by the search for resources, but also by the need to acquire information about the distribution of resources in the environment.</p><p>This creates a natural trade-off between exploration and exploitation <ref type="bibr" target="#b138">(March, 1991)</ref>, where an effective search policy needs to adequately balance exploring areas with higher uncertainty, while also exploiting existing information to obtain rewards. One key difference in the presented task is that the decision-maker must determine where to search, and not only whether to stay or to leave a patch.</p><p>To describe participants' behavior in such tasks, both a model of learning and a sampling strategy for where to search next are required. An example of how these two might work together is shown in <ref type="figure" target="#fig_102">Figure 6</ref>.1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Function learning model</head><p>The function learning model is set up as a type of Gaussian Process regression. Let f :</p><p>X → R denote a function over input space X that maps to real-valued scalar outputs.</p><p>As described in Chapter 3, the function can be modeled as a random draw from a Gaussian process:</p><formula xml:id="formula_69">f ∼ GP(m, k), (6.1)</formula><p>where m is a mean function specifying the expected output of the function given input</p><p>x, and k is a kernel (or covariance) function specifying the covariance between outputs. A common choice of kernel function when exploring and exploiting unknown functions is the radial basis function kernel.</p><formula xml:id="formula_70">k(x, x ′ ) = σ 2 f exp ( − |x − x ′ | 2 2λ 2 ) , (6.2)</formula><p>where λ governs how quickly correlations between points x and x ′ decay towards zero as their distance increases. The length-scale λ will be treated as a free parameter to estimate the extent to which people generalize between different points in our model comparison procedure, with smaller values indicating generalization over shorter spatial extents.</p><p>This model learns a function that maps locations, for example in a grid or an array of arms of a bandit, onto expected rewards and their attached uncertainties. It assumes that rewards are generated by an underlying function</p><formula xml:id="formula_71">y i,t = f(x i,t ) + ε t (6.3) with noise ε i,t ∼ N (0, σ 2 ε )</formula><p>. The Gaussian Process function learning model manages to predict outcomes for a broad space of both sampled and not yet observed arms and thus provides a powerful mechanism for generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Associative learning model</head><p>The associative learning model is set up as a simple mean tracking approach towards learning about the distribution of rewards for each arm individually. This model assumes that the average reward associated to an input is constant over time (i.e., no temporal dynamics), which is the case in the search task. Thus, the associative learning model computes a time-invariant posterior distribution for the mean μ j of each option j including its variance σ j . The implemented version assumes that rewards are normally distributed with a known variance but unknown mean</p><formula xml:id="formula_72">y i,t ∼ N (μ i , σ 2 ε ) (6.4)</formula><p>where the prior distribution of the mean is again a normal distribution. This implies that the posterior distribution for each mean is also a normal distribution:</p><formula xml:id="formula_73">p(μ j |D t−1 ) = N (μ j,t−1 , σ 2 j,t−1 ) (6.5)</formula><p>The estimated mean μ j,t and variance σ 2 j,t for a given option j are only updated when selected at trial t:</p><formula xml:id="formula_74">μ j,t = μ j,t−1 + δ j,t G j,t [ y t − μ j,t−1 ] (6.6) σ 2 j,t = [ 1 − δ j,t G j,t ] σ 2 j,t−1 (6.7)</formula><p>where δ j,t = 1 if option j was chosen on trial t, and 0 otherwise. Intuitively, the estimated mean of the chosen option μ j,t is updated based on the difference between the observed value y t and the expected mean μ j,t−1 , multiplied by G j,t . At the same time, the estimated variance σ 2 j,t is reduced by a factor of 1 − G j,t , where G j,t is defined as:</p><formula xml:id="formula_75">G j,t = σ 2 j,t−1 σ 2 j,t−1 + θ 2 ε , (6.8)</formula><p>where θ 2 ε is the error variance, which is estimated as a free parameter. Intuitively, the estimated mean of the chosen option μ j,t is updated based on the difference between the observed value y t and the expected mean μ j,t−1 , multiplied by G j,t . At the same time, the estimated variance σ j,t is reduced by a factor of 1 − G j,t , which is in the range [0, 1]. The error variance (θ 2 ε ) can be interpreted as an inverse sensitivity, where smaller values result in more substantial updates to the mean μ j,t , and larger reductions of uncertainty σ j,t . The prior mean of the mean value of payoffs is set to μ j,0 = 50 and the prior variance to σ 2 j,0 = 500 6.4 Adaptive sampling strategies I consider various computational models for describing human sampling strategies. All of these strategies make sequential predictions about where people are likely to search for rewards. As both learning models generate normally distributed predictions about the expectation μ(x) and the uncertainty σ(x) for each arm, which are available to the sampling strategies for evaluating the quality, q(x), and ultimately making a prediction about where to sample next, i.e. which arm participants are likely to sample on a given trial.</p><p>The Variance Greedy (VG) strategy values an arm using only the estimated uncertainty</p><formula xml:id="formula_76">q VG (x) = σ(x) (6.9)</formula><p>and is an efficient step-wise (greedy) approximation of information gain <ref type="bibr" target="#b212">(Srinivas et al., 2010)</ref>, which seeks to learn the global value function as rapidly as possible. VG achieves at least a constant fraction of the optimal information gain value <ref type="bibr" target="#b117">(Krause &amp; Guestrin, 2005)</ref>; however, it fails to adequately trade-off between exploration and exploitation, because effort is wasted exploring the function where f(x) is small and only learning about the function is not the objective of the task, but rather to both explore and exploit the function over time.</p><p>The Mean Greedy (MG) strategy is also step-wise greedy, valuing arms using only the estimated mean reward</p><formula xml:id="formula_77">q MG (x) = μ(x) (6.10)</formula><p>although this strategy carries no known guarantees and is prone to getting stuck in local optima.</p><p>Upper confidence bound sampling (UCB) as described in Chapter 3 combines the VG and MG strategies</p><formula xml:id="formula_78">q UCB (x) = μ(x) + βσ(x) (6.11)</formula><p>where the exploration factor β determines how the reduction of uncertainty trades off against exploiting high expected rewards. This is sometimes referred to as optimistic "sam-pling with confidence" as it inflates expectations with respect to the upper confidence bounds <ref type="bibr" target="#b212">(Srinivas et al., 2010)</ref>, creating a natural balance between exploration and exploitation. The parameter β will be optimized as a free parameter.</p><p>There are also various other sampling strategies that combine expectations and uncertainties but in other ways than the upper confidence bound sampling strategy described in Chapter 3.</p><p>The Expected Improvement (EXI) evaluates each option by how much (in expectation) it promises to be better than the best outcome (x + = arg max x i ∈x1:t f(x i )) observed so far:</p><formula xml:id="formula_79">q EXI (x) =        Φ(Z)(μ(x) − f(x + )) + σ(x)φ(Z), if σ(x) &gt; 0 0, if σ(x) = 0 (6.12)</formula><p>where Φ(•) is the normal CDF, φ(•) is the normal PDF, and</p><formula xml:id="formula_80">Z = (μ(x) − f(x + ))/σ(x).</formula><p>The Probability of Improvement (POI) strategy evaluates an option based on how likely it will be better than the best outcome (x + ) observed so far:</p><formula xml:id="formula_81">q POI (x) = P ( f(x) ≥ f(x + ) ) = Φ ( μ(x) − f(x + ) σ(x) ) (6.13)</formula><p>where Φ(•) is the normal CDF. This sampling strategy assesses the probability of one option to generate a higher utility than the best option observed so far. Similar strategies have been used in experiments involving multi-attribute choices before .</p><p>The Probability of Maximum Utility (PMU, Speekenbrink &amp; Konstantinidis, 2015) samples each option according to the probability that it results in the highest reward of all options in a particular context.</p><formula xml:id="formula_82">q PMU (x) = P ( y j ≥ y i , ∀i ̸ = j ) (6.14)</formula><p>This sampling strategy will be implemented by Monte Carlo sampling from the posterior predictive distribution of a learning model for each option, and evaluating how often a given option turns out to be the maximum over 1,000 generated samples. It is a form of probability matching and can be implemented by sampling from each option's predictive distribution once, and then choosing the option with the highest sampled pay-off. This strategy can be seen as a form of probability matching <ref type="bibr" target="#b155">(Neimark &amp; Shuford, 1959)</ref> and can be implemented by sampling from each option's predictive distribution once, and then choosing the option with the highest sampled pay-off. Even though this sampling strategy seems relatively simple, it describes human choices in restless bandit tasks well <ref type="bibr" target="#b210">(Speekenbrink &amp; Konstantinidis, 2015)</ref>. It is also closely related to Thompson sampling <ref type="bibr" target="#b141">(May et al., 2012)</ref>, which samples from the posterior distribution of the mean rather than the predictive distribution of rewards. Thus, while Thompson sampling "probability matches" the expected rewards of each arm, the probability of maximum utility rule matches to actual rewards that might be obtained.</p><p>All possible combinations of the learning models and sampling strategies will be compared by how well they predict participants' behavior within different versions of the spatiallycorrelated multi-armed bandit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1">Heuristic strategies</head><p>Local search predicts that search decisions have a tendency to stay local to the previous choice. This can be incorporated by using the inverse Manhattan distance (IMD) to quan-tify locality: <ref type="bibr">(6.15)</ref> where x and x ′ are vectors in R n . For the special case where x = x ′ , I set IMD(x, x ′ ) = 1.</p><formula xml:id="formula_83">IMD(x, x ′ ) = n ∑ i=1 |x i − x ′ i |,</formula><p>With the exception of the local search model itself, all other models can also be localized. A form of a win-stay lose-sample (WSLS) heuristic <ref type="bibr" target="#b10">(Bonawitz et al., 2014)</ref> is implemented,</p><p>where a win is defined as finding a payoff with a higher or equal value than the previous best. When the decision-maker "wins", it is assumed that any tile with a Manhattan distance ≤ 1 is chosen (i.e., a repeat or any of the four cardinal neighbors) with equal probability. Losing is defined as the failure to improve, and results in choosing any unrevealed tile with equal probability.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>A 2×2 between subject design was used, where participants were randomly assigned to one of two different pay-off conditions and one of two different classes of environments.</p><p>Each grid represented a uni-variate function, with each observation including normally distributed noise, ε ∼ N (0, 1). The task was presented over 16 blocks on different grid worlds drawn from the same class of environments. In each block, participants had either a Short (5 clicks) or Long (10 clicks) search horizon to interact with the grid. The search horizon alternated between blocks (within subject), with initial horizon length counterbalanced between subjects. Per block, observations were scaled to a uniformly sampled maximum value in the range of 65 to 85, so that the value of the global optima could not be easily guessed (e.g., a value of 100). <ref type="figure" target="#fig_102">Figure 6</ref>.3 shows the design of Experiment 10. Sample horizons could be either short (5 clicks) or long (10 clicks, within subject manipula on, counter-balanced).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and procedure</head><p>Before starting, participants were shown four fully revealed grids in order to familiarize themselves with the task. Example environments were drawn from the same class of environments assigned to the participant (Smooth or Rough) and underwent the same random scaling of observations. Additionally, three comprehension questions were used to ensure full understanding of the task.</p><p>At the beginning of each of the 16 blocks, one random tile was revealed and participants could use their mouse to click any of the 30 tiles until the search horizon was exhausted,</p><p>including re-clicking previously revealed tiles. Clicking an unrevealed tile displayed the numerical value of the reward along with a corresponding color aid, where darker colors indicated higher point values. Previously revealed tiles could also be re-clicked, although there were variations in the observed value due to noise. For repeat clicks, the most recent observation was displayed numerically, while hovering over the tile would display the en-tire history of observations. The color of the tile corresponded to the mean of all previous observations.</p><p>Payoff conditions Performance will be compared under two different payoff conditions, requiring either a balance between exploration and exploitation (Accumulators) or a more exploration focused context of having to find the overall maximum without accruing rewards on every trial (Maximizers). Previous work has shown that people can adapt (sometimes with difficulty)</p><p>to different payoff conditions in information acquisition tasks <ref type="bibr" target="#b144">(Meder &amp; Nelson, 2012)</ref>.</p><p>In each payoff condition, participants received a performance contingent bonus of up to $1.50. Importantly, participants in the Accumulator group were told to "gain as many points as possible across all 16 grids" and were given a bonus based on the sum of their overall points. Participants in the Maximizer condition were told to "learn where the largest reward is" and were given a bonus using the ratio of the highest observed reward to the global optimum, ( max yt y * ) 4 , taken to the power of 4 to exaggerate differences in the upper range of performance and for parity in expected earnings across payoff conditions. All 16 blocks were weighted equally, using noisy but unscaled observations to assign a bonus of up to $1.50. Subjects were informed in dollars about the bonus earned at the end of each block. Repeated participation was not allowed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smoothness of the environment</head><p>Two different classes of environments were used, corresponding to different levels of smoothness ( <ref type="figure" target="#fig_102">Fig. 6.2)</ref>. All environments were sampled from a Gaussian Process prior parameterized with a radial basis function kernel, where the length-scale parameter (λ) determines the rate at which the correlations of rewards decay over distance. I sampled 20 Smooth environments (λ = 2) and 20 Rough environments (λ = 1). Subjects performed the task on 16 grids randomly drawn (without replacement) from their assigned class of environments, while the four fully revealed environments used to familiarize subjects with the task were the remaining 4 environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search horizons</head><p>The length of the search horizon influences the value of information learned about the environment, with respect to the assigned payoff condition. Longer horizons provide more opportunities for exploiting acquired information, thereby making early exploration more valuable. I chose two horizon lengths (Short= 5 and Long= 10) that were fewer than the total number of tiles on the grid (total number of arms was 30), and varied within subject (alternating between blocks). ). There may be a less-is-more-effect <ref type="bibr" target="#b145">(Medvec et al., 1995)</ref>, with longer horizons leading to over-exploration, given the goal of maximizing average rewards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.3">Cross-validation</head><p>The cross-validation procedure assesses all 27 models resulting from combining all models of learning with all sampling strategies and also comparing the heuristic strategies as well.</p><p>I use maximum likelihood estimation (MLE) for parameter estimation and cross-validation to measure out-of-sample predictive accuracy. A softmax choice rule transforms each model's prediction into a probability distribution over options:</p><formula xml:id="formula_84">p(x) = exp(q(x)/τ) ∑ N j=1 exp(q(x j )/τ) , (6.16)</formula><p>where q(x) is the predicted value of each option x for a given model, and τ is a free temperature parameter. Lower values of τ indicate more concentrated probability distributions, corresponding to more precise predictions.</p><p>In general, for the Gaussian Process-based function learning models I estimate the lengthscale, λ, of the radial basis function kernel and for the associative learning models σ 2 ε , the error variance. The upper confidence bound sampling strategy has a free parameter β, governing the exploration bonus. Additionally, all models include τ as a free parameter modeling the concentration of predictions within the softmax transformation.</p><p>All models were fitted-per participant-using cross-validated MLE, with either a Differential Evolution algorithm <ref type="bibr" target="#b153">(Mullen et al., 2009)</ref>  Prediction error (computed as log loss) is summed up over all rounds, and is reported as predictive accuracy, using a pseudo-R 2 measure that compares the total log loss prediction error for each model to that of a random model.</p><formula xml:id="formula_85">R 2 = 1 − log L(M k ) log L(M rand ) , (6.17)</formula><p>where log L(M rand ) is the log loss of a random model (i.e., picking options with equal probability) and log L(M k ) is the log loss of model k's out-of-sample prediction error. Intuitively, R 2 = 0 corresponds to prediction accuracy equivalent to chance, while R 2 = 1 corresponds to theoretical perfect prediction accuracy, since log <ref type="bibr" target="#b143">McFadden, 1973)</ref>, although it uses a completely random model M rand as baseline.</p><formula xml:id="formula_86">L(M k )/ log L(M rand ) → 0 when log L(M k ) ≪ log L(M rand ). This measure is similar to McFadden's pseudo-R 2 (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model comparison results</head><p>Results of the full model comparison for Experiment 10 are shown in <ref type="figure" target="#fig_102">Figure 6</ref>.5.    Environments could be either smooth or rough (between subject manipula on). Sample horizons could be either short (20 clicks) or long (40 clicks, within subject manipula on, counter-balanced).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and procedure</head><p>Materials and procedures were almost identical to the uni-variate case. Participants were shown four fully revealed grids in order to familiarize themselves with the task before they started. Example environments were drawn from the same class of environments assigned to the participant (Smooth or Rough). As before, three comprehension questions were used to ensure full understanding of the task.</p><p>At the beginning of each of the 8 blocks, one random tile was revealed and participants could use their mouse to click any of the 30 tiles until the search horizon was exhausted,</p><p>including re-clicking previously revealed tiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Payoff conditions</head><p>Performance is compared under two different payoff conditions, Accumulators) or Maximizers. In each payoff condition, participants received a performance contingent bonus of up to $1.50. All 8 blocks were weighted equally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smoothness of the environment</head><p>All environments were sampled from a bivariate Gaussian Process prior parameterized with a radial basis function kernel. I sampled 20 Smooth environments using λ = 2 and 20</p><p>Rough environments using λ = 1. Subjects performed the task on 8 grids randomly drawn (without replacement) from their assigned class of environments, while the four fully revealed environments used to familiarize subjects with the task were randomly drawn from the remaining 12 environments without replacement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search horizons</head><p>The two horizon lengths were 20 for Short and 40 for Long blocks and varied within subject (alternating between blocks) as in Experiment 10.  rewards for all payoffs and environment conditions (t(79) = 9.98, p &lt; 0.001, d = 1.12).</p><formula xml:id="formula_87">q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.3">Cross-validation results</head><p>Cross-validation was performed as in Experiment 10 for all 27 models and each participant individually. In total, the cross validation for the bivariate experiment took around 52,000 hours or about 3 days on distributed across a 716 CPU cluster.</p><p>Results of the full model comparison for Experiment 11 are shown in <ref type="figure" target="#fig_102">Figure 6</ref>.10.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Discussion</head><p>Generalization is a powerful tool that helps guide human decision making, supporting faster learning rates and increased performance. In this chapter, I examined human behavior in a reward acquisition task within two type of grid worlds containing spatially corre-lated rewards. These environments were designed such that the number of states vastly exceeded the available search horizon. However, the presence of spatial correlation provided traction for generalization, making it possible to learn an underlying value function based on spatial context. Participants performed better with stronger spatial correlations, reached similar performance in short compared to long horizons, and were sometimes able to find the optimal option just by balancing exploration and exploitation.</p><p>Using predictive cross-validation, I found that participants were best described by a</p><p>Gaussian Process-based function learning model, which relates different search options by their spatial contexts. The advantage of function learning is that it provides a mechanism for generalization from a small number of observations to a vast number of possibilities.</p><p>The recovered parameter estimates indicate that there was a systematic tendency to undergeneralize the strength of spatial correlations, yet comparisons with associative learning models provide evidence that generalization is a robust and recoverable phenomenon (also see Appendix).</p><p>Participants seem to deliberately trade off between exploration and exploitation as they are predicted well by an upper confidence bound sampling strategy. Even though this strategy is both optimistic (by assuming uncertainty is always positive) and myopic, it is nonetheless the only known algorithm with performance guarantees <ref type="bibr" target="#b212">(Srinivas et al., 2010)</ref> in this setting. Similar approaches have previously been applied to problems in ecology <ref type="bibr" target="#b81">(Gotovos et al., 2013)</ref>, robotics <ref type="bibr" target="#b6">(Berkenkamp et al., 2016)</ref> and biology <ref type="bibr" target="#b50">(Desautels, 2014)</ref>. The finding that human behavior is best predicted by this model shows that humans are capable of learning and adapting their behavior in complex and uncertain environments, even if an optimal solution is unobtainable.</p><p>The results presented in this chapter have tried to bridge a gap in the current reinforce-ment learning literature by stressing the importance of generalization, specifically in situations in which humans have to learn and adapt to environments where not all outcomes can be observed. This has been one of the first studies to predict individual decisions in such a complex search task, including a rigorous comparison between 27 models that yielded robust model comparisons and parameter estimates. Interestingly, recent findings have connected both spatial and conceptual representations to a common neural substrate <ref type="bibr" target="#b38">(Constantinescu et al., 2016)</ref>, opening up the opportunity to apply the function learning model to assess generalization and decision making in further contextualized settings. This will be the focus of the next chapter.</p><p>"In time, and as one comes to benefit from experience, one learns that things will not turn out as well as one hoped." <ref type="bibr">Jerome Bruner, 1966</ref> 7.1 Introduction Chapter 6 focused on search behavior in various grid worlds in a spatially correlated multiarmed bandit paradigm. As different options' rewards were related by their spatial location, learning a function mapping space to expected rewards provided an opportunity for generalization. Thus, the spatial location of an option acted as a context guiding participants' decision making. However, contextual cues do not only come as spatial information but can frequently also contain conceptual information. Coming back to the restaurant example from before, if you are trying to find a good restaurant to dine in tonight, you might not even know the location of different restaurants, but rather use other contextual cues such as the price of the food on the menu or recommendations from friends and online rating pages.</p><p>This chapter investigates human behavior in such problems within a paradigm called the contextual multi-armed bandit task. Learning and decision making within contextual multi-armed bandit tasks require the same two elements as before: learning a function that maps the observed features of options to their expected rewards, and a sampling strategy that uses these expectations to choose between the options. Function learning is important as it allows one to generalize previous experiences to novel situations. For example, it allows to predict the quality of a new restaurant from experiences with other restaurants with a similar number of customers and a similarly priced menu. The decision (or sampling) strategy is important because not only should one attempt to choose options that are currently most rewarding, but also take into account how much one can learn in order to make good choices in the future. This again means taking into account the exploration-exploitation trade-off, where exploration means learning about the function that relates features to re-wards and exploitation means using that functional knowledge to generate high rewards.</p><p>In what follows, I will introduce the contextual multi-armed bandit paradigm in more detail and propose several models to describe how people solve such tasks. I will then describe three experiments which explore how people perform within different variants of the task. The results will show that participants are able to learn within this paradigm, approximating the function in an efficient way <ref type="bibr" target="#b212">(Srinivas et al., 2010;</ref><ref type="bibr" target="#b136">Lucas et al., 2015)</ref> and using their knowledge to sensitively balance exploration and exploitation. However, the extent to which participants are able to learn and generalize the underlying function depends on the complexity of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Contextual multi-armed bandits</head><p>A contextual multi-armed bandit task (CMAB) is a game in which on each round, an agent is presented with a context (a set of features) and a number of options which each offer an unknown reward. The expected rewards associated to each option depend on the context through an unknown function. The context can contain general features that apply to all options (e.g., the city the restaurants are in) or specific features that apply to single options (e.g., the exact menu and its price). The agent's task is to choose those options that will accumulate the highest reward over all rounds of the game. The rewards are stochastic, such that even if the agent had complete knowledge of the task, a choice would still involve a kind of gamble. In this respect, choosing an option can be seen as choosing a slot machine (a one-armed bandit) to play, or, equivalently, choosing which arm of a multi-armed bandit to play. After choosing an option in a round, the agent receives the reward of the chosen option but is not informed of the foregone rewards that could have been obtained from the other options. For an agent who ignores the context, the task would appear as a restless bandit task (e.g., <ref type="bibr" target="#b210">Speekenbrink &amp; Konstantinidis, 2015)</ref>, as the rewards associated with an arm will vary over time due to the changing context. However, learning the function that maps the context to (expected) rewards will make these changes in rewards predictable and thereby choosing the optimal arm easier. In order to choose wisely, the agent should thus learn about the underlying function. Sometimes, this may require her to choose an option which is not expected to give the highest reward on a particular round, but one that might provide useful information about the function, thus choosing to explore rather than to exploit.</p><p>Contextual multi-armed bandit tasks provide a scenario in which a participant has to learn a function in order to maximize the outputs of that function over time by making wise choices. They are a natural extension of both the classic multi-armed bandit task, which is a CMAB with an invariant context throughout, and the restless bandit task, which is a CMAB with time as the only contextual feature.</p><p>While the CMAB is novel in the psychological literature (though see <ref type="bibr" target="#b216">Stojic et al., 2015,</ref> for a related task), where few tasks explicitly combine function learning and experiencebased decision making, there are certain similarities with tasks used in previous research.</p><p>For example, recent studies in experience-based decision-making provided participants with descriptions about the underlying distributions that generate rewards (e.g., <ref type="bibr" target="#b130">Lejarraga &amp; Gonzalez, 2011;</ref><ref type="bibr" target="#b233">Weiss-Cohen et al., 2016)</ref>. Just as in the CMAB, this presents a naturalistic decision environment in which different sources of information (e.g., descriptions and participants' own experience) need to be integrated in order to choose between alternatives or courses of action.</p><p>Another related paradigm is multiple cue probability learning <ref type="bibr">(MCPL, Kruschke &amp; Johansen, 1999;</ref> in which participants are shown an array of cues that are probabilistically related to an outcome and have to learn the underlying function mapping the cues' features to expected outcomes. Especially when the outcome is a categorical variable, such as in the "Weather Prediction Task" <ref type="bibr" target="#b73">(Gluck et al., 2002;</ref> as described in Chapter 2, making a prediction is structurally similar to a decision between multiple arms (possible predictions) that are rewarded (correct prediction) or not (incorrect prediction). Just as in the CMAB, multiple-cue probability learning and probabilistic category learning tasks require people to learn a function which maps multiple cues or features to expected outcomes. An important difference however is that in these latter tasks there is a strong dependency between the options: there is only one correct prediction, and hence there is a perfect (negative) correlation between the rewards for the options. Whether a current choice was rewarded or not thus provides information about whether the non-chosen options would have been rewarded. This dependency weakens the need for exploration, especially when the outcome is binary, in which case there is no need for exploration at all. In CMAB tasks, there is a stronger impetus for exploration, as the rewards associated to arms are generally conditionally independent, given the context.</p><p>Knowing that a particular option was rewarded thus does not provide immediate information whether another option would have been rewarded. Another major difference is that MCPL tasks generally require participants to learn the whole function. In CMAB tasks, learning the function is only necessary insofar as it helps to generalize from observed outcomes and thus leads to better decisions. To solve the exploration-exploitation dilemma, it may suffice to learn the function well only in those regions that promise to produce high rewards. Moreover, as I will describe later, each option can be governed by its own function relating context to rewards. To the best of my knowledge, simultaneous learning of multiple functions has not previously been investigated.</p><p>Another area of related research comes from the associative learning literature, where it has been shown that context can act as an additional cue to maximize reward (cf <ref type="bibr" target="#b14">Bouton &amp; King, 1983;</ref>. In one example of this, <ref type="bibr" target="#b69">Gershman &amp; Niv (2015)</ref> showed how generalization based on context (the average reward of options in an environment) can explain how participants react to novel options in the same environment, such that a high-reward context leads people to approach novel options, while a low-reward context leads to avoidance of novel options. The CMAB paradigm introduced here is related to such situations, but instead of a single, constant context, varies the contexts such that good performance requires learning the underlying contextual function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">General CMAB task</head><p>In the experimental implementation of the CMAB task, participants are told they have to mine for "Emeralds" on different planets. Moreover, it is explained that at each time of mining, the galaxy is described by 3 different environmental factors, "Mercury", "Krypton", and "Nobelium", that have different effects on different planets. Participants are then told they have to maximize their production of Emeralds over time by learning how the different environmental factors influence the planets and choosing the planet they think will produce the highest outcome in light of the available factors. Participants were explicitly told that different planets can react differently to specific environmental factors. A screenshot of the CMAB task can be seen in <ref type="figure">Figure 7</ref>.1.</p><p>As each planet responds differently to the contexts, they can be seen as arms of a multiarmed bandit that are related to the context by different functions. The reward of an op- tion j is given as</p><formula xml:id="formula_88">y j,t = f(a t = j, x t ) = f j (x t ) + ε j,t (7.1)</formula><p>with ε j,t ∼ N (0, 5). The task consists of 150 trials in which a random context is drawn and participants choose a planet to mine on * .</p><p>The three experiments differ in the functions f j and whether the environmental factors defining the context were binary or continuous. This is specified in more detail when describing the experiments. Source code for the experimental set-up is available online. † 7.4 Models of learning and decision making in CMAB-tasks 7.4.1 Contextual and context-blind learning I will specify two different classes of learning within CMAB-tasks, contextual and contextblind learning. Whereas contextual models learn and make use of how the provided context * The initial trial had the same context x 1 for all participants. Afterwards, the values of the context x t were sampled at random † https://github.com/ericschulz/contextualbandits maps onto expected rewards over time, context-blind models only learn the reward for each option separately without taking functional knowledge into account. This is similar to the distinction between associative and function learning models of the previous chapter.</p><p>There will be two kinds of context-blind models, a Bayesian mean tracker and Kalman filtering. The Bayesian mean-tracking model assumes that the average reward associated to each option is constant over time and simply computes a posterior distribution over the mean μ j of each option j. Here, this is implemented as a relatively simple version of such a model which assumes rewards are normally distributed with a known variance but unknown mean and the prior distribution for that mean is again a normal distribution. This corresponds exactly to the associative learning model from chapter 6 and implies that the posterior distribution for each mean is also a normal distribution:</p><formula xml:id="formula_89">p(μ j,t |D t−1 ) = N (μ j,t , σ 2 j,t ) (7.2)</formula><p>where the mean μ j,t represents the currently expected outcome for a particular arm j and the variance σ 2 j,t represents the uncertainty attached to that expectation. The posterior distribution can be computed through a mean-stable version of the Kalman filter, which I will describe next.</p><p>Unlike the Bayesian mean tracking model, which computes the posterior distribution of a time-invariant mean μ j after each new observation, the Kalman filter is a suitable model for tracking a time-varying mean μ j,t which I here assume varies according to a simple random walk</p><formula xml:id="formula_90">μ j,t+1 = μ j,t + ζ t ζ t ∼ N (0, σ 2 ζ ) (7.3)</formula><p>Kalman filtering models have been used to successfully describe participants' choices in a restless bandit task <ref type="bibr" target="#b210">(Speekenbrink &amp; Konstantinidis, 2015)</ref> and have also been proposed as a model unifying many findings within the literature of context-free associative learning <ref type="bibr" target="#b120">(Kruschke, 2008;</ref><ref type="bibr" target="#b62">Gershman, 2015)</ref>. In this model, the posterior distribution of the mean is again a normal distribution</p><formula xml:id="formula_91">p(μ j,t |D t−1 ) = N (μ j,t , σ 2 j,t ) (7.4) with mean μ j,t = μ j,t−1 + δ j,t G j,t (y t − μ j,t−1 ) (7.5)</formula><p>where y t is the received reward on trial t and δ j,t = 1 if arm j was chosen on trial t, and 0 otherwise. The "Kalman gain" term is computed as</p><formula xml:id="formula_92">G j,t = σ 2 j,t−1 + σ 2 ζ σ 2 j,t−1 + σ 2 ζ + σ 2 ε (7.6)</formula><p>where σ 2 k,t is the variance of the posterior distribution and the mean μ j,t is computed as</p><formula xml:id="formula_93">v j,t = (1 − δ j,t G j,t )(σ 2 j,t−1 + σ 2 ζ ) (7.7)</formula><p>Prior means and variances were initialized to μ j,0 = 0 and σ 2 j,0 = 1000, while the innovation variance σ 2 ζ and error variance σ 2 ε were free parameters. The Bayesian mean-tracking model is obtained from the Kalman filter model by setting the innovation variance to σ 2 ζ = 0, implying the underlying mean is not assumed to change over time.</p><p>Contextual learning models will be implemented as Gaussian Process regression for which it will be assumed that participants learn a separate function f j (x) that maps contexts</p><p>x to rewards y for each option j. There will be two different kernels specifying how people learn within CMAB tasks. The first is the radial basis function kernel</p><formula xml:id="formula_94">k(x, x ′ ) = σ 2 f exp ( − |x − x ′ | 2 2λ 2 ) (7.8)</formula><p>for which λ indicates the level of generalization participants might perform and is again estimated as a free parameter. The second kernel is a linear kernel</p><formula xml:id="formula_95">k(x, x ′ ) = θ 1 (x − θ 2 )(x ′ − θ 2 ) (7.9)</formula><p>which is the same as performing Bayesian linear regression and thus a simple rule-based function learning model to compare the more universal radial basis function kernel against.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.2">Sampling strategies</head><p>As in Chapter 6, the models of learning return a predictive distribution for each option which then has to be transformed to actual choices. Thus, I will again compare different sampling strategies which I recapitulate quickly.</p><p>The upper confidence bound (UCB) sampling strategy defines a trade-off between an option's expected value and the associated uncertainty and chooses the option for which the upper confidence bound of the mean is highest. It has a free parameter β, which determines the width of confidence interval. The UCB sampling strategy can be described as a selection strategy with an exploration bonus, where the bonus dynamically depends on the confidence interval of the estimated mean reward at each time point. I have found it to be the best sampling strategy within the spatially correlated multi-armed bandit paradigm within the previous chapter.</p><p>Another decision strategy is the probability of improvement (PoI) rule, which calculates the probability for each option to lead to an outcome higher than the option that is currently believed to have the highest expected value <ref type="bibr" target="#b122">(Kushner, 1964)</ref>. Intuitively, this algorithm estimates the probability of one option to generate a higher utility than another option, which is taken to be the best option observed so far.</p><p>The PoI rule focusses solely on the probability that an option provides a higher outcome than another; whether the difference in outcomes is large or small does not matter. The expected improvement (EXI) rule is similar to the PoI rule, but does take the magnitude of the difference in outcomes into account and compares options to the current favorite in terms of the expected increase of outcomes <ref type="bibr" target="#b150">(Mockus et al., 1978)</ref>.</p><p>The fourth decision strategy is the probability of maximum utility (PMU) rule <ref type="bibr" target="#b210">(Speekenbrink &amp; Konstantinidis, 2015)</ref>. This strategy chooses each option according to the probability that it results in the highest reward out of all options in a particular context. It is again implemented by Monte Carlo-sampling from the posterior predictive distribution.</p><p>As participants' decisions are expected to be more noisy reflections of the provided decision strategies, I use a softmax transformation to map the value of each option according to the decision rule into probabilities of choice:</p><formula xml:id="formula_96">p(a t = j|s t , D t−1 ) = exp{τ −1 • q(a = j|s t , D t−1 )} ∑ n i=1 exp{τ −1 • q(a = i|s t , D t−1 )} (7.10)</formula><p>The temperature parameter τ &gt; 0 governs how consistently participants choose according to the values generated by the different model-sampling strategy combinations and will be estimated as a free parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.3">Model comparison</head><p>All models are compared in terms of their out-of-sample predictive performance, assessing the accuracy of their one-step-ahead predictions and comparing them to that of a random model which picks each option with the same probability. The procedure is as follows: for each participant, a given model is fitted by maximum likelihood to the first t − 1 trials with a differential evolution optimization algorithm (using 100 epochs, cf. <ref type="bibr" target="#b153">Mullen et al., 2009)</ref>.</p><p>Afterwards, the fitted model is used to predict the choice on trial t. As repeating this procedure for every trial is computationally too expensive, models' predictive accuracy for every participant will be assessed on trials t = {10 <ref type="bibr">, 30, 50, 70, 90, 110, 130, 150}</ref>. The one-stepahead predictive accuracy measure compares each model M k to a random model M rand :</p><formula xml:id="formula_97">R 2 p = 1 − log L(M k )/ log L(M rand ) (7.11)</formula><p>where L(M) denotes the likelihood of model M (i.e., the probability of a participants' choices as predicted by fitted model M). This measure returns values between 0 (accuracy equal to the random model) and 1 (accuracy infinitely larger than the random model) and is exactly the same measure of predictive validity as used in Chapter 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Experiment 12: Binary features</head><p>The goal of the first contextual multi-armed bandit experiment was to test whether participants can learn to make good decisions in a CMAB task at all. For this purpose, I set up a relatively simple contextual bandit scenario in which the context only consists of binary features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.1">Participants</head><p>Forty-seven participants (26 male) with an average age of 31.9 years (SD = 8.2) were recruited via Amazon Mechanical Turk and received $0.3 plus a performance-dependent bonus. The experiment took 12 minutes to complete on average and the average reward was $0.73±0.07.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.2">Task</head><p>There were four different arms that could be played (planets that could be mined). In addition, three discrete variables, x i,t , i = 1, 2, 3, were introduced as the general context. The three variables defining the contexts could either be on (x i,t = 1) or off (x i,t = −1). The outcomes of the four arms were dependent on the context as follows:</p><formula xml:id="formula_98">f 1 (x t ) = 50 + 15 × x 1,t − 15 × x 2,t (7.12) f 2 (x t ) = 50 + 15 × x 2,t − 15 × x 3,t (7.13) f 3 (x t ) = 50 + 15 × x 3,t − 15 × x 1,t (7.14) f 4 (x t ) = 50 (7.15)</formula><p>On each trial, the probability that a contextual feature was on or off was set to p(x i,t = 1) = p(x i,t = −1) = 0.5, making each of the 8 possible contexts equally likely to occur on a given trial. The functions f j were designed such that the expected reward of each arm over all possible contexts equals E[y j,t ] = 50. This means that the only way to gain higher rewards than the average of 50 is by learning how the contextual features influence the rewards. More formally, this implies that no arm achieves first-order stochastic dominance. Moreover, including the context-independent fourth arm that returns the mean with added noise helps to distinguish even further between learning and not learning the context: this arm has the same expected value as all the other arms but a lower variance and therefore achieves second-order stochastic dominance over the other arms. As such, a context-blind and risk-averse learner would prefer this arm over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.3">Procedure</head><p>After giving their informed consent, participants received instructions to the experiment.</p><p>Participants were told that they had to mine for "Emeralds" on different planets. Moreover, it was explained that at each time each of the 3 different environmental factors could either be on (+) or off (-) and had different effects on different planets. Participants were told that they had to maximize the overall production of Emeralds over time by learning how the different elements influence the planets and then picking the planet they thought would produce the highest outcome, given the status (on or off) of the elements. It was explicitly noted that different planets can react differently to different elements. After reading the instructions, participants performed the CMAB task. There were a total number of 150 trials and participants were paid $0.3 + total score/(150 × 100).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral results</head><p>Participants gained 66.78 points (SD=13.02) per round on average throughout the task.</p><p>Participants' average scores were significantly above the chance level of 50 (t(46) = 8.83, p &lt; 0.01, d = 1.29). 34 out of 47 participants performed better than chance according to a simple t-test with α = 0.05 and μ 0 = 50. Thus, participants seemingly learned to take the context into account, obtaining higher rewards than expected if they were ignoring the context.  As a final assessment of whether participants took the context into account, I tested whether the outcome and chosen arm on the previous trial were related to the choice of arm on the current trial. If participants relied on the context, one would not expect previous outcomes and choices to be related to current choices. If participants ignored the context and for instance relied on (average) rewards or a win-stay-lose-shift strategy, a positive relation between current choices and previous choices and outcomes would be expected. A hierarchical multinomial regression (where trials were nested within participants) with cho-sen arms as dependent variable and outcomes and chosen arm on trial t − 1 as predictors showed no significant effects of the predictors. Again, this indicates participants learned the underlying function instead of using more simplistic (and in this case not very useful)</p><p>heuristic memorization techniques such as testing similar arms in sequences or changing to a particular arm after a particular score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling results</head><p>To determine which combination of learning model and sampling strategy best captures participants' choices, the one-step-ahead predictive comparison was used. For each participant and model, the pseudo-R 2 at the eight test trials was computed. Higher R 2 -values indicate better model performance. The results are shown in <ref type="figure">Figure 7</ref>.3.</p><p>Overall, the best performing model was the GP learning model with a radial basis function kernel with the PoI sampling strategy. Aggregating over sampling strategies, the contextual models produced significantly better one-step-ahead predictions than the contextblind models (t(46) = 6.82, p &lt; 0.001, d = 0.99). Additionally, the GP-model with an RBF kernel performed better than the linear model (t(46) = 7.88, p &lt; 0.001, d = 1.15).</p><p>Distinguishing the different sampling strategies turned out to be harder than comparing the different learning models. Aggregating over models, the probability of maximum utility strategy performed marginally better than all other sampling strategies (t(46) = 3.10, The median noise variance (σ 2 ε = 3.08) was reasonably close to the underlying observation noise variance of σε 2 = 5, albeit smaller in general (t(46) = −4.71, p &lt; 0.01, d = 0.69); thus, participants seemed to underestimate the overall noise in the observed outcomes. The estimates of the length-scale parameter clustered around the mean value of λ = 6.12. An RBF kernel can emulate a linear kernel by setting a very high length-scale. As the true underlying functions were linear in the experiment, we could thus expect high values forλ. In that light, a value of six for the estimated length-scale seems surprisingly small, as it indicates that the dependencies between input points are expected to decay rather quickly, i.e. that participants generalized more locally than what was necessary. The overall temperature parameter was relatively low (mean estimate:τ −1 = 0.085), indicating that participants quite consistently chose the options with the highest predicted rewards.</p><p>According to the best fitting model in the cognitive modeling exercise, people learn the relation between context and outcomes by relying on a more general function approximator than linear regression. By using a Probability of Improvement decision strategy, participants compare the option which is thought to have the highest average rewards in the current context, to relatively lesser known options in that context, determining how probable these are to provide a higher reward. This strategy is in agreement with prior findings in simpler multi-attribute choice tasks (for example, <ref type="bibr" target="#b30">Carroll &amp; De Soete, 1991)</ref>. 7.6 Experiment 13: Continuous-linear features Experiment 12 contained only 8 unique contexts. In this case, a memorization strategy could have been feasible, such that participants may have simply memorized the expected rewards for each option in each context, rather than having inferred a more general model of the underlying function (although further behavioral checks spoke against this explanation). The goal of the next experiment was therefore to assess whether the findings from Experiment 12 would generalize to a task with a larger number of unique contexts, in which memorizing input-output pairs is less feasible. For this purpose, Experiment 12 used the same task, but with continuous rather than binary features comprising the contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.1">Participants</head><p>Fifty-nine participants (30 male) with a mean age of 32.4 (SD=7.8) were recruited via Amazon Mechanical Turk and received $0.3 as a basic reward and a performance-dependent bonus of up to $0.5. Participants earned an average amount of $0.69 ± 0.08. Average time to complete the experiment was around 13 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.2">Task and Procedure</head><p>The task was identical to that of Experiment 12, only this time the context contained continuous features with an underlying linear function mapping inputs to outputs:</p><formula xml:id="formula_99">f 1 (x t ) = 50 + 3 × x 1,t − 3 × x 2,t (7.16) f 2 (x t ) = 50 + 3 × x 2,t − 3 × x 3,t (7.17) f 3 (x t ) = 50 + 3 × x 3,t − 3 × x 1,t (7.18) f 4 (x t ) = 50 (7.19)</formula><p>The values of the context variables x j,t were sampled randomly from a uniform distribution</p><p>x j,t ∼ U (−10, 10). The values were rounded to whole numbers and shown in their numerical form to participants. Again, the expected value (over all contexts) for each option was 50, so no option achieved first-order stochastic dominance, while the fourth option achieved second-order stochastic dominance, as the variance of its rewards was the lowest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral results</head><p>The average obtained reward across participants was 59.84 (SD = 9.41), significantly higher than chance (t(58) = 7.17, p &lt; 0.01, d = 0.78). As in Experiment 12, participants were able to take the context into account in order to increase their performance above chance level.</p><p>Performance increased over trials, r = 0.39, t(58) = 3.64, p &lt; 0.01, although this was not as pronounced as in Experiment 12 (see  A hierarchical multinomial regression assessing whether either a given chosen arm or a given output was predictive for choosing a particular arm next in, again revealed no significant effect (all p &gt; 0.05), indicating that participants did not seem to use any temporaldependent heuristics. This means that repetitions of sequences or more simplistic choice patterns after a given score are not the main driver of participants' behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling results</head><p>Cross validation results are shown in Regarding the sampling strategy, the UCB strategy performed better than the other strategies, significantly so for the linear learning model,t(58) = 3.38,p &lt; 0. Parameter estimates indicates that participants mostly consistently chose the options with the highest predicted utility. The estimated error variance wasσ 2 ε = 5.07 on average, which was very close to the actual variance of σ 2 ε = 5 (t(58) = 0.16, p &gt; 0.05, d = 0.02). The estimated lengthscale parameter was clustered tightly around a value ofλ = 10.31. This indicates a tendency towards further extrapolation than in Experiment 12, but is still quite far removed from the level of extrapolation a linear function would provide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7">Experiment 14: Continuous-non-linear features</head><p>The previous contextual multi-armed bandit experiments showed that most participants were able to learn how a multi-featured context differentially affects the rewards associated to decision alternatives. The goal of the third experiment was to investigate whether this would still be the case in an even more complicated environment with continuous valued features which are related to the options' rewards through non-linear functions. In order to cover a wide range of non-linearities, the functions relating contexts to rewards were themselves sampled from a Gaussian Process prior. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7.2">Task and Procedure</head><p>The task was identical to that of Experiment 13, apart from the functions mapping inputs to outputs, which were drawn from a Gaussian process prior: <ref type="bibr">. . . , 3 (7.24)</ref> where the mean function μ was set to 0 the kernel generating Σ was a radial basis kernel with a length-scale of λ = 2.</p><formula xml:id="formula_100">f 1 (x t ) = 50 + f 1 (x 1,t , x 2,t ) (7.20) f 2 (x t ) = 50 + f 2 (x 2,t , x 3,t ) (7.21) f 3 (x t ) = 50 + f 3 (x 3,t , x 1,t ) (7.22) f 4 (x t ) = 50 (7.23) f j ∼ GP(m, K), j = 1,</formula><p>As in Experiment 13, the features were described numerically and could take values between -10 and 10. These values were sampled from a uniform distribution x i,t ∼ U(−10, 10).</p><p>As before, the average expectation for all planets was 50 and the variance for the fourth arm was the lowest.</p><p>The procedure was identical to the one of Experiment 13.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral results</head><p>On average, participants obtained rewards of 55.35 (SD = 6.33), which is again significantly  Experiment 13 (see <ref type="figure">Figure 7</ref>.8b), which might be due to the increase in difficulty of the task.</p><p>The proportion of participants choosing the best option in a context did not increase much over trials, r = 0.12, p &lt; 0.05 (see <ref type="figure">Figure 7</ref>.8c). The proportion of choosing the noncontextual arm did not significantly decrease over time, r = 0.04, p &gt; 0.05. Overall, these results seem to indicate that participants struggled more than in any of the two prior experiments to perform well within the continuous non-linear task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling results</head><p>Modeling results are shown in <ref type="figure">Figure 7</ref>.9. Overall, the best performing model is the GP-RBF learning model paired with a upper confidence bound sampling strategy.</p><p>The contextual models predicted participants' choices only slightly better than the context-  As this experiment required participants to learn three different non-linear functions, it might have been too difficult to learn the functions, so that some of them reversed back to learning in a context-free manner. Moreover, it seems less feasible in this scenario to distinguish between the different sampling strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.8">Inter-experimental model comparison</head><p>To assess how participants adapted to the different task environments, this section assesses how model performance and parameter estimates vary between different experiments. For this analysis, the focus will be on the model with a GP learning component and a UCB decision strategy because this strategy described participants reasonably well in all of the experiments and comes with the additional benefit that the parameters are very interpretable.</p><p>For example, higher β-estimates are an indicator of more exploration behavior, higher λestimates indicate further generalization (i.e., the gradient of functional generalization), and higher noise parameters model an increasing tendency to perceive the underlying function as noisy. 7.11 shows the mean estimates of this model across all three experiments.</p><p>The overall predictive performance of the model was significantly higher within the first experiment as compared to the other two experiments (t(152) = 4.52, p &lt; 0.01, d = 0.79).</p><p>There was no meaningful difference between the continuous-linear and the continuous- with r = −0.18, p &lt; 0.05. This means that participants seem to explore less as the task becomes more difficult. The assumed noise term σ was estimated to be lower for the discrete experiment than for the continuous-linear experiments (t(140) = 3.3, p &lt; 0.01, d = 0.87) which in turn was smaller than the estimated variance of the continuous-nonlinear experiment (t(163) = 2.22, p &lt; 0.05, d = 0.36). Therefore, more difficult tasks can lead to a higher level of subjective noise within the learned functions. The length-scale parameter λ did not differ significantly between the three experiments (all p &gt; 0.5). This indicates that participants seem to approach diverse function learning tasks with a similar assumption about the underlying smoothness. While the assumed smoothness was less than the objective smoothness of the environment in the first two experiments, it was slightly higher in the last experiment.</p><p>In summary, comparing parameter estimates of the GP-RBF learning and a upper confidence bound sampling strategy between experiments showed that (1) the model captures participants' behavior best for the more simple discrete experiment, (2) participants seem to explore less in more difficult experiments, (3) the length-scale parameter modeling the assumed smoothness of the environment seems to be relatively stable across experiments, indicating a general approach to learning about unknown functions, and (4) the continuousnon-linear experiment was hard for participants as the model captured their behavior less well and assumed more noise overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.9">Discussion</head><p>In this chapter, I have introduced the contextual multi-armed bandit (CMAB) task as a paradigm to investigate behavior in situations where participants have to learn functions and simultaneously make decisions according to the predictions of those functions. The CMAB is a natural extension of past research on function learning, experience-based decision making in multi-armed bandit tasks, as well as the spatially-correlated multi-armed bandit introduced in Chapter 6. In three experiments, I assessed people's performance in a CMAB task where a general context affected the rewards of options differently (i.e. each option had a different function relating contexts to rewards). Even though learning multiple functions simultaneously is likely to be more complex than learning a single function (as is common in previous studies on function learning and multiple cue probability learning), on average, participants were able to perform better than expected if they were unable to take generalize from the provided context. This was even the case in a rather complex situation where the functions were sampled from a general class of non-linear functions, although performance dropped considerably as compared to environments with linear functions.</p><p>The presented experiments focused on a general context which differentially affected the outcomes of options. This is different than the CMAB task of <ref type="bibr" target="#b216">Stojic et al. (2015)</ref>, in which the features had different values for each option, while the function relating the contexts to rewards was the same for each option. Future studies could combine these paradigms and incorporate both option-specific (e.g., the type of restaurant) as well as general (e.g., the area in which the restaurants are located) contextual features, possibly allowing these to interact (e.g., a seafood restaurant might be preferable to a pizzeria in a fishing village, but not a mountain village).</p><p>Modeling function learning as Gaussian Process regression allowed to incorporate both rule-based and similarity-based learning in a single framework. In all three environments, participants' learning appeared to rely on a universal learning and generalization strategy based on a Gaussian Process regression with a radial basis function kernel. This is a universal function learning engine and assumes rather smooth functions to generalize from previous observations to similar contexts. This is close to a combination of exemplar learning, in which past observations are memorized and averaged when making new predictions, and similarity-based extrapolation.</p><p>The results regarding the sampling strategy were somewhat less consistent. When the features comprising the contexts were binary, people appeared to rely on a strategy in which they focus on the probability of improvement over past outcomes. In environments with continuous contextual features and linear and non-linear functions, they appeared to tradeoff their expectations and uncertainties more explicitly, and their decisions were best described by an upper confidence bound sampling strategy. Participants may have adapted their decision strategy to the task at hand. In a relatively simple scenario with binary contextual features, they appeared to focus on trying to improve upon past outcomes. When there are few unique and distinct contexts, it might be possible to memorize the average outcomes for those contexts, such that trying to maximally improve upon the current best option may be a feasible and efficient strategy. As the environment becomes more complicated, they seemed to balance their expectations and uncertainties more explicitly. Upper confidence bound sampling is not only the only sampling strategy with provable good regret <ref type="bibr" target="#b213">(Srinivas et al., 2012)</ref>, but it has also been proposed as a dynamic shaping bonus within the exploratory choice literature before <ref type="bibr" target="#b45">(Daw et al., 2006)</ref>.</p><p>The environment involving non-linear functions sampled from a Gaussian Process prior was more difficult than the others, and a proportion of participants appeared unable to learn the functions, performing more in line with a context-blind learning strategy (Kalman filter) that treats the task as a restless bandit in which the expected rewards fluctuate over time but where these fluctuations are not predictable from the changes in context. The combination of a Kalman filter learning model with a "probability of maximum utility" decision strategy that described these participants best has been found to describe participants behavior well in an actual restless bandit task <ref type="bibr" target="#b210">(Speekenbrink &amp; Konstantinidis, 2015)</ref> and here might have indicated the limits of participants' learning abilities.</p><p>While previous research on function learning has found a bias towards linear functions in such environments (e.g., <ref type="bibr" target="#b136">Lucas et al., 2015)</ref>, this was not the case in the presented experiments. This could be due to the increased complexity of learning multiple functions simultaneously, or due to participants' learning the functions with the purpose of making good decisions, rather than to accurately predict the outcomes as such. While good performance in standard function learning experiments requires accurate knowledge of a function in its whole domain, more course-grained knowledge may suffice in a CMAB task, where it might be enough to know which function has the maximum output for a given context.</p><p>Although the true functions relating contexts to rewards were smoother than those as-sumed by the estimated length-scale parameters within two of the three experiments, it is not clear whether this constitutes as a bias (in the psychological sense) or might be a useful prior to have in the real world. Approaching a task with a relatively less smooth kernel may be wise when there is uncertainty about the level of smoothness in the environment.</p><p>Furthermore, assuming unsmooth functions and learning in a situation of smoother than expected functions might lead to smaller errors than the other way around, that is, expecting smooth functions and having to learn in unsmooth environments. Further probing the effects of mismatched priors on generated rewards will be the focus of Chapter 8.</p><p>"And now, at last, I come to the humanly significant and exciting problem: namely, what are the conditions which favor narrow strip-maps and what are those which tend to favor broad comprehensive maps not only in rats but also in men?" Edward C. <ref type="bibr" target="#b225">Tolman, 1948</ref> 8 From behavior to theory This chapter investigates the previously reported result that participants underestimate smoothness using a Bayesian optimization simulation with mismatched priors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Introduction</head><p>One of the main findings of the last two chapters was that the estimated λ-parameter, which governs generalization within the radial basis function kernel, tends to be smaller than expected given the environments in which participants had to search for rewards. I have found this to be the case for both the spatially correlated and the contextual multi-armed bandit and across different versions of both tasks. As λ scales the correlation between points as their distance grows, smaller λ-estimates indicate that people generalize to a lesser extend than what they could for the underlying smoothness of the task. This raises the following questions: Why is the estimated length-scale parameter frequently smaller than it could be? Do people act irrationally when they do not tune their tendency to generalize to the underlying environment? Or might there be another explanation for the found mismatch between the smoothness participants seem to expect and the smoothness they observe?</p><p>This chapter investigates how much mismatched expectations about the generalizability of the underlying function affect performance in function exploration-exploitation tasks. More specifically, I use simulations to assess what kind of error is worse, expecting smooth and having to optimize unsmooth functions or expecting unsmooth and having to optimize smooth functions. Furthermore, my simulations will assess the extend to which a Bayesian optimization algorithm performs worse if assumptions are mismatched as compared to getting the expected smoothness right. The results of these simulations will have consequences as to whether or not the previously found human behavior can be seen as bias or as adaptive behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Mismatched Bayesian optimization</head><p>The goal of Bayesian optimization is to find the maximum of a target function f(x) on some bounded set X , which I will take to be a subset of R D <ref type="bibr" target="#b21">(Brochu et al., 2010;</ref><ref type="bibr" target="#b204">Snoek et al., 2012;</ref><ref type="bibr" target="#b193">Shahriari et al., 2016)</ref> by using a Gaussian Process (GP) as a probabilistic model for f <ref type="bibr">(x)</ref> and then exploiting this model via a sampling strategy to decide where in X to evaluate the function next <ref type="bibr" target="#b71">(Ghahramani, 2015)</ref>. This set-up is exactly the same as in the paradigms used in Chapters 6 and 7. Bayesian optimization algorithms are frequently also applied for problems of black box function optimization * . Even though different sampling strategies have been compared statistically before (cf. <ref type="bibr" target="#b21">Brochu et al., 2010;</ref><ref type="bibr" target="#b204">Snoek et al., 2012)</ref> and Bayesian optimization is frequently applied to optimize neural network hyperparameters <ref type="bibr" target="#b5">(Bergstra et al., 2011)</ref>, fitness landscapes <ref type="bibr" target="#b174">(Romero et al., 2013)</ref>, or even to replace more traditional numerical methods <ref type="bibr" target="#b91">(Hennig &amp; Hauberg, 2014)</ref>, surprisingly little is known about how choosing a particular kernel affects Bayesian optimization routines in practice.</p><p>In fact, many practitioners seem to either use the radial basis function kernel or a Matérn kernel in order to encode assumptions about smooth or medium smooth target functions (to the best of my knowledge first proposed by <ref type="bibr" target="#b204">Snoek et al., 2012)</ref>. Thus, assessing how different kernels affect the performance of the Bayesian optimization routine is not only an important psychological question, it also matters for practitioners of Bayesian optimization in order to decide when to use which kernel, potentially providing a case in which cognitive psychology can aid machine learning research.</p><p>Given two kernels k 1 and k 2 , I will define mismatched optimization as optimizing a func-tion f ∼ GP(0, k 1 (x s , x s ) sampled from a GP-prior parameterized by k 1 using a GP parameterized by k 2 , iff k 1 and k 2 are not the same kernel. This means that a target function is sampled from a Gaussian Process parameterized by one kernel and then optimized with a GP parameterize by another kernel. As the kernel can encode assumptions about the expected smoothness of the target function, mismatched optimization occurs if these assumptions are misaligned. I will refer to the kernel that has generated the target function as the teacher and to the kernel that is used to optimize the target function as the student.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.1">Sampling strategies</head><p>A simulation assessing the mismatch of assumptions in Bayesian optimization might not only vary the used kernels, but also the chosen sampling strategy. In the following simulations, I will assess 6 sampling strategies in terms of their performance within mismatched optimization scenarios. Some of these strategies have been used in the model comparisons before, whereas others were too costly to be evaluated in a psychological setting. Let me quickly recapitulate these sampling strategies one more time.</p><p>Upper confidence bound (UCB) sampling picks the next point that currently has the highest upper confidence bound <ref type="bibr" target="#b212">(Srinivas et al., 2010)</ref>:</p><formula xml:id="formula_101">UCB(x) = μ(x) + βσ(x) (8.1)</formula><p>UCB sampling is an optimistic strategy that samples based on an explicit exploration-exploitation trade-off, and has been proven to produce sub-linear regret <ref type="bibr" target="#b213">(Srinivas et al., 2012)</ref>, where regret is measured by the difference between the currently produced output and the best possible output on every trial t</p><formula xml:id="formula_102">r t = f(x max ) − f(x t ) (8.2)</formula><p>Moreover, upper confidence bound sampling has been the strategy that has predicted participants' behavior best in the experiments presented in Chapters 6 and 7, indicating that a trade-off between exploration and exploitation captures human behavior well.</p><p>The Probability of Improvement (POI) sampler picks the next point that currently shows the highest probability of being better than an incumbent point which is normally set to x + = arg max x i ∈x1:t f(x i )-i.e., the best outcome observed so far <ref type="bibr" target="#b122">(Kushner, 1964)</ref>:</p><formula xml:id="formula_103">POI(x) = P(f(x) ≥ f(x + + ξ)) = Φ ( μ(x) − f(x + − ξ) σ(x) ) (8.3)</formula><p>where Φ(•) is the normal cumulative distribution function and ξ ≥ 0 is a trade-off parameter controlling exploration. This sampling strategy predicted participants' choices best within the contextual multi-armed bandit experiment with discrete binary cues in Chapter</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.</head><p>The Expected Improvement (EXI) assesses each point by how much in expectation it promises to be better than an incumbent point x + <ref type="bibr" target="#b149">(Močkus, 1975)</ref>: </p><formula xml:id="formula_104">EXI(x) =        (μ(x) − f(x + ) − ξ)Φ(Z) + σ(x)φ(Z), if σ(x) ≥ 0 0, if σ(x) = 0<label>(</label></formula><formula xml:id="formula_105">E p(f) [R f (x)] = E p(f) [f(x max ) − f(x)].</formula><p>(8.6) MRP picks the point which with minimal regret under p n (f),x = arg min x ER(p n )(x).</p><formula xml:id="formula_106">MRP(x) = min ER(p n )(x) − E y|pn(f) , x[miñ x ER(p [x,y] n )(x)] (8.7)</formula><p>where p</p><formula xml:id="formula_107">[x,y] n = p(f|D ∪ {x q , y})</formula><p>is the updated probability distribution of f after having queried x q and observing y = f(x q ) + ε. MRP sampling can also be modified to account for the inherent uncertainty aboutx via marginalization leading to Minimum Regret Search (MRS) as described in detail by <ref type="bibr" target="#b146">Metzen (2016)</ref>. </p><formula xml:id="formula_108">MRS(x) = Ex ∼p * n [ER(p n )(x)] − E y|pn(f),x q [E p * Dn∪{(x q ,y)} [ER(p [x,y] n )(x)]]<label>(8.</label></formula><formula xml:id="formula_109">k ν (τ) = σ 2 f 2 1−ν Γ(ν) ( √ 2ν τ λ ) ν K ν ( √ 2ν τ λ ) (8.9)</formula><p>where Γ is the gamma function, K v is the modified Bessel function of the second kind, and λ and ν are non-negative covariance parameters. A GP with a Matérn covariance has sam-ple paths that are ν − 1 times differentiable. When ν = p + 0.5, the Matérn kernel can be written as a product of an exponential and a polynomial of order p. When ν = p + 0.5, the Matérn kernel can be written as a product of an exponential and a polynomial of order p.</p><formula xml:id="formula_110">k p+0.5 (τ) = σ 2 f exp ( − √ 2ντ λ ) Γ(p + 1) (2p + 1) × p ∑ i=0 (p + i)! i!(p − i)! (√ 8ντ λ ) p−i (8.10)</formula><p>I will compare two extreme cases in the following simulations, the Ornstein-Uhlenbeck process (a Matérn 1/2 kernel),</p><formula xml:id="formula_111">k(τ) = σ 2 f exp(−τ/λ) (8.11)</formula><p>that results when setting p = 0 and the radial basis function kernel that results when </p><formula xml:id="formula_112">p → ∞, k(τ) = σ 2 f exp(−τ 2 /<label>2λ</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.3">Past research on mismatched assumptions</head><p>How mismatch affects the performance of Gaussian Process regression methods has been investigated before. In fact, the derivations of learning curves discussed in Chapter 3 have also been applied to mismatched scenarios. <ref type="bibr" target="#b205">Sollich (2002)</ref> pioneered this work by deriving approximations to the learning curves for the case of mismatched models and found that, for large input space dimensionality, there are universal plateaux in the learning curves, with transitions in between that can exhibit arbitrarily many over-fitting maxima. In lower dimensions, plateaux also appear, and the learning curve remains dependent on the mismatch between student and teacher even in the asymptotic limit of a large number of training examples. In particular, these results showed that learning with excessively strong smoothness assumptions is unwise: a student with a radial basis function kernel will learn a rougher teacher function from a Matérn family only "logarithmically slowly".</p><p>Later, <ref type="bibr" target="#b206">Sollich (2005)</ref>   <ref type="bibr" target="#b213">Srinivas et al. (2012)</ref> showed that GP-UCB has sublinear regret for cases when the true underlying function lies in a low Reproducible Kernel Hilbert Space norm, even in the agnostic setting of not precisely defining the kernel function.</p><p>To the best of my knowledge, no further theoretical proof for Bayesian optimization in the mismatched setting exists.</p><p>Therefore, I will utilize extensive simulations of mismatched optimizations in order to assess the effect of a misspecification of the target function's smoothness empirically. Hopefully, this will then shed some light onto human generalization behavior found within the spatially correlated and the contextual multi-armed bandit described before while also being informative for applied settings of Bayesian optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Simulation 1: Simple mismatch</head><p>In the first simulation, the target function</p><formula xml:id="formula_113">y t = f(x t ) + ε (8.13)</formula><p>was created by sampling</p><formula xml:id="formula_114">f ∼ GP(0, k(x, x ′ )) (8.14)</formula><p>and ε ∼ N (0, 10 −3 ) from a teacher kernel and a student kernel was used to optimize it.</p><p>This procedure is repeated 100 times for every student-teacher-sampling strategy combination resulting in 4 different comparisons for every sampling strategy, i.e. all combinations of the Ornstein-Uhlenbeck (Matérn 1/2) and the radial basis function kernel as either the teacher or the student kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.1">Simple regret</head><p>In the first simulation, I fix the length-scale parameter to λ = 0.1 for both student and teacher kernels. <ref type="figure" target="#fig_104">Figure 8</ref>.1 shows the median regret calculated over 100 simulations for all of the sampling strategies over 100 trials.  Maximizing an unsmooth function is harder than maximizing a smooth function. The lowest regret achieved after 100 trials is within the region of 10 −5 produced by the minimum regret search sampling strategy for the scenario in which a radial basis function student maximizes a radial basis function teacher. The upper confidence bound sampling algo-rithm reaches a regret within the region of 10 −3 within the same scenario. A Matérn 1/2 (i.e.</p><formula xml:id="formula_115">q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q</formula><p>Ornstein-Uhlenbeck) student trying to optimize a radial basis function teacher can also perform reasonably well. The lowest median regret reached in such a scenario is in the region of 10 −4 , again by the minimum regret search acquisition function. The upper confidence bound sampling algorithm achieved a regret in the margin of 10 −2 in this scenario. Optimizing an unsmooth function turned out to be harder overall. In the matched case, with a Matérn 1/2 teacher and a Matern 1/2 student, the best regret achieved was in the region of 10 −1.5 , again achieved by the minimum regret sampling strategy. The upper confidence bound sampling strategy achieved a regret in the region of 10 −1 in this scenario. Using a radial basis function kernel student to optimize a Matern 1/2 kernel lead to the worst regret overall. In this scenario, the minimum regret search only achieved a median regret of 0.16 and the upper confidence bound sampling algorithm of 0.35 after 100 trials.</p><p>These results show that mismatched optimization leads to worse performance as compared to expecting the right level of smoothness. The worst possible regret results from expecting a smooth function and in reality optimizing a very rough function. Overall, the information-based sampling strategies performed best. Notably, mismatch mattered more than specifying the right sampling strategy. This is surprising as debates in the machine learning literature frequently concern the choice of an adequate sampling strategy and not specifying the right kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Simulation 2: Regret in higher dimensions</head><p>Simulation 1 focused on the most simplistic case of having to optimize a univariate function. However, the previous experiments also showed an effect of undergeneralization when participants had to optimize a function on a bivariate grid or using a context incor-porating three variables. Therefore, the next simulation focused on mismatch in higher dimensions. The same simulation as before was repeated but this time over 50 trials and for d = {2, 3, 4} dimensions of the input space over which the function had to be optimized. Interestingly, when just looking at the performance of the upper confidence bound sampling strategy, the counter-factual regret of a Matérn 1/2-student for d = {2, 3} dimensions decreases again and is indistinguishable from 0 after 50 trials, even though this is not completely the case for d = 4. However, the counter-factual regret of a radial basis function kernel trying to optimize Matérn 1/2 never goes back to 0 again. In some cases, expecting a rough function and having to optimize a smoother functions is better than the other way around. However, this is not necessarily often the case. For example, looking at the information-based sampling strategies in the cases when an RBF kernel is used to optimize functions sampled from a Matérn 1/2-kernel, the regret does not seem to go up in higher dimensions. Thus, there are also cases when expecting smoother functions does not hurt performance.</p><p>8.5 Simulation 3: Optimizing hyper-parameters <ref type="bibr" target="#b206">Sollich (2005)</ref> has shown that some of the effects caused by mismatched assumptions can be overcome by optimizing hyper-parameters in the pure learning case. Therefore, I next assessed if this also holds true for the optimization case, when the student kernel's hyperparameters θ are optimized via the log marginal likelihood</p><formula xml:id="formula_116">log p(y|X, θ) = − 1 2 y ⊤ K −1 y y − 1 2 log |K y | − n 2 log 2π. (8.15)</formula><p>As before, I set the length-scale of the teacher kernel to λ = 0.1. However, this time the student's length-scale is optimized on every step of the optimization routine. The simulation is again run over 100 trials and repeated 100 times for each sampling strategy. <ref type="figure" target="#fig_104">Figure 8</ref>.3</p><p>shows the resulting median regret per trial for all sampling strategies and every studentteacher combination.   The resulting regret shows that mismatch still affects the performance of the Bayesian optimization routine. In cases where the teacher and student both come from a Matérn 1/2 kernel, the lowest overall reached regret is in the region of 10 −2 , whereas the best regret when trying to optimize the Matérn 1/2 kernel by using a RBF kernel is 10 −1.5 . The effect of mismatch is even stronger in the case of an RBF-teacher, where the best overall regret in the matched case is 10 −10 but only 10 −4.5 for the mismatched case. This means that optimizing hyper-parameters leads to better performance in all cases, no matter if mismatch occured or not. However, having the right assumptions about the target function's smoothness matters even more in cases when the hyper-parameters are optimized. Given that participants' estimates of λ seemed to be relatively stable across experiments in Chapters 6-7, they likely did not adapt much to the underlying smoothness, but rather approached different settings with similar expectations. Two kernels, a student and a teacher, were used. Both kernels were set up to be radial basis function kernels, where the teacher kernel was parameterized with a length-scale λ 0 and the student kernel with a length-scale λ 1 . For situations in which λ 0 ̸ = λ 1 , the optimization routine can be seen as mismatched before. If λ 1 &gt; λ 0 , then the student kernel tends to overgeneralize from the observed points, whereas if λ 1 &lt; λ 0 the student kernel  10 −10 10 −8 10 −6 10 −4 10 −2 10 0</p><p>Effect of mismatched λ on regret The results of this simulation revealed several interesting factors influencing regret. First of all, regret decreases fastest when smooth teachers are optimized by equally smooth students as can be seen in the right upper corner of the heat-maps in <ref type="figure" target="#fig_104">Figure 8</ref>.4. Furthermore, there are cases in which a student can recover from mismatched assumptions over time, producing similar regret as if a completely matched student had been used. Importantly, this happens much more frequently for students that were parameterized to be less smooth than the teacher than the other way around, as can be seen on the right lower part of the heat-maps throughout all optimizations. The value of λ 1 producing the lowest average regret over all trials wasλ 1 = 0.2 over all sampling strategies andλ 1 = 0.2 for the upper confidence bound sampling strategy. Estimating the best possible alignment between λ 0 and λ 1 to produce the lowest regret revealed that under estimating λ 0 by an average of about 0.19 over all sampling strategies and by 0.21 for the upper confidence bound sampling strategy can potentially produce the best regret. Thus, these results provide strong evidence that lower values of λ do not necessarily constitute a bias but can sometimes lead to competitive overall regret. This is most likely due to the additional flexibility gained by assuming less smooth functions. If the true value of λ 0 is unknown, and optimizing λ 1 unfeasible, erring on the side of assuming a rougher environment thus seems wise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.7">Discussion</head><p>Bayesian optimization is not only a popular method to optimize black box functions, I</p><p>have also found it to predict participants' search behavior in both spatially correlated and contextual multi-armed bandit tasks. However, in both of these paradigms the estimated length-scale parameters showed that participants seem to underestimate the underlying smoothness of the environment, i.e. they did not generalize as much as they could have. In this chapter, I have tried to assess the effect of this underestimation using various simulations manipulating the difference of smoothness between a teaching kernel from which a target function is generated and a student kernel that is used to optimize the target func-tion.</p><p>First of all, from a machine learning perspective, the results suggest that the wrong prior assumptions about a target function's smoothness can lead to a large increase in regret, that this effect gets worse in higher dimensions, and remains even if hyper-parameters are optimized. Moreover, often-times choosing the right prior matters far more than choosing the sampling strategy. Thus, taking the term "black box optimization" too literally can lead to noticeable under-performance. My results thus tell a cautionary tale about how thinking hard about prior assumptions can sometimes be more important than choosing a particular sampling strategy.</p><p>Secondly, from a psychological perspective, the results suggest that underestimating the underlying smoothness is not always maladaptive. For example, in the simple regret simulation, assuming extremely rough functions still leads to comparably competitive performance when optimizing an extremely smooth function. Moreover, in higher dimensions, the counter-factual regret of the upper confidence bound sampling strategy was relatively robust to misspecification and (at least for lower dimensions) was able to fully recover from misspecified priors. In the scenario where the length-scale is optimized on every step, underestimating the underlying smoothness can lead to under-performance. However, it is likely not the case that participants adapt their length-scale according to the evidence seen on every trial, especially given very stable estimates across the different settings in the multiarmed bandit experiments. In the final simulation I generated different levels of mismatch by parameterizing radial basis function kernel teachers and students with different values of the length-scale λ. The results showed that undergeneralization can be beneficial for all Bayesian optimization routines, with the best possible λ 1 to be used for optimizing a teacher with λ 0 to be -on average-smaller by 0.19 (at trial 100).</p><p>The simulations presented here have tried to shed more light onto the finding of participants' consistently lower than necessary length-scale parameter estimates in all of the bandit experiments presented previously. The motivation was to assess if the apparent undergeneralization found in such tasks is practically damaging participants' performance and by how much. I have found that it is not always bad for a Bayesian optimization routine to be pessimistic, that is to expect rough functions and in fact being confronted with smoother functions. Sometimes being pessimistic about the world one needs to learn in can pay off in the end. Thus, under-generalization might not be a bug but rather a feature of human behavior.</p><p>Nonetheless, the question of why people seem to undergeneralize as much as they do needs to be addressed further. One mechanism proposed in the literature is that people might try to avoid overgeneralization from encountered exemplars . Such a mechanism could be especially important if a learning algorithm is paired with a naive and optimistic sampling approach such as upper confidence bound sampling or within scenarios requiring to avoid very bad outcomes. Other explanations such as memory restrictions or sparse updates could also be investigated. Further disentangling these mechanisms should be the goal of future experiments on human behavior in contextualized bandit settings.</p><p>"And then will follow the period of slow and steady progress, varied by a certain amount of wholesome interruption." <ref type="bibr">Edward Titchener, 1914</ref> 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This chapter concludes the thesis by summarizing the main findings, discussing possible shortcomings, and proposing future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Lessons learned</head><p>I began this thesis by posing the fundamental computational problem of generalization:</p><p>how do people know what to do in novel situations? I then proposed that Gaussian Process regression offers a unifying theory to explain human generalization across a wide range of cognitive domains. I will now briefly summarize the main findings of this thesis, examine potential shortcomings, and propose further experiments and steps towards theory unification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.1">Gaussian process learning curves match perceived predictability</head><p>The first experiment assessed if the characteristics theoretically influencing the generalizability of functions also influence participants' predictability judgments and found this to be the case: participants perceive the smoothness of functions as more important than the attached noise when making predictability judgments. Thus, predictions derived from learning curves match participants' behavior.</p><p>A shortcoming of this study is that it only asked participants' to judge about different functions' predictability without letting them generate actual predictions later on. Future studies could let participants make predictability judgments first and afterwards reward them based on how well they can actually predict the presented functions, taking into account their prior judgments.</p><p>Moreover, as the derived learning curves assumed a match between the student and the teacher kernel, future experiments could also assess the effect of mismatched learning on both predictability judgments and function learning performance. In particular, it would be interesting to assess what happens when participants learn in either rougher, smoother, or dynamically changing environments, before assessing them on the same level of smoothness. This could be used to develop and test different hierarchies of function learning models, such as warm starting (i.e., adjusting hyper-parameters over environments <ref type="bibr" target="#b169">Poloczek et al., 2016)</ref>, mismatched learning (i.e., assuming a fixed length-scale that is either too small or too large for the test set), or even "learning-to-learn"-algorithms <ref type="bibr" target="#b35">(Chen et al., 2017)</ref> within environments of the same class over time.</p><p>Currently, the design of the predictability experiments also has been fully passive, whereas I could also ask participants to sample points actively. As learning curves for uncertaintyguided sampling with Gaussian Process regression exist <ref type="bibr" target="#b192">(Seo et al., 2000)</ref>, it would be straight forward to again compare theoretical predictions with human behavior in such paradigms.</p><p>Putting these concerns aside, I believe that studies on predictability, and associated therewith theoretically derived learning curves, will continue to produce elegant insights into human generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.2">Function learning and generalization is compositional</head><p>In As is often the case, these results answer some but also generate many new questions.</p><p>Most important is probably the question whether a compositional theory of human generalization offers a universal theory of generalization. Shepard's original proposal was to assess the gradient of generalization and later on researchers such as Carroll and Brehmer proposed rule-based accounts of function learning. One could argue that a compositional theory of generalization runs the risk of falling into the same complexity trap as more traditional rule-based accounts: as many possible base kernels exist (many more than the three proposed in Chapter 5), the main question becomes how participants choose and combine kernels in order to make sense and generalize from encountered data. Thus, my proposal of compositional inductive biases might move the quest for a universal rule of human cognition from an area that is a bit like physics (i.e. finding a particular rule or framework that predicts behavior across many set-ups) to one that is more akin to chemistry (i.e. trying to find the elements of generalization and the rules they adhere to). To this I say that proposing compositionality as a core principle of generalization is not opposed to assessing the gradient of functional generalization. Indeed, in order to truly understand human behavior across a wide range of domains, we will need both a top-down theory that tells us what the "human kernel" might look like, as well as a bottom-up model describing how participants arrive at a particular form of generalization over repeated experience. My results about compositionally in function learning imply that human generalization is compositional, even if my model is not exactly perfect.</p><p>The empirical finding of compositional inductive biases paves the way for multiple follow-up studies. An obvious one is defining and assessing a compositional theory of function exploration-exploitation which I will describe in more detail below. Another one con-cerns the distribution of compositional priors and how idiosyncratic and task-specific these are.</p><p>Lastly, I have only assessed compositionality by combining different kernels in order to make the search tree "wider". However, compositionality could also be assessed by making the tree deeper. This could be done by parsing the results computed from one function into another function, resulting in a Deep Gaussian Process <ref type="bibr" target="#b42">(Damianou &amp; Lawrence, 2013)</ref>.</p><p>Deep GPs can overcome some problems such as mismatch under stationarity assumptions, but also leads to further inferential complexities at run time.</p><p>Taken together, I believe that the results presented in Chapter 5 make a strong case that a successful quest for a theory of human generalization must adhere to the principle of compositionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.3">Function learning guides search through complex tasks</head><p>Within both a spatially correlated and a multi-armed bandit task, I have found that participants' search behavior is generally best predicted by a combination of a Gaussian Process function learning model and the optimistic upper confidence bound sampling strategy.</p><p>This not only means that participants' search in complex spaces is guided by a function mapping contexts to expected rewards and their attached uncertainties, but also that they solve the exploration-exploitation dilemma by balancing between sampling highly valued options while also valuing exploration in order to reduce uncertainty. As a Gaussian Process function learning model paired with the upper confidence bound sampling strategy is also the only computational algorithm in such scenarios with known performance guarantees, participants' behavior is surprisingly adaptive.</p><p>The experiments presented in Chapters 6-7 open the way for further cross-experimental comparisons. As recent neuroscientific evidence has connected both spatial and conceptual representations to a common neural substrate <ref type="bibr" target="#b38">(Constantinescu et al., 2016)</ref>, a model of generalization could also further unite contextual and spatial search problems. For example, the bivariate spatially correlated multi-armed bandit can be seen as a contextual multiarmed bandit problem with 121 arms and 2 continuous features. This makes the task comparable to the one used by <ref type="bibr" target="#b216">Stojic et al. (2015)</ref>. The results of such a comparison could test if the same model that predicts behavior in spatially correlated grids also describes behavior in contextual bandits, if the extracted parameters, in particular the estimated extent of generalization, are similar, and whether or not the neural representation of such tasks is analogous. The Gaussian Process function learning model could also be adjusted by extending the model's search horizon as has been proposed in the Bayesian optimization community before <ref type="bibr" target="#b76">(González et al., 2016)</ref>.</p><p>The results presented in Chapters 6-7 show that marrying powerful yet interpretable function learning techniques with methods commonly applied in the reinforcement learning literature can further advance our understanding of adaptive behavior and generalization in complex environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.4">Under-generalization is sometimes beneficial</head><p>Chapter 8 has addressed the question if the empirically found phenomenon of participants' low λ-parameter estimates and the resulting under-generalization is always disadvantageous or if -indeed-there are situations in which being pessimistic about the underlying smoothness can be beneficial. The results of mismatched optimization simulations revealed that -even though expecting the right level of smoothness is usually best-there are situations in which it is easier to recover from mismatched priors if those have been defined pessimisti-cally rather than optimistically. A quote commonly attributed to Albert Einstein says :"I'd rather be an optimist and a fool than a pessimist and right". As it turns out -at least in function exploration-exploitation scenarios-even Einstein can be wrong sometimes.</p><p>There are several remedies that could be applied to further overcome mismatch in Bayesian optimization. One is to integrate out the estimated hyper-parameters of the kernel by applying slice sampling <ref type="bibr" target="#b204">(Snoek et al., 2012)</ref>. Whether or not integrating out hyper-parameters can indeed overcome mismatch is an open empirical question.</p><p>Another way to overcome mismatch could be to utilize a compositional approach in which differently smooth kernels are combined additively and the weights are optimized using the log-evidence. When I tried this in a simulation for functions sampled from an Ornstein-Uhlenbeck kernel, a simple mixture of a radial basis function and an Ornstein-Uhlenbeck kernel was not able to produce lower regret than just using the Ornstein-Uhlenbeck kernel alone (see Appendix A8). This is most likely due to the fact that in optimization scenarios, algorithms only sample from very restricted points of the input space, i.e. points that promise to produce high outputs. Therefore, such sampling strategies do not provide enough information to optimize mixture weights.</p><p>By further assessing the effects of mismatched priors, both within computational simulations and psychological experiments, we may create new insights bridging psychology and machine learning research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Open questions</head><p>There also remain open theoretical questions, the most important of which I want to address here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.1">Is this a process level model?</head><p>As Gaussian Process regression is a Bayesian algorithm that scales cubically with the number of training points, the question about whether or not my proposal equips us with a process level model seems adequate. Let me respond to this concern in two ways.</p><p>First, I do not see Gaussian Process regression as a process model per se, but rather as a computational level theory * . However, the borders between different levels of analysis become blurred relatively quickly. Consider Shepard's paradigmatic example of a universal law for which he defers to Newton's law of gravity. Even though Newton's law predicts the behavior of atoms, planets, and even galaxies, it is nonetheless not a process level model per se. It does not explicitly state how (i.e., by which underlying mechanism) different objects attract or repel each other. In fact, in his lectures on "The Character of Physical Law", Richard Feynman elaborates on three different ways by which Newton's law could be interpreted. Gravity could either refer to forces generated at a distance, to a potential at an object's center, or be defined by the shortest path between two objects. All of these interpretations are mathematically equivalent to Newton's law, but "psychologically feel very different" <ref type="bibr" target="#b55">(Feynman &amp; Wilczek, 1964)</ref>. Regardless, Newton's law describes and predicts a wide range of physical phenomena. While I do not claim that the theory of Gaussian Process-based generalization forward is comparable to Newton's universal law, I think the mechanism of action is similar. By providing a computational framework to assess different forms of generalization, I hope to find empirical commonalities, be it compositionality or under-generalization, that build up a theory of generalization which predicts behavior across a wide range of paradigms.</p><p>There also exist several methods to be applied to transform Gaussian Process regression into a more plausible form of what is commonly referred to as a psychological process model. One such way is to speed up inference by approximation, for example via sparse sampling <ref type="bibr" target="#b93">(Herbrich et al., 2003)</ref> † . This is similar to sampling-based process models that are currently gaining popularity as computationally rational solutions of resource-limited agents to complex problems <ref type="bibr" target="#b65">(Gershman et al., 2015a;</ref><ref type="bibr" target="#b43">Dasgupta et al., 2017a;</ref><ref type="bibr" target="#b17">Bramley et al., 2017)</ref>. Another approach could be to computationally embrace the linearity bias that is frequently observed in traditional function learning settings. As inference for linear regression is computationally cheap (it scales linearly with the number of data points), the linearity bias could be re-defined as a computationally less taxing "linearity heuristic". Participants' behavior might correspond well to models that try to jump to the limiting parametric form in order to save computations <ref type="bibr" target="#b82">(Gramacy &amp; Lee, 2008)</ref>. Thus, there are multiple ways by which Gaussian Process regression could be made more "human-like".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.2">Why not one model to rule them all?</head><p>Can the compositional model of generalization assessed in Chapter 5 be applied to the function exploration-exploitation scenarios assessed in Chapters 6-7? ‡</p><p>One easy way to assess if compositions play a role when optimizing functions is to let participants explore and exploit the univariate functions created as the "matched set" in Chapter 5. If participants perform better when optimizing the compositional as compared to the non-compositional set, then this will provide first evidence that compositions also matter in exploration-exploitation situations. The task will then be to build a computational model of compositional optimization. One possible problem for this could be that the restricted set of observations that the sampling strategies produce might not be informative enough to discover sufficient structure. Thus, a compositional approach to optimization will likely need an explicit exploration bonus towards uncovering compositions or strong compositional priors. This could be accomplished by adding a strategic exploration mechanism that chooses between maximization, simple exploration, or exploration to discover compositional structure.</p><p>In the long run, I believe that combining compositional search with adequate sampling strategies will create both psychologically plausible and computationally powerful reinforcement learning models that can generalize to new tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Generalizing generalization?</head><p>There are also a few more general directions in which the present research can be taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3.1">Further theory unification</head><p>A Gaussian Process-based theory of generalization offers many opportunities for further theory unification. For example, the associative learning models as specified in Chapters 6-7 can be reformulated as a GP regression model <ref type="bibr" target="#b172">(Reece &amp; Roberts, 2010)</ref> and hence implemented as a function learning model. In addition, when the length-scale of the radial basis function kernel approaches 0 (λ → 0), the function learning model effectively assumes state-independence, as in traditional reinforcement learning models. Thus, there may be a continuum of reinforcement learning models, ranging from the traditional assumption of state independence to the opposite extreme of complete state interdependence.</p><p>Moreover, a Gaussian Process is also equivalent to a Bayesian Neural Network with infinite nodes <ref type="bibr" target="#b154">(Neal, 1996)</ref>, suggesting a further link to distributed function learning models <ref type="bibr" target="#b127">(LeCun et al., 2015)</ref>. Indeed, one explanation for the impressive performance of Deep Reinforcement Learning <ref type="bibr" target="#b148">(Mnih et al., 2015)</ref> is that neural networks are specifically a powerful type of function approximator <ref type="bibr" target="#b179">(Schölkopf, 2015)</ref>.</p><p>As Bayesian reinforcement can also be seen as approximate dual control <ref type="bibr" target="#b47">(Dayan &amp; Sejnowski, 1996)</ref>, approximating and propagating an underlying value function can also be modeled by Gaussian Process regression <ref type="bibr" target="#b114">(Klenske &amp; Hennig, 2015;</ref><ref type="bibr" target="#b181">Schulz et al., 2017a)</ref>.</p><p>Given that the successor representation of reinforcement learning <ref type="bibr" target="#b46">(Dayan, 1993)</ref> has recently been shown to play a role in learning, memory and control <ref type="bibr" target="#b67">(Gershman et al., 2012;</ref><ref type="bibr" target="#b151">Momennejad et al., 2017)</ref> and that it is possible to define a kernel using the inverse graph Laplacian (the successor representation under a random walk <ref type="bibr" target="#b116">Kondor &amp; Lafferty, 2002)</ref>, assessing diffusion kernels with an exponential decay over graphs in reinforcement learning situations seems timely.</p><p>Sampling models of choice and decision making <ref type="bibr" target="#b203">(Smith, 2000)</ref> could also be re-cast as a special case of Gaussian Process regression. For example, it is possible to think about Gaussian Processes applied to decision making as accumulating evidence at different time scales, i.e. not only over trials but within a trial. The generative model underlying the drift diffusion model is in fact a Gaussian Process, but defined in terms of intra-trial evidence dynamics. Thus, it is possible to define a single covariance function that incorporates both inter-trial and intra-trial dynamics. One implication of this is that any neural circuitry programmed to do Gaussian evidence accumulation can also be programmed to do learning across trials when configured with the appropriate recurrent connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3.2">Scaling up</head><p>Carroll already said that participants in Shepard's task do not only learn functions, but also "programs". I think making the compositional approach wider and deeper is only a first stepping stone towards thoroughly exploring the human ability to generalize. In order to really understand human generalization, I think what we need is a compositional approach that is closer to functional programming than to kernel compositions. This could be achieved by recasting human problem solving as a form of program induction <ref type="bibr" target="#b48">(Dechter et al., 2013;</ref><ref type="bibr" target="#b54">Ellis et al., 2016)</ref>, for example in paradigms that assess creative problem solving and hypothesis testing. In another line of research, I have shown how heuristic decision making strategies can emerge from compositional approximately Bayesian inference <ref type="bibr" target="#b187">(Schulz et al., 2016c)</ref>, which -I believe-could also be adapted to compositional functional programming more generally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4">Conclusion</head><p>Situations in which generalization is required are ubiquitous. No matter if we perform inferences about patterns in the environment or decide where to dine tonight, there can be little doubt that generalization is a powerful ability aiding us to generate expectations in novel situations, a core ingredient of human intelligence. The controversial question is how we achieve this and what a unifying theory of human generalization might look like.</p><p>In this thesis, I have proposed to use Gaussian Process regression as method to investigate human generalization. The results of my experiments showed that generalization is compositional, that it guides decision making through complex tasks, and that the human tendency to under-generalize can sometimes be beneficial rather than harmful. Thus, the gradient of generalization is not the result of inferences someone makes, but a core ingredi-ent of those inferences.</p><p>Of course, these have only been investigations into a few domains that were immediately accessible to the chosen function learning approach. The next steps are now to test how much these results themselves generalize both theoretically and empirically to other domains. I am confident that doing so systematically and rigorously will bring us closer to uncover universal rules of cognition-"possibly, behind the diverse behaviors of humans and animals, as behind the various motions of planets and stars, we may discern the operation of universal laws" <ref type="bibr" target="#b197">(Shepard, 1987)</ref>. I follow the approach put forwad by <ref type="bibr" target="#b75">Goerg (2013)</ref> and estimate Ω(f) by first estimating the spectrum S f , normalizing it so that it integrates to 1, and then plugging it back into Eq. A.1.</p><p>I use the periodogram as an unbiased estimator of S f (see Goerg, 2013, for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Wavelet transform similarity measure</head><p>A discrete wavelet Haar Transform performs a scale-wise decomposition of the time series in such a way that most of the energy of the time series can be represented by a few coefficients. The main idea is to replace the original series by its wavelet approximation coefficients a in an appropriate scale, and then to measure the dissimilarity between the wavelet approximations. A detailed description of wavelet methods for time series analysis can be found in <ref type="bibr" target="#b166">Percival &amp; Walden (2006)</ref>. I use the R-package TSclust <ref type="bibr" target="#b152">(Montero &amp; Vilar, 2014)</ref> to find the appropriate scale of the transform. I then measure the dissimilarity between two series x 1 and x 2 by the Euclidean distance at the selected scale:</p><formula xml:id="formula_117">d(x 1 , x 2 ) = ||a 1 − a 2 ||.</formula><p>(A.4)</p><p>A.3 Model details for spatially correlated mulit-armed bandit experiments <ref type="table">Table A</ref>.1 shows every model's parameter estimates and predictive accuracy for both Experiment 10 and 11 presented in Chapter 6. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Model recovery</head><p>Figure A.1: Model recovery results, where data was generated by the specified genera ng model using individual par cipant parameter es mates. The recovery process used the same cross-valida on method used in the model comparison. I report the predic ve accuracy of each candidate recovery model (bars including standard error) and the number of simulated par cipants best described (icon array). For both genera ng and recovery models, I used UCB sampling. <ref type="table">Table A</ref>.1 reports the median values of the cross-validated parameter es mates used to specify each genera ng model. I present model recovery results that assess whether or not the predictive model comparison procedure of experiments 10-11 (but also, conceptually, of Experiments 12-14) allows to correctly identify the true underlying model. To assess this, I generated data based on each individual participant's parameter estimates. More specifically, for each participant and round, I use the cross-validated parameter estimates to specify a given model, and then generate new data resembling participants' data. I generate data using the associative learning and the function learning model for Experiment 10 and the associative learning* model and the function learning* model for Experiment 11. In all cases, I use the UCB sampling strategy in conjunction with the specified learning model. I then utilize the same cross-validation method as before in order to determine if it is possible to successfully identify which model has generated the underlying data. <ref type="figure">Figure A</ref>.1 shows the cross-validated predictive performance (bars) for the simulated data, along with the number of simulated participants best described (icon array).</p><p>In the simulation for Experiment 10, the predictive model comparison procedure shows that the associative learning model is a better predictor for data generated from the same underlying model, whereas the function learning model is only marginally better at predicting data generated from the same underlying model. This suggests that the main model comparison results are robust to Type I errors, and provides evidence that the better predictive accuracy of the function learning model on participant data is unlikely due to overfitting.</p><p>When the associative learning model generates data using participant parameter estimates, the same associative learning model achieves an average predictive accuracy of R 2 = .1 and describes 70 out 81 simulated participants best. On the same generated data, the function learning model achieves an average predictive accuracy of R 2 = .09 and only describes 11 out of 81 simulated participants best.</p><p>When the function learning model has generated the underlying data, the same function learning model achieves a predictive accuracy of R 2 = .4 and describes 41 out of 81 simulated participants best, whereas the associative learning model achieves a predictive accuracy of R 2 = .39 and describes 40 participants best. This makes the finding of the function learning as the best predictive model even stronger as -technically-the associative learning model could mimic parts of the function learning behavior.</p><p>In the simulations for Experiment 11, I use the localized version of each type of learning model for both generation and recovery, since in both cases, localization improved predictive accuracy of human participants <ref type="table">(Table A</ref>.1). Here, I find very clear recoverability in all cases, with the recovering model best predicting the vast majority of simulated participants when it is also the generating model <ref type="figure">(Fig. A.1)</ref>.</p><p>When the associative learning* model generated the data, the associative learning* model achieves a predictive accuracy of R 2 = .31 and predicts 79 out of 80 simulated participants best, whereas the function learning* model predicts only a lone simulated participant better, with an average predictive accuracy of R 2 = .26.</p><p>If the function learning* model generated the underlying data, the same function learning* model achieves a predictive accuracy of R 2 = .34 and describes 77 out of 80 simulated participants best, whereas the associative learning* model only describes 3 out of 80 simulated participants better, with a average predictive accuracy of R 2 = .32.</p><p>In all of the these simulations, the model that has generated the underlying data is also the best performing model, as assessed by its predictive accuracy and the number of simulated participants predicted best. Thus, I can confidently say that the cross-validation procedure distinguishes between the two assessed model classes. Moreover, in the cases where the function learning or function learning* model has generated the underlying data, the predictive accuracy of the same model is not perfect (i.e., R 2 = 1), but rather closer to the predictive accuracy I have found on the actual participant data <ref type="table">(Table A</ref>.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Parameter Recovery</head><p>Another important question is whether or not the reported parameter estimates of the models are reliable and recoverable. I address this question by assessing the recoverability of the three parameters of the function learning model, the length-scale λ, the exploration factor β, and the temperature parameter τ of the softmax choice rule. I use the results from the model recovery simulation described above, and correlate the empirically estimated parameters used to generate data (i.e., the estimates based on participants' data), with the parameter estimates of the recovering model (i.e., the MLE from the cross-validation procedure on the simulated data). I assess whether the recovered parameter estimates are similar to the parameters that were used to generated the underlying data. I present parameter recovery results for the function learning model for Experiment 10 and the function learning* model for Experiment 11, both using the UCB sampling strategy. I report the results in  Model details for contextual mulit-armed bandit experiments <ref type="table">Table A</ref>.2 shows the full parameter estimates and predictive performance for all models applied in the CMAB with binary features assessed in Experiment 12.  <ref type="table">Table A</ref>.3 shows the full parameter estimates and predictive performance for all models applied in the CMAB with continuous-linear features assessed in Experiment 13.  <ref type="table">Table A</ref>.4 shows the full parameter estimates and predictive performance for all models applied in the CMAB with continuous non-linear features assessed in Experiment 14. A.7 Sublinear regret of GP-UCB</p><p>The regret bounds (up to polylog factors) for the upper confidence bound sampling strategy were derived by <ref type="bibr" target="#b213">(Srinivas et al., 2012)</ref>. Let T be the time horizon, d the dimension of the data, and ν the Matérn parameter, then the regret bound for the linear kernel is   target function. Whereas the mixture kernel reaches a regret in the region of 10 −1 when optimizing a Matérn 1/2 kernel, the best regret in the matched setting was 10 −1.5 . Whereas the mixture kernel reaches a regret in the region of 10 −2.5 , the best regret in the matched setting was in the region of 10 −4 . Thus, the mixture regret does not recover the performance of its matching component.</p><formula xml:id="formula_118">R T = d √ T,<label>(A.</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>5). The red triangle shows the prediction for the newly presented stimuli x ⋆ = 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3.4 Different gradients of functional generalization as induced by different Matérnkernels. The correlation is assessed as the mean correlation between two points in dependency of their mutual distance. For bigger λ-parameters, the correlation decays more slowly leading to broader generalization. . . . . . . . . . . 42xii 3.5 Example of samples from differently smooth Gaussian Process priors and their posteriors after having observed the same set of points. Grey lines indicate samples from the GP. Black dots mark empirical observations. The dark gray line marks the current mean of the GP.The red triangle shows the prediction for the new data point. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 3.6 Results of extrapolation experiment conducted by DeLosh et al. (1997), possibly showing periodic extrapolation. . . . . . . . . . . . . . . . . . . . . . . 44 3.7 Example of composing kernels by combining simpler kernels in order to explain a complex function. Data were mean-centered before fitting the Gaussian Process and predictions were transformed back afterwards. Grey lines show observed CO2 emissions. Red lines show posterior predictions of Gaussian Process regressions with different kernels: RBF is a radial basis function kernel, RBF+Lin is a kernel composed by adding a RBF and a linear kernel, RBF×Per + Lin is a kernel composed by multiplying a radial basis function and periodic kernel and adding a linear kernel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45 3.8 GP-UCB example. The yellow line marks the current mean of the GP. The dashed line marks the GP's upper confidence bound. The light green lines are samples from the GP. The red triangle marks the point that currently produces the highest UCB. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4.1 Screenshot of the predictability experiment. Dots were sampled uniformly from a function whose order, variance, and sample size was sampled prior and unknown to participants. Participants had to indicate how well they thought they could predict this function on a scale from 0 (not at all) to 100 (certainly). . . . . . 61 4.2 Participants' perceived predictability in dependency of different levels of smoothness, noise, and sample size. Error bars represent the standard error of the mean. 62 4.3 Perceived predictability as a function of theoretical generalization error. Derived generalization error has been distributed across 8 equally-sized bins. . . . . . 63 5.1 Examples of base and compositional kernels. The base kernels are radial basis function (RBF), linear (LIN), and periodic (PER); the composition operators are addition and multiplication. Adding a periodic and a linear kernel creates functions with trends and seasonality. Multiplying a periodic kernel with a radial basis function results in more localized periods than a standard periodic kernel would be able to capture. . . . . . . . . . . . . . . . . . . . . . . . . . 76 5.2 Screenshot of Experiment 2a. Pattern completions (shown in red) were generated by a spectral mixture (left), a radial basis (middle), and a compositional kernel (right). The actual position was determined at random. . . . . . . . . . . 80 xiii 5.3 Results of Experiment 2a. Proportion of pattern completion choices for three kernels. Error bars represent the standard error of the mean. . . . . . . . . . 81 5.4 Results of Experiment 2b. Proportions of pattern completion choices. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . 5.5 Results of Experiment 3a. Proportions of chosen completions over the last 5 trials. Error bars represent the standard error of the mean. Generating kernel (ground truth) marked in red. l: linear kernel, p: periodic kernel, r: radial basis function kernel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 5.6 (Top) Real-world data sets used in Experiment 3b. Descriptions and origin of the data were unknown to participants. (Bottom) Participants were shown the region in blue; most frequently selected completions are shown in red. Note that the periodic composition has been adapted by multiplying it with a radial basis kernel. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.7 Results of Experiment 3b. Proportions of chosen predictions over last 5 trials. l: linear kernel, p: periodic kernel, r: radial basis function kernel. . . . . . . . 91 5.8 Screenshots of manual pattern completions (Experiment 4). The unobserved region (for completion) is delimited by vertical lines. . . . . . . . . . . . . . 5.9 Results of Experiment 4. Average root mean squared distance for interpolation (left) and extrapolation (right) drawings. Error bars show standard error of the mean. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.10 Sampled compositional functions. . . . . . . . . . . . . . . . . . . . . . . 5.11 Sampled spectral mixture functions. . . . . . . . . . . . . . . . . . . . . . 97 5.12 Screenshots of the two predictability judgment tasks (Experiment 5). (Left) Absolute predictability judgments. (Right) Relative predictability judgments. . . 5.13 Mean predictability judgments. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.14 Relative predictability judgments. Positive values indicate that the compositional function was judged to be more predictable than the non-compositional function. Error bars represent the standard error of the mean. . . . . . . . . . . . 101 5.15 Average correlation between model predictions and participants' predictability judgments. Predictions were derived from models' average generalization error. As generalization error and predictability are inversely related, the inverse of the generalization error was used to produce the correlations. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>. . . . . . . . . . . . . . . 5.17 Results of Experiment 6. Mean difference between predictions and outcomes for compositional and spectral kernel. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.18 Model fit (Pearson correlation coefficient) for predicting participants' next predictions given the current input over all trials in Experiment 6. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . 107 5.19 Screenshot of Experiment 7. Dots stayed on the screen for 1000ms and then vanished before the slider could be used. . . . . . . . . . . . . . . . . . . . . . 5.20 Mean difference between presented and estimated number of red dots over number of shown dots. Error bars represent the standard error of the mean. As more red dots are presented, participants tend to under-estimate the actual number more. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.21 Results of Experiment 7. Comparative judgments. Lower values mean that participants underestimated the number of red dots. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 5.22 Schematic of change detection task (Experiment 8). Initial stimulus was presented for 1000ms, drawn either from the compositional or from the non-compositional (spectral mixture) set. After an inter-stimulus interval (500ms), a test probe was presented and participants had to make a same/different judgment. . . . . . 5.23 Results of Experiment 8. Proportion of correctly detected changes. Participants were more likely to detect changes in compositional functions. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . 5.24 Mean point biserial correlation between model predictions and participants' responses in the change detection task. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 5.25 Schematic of Experiment 9. A sequence of stimuli was sampled from the matched set of functions. Every stimulus was presented for 1000ms, followed by an interstimulus interval (500ms), and then a probe (speeded old/new judgment). . . 5.26 Proportion of correctly identified probes as a function of set size. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . 121 5.27 Mean point biserial correlation for the compositional and the spectral mixture models. Error bars represent the standard error of the mean. . . . . . . . . . 6.1 Overview of the Gaussian Process function learning model, combined with an upper confidence bound sampling strategy (specified using median participant parameter estimates from Experiment 11. A) Screenshot of Experiment 11. Participants were allowed to select any tile until the search horizon was exhausted. B) Estimated reward as predicted by a Gaussian Process function learning engine, based on the sampled points in Panel A. (Not shown, the estimated uncertainty). C) Upper confidence bound of predicted rewards. D: Choice probabilities after a softmax choice rule, P(x) = exp(UCB(x)/τ)/ ∑ N j=1 exp(UCB(x j )/τ), where τ is the temperature parameter (i.e., lower temperature values lead to more precise predictions). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.2 Screenshot of Experiment 10. Univariate spatially correlated multi-armed bandit. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.3 Design of Experiment 10. Environments could be either smooth or rough (between subject manipulation). Sample horizons could be either short (5 clicks) or long (10 clicks, within subject manipulation, counter-balanced). . . . . . . 141 6.4 Results of Experiment 10. . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.5 Model comparison results of Experiment 10. . . . . . . . . . . . . . . . . . 147 6.6 Parameter estimates of Experiment 10. . . . . . . . . . . . . . . . . . . . . 6.7 Screenshot of Experiment 11. Bivariate spatially correlated multi-armed bandit. 6.8 Design of Experiment 11. Environments could be either smooth or rough (between subject manipulation). Sample horizons could be either short (20 clicks) or long (40 clicks, within subject manipulation, counter-balanced). . . . . . . 151 6.9 Results of Experiment 11. . . . . . . . . . . . . . . . . . . . . . . . . . . . 6.10 Model comparison results of Experiment 11. . . . . . . . . . . . . . . . . . . 6.11 Parameter estimates of Experiment 11. . . . . . . . . . . . . . . . . . . . . . 7.1 Screenshot of the CMAB task depicting Experiment 12. . . . . . . . . . . . . 7.2 Results of the binary CMAB task of Experiment 12. Average overall score (a), proportion of choosing the fourth arm (b), and proportion of choosing the best arm (c) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7.3 Predictive accuracy of the models for the CMAB task with discrete cues in Experiment 12. Error bars represent the standard error of the mean. . . . . . . . 7.4 Median estimates of the error variance σ, the length-scale λ, and the temperature parameter τ for the Gaussian Process regression radial basis function kernel model. 176 7.5 Results of the binary CMAB task of Experiment 13. Average overall score (a), proportion of choosing the fourth arm (b), and proportion of choosing the best arm (c) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7.6 Predictive accuracy of the models for the CMAB task with continuous-linear cues in Experiment 13. Error bars represent the standard error of the mean. . . 7.7 Median estimates of the error variance σ, the length-scale λ, and the temperature parameter τ for the GP-RBF model. . . . . . . . . . . . . . . . . . . . . . 181 7.8 Results of the binary CMAB task of Experiment 14. Average overall score (a), proportion of choosing the fourth arm (b), and proportion of choosing the best arm (c) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7.9 Predictive accuracy of the models for the CMAB task with continuous-non-linear cues in Experiment 14. Error bars represent the standard error of the mean. . . 7.10 Median estimates of the error variance σ, the length-scale λ, and the temperature parameter τ for the GP-RBF model. . . . . . . . . . . . . . . . . . . . . . 7.11 Mean estimates of the predictive performance R 2 , the exploration parameter β, the error variance σ, and the length-scale λ across all experiments. Error bars represent the standard error of the mean. . . . . . . . . . . . . . . . . . . . . . 8.1 Median regret over time for different sampling strategies in matched and mismatched conditions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8.2 Median counter-factual regret over 50 trials for different input-dimensions. . 8.3 Median regret over time for different sampling strategies in matched and mismatched conditions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207 8.4 Median regret for different student-teacher combinations and sampling strategies at trial number N = {1, 5, 10, 15, 50}. . . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>kernels in the compositional grammar. . . . . . . . . . . . . . . . . . . 5.2 Kernel combinations in the compositional grammar and their interpretations. 77 5.3 Regression model of predictability judgments. Overall model fit: Conditional pseudo-R 2 = 0.17. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.4 Regression model of the traditional function learning paradigm. Overall model fit: R 2 = 0.14. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.5 Parameter estimates from numerosity judgments regression analysis. . . . . . 111 5.6 Result of change detection logistic regression. . . . . . . . . . . . . . . . . . 5.7 Results of logistic regression analysis of the memory experiment. . . . . . . . 5.8 Results of logistic regression analysis of the memory experiment. . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 . 1 :</head><label>21</label><figDesc>Example of Shepard's rule of generaliza on.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 . 3 :</head><label>23</label><figDesc>Results of extrapola on experiment conducted by DeLosh et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>"3</head><label></label><figDesc>It is a friendship made in heaven and executed on earth." Eric Kandel about Aplysia (Eric Schulz about GPs) From function learning to generalization This chapter introduces Gaussian Processes regression as a tool to investigate function learning and shows how assumptions about the kernel correspond to assumptions about human generalization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 . 1 :</head><label>31</label><figDesc>Example of performing Bayesian linear and cubic regression. Green lines indicate predic ons for different sampled posterior weights. Dots mark empirical observa ons. Yellow lines mark the current mean posterior predicons. The red triangle shows the predic on for the newly presented s muli x ⋆ = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>12) i.e. the average of all functions in the distribution evaluated at input x. The prior mean function is frequently set to m(x) = 0 in order to avoid expensive posterior computations and only perform inference via the covariance directly. The covariance function k(x, x ′ ) models the dependence between the function values at different input points x and x ′ :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Figure 3.2 shows differently broad gradients of functional generalization resulting from setting the length-scale parameter λ to different values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 3 . 2 :</head><label>32</label><figDesc>Different gradients of func onal generaliza on as induced by se ng the length-scale λ = {0.5, 1, 2}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 3 .</head><label>3</label><figDesc>3 shows samples from a GP prior parameterized by a radial basis function kernel and the posterior mean functions after the data in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 3 . 3 :</head><label>33</label><figDesc>Green lines indicate predic ons for different sampled posterior weights. Dots mark empirical observaons. Yellow lines mark the current mean of the GP (λ was set to 0.5). The red triangle shows the predic on for the newly presented s muli x ⋆ = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 3 . 4 :</head><label>34</label><figDesc>Different gradients of func onal generaliza on as induced by different Matérn kernels. The correlaon is assessed as the mean correla on between two points in dependency of their mutual distance. For bigger λ-parameters, the correla on decays more slowly leading to broader generaliza on.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 3 . 5 :</head><label>35</label><figDesc>Example of samples from differently smooth Gaussian Process priors and their posteriors a er having observed the same set of points. Grey lines indicate samples from the GP. Black dots mark empirical observa ons. The dark gray line marks the current mean of the GP. The red triangle shows the predic on for the new data point. capture all phenomena of human function learning and generalization. First of all, as I have described before, subjects tend to extrapolate in a linear fashion which does not correspond to correlations between points that thin out over longer distances. Secondly, another observation comes from the previously mentioned study by DeLosh et al. (1997). Therein, not all participants extrapolated an underlying quadratic function as shown in Figure 2.3. Some participants also extrapolated this function as shown in Figure 3.6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 3 . 6 :</head><label>36</label><figDesc>Results of extrapola on experiment conducted by DeLosh et al. (1997), possibly showing periodic extrapola on. 2013). For example, adding two kernels together models the data as a superposition of independent functions, while multiplying a kernel with the radial basis function kernel, locally smooths the effect of the first kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 3 .</head><label>3</label><figDesc>7 shows a data set of atmospheric concentration of carbon dioxide over a forty year</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>Figure 3.7 shows the posterior predictive mean of different kernel compositions. The first one shows a radial basis function kernel alone, the second a sum of a radial basis function kernel and a linear kernel, k(x, x ′ ) =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure</head><label></label><figDesc>Figure 3.7: Example of composing kernels by combining simpler kernels in order to explain a complex func on. Data were mean-centered before fi ng the Gaussian Process and predic ons were transformed back a erwards. Grey lines show observed CO2 emissions. Red lines show posterior predic ons of Gaussian Process regressions with different kernels: RBF is a radial basis func on kernel, RBF+Lin is a kernel composed by adding a RBF and a linear kernel, RBF×Per + Lin is a kernel composed by mul plying a radial basis func on and periodic kernel and adding a linear kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 3 . 8 :</head><label>38</label><figDesc>GP-UCB example. The yellow line marks the current mean of the GP. The dashed line marks the GP's upper confidence bound. The light green lines are samples from the GP. The red triangle marks the point that currently produces the highest UCB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head></head><label></label><figDesc>Given a dataset D = {x, y} and an error function L(•, •) which measures the difference between the predicted and true function values, the data-dependent generalization error is defined as the expected error on a test input x ⋆ sampled from a uniform distribution, marginalizing over the latent function:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure</head><label></label><figDesc>50 sequential trials in total where points were sampled equidistantly from different GPs with the Matérn covariance function. The parameters for the smoothness p = [1, 2, 3], the variance σ 2 = [0, 0.05, 0.1, 0.15, 0.2], and sample size n =[10, 20, 30, 40, 50]  were randomly selected on each trial. As Gaussian Process samples were</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 4</head><label>4</label><figDesc>Figure 4.1: Screenshot of the predictability experiment. Dots were sampled uniformly from a func on whose order, variance, and sample size was sampled prior and unknown to par cipants. Par cipants had to indicate how well they thought they could predict this func on on a scale from 0 (not at all) to 100 (certainly).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 4 .</head><label>4</label><figDesc>2 shows the relationship between different Gaussian Process parameters and participants' perceived predictability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 4 . 2 :</head><label>42</label><figDesc>Par cipants' perceived predictability in dependency of different levels of smoothness, noise, and sample size. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 4 . 3 :</head><label>43</label><figDesc>Perceived predictability as a func on of theore cal generaliza on error. Derived generaliza on error has been distributed across 8 equally-sized bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 5 .</head><label>5</label><figDesc>1 shows an example of how different kernels (radial basis function, linear, periodic) can be combined. The approach put forward here, following<ref type="bibr" target="#b51">Duvenaud et al. (2013)</ref>,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 5 . 1 :</head><label>51</label><figDesc>Examples of base and composi onal kernels. The base kernels are radial basis func on (RBF), linear (LIN), and periodic (PER)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head></head><label></label><figDesc>29 women) with an average age of 36.15 (SD = 9.11) were recruited via Amazon Mechanical Turk and received $1 for their participation. The experiment took 5 minutes on average to complete. Design 20 different functions were pre-selected § sampled from a Gaussian Process parametrized by various compositional kernels within an input space of x = [0, 0.1, 0.2, • • • , 10]. Afterwards, the functional outputs for x learn = [0, 0.1, 0.2, • • • , 7] were used as a training set to which all three approaches were fitted and then used to generate predictions for a test set x test = [7.1, 7.2, • • • , 10] for generalization. The hyper-parameters of the radial basis kernel as well as the number of components and the hyper-parameters of the spectral mixture kernel were fitted by optimizing the marginal likelihood of the training set. The best prediction of the compositional kernel was found by choosing the composition from the grammar (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 5 . 2 :</head><label>52</label><figDesc>Screenshot of Experiment 2a. Pa ern comple ons (shown in red) were generated by a spectral mixture (le ), a radial basis (middle), and a composi onal kernel (right). The actual posi on was determined at random.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>Figure 5 . 3 :</head><label>53</label><figDesc>Results of Experiment 2a. Propor on of pa ern comple on choices for three kernels. Error bars represent the standard error of the mean.5.5 Experiment 2b: Pattern completions of non-compositional functions While the results of Experiment 2a suggest a preference for compositionally structured functions, they do not indicate whether humans have an inductive bias for such functions, since the results are perfectly compatible with the possibility that participants adapted to the ground truth structure without a compositional inductive bias. In Experiment 2b, I subject the compositional theory to a stronger test, measuring pattern completion preferences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head></head><label></label><figDesc>32%, χ 2 (N = 1300, df = 2) = 172.8, p &lt; 0.01; Figure 5.4). Moreover, 41 of 65 participants significantly preferred the compositional over spectral pattern completions at the α = 0.05-level. This finding is consistent with the claim that human inductive biases for functions are sufficiently strong and compositional to induce preference for compositional completions even when the ground truth is non-compositional.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head>Figure 5 . 4 :</head><label>54</label><figDesc>Results of Experiment 2b. Propor ons of pa ern comple on choices. Error bars represent the standard error of the mean.5.6 Markov chain Monte Carlo with peopleThe next set of experiments seeks to elicit samples from a compositional posterior predictive distribution over functions in order to gain finer-grained insight into the subjective representation of functions. This is accomplished by using a technique called Markov chain Monte Carlo with People (MCMCP;<ref type="bibr" target="#b177">Sanborn et al., 2010)</ref>. This technique asks participants to accept or reject proposed hypotheses, effectively simulating a Markov chain whose stationary distribution is the posterior over hypotheses given the presented data. In the following experiments, I condition on a training set and ask participants to choose between completions (as in Experiments 2a and 2b); thus the stationary distribution is the posterior predictive distribution over pattern completions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 5</head><label>5</label><figDesc>.5. The first 25 trials were excluded to avoid trials on which participants might not have reliably moved towards their subjective posterior extrapolations, a process commonly called "burn-in".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 5 . 5 :</head><label>55</label><figDesc>p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr l p r l+p l+r p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr l p r l+p l+r p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr l p r l+p l+r p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr l p r l+p l+r p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr l p r l+p l+r p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr l p r l+p l+r p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr l p r l+p l+r p+r lxp lxr pxr p+r+l pxr+l pxl+r rxl+p pxlxr 0Results of Experiment 3a. Propor ons of chosen comple ons over the last 5 trials. Error bars represent the standard error of the mean. Genera ng kernel (ground truth) marked in red. l: linear kernel, p: periodic kernel, r: radial basis func on kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head></head><label></label><figDesc>51 participants (31 male) with an average age of 32.55 (SD = 12.14) were recruited via Amazon Mechanical Turk and received $1 for their participation. The experiment took 7 minutes on average to complete. Procedure I used four real-world time series (Figure 5.6): airline passenger data, volcano CO2 emission data ‖ , the number of gym memberships over 5 years, and the number of times people googled the band "Wham!" over the last 8 years. Some of these functions have been extensively analyzed in the time series modeling literature and all of them showed interesting patterns a priori. Participants were not told any information about the data sets (including input and output descriptions); they were simply shown the unlabeled input-output pairs in the experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head>Figure 5 . 7 :</head><label>57</label><figDesc>Results of Experiment 3b. Propor ons of chosen predic ons over last 5 trials. l: linear kernel, p: periodic kernel, r: radial basis func on kernel. describing the observed data and to complete this function within the observed and unobserved regions. A screenshot of the experiment is shown in Figure 5.8. Participants 36 participants (23 males) with a mean age of 30.5 (SD = 7.15) were recruited from Amazon Mechanical Turk and received $2 for their participation. The experiment took 12 minutes on average.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><head>Figure 5 . 8 :</head><label>58</label><figDesc>Screenshots of manual pa ern comple ons (Experiment 4). The unobserved region (for comple on) is delimited by ver cal lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Figure 5 . 9 :</head><label>59</label><figDesc>Results of Experiment 4. Average root mean squared distance for interpola on (le ) and extrapola on (right) drawings. Error bars show standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>Figure 5 . 10 :</head><label>510</label><figDesc>Sampled composi onal func ons.5.11 Experiment 5: Compositional predictabilityIf human inductive biases for functions are inherently compositional, then compositional functions should be perceived as more predictable. ‡ ‡ In Chapter 4, I operationalized predictability in terms of generalization error. As predictability is the expected prediction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head>Figure 5 . 11 :</head><label>511</label><figDesc>Sampled spectral mixture func ons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_46"><head>Figure 5 . 12 :</head><label>512</label><figDesc>Screenshots of the two predictability judgment tasks (Experiment 5). (Le ) Absolute predictability judgments. (Right) Rela ve predictability judgments. 0.001) compared to predictability judgments for non-compositional functions (r = 0.18, p &lt; 0.001; difference test: z = 2.36, p &lt; 0.05).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_47"><head>Figure 5 . 13 :</head><label>513</label><figDesc>Mean predictability judgments. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_48"><head></head><label></label><figDesc>pled new input point. This approximation is computed for every sample that a participant saw under different kernel choices: linear, radial basis function, spectral mixture, or a compositional kernel. To generate predictions from each kernel, the hyper-parameters (including the composition for the compositional kernel) that maximized the log marginal likelihood were used and the mean generalization error was assessed empirically. This approach tests if the ease of generalizations for different functions as assessed by different approaches towards generalizations tracks participants' predictability judgments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_49"><head>Figure 5 .</head><label>5</label><figDesc>15 shows the average correlation between each kernel's generalization error and participants' predictability judgments, averaged over all trials and participants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_50"><head>Figure 5 . 14 :</head><label>514</label><figDesc>The spectral mixture kernel (t-test against a correlation of 0: t(49) = −2.351, p &lt; 0.05, d = 0.33), the compositional kernel (t(49) = −19.73, p &lt; 0.001, d = 2.79) as well Rela ve predictability judgments. Posi ve values indicate that the composi onal func on was judged to be more predictable than the non-composi onal func on. Error bars represent the standard error of the mean. as the radial basis function kernel (t(49) = −4.3, p &lt; 0.01, d = 0.61) all correlated significantly with participants' judgments. The linear (t(49) = 0.846, p &gt; 0.1, d = 0.12) kernel did not correlate with participants' judgments better than chance. Crucially, the compositional kernel showed a significantly higher correlation than either the spectral mixture kernel (t(49) = −7.86, p &lt; 0.001, d = 1.57) or the radial basis function kernel (t(49) = −9.92, p &lt; 0.001, d = 1.49).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_51"><head>Figure 5 . 15 :</head><label>515</label><figDesc>Average correla on between model predic ons and par cipants' predictability judgments. Predic ons were derived from models' average generaliza on error. As generaliza on error and predictability are inversely related, the inverse of the generaliza on error was used to produce the correla ons. Error bars represent the standard error of the mean.5.12 Experiment 6: Traditional function learning paradigmIn the experiments presented so far, I have only used single function learning paradigms with a particular focus on pattern completions, either by letting participants choose completions in forced choice or MCMCP tasks or by asking them to draw manual pattern completions. Psychological experiments on function learning have traditionally focused on sequential function learning (as described in Chapter 3). For example,<ref type="bibr" target="#b29">Carroll (1963)</ref> asked participants to predict the width of one bar given another bar's width. After every prediction, participants received feedback about the actual width of the bar. Performing this task required participants to build up a representation of a function sequentially, rather than a more perceptual generalization that can be used in a single function learning task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_52"><head></head><label></label><figDesc>mean age=31, SD=11; 30 males) were recruited via Amazon Mechanical Turk and received $0.5 for their participation. The experiment took 12 minutes on average to complete.ProcedureParticipants were asked to predict an output indicated by the height of a red bar given the current input indicated by the height of a blue bar (Figure 5.16). On each trial, they saw the current input (a blue bar) and had to indicate their predictions by adjusting the height of an orange bar using a slider. After submitting their prediction, the actual output appeared marked as a red bar directly next to the orange bar. Additionally, participants saw the numerical value of the current input, their prediction and -after they submitted their predictions-the output, as well as the difference between their prediction and the actual output. It was explicitly stated to participants that the input is related to the output by an underlying function and that they had to learn that function in order to produce the smallest possible difference between their predictions and the outputs.Participants learned 4 different functions over 4 blocks. Out of the 4 different functions participants had to learn, 2 were sampled from the set of matched compositional functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_53"><head>Figure 5 . 16 :</head><label>516</label><figDesc>Screenshots of Experiment 6. The height of the blue bar indicates the input.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_54"><head>Figure 5 . 17 :</head><label>517</label><figDesc>Results of Experiment 6. Mean difference between predic ons and outcomes for composi onal and spectral kernel. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_55"><head>Figure 5 . 18 :</head><label>518</label><figDesc>Model fit (Pearson correla on coefficient) for predic ng par cipants' next predic ons given the current input over all trials in Experiment 6. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_56"><head>Figure 5 . 19 :Figure 5 . 20 :</head><label>519520</label><figDesc>Screenshot of Experiment 7. Dots stayed on the screen for 1000ms and then vanished before the slider could be used.comparison of numerosity estimates for compositional and non-compositional patterns.Overall, participants underestimated the number of dots more for compositional than for non-compositional patterns (−0.74 vs. −0.53, hierarchical t-test: t(38) = −2.2, p &lt; 0.05,d = 0.43).A regression analysis, with the difference between participants' estimates and the actual number of dots as the dependent variable, was performed to account for both the number of dots and the function type. The results (presented in Table 5.5) showed that with an increasing number of red dots, participants showed a stronger tendency to underestimate numerosity (β = −0.39). Additionally, there was a main effect of function type (β = Mean difference between presented and es mated number of red dots over number of shown dots. Error bars represent the standard error of the mean. As more red dots are presented, par cipants tend to underes mate the actual number more.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_57"><head>Figure 5 . 21 :</head><label>521</label><figDesc>Results of Experiment 7. Compara ve judgments. Lower values mean that par cipants underes mated the number of red dots. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_58"><head>Figure 5 . 22 :Figure 5 . 23 :</head><label>522523</label><figDesc>Change probes were constructed by randomly selecting n ∈ {2, 3, • • • , 5} dots and permuting them (under the constraint that no point ends up at the same position as before).5.14.3 Results and discussionFigure 5.23 shows the mean proportions of correct responses for compositional and noncompositional trials across different levels of change: "no change", "small change" (1-2 dots permuted) and "large change" (3-5 dots permuted). This analysis demonstrated that performance was superior for change of compositional structure.Participants responded correctly on 82% of no-change trials for the compositional functions and on 81% of the no-change trials for the non-compositional functions. Thus, there was no significant difference in correct rejection rate for the two types of functions (χ 2 (N = 1185, df = 1) = 0.21, p &gt; 0.05). However, 77% of the changed compositional functions were correctly identified as having changed, whereas that proportion was only 67% for the changed non-compositional functions. Therefore, change is more easily detected for compositional functions (χ 2 (N = 1188, df = 1) = 12.13, p &lt; 0.001). In total, 49 of 66 participants correctly identified change of compositional functions more frequently than change of non-compositional functions (χ 2 (N = 66, df = 1) = 9.67, p &lt; 0.01). Schema c of change detec on task (Experiment 8). Ini al s mulus was presented for 1000ms, drawn either from the composi onal or from the non-composi onal (spectral mixture) set. A er an inter-s mulus interval (500ms), a test probe was presented and par cipants had to make a same/different judgment.In order to quantitatively capture these results, I put forward a Bayesian theory of functional change detection. Let D 1 and D 2 denote the first and second stimuli (input-output Results of Experiment 8. Propor on of correctly detected changes. Par cipants were more likely to detect changes in composi onal func ons. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_59"><head>Figure 5 . 24 :</head><label>524</label><figDesc>Mean point biserial correla on between model predic ons and par cipants' responses in the change detec on task. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_60"><head>Figure 5 . 25 :</head><label>525</label><figDesc>Schema c of Experiment 9. A sequence of s muli was sampled from the matched set of func ons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_61"><head>Figure 5 . 26 :</head><label>526</label><figDesc>Propor on of correctly iden fied probes as a func on of set size. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_62"><head>Figure 5 . 27 :</head><label>527</label><figDesc>Mean point biserial correla on for the composi onal and the spectral mixture models. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_63"><head></head><label></label><figDesc>this chapter, I pursued the hypothesis that humans have functional inductive biases that are compositionally structured-that is, humans prefer to represent complex functions as compositions of simpler building blocks. I formalized this idea using a compositional kernel within a Gaussian Process regression framework. Human inductive biases were assessed across a diverse range of experiments. The first set (Experiments 2, 3, 4 and 6) attempted to directly measure inductive biases using extrapolation and interpolation judgments, finding that participants preferred compositional over non-compositional pattern completions. The second set of experiments examined the broader implications of compositionality, finding that compositional functions are perceived as more predictable (Experiment 5) and memorable (Experiment 9) compared to non-compositional functions. Furthermore, discrete displays of items are perceived as less numerous (a signature of statistical regularities; Experiment 7), and changes in such displays are more easily detected (Experiment 8). Taken together, these experimental findings provide strong support for the compositional hypothesis. 5.16.1 Related work The work presented here is connected to several lines of previous work. Most relevant are the seminal work of Griffiths et al. (2009) and Lucas et al. (2015) on Gaussian processes for function learning in general, and Wilson et al. (2015) more recent attempts to reverseengineer the human kernel using a non-parametric kernel in particular. The work presented in this chapter is complementary to this research. If one wants to find out how people perceive and reason about functional structure, then one needs both a bottom-up theory to describe how people make sense of structure as well as a top-down method to indicate what the final structure might look like when represented as a kernel. Additionally, implementing a structure search algorithm as a parse tree, as I have done here, has recently</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_64"><head>Figure 6 . 1 :</head><label>61</label><figDesc>Overview of the Gaussian Process func on learning model, combined with an upper confidence bound sampling strategy (specified using median par cipant parameter es mates from Experiment 11. A) Screenshot of Experiment 11. Par cipants were allowed to select any le un l the search horizon was exhausted. B) Es mated reward as predicted by a Gaussian Process func on learning engine, based on the sampled points in Panel A. (Not shown, the es mated uncertainty). C) Upper confidence bound of predicted rewards. D: Choice probabili es a er a so max choice rule,P(x) = exp(UCB(x)/τ)/ ∑ N j=1 exp(UCB(x j )/τ),where τ is the temperature parameter (i.e.,lower temperature values lead to more precise predic ons).6.3 Models of learning in complex spacesI will assess two kinds of models to describe how people learn within spatially-correlated bandit tasks . The function learning model uses the spatial correlation between rewards in order to learn about an underlying value function mapping inputs to expected rewards and their attached uncertainty. It is able to generalize from sampled to unexplored options. The associative learning model does not learn about an underlying function, but rather learns about each input individually by associating inputs with previously generated rewards. It is not able to generalize to unexplored options.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_65"><head></head><label></label><figDesc>Localization can be introduced by weighting a model's predicted values of each option q(x) by the inverse Manhattan distance (IMD) to the previously revealed tile. This is equivalent to a multiplicative combination with the Local Search model, without the introduction of any additional free parameters. Localized models will be indicated with an asterisk (e.g., function learning*).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_66"><head>6. 5</head><label>5</label><figDesc>Experiment 10: Univariate function exploration-exploitation The first variant of the spatially-correlated multi-armed bandit presents participants with a uni-variate multi-armed bandit problem with spatially correlated rewards. The problem space is represented by a one-dimensional array of 1×30 possible arms, i.e. 30 different options to sample. Participants can click to reveal unexplored tiles or re-click previously uncovered tiles to further explore or exploit known rewards. A screenshot of Experiment 10 is shown in Figure 6.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_67"><head>Figure 6 . 2 :</head><label>62</label><figDesc>Screenshot of Experiment 10. Univariate spa ally correlated mul -armed bandit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_68"><head>Figure 6 . 3 :</head><label>63</label><figDesc>Design of Experiment 10. Environments could be either smooth or rough (between subject manipula on).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_69"><head>Figure 6 .Figure 6 . 4 :</head><label>664</label><figDesc>4 shows task performance. In all conditions, performance improved as a function of the trial number (i.e., with each additional click), as measured by both the overall correlation between average reward and trial number (r = 0.66, p &lt; 0.001) and between the maximum observed reward and trial number (r = .91, p &lt; 0.001). There were no learningeffects across blocks (i.e., over successive grids), indicated by a lack of correlation between average reward and block number (r = −0.05, p &gt; 0.5), or between maximum reward and block number (r = −0.05, p &gt; 0.1). Performance improved as more information was revealed (i.e., over trials), but not over additional blocks of identically parameterized environments. Results of Experiment 10. Payoff conditions Payoff conditions influenced search behavior, with participants in the Maximum Reward condition displaying more variance in the locations sampled (t(79) = −3.26, p &lt; 0.05, d = 0.73). Participants in the Accumulator group achieved a higher average reward than participants in the Maximizer group (t(79) = 2.89, p &lt; 0.01, d = 0.65). However, Maximizers did not reveal a higher maximum value than Accumulators (t(79) = 0.28, p &gt; 0.7, d = 0.06). Thus, a strategy balancing exploration and exploitation, at least for human learners, may find the global maximum en passant. Environment and horizon Independent of the payoff condition, participants assigned to Smooth environments achieved higher average rewards (t(79) = 3.55, p &lt; 0.001, d = 0.79) and higher maximum rewards (t(79) = 3.46, p &lt; 0.001, d = 0.77) than those assigned to the Rough environments, suggesting that stronger correlations of payoffs make the task easier. Interestingly, longer horizons did not lead to better overall performance in the Average Reward condition (t(80) = 0.60, p &gt; 0.5, d = 0.07), although participants given longer horizons found larger maximum rewards for all payoffs and environment conditions (t(80) = 9.75, p &lt; 0.001, d = 1.08</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_70"><head></head><label></label><figDesc>or a grid search if the model contained only a single parameter. Parameter estimates are constrained to positive values in the range [exp(−5), exp(5)]. Cross-validation is performed by first separating participant data according to horizon length, which alternated between rounds within subject. For each participant, half of the rounds corresponded to a short horizon and the other half corresponded to a long horizon. Within all rounds of each horizon length, leave-one-out cross-validation is used to iteratively form a training set by leaving out a single round, computing a MLE on the training set, and then generating out of sample predictions on the remaining round.This is repeated for all combinations of training set and test set, and for both short and long horizon sets for each participant individually. The cross-validation procedure will yield one set of parameter estimates per round, per participant, and out of sample predictions for 120 choices per participant. In total, cross validation required approximately 25,000 hours of computation, or about 2 days distributed across a 716 CPU cluster.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_71"><head>Figure 6 . 5 :Figure 6 . 6 :</head><label>6566</label><figDesc>Model comparison results of Experiment 10.The function learning models generally predicted participants' behavior better than the associative learning models (t(80) = 15.81, p &lt; 0.001, d = 1.76) and better than the simple strategies (t(80) = 9.22, p &lt; 0.001, d = 1.02). Within the function learning models, the upper confidence bound sampling strategy performed better than all other sampling strategies (t(80) = 15.34, p &lt; 0.001, d = 1.71). Even though localization improved both the function learning model's (t(80)= 5.05, p &lt; 0.001, d = 0.56) and the associative learning model's (t(80) = 17.1,p &lt; 0.001, d = 1.9) performance, assessing only the upper confidence bound sampling strategies, the non-localized model performed better than the localized function learning model (t(80) = 5.0495, p &lt; 0.001, d = 0.56). Furthermore, decomposing the upper confidence bound sampling strategy into pure exploitation (mean greedy) or pure exploration (variance greedy) components revealed that both high expectations of reward and the reduction of uncertainty are necessary components for the function learning model to predict human search behavior, with mean greedy (t(80) = −8.85, p &lt; .001, d = 0.98) and variance greedy (t(80) = −16.63, p &lt; .001, d = 1.85) performing worse than the combined UCB algorithm. In total, 48 participants were best predicted by the function learning model combined with a upper confidence bound sampling strategy. Extracted parameter estimates Looking more closely at the parameter estimates of the Gaussian Process-based function learning model with upper confidence bound sampling (Figure 6.6; median estimates per participant) showed that people tend to underestimate the extent of spatial correlations, with estimated λ values significantly lower than the ground truth for both Smooth (mean estimate:λ = 0.82, t(41) = −17.60, p &lt; .001, d = 2.71; compared to ground truth λ Smooth = 2) and Rough environments (λ = 0.78, t(38) = −3.89, p &lt; .001, d = 0.62;compared to λ Rough = 1), which could be interpreted as a tendency to avoid overgeneralization. The exploration bonus of UCB sampling (β) was robustly Parameter es mates of Experiment 10. estimated above 0 (β = 0.47, t(80) = 12.78, p &lt; .001, d = 1.42, compared to the lower estimation bound), indicating participants valued the exploration of uncertain options, along with exploiting high expectations of reward. Additionally, the estimates of the softmax temperature were very low (τ = 0.01), corresponding to more precise model predictions.6.6 Experiment 11: Bivariate function exploration-exploitationThe second variant of the spatially-correlated multi-armed bandit presents participants with a bi-variate spatially correlated bandit. Therein, the problem space was represented as a two-dimensional grid, measuring 11×11, resulting in 121 unique tiles in total. As in the univariate experiment, participants could click to reveal unexplored tiles or re-click previously uncovered tiles. A screenshot of Experiment 11 is shown inFigure 6.7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_72"><head>Figure 6 . 7 :</head><label>67</label><figDesc>Screenshot of Experiment 11. Bivariate spa ally correlated mul -armed bandit. recruited from Amazon Mechanical Turk (25 Female; mean age ± SD 32 ± 9). Each participant was paid a participation fee of $0.50 and a performance contingent bonus up to $1.50. Subjects earned on average $1.64 ± 0.20 and spent on average 8 minutes on the task.DesignAs before, a 2×2 between subject design was used, where participants were randomly assigned to one of two different pay-off structures (Maximizers vs. Accumulators) and one of two different classes of environments (Smooth vs. Rough). Each grid represented a bi-variate function, with each observation including normally distributed noise, ε ∼ N (0, 1). The task was presented over 8 blocks on different grid worlds drawn from the same class of environments. In each block, participants had either a Short (20 clicks) or Long (40 clicks) search horizon to interact with the grid. The search horizon alternated between blocks (within subject), with initial horizon length counterbalanced between subjects. Observations were again scaled for every block to a uniformly sampled maximum value in the range of 65 to 85 as before. The design of Experiment 11 is shown inFigure 6.8.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_73"><head>Figure 6 . 8 :</head><label>68</label><figDesc>Design of Experiment 11.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_74"><head></head><label></label><figDesc>task performance. Performance improved as a function of the trial number as measured by both the overall correlation between average reward and trial number (r = 0.32, p &lt; 0.001) and between the maximum observed reward and trial number (r = 0.83, p &lt; 0.001). There were no learning effects across blocks, indicated by a lack of correlation between average reward and block number (r = 0.19, p &gt; 0.5), or between maximum reward and block number (r = −0.37, p &gt; 0.1). Thus, as in the univariate experiment, performance improved as more information was revealed, but not over additional blocks of identically parameterized environments.Payoff conditionsPayoff conditions influenced search behavior, with participants in the Maximizer condition displaying more variance in the locations sampled (t(78) = −2.48, p &lt; 0.01, d = 0.55).Participants in the Accumulator group did not achieved a higher average reward than participants in the Maximizer group (t(78) = 1.32, p &gt; 0.1. d = 0.29) and Maximizers did not reveal a higher maximum value than Accumulators (t(78) = 1.48, p &gt; 0.1, d = 0.33).Environment and horizonIndependent of the payoff condition, participants assigned to Smooth environments achieved higher average rewards (t(78) = 6.55, p &lt; 0.001, d = 1.47) and higher maximum rewards (t(78) = 5.45, p &lt; 0.001, d = 1.22) than those assigned to the Rough environments, suggesting that stronger correlations of payoffs make the task easier. As before, longer horizons did not lead to better overall performance in the Accumulator condition (t(79) = 0.96, p &gt; 0.3, d = 0.11), although participants given longer horizons found larger maximum</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_75"><head>Figure 6 . 9 :</head><label>69</label><figDesc>Results of Experiment 11.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_76"><head>Figure 6 . 10 :Figure 6 . 11 :</head><label>610611</label><figDesc>Model comparison results of Experiment 11.Again, the function learning model performed better than the associative learning model(t(79) = −5.01, p &lt; 0.001, d = 0.56). However, this time further localization of the models improved both the associative (t(79) = 27.46, p &lt; 0.001, d = 3.07) and the function learning model (t(79) = 19.12, p &lt; 0.001 d = 2.13). Again, the upper confidence bound sampling strategy was by far the best sampling strategy (t(79) = 12.57, p &lt; 0.001, d = 1.41). The localized function learning* model paired with a upper confidence bound sampling strategy predicted 59 participant best overall and performed significantly better than the localized associative learning* model (t(70) = −2.18, p &lt; 0.05, d = 0.24; UCB only). Again, both components of the UCB strategy-the expected reward (t(79) = −6.44, p &lt; .001, d = 0.72) and the attached uncertainty (t(79) = −14.32, p &lt; .001, d = 1.60)-were necessary to predict choices. 6.6.4 Parameter estimates Further extracting the median parameter estimates per participant from the localized Gaussian Process-based function learning* model (Figure 6.11) showed that participants again un-: λ Exploration bonus: β Softmax: τ Estimate Experiment 2: Function Learning* Parameter es mates of Experiment 11. derestimated the strength of the underlying spatial correlation in both Smooth (λ = 0.92, t(42) = −14.62, p &lt; .001, d = 2.22; comparison to λ Smooth = 2) and Rough environments (λ = 0.78, t(36) = −5.31, p &lt; .001, d = 0.87; comparison to λ Rough = 1), suggesting a robust tendency to avoid overgeneralization. The estimated exploration bonus β was again greater than 0 (β = 0.45, t(79) = 27.02,p &lt; .001, d = 3.02, compared to the lower estimation bound), while the estimated softmax temperature parameter τ was slightly larger than in Experiment 10,τ = 0.09.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_77"><head>Figure 7 . 1 :</head><label>71</label><figDesc>Screenshot of the CMAB task depic ng Experiment 12.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_78"><head></head><label></label><figDesc>Propor on of best arm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_79"><head>Figure 7 . 2 :</head><label>72</label><figDesc>Results of the binary CMAB task of Experiment 12. Average overall score (a), propor on of choosing the fourth arm (b), and propor on of choosing the best arm (c)Over time, participants made increasingly better choices (seeFigure 7.2a), as indicated by a significant correlation between the average score (over participants) and trial number, r = 0.74, p &lt; 0.01. The proportion of participants choosing the non-contextual option (the option that did not respond to any of the contextual features, indicated as the 4th arm) decreased over time (r = −0.22, p &lt; 0.05, Figure 7.2b), another indicator that participants learned the underlying functions. The proportion of participants choosing the best option for the current context increased during the task (r = 0.72, p &lt; 0.01, see Figure 7.2a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_80"><head>pFigure 7 . 3 :</head><label>73</label><figDesc>&lt; 0.05, d = 0.45). The probability of improvement sampling strategy numerically predicted participants' choices best out of all the sampling strategies when combined with the radial basis function kernel (t(46) = 4.84, p &lt; 0.001, d = 0.71).The median parameter estimates of the GP-RBF model over all sampling strategies per participant, are shown inFigure 7.4. Predic ve accuracy of the models for the CMAB task with discrete cues in Experiment 12. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_81"><head>Figure 7 . 4 :</head><label>74</label><figDesc>) λ (Length−scale) τ (Temperature) Estimate (log scale)Parameter estimates Median es mates of the error variance σ, the length-scale λ, and the temperature parameter τ for the Gaussian Process regression radial basis func on kernel model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_82"><head></head><label></label><figDesc>Figure 7.5a). While the proportion of participants choosing the fourth option did not decrease significantly over time (r = 0.05, Propor on of best arm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_83"><head>Figure 7 . 5 :</head><label>75</label><figDesc>Results of the binary CMAB task of Experiment 13. Average overall score (a), propor on of choosing the fourth arm (b), and propor on of choosing the best arm (c) p &gt; 0.05), the proportion of choosing the best option given the context significantly increased over trials (r = 0.33, p &lt; 0.01, seeFigure 7.5c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_84"><head>Figure 7 . 6 :</head><label>76</label><figDesc>Figure 7.6. The best performing model incorporates again a GP learning component, but now coupled with a UCB decision strategy. Contextual models again performed better than the context-blind models (t(58) = 3.11, p &lt; 0.01, d = 0.40). Yet, the linear model performed significantly worse than all of the other models (t(58) = −2.84,p &lt; 0.01, d = 0.37). The Gaussian Process model with a radial basis function kernel performed significantly better than all of the other candidate models Predic ve accuracy of the models for the CMAB task with con nuous-linear cues in Experiment 13. Error bars represent the standard error of the mean.(t(58) = 3.95, p &lt; 0.001, d = 0.51). Thus, as in Experiment 12, participants were best predicted by a GP-based learning model with a universal kernel function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_85"><head>σ</head><label></label><figDesc>001, d = d = 0.63, and the GP-learning model, t(58) = 2.43, p &lt; 0.05, d = 0.32. The probability of maximum utility sampling strategy resulted into better predictive performance for both the Bayesian mean tracker (t(58) = 8.05, p &lt; 0.001, d = 1.05) and Kalman filter learning model (t(58) = 7.22, p &lt; 0.001, d = 0.94). This mirrors previous findings on restless bandit tasks (Speekenbrink &amp; Konstantinidis, 2015) and could indicate that some people switched to a non-contextual strategy within this more difficult set-up. The median estimates of the GP-RBF-learning model for each participant are shown in Figure 7.7. The mean estimated temperature parameter wasτ −1 = 0.049, which again (Variance) λ (Length−scale) τ (Temperature) Estimate (log scale)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_86"><head>Figure 7 . 7 :</head><label>77</label><figDesc>Median es mates of the error variance σ, the length-scale λ, and the temperature parameter τ for the GP-RBF model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_87"><head></head><label></label><figDesc>28 female) with a mean age of 29 (SD=8.2) were recruited via Amazon Mechanical Turk and received $0.3 as a basic reward and a performance-dependent reward of up to $0.5. Participants earned $0.67 ± 0.04 on average. The experiment took around 12 minutes to complete.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_88"><head></head><label></label><figDesc>above chance level, t(59) = 5.85, p &lt; 0.01, d = 0.85.Average scores increased over trials, r = 0.19, p &lt; 0.01, but to a lesser extent than in Propor on of best arm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_89"><head>Figure 7 . 8 :</head><label>78</label><figDesc>Results of the binary CMAB task of Experiment 14. Average overall score (a), propor on of choosing the fourth arm (b), and propor on of choosing the best arm (c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_90"><head>Figure 7 . 9 :</head><label>79</label><figDesc>blind models (t(59) = 2.7047, p &lt; 0.01, d = 0.37), but this was due to the linear model generating worse predictions than all of the other models (t(59) = −3.59, p &lt; 0.001, d = 0.50). The Gaussian Process model parameterized with a radial basis function kernel generated better predictions than all of the other models (t(59) = 4.13, p &lt; 0.001, Predic ve accuracy of the models for the CMAB task with con nuous-non-linear cues in Experiment 14. Error bars represent the standard error of the mean. d = 0.57). The probability of maximum utility sampling strategy generated better predictions within the the Kalman filter (t(59) = 1.90, p &lt; 0.05, d = 0.26) learning models.There was no meaningful difference between different sampling strategies for the Gaussian Process model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_91"><head>Figure 7 .Figure 7 . 10 :</head><label>7710</label><figDesc>10 shows the median estimates of the GP-RBF learning model for all partici-pants. The low average estimated temperature parameterτ = 0.06 again indicates that Median es mates of the error variance σ, the length-scale λ, and the temperature parameter τ for the GP-RBF model. participants consistently chose the option with higher predicted rewards. The estimated length-scale clustered tightly along a value ofλ = 6.86 and the estimated noise variance ofσ 2 ε = 5.71 was again indistinguishable from the underlying true variance of σ 2 ε = 5 (t(59) = 1.09, p &gt; 0.05, d = 0.02).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_92"><head></head><label></label><figDesc>non-linear experiment (t(105) = −0.28, p &gt; 0.05, d = 0.05). Comparing the explorationparameter β across experiments revealed that there was a negative correlation between the tendency to explore and the complexity of the task (ranked from discrete to non-linear)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_93"><head></head><label></label><figDesc>Mean es mates of the predic ve performance R 2 , the explora on parameter β, the error variance σ, and the length-scale λ across all experiments. Error bars represent the standard error of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_94"><head></head><label></label><figDesc>8.4)where φ(•) is the normal probability density function and Z = (μ(x) − f(x + ) − ξ)/σ(x).The remaining three sampling strategies are all based on relatively costly Monte Carlo methods. They are included in the simulations because they are frequently applied in computational optimization scenarios. Yet, I have not used them as candidate sampling strategies of human search in the experiments presented earlier. This was mostly due to the fact that these acquisition functions are computationally expensive to run such that it would not have been possible to use them for each participant individually while also optimizing kernel hyper-parameters. For example, the probability of maximum utility sampling strategy, which can be seen as a more simplistic case of the following strategies, already takes three times as long as all the other sampling strategies when parameters were optimized at the same time, running for about 4 hours per participant.Predictive entropy search (PES) is an information-based acquisition function that samples points that promise to maximally reduce the differential entropy of an unknown optimizer x * = arg max x∈X f(x)<ref type="bibr" target="#b92">(Hennig &amp; Schuler, 2012;</ref><ref type="bibr" target="#b94">Hernández-Lobato et al., 2014)</ref>.After having observed data D n , the posterior distribution of x * is p * (x|D). The predictive entropy search sampler then isPES(x) = H(y|D n , x) − E x * |Dn [H(y|D n , x, x * )] (8.5)where H(x * |D n ) denotes the differential entropy of p * (x|D). The differential entropy can be approximated by Monte Carlo sampling from the posterior GP<ref type="bibr" target="#b94">(Hernández-Lobato et al., 2014)</ref>.Minimum regret point (MRP) sampling samples the point producing the lowest simple regret<ref type="bibr" target="#b146">(Metzen, 2016)</ref>. The expected simple regret (ER) of selecting x under p(f) can be expressed as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_95"><head></head><label></label><figDesc>Chapter 3 showed how differently smooth priors result into different levels of posterior generalization, i.e. how much information one point provides about proximal points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_96"><head></head><label></label><figDesc>investigated whether GPs can be made robust against mismatch effects by optimizing the student's model hyper-parameters to maximize the data likelihood. He derived an approximation for the average evidence and used it to predict the optimal hyper-parameter values and the resulting generalization error. This showed that, in lower-dimensional learning scenarios, evidence maximization eliminates logarithmically slow learning and recovers the optimal scaling of the decrease of generalization error with training set size. Furthermore, van der Vaart &amp; van Zanten (2008) derived rates of contraction of posterior distributions on nonparametric or semiparametric models based on Gaussian Processes and showed that smoother functions show faster contraction rates than rough ones and that having the right expectation about the underlying smoothness improves the rate of convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_98"><head>Figure 8 . 1 :</head><label>81</label><figDesc>Median regret over me for different sampling strategies in matched and mismatched condi ons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_99"><head>Figure 8 .Figure 8 . 2 :</head><label>882</label><figDesc>2 shows the median root mean squared difference between each sampling strategy's Median counter-factual regret over 50 trials for different input-dimensions. performance in the mismatched setting compared to the same strategy's performance in the matched setting for each dimension. This provides a relative measure of counter-factual regret, i.e. by how much could each of the strategies have done better on each trial if it had been specified with the right prior about the target function's smoothness. It can be seen that, whereas most sampling strategies seem to recover from misspecified assumptions in the bi-variate case, the effect of misspecifications exacerbates over time in higher dimen-sions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_101"><head>Figure 8 . 3 :</head><label>83</label><figDesc>Median regret over me for different sampling strategies in matched and mismatched condi ons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_102"><head>8. 6</head><label>6</label><figDesc>Simulation 4: The effect of λ on regret Throughout all of the experiments in Chapters 6-7 I have used a radial basis function kernel to describe participants' generalization. As the estimated λ, which I interpreted as a gradient of functional generalization, turned out to be lower than what the underlying function allowed for, I next assess the effect of mismatched λs directly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_103"><head></head><label></label><figDesc>tends to undergeneralize. Every possible combination between λ 0 = {0.1, 0.2, • • • , 1} and λ 1 = {0.1, 0.2, • • • , 1} was created leading to 100 different combinations of student-teacher optimization scenarios. For every run of the simulation, I sampled a target function from a univariate Gaussian Process parameterized by λ 0 and then used a Gaussian Process parameterized by λ 1 and one of the 6 sampling strategies to optimize the target function over 50trials. This was repeated for 100 runs for every student-teacher-sampling strategy combination leading to 60,000 runs of the simulation in total (i.e., 10 different λ 0 -values times 10 different λ 1 -values times 6 sampling strategies).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_104"><head>Figure 8 .</head><label>8</label><figDesc>4 show the median regret for 100 runs for all sampling strategies and every λ 0 -λ 1combination at trial number N = {1, 5, 10, 15, 50}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_105"><head>Figure 8 . 4 :</head><label>84</label><figDesc>Median regret for different student-teacher combina ons and sampling strategies at trial number N = {1, 5, 10, 15, 50}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_106"><head></head><label></label><figDesc>the fifth chapter of this thesis, I defined and tested a compositional theory of human function learning and generalization. Within 8 experimental paradigms, from simple pattern completion to a working memory task, I have probed how a pre-defined compositional grammar of functional inductive biases explains human behavior. The results and analyses of all experiments converged clearly on the same interpretation, namely that participants do indeed have compositional inductive biases. Other approaches of structure learning and generalization such as approximating the gradient of functional generalization explicitly or just assuming a smooth radial basis function kernel were unable to explain the richness of behavioral findings across all experiments. A compositional theory of human generalization provides a plausible and unique description of human generalization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_107"><head>For</head><label></label><figDesc>and only if f is white noise, the least forecastable signal with a uniform spectrum. The forecastibility measure Ω(f) is then defined asΩ(f) = 1 − H(f) ln(2π) . (A.3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_108"><head>Figure A. 2 :</head><label>2</label><figDesc>Parameter recovery results. The genera ng parameter es mate is on the x-axis and the recovered parameter es mate is on the y-axis. The genera ng parameter es mates are from the cross-validated par cipant parameter es mates, which were used to simulate data (see Model Recovery). Recovered parameter es mates are the result of the cross-validated model comparison (see Model Comparison) on the simulated data. While the cross-valida on procedure yielded k-es mates per par cipant, one for each round (k exp1 = 16; k exp2 = 8), I show the median esmate per (simulated) par cipant. The dashed line shows a linear regression on the data, while the Pearson correla on and p-value is shown above the plot. For readability, colors represent the bivariate kernel density es mate, with red indica ng higher density.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_110"><head>Figure A. 3 :</head><label>3</label><figDesc>Median regret over me for different sampling strategies using a mixture kernel student.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_111"><head>Figure A. 3</head><label>3</label><figDesc>shows the median regret over 100 runs for a mixture kernel, with a Matérn 1/2 and radial basis function kernel component, optimizing either a RBF or a Matérn 1/2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Table A.1 reports the median values of the cross-validated parameter estimates used to specify each generating model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A.2 Parameter recovery results. The generating parameter estimate is on the x-axis and the recovered parameter estimate is on the y-axis. The generating parameter estimates are from the cross-validated participant parameter estimates, which were used to simulate data (see Model Recovery). Recovered parameter estimates are the result of the cross-validated model comparison (see Model Comparison) on the simulated data. While the cross-validation procedure yielded k-estimates per participant, one for each round (k exp1 = 16; k exp2 = 8), I show the median estimate per (simulated) participant. The dashed line shows a linear regression on the data, while the Pearson correlation and p-value is shown above the plot. For readability, colors represent the bivariate kernel density estimate, with red indicating higher density. . . . . . . . . . . . . . . . . . . . . . . . . . 232 A.3 Median regret over time for different sampling strategies using a mixture kernel student. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237 Listing of tables 3.1 Observations for the function learning example. Inputs x t and corresponding outputs y t observed at times t = 1, . . . , 6. . . . . . . . . . . . . . . . . . . . 27 3.2 Example of generating a prediction using a Gaussian Process with a radial basis function kernel. w i = (K(X, X) + σ 2 ε I) −1 y i ; x ⋆ =3; . . . . . . . . . . . . . .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>This thesis consists of 9 chapters. Chapter 2 introduces the historical background of theories concerning human generalization and function learning. Therein, I argue that an understanding of function learning is cardinal to understanding human generalization. The</figDesc><table><row><cell>introduces and extensively probes a compositional theory of function learning and general-</cell></row><row><cell>ization. Chapter 6 assesses how people explore and exploit options on a grid containing spa-</cell></row><row><cell>tially correlated reward allowing for functional generalization. The contextual multi-armed</cell></row><row><cell>bandit, a paradigm in which participants have to both learn about a functions mapping</cell></row><row><cell>features to outcomes and generate rewards, is assessed across different degrees of difficulty</cell></row><row><cell>in Chapter 7. Chapter 8 tries to shed more light onto the adaptiveness of human behavior</cell></row><row><cell>by assessing what happens to different Bayesian optimization routines in the case of mis-</cell></row><row><cell>matched prior assumptions about the generalizability of observations. Chapter 9 concludes</cell></row><row><cell>mathematical underpinnings of Gaussian Process regression, kernel-encoded functional</cell></row><row><cell>characteristics, structure search by kernel composition, as well as Bayesian optimization</cell></row><row><cell>are laid out in Chapter 3. Chapter 4 demonstrates how precise predictions can be derived</cell></row><row><cell>from Gaussian Process learning curves and demonstrate that factors theoretically influ-</cell></row><row><cell>encing a function's generalizability equally influence participants' judgments. Chapter 5</cell></row></table><note>this thesis by summarizing the main lessons learned while laying out a road-map of how a Gaussian Process-based theory of generalization could further unify different psychological phenomena.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .2:</head><label>3</label><figDesc>Example of genera ng a predic on using a Gaussian Process with a radial basis func on kernel.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 . 1 :</head><label>41</label><figDesc>Parameter es mates of factors influencing predictability judgments extracted from a mixed-effects regression analysis. Condi onal pseudo-r 2 = 0.30.</figDesc><table><row><cell></cell><cell cols="3">Estimate s.e. t-value Pr(&gt;|t|)</cell></row><row><cell>Intercept</cell><cell cols="2">41.70 1.82 22.93</cell><cell>0.00</cell></row><row><cell>n</cell><cell>0.79 1.02</cell><cell>0.77</cell><cell>0.44</cell></row><row><cell>p</cell><cell cols="2">8.00 0.72 11.11</cell><cell>0.00</cell></row><row><cell>σ 2</cell><cell>-5.21 0.66</cell><cell>-7.90</cell><cell>0.00</cell></row><row><cell>n × p</cell><cell>1.48 0.38</cell><cell>3.90</cell><cell>0.00</cell></row></table><note>hand, is not significant. Nonetheless, sample size interacts significantly with smoothness:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 4 . 2 :</head><label>42</label><figDesc>Average correla on between factors and par cipants' predictability judgments r and importance as assessed by a random forest permuta on algorithm.</figDesc><table><row><cell cols="3">Variable Average r Importance</cell></row><row><cell>n</cell><cell>0.06</cell><cell>8.04</cell></row><row><cell>σ 2</cell><cell>-0.24</cell><cell>8.25</cell></row><row><cell>s</cell><cell>0.36</cell><cell>10.02</cell></row><row><cell>E(n)</cell><cell>-0.34</cell><cell>11.58</cell></row><row><cell>4.4 Discussion</cell><cell></cell><cell></cell></row></table><note>This investigation of predictions directly derived from Gaussian Process learning theory shows that theoretical predictions about a function's generalizability provide a framework for understanding participants' perception of a function's predictability. This model cap- tures qualitative effects of a function's smoothness, noise variance, and sample size on the generalization error, which is essentially the the inverse of predictability. The smoothness</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>'s research on the generation of different alphabets of characters. Their proposal is a Bayesian Program Induction framework<ref type="bibr" target="#b125">(Lake et al., 2013)</ref> that learns simple stochastic programs to represent concepts, building them compositionally from parts, subparts, and spatial relations. This model defines a generative model that can sample new types of concepts by combining parts and subparts in new ways, essentially a compositional approach to character learning. Within a simple Turing-like task participants could not distinguish new characters generated by this model from characters generated by other humans, thereby demonstrating the full expressiveness of this approach. Yet, how can compositionality support human function learning and gen-</figDesc><table /><note>eralization? In what way, if any, is human function learning compositional?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table /><note>1: Base kernels in the composi onal grammar.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 5 . 2 :</head><label>52</label><figDesc>Kernel combina ons in the composi onal grammar and their interpreta ons.</figDesc><table><row><cell>Combination</cell><cell>Interpretation</cell></row><row><cell>Linear</cell><cell>Linear function</cell></row><row><cell>Radial basis</cell><cell>Locally smooth function</cell></row><row><cell>Periodic</cell><cell>Repeated pattern</cell></row><row><cell>Linear + Periodic</cell><cell>Linear trend plus repeated pattern</cell></row><row><cell>Linear + RBF</cell><cell>Linear trend plus local deviations</cell></row><row><cell>RBF + Periodic</cell><cell>Repeated pattern plus local deviations</cell></row><row><cell>Linear × Periodic</cell><cell>Repeated pattern with increasing amplitude</cell></row><row><cell>Linear × RBF</cell><cell>Local deviations with increasing amplitude</cell></row><row><cell>RBF × Periodic</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 5</head><label>5</label><figDesc>.2, optimizing each kernel's hyper-parameters on the training set and then generating the completions for the extrapolation set. On each trial, participants chose between their most recently accepted extrapolation and a new proposal. Proposals were sampled uniformly from this set. I mainly focused on combinations containing linear and periodic components, as these provide more interesting structure than the smoothness induced by samples from the radial basis function kernel.</figDesc><table><row><cell>Participants</cell></row><row><cell>51 participants (27 male) with an average age of 32.55 (SD = 8.21) were recruited via Ama-</cell></row><row><cell>zon's Mechanical Turk web service and paid $1. The experiment took 8 minutes on average</cell></row><row><cell>to complete.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head></head><label></label><figDesc>86.96 vs. 58.33, hierarchical t-test: t(676) = −2.28, p &lt; 0.05, d = 0.35) and extrapolation areas (110.45 vs 83.91, hierarchical t-test: t(434) = 2.2, p &lt; 0.05, d = 0.33). The radial basis function kernel produced similar distances as the compositional kernel in interpolation (55.8, hierarchical t-test: t(649) = −0.55, p &gt; 0.05, d = 0.03), but predicted participants' drawings significantly worse in extrapolation areas (97.9, t(508) = 1.8, p &lt; .05, d = 0.17). As extrapolation is normally seen as the best criterion to measure generalization and thus the best measure to compare models of function learning (</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 5 . 3 :</head><label>53</label><figDesc>Regression model of predictability judgments. Overall model fit: Condi onal pseudo-R 2 = 0.17.</figDesc><table><row><cell></cell><cell cols="4">Estimate Std. Error t-value Pr(&gt;|t|)</cell></row><row><cell>Intercept</cell><cell>13.06</cell><cell>3.50</cell><cell>3.72</cell><cell>0.0002</cell></row><row><cell>Compositional</cell><cell>17.44</cell><cell cols="2">1.53 11.39</cell><cell>0.0000</cell></row><row><cell>Sample size</cell><cell>0.34</cell><cell>0.04</cell><cell>7.42</cell><cell>0.0000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="4">Estimate Std. Error t value Pr(&gt;|t|)</cell></row><row><cell>Intercept</cell><cell>23.01</cell><cell cols="2">0.72 32.02</cell><cell>0.0000</cell></row><row><cell>Compositional</cell><cell>-1.56</cell><cell>0.62</cell><cell>-2.52</cell><cell>0.0118</cell></row><row><cell>Trial</cell><cell>-0.30</cell><cell>0.0535</cell><cell>-5.65</cell><cell>0.0000</cell></row></table><note>4: Regression model of the tradi onal func on learning paradigm. Overall model fit: R 2 = 0.14.Participants improved over the course of each block, as evidenced by the main effect of trial. While compositional functions are on average predicted better (β = −1.56), this</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="4">Estimate Std. Error t-value Pr(&gt;|t|)</cell></row><row><cell>Intercept</cell><cell>3.23</cell><cell cols="3">0.12 27.631 &lt;2e-16</cell></row><row><cell>Number of dots</cell><cell>-0.39</cell><cell cols="3">0.01 -35.845 &lt;2e-16</cell></row><row><cell>Compositional</cell><cell>-0.17</cell><cell>0.07</cell><cell>-2.43</cell><cell>0.015</cell></row><row><cell cols="4">5.14 Experiment 8: Change detection with functions</cell><cell></cell></row><row><cell cols="5">Next, I assessed the effect of compositional structure on change detection performance</cell></row></table><note>5: Parameter es mates from numerosity judgments regression analysis.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="4">Estimate Std. Error z value Pr(&gt;|z|)</cell></row><row><cell>Intercept</cell><cell>1.3018</cell><cell cols="2">0.0918 14.19</cell><cell>0.0000</cell></row><row><cell>Compositional prediction</cell><cell>0.0122</cell><cell cols="2">0.0006 19.61</cell><cell>0.0000</cell></row><row><cell>Spectral mixture prediction</cell><cell>0.0012</cell><cell>0.0006</cell><cell>1.95</cell><cell>0.0517</cell></row></table><note>6: Result of change detec on logis c regression.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 5 .7:</head><label>5</label><figDesc>Results of logis c regression analysis of the memory experiment.</figDesc><table><row><cell></cell><cell cols="3">Estimate Std. Error z-value</cell><cell>Pr(&gt;|z|)</cell></row><row><cell>Intercept</cell><cell>2.04</cell><cell>0.29</cell><cell cols="2">7 &lt;2.57e-12</cell></row><row><cell>Set size</cell><cell>-0.22</cell><cell>0.06</cell><cell>-3.33</cell><cell>&lt;0.001</cell></row><row><cell>Compositional</cell><cell>1.24</cell><cell>0.37</cell><cell>3.33</cell><cell>&lt;0.001</cell></row><row><cell>Set size × Compositional</cell><cell>-0.18</cell><cell>0.08</cell><cell>2.2</cell><cell>0.02</cell></row><row><cell cols="5">I next developed a Bayesian model of performance in the task, adapting the same basic</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="4">Estimate Std. Error z value Pr(&gt;|z|)</cell></row><row><cell>Intercept</cell><cell>1.4314</cell><cell>0.2147</cell><cell>6.67</cell><cell>0.0000</cell></row><row><cell>Compositional prediction</cell><cell>0.0543</cell><cell>0.0098</cell><cell>5.53</cell><cell>0.0000</cell></row><row><cell>Spectral mixture prediction</cell><cell>0.0176</cell><cell>0.0096</cell><cell>1.83</cell><cell>0.0676</cell></row><row><cell cols="5">Finally, I calculated the correlation between each model's predictions and participants'</cell></row></table><note>8: Results of logis c regression analysis of the memory experiment.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head></head><label></label><figDesc>"I tried to develop theories that took account of the uncertainty and the complexity in the world."</figDesc><table><row><cell>6.1 Introduction</cell></row><row><cell>The experiments so far have investigated how participants perceive, judge about, or predict</cell></row><row><cell>Herbert Simon, 1978</cell></row><row><cell>unknown functions in single or sequential function learning tasks. However, function learn-</cell></row><row><cell>ing and generalization are also important for another domain, which is when the goal is to</cell></row><row><cell>generate rewards, i.e. in function exploration-exploitation tasks.</cell></row><row><cell>Consider having just arrived at a new place and having to decide where to dine tonight. 6 If it is a big city, then there are likely many different restaurants available and quite possibly</cell></row><row><cell>Exploration and generalization in vast</cell></row><row><cell>spaces</cell></row><row><cell>these fea-</cell></row><row><cell>tures to make a prediction about a restaurant's culinary quality and the kind of experience</cell></row><row><cell>you expect when dining there. This not only means that you can use this information to</cell></row><row><cell>This chapter combines Gaussian Process regression with upper confi-make your decision, it also means that a situation in which you would otherwise have to</cell></row><row><cell>dence bound sampling to model how participants explore and exploit explore a vast number of different restaurants in order to learn about their underlying qual-</cell></row><row><cell>unknown functions in spatially correlated multi-armed bandit tasks. ities and cuisine suddenly becomes much more tractable as you utilize a function that maps</cell></row><row><cell>features onto expected rewards. Learning a mapping between features and expected out-</cell></row><row><cell>comes whilst making decisions that both explore and exploit the underlying function is the</cell></row><row><cell>topic of this chapter.</cell></row></table><note>more than you could ever try during your stay or even -if you are in a place like London, Berlin, or New York-during a life time. How do you decide where to dine tonight? Fortunately, this might not be the first time you have to make this kind of decision. In- stead, you have likely tried out different restaurants in the past and you know what you like and are confident about what kind of experience you want. Additionally, different restaurants also come with different features such as the cuisine on offer, their location, their price, their rating on different travel websites, and so forth, and you can use</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head></head><label></label><figDesc>use the Matérn class of kernel functions to encode the expected smoothness of the target function explicitly as in Chapters 3-4. To recaptitulate this kernel class one more time, the Matérn covariance between two points separated by τ = |x − x ′ | distance units is</figDesc><table><row><cell>8)</cell></row><row><cell>8.2.2 Encoding Smoothness</cell></row><row><cell>I will again</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_33"><head>Table A . 1 :</head><label>A1</label><figDesc>Modeling results of Experiments 10 and 11. Parameter estimates are the mean over all participants. There were 81 participants in Experiment 10 and 80 participants in Experiment 11.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Experiment 10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Experiment 11</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Model Comparison</cell><cell></cell><cell cols="3">Parameter Estimates</cell><cell cols="2">Model Comparison</cell><cell></cell><cell cols="3">Parameter Estimates</cell></row><row><cell>Model</cell><cell>Predictive Accuracy</cell><cell>Participants Best Described</cell><cell>Length Scale (λ)</cell><cell>Exploration Bonus (β)</cell><cell>Error Variance ( √ θ 2 ε )</cell><cell>Softmax Temperature (τ)</cell><cell>Predictive Accuracy</cell><cell>Participants Best Described</cell><cell>Length Scale (λ)</cell><cell>Exploration Bonus (β)</cell><cell>Error Variance ( √ θ 2 ε )</cell><cell>Softmax Temperature (τ)</cell></row><row><cell>associative learning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.09</cell><cell>1</cell><cell>-</cell><cell>2.54</cell><cell>1.01</cell><cell>0.03</cell><cell>0.1</cell><cell>0</cell><cell>-</cell><cell>0.97</cell><cell>1.96</cell><cell>0.02</cell></row><row><cell>Pure Exploitation</cell><cell>0.07</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell>54.6</cell><cell>54.6</cell><cell>0.1</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>148.41</cell><cell>148.41</cell></row><row><cell>Pure Exploration</cell><cell>0.02</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.6</cell><cell>0.05</cell><cell>0.01</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>15.9</cell><cell>0.03</cell></row><row><cell>Expected Improvement</cell><cell>0.02</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.59</cell><cell>0.01</cell><cell>0.01</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>1.56</cell><cell>0.02</cell></row><row><cell>Probability of Improvement</cell><cell>0.02</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.42</cell><cell>0.01</cell><cell>0.1</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.01</cell><cell>0.11</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.00</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.62</cell><cell>7.63</cell><cell>0</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.54</cell><cell>0.01</cell></row><row><cell>associative learning*</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.21</cell><cell>1</cell><cell>-</cell><cell>20.12</cell><cell>0.01</cell><cell>28.12</cell><cell>0.36</cell><cell>12</cell><cell>-</cell><cell>44.08</cell><cell>0.07</cell><cell>15.79</cell></row><row><cell>Pure Exploitation</cell><cell>0.07</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>54.6</cell><cell>0.01</cell><cell>0.1</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>148.41</cell><cell>148.41</cell></row><row><cell>Pure Exploration</cell><cell>0.18</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.01</cell><cell>1.6</cell><cell>0.33</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>0.58</cell><cell>0.43</cell></row><row><cell>Expected Improvement</cell><cell>0.17</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.01</cell><cell>0.62</cell><cell>0.32</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.63</cell><cell>0.14</cell></row><row><cell>Probability of Improvement</cell><cell>0.15</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.06</cell><cell>0.18</cell><cell>0.32</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.01</cell><cell>0.09</cell></row><row><cell>Probability of Maximum Utility</cell><cell>.012</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.67</cell><cell>0.46</cell><cell>0.13</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>0.36</cell><cell>0.01</cell></row><row><cell>function learning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.29</cell><cell>48</cell><cell>0.5</cell><cell>0.51</cell><cell>-</cell><cell>0.01</cell><cell>0.24</cell><cell>4</cell><cell>0.54</cell><cell>0.47</cell><cell>-</cell><cell>0.02</cell></row><row><cell>Pure Exploitation</cell><cell>0.16</cell><cell>6</cell><cell>1.94</cell><cell>-</cell><cell>-</cell><cell>0.15</cell><cell>0.16</cell><cell>0</cell><cell>1.55</cell><cell>-</cell><cell>-</cell><cell>0.11</cell></row><row><cell>Pure Exploration</cell><cell>0.02</cell><cell>0</cell><cell>0.11</cell><cell>-</cell><cell>-</cell><cell>0.03</cell><cell>0.01</cell><cell>0</cell><cell>0.17</cell><cell>-</cell><cell>-</cell><cell>0.55</cell></row><row><cell>Expected Improvement</cell><cell>0.15</cell><cell>9</cell><cell>0.56</cell><cell>-</cell><cell>-</cell><cell>0.01</cell><cell>0.23</cell><cell>0</cell><cell>0.67</cell><cell>-</cell><cell>-</cell><cell>0.05</cell></row><row><cell>Probability of Improvement</cell><cell>0.05</cell><cell>0</cell><cell>3.43</cell><cell>-</cell><cell>-</cell><cell>0.18</cell><cell>0.02</cell><cell>0</cell><cell>0.87</cell><cell>-</cell><cell>-</cell><cell>0.09</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.00</cell><cell>0</cell><cell>0.69</cell><cell>-</cell><cell>-</cell><cell>7.17</cell><cell>0.02</cell><cell>0</cell><cell>0.49</cell><cell>-</cell><cell>-</cell><cell>0.01</cell></row><row><cell>function learning*</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.23</cell><cell>10</cell><cell>0.96</cell><cell>0.54</cell><cell>-</cell><cell>0.16</cell><cell>0.38</cell><cell>60</cell><cell>0.76</cell><cell>0.49</cell><cell>-</cell><cell>0.09</cell></row><row><cell>Pure Exploitation</cell><cell>0.16</cell><cell>1</cell><cell>7.13</cell><cell>-</cell><cell>-</cell><cell>0.12</cell><cell>0.23</cell><cell>0</cell><cell>14.4</cell><cell>-</cell><cell>-</cell><cell>0.06</cell></row><row><cell>Pure Exploration</cell><cell>0.14</cell><cell>3</cell><cell>0.08</cell><cell>-</cell><cell>-</cell><cell>0.32</cell><cell>0.27</cell><cell>0</cell><cell>0.17</cell><cell>-</cell><cell>-</cell><cell>.19</cell></row><row><cell>Expected Improvement</cell><cell>0.09</cell><cell>1</cell><cell>0.71</cell><cell>-</cell><cell>-</cell><cell>0.11</cell><cell>0.23</cell><cell>1</cell><cell>0.67</cell><cell>-</cell><cell>-</cell><cell>0.05</cell></row><row><cell>Probability of Improvement</cell><cell>0.12</cell><cell>0</cell><cell>7.14</cell><cell>-</cell><cell>-</cell><cell>0.2</cell><cell>0.24</cell><cell>0</cell><cell>0.84</cell><cell>-</cell><cell>-</cell><cell>0.09</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.12</cell><cell>0</cell><cell>0.67</cell><cell>-</cell><cell>-</cell><cell>0.46</cell><cell>0.12</cell><cell>0</cell><cell>0.46</cell><cell>-</cell><cell>-</cell><cell>0.01</cell></row><row><cell>Win-Stay Lose-Sample</cell><cell>0.00</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>3.72</cell><cell>0.05</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.32</cell></row><row><cell>Win-Stay Lose-Sample*</cell><cell>0.05</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.73</cell><cell>0.26</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.22</cell></row><row><cell>Local Search</cell><cell>0.12</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.46</cell><cell>0.28</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.22</cell></row><row><cell>Note:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_34"><head>Table A . 2 :</head><label>A2</label><figDesc>Model results of CMAB with binary features</figDesc><table><row><cell>Model</cell><cell cols="2">Predictive R 2 #best</cell><cell>λ</cell><cell>β</cell><cell>σ</cell><cell>τ</cell></row><row><cell>GP-RBF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.38</cell><cell>3</cell><cell cols="4">7.82 2.13 2.89 1.33</cell></row><row><cell>Expected Improvement</cell><cell>0.45</cell><cell>11</cell><cell>7.46</cell><cell>-</cell><cell cols="2">4.32 3.98</cell></row><row><cell>Probability of Improvement</cell><cell>0.46</cell><cell>15</cell><cell>7.39</cell><cell>-</cell><cell cols="2">3.37 8.43</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.40</cell><cell>3</cell><cell>8.40</cell><cell>-</cell><cell cols="2">3.62 4.21</cell></row><row><cell>GP-Linear</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.13</cell><cell>5</cell><cell>-</cell><cell>1.31</cell><cell>-</cell><cell>4.17</cell></row><row><cell>Expected Improvement</cell><cell>0.14</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1.39</cell></row><row><cell>Probability of Improvement</cell><cell>0.12</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1.67</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.12</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>1.38</cell></row><row><cell>Kalman Filter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.07</cell><cell>0</cell><cell>-</cell><cell cols="3">2.06 3.21 0.13</cell></row><row><cell>Expected Improvement</cell><cell>0.10</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell cols="2">3.60 3.98</cell></row><row><cell>Probability of Improvement</cell><cell>0.09</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell cols="2">9.43 0.72</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.16</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell cols="2">1.17 2.69</cell></row><row><cell>Mean Tracker</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.08</cell><cell>0</cell><cell>-</cell><cell cols="3">2.12 4.44 0.34</cell></row><row><cell>Expected Improvement</cell><cell>0.09</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell cols="2">6.37 8.32</cell></row><row><cell>Probability of Improvement</cell><cell>0.09</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell cols="2">3.45 0.75</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.16</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell cols="2">6.45 2.67</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_35"><head>Table A . 3 :</head><label>A3</label><figDesc>Model results of linear CMAB with con nous features</figDesc><table><row><cell>Model</cell><cell cols="2">Predictive R 2 #best</cell><cell>λ</cell><cell>β</cell><cell>σ</cell><cell>τ</cell></row><row><cell>GP-RBF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.22</cell><cell>16</cell><cell cols="4">8.44 1.84 5.34 2.39</cell></row><row><cell>Expected Improvement</cell><cell>0.19</cell><cell>4</cell><cell>8.43</cell><cell>-</cell><cell cols="2">5.99 1.11</cell></row><row><cell>Probability of Improvement</cell><cell>0.19</cell><cell>4</cell><cell>7.39</cell><cell>-</cell><cell cols="2">5.38 6.07</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.19</cell><cell>1</cell><cell>7.90</cell><cell>-</cell><cell cols="2">4.77 0.54</cell></row><row><cell>GP-Linear</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.18</cell><cell>9</cell><cell>-</cell><cell>0.95</cell><cell>-</cell><cell>3.22</cell></row><row><cell>Expected Improvement</cell><cell>0.08</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.64</cell></row><row><cell>Probability of Improvement</cell><cell>0.07</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.43</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.06</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.74</cell></row><row><cell>Kalman Filter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.09</cell><cell>2</cell><cell>-</cell><cell cols="3">2.72 0.13 0.28</cell></row><row><cell>Expected Improvement</cell><cell>0.08</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell cols="2">3.60 0.61</cell></row><row><cell>Probability of Improvement</cell><cell>0.07</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell cols="2">9.43 3.47</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.15</cell><cell>8</cell><cell>-</cell><cell>-</cell><cell cols="2">1.17 6.04</cell></row><row><cell>Mean Tracker</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.09</cell><cell>0</cell><cell>-</cell><cell cols="3">2.94 5.69 0.25</cell></row><row><cell>Expected Improvement</cell><cell>0.08</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell cols="2">6.37 9.19</cell></row><row><cell>Probability of Improvement</cell><cell>0.08</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell cols="2">6.45 0.66</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.15</cell><cell>6</cell><cell>-</cell><cell>-</cell><cell cols="2">6.69 3.51</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_36"><head>Table A . 4 :</head><label>A4</label><figDesc>Model results of non-linear CMAB with con nous features</figDesc><table><row><cell>Model</cell><cell cols="2">Predictive R 2 #best</cell><cell>λ</cell><cell>β</cell><cell>σ</cell><cell>τ</cell></row><row><cell>GP-RBF</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.23</cell><cell>9</cell><cell cols="4">8.94 1.59 6.09 8.86</cell></row><row><cell>Expected Improvement</cell><cell>0.23</cell><cell>6</cell><cell>7.49</cell><cell>-</cell><cell cols="2">7.17 15.7</cell></row><row><cell>Probability of Improvement</cell><cell>0.24</cell><cell>2</cell><cell>7.73</cell><cell>-</cell><cell cols="2">6.23 5.19</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.23</cell><cell>8</cell><cell>7.09</cell><cell>-</cell><cell cols="2">6.33 5.44</cell></row><row><cell>GP-Linear</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.14</cell><cell>4</cell><cell>-</cell><cell>1.08</cell><cell>-</cell><cell>3.88</cell></row><row><cell>Expected Improvement</cell><cell>0.08</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.93</cell></row><row><cell>Probability of Improvement</cell><cell>0.10</cell><cell>2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.81</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.09</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.93</cell></row><row><cell>Kalman Filter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.14</cell><cell>2</cell><cell>-</cell><cell cols="3">2.19 0.14 0.41</cell></row><row><cell>Expected Improvement</cell><cell>0.12</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell cols="2">3.79 5.97</cell></row><row><cell>Probability of Improvement</cell><cell>0.10</cell><cell>1</cell><cell>-</cell><cell>-</cell><cell cols="2">9.11 1.75</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.17</cell><cell>5</cell><cell>-</cell><cell>-</cell><cell cols="2">0.99 2.89</cell></row><row><cell>Mean Tracker</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Confidence Bound</cell><cell>0.14</cell><cell>1</cell><cell>-</cell><cell cols="3">2.36 6.41 0.41</cell></row><row><cell>Expected Improvement</cell><cell>0.12</cell><cell>3</cell><cell>-</cell><cell>-</cell><cell cols="2">8.43 10.39</cell></row><row><cell>Probability of Improvement</cell><cell>0.10</cell><cell>0</cell><cell>-</cell><cell>-</cell><cell cols="2">6.45 1.97</cell></row><row><cell>Probability of Maximum Utility</cell><cell>0.18</cell><cell>4</cell><cell>-</cell><cell>-</cell><cell cols="2">6.38 2.97</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">*  Carroll mentions that other functions, for example sinusoidal combinations, could also be incorporated into his framework.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">* Note that one could equally differentiate between visually presented points (sometimes called "curve fitting") and sequentially presented outputs of different magnitudes. Function learning really comes in many forms.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">‡ In fact, it can be shown that the radial basis function kernel's spectral density is normally distributed, whereas the density for the Ornstein-Uhlenbeck kernel is a Student's t-distribution, see also.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">† I created a JavaScript library to sample from different Gaussian Process priors at the client's site, available at github.com/ericschulz/gpsmooth.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">† This would also be an interesting approach towards assessing human generalization, for example by assessing the density for self-directed vs. simple function learning tasks.‡ This is essentially a form of extrapolation judgment, but unlike typical extrapolation paradigms that test input-output pairs one at a time, pattern completion asks participants to consider a set of input-output pairs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">‡ ‡ Predictability is closely related to forecastability, insofar as both measures can be characterized in terms of the eigenspectrum<ref type="bibr" target="#b205">(Sollich, 2002</ref>, see also Chapter 4). Here, I focus on predictability since it has a more intuitive interpretation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Contextual Multi-Armed BanditsIn this chapter, I investigate human behavior within a paradigm in which contextual cues are related to an option's expected reward by an underlying function.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">* It is called black box as the underlying function or at least some important characteristics of it are either unknown or expensive to evaluate.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">* Based on<ref type="bibr" target="#b139">Marr &amp; Hildreth (1980)</ref>'s levels of analysis, the computational level (What does it do and why?), the algorithmic level (What is the representation and algorithm?), and the implementation level (What is the physical realization?).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">† Similar savings can also be achieved by re-using previous computations<ref type="bibr" target="#b44">(Dasgupta et al., 2017b</ref>). ‡ Indeed, the chapters of this thesis are not sorted chronologically but rather topically. The function exploration-exploitation experiments were in fact conceptualized prior to defining and assessing the compositional theory of function learning. Thus, developing and assessing a theory of how compositional building blocks are combined when having to optimize unknown functions is a logical next step.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Forecastibility</head><p>The Shannon entropy of a function f can be measured by the uncertainty of its spectrum</p><p>ure A.2, with the generating parameter estimate on the x-axis and the recovered parameter estimate on the y-axis.</p><p>For Experiment 10, the correlation between the generating and the recovered length-scale λ is r = .62, p &lt; .001, the correlation between the generating and the recovered exploration factor β is r = 0.62, p &lt; .001, and the correlation between the generating and the recovered softmax temperature parameter τ is r = 0.91, p &lt; .001. For Experiment 11, the correlation between the generating and the recovered λ is r = 0.91, p &lt; .001, for β the correlation is r = 0.77, p &lt; .001, and for τ the correlation is r = 0.76, p &lt; .001.</p><p>These results show that the correlation between the generating and the recovered parameters is incredibly high for both experiments and for all parameters. Thus, I have found strong evidence to support the claim that the reported parameter estimates of the Gaussian Process-based function learning model <ref type="table">(Table A.1) are recoverable, reliable, and therefore</ref> interpretable. Importantly, I find that estimates for β (exploration bonus) and τ (softmax temperature) are indeed recoverable, providing evidence for the existence of a directed exploration bonus, as a separate phenomena from random, undirected exploration <ref type="bibr" target="#b45">(Daw et al., 2006)</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Judgmental extrapolation and the salience of change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="347" to="372" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Empirical characterization of random forest variable importance measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Kimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analys</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2249" to="2260" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="235" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Monte carlo calculations of the radial distribution functions for a proton electron plasma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Barker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australian Journal of Physics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="134" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deciding advantageously before knowing the advantageous strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bechara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Damasio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tranel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Damasio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="issue">5304</biblScope>
			<biblScope unit="page" from="1293" to="1295" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithms for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kégl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2546" to="2554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Safe controller optimization for quadrotors with Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Berkenkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Schoellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Automation (ICRA), 2016 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="491" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the relationship between task performance and associated verbalizable knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Broadbent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psycholo</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="231" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recognition-by-components: A theory of human image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Heuristics and biases in judgmental forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bolger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harvey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>John Wiley &amp; Son</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Win-stay, lose-sample: A simple sequential algorithm for approximating bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psycholo</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bayesian optimization explains human active search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonmonotonic extrapolation in function learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Heit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Overview of random forest methodology and practical guidance with emphasis on computational biology and bioinformatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-L</forename><surname>Boulesteix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Janitza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kruppa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">R</forename><surname>König</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="493" to="507" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Contextual control of the extinction of conditioned fear: tests for the associative value of the context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Bouton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Animal Behavior Process</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">248</biblScope>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A review of visual memory capacity: Beyond individual items and toward structured representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Konkle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4" to="4" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A probabilistic model of visual working memory: Incorporating higher order regularities into working memory capacity estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Formalizing neurath&apos;s ship: Approximate algorithms for online causal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Bramley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lagnado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">301</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Subjects&apos; ability to use functional rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="259" to="260" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning complex rules in probabilistic inference tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Psycholo</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="309" to="312" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Effects of function form and cue validity on the subjects&apos; hypotheses in probabilistic inference tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kuylenstierna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-E</forename><surname>Liljergren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Performance</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="338" to="354" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brochu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Cora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1012.2599</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bayesian strategy assessment in multi-attribute decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="213" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Toward a theory of instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bruner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<publisher>Harvard University Press</publisher>
			<biblScope unit="volume">59</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A study of thinking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bruner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Goodnow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Austin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Editions</title>
		<imprint>
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Coding theory of visual pattern completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Buffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Leeuwenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Restle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">241</biblScope>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning functional relations based on experience with input-output pairs by humans and artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Byun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Delosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Concepts and Categori</title>
		<editor>K. Lamberts &amp; D. Shanks</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="405" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Interaction between prior knowledge and type of nonlinear relationship on function learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Byun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Functional learning: The learning of continuous functional mappings relating stimulus and response continua</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ETS Research Report Seri</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1963</biblScope>
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Toward a new paradigm for the study of multiattribute choice behavior: Spatial and discrete modeling of pairwise preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>De Soete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">342</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Perception in chess</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psycholo</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="81" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The probabilistic mind: Prospects for Bayesian cognitive science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oaksford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>OUP</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Probabilistic models of cognition: Conceptual foundations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive scienc</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="287" to="291" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Simplicity: A unifying principle in cognitive science?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vitányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trends in Cognitive Scienc</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning to learn without gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Syntactic structures. the hague: Mouton.. 1965. aspects of the theory of syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chomsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lectur on Government and Binding</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="52" />
			<date type="published" when="1957" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Organizing conceptual knowledge in humans with a gridlike code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Constantinescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Behrens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">352</biblScope>
			<biblScope unit="issue">6292</biblScope>
			<biblScope unit="page" from="1464" to="1468" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Modelling frontal discontinuities in wind fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cornford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T</forename><surname>Nabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Nonparametric Statistics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="43" to="58" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Gaussian process regression for trajectory analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kachergis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shiffrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Cognitive Science Society</title>
		<meeting>the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">State of the field: Measuring information and confirmation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Crupi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tentori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studi in History and Philosophy of Science Part A</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Damianou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="207" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Where do hypotheses come from? Cognitive Psycholo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Amortized hypothesis generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 39th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Cortical substrates for exploratory decisions in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="issue">7095</biblScope>
			<biblScope unit="page">876</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improving generalization for temporal difference learning: The successor representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="613" to="624" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Exploration bonuses and dual control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="5" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Bootstrap learning via modular concept discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dechter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malmaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1302" to="1309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Extrapolation: The sine qua non for abstraction in function learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Delosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">968</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Spinal cord injury therapy through active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Desautels</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Structure discovery in nonparametric regression through compositional kernel search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Ueber das gedächtnis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ebbinghaus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Intuitive time-series extrapolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">R</forename><surname>Eggleton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Accounting Research</title>
		<imprint>
			<biblScope unit="page" from="68" to="102" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Sampling for Bayesian Program Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1297" to="1305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">The character of physical law</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feynman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wilczek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Contour integration by the human visual system: Evidence for a local &quot;association field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Hess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="193" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Language, thought and compositionality. Royal Institute of Philosophy Supplements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fodor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="227" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">The language of thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fodor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>Harvard University Press</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Connectionism and cognitive architecture: A critical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fodor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">W</forename><surname>Pylyshyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="71" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Interactive interpolation and approximation by bézier polynomials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Forrest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="79" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The free-energy principle: A unified brain theory?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="138" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A unifying probabilistic view of associative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biolo</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1004567</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Context, learning, and extinction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">197</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Reinforcement learning and episodic memory in humans and animals: An integrative framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psycholo</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="101" to="128" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Computational rationality: A converging paradigm for intelligence in brains, minds, and machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">6245</biblScope>
			<biblScope unit="page" from="273" to="278" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Structured representations of utility in combinatorial domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malmaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">67</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The successor representation and temporal context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Sederberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1553" to="1568" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Learning latent structure: Carving nature at its joints. Current Opinion in Neurobiolo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="251" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Novelty and inductive generalization in human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="391" to="415" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Discovering latent causes in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Scienc</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="43" to="50" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Probabilistic machine learning and artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="452" to="459" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">From tools to theories: A heuristic of discovery in cognitive psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">254</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">How do people solve the &quot;weather prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">task? individual variability in strategies for probabilistic category learning. Learning &amp; Memory</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="408" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Expert memory: A comparison of four theories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="152" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Forecastable component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Goerg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML-13)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML-13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="64" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">GLASSES: Relieving the myopia of Bayesian optimisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the 19th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="790" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A rational analysis of rule-based concept learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="154" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Compositionality in rational analysis: Grammar-based induction for concept learning. The probabilistic mind: Prospects for Bayesian cognitive science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feldman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Improving judgmental time series forecasting: A review of the guidance provided by research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="161" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Active learning for level set estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gotovos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Casati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1344" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Gaussian processes and limiting linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Gramacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analys</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="136" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Language evolution by iterated learning with bayesian agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Kalish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="441" to="480" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Modeling human function learning with Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Kalish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="553" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Exploiting compositionality to explore a large space of model structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Scalable and efficient Bayes-adaptive reinforcement learning based on monte-carlo tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="841" to="883" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Self-directed learning: A cognitive and computational perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Markant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectiv on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="464" to="481" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Discriminability and stimulus generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Guttman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">I</forename><surname>Kalish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Graphs versus tables: Effects of data presentation format on judgemental forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bolger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="137" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Effects of data noise on statistical judgement</title>
	</analytic>
	<monogr>
		<title level="j">Thinking &amp; Reasoning</title>
		<editor>Harvey Teresa Ewart Robert West, N.</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="132" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Probabilistic solutions to differential equations and their application to Riemannian statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hennig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hauberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="347" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Entropy search for information-efficient global optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hennig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1809" to="1837" />
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Fast sparse Gaussian process methods: The informative vector machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Predictive entropy search for efficient global optimization of black-box functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="918" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Ridge regression: Biased estimation for nonorthogonal problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Hoerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Kennard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="67" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">The pragmatics of analogical transfer. Psycholo of learning and motivation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="59" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">The legacy of Guttman and Kalish (1956): 25 years of research on stimulus generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Honig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Urcuioli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Experimental Analys of Behavior</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="405" to="445" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Nonlinear causal discovery with additive noise models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">The conflicting psychologies of learning-a way out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">491</biblScope>
			<date type="published" when="1935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Interplay of approximate planning strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Huys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Faulkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Eshel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Seifritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Roiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Scienc</title>
		<meeting>the National Academy of Scienc</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="3098" to="3103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Automatic construction of nonparametric relational regression models for multiple time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Large-scale unusual time series detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Laptev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining Workshop (ICDMW), 2015 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1616" to="1619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A tutorial on kernel methods for categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jäkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psycholo</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="343" to="358" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">An explicit representation of a stationary Gaussian process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siegert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="page" from="438" to="442" />
			<date type="published" when="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Learning and extrapolating a periodic function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Kalish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">886</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Iterated learning: Intergenerational knowledge transmission reveals inductive biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Kalish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="288" to="294" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Population of linear experts: Knowledge partitioning and function learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Kalish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1072</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">In search of memory: The emergence of a new science of mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Kandel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>WW Norton &amp; Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Organization in vision: Essays on Gestalt perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kanizsa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Praeger Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Subjective contours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kanizsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">234</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="48" to="52" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Exploring the conceptual universe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">685</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Structured statistical models of inductive reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Cultural differences in the misperception of exponential growth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Keren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="289" to="293" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Klenske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hennig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03591</idno>
		<title level="m">Dual control for approximate Bayesian reinforcement learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Function learning: Induction of continuous stimulusresponse relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">811</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Diffusion kernels on graphs and other discrete input spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="315" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Optimal nonmyopic value of information in graphical models: Efficient algorithms and theoretical limits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Optimal foraging, predation risk and territory defence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Krebs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ardea</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="83" to="90" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Bayesian approaches to associative learning: From passive to active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="210" to="226" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">A model of probabilistic category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1083" to="1119" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Kushner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Basic Engineering</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="106" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Why people underestimate y when extrapolating in linear functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Kwantes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1019</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">One-shot learning by inverting a compositional causal process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2526" to="2534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Scienc</title>
		<imprint>
			<biblScope unit="page" from="1" to="101" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Neural computations underlying arbitration between model-based and model-free learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="687" to="699" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">Efficient coding of visual scenes by grouping and segmentation. Bayesian brain: Probabilistic approach to neural coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="141" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">Effects of feedback and complexity on repeated decisions from description. Organizational Behavior and Human Decision Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lejarraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="286" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">Learning physical intuition of block towers by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01312</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Ensemble clustering in visual working memory biases location memories and reduces the weber noise of relative positions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Lew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="10" to="10" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Simplified learning in complex situations: Knowledge partitioning in function learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kalish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ngang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : General</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">163</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">On a measure of the information provided by an experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Lindley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="page" from="986" to="1005" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title level="m" type="main">Automatic construction and natural-language description of nonparametric regression models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.4304</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">A rational model of function learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Kalish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1193</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Stimulus representation and the timing of reward-prediction errors in models of the dopamine system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Kehoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3034" to="3054" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Exploration and exploitation in organizational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>March</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="87" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Theory of edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society of London: Biological Scienc</title>
		<imprint>
			<biblScope unit="volume">207</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">What&apos;s magic about magic numbers? Chunking and data compression in short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="346" to="362" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Optimistic Bayesian sampling in contextual-bandit problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Korda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Leslie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2069" to="2106" />
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Predicting transfer performance: A comparison of competing function learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dimperio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Griego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">173</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Conditional logit analysis of qualitative choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcfadden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Frontiers in Econometrics</title>
		<editor>P. Zarembka</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1973" />
			<biblScope unit="page" from="105" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Information search with situation-specific reward functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="119" to="148" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">When less is more: Counterfactual thinking and satisfaction among Olympic medalists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">H</forename><surname>Medvec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Madey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gilovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psycholo</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">603</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Minimum regret search for single-and multi-task optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01064</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">The magical number seven, plus or minus two: Some limits on our capacity for processing information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="81" to="97" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">On Bayesian methods for seeking the extremum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Močkus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimization Techniqu IFIP Technical Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1975" />
			<biblScope unit="page" from="400" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">The application of Bayesian methods for seeking the extremum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mockus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tiesis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zilinskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Towards global optimization</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="129" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">The successor representation in human reinforcement learning. bioRxiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Russek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Cheong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Tsclust: Time series clustering utilities. R package version</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Montero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vilar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title level="m" type="main">DEoptim: An R package for global optimization by differential evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Mullen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ardia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Windover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Priors for infinite networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian Learning for Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="29" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Comparison of predictions and estimates in a probability learning situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Neimark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shuford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">294</biblScope>
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Finding useful questions: On Bayesian diagnosticity, probability, impact, and information gain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">112</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Attention, similarity, and the identification-categorization relationship</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : General</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Rule-plus-exception model of classification learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Palmeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Mckinley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">53</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">General bounds on Bayes errors for regression with Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Opper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vivarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">A probabilistic clustering theory of the organization of visual short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Orhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">297</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Controlling uncertainty: A review of human behavior in complex dynamic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Osman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Active learning as a means to distinguish among prominent decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Parpart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 37th Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1829" to="1834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<title level="m" type="main">Familiarity and visual change detection. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pashler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="369" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Self-report measures of intelligence: Are they useful as proxy iq tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Paulhus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Lysy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Yik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="525" to="554" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">P</forename><surname>Pavlov</surname></persName>
		</author>
		<title level="m">Lectures on conditioned reflexes. vol. ii. conditioned reflexes and psychiatry</title>
		<imprint>
			<date type="published" when="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<title level="m" type="main">Wavelet methods for time seri analys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Percival</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Walden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<title level="m" type="main">The implementation of functional programming languag (prentice-hall international seri in computer science)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyton</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Prentice-Hall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">The logical primitives of thought: Empirical foundations for compositional cognitive models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Piantadosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">392</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Warm starting Bayesian optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Poloczek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">I</forename><surname>Frazier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Simulation Conference (WSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajeswar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dutil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10929</idno>
		<title level="m">Adversarial generation of natural language</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b171">
	<monogr>
		<title level="m" type="main">Gaussian process for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press Cambridge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">An introduction to Gaussian processes for the Kalman filter expert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reece</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Fusion (FUSION), 2010 13th Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<monogr>
		<title level="m" type="main">Average-case analys of numerical problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ritter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Navigating the protein fitness landscape with Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Scienc</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="201" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">How to measure working memory capacity in the change detection paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cowan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="324" to="330" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">The sampling brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Scienc</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="492" to="493" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Uncovering mental representations with Markov chain Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psycholo</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="106" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<monogr>
		<title level="m" type="main">Meaning and compositionality statistical induction of categori and constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Schmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Artificial intelligence: Learning to see and act</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="486" to="487" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Better safe than sorry: Risky function exploitation through safe optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Huys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Eighth Annual Conference of the Cognitive Science Society</title>
		<meeting>the Thirty-Eighth Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1140" to="1145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Strategic exploration in human adaptive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Klenske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bramley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 39th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Exploration-exploitation in a contextual multi-armed bandit task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Cognitive Modeling</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="118" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Learning and decisions in contextual multi-armed bandit tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Seventh Annual Conference of the Cognitive Science Society</title>
		<meeting>the Thirty-Seventh Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2122" to="2127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Putting bandits into context: How function learning supports decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning, Memory, and Cognition</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Quantifying mismatch in Bayesian optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Bayesian Optimization: Black-box Optimization and beyond</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">A tutorial on Gaussian process regression with a focus on exploration-exploitation scenarios. bioRxiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">95190</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">Simple trees in complex forests: Growing take the best by approximate bayesian computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 38th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Probing the compositionality of intuitive functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3729" to="3737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<title level="m">Compositional inductive biases in function learning. bioRxiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Reshef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gershman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Assessing the perceived predictability of functions</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 37th Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<biblScope unit="page" from="2116" to="2121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Gaussian process regression: Active data selection and test point rejection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE-INNS-ENNS International Joint Conference on</title>
		<meeting>the IEEE-INNS-ENNS International Joint Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="241" to="246" />
		</imprint>
	</monogr>
	<note>Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Taking the human out of the loop: A review of bayesian optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="148" to="175" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Stimulus and response generalization: A stochastic model relating generalization to distance in psychological space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="345" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Stimulus and response generalization: Tests of a model relating generalization to distance in psychological space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">509</biblScope>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Psychological relations and psychophysical scales: On the status of &quot;direct&quot; psychophysical measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psycholo</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="57" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Toward a universal law of generalization for psychological science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="issue">4820</biblScope>
			<biblScope unit="page" from="1317" to="1323" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Learning and memorization of classifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>Hovland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological monographs: General and applied</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">Rationality as process and as product of thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Economic Review</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<title level="m" type="main">How google plans to solve artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Simonite</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<title level="m" type="main">The operational analysis of psychological terms. Psychological Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Skinner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1945" />
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">270</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">Stochastic dynamic models of response time and accuracy: A foundational primer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psycholo</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="408" to="463" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2951" to="2959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Gaussian process regression with mismatched models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sollich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="519" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">Can Gaussian process regression be made robust against model mismatch?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sollich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture not in computer science</title>
		<imprint>
			<biblScope unit="volume">3635</biblScope>
			<date type="published" when="0199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">Learning curves for Gaussian process regression: approximations and bounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sollich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1393" to="1428" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Evidence integration in model-based tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Scienc</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">37</biblScope>
			<biblScope unit="page" from="11708" to="11713" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Learning strategies in amnesia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Channon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience &amp; Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="292" to="310" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Uncertainty and exploration in a restless bandit task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topics in Cognitive Science</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="351" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<monogr>
		<title level="m" type="main">Through the looking glass: A dynamic lens model approach to multiple cue learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<editor>N. Chater &amp; M. Oaksford</editor>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="409" to="429" />
		</imprint>
	</monogr>
	<note>The probabilistic mind</note>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Gaussian process optimization in the bandit setting: No regret and experimental design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning</title>
		<meeting>the 27th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1015" to="1022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Information-theoretic regret bounds for gaussian process optimization in the bandit setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3250" to="3265" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">High-speed scanning in human memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sternberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">3736</biblScope>
			<biblScope unit="page" from="652" to="654" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">A Bayesian analysis of human decision-making on bandit problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psycholo</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="168" to="179" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Human behavior in contextual multi-armed bandit problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Analytis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 37th Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2290" to="2295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<monogr>
		<title level="m" type="main">An analysis of the delta rule and the learning of statistical associations. Parallel distributed processing: Explorations in the microstructure of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">O</forename><surname>Stone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="444" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Generalization in reinforcement learning: Successful examples using sparse coarse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1038" to="1044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press Cambridge</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Generalization, similarity, and Bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Scienc</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="640" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">How to grow a mind: Statistics, structure, and abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="issue">6022</biblScope>
			<biblScope unit="page" from="1279" to="1285" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Practical issues in temporal difference learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="257" to="277" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Cognitive structures in comprehension and memory of narrative discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Thorndyke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psycholo</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="110" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">An historical note on the james-lange theory of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Titchener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Journal of Psycholo</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="427" to="447" />
			<date type="published" when="1914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">Cognitive maps in rats and men</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Tolman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">189</biblScope>
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Human learning in atari</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Tsividis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pouncy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The AAAI 2017 Spring Symposium on Science of Intelligence: Computational Principl of Natural and Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Rates of contraction of posterior distributions based on Gaussian process priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Van Der Vaart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Van Zanten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="page" from="1435" to="1463" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">The mean square successive difference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Von Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bellinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="162" />
			<date type="published" when="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Deisenroth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Amor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Probabilistic modeling of human movements for intention inference</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Robotics: Science and Systems</title>
		<meeting>Robotics: Science and Systems<address><addrLine>VIII</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<monogr>
		<title level="m" type="main">Learning from delayed rewards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J C H</forename><surname>Watkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<pubPlace>King&apos;s College, Cambridge</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b232">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Watson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958" />
			<publisher>Behaviorism. Transaction Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<monogr>
		<title level="m" type="main">Incorporating conflicting descriptions into decisions from experience. Organizational Behavior and Human Decision Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Weiss-Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harvey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="55" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">Gaussian processes for regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Processing Systems</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="514" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<monogr>
		<title level="m" type="main">Gaussian processes for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>the MIT Press</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">Upper and lower bounds on the learning curve for Gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vivarelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="77" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">Gaussian process kernels for pattern discovery and extrapolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML-13)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML-13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1067" to="1075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">The human kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanc in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2854" to="2862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">Humans use directed and random exploration to solve the explore-exploit dilemma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psycholo : General</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2074</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">Mapping the unknown: The spatially correlated multi-armed bandit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 39th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<monogr>
		<title level="m" type="main">Exploration and generalization in vast spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meder</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted</note>
</biblStruct>

<biblStruct xml:id="b242">
	<monogr>
		<title level="m" type="main">Grundriss der Psychologie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Wundt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1896" />
			<publisher>W. Engelmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<monogr>
		<title level="m" type="main">Statistical efficiency of compositional nonparametric prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Honorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01896</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">An efficient method of estimating seemingly unrelated regressions and tests for aggregation bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zellner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical Association</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">298</biblScope>
			<biblScope unit="page" from="348" to="368" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<analytic>
		<title level="a" type="main">Mutual interference between statistical summary perception and statistical learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mckendrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1212" to="1219" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<analytic>
		<title level="a" type="main">Statistical regularities reduce perceived numerosity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Q</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="217" to="222" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
