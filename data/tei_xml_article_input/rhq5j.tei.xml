<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Revealing the impact of expertise on human planning with a two-player board game</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bas</forename><surname>Van Opheusden</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Neural Science and Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianni</forename><surname>Galbiati</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Neural Science and Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ionatan</forename><surname>Kuperwajs</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Neural Science and Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahy</forename><surname>Bnaya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Neural Science and Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Neural Science and Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><forename type="middle">Ji</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Neural Science and Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Revealing the impact of expertise on human planning with a two-player board game</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In recent years, artificial intelligence has made great progress in improving machine performance in tasks that require planning many steps ahead. By comparison, cognitive science has lagged behind in understanding human planning in complex tasks. One question of long-standing interest in this domain is whether skilled decision-makers plan further into the future than novices. Traditionally, the study of expertise in planning has focused on board games like chess, but the complexity of these games poses a barrier to detailed behavioral modeling. Conversely, common planning tasks in cognitive science are often lower-complexity and impose a ceiling for the depth to which any player can plan. Here, we investigate expertise in a complex board game that offers ample opportunity for skilled players to plan deeply. Despite this complexity, we show that human behavior can be captured using a computational cognitive model based on heuristic search. To validate this model, we predict human choices, response times, eye movements and perform a Turing test. Using the model, we find robust evidence for increased planning depth with expertise in both laboratory and large-scale mobile data. Our results highlight the promise of investigating human planning in complex tasks with precise behavioral modeling.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Introduction. Real-world decision-making often involves considering sequences of actions with multiple alternatives at each stage. Making such decisions requires people to mentally simulate the consequences of candidate actions multiple steps into the future using an internal model of the environment. This process is known as planning, and examples of ecologically relevant planning tasks are navigation, preparing a meal, career decisions or strategy games. Given the importance of planning to human behavior, a natural hypothesis is that skilled decisionmakers are more successful because they plan further into the future. Following seminal work by de Groot <ref type="bibr" target="#b0">[1]</ref> and Simon &amp; Chase <ref type="bibr" target="#b1">[2]</ref>, a growing body of literature has investigated the nature of expertise in planning by studying how expert chess players differ from less skilled counterparts <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>. This literature has explained the superior performance of experts as better pattern recognition <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref> and/or deeper search <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>However, developing computational cognitive models that accurately predict individual players' chess moves has proven difficult <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, and instead studies tend to rely on clever experimental manipulations <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref> or verbal report analysis <ref type="bibr" target="#b16">[17]</ref>.</p><p>In contrast to the chess expertise literature, studies of planning in cognitive and neural science have often employed simpler tasks so that behavior and neural activity can be precisely modeled. These studies provide ample evidence that humans and animals engage in forward planning at decision time, and suggest candidates for the neural substrates supporting that behavior <ref type="bibr" target="#b17">[18]</ref>.</p><p>In humans, modeling people's choices in the classic two-step decision-making task <ref type="bibr" target="#b18">[19]</ref> reveals a goal-directed planning component to their decision-making. In a more complex goal-directed decision-making task, Huys et al. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> found that people plan along multiple branches in a decision tree, but eliminate unpromising branches by pruning. Snider et al. <ref type="bibr" target="#b21">[22]</ref> studied planning in a fast-paced, dynamic environment and found human behavior consistent with planning 3 to 4 steps into the future. Kolling et al. <ref type="bibr" target="#b22">[23]</ref> demonstrated that people use prospective information to guide current choices, and located the representation of prospective information to cingulate and prefrontal cortices. Additionally, multi-step iterated reasoning has been studied in behavioral economics and game theory, resulting in concepts such as level-k reasoning <ref type="bibr" target="#b23">[24]</ref> and the cognitive hierarchy <ref type="bibr" target="#b24">[25]</ref>.</p><p>In animals, signatures of prospective activity along possible trajectories an animal might take have been found in sequences of hippocampal place cell activity <ref type="bibr" target="#b25">[26]</ref>, particularly when an animal stops at a choice point <ref type="bibr" target="#b26">[27]</ref>. Hippocampal neural activity has been associated with both planning at decision time and planning in the background <ref type="bibr" target="#b27">[28]</ref>. Additionally, evidence for planning in animals has been found in adaptations of the two-step task for rodents <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>These human and animal studies rely on planning tasks of limited complexity, which impose a ceiling for the depth of planning and makes them less suitable to study the nature of expertise.</p><p>The perfect task for studying expertise in planning needs to be complex enough that strong play requires thinking multiple moves ahead, but tractable for computational modeling. Additionally, to encourage learning, it should be novel, have simple rules, and be engaging. Here, we introduce a task that satisfies these competing desiderata, develop a computational cognitive model for human decision-making, validate it using choice, response time and eye movement data, and finally use the model to investigate the nature of expertise in planning.</p><p>Task. Our task is a generalization of tic-tac-toe, in which two players alternate placing tokens on a 4-by-9 board ( <ref type="figure" target="#fig_0">Fig 1A)</ref>; black moves first. The objective is to get four tokens in a row horizontally, vertically, or diagonally. The game, which we call 4-in-a-row, can be played online at basvanopheusden.github.com. With approximately 1.2 • 10 16 non-terminal states (section S2), this game has a state space complexity <ref type="bibr" target="#b31">[32]</ref> that far exceeds tasks commonly used in cognitive science <ref type="bibr" target="#b32">[33]</ref>.</p><p>Model. We adapt our model of human planning from the artificial intelligence literature, in particular heuristic search <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. The core of a heuristic search algorithm is a heuristic function, which maps a given board state to a value estimate, often as a weighted linear combination of board features. For example, a common chess heuristic is to count pieces for both players, with different point values for different pieces (pawns, knights, rooks, etc). Similarly, our heuristic function counts how often particular features ( <ref type="figure" target="#fig_0">Fig 1B)</ref> appear on the board. It weighs those counts by feature weights, resulting in a quick to compute but rough value estimate.</p><p>To refine the value estimate, the model explores a decision tree of possible continuations <ref type="figure" target="#fig_0">(Fig 1C,D)</ref>. We base our model on best-first search <ref type="bibr" target="#b35">[36]</ref>; this algorithm iteratively expands nodes Two players, black and white, alternate placing pieces on the board, and the first player to achieve 4-in-a-row wins the game. In this position, black is about to win by moving on the 3rd square in the bottom row (open circle, mouse cursor). B. Features used in the heuristic function. Features with identical colors are constrained to have identical weights. The model also includes a central tendency feature and a 4-in-a-row feature. C. Illustration of the heuristic search algorithm. In the root position (left), black is to move. After expanding the root node with two candidate moves for black and evaluating the resulting positions using V (s), the algorithm selects the highest-value node (V = 2.3) on the second iteration and expands it with three candidate moves for white. The algorithm evaluates the resulting positions, and now backpropagates the lowest value (V = 0.3), since white is the opponent. That value will be compared against its alternatives in each intermediate node of the tree, to decide in which direction to expand the tree in the algorithm's next iteration. D. Decision tree built by the model with fitted parameters on an example board. The red nodes indicate the principal variation; the sequence of highest-value moves for both players. Note that different branches are evaluated to different depths.</p><p>on the principal variation, the sequence of actions that leads to the best outcome for both players given the current decision tree. Best-first search is particularly appealing as a human planning algorithm, since it effectively allocates computational resources to relevant branches of the decision tree, and such computational efficiency is a hallmark of human intelligence <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40</ref>].</p><p>Our other model choices are derived from cognitive science. Inspired by research from Huys et al. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, the model prunes branches in the decision tree with low heuristic value.</p><p>This improves the efficiency of search, but the model may fail to spot winning sequences if the starting move is low-value. Additionally, to allow the model to capture variability in human play and make human-like mistakes, we add Gaussian noise to the heuristic function and include feature dropout. For each move the model makes, it randomly omits some instances of features from the heuristic function before it performs search. We interpret these feature omissions cognitively as lapses of selective attention <ref type="bibr" target="#b40">[41]</ref>.</p><p>Model validation. We conducted several experiments and analyses to validate our com- In sections S4-6, we show that the model's parameters can be reliably estimated with custom fitting methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>, and that it predicts multiple summary statistics. We validate our model specification by comparing against 22 alternative models, including ones that lesion model components. We find that a feature-based value function, tree search and a mechanism for attentional oversights are essential to predicting human choices (section S7). We select the main model as a parsimonious representative of that model class.</p><p>Next, we performed a "generalization" experiment in which 40 participants perform three tasks: playing against computer opponents, a two-alternative forced-choice (2AFC) between moves in a given position and a board evaluation task. We selected positions to make the decisions challenging, both to our participants and for the model to predict. For each player, we  The dashed line represents the accuracy of a "chance" model, which assumes that people move on a randomly selected unoccupied square. C. Model accuracy for 2AFC decisions in the generalization experiment. For each participant, we estimated model parameters from that participant's moves in games against computer opponents. D. Same as C, for the correlation between predicted and observed responses on the board evaluation task. E. Predicted and observed response times across all participants in the human-vs-human data. We exclude any positions with fewer than 6 or more than 30 pieces on the board. F. Correlation between predicted and observed response times for each participant, ranked from worst to best. G. Trajectory of eye movements on one example trial. The black lines represent saccades, the yellow circles fixations with duration proportional to the area of the circle. H. Estimated distribution of overt attention across unoccupied squares, obtained by convolving the eye trajectory with a Gaussian filter. I. Distribution of squares visited by the search algorithm, with model parameters estimated from the participant's choices.</p><p>estimate model parameters from their choices during human-vs-computer games, and predict their 2AFC and evaluation decisions. For both tasks, the model predicts people's choices above chance (percent correct 2AFC: p correct = 58.6 ± 1.0%, t(39) = 8.3, p &lt; 0.001, <ref type="figure" target="#fig_4">Fig 2C,</ref> correlation predicted-observed evaluations: ρ = 0.377 ± 0.039, t(39) = 9.6, p &lt; 0.001, <ref type="figure" target="#fig_4">Fig 2D)</ref>.</p><p>These results suggest that the computational cognitive model can generalize between different choice tasks in the 4-in-a-row domain. In section S8, we show that the model's accuracy compares favorably to that of an oracle model (which makes objectively correct moves with random tie-breaking), suggesting that the model captures individual participants' subjective preferences.</p><p>Finally, we conducted a "Turing test" experiment <ref type="bibr" target="#b43">[44]</ref>, in which 30 observers, familiar with the game, decided whether sequences of moves, 9.38 on average, were generated by the model or by human players. Human observers were able to discriminate with only 55.4% accuracy, which suggests that the main model makes human-like decisions.</p><p>We tested the model's ability to predict process data by analyzing response times and eye movements. To predict a participant's response time on a single move, we amend the best-first search algorithm with an early-termination rule (section S10), which terminates search when the model's decision is unlikely to change with more iterations. With this modification, we can fit the model parameters on choice data, and predict response times as the mean size of the decision tree built by the model on each trial. To analyze eye movements, we conducted an experiment in which 10 participants played against computer opponents while we tracked their eye movements with an infra-red videobased eye tracker (section S11). <ref type="figure" target="#fig_4">Fig 2G</ref> shows one participant's fixation trajectory in an example board position. For each move made by each participant, we estimate the distribution of squares they overtly attend to by convolving their fixation trajectory with a Gaussian filter, truncating to unoccupied squares and averaging in time. We then show that this distribution is similar to the distribution of squares visited by the cognitive model during its search process (mean correlation across participants: ρ = 0.535 ± 0.024, t(9) = 21, p &lt; 0.001, see <ref type="figure" target="#fig_4">Fig 2H,I</ref>). In section S11, we</p><p>show that this correlation is driven by branches in the decision tree occasionally reaching up to</p><formula xml:id="formula_0">7 moves deep.</formula><p>The ability of the model to predict both response times and eye movements on individual trials suggests that people plan their moves by building decision trees, using an algorithm similar to that of our cognitive model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Expertise in planning.</head><p>The cognitive model allows us to investigate how expert players differ from novices. To do so, we performed a learning experiment in which 30 participants play against computer opponents for 5 sessions, each spaced no more than 2 days apart. We measure participants' task performance using Elo ratings <ref type="bibr" target="#b44">[45]</ref>, with a common baseline across all experimental data (section S2.1).</p><p>In <ref type="figure" target="#fig_6">Fig 3A,</ref> we show that participants' playing strength increases during the 5 sessions of the learning experiment (linear regression: β = 21 ± 4.6, p &lt; 0.001). To investigate which aspects of people's decision-making process underlie this performance increase, we convert the set of parameters inferred for each participant in each session to 3 metrics: planning depth, feature drop rate and heuristic quality (section S2.7). The planning depth is defined as the length of the principal variation in the tree, and roughly corresponds to the number of steps one thinks ahead. The feature drop rate is defined as the attentional lapse probability, a model parameter.</p><p>Finally, the heuristic quality is defined as the correlation between heuristic and objective value, and therefore measures the "correctness" of the feature weights. Thus, these metrics map to different hypotheses on the nature of expertise (see discussion). In section S4, we show that these metrics, and planning depth in particular, can be reliably inferred from choice data, and together they explain 56.7% of the variance in playing strength (section S12). does not increase, and even decreases slightly (β = −0.0067 ± 0.0020, p = 0.0012). In section S13, we show that individual differences in playing strength are also correlated with planning depth and feature drop rate, but not heuristic quality. Finally, in section S12, we break down the overall gain of 90 ± 26 Elo points between sessions 1 and 5 as a gain of 36 ± 11 points due to increased planning, a gain of 46 ± 12 due to attention, and a loss of 6.6 ± 3.5 points due to heuristic quality. These results suggest that stronger players plan deeper and have fewer lapses of attention. We find no evidence for improvements in feature weights.</p><p>In section S14, we show that participants' response time decreases across sessions, verifying that the planning depth increase is not a result of slower play. Another potential concern is that the estimates of planning depth, feature drop rate and heuristic quality are dependent on our model specification, and human planning strategies may deviate from the model. Specifically, one may worry that people use features not present in our heuristic function, and that the model confuses increases in the weights of those feature across sessions with increased planning. In section S17, we investigate this possibility. First, we note that planning depth and feature weights are not confusable, at least for features in our model (section S4). Additionally, we show that the main result in <ref type="figure" target="#fig_6">Fig 3 is</ref> robust across all alternative model specifications. Although the existence of additional features in people's heuristic functions is impossible to rule out completely, we have no evidence suggesting that adding features to the model will change the main result of increased planning and improved attention with expertise.</p><p>Time pressure. To experimentally validate the planning depth metric, we conducted a time pressure experiment in which 30 participants played against computer opponents, with a time limit of 5, 10 or 20 seconds per move, randomly sampled for each game. In S15, we show that this manipulation is effective at changing participants' response time. We predict that, if planning depth is a rough measure of the amount of computations a participant performs while making a move, it should scale with time used for that move <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b46">47]</ref>. <ref type="figure" target="#fig_6">Fig 3F</ref> shows that planning depth is overall lower than the learning experiment, and that planning depth indeed increases with longer time limits (β = 0.042 ± 0.018, p = 0.019).</p><p>Despite this increase, however, we find no improvement in participant's playing strength (β = −2.0 ± 1.6, p = 0.21, <ref type="figure" target="#fig_6">Fig 3E)</ref>. The model suggests a potential explanation for the lack of performance: at the most relaxed time limit, people overlook features more often (β = 0.0027±0.0010, p = 0.009, <ref type="figure" target="#fig_6">Fig 3G)</ref>, and the dropped features cancel out the benefit of increased search. Finally, in this experiment the heuristic quality does not change with time pressure (β = 0.00086 ± 0.00056, p = 0.13, <ref type="figure" target="#fig_6">Fig 3H)</ref>.</p><p>Generalization to large-scale mobile data. In all these experiments, we investigated expertise in participants recruited to perform a psychology experiment in a laboratory context. It is not clear whether our expertise results will generalize to a more natural context for acquiring expertise. To address this issue, we collaborated with Peak, a mobile app company (https://www.peak.net), to collect a large-scale data set of users playing a visually enriched version (section S1.8) of 4-in-a-row at their leisure in their daily environment.  We analyze data from 1,000 randomly selected users who played at least 100 games; this approximately matches the total experience of participants in our learning experiment. For each user, we grouped their experience into 5 blocks of 20 games, and estimated model parameters for each block (section S1.8). As before, playing strength (β = 1.13 ± 0.04, p &lt; 0.001, <ref type="figure" target="#fig_8">Fig 4A)</ref> and the depth of planning (β = 0.0108 ± 0.0010, p &lt; 0.001, <ref type="figure" target="#fig_8">Fig 4B)</ref> increase with experience, while the feature drop rate decreases (β = −2.58 • 10 −4 ± 4.7 • 10 −5 , p &lt; 0.001, <ref type="figure" target="#fig_8">Fig 4C)</ref>. Once again, we validate that the increase in users' planning depth is not a result of slower play (section S18), replicating the results from the laboratory experiment. In this experiment, we also observe a reliable increase in heuristic quality (6.12 • 10 −4 ± 4.2 • 10 −5 , p &lt; 0.001, <ref type="figure" target="#fig_8">Fig 4D)</ref>. However, the heuristic quality in the first 20 games of the mobile app data is much lower than that in the first session of the laboratory data (0.5301 ± 0.0098 vs 0.4788 ± 0.0044, t(999) = 4.7, p &lt; 0.001).</p><p>Therefore, the users have more opportunity to improve their feature weights, whereas heuristic quality in the laboratory data might already start at ceiling.</p><p>Increased planning depth as pattern recognition. Previous chess literature has framed the superior performance of experts in terms of pattern recognition <ref type="bibr" target="#b8">[9]</ref>, often operationally defined through reconstruction experiments <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8]</ref>. We conducted a memory and reconstruction experiment with participants in the expertise experiment (See section S16), which shows that experts are better at reconstructing specifically those feature that our model relies on for evaluations. Thus, this data suggests a mechanistic explanation for the observed effect of expertise on planning depth. With expertise, players sharpen their representation of game-relevant features, allowing players to evaluate more positions per unit time and therefore plan more deeply.</p><p>Hence, our results are consistent with improved pattern recognition in experts, but highlight the under-appreciated role of processing speed.</p><p>Discussion. In this article, we introduced a two-player combinatorial game of intermediate complexity that provides rich behavior, but for which cognitive modeling is still tractable. We demonstrated that a computational model based on a heuristic value function and forward search algorithm predicts human choices as well as response times and eye movements. Using this task and model, we showed robust evidence for increased planning and improved attention with expertise in both laboratory and large-scale mobile data.</p><p>Our fitting results indicate that our model best matches individual participants' choices with a planning depth of 4 to 6. However, this contradicts participants' anecdotal responses as well as the lower planning depths found in previous studies <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>First, we note that the planning depth result does not imply that people's plan is equally concrete for each of their next 4-6 moves. Our model contains value noise that is added along the nodes on the principal branch of the decision tree. Therefore, the model forms a concrete plan only for the first few moves, and later moves are planned more loosely. Additionally, the model contains a sophisticated algorithm for deciding which nodes in the tree to explore, but its decision as to when to terminate this search is random. In practice, this leads the model to often continue search without changing its eventual decision. By contrast, people have been shown to make such decisions more strategically and close to optimally <ref type="bibr" target="#b37">[38]</ref>.</p><p>In section S10, we show that amending the model with a threshold-based termination rule decreases the estimated planning depth, but the threshold cannot be identified from choice data.</p><p>However, for any value of the threshold, we find a correlation between expertise and planning depth.</p><p>Would our results on the nature of expertise generalize to more complex games or natural planning tasks? We speculate that in more complex games, the same effects of expertise on attention and search will exist. For the heuristic quality effect, we note that in the laboratory data, participants already start with approximately correct inductive biases <ref type="bibr" target="#b48">[49]</ref> about the relevant features and their relative values, and we observe no increase in heuristic quality with expertise. In the mobile app data, people's feature weights are initially worse and we do observe an increase. Thus, the model reveals a difference between laboratory and mobile data not obvious from playing strength alone.</p><p>Complex games like chess or Go contain many non-obvious features, which people can only learn through extensive experience or explicit instruction <ref type="bibr" target="#b49">[50]</ref>. Therefore, we speculate that in such games, the superior performance of experts relies much more on domain-specific knowledge. Additionally, we note that 4-in-a-row, chess and Go are all deterministic two-player games, and expertise in planning with stochastic environments <ref type="bibr" target="#b50">[51]</ref> or multi-agent interaction <ref type="bibr">[52]</ref> might involve other computational mechanisms.</p><p>Since our model is framed generically, it can be adapted straightforwardly to study expertise in more complex planning tasks (such as chess, go, shogi or Connect-Four). However, it does require a set of features to define the heuristic function. The 4-in-a-row game contains a small set of simple features, which allow the model to explain people's choices. We discovered these features through manual exploration and model comparison. For more complex games which require more sophisticated features, learning these features might prove more difficult. One promising approach would be to train neural networks to either play these games or predict human choices, and examine its internal representations. This approach could also open up a space of alternative models for 4-in-a-row. [52] Anthony, T. et al. Learning to play no-press diplomacy with best response policy iteration. arXiv preprint arXiv:2006.04635 (2020).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Participants</head><p>We recruited participants through the NYU Psychology research participant system, flyers, a sign-up link on our lab webpage or personal communication. We compensated participants $12 per hour, but did not incentivize task performance. Participants provided informed consent and our experiments were approved by the Institutional Review Board of New York University.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Human-vs-human</head><p>For our human-vs-human experiment, we recruited 40 participants in pairs. For each pair, we provided consent forms and instructed participants on the task together, after which we separated them into different rooms. We manually started the task for each participant, then they played games against each other through an online interface. After 50 minutes had expired and they finished their last game, we manually proceeded them to a post-task questionnaire, during which we provided them with payment ($12 in cash). Only after completing the survey and receiving payment did participants leave their respective rooms. Thus, participants interacted socially before and after the experiment, but not during the task.</p><p>Participants played games against each other, switching colors after every game. After each game, we presented both participants with a pop-up showing both players' names, current score and a button to continue to the next game. The interface proceeded only after both players had clicked the "continue" button. Every time the participant or their opponent moved, the interface made a faint "clicking" noise. During games, instead of making a move, participants could offer a draw to their opponent, which caused a pop-up prompt to appear on the other participants' screen to accept or reject the offer. If the opponent accepted the draw, the game ended immediately, otherwise the pop-up disappeared and the player who made the offer could make a move instead. We did not restrict how many draw offers participants could make (including multiple draw offers on the same move), but participants made relatively few draw offers. In this experiment, we never imposed any time limits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Generalization</head><p>In this experiment and all following ones, participants performed the task individually. Each session started with the participant providing informed consent, after which we instructed them on the details of the task. We always compensated participants $12 at the end of their session.</p><p>In the generalization experiment, participants played against computer opponents for 30 minutes, after which they completed 82 trials each of a two-alternative forced-choice (2AFC) between moves in given board positions, and 82 board evaluation trials, in which they rated their winning chances in given board positions on a 7-point scale. Afterwards, we debriefed participants and provided payment. The interface for the play-against-computer task was identical to the human-vs-human experiment, except for two modifications: the between-game pop-up did not display any names or current score, and we removed the "offer draw" button.</p><p>In all human-vs-computer games, the computer's algorithm is similar to the behavioral model (see section 2.3) with 3 modifications: we used the pruning rule from the Fixed branching model, we included scale factors for weights of features belonging to the opponent (as in the Opponent scaling model) and for features of different orientation (the Orientationdependent weights model) but not between "active" and "passive" feature weights (as in the No active scaling model). Finally, the algorithm used a slightly different feature set. We artifi-cially added a "thinking time" to each computer move, which monotonically increased with the number of search iterations that the computer performed on each move. This ensured that the computer played faster in easy positions than in harder ones.</p><p>We created 30 computer opponents, all using the same algorithm but with different parameters. We started by fitting the behavioral model on participants in the human-vs-human experiment. For each parameter vector for a human participant, we created additional vectors by either dividing the feature drop rate by 2, doubling the mean tree size, halving the value noise or any combination thereof. We then ran an all-vs-all tournament between agents using these parameter vectors, and ranked their performance using the Elo system (2.1). Finally, we selected 30 agents such that their Elo ratings uniformly cover an interval ranging from slightly weaker than the worst human players to slightly stronger than the best. We divided the set of 30 agents into 6 levels with 5 agents per level, and matched participants with computer opponents using a one-up, one-down staircase, starting at level 3. For each game, we randomly selected an opponent from the 5 agents on the current level.</p><p>On a 2AFC trial, we presented a participant with a board position and two candidate options, and they indicated their preference by clicking on the corresponding candidate move ( <ref type="figure" target="#fig_0">Fig S1A)</ref>. We did not impose any time limits on participants' choices. To present participants with interesting choices and to ensure that participants' choices constrain model parameters, we selected board positions that maximize mutual information between the chosen move and model parameters, within the set of parameter vectors inferred by the model for human participants. Additionally, we computed the objective value of each move, and ensured that each trial type (both moves winning, one winning and one drawn, both drawn, etc) is represented equally (14 times). We presented the same positions to each participant, in shuffled order.</p><p>In the evaluation experiment, we presented participants with pre-arranged board positions and instructed them to indicate their expected winning chances on a 7-point scale (see <ref type="figure" target="#fig_0">Fig S1B)</ref>.</p><p>Participants entered their rating by clicking one of 7 buttons. We labeled the first, middle and last button with "losing", "equal" and "winning", respectively. For the evaluation experiment, we selected positions using the same procedure as in the 2AFC experiment, except that in the final selection stage, we ensured that the game-theoretic values (S2.4) of the presented positions were equally distributed across winning, losing or drawn (28 each). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Turing test</head><p>The Turing test experiment consisted of two sessions on consecutive days. On the first session, participants played against computer opponents for 60 minutes. In this experiment, each computer opponent followed the main model with parameters inferred for an individual participant in the human-vs-human experiment.</p><p>On the second session, participants performed 180 trials of a classification task (see <ref type="figure" target="#fig_0">Fig 15)</ref>.</p><p>On each trial, we presented participants with a movie of a segment of a game played either by two players in the human-vs-human experiment, or two computers following the main model with parameters inferred for those players. Participants could start the movie at any time by pressing a "Play" button, and the video played at a constant speed of 1.8 seconds per move. After the video, participants judged the video using a slider labeled "Certainly computers" on the left, "No clue" in the middle and "Certainly humans" on the right. After each trial, we provided participants with feedback whether their classification judgment was correct ("Correct!") or not ("Incorrect.").</p><p>We selected game segments to use for human-vs-human videos from games played in human-vs-human experiment, and computer-vs-computer videos using a similar sampling method.</p><p>First, we created one video excerpt from each game in the human-vs-human experiment. For each game, we drew a number from a geometric distribution with rate 0.15 and selected the position that occurred in the game after that many moves. We then drew a maximum length for the segment from another geometric distribution with rate 0.1, and added moves from the game until the segment exceeded that maximum length or until the end of the game. For each game, we also generated a computer-vs-computer segment, starting from the same position, using the same maximum length. As before, we added moves from a simulated computer-vs-computer game until that segment exceeded the maximum length or the game ended. In other words, all computer-vs-computer video segments start from a position that occurred in a human-vs-human game, but all moves are made by the behavioral model. Because of this sampling method, and the constant playback speed of the videos, the only cues available to participants are the moves played and not the starting position or response times. Finally, we selected a random subset of 90 games to use for human-vs-human videos and 90 others for computer-vs-computer videos.</p><p>To instruct participants on the task, we used the following text: "Today, you will be shown 180 short videos, either from games between two human players or between two computers.</p><p>Half of the videos are from games between humans, the other half between computers. The videos may start from any point in a game, so the starting position is not necessarily an empty board. Your task is to identify if the video is from a human-vs-human game or a computervs-computer game. You will also be asked to report how confident you are about your choice.</p><p>There is no time limit to this task."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Eye tracking</head><p>In the eye tracking experiment, participants play against computer opponents for 40 minutes and performed 82 trials of the 2AFC experiment, with settings for both experiments identical to the generalization experiment above. For the entire experiment, we recorded their eye movements with a remote infrared video-oculographic system (EyeLink 1000; SR Research, Ltd., Mississauga, Ontario, Canada[56]) with a 1 kHz sampling rate and ≈ 0.01 degree precision.</p><p>We acquired eye position data with the EyeLink software using the "Heuristic filter ON" option. We displayed stimuli on a 21-inch Sony GDMF520 CRT monitor (resolution: 1280 × 960 pixels, refresh rate: 100 Hz). Subjects used a headrest located approximately 57 cm from the screen. We set the eye tracker to record events only, so that our data set consists of a time series of fixations, saccades and blinks.</p><p>On each session, we first calibrated the eye tracker with the built-in 9-point calibration method, but we also added a calibration condition directly before and after the play-againstcomputer component of our experiment. In this calibration procedure, we presented an empty board with a white piece with a fixation cross on top of it on the bottom left tile ( <ref type="figure" target="#fig_4">Fig S2A)</ref>. We instructed participants to fixate on the cross and press the space bar when they felt their fixation was steady. After they pressed the space bar, the piece and the cross moved one tile to the right, instructing the participant to fixate on the next tile, which they again indicated with a space bar press. We continued moving the cross accordingly across all 36 squares, obtaining fixation coordinates and time stamps for the space bar presses for each square.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6">Learning</head><p>The learning experiment consisted of 5 sessions. We required participants to schedule consecutive sessions with no more than 2 days in between. On the first, third and fifth session, of the 2AFC and evaluation conditions. On the second and fourth sessions, participants played against computer opponents for the entire 60-minute session. In all these sessions, the computer opponents were identical to those of the generalization experiment and the positions were selected using the same information criteria, with one difference. We selected 180 positions that we divided into 3 groups of 60, and ensured that the order of the days on which we presented these positions was counterbalanced across participants. We compensated participants $12 per session, with a $12 completion bonus at the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.7">Time pressure</head><p>In the time pressure experiment, participants played against computer opponents for 50 minutes, again with the identical procedure as the generalization experiment. However, in each game, both the human participant and the computer opponent had to obey a time limit of 5, 10 or 20 seconds per move. The time constraint was constant within each game and varied randomly between games. If a participant exceeded this time limit, the game ended immediately and counted as a loss. We also amended the "thinking time" for the computer, to ensure that it never uses more than 80% of its allotted time. However, we emphasize that this did not change the computer opponent's decisions, as those take only a fraction of a second to compute. We control the opponent's thinking time by simply pausing the interface for the appropriate amount of time.</p><p>To inform participants of the time constraint, we indicated the time limit for each game in a pop-up before the start of that game. Additionally, directly to the right of the board we displayed a timer; a colored bar that shrunk gradually while participants were contemplating their move. Directly below the timer, we displayed a text-based count-down with the remaining thinking time in seconds ( <ref type="figure" target="#fig_4">Fig S2B)</ref>. In the 20-second condition, at the start of each move the colorbar was equally high as the board and linearly decreased to zero in 20 seconds. Initially, the bar was green, but when the participant had 10 seconds left it changed color to blue, and 5</p><p>seconds before the end it changed color to red. To warn participants even more of the passage of time, we played three warning sounds (short beeps) when the participant had 2, 1 or 0 seconds left, with increasingly higher pitch as time counted down. In the 5 or 10-second condition, we started the timer in the same state it would be in the 20-second condition after 10 or 15 seconds had elapsed (10 seconds: blue colorbar, half as high as the board; 5 seconds: red bar, quarter board height). When the computer was "thinking", we displayed a timer to the left of the board, with the identical behavior. The time warnings were largely effective, and participants lost on time in only 1.87% (33 out of 1766) of their games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.8">Large-scale mobile data</head><p>In collaboration with the mobile app company Peak (https://www.peak.net), we collected a data set of people playing 4-in-a-row. When signing up for the app, users consented to a privacy policy, which included a provision that aggregated and anonymized data might be shared with third parties such as universities. The Institutional Review Board of New York University determined that no further consent was required and approved the research protocol as "exempt".</p><p>We collected 10,874,547 games from 1,234,844 unique users. Users always play first, and the game board itself is vertically-oriented and gamified ( <ref type="figure" target="#fig_4">Fig S2C)</ref>. Additionally, users play atwill against a computer opponent implementing a version of our main model, with parameters adapted from fits on data collected in the laboratory experiments (human-vs-human, generalization, eye tracking, learning, and time pressure). The procedure for generating the computer opponents is identical to the one in the generalization, learning, and time pressure experiments, but we re-calibrated the computer opponents since they always play second. We created 7</p><p>classes of computer opponents of varying strength, and matched users with an opponent based on their track record of game results. For analysis, we randomly selected 1, 000 participants from this data set that had each played at least 100 games. We grouped their experience into 5</p><p>blocks of 20 games in order to approximately match the total experience level of participants in the learning experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.9">Memory and reconstruction experiment</head><p>In this experiment, participants memorized and reconstructed board positions. We recruited two groups of 19 participants. The first group consisted of participants who had previously completed the learning experiment, no more than 4 weeks prior. The second group had no prior experience with the game and were informed that the task involved memorizing patterns of squares and circles.</p><p>On each trial, we presented participants with board positions for 10 seconds followed by a blank board for 1 second. We then prompted them to reconstruct the original position without a time limit. The reconstruction interface allowed participants to right-click on any square to place or remove a black piece and to left-click to place or remove a white piece. At any time, participants could click a "submit" button to indicate they had finished their reconstruction, after which they received feedback indicating the fraction of the 36 squares correctly reconstructed, including empty squares.</p><p>Each participant reconstructed the same set of 96 positions in a random order, in an approximately one-hour session. We generated two sets of 48 positions. The first set contained positions from human-vs-human games. To generate this set, we varied the number of pieces in each position from 11 to 18, and randomly selected 6 positions from human-vs-human games with that number of pieces. The second set consisted of procedurally generated positions, constrained to exactly match the distribution of the number of pieces, and approximately match the marginal distribution of occupied squares. In the computer-vs-computer tournament, we include both the agents used in the generalization, learning and time pressure experiment as well as the agents used in the mobile app.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model specification</head><p>We assume that people's choices on each move are independent and generated by the same decision-making process with the same parameters within a single session. We first describe the model broadly, then in more detail. Our model is based on heuristic search <ref type="bibr" target="#b33">[34]</ref>, and consists of a value function and a tree search algorithm. Additionally, we include sources of noise to capture variability in human play and human-like mistakes.</p><p>Value function. The core of our model is a value function V (s, w), which assigns a value to a board state s. The higher this value, the more likely the black player is to win from that state.</p><p>We assume that people use value function approximation <ref type="bibr">[58]</ref>, and that people's value function is a weighted sum of features</p><formula xml:id="formula_1">V (s, w) = 5 i=1 w i φ i (s, self) − 5 i=1 w i φ i (s, opponent)<label>(1)</label></formula><p>where φ i denote the features and w i the weights. In the following, and in the main text, we omit the dependence of V (s, w) on w for brevity. The value function uses 5 features: center, connected 2-in-a-row, unconnected 2-in-a-row, 3-in-a-row and 4-in-a-row. The center feature assigns higher value to squares near the center of the board. The other features count how often their corresponding patterns occur on the board (horizontally, vertically, or diagonally).</p><p>Whenever the model evaluates a state, the weights of features belonging to the active player are multiplied by a scaling constant C. For example, the three-in-a-row feature is more valuable when it's the player's own move (it's an immediate win) than on the opponent's (it can be blocked). Active scaling does not apply to the center feature.</p><p>Tree search. The evaluation function guides the construction of a decision tree with an iterative best-first search algorithm <ref type="bibr" target="#b35">[36]</ref>. Each iteration, the algorithm chooses a board position to explore further, evaluates the positions resulting from each legal move, and prunes all moves with value below that of the best move minus a threshold. After each iteration, the algorithm stops with a probability γ, resulting in a geometric distribution over the total number of iterations.</p><p>Noise. To account for variability in people's choices, we add three sources of noise. We model selective attention by randomly dropping features (at specific locations and orientations) before constructing the decision tree, which are then omitted during the calculation of V (s)</p><p>anywhere in the tree. During tree search, we add Gaussian noise to V (s) in each node. Finally, we include a lapse rate λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Detailed model specification</head><p>Value function. The value function consists of two terms, the first of which measures whose pieces are closer to the board center:</p><formula xml:id="formula_2">V center (s) = x∈Pieces(s,black) 1 x − x center − x∈Pieces(s,white) 1 x − x center<label>(2)</label></formula><p>where Pieces(s, p) enumerates the locations of all pieces that player p owns, x center denotes the coordinate of the board center, and • is the Euclidean distance.</p><p>The second term counts how often particular patterns occur on the board (horizontally, vertically, or diagonally). A feature is a binary function f t,x,y,o (s) that returns 1 if a pattern of type t occurs at location (x, y) with orientation o, and 0 otherwise. We use the following 4 patterns:</p><p>1 Connected 2-in-a-row: two adjacent pieces with enough empty squares around them to complete 4-in-a-row.</p><p>2 Unconnected 2-in-a-row: two non-adjacent pieces that lie on a line of four contiguous squares, with the remaining two squares empty.</p><p>3 3-in-a-row: three pieces that lie on a line of four contiguous squares, with the remaining square empty. This pattern represents an immediate winning threat. <ref type="bibr" target="#b3">4</ref> 4-in-a-row: four pieces in a row. This pattern appears only in board states where a player has already won the game.</p><p>We define F to be the set of all such features (one for each type, orientation and board location), and associate a weight w to each feature in this set. The feature weight depends only on its type, not the orientation or location. Finally, we write the value function as:</p><formula xml:id="formula_3">V F (s) = w center V center (s) + c black i∈F w i f i (s, black) − c white i∈F w i f i (s, white) + N (0, 1) (3)</formula><p>where c black = C and c white = 1 whenever black is to move in state s, and c black = 1 and c white = C when it is white's move. The scaling constant C captures value differences between "active" Here, Lapse and Stop represent stochastic functions that return true with probability λ and γ, respectively, and Determined checks if the value of the root node (winning, losing or drawn) has been determined with certainty. RandomMove(s) returns a random legal move in state s. The SelectNode function determines the order by which nodes are added to the tree.</p><p>We use best-first search, which selects a node by following the principal variation, in which both players always make the best moves according to the currently estimated values, starting from the root to a leaf node. Because the value of nodes in the tree change after each iteration, so does the principal variation, and therefore the search algorithm dynamically switches between different branches of the tree. The main model has 10 parameters: the pruning threshold θ, the stopping probability γ, the lapse rate λ, the feature drop rate δ, the active scaling constant C and the feature weights w center , w connected 2-in-a-row , w unconnected 2-in-a-row , w 3-in-a-row , w 4-in-a-row . We do not add a parameter for the variance of the value noise, since changing the noise distribution from</p><formula xml:id="formula_4">N (0, 1) to N (0, σ 2 )</formula><p>has the same effect as changing θ → θ σ and w → w σ for each feature. Therefore, adding σ would over-parametrize the model and by construction cause σ, θ and {w i } to be unidentifiable from data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Computing game-theoretic values</head><p>We can use the model to calculate the game-theoretic valueṼ (s) of a position s, that is, the outcome of a game starting from position s with perfect play from both sides. To compute the game-theoretic value, we execute the best-first search algorithm with default feature weights, no sources of noise and no pruning. In the limit of infinitely many iterations, the value of the root node in the decision tree of best-first search is guaranteed to converge to the game-theoretic value. In practice we found that 200,000 search iterations was sufficient for almost all positions.</p><p>For positions in which 200,000 iterations did not yield a determined result, we set the gametheoretical value toṼ (s) = 0, in other words, a draw. To obtain the No pruning model, we fix θ to 20, 000, which is larger than any value difference that occurs in search and causes the model to never prune. Note that the model cannot compensate by increasing feature weights since their order of magnitude is yoked by fixing the value noise to have unit variance. Finally, the No tree model is achieved by fixing γ to 1. This causes the algorithm to stop after 1 iteration, in which case it will have expanded only the root node, and its choice will be the highest-value child. Pruning lower-value children does not affect this choice, so θ is not a parameter in this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Modifications</head><p>In our first modified model, Fixed iterations, we change the stopping routine Stop from a stochastic function to a deterministic function that returns true whenever the number of iterations has exceeded a constant N . In the Fixed depth model, we amend the search process to explore every branch up to a fixed depth D. In the Fixed branching model, we amend the pruning rule to keep the K highest-value children in each node (lowest-value when white is to move). If the expanded node has less than K children, the algorithm prunes nothing. Next, we consider removing the feature drop mechanism and instead applying a function in which each child is pruned with a probability ε in ExpandNode before the value-based pruning, re- Finally, we consider Monte Carlo Tree Search (MCTS). In this algorithm, instead of evaluating a state with V (s), we perform a rollout; a simulated game starting from state s between two agents that follow a myopic policy. That is, in state s , the agent chooses the move m that maximizes V (s + m), or the one that minimizes it when white is to move. We then assign a value of 1 to state s if the rollout results in a win for black, 0 for white wins, and <ref type="bibr" target="#b0">1</ref> 2 if the game is a draw. Note that, since the evaluation function contains noise, the myopic policy and the outcome of the rollout are also stochastic. Note also that we perform only a single rollout when evaluating a state.</p><p>After performing a rollout, MCTS backpropagates by averaging rather than minimax, ensuring that the value of each intermediate node of the tree is equal to the average outcome of the rollouts conducted in all descendants of that node. We also amend the best-first selection rule</p><formula xml:id="formula_5">n = argmax c∈children(n) c.val<label>(4)</label></formula><p>to the UCB formula</p><formula xml:id="formula_6">n = argmax c∈children(n) c.val + C exp * log (n.N rollouts ) c.N rollouts<label>(5)</label></formula><p>where n.N rollouts counts the number of rollouts that have been conducted in node n or any of its descendants, and C exp is a parameter that controls the balance between exploitation (investigat-ing high-value children) and exploration (investigating children that haven't been investigated much). Finally, after the tree search terminates, the algorithm makes a move by maximizing N rollouts across all children of the root node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3">Extensions</head><p>We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Model fitting</head><p>The main model has 10 parameters: the 5 feature weights, the active-passive scaling constant C, the pruning threshold θ, stopping probability γ, feature drop rate δ and the lapse rate λ. We infer these parameters for individual participants and individual learning sessions or time limit conditions with maximum-likelihood estimation. Unfortunately, deriving the log-likelihood analytically requires marginalization of all latent variables (which features are dropped, the value at each node and the number of iterations in the search algorithm), which is intractable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Derived metrics</head><p>To analyze the nature of expertise and the effect of time pressure, we convert the set of 10</p><p>parameters from the main model to 3 derived metrics: planning depth, feature drop rate and heuristic quality.</p><p>We the define the planning depth as the length of the principal variation in the model's decision tree, averaged across simulations of the model with a given a parameter vector in a fixed set of probe positions, specifically, all positions that occurred in the human-vs-human experiment (5,482 positions). As in algorithm 2, the principal variation is the sequence in which both players make the best move according to the values in the decision tree, from the root to a leaf. The length of this sequence is equal to the depth of that leaf node, and reflects how far</p><p>into the future the model plans. We average this depth across 10 simulated moves, and across all probe positions. Note that, because the set of probe positions is fixed, the planning depth is only a function of the model parameters.</p><p>The feature drop rate is simply the parameter δ. To define the heuristic quality, we evaluate In other words, the derived metrics carve up the set of 10 parameters: planning depth primarily depends on pruning threshold and stopping probability, feature drop rate on the feature drop rate, and heuristic quality solely depends on feature weights. Together, the three metrics provide a reduced representation of the model parameters that is more interpretable, more reliably inferred ( <ref type="figure" target="#fig_8">Fig S4)</ref> and sufficient to capture the increase in performance across sessions ( <ref type="figure" target="#fig_4">Fig S20)</ref>.</p><formula xml:id="formula_7">V</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Data and Code Availability</head><p>Data and code that support the findings of this study are available through the Open Science Framework (https://osf.io/n2xjm/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information for</head><p>Revealing the impact of expertise on human planning with a two-player board game</p><formula xml:id="formula_8">Bas van Opheusden, Gianni Galbiati, Ionatan Kuperwajs, Zaha Bnaya, Yunqi Li, Wei Ji Ma</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Statistics</head><p>To analyze changes in Elo rating and derived metrics in the learning and time pressure experiment, and in the mobile data, we perform mixed effects regressions with random intercepts for every participant. In each regression, we treat the condition (i.e., session number for the learning experiment, time limit for time pressure, and games played in the mobile data) as a continuous predictor. To assess whether the condition has a significant effect, we performed a likelihood ratio test between an unrestricted regression predicting depth with a fixed effect of condition, and a restricted regression with no fixed effect. We performed all regressions using the lme4 library in Rstudio.     <ref type="table">Table 5</ref>: Coefficients in a linear mixed-effects regression analysis predicting feature drop rate in the learning experiment treating session number as a continuous predictor and controlling for participant-specific effects using random intercepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Estimating the number of non-terminal states</head><p>Any non-terminal state in the 4-in-a-row game needs to satisfy two conditions. First, the number of black pieces is either equal to the number of white pieces (when black is to move), or     <ref type="table">Table 9</ref>: Coefficients in a linear mixed-effects regression analysis predicting Elo rating in the time pressure experiment treating time limit as a continuous predictor and controlling for participant-specific effects using random intercepts.</p><p>one higher (when white is to move). Second, neither player has 4 pieces in a row, column or diagonal. Any state meeting these two conditions can be reached in a legal game. Therefore,              </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model comparison</head><p>To validate the specification of our main model, we compare it to several alternatives. We test three categories of alternative models: lesions, generated by removing model components;</p><p>extensions, generated by adding new model components; and modifications, generated by re-placing a model component with a similar implementation.</p><p>In <ref type="figure" target="#fig_0">Fig S1A, we</ref> show the cross-validated log-likelihood per move of each model averaged across all participants in the human-vs-human, generalization, eye tracking, learning and time pressure experiments. All lesion models fit worse than the main model, showing that all model components are necessary to capture human behavior. In particular, lesioning any feature, tree search or feature dropping considerably worsens the model. Lesioning the active scaling constant also worsens the model but its effect is small. Of the modifications, the optimal weights and Monte Carlo Tree Search models perform poorly. The remaining models, as well as the model extensions, perform almost identically to the main model. In <ref type="figure" target="#fig_0">Fig S1B-F</ref>, we show the model comparison for each data set individually, with highly consistent results (correlation across models between experiments: ρ = 0.932 ± 0.010).</p><p>In <ref type="figure" target="#fig_4">Figure 2</ref>, we show the performance of all models in different sessions of the learning experiment, and we find that the main model is among the best in all sessions. This demonstrates that experience-related changes in behavior are not due to experts using different models, but the same model with different parameters.</p><p>Together, these results show that people's choices are consistent with a broad class of planning algorithms, namely ones that contain a feature-based evaluation function, tree search, pruning and a mechanism to capture attentional oversights. We select our main model as a representative of this class that balances parsimony with predictive power. This model captures human behavior across a variety of experimental conditions: playing against other humans or computers, under time pressure, or while head-fixed with the experimenter present for eye tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Reliability of parameter estimates and derived metrics</head><p>To assess the reliability of our parameter estimation methods, we perform two analyses. First, we compute the correlation between inferred parameters on two independent fits of the main   The color indicates the model type (lesion, modification or extension). We observe no indication that any alternative models consistently outperform the main model on early or later sessions in the experiment.</p><p>model to the human-vs-human data across participants ( <ref type="figure" target="#fig_6">Fig S3A)</ref>. In principle, since we use maximum-likelihood estimation, the best-fitting parameters are a deterministic function of the data. However, because IBS only provides stochastic estimates of the log-likelihood, we also obtain stochastic estimates of the maximum-likelihood parameters. We find that all parameters except the lapse rate are correlated across the two independent fits, and the most reliably estimated parameters are w center (ρ = 0.93, p &lt; 0.001), w connected 2-in-a-row (ρ = 0.92, p &lt; 0.001) and</p><p>δ (ρ = 0.74, p &lt; 0.001).  Second, we compute the correlation between parameter estimates for the same participant on different sessions of the learning experiment <ref type="figure" target="#fig_6">(Fig S3B)</ref>. This correlation assesses both noise induced by the stochastic nature of the model fitting methodology, but also the reliability of people's strategy across time. We average this metric across all (5 × 4)/2 = 10 combinations of the 5 learning sessions. The correlations are positive for all parameters, with once again the most reliable parameters being w center (ρ = 0.578 ± 0.045, t(9) = 12, p &lt; 0.001), w connected 2-in-a-row (ρ = 0.551 ± 0.031, t(9) = 17, p &lt; 0.001) and δ (ρ = 0.535 ± 0.041, t(9) = 12, p &lt; 0.001).</p><p>These analyses show that the model parameters are estimated reliably, but our main results depend on the derived metrics of planning depth, feature drop rate and heuristic quality instead of the raw model parameters. Therefore, we repeat these reliability analyses and show that planning depth and heuristic quality are both reliably estimated on independent fits (planning depth: ρ = 0.86, p &lt; 0.001, heuristic quality: ρ = 0.77, p &lt; 0.001, <ref type="figure" target="#fig_8">Fig S4A)</ref>, and different sessions of the learning experiment (planning depth: ρ = 0.508 ± 0.044, t(9) = 12, p &lt; 0.001, heuristic quality: ρ = 0.544±0.051, t(9) = 10, p &lt; 0.001, <ref type="figure" target="#fig_8">Fig S4B)</ref>. Note that since the feature drop rate is simply the parameter δ, this is already tested in <ref type="figure" target="#fig_6">Fig S3.</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Trade-offs between estimated model parameters</head><p>Aside from noise and uncertainty in parameter estimates, one may worry about parameter identifiability and trade-offs. A trade-off occurs when two (or more) parameters in a model cause similar changes in the distribution of responses, and therefore inferring which parameter is responsible for a given shift in behavior is difficult. One method to assess trade-offs is a parameter recovery analysis, in which one fits the model on fake data sets generated by varying one parameter, and asks if this causes shifts in the estimated values of other parameters. However, as mentioned in S2.6, the model fitting pipeline is slow, and a parameter recovery analysis is intractable. Instead, we investigate trade-offs by analyzing parameter estimates in the lesion models. In each lesion model, a specific parameter θ i is fixed to a constant. If θ i trades off with θ j , the optimization algorithm will compensate for the lesioning of θ i by increasing (or decreasing) θ j . Specifically, we test for two signatures of trade-offs:</p><p>1. Fixing θ i to a constant changes the distribution (across participants) ofθ j .</p><p>2. The change inθ j that results from fixing θ i is correlated (across participants) with the value ofθ i in the unconstrained model.</p><p>The first signature is generic and tests for any kind of non-independence of θ i and θ j . The second signature specifically tests for those kind of trade-offs that could complicate the interpretation of correlations betweenθ j and experimental variables such as session number or time limit condition. Namely, if such a trade-off is present, and there exists a true correlation between that experimental variable and θ i , but the model fitting pipeline for some reason produces biased estimates of θ i , it might compensate for this bias by increasing θ j . This could then lead to a spurious correlation between the experimental variable and θ j . To detect these signatures, we perform two tests for for each (θ i , θ j ) pair:</p><p>1. a 2-sample Kolmogorov-Smirnov (KS) test between the distribution ofθ lesion i j (the j-th parameter in the model where parameter i is lesioned) andθ full j across participants in the human-vs-human experiment (see <ref type="figure" target="#fig_16">Fig S5A)</ref> 2. the Pearson correlation betweenθ full i andθ full j −θ lesion i j (see <ref type="figure" target="#fig_16">Fig S5B)</ref>.</p><p>In both of these tests, we compensate for multiple comparisons using a false discovery rate of</p><formula xml:id="formula_9">α FDR = 0.05.</formula><p>The KS test reveals a mutual interaction between the 4-in-a-row feature weight and pruning, and unidirectional effects of lesioning the three-in-a-row feature or the decision tree on almost every other parameter. Additionally, the active scaling constant is affected by lesioning the feature drop mechanism or the connected two-in-a-row feature. The Pearson correlation test only reveals interactions between the feature drop rate, active scaling constant, connected twoin-a-row and 3-in-a-row feature weights. However, the only trade-off for which both tests are significant is the effect of lesioning the 3-in-a-row feature on the feature drop rate. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary statistics</head><p>We would like to directly compare the main model to human choices, which is challenging because the data (moves in board positions) is high-dimensional and discrete. Instead, we compare summary statistics. For each move made by each human player, we compute the distance from the chosen square to the center of the board, the distance to the nearest piece owned by that player, the distance to the nearest piece of the opponent, the distance to the the center of mass of that player's pieces, the distance to the center of mass of the opponent's pieces, the number of that player's pieces on the 8 squares neighboring the chosen square, and the number of opposing pieces on neighboring squares. Additionally, we indicated whether with their chosen move, the player created a threat to make 4-in-a-row on the next move or parried a direct threat from their opponent. Together, this yields 9 summary statistics. We also compute these statistics for moves made by the main model in the same positions encountered by human players, with parameters inferred for those players, and for random moves. <ref type="figure" target="#fig_26">Fig S7</ref> shows the average of these 9 summary statistics, aggregated across all participants in the human-vs-human data set, as a function of the number of pieces on the board. This analysis probes systematic patterns in the time course of people's games, for example a tendency to start playing near the center of the board and gradually expand outwards. For all summary statistics, people deviate considerably from random, and the main model matches the human data almost exactly. In <ref type="figure" target="#fig_27">Fig S8,</ref> we plot the average of these 9 summary statistics for each participant, against the prediction of the main model. The human data and model prediction are highly correlated for all summary statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Example positions illustrating model components</head><p>To investigate which patterns in the data are explained by different model components, we compare the distribution of choices predicted by the main model and different lesion models. First,</p><p>we compare the main model to the No tree model. We simulate moves from both models in all positions that occurred in human-vs-human games, for 200 different parameter vectors taken from previous model fits. We then average the move distributions across those 200 parameter vectors, and calculate the Jensen-Shannon divergence between the main model and that of the no tree lesion. This JS divergence is high for positions in which the model makes highly different moves with and without planning, irrespective of the parameters. In other words, such positions maximally distinguish planning vs no planning.  Distance to own center-of-mass  is losing and the one by the main model is drawn, but this relies on a specific 10-move forced sequence that can only be found through explicit search.</p><p>Next, we repeat the analysis but compare the main model against the Optimal weights lesion model. This highlights positions in which human preferences do not align with the optimal value function, and motivate the need to fit feature weights to human behavior rather than using a fixed value function. <ref type="figure" target="#fig_0">Fig S10</ref> shows 5 example positions. One common pattern in these positions is that the optimal weight model often prefers making a direct 3-in-a-row threat over moves that set up multiple 2-in-a-row threats. Additionally, the optimal weights is often overly confident in its predictions, which suggests that it is unable to capture human errors that stem from incorrect feature weights.</p><p>To investigate the contribution of different sources of noise (feature dropping and value noise), we perform a version of the same analysis, except as our metric we use the ratio between the probability of the human move in the main model and the model without that noise source. In other words, this analysis highlights moves made by a human player that can only be explained using the different noise sources. noise. These positions are less clearly related, but one common pattern is that the human move has close to zero probability according to the model without value noise, and the value noise mechanism essentially acts as a mechanism to smooth out the distribution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">2AFC comparison with an oracle model</head><p>Here, we show that the main model predicts people's 2AFC and evaluation decisions better than an oracle model, which has access to the game-theoretic value of each position and the objectively correct moves (S2.4). On 2AFC trials where one move is objectively better than the other, the oracle model picks that move. On trials where both moves are equally strong, the model picks randomly. On evaluation trials, the oracle model responds 1 when the position is lost, 4 when it's a draw and 7 for winning positions.</p><p>In <ref type="figure" target="#fig_0">Fig S14,</ref> we show the performance of this oracle model against that of the main model.</p><p>For both 2AFC and evaluation, the main model outperforms the oracle (2AFC: ∆acc = 0.0362± 0.0093, t(39) = 3.8, p &lt; 0.001, evaluation: ∆ρ = 0.079 ± 0.012, t(39) = 6.5, p &lt; 0.001).</p><p>These results suggests the main model predicts subjective preferences of individual participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Turing test</head><p>In the Turing test, we showed participants video segments of sequences of moves. <ref type="figure" target="#fig_0">Figure 15A</ref> shows observers' classification accuracy as a function of the length of the video, that is, the num- For each video, we calculate the percentage of observers who classify it as being generated from a human-vs-human game. <ref type="figure" target="#fig_0">Figure 15B</ref> shows the histogram of this percentage across videos, split up by the true label of the video (humans or computers). While it is true that human games are on average more likely to be classified as human and vice versa, there are no videos for which all 30 observers agree, and there is a considerable fraction of videos (63 out of 180) for which a majority of observers respond incorrectly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Stopping rule</head><p>To make predictions for response times and eye movements, we amend the model with a stop- prediction from the model with given parameters on a given trial, we simulate 100 moves from the model, and measure the average number of search iterations executed before the algorithm terminates.</p><p>The stopping rule allows the model to predict differences in response times across trials for the same participant. In positions where one move is clearly preferred over other options (for example, if the opponent has a direct threat that needs to be parried), the algorithm will quickly rule any alternatives and spend its remaining time calculating the future consequences of that move. Therefore, the preferred move in the root node remains unchanged for many iterations, and the stopping rule causes the search to terminate, resulting in a low number of iterations. In other positions with many plausible alternatives, the model will waver, and the stopping rule will not be called and the model will search longer. Thus, the termination rule is one way of incorporating the known effect of decision difficulty on response times. Other plausible stopping rules might behave similarly. For example, one can base the termination criterion on relative node values or node visits, as in MCTS.</p><p>In the main text, we showed that the model predicts people's response times on individual trials with this stopping rule based on 50 iterations. However, the choice to use 50 iterations as  the threshold is arbitrary. We therefore analyze models with stopping thresholds varying from 2 to 200 iterations ( <ref type="figure" target="#fig_0">Fig S16)</ref>. The correlation between predicted and observed response times is high for a broad range of stopping thresholds (30-100). Note that the lower the threshold, the larger the deviation between the choices made by the main model with and without the stopping rule. This analysis demonstrates that the correlation between search iterations in the model and participants' response times on individual trials is robust to the value of the stopping threshold, within a reasonable range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Eye movement analyses</head><p>To pre-process eye tracking data, we first convert the output files from edf to ASCII format using the edf2asc.exe program provided by SR Research. This results in a time series of fixations and saccades for each participant, with time measured relative to the moment we turned on the eye tracking software, and position in a coordinate system defined by the eye tracker calibration. We start by re-calibrating both time and space, using data from the calibration that each participant completes at the beginning and end of the experiment (S1.5). In each calibration, the participant fixates on all 36 squares consecutively, pressing the space bar to provide a time stamp for each fixation.</p><p>In <ref type="figure" target="#fig_0">Fig S17A,</ref>  times of the space bar press and the corresponding tile coordinate, summed across horizontal and vertical dimensions. We then calibrated spatial coordinates using the temporally aligned data.</p><p>To recalibrate space, we assume the transformation from eye tracker to board coordinates is linear for each square, but not necessarily globally linear. We divide the eye coordinate space into 36 tiles using a Voronoi tessellation with as centroids the eye tracker coordinates at the time of space bar presses, averaged across the pre-task and post-task calibration <ref type="figure" target="#fig_0">(Fig S17B)</ref>.</p><p>The Voronoi tessellation allows us to assign a square for eye fixation in the time series.</p><p>For any fixation vector c in eye tracking coordinates, we compute the fractional board coordinates with a 3-step process.</p><p>1. Use the Voronoi tessellation to assign the fixation to a board square, and define c tile to be the eye tracker coordinates of that tile's centroid. </p><p>This equation defines a linear function from the Voronoi cell to [−∞, 1], so that the centroid maps to 0 and any point on the boundary with this neighbor maps to 1.</p><p>3. Define the fractional coordinates in board space as</p><formula xml:id="formula_11">x = f right /2 if |f right | &lt; |f left | −f left /2 otherwise y = f up /2 if |f up | &lt; |f down | −f down /2 otherwise<label>(8)</label></formula><p>For squares on the edge of the board, where f right , f left , f up or f down may be ill-defined, we use the case in the equation above that is well-defined. This results in a piecewise linear mapping between board space and eye tracker coordinates. In <ref type="figure" target="#fig_0">Fig S17C,D, we</ref> show the resulting mapping from eye tracker space to board coordinates for an example participant.</p><p>To predict eye movements from the behavioral model, we simulate 100 moves from the model in each position encountered by each participant in the eye tracking data set, with model parameters inferred for that participant. After the model makes a move, we count for each square and each depth how often the principal variation in the selection step of the search algorithm includes a move on that square at that depth. This results in a histogram over unoccupied squares for each position in our data set and each depth, which we normalize into probability distributions of the model's square visits. For each position, we also create a probability distribution that is 1 for the square on which the participant actually moved and zero otherwise.</p><p>We then regress the model's square visit distributions at different depths and the actual move distribution against participants' distribution of attention estimated from eye movements. This results in a positive correlation between predicted and observed eye movements, as outlined in the main text. Crucially, the regression coefficients are significantly larger than zero (onesample T-test across participants) for depth up to 7, and highest for depth closer to 1 <ref type="figure" target="#fig_0">(Fig S18)</ref>.</p><p>To support the interpretation of dropped features as lapses of selective attention, we now</p><p>show that when the behavior modeling suggests that a participant has dropped a feature, that participant spends little to no time looking at the relevant squares.   metrics. Specifically, for each session of the learning experiment, we perform a multiple linear regression predicting Elo rating from planning depth, feature drop rate and heuristic quality.</p><p>This results in regression slopes of −818 ± 108 Elo points per feature drop rate (mean and s.e.m. across sessions), 33.9±4.9 points per planning depth, and 326±156 per heuristic quality.</p><p>We then combine the predictions of the regression across all sessions, and show that using the derived metrics, we can explain 56.7% of the variance in participants' Elo rating <ref type="figure" target="#fig_4">(Fig S20A)</ref>.</p><p>Additionally, even though the regression coefficients are based on within-session data only, the observed trend of increasing playing strength across sessions is well captured by this regression <ref type="figure" target="#fig_4">(Fig S20B)</ref>. Note that in this regression, we use a constant intercept for all sessions. Finally, by multiplying the regression slopes with the empirically measured changes in the derived metrics, we can break down the increase in Elo rating as 36 ± 11 points from planning, a 46 ± 12 due to featured dropping, and −6.6 ± 3.5 due to heuristic quality.</p><p>A B  <ref type="figure" target="#fig_6">(Fig 3)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="13">Individual differences in playing strength</head><p>In <ref type="figure" target="#fig_0">Fig S18,</ref> we show the correlation between Elo ratings and the three metrics across all participants in all sessions of the learning and time pressure experiments. Playing strength correlates with planning depth (ρ = 0.62, p &lt; 0.001) and feature drop rate (ρ = −0.73, p &lt; 0.001), but not with heuristic quality (ρ = 0.11, p = 0.088). 14 Response times in the learning experiment 15 Response times in the learning experiment </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A C B</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="16">Memory and reconstruction experiment</head><p>To better understand the mechanism behind participants' increase in performance and planning depth, we conducted a memory and reconstruction experiment, akin to de Groot[61], Chase &amp; Simon <ref type="bibr" target="#b1">[2]</ref> (See methods1.9). <ref type="table" target="#tab_5">Table S25</ref> shows the probability for experts and novices to correctly reconstruct a piece given the condition (real games vs randomly scrambled boards) and the identity of the piece (black, white or an empty square). A mixed effects regression shows that experts are more often correct than novices (β = 0.015 ± 0.004, p &lt; 0.001), and that pieces from real games are more often correctly reconstructed than random positions (β = 0.058±0.005, p &lt; 0.001), but we find no evidence for an interaction (β = 0.0002±0.0051, p = 0.96).  <ref type="figure" target="#fig_4">Figure 24</ref>: A. Error rates in the memory and reconstruction experiment. B. Scatterplot of total reconstruction time for experts and novices. Each point represents a board position in the memory in reconstruction experiment, the x-coordinate the average time that experts take to finish their reconstruction, and the y-coordinate the same but for novices. Positions from games are colored pink, randomly scrambled positions in gray.</p><p>( <ref type="figure" target="#fig_4">figure S25)</ref>. We define the accuracy as the probability for a feature instance to be present in a given location and orientation in the reconstructed board given that it was present on the original. Since participants place piece in the reconstruction sequentially, we define the reconstruction time for a given feature instance as the time from the start of reconstruction to the first time that the feature instance is present on the reconstructed board. Note that this metric does not take into account the possibility that the participant subsequently removes those pieces, since participants rarely remove pieces (7.3 ± 0.5% of clicks). <ref type="figure" target="#fig_4">Figure S25</ref> shows that experts are more accurate at reconstructing game-relevant features <ref type="bibr">(3-</ref>in-a-row: β = 0.062±0.020, p = 0.0046; connected 2-in-a-row: β = 0.053±0.015, p &lt; 0.001; unconnected 2-in-a-row: β = 0.068±0.015, p &lt; 0.001). Additionally, when experts reconstruct these features, they at an earlier point in the trial (3-in-a-row: β = 0.034 ± 0.012, p &lt; 0.001; connected 2-in-a-row: β = 0.028 ± 0.008, p &lt; 0.001; unconnected 2-in-a-row: β = 0.039 ± 0.009, p &lt; 0.001), leading to an approximately equal first reconstruction time (3-in-a-row: β = −0.06 ± 0.17, p = 0.69; connected 2-in-a-row: β = 0.23 ± 0.14, p = 0.028; unconnected 2-ina-row: β = 0.14 ± 0.15, p = 0.20). In other words, experts are more accurate at reconstructing features in the same amount of time, and experts start their reconstructions with the gamerelevant features. <ref type="figure" target="#fig_4">Figure S26)</ref> shows an example position in which experts reconstruct a 3-in-arow feature more accurately than novices. Together, these results suggest that players represent boards in memory in terms of game-relevant features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="17">Robustness</head><p>To demonstrate that the main results on expertise are robust to choices in the model specification, we repeat the analysis for all alternative models. This requires extending the definition of the planning depth, feature drop rate and heuristic quality metrics to the alternative models. This is straightforward for all models except the Orientation-dependent dropping and Type-dependent dropping models, for which we define the feature drop rate as the drop rate of the horizontal 3-in-a-row feature. Additionally, we note that in the Fixed depth model, every branch of the decision tree is explored up to the same depth, hence the planning depth is not just the length of the principal variation, but also the length of every other variation. <ref type="table" target="#tab_5">Table S26</ref> shows the result of a correlation between Elo rating and planning depth, feature drop rate or heuristic quality across individuals in the learning experiment (analogous to S13) for all models. Across all 22 models for which it is applicable, participants' Elo rating correlates strongly with planning depth and feature drop rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="18">Response times in mobile data</head><p>As in the in-lab data, we verify that the increase in users' planning depth is not a result of slower play in the mobile data set. <ref type="figure" target="#fig_4">Fig S22B shows</ref> that this indeed the case, as users' response time decreases with experience.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Task and computational model. A. Example board position in the 4-in-a-row game.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>putational model for human decision-making in 4-in-a-row. In our first experiment, 40 human participants play games against other human players, without any time pressure. For each participant, we estimate model parameters (feature weights, feature drop rate, decision tree size, pruning threshold and noise level) using 5-fold cross-validation. The model predicts out-of-sample choices with 40.8 ± 1.4% accuracy (mean and standard error across participants, two-sample T-test against chance: t(39) = 26, p &lt; 0.001). Fig 2A shows an example model prediction, and Fig 2B the model accuracy for each participant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>The model accounts for multivariate data and generalizes to unseen data. A. Example board position from a human-vs-human game. The white open circle indicates the move that the active player (white) chose. Red shading indicates the probability distribution of that participant's next move, as predicted by the model with parameters inferred for that participant using 5-fold cross-validation. B. Model accuracy (percent correctly predicted moves) for each participant in human-vs-human games, ranked from worst to best predicted. Error bars indicate standard error of the mean (s.e.m.) across all positions in that participant's games.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig 2E shows the predicted and observed response times (in logarithmic space) across all participants in the human-vs-human experiment, Fig 2F the Pearson correlation for each participant (ρ = 0.351 ± 0.029, t(39) = 11.66, p &lt; 0.001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>FigFigure 3 :</head><label>3</label><figDesc>3B-D shows that planning depth increases across sessions (β = 0.255 ± 0.061, p &lt; 0.001) while feature drop rate decreases (β = −0.0119 ± 0.0028, p &lt; 0.001). Heuristic quality 8 The effects of expertise and time pressure on planning. A. Average Elo rating of participants in the learning experiment, as a function of session number. In this panel and all others, error bars denote mean and standard error across participants. B. Average depth to which participants plan, as estimated by the behavioral model. C. Same as B, for feature drop rate. D. Same as B, for heuristic quality. E. Average Elo rating of participants in the time pressure experiment, as a function of the time limit. F-H. Same as B-D, for the time pressure experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>The effects of expertise on planning in mobile data. A. Average Elo rating of users of the mobile app, as a function of number of games played. In this panel and all others, error bars denote mean and standard error across participants. B. Average depth to which users plan, as estimated by the behavioral model. C. Same as B, for feature drop rate. D. Same B, for heuristic quality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Our modeling results show how experts differ from novice players, but do not shed light on how those differences emerge from their experience. In future work, we aim to analyze games from all 1.2 million users in the mobile data set, and match people's experience with their future actions. A promising candidate for modeling this learning process is deep reinforcement learning, specifically algorithms such as AlphaZero[53] and SAVE[54], which combine prior experience with forward planning at decision time. Our work opens the door to a precise understanding of human planning across development and in patient populations. Additionally, it raises the question of how the components of the model are represented neurally. A specific hypothesis is that the value of future states is correlated with the activity of neurons associated with reward-based decision-making, such as those in orbitofrontal cortex[55]. Additionally, we predict that the time course of neural activity while a player contemplates their move reflects the dynamics of the value of the root node over iterations of the search algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>[ 53 ]</head><label>53</label><figDesc>Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and go through self-play. Science 362, 1140-1144 (2018). [54] Hamrick, J. B. et al. Combining q-learning and search with amortized value estimates. arXiv preprint arXiv:1912.02807 (2019). [55] Padoa-Schioppa, C. &amp; Assad, J. A. Neurons in the orbitofrontal cortex encode economic value. Nature 441, 223-226 (2006). [56] Cornelissen, F. W., Peters, E. M. &amp; Palmer, J. The eyelink toolbox: eye tracking with matlab and the psychophysics toolbox. Behavior Research Methods, Instruments, &amp; Computers 34, 613-617 (2002). [57] Hunter, D. R. Mm algorithms for generalized bradley-terry models. Annals of Statistics 384-406 (2004). [58] Sutton, R. S., McAllester, D. A., Singh, S. P. &amp; Mansour, Y. Policy gradient methods for reinforcement learning with function approximation. In Advances in neural information processing systems, 1057-1063 (2000). [59] de Groot, M. H. Unbiased sequential estimation for binomial populations. The Annals of Mathematical Statistics 80-101 (1959).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>[ 60 ]</head><label>60</label><figDesc>Huyer, W. &amp; Neumaier, A. Global optimization by multilevel coordinate search. Journal of Global Optimization 14, 331-355 (1999). [61] de Groot, A. D. Het Denken van den sckaken (Noord-Holland. Uitgev. Maatschappij, 1946).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>1 Methods</head><label>1</label><figDesc>We conducted six laboratory experiments: human-vs-human (N = 40 participants), generalization (N = 40), eye tracking (N = 10), learning (N = 30), time pressure (N = 30) and a Turing test (N = 30). The experiments can be played online on our website basvanopheusden.github.com (except for human-vs-human and eye tracking).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 1 :</head><label>1</label><figDesc>A. Example board in the 2AFC task. The participant, playing black, chooses between one of two candidate moves in a given board position. B. Example evaluation board. The participant ranks the winning chances of the current player on a 7-point scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>CFigure 2 :</head><label>2</label><figDesc>participants played against computer opponents for 30 minutes and completed 60 trials each A B A. Screenshot of the calibration component of the eye tracking experiment. We instructed participants fixate on the black cross in the white circle, and press the space bar. The white circle and the cross then move to the next tile, until we have acquired fixation coordinates for all 36 tiles. B. Screenshot of the pre-game pop-up in the time pressure experiment. The time limit is indicated on the pop-up, and underneath the visual timer on the right of the board. Additionally, the height and color of the colorbar inform the participant of the time limit. During each participant's move, the colorbar on the right gradually shrinks while the text beneath counts down to zero. The same happens for the left timer during each computer's move. C. Screenshot of the game interface on the mobile application.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Algorithm 2 :</head><label>2</label><figDesc>SelectNode() n ← root; while children(n) = ∅ do if n.color = black then n = arg max c∈children(n) c.val else n = arg min c∈children(n) c.val return n;After the search algorithm has selected a leaf node to explore, it expands it by adding one child node for each legal move in the associated state. As it initializes the children, it automatically evaluates their states using V (s) as defined above. The algorithm does not yet check whether either of these states is terminal (that is, either player has achieved 4-in-a-row or the board is full), but it effectively does so if w 4-in-a-row is high enough. Next, the algorithm prunes unpromising children; those whose value difference with the best candidate move exceeds a threshold θ. Only afterwards does it assign V = 10, 000 to each child state in which black has won, V = −10, 000 if white has won and V = 0 for draws. It is therefore possible that, if w 4-in-a-row is too low, or if the algorithm has dropped a 4-in-a-row feature in a relevant location, it will prune away an immediately winning move, which can result in gross (but human-like)blunders.Algorithm 3: ExpandNode(node n) s← n.state; foreach legal move m in s do n.AddChild(node(s + m)); if n.color = black then V max = max c∈children(n) c.val else V max = min c∈children(n) c.val for c ∈ children(n) do if |c.val − V max | &gt; θ then RemoveChild(c) Next, the search algorithm incorporates the value of the newly created nodes into the deci-sion tree with minimax backpropagation. After backprogagation, the value of each state reflects the search algorithm's best estimate of the result of a game starting in that state with perfect play from both sides. Algorithm 4: Backpropagate(node n) if n.color=black then n.val ← max c∈children(n) c.val else n.val ← min c∈children(n) c.val if n =root then Backpropagate (n.parent) The search algorithm continues to run until the Stop routine returns true, after which it makes the best move according to its estimated values. Since the Stop routine is random and independently drawn each iteration, the total number of iterations follows a geometric distribution with parameter γ. When implementing our model as an AI algorithm to play against human opponents, we convert the number of iterations N into a 'thinking time' for the AI by t = a √ N γ + b, where a = 4s and b = 0.5s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>2. 5</head><label>5</label><figDesc>Alternative model specifications 2.5.1 Lesions Our first set of alternative models are lesion models, obtained by removing components from the main model. Each lesion can be implemented by fixing a parameter to a constant. The No center, No connected 2-in-a-row, No unconnected 2-in-a-row, No 3-in-a-row and No 4-ina-row models are obtained by setting the respective feature weight to zero. The No feature drop model is obtained by fixing δ to zero, and the No active scaling model results from fixing C to 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>sulting in the Tile dropping model. For the Optimal weights model, we restrict the feature weights {w i } to a constant vector, which we chose by maximizing the Pearson correlation between tanh (V (s)/20) and the game-theoretic valueṼ (s) across all states s that occurred in the human-vs-human experiment (see S2.4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>(s, w) in all the probe positions, and compute the Pearson correlation between tanh(V (s, w)/20) and the game-theoretic valueṼ (s) (see S2.4). Note that the heuristic quality only depends on the feature weights w and the active scaling constant C. Because the probe positions are fixed in the definition of planning depth, it is purely a function of the model parameters. Planning depth depends primarily on the stopping probability (Spearman correlation: ρ = −0.87, p &lt; 0.001), and there is a minor dependence on the pruning threshold (ρ = −0.21, p &lt; 0.001). These correlations are computed across a range of parameter vectors taken from model fits to human data. The heuristic quality is a more complicated function of the feature weights and active scaling constant. For example,the heuristic quality correlates with w 3-in-a-row /w connected 2-in-a-row , but the correlation is relatively weak (ρ = 0.55, p &lt; 0.001), and other feature weights influence the heuristic quality too.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 1 :</head><label>1</label><figDesc>Model comparison. A. Cross-validated log-likelihood per move, averaged across all participants in the laboratory experiments, for the main model and its alternatives. Error bars indicate standard error of the mean log-likelihood difference between a model and the main model. B. Same as A., for participants in the human-vs-human experiment only. C-F. Same, for the generalization, eye tracking, learning and time pressure experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 2 :</head><label>2</label><figDesc>Difference between log-likelihood per move of alternative models minus that of the main model, as a function of session number in the learning experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>4</head><label>4</label><figDesc>w connected 2-in-a-row w unconnected 2-in-a-row w 3-in-a-row w w connected 2-in-a-row w unconnected 2-in-a-row w 3-in-a-row w 4-in-a-row B A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 3 :</head><label>3</label><figDesc>Pearson correlation across participants between model parameters estimated in A. two independent fits, B. different sessions in the learning experiment. The errorbars denote standard error of the mean correlations across all session pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 4 :</head><label>4</label><figDesc>Same as Fig S3, for the derived metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>1 Figure 5 :Figure 6 :</head><label>156</label><figDesc>These results show that parameters in our model are not fully distinguishable, which is a consequence of the model fitting methodology as well as the finite data size. However, the main results of our paper concerns the derived metrics of planning depth, feature drop rate and heuristic quality. To show that these metrics are distinguishable, we analyze the No tree, No feature drop and Optimal weights lesion models. In these models, the planning depth, feature drop rate or heuristic quality are constant, hence we can think of these as 'lesions' of those metrics. As before, we test whether the distribution of planning depth, feature drop rate or heuristic quality in the lesion models differs from that in the main model, and whether the change induced by the lesion correlates with the value of the lesioned metric.Fig S6A shows the result of the Kolmogorov-Smirnov test, Fig S6B the Pearson correlation. We find no significant trade-offs that could lead to spurious effects in our analyses of planning depth, feature drop rate B A θ γ δ C w c e n te r w c o n n e c te d 2 -i n -a -r o w w u n c o n n e c te d 2 -i n -a -r o w w 3 -i n -a -r o w w 4 -i n -a -r o w n te r w c o n n e c te d 2 -i n -a -r o w w u n c o n n e c te d 2 -i n -a -r o w w 3 -i n -a -r o w w 4 -i n -a -r o w We detect trade-offs between model parameters using two approximate methods, since computing the full confusion matrix in a parameter recovery analysis is too computationally costly. A. 2-sample Kolmogorov-Smirnov (KS) test statistic between the distribution ofθ lesion i j andθ full j for each pair of parameters. We indicate statistics that are significant at α = 0.05, α = 0.01, α = 0.001 (all FDR-corrected) with one, two or three stars, respectively. B. Pearson correlation betweenθ full i andθ full j −θ lesion i j for each pair of model parameters, with significance levels as in A. and heuristic quality as a function of expertise or time pressure. B A P l a n n i n g d e p t h F e a t u r e d r o p r a t e H e u r i s t i c q u a l i t n n i n g d e p t h F e a t u r e d r o p r a t e H e u r i s t i c q u a l i t Same as Fig S5, but for derived metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig S9 shows 5</head><label>5</label><figDesc>example positions for which this dissimilarity is among the highest (the maximum is 0.149). Upon inspection, we recognize these positions as ones where the player to move has multiple reasonable options, but to evaluate their quality one has to calculate many moves ahead. For example, in the second position, the move preferred by the No tree model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 7 :</head><label>7</label><figDesc>Summary statistics computed as a function of number of pieces on the board, for moves made by human players (green solid lines), the behavioral model with inferred parameters (blue lines) or random moves (black dashed lines). These graphs depict cross-validated predictions. For all statistics, the model prediction is much closer to the human data than random.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 8 :</head><label>8</label><figDesc>The model predicts individual differences in summary statistics. Each panel shows a scatterplot for a summary statistic, where each point represents a participant in the humanvs-human experiment, the x-coordinate the statistic computed on that participant's moves and the y-coordinate the statistic computed on moves made by the model. The inset in each panel shows the corresponding Pearson correlation coefficient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig S11 shows 5</head><label>5</label><figDesc>example positions for feature dropping. The feature drop mechanism is necessary to explain a human tendency to overlook possibilities to immediate make 4-in-a-row, or immediate 4-in-a-row threats by the opponent. More generally, the feature drop mechanism applies to all features in the model, but the impact is largest when considering 3-in-a-row and 4-in-a-row features.Fig S12 shows 5 examples in which the human move cannot be explained without value</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Finally, we investigateFigure 9 :Figure 10 :Figure 11 :Figure 12 :</head><label>9101112</label><figDesc>which moves necessitate a non-zero lapse rate in the model. For Example positions from human-vs-human games in which the model with (right column) and without tree search (left column) make highly different predictions (red shade). In each position, we also show the models' preferred move (with an x) and the move made by the human participant (open circle). Same asFig S9,for the Optimal weights model compared to the main model. Same asFig S9,but comparing the main model with the No feature dropping lesion, and using the ratio between the predicted probability of the human move (circle) as the metric (red shading). Same asFig S9,but comparing the main model with the No value noise lesion. this analysis, we cannot fit a No lapse model, but that is numerically unstable. Instead, we run 200 simulations of the main model with different parameter vectors (see above), and as our qualifying metric we use the probability of the human move averaged across these 200 simulations.Fig S13 shows the top-5positions where the human move is least probable. These positions are all instances where the human participant made a particularly poor (and in 4 out of 5 cases, losing) move that has no apparent rationale behind it. Thus, the model can only explain these choices as lapses, i.e., the human participant making a completely random move.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 13 :Figure 14 :</head><label>1314</label><figDesc>ber of moves in the segment. On average, sequences were 9.38 moves long. Showing sequences instead of individual moves was necessary, as participants are not above chance for classifica-Same as Fig S9, but only showing the main model, and using the probability of the human move (circle) as the metric (red shading). A. Accuracy of the main model prediction and that of an oracle model on 2AFC data. Each point is a participant, the dashed line indicates equality. B. Same, for the Pearson correlation coefficient between predicted and observed board evaluations. For both 2AFC and evaluation, the main model outperforms the oracle.tion of one-move videos (of which there were 8). Instead, participants require longer sequences and their accuracy only substantially exceeds 50% for sequences longer than 10 moves. A mixed effects linear regression with accuracy as dependent variable and observer-specific random intercepts estimates the increase in accuracy per observed move as only 0.33 ± 0.10%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 15 :</head><label>15</label><figDesc>ping rule: we terminate the best-first search algorithm when the model's preferred move in the root node remains unchanged for 50 consecutive iterations. This stopping rule is in addition to the random stopping rule implied by the stopping probability γ. To obtain a response time A. Classification accuracy in the Turing test as a function of video length. Error bars denote mean and standard error. B. Histogram of the percentage of observers classifying a given video as human-vs-human or computer-vs-computer, for either human games (pink), or computer-generated games (gray).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 16 :</head><label>16</label><figDesc>Correlation between predicted and observed log response times in the main model with different choices for the stopping threshold. The vertical dashed line at 50 indicates the stopping threshold used in the main text. The correlation is robust to the choice of stopping threshold, within a range from approximately 30 to 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head></head><label></label><figDesc>we plot the horizontal and vertical eye position as a function of time, for both calibration periods and one example participant. Note the typical staircase-like pattern that arises when a participant scans each row of the board, starting at the bottom, from left to right. Fig S17A also shows the time of each of the 72 space bar presses as vertical lines. To correct for small temporal offsets between times measured on the eye tracking computer and the experiment server, we varied a temporal offset between the behavioral and eye tracking time stamps and maximized the Pearson correlation between the eye coordinate at the (corrected)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head>2 .c tile 2 cc neighbor 2 c</head><label>222</label><figDesc>For each neighboring square (up, down, left or right) with centroid coordinates c neighbor , compute f neighbor = 1 + c − tile − c neighbor 2 − c − tile − c neighbor 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>Fig S19 shows 5 Figure 17 :</head><label>517</label><figDesc>example Eye calibration procedure. A. Behavioral and eye tracking data during the calibration stages before and after the experiment. The blue and orange lines indicate the horizontal and vertical eye position in eye tracker coordinates (arbitrary units), and each vertical line indicates a time at which the participant pressed the space bar. For both calibration periods, we measure time relative to the time of the first space bar press. B. Eye coordinates at the time of each space bar press in both calibration stages (gray dots), and a Voronoi tesselation (black solid &amp; dashed lines) with centroids (black dots) at the average of the two calibration coordinates for each tile. C,D. For each point in eye coordinate space, we compute fractional board coordinates using equation 8 and display the angle formed by x and y (C, in hue) as well as the distance from the square center (D, using d = max(|x|, |y|), in grayscale). The regions in eye tracker space that lie outside the board edges is colored white. Note the correspondence between the Voronoi tesselation centroids and edges with the pinwheels and discontinuities in these maps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head>Figure 18 :</head><label>18</label><figDesc>Coefficients in a linear regression predicting participants' attentional distribution from the distribution of squares that the model includes in its principal variation at each depth. Error bars denote mean and standard error across participants. positions from the eye tracking data, selected using the same method as in S7, in which the No feature drop model assigns low probability to the participant's move. Upon inspection, we notice that these are all positions in which an immediate 4-in-a-row is possible for the participant or their opponent, and the model's preferred move is to either complete this threat, or block it. However, the participant fails to do so. On the right column,Fig S19shows the participant's eye movements while contemplating their move in these positions. Indeed, in 4 out of 5 positions, participants spend no time whatsoever looking at the square preferred by the model, and in the remaining one (4th row), the participant looks at the relevant square but it is not their main focus of attention. Thus, this analysis suggests that positions in which the model identifies dropped features are likely instances where the participant failed to spot a particular pattern on the board.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>12Figure 19 :</head><label>19</label><figDesc>Experience-dependent performance gains are mediated by metricsTo demonstrate that the derived metrics of planning depth, feature drop rate and heuristic quality are sufficient to capture experience-dependent changes in playing strength, we perform a linear regression predicting the Elo rating of participants in the learning experiment from the derived Same asFig S9, but onlyshowing the main model, and using the probability of the human move (circle) as the metric (red shading).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 20 :</head><label>20</label><figDesc>A. Predicted vs observed Elo ratings in a linear regression predicting Elo rating from derived metrics of planning depth, feature drop rate and heuristic quality. B. Predicted change in Elo rating across sessions using coefficients from the regression in A., combined with the empirical change in the derived metrics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head>Figure 21 :</head><label>21</label><figDesc>A. Planning depth vs Elo rating of all participants in the learning (green) and time pressure experiments (purple). B.-C. Same, for feature drop rate and heuristic quality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head>FigFigure 22 :Figure 23 :</head><label>2223</label><figDesc>S22A shows the average response time for each session in the learning experiment. Participants play slightly faster in later sessions. Therefore, our finding of increased planning in later sessions is not confounded by increases in thinking time. Instead, people plan more while using less time. A. Response time for participants in each session of the learning experiment. Error bars denote mean and standard error across all positions encountered by all participants. B. Same, for users in each block of games in the mobile experiment. Response time for participants in each time limit condition in the time pressure experiment. Error bars denote mean and standard error across all positions encountered by all users.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><head>Fig</head><label></label><figDesc>S23 shows the average response time for each time limit condition in the time pressure experiment. The time limit manipulation is effective at increasing participants' response times, even though they use only a fraction of the available time on average.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>Figure 25 :</head><label>25</label><figDesc>A.-C. Reconstruction accuracy in the memory experiment. Each panel shows a scatterplot for a different feature, were each point represents a board position which contains one or more features of that type, the x-coordinate the average probability for experts to correctly reconstruct those features, and the y-coordinate the same but for novices. Positions from games are colored pink, randomly scrambled positions in gray. D.-F. Same, for the time of first reconstruction. G.-I. Same, for the time of first reconstruction relative to the total trial duration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Playing strength estimation using Bayeselo To estimate a player's playing strength from games against computer opponents, we use Elo ratings[45], implemented using the publicly available program Bayeselo[57]. To measure Elo ratings of all players in all experiments against a common baseline, we run Bayeselo on a database containing all human-vs-computer games and a simulated computer-vs-computer tournament, in which each computer plays once against every other computer, including itself.</figDesc><table><row><cell>2 Analysis methods</cell></row><row><cell>2.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Upon initialization, the value of a new node is set by calling the feature-based evaluation function. However, this value changes as the algorithm investigates the consequences of future play from that state. The algorithm starts with a single-node decision tree and gradually grows the tree. Each iteration, the algorithm selects a leaf node, expands it by adding one child node each for a number of candidate moves, and backpropagates the value of these new nodes recursively into the leaf node as well as its parents.</figDesc><table><row><cell>Algorithm 1: MakeMove(State s)</cell></row><row><cell>if Lapse(λ) then</cell></row><row><cell>return RandomMove(s);</cell></row><row><cell>else</cell></row><row><cell>DropFeatures(δ);</cell></row><row><cell>root ←node(s); while !Stop(γ) and !Determined(root) do</cell></row><row><cell>n ←SelectNode(); ExpandNode(n);</cell></row><row><cell>Backpropagate(n);</cell></row><row><cell>end</cell></row><row><cell>end</cell></row><row><cell>return argmax c∈children(root) c.val;</cell></row></table><note>and "passive" features. For example, a black three-in-a-row feature signals an immediate win on the black's move, but not on white's. The last term N (0, 1) represents additive Gaussian noise with mean zero and unit variance. Search algorithm. The search algorithm constructs a decision tree, consisting of nodes that contain a state s, the color of the active player in that state and a value associated to the state.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Restricting ourselves to only models with analytical likelihoods would limit the types of models that one can consider, particularly in regards to the noise structure. Instead, we estimate the log-likelihood with inverse binomial sampling (IBS)[59,<ref type="bibr" target="#b41">42]</ref>, a method that estimates the loglikelihood by comparing the data to simulated data generated from the model. IBS is unbiased but its estimates are noisy. Moreover, we cannot calculate gradients of the log-likelihood, so we optimize the log-likelihood with multilevel coordinate search [60], a gradient-free algorithm.</figDesc><table><row><cell>To reduce overfitting, we compare models with 5-fold cross-validation.</cell></row><row><cell>The fitting pipeline is computationally expensive, and fitting one participant's data for a</cell></row></table><note>single model requires approximately 10 14 floating point operations. We perform the model fits on the NYU high performance cluster (Intel Xeon E5-2690v2 CPUs 3.0GHz) with a parallel implementation of IBS, which uses 20 cores. On our hardware, fitting takes approximately 1 hour for one participant and one model. In this article, we fit all 22 models on 330 data sets, and the main model on an additional 5,000 data sets. The computational expense of model fitting implies that some common statisti- cal analyses of model reliability like parameter and model recovery are intractable. Therefore, in section S4, we assess the reliability and robustness of our modeling methods using less com- putationally expensive methods.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Likelihood ratio test between the model in table 1, and a restricted regression without the fixed effect of session number.</figDesc><table><row><cell>Fixed effects:</cell><cell cols="3">Estimate Std. Error T value</cell></row><row><cell>Intercept</cell><cell cols="2">5.23508 0.24443</cell><cell>21.418</cell></row><row><cell cols="3">Session number 0.25477 0.06056</cell><cell>4.207</cell></row><row><cell cols="3">Random effects: Variance Std.Dev.</cell></row><row><cell>Participant</cell><cell>1.132</cell><cell>1.064</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell cols="4">Without session number 515.10 524.13 -254.55 509.10</cell></row><row><cell>With session number</cell><cell cols="3">500.47 512.51 -246.23 492.47</cell><cell>16.637 1</cell><cell>&lt; 0.001</cell></row></table><note>Coefficients in a linear mixed-effects regression analysis predicting planning depth in the learning experiment treating session number as a continuous predictor and controlling for participant-specific effects using random intercepts.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Likelihood ratio test between the model in table 3, and a restricted regression without the fixed effect of session number.</figDesc><table><row><cell>Fixed effects:</cell><cell>Estimate</cell><cell>Std. Error T value</cell></row><row><cell>Intercept</cell><cell cols="2">0.221553 0.011568 19.153</cell></row><row><cell cols="3">Session number -0.011932 0.002796 -4.267</cell></row><row><cell cols="2">Random effects: Variance</cell><cell>Std.Dev.</cell></row><row><cell>Participant</cell><cell cols="2">0.002607 0.05106</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Likelihood ratio test between the model in table 5, and a restricted regression without the fixed effect of session number.</figDesc><table><row><cell>Fixed effects:</cell><cell>Estimate</cell><cell>Std. Error T value</cell></row><row><cell>Intercept</cell><cell cols="2">0.535416 0.008634 62.01</cell></row><row><cell cols="3">Session number -0.006702 0.002025 -3.31</cell></row><row><cell cols="2">Random effects: Variance</cell><cell>Std.Dev.</cell></row><row><cell>Participant</cell><cell cols="2">0.001499 0.03871</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell cols="4">Without session number -506.13 -497.10 256.07 -512.13</cell></row><row><cell>With session number</cell><cell cols="3">-514.70 -502.66 261.35 -522.70</cell><cell>10.569 1</cell><cell>0.00115</cell></row></table><note>Coefficients in a linear mixed-effects regression analysis predicting heuristic quality in the learning experiment treating session number as a continuous predictor and controlling for participant-specific effects using random intercepts.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Likelihood ratio test between the model in table 7, and a restricted regression without the fixed effect of session number.</figDesc><table><row><cell>Fixed effects:</cell><cell cols="3">Estimate Std. Error T value</cell></row><row><cell>Intercept</cell><cell cols="2">-42.017 30.823</cell><cell>-1.363</cell></row><row><cell>Time limit</cell><cell>-1.999</cell><cell>1.599</cell><cell>-1.250</cell></row><row><cell cols="3">Random effects: Variance Std.Dev.</cell><cell></cell></row><row><cell>Participant</cell><cell>15080</cell><cell>122.80</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell cols="4">Without time limit 311.47 318.97 -152.74 305.47</cell></row><row><cell>With time limit</cell><cell cols="3">307.95 317.95 -149.97 299.95</cell><cell>5.5237 1</cell><cell>0.01876</cell></row></table><note>Coefficients in a linear mixed-effects regression analysis predicting planning depth in the time pressure experiment treating time limit as a continuous predictor and controlling for participant-specific effects using random intercepts.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Likelihood ratio test between the model in table 11, and a restricted regression without the fixed effect of time limit.</figDesc><table><row><cell>Fixed effects:</cell><cell>Estimate Std. Error T value</cell></row><row><cell>Intercept</cell><cell>0.238714 0.019526 12.225</cell></row><row><cell>Time limit</cell><cell>0.002745 0.001018 2.698</cell></row><row><cell cols="2">Random effects: Variance Std.Dev.</cell></row><row><cell>Participant</cell><cell>0.006002 0.07747</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 13 :Table 14 :</head><label>1314</label><figDesc>Coefficients in a linear mixed-effects regression analysis predicting feature drop rate in the time pressure experiment treating time limit as a continuous predictor and controlling for participant-specific effects using random intercepts. Likelihood ratio test between the model in table 13, and a restricted regression without the fixed effect of time limit.</figDesc><table><row><cell cols="10">we can write the number of non-terminal states as</cell></row><row><cell>N =</cell><cell>36 n=0</cell><cell>N s</cell><cell>n 2</cell><cell>,</cell><cell>n 2</cell><cell>p nt</cell><cell>n 2</cell><cell>,</cell><cell>n 2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 15 :</head><label>15</label><figDesc>Coefficients in a linear mixed-effects regression analysis predicting heuristic quality in the mobile data treating as a continuous predictor and controlling for participant-specific effects using random intercepts.</figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell cols="4">Without time limit -309.12 -301.62 157.56 -315.12</cell></row><row><cell>With time limit</cell><cell cols="3">-309.43 -299.43 158.72 -317.43</cell><cell>2.3083 1</cell><cell>0.1287</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 16 :</head><label>16</label><figDesc>Likelihood ratio test between the model in table 15, and a restricted regression without the fixed effect of time limit.</figDesc><table><row><cell>Fixed effects:</cell><cell>Estimate</cell><cell cols="2">Std. Error T value</cell></row><row><cell>Intercept</cell><cell cols="2">-69.75210 4.13493</cell><cell>-16.87</cell></row><row><cell>Games played</cell><cell>1.12853</cell><cell>0.04357</cell><cell>25.90</cell></row><row><cell cols="2">Random effects: Variance</cell><cell>Std.Dev.</cell><cell></cell></row><row><cell>Participant</cell><cell>8743</cell><cell>93.51</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 17 :</head><label>17</label><figDesc>Coefficients in a linear mixed-effects regression analysis predicting Elo rating in the mobile experiment treating games played as a continuous predictor and controlling for participant-specific effects using random intercepts.</figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell>With games played</cell><cell cols="3">61400 61420 -30697 61394</cell></row><row><cell cols="4">Without games played 60782 60808 -30387 60774</cell><cell>620.27 1</cell><cell>&lt; 0.001</cell></row></table><note>where • and • denote the ceiling and floor functions, respectively, N s (m, n) is the num- ber of distinct configurations of m black and n white pieces on the board and p nt (m, n) is the</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 18 :</head><label>18</label><figDesc>Likelihood ratio test between the model in table 17, and a restricted regression without the fixed effect of games played.</figDesc><table><row><cell>Fixed effects:</cell><cell cols="2">Estimate Std. Error T value</cell></row><row><cell>Intercept</cell><cell cols="2">5.197720 0.072888 71.31</cell></row><row><cell>Games played</cell><cell cols="2">0.010814 0.001004 10.77</cell></row><row><cell cols="3">Random effects: Variance Std.Dev.</cell></row><row><cell>Participant</cell><cell>0.8798</cell><cell>0.938</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 19 :</head><label>19</label><figDesc>Coefficients in a linear mixed-effects regression analysis predicting planning depth in the mobile experiment treating games played as a continuous predictor and controlling for participant-specific effects using random intercepts.</figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell cols="4">Without games played 22015 22034 -11004 22009</cell></row><row><cell>With games played</cell><cell cols="3">21902 21928 -10947 21894</cell><cell>114.44 1</cell><cell>&lt; 0.001</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 20 :</head><label>20</label><figDesc>Likelihood ratio test between the model in table<ref type="bibr" target="#b18">19</ref>, and a restricted regression without the fixed effect of games played.</figDesc><table><row><cell>Fixed effects:</cell><cell>Estimate</cell><cell>Std. Error</cell><cell>T value</cell></row><row><cell>Intercept</cell><cell>0.2950</cell><cell>0.003511</cell><cell>84.027</cell></row><row><cell>Games played</cell><cell cols="3">−2.578 • 10 −4 4.659 • 10 −5 -5.533</cell></row><row><cell cols="2">Random effects: Variance</cell><cell>Std.Dev.</cell><cell></cell></row><row><cell>Participant</cell><cell>0.002772</cell><cell>0.05265</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 21 :</head><label>21</label><figDesc>Coefficients in a linear mixed-effects regression analysis predicting feature drop rate in the mobile experiment treating games played as a continuous predictor and controlling for participant-specific effects using random intercepts.</figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell cols="4">Without games played -8553.7 -8534.1 4279.8 -8559.7</cell></row><row><cell>With games played</cell><cell cols="3">-8582.2 -8556.1 4295.1 -8590.2</cell><cell>30.508 1</cell><cell>&lt; 0.001</cell></row></table><note>probability that a random configuration with that number of pieces does not contain 4-in-a- row patterns. The number of possible configurations is given by the multinomial coefficient</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 22 :</head><label>22</label><figDesc>Likelihood ratio test between the model in table 21, and a restricted regression without the fixed effect of games played.</figDesc><table><row><cell>Fixed effects:</cell><cell>Estimate</cell><cell>Std. Error</cell><cell>T value</cell></row><row><cell>Intercept</cell><cell>0.4774</cell><cell>0.003345</cell><cell>142.7</cell></row><row><cell>Games played</cell><cell cols="3">6.115 • 10 −4 4.245 • 10 −5 14.4</cell></row><row><cell cols="2">Random effects: Variance</cell><cell>Std.Dev.</cell><cell></cell></row><row><cell>Participant</cell><cell>0.003261</cell><cell>0.0571</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 23 :</head><label>23</label><figDesc>Coefficients in a linear mixed-effects regression analysis predicting heuristic quality in the mobile experiment treating games played as a continuous predictor and controlling for participant-specific effects using random intercepts.</figDesc><table><row><cell></cell><cell>AIC</cell><cell>BIC</cell><cell cols="2">Loglik Deviance χ 2</cell><cell>DoF p</cell></row><row><cell cols="4">Without games played -9084.6 -9065.0 4545.3 -9090.6</cell></row><row><cell>With games played</cell><cell cols="3">-9284.9 -9258.9 4646.5 -9292.9</cell><cell>202.34 1</cell><cell>&lt; 0.001</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 24 :</head><label>24</label><figDesc>Likelihood ratio test between the model in table 23, and a restricted regression without the fixed effect of games played. , which we can evaluate analytically. To estimate the probability that a random state is non-terminal, we use a Monte Carlo procedure, generating random configurations and counting how many contain 4-in-a-row patterns. This results in an estimate of 1.1812 • 10 16 ± 3.1 • 10 13 non-terminal states.</figDesc><table><row><cell>N s (m, n) =</cell><cell>36! m!n!(36−m−n)!</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Zeyan Shu for piloting an early version of the experiment and Feroz Khalidi for assistance with data collection. We thank Andra Mihali, Aspen Yoo, Maija Honig, Luigi Acerbi, </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p>All authors contributed to conceptualization of the research. BvO, GG, IK and YL collected data. BvO, GG, IK, YL and ZB developed software, methodology and performed analysis.</p><p>BvO, IK and WJM wrote the paper. WJM supervised the project and acquired funding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional Information</head><p>Supplementary Information is available for this paper.</p><p>Correspondence and requests for materials should be addressed to basvanopheusden@nyu.edu Reprints and permissions information is available at www.nature.com/reprints.  <ref type="table">Table 25</ref>: Reconstruction probabilities in the memory and reconstruction experiment. Each row indicates the probability distribution of the identity of the reconstructed piece (black, white or empty) for a given piece identity, condition and participant group. <ref type="figure">Figure S24A</ref> shows a visual summary of this data using three error rate metrics. First, the missed piece error rate is the probability for a participant to fail to place a piece on a square during reconstruction given that a piece was present. Second, the extra piece error rate is the probability for a participant to place a piece on a square that was originally empty. Finally, and the wrong color error is the probability to place a piece of the wrong color, given that the square was originally occupied. Although experts are slightly worse than novices in the extra piece error rate (β = 0.0071 ± 0.0031, p = 0.049), experts substantially outperform novices in the missed piece (β = 0.037 ± 0.006, p &lt; 0.001) and the wrong color rate (β = 0.019 ± 0.003, p &lt; 0.001). However, <ref type="figure">Figure S24B</ref> shows that experts also take more time to reconstruct pieces (β = 2.7±0.57, p &lt; 0.001), meaning that the performance result could reflect a speed-accuracy trade-off as opposed to an overall improvement.</p><p>To gain more insight into the relationship between reconstruction speed, accuracy and expertise, we investigate how quickly and accurately participants reconstruct game-relevant features, in particular the connected 2-in-a-row, unconnected 2-in-a-row and 3-in-a-row feature</p><p>Original Board Reconstruction Novices Reconstruction Experts <ref type="figure">Figure 26</ref>: Example position of the memory and reconstruction experiment. The original board contains a 3-in-a-row feature on the bottom row (yellow shading). In the reconstructions, each circle indicates the distribution of pieces placed by different observers, with the angles of the gray, black and white wedges indicating the probability for that square to be empty, contain a black or contain a white piece, respectively. Novices correctly reconstruct the 3-in-a-row feature 42.1% of the time, but experts 84.2%.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loglik</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Het denken van den schaker: een experimenteel-psychologische studie (Noord-Hollandsche Uitgevers Maatschappij</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>De Groot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Perception in chess</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Adaptive expert decision making: Skilled chess players search more and deeper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Campitelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The effects of time pressure on chess skill: an investigation into fast and slow processes underlying expert performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Harreveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="591" to="597" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Chess players&apos; eye movements reveal rapid recognition of complex visual patterns: Evidence from a chess-related visual search task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Reingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="4" to="4" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Expert chess memory: Revisiting the chunking hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="225" to="255" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mechanisms and neural basis of object and pattern recognition: a study with chess experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bilalić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Erb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Grodd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Entanglement of perception and reasoning in the combinatorial game of chess: Differential errors of strategic reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Linhares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E T</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Systems Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="72" to="86" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Expertise in chess: The balance between knowledge and search. Toward a general theory of expertise: Prospects and limits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Charness</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="39" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visuospatial and articulatory interference in chess players&apos; information intake</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saariluoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="77" to="89" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The psychology of chess skill</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Holding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>Lawrence Erlbaum</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Evaluation factors in human tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Holding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="103" to="108" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards a chess program based on a model of human memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in computer chess</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="35" to="60" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A pattern-recognition theory of search in expert problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Thinking &amp; Reasoning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="291" to="313" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Counting backward during chess move choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Holding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the Psychonomic Society</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="421" to="424" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Theories of chess skill</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Holding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="10" to="16" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Expertise in chess and bridge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Charness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Complex information processing</title>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="203" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-step planning in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Venditto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="29" to="39" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1704</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bonsai trees in your head: how the pavlovian system sculpts goaldirected choices by pruning decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Huys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1002410</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interplay of approximate planning strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Huys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="3098" to="3103" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Prospective optimization with limited resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poizner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gepshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1004501</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Prospection, perseverance, and insight in sequential behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kolling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scholl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chekroud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Trier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Rushworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1069" to="1082" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The 11-20 money request game: a level-k reasoning study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Economic Review</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="3561" to="3573" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A cognitive hierarchy model of games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Chong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="861" to="898" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hippocampal place-cell sequences depict future paths to remembered goals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">497</biblScope>
			<biblScope unit="page">74</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Vicarious trial and error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Redish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">147</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Planning at decision time and in the background during spatial navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Donnarumma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maisto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoianov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="69" to="76" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dorsal hippocampus contributes to modelbased planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Brody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">1269</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Chronic exposure to methamphetamine disrupts reinforcement-based decision making in rats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Groman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="770" to="780" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The anterior cingulate cortex predicts future states to mediate model-based action selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Combinatorial games: tic-tac-toe theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">114</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Tasks for aligning human and machine planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Opheusden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press Cambridge</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Planning as heuristic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="5" to="33" />
			<date type="published" when="2001-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generalized best-first search strategies and the optimality of a</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dechter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="505" to="536" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rational use of cognitive resources: Levels of analysis between the computational and the algorithmic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="217" to="229" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A resource-rational analysis of human planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CogSci</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Resource-rational analysis: understanding human cognition as the optimal use of limited computational resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">60</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Computational rationality: Linking mechanism and behavior through bounded utility maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="279" to="311" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A feature-integration theory of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gelade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="97" to="136" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unbiased and efficient log-likelihood estimation with inverse binomial sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Opheusden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Acerbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1008483</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization for model fitting with bayesian adaptive direct search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Acerbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1836" to="1846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Computing machinery and intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page">433</biblScope>
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The rating of chessplayers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Elo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
			<publisher>Arco Pub</publisher>
		</imprint>
	</monogr>
	<note>past and present</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Visualization, pattern recognition, and forward search: Effects of playing speed and sight of the position on grandmaster chess errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Chabris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="637" to="648" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Time pressure, skill, and move quality in chess. The American journal of psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Calderwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Crandall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="481" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Adaptive planning in human search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Krusche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioRxiv</title>
		<imprint>
			<biblScope unit="volume">268938</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Investigating human priors for playing video games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.10217</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The role of deliberate practice in chess expertise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Charness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tuffiash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krampe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vasyukova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="151" to="165" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Superhuman ai for multiplayer poker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sandholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="page" from="885" to="890" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
