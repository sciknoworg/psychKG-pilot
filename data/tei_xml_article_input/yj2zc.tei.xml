<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Linear integration and lexicographic models of choice: A cue weight learning perspective</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrvoje</forename><surname>Stojić</surname></persName>
							<email>h.stojic@ucl.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Olsson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pantelis</forename><forename type="middle">P</forename><surname>Analytis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Hogarth</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gael</forename><surname>Le Mens</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Rieskamp</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Pachur</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Pompeu Fabra University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Santa Fe Institute</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Economics and Business</orgName>
								<orgName type="department" key="dep2">Fe Institute; Pantelis P. Analytis, Danish Institute of Advanced Studies and Department of Management and Marketing</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<addrLine>Pom-peu Fabra University; Henrik Olsson</addrLine>
									<settlement>Santa</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Ministerio de Educación</orgName>
								<address>
									<addrLine>Cultura y De-porte</addrLine>
									<postCode>FPU12/05859</postCode>
									<settlement>Grant</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="laboratory">Max Planck UCL Centre for Computational Psychia-try and Ageing Research</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>10-12 Rus-sell Square</addrLine>
									<postCode>WC1B 5EH</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Linear integration and lexicographic models of choice: A cue weight learning perspective</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1037/xlm0000853</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>decision making</term>
					<term>cue weight learning</term>
					<term>heuristics</term>
					<term>strategy selection</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Choosing between options characterized by multiple cues can be a daunting task. People may integrate all information at hand or just use lexicographic strategies that ignore most of it. Notably, integrative strategies require knowing exact cue weights, whereas lexicographic heuristics can operate by merely knowing the importance order of cues. Here we study how using integrative or lexicographic strategies interacts with learning about cues. In our choicelearning-estimation paradigm people first make choices, learning about cues from qualities of chosen options, and then estimate qualities of new options. We developed delta-elimination (DE), a new lexicographic strategy that generalizes previous heuristics to any type of environment, and compared it to the integrative weighted-additive (WADD) strategy. Our results show that participants learned cue weights regardless of the choice strategy employed. The group of people best described by the DE strategy learned cue weights, exactly like the group best described by the WADD. Still, there was an interaction between the adopted strategy and the cue weight learning process: the DE users learned cue weights slower than the WADD users. This work advances the study of lexicographic choice strategies, both empirically and theoretically, and deepens our understanding of strategy selection, in particular the interaction between the strategy used and learning the structure of the environment.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Imagine you are an avid movie-goer and every couple of weeks you wind up in the local cinema looking for a good flick. There are several movies from which you can choose at each cinema visit, some that you would relish and others that you would loathe. Luckily, you have several useful pieces of information at your disposal to guide your choice: you can look at the average movie review ratings on a popular movie review website, the number of reviews, the director, the leading actor and the length of the movie. How do you go about picking the movie you will like the most, and how does this choice process interacts with learning how useful various pieces of information are?</p><p>There are various ways in which people can use the available cues -pieces of information predictive of a variable of interest, a criterion variable -to choose among a number of different options. First, you could form an estimate of criterion value of each option by weighing and adding its cues and then choose the option that you gauge to have the highest value. This choice process summarizes the so-called weighted-additive strategy (WADD; <ref type="bibr" target="#b4">Brehmer, 1994;</ref><ref type="bibr" target="#b58">Payne, Bettman, &amp; Johnson, 1993)</ref>. Alternatively, you could order cues on some measure of cue importance, compare the options on the first ranking cue and pick the one excelling on that cue (Take-the-best, see <ref type="bibr" target="#b20">Gigerenzer &amp; Goldstein, 1996;</ref><ref type="bibr" target="#b25">Hogarth &amp; Karelaia, 2005a)</ref> or eliminate options that are clearly inferior on that cue (Elimination-by-aspects, see <ref type="bibr" target="#b26">Hogarth &amp; Karelaia, 2005b;</ref><ref type="bibr" target="#b86">Tversky, 1972)</ref>. If there is no difference or no noticeable difference on that cue (∆-inference, see <ref type="bibr" target="#b45">Luan, Schooler, &amp; Gigerenzer, 2014)</ref>, you could move to the next cue in the order and repeat these steps until you reach a decisive piece of information or are left with only one option, at which point you choose that option. In sequential search processes like these, choices are commonly based on the few decisive factors looked up first and, as a result, much of the information is ignored. Although the WADD strategy comes with the promise of accurate choices, it is also accompanied with a hefty mental effort price tag. Without compromising much on choice quality (or even at all, see <ref type="bibr" target="#b19">Gigerenzer &amp; Brighton, 2009;</ref><ref type="bibr" target="#b25">Hogarth &amp; Karelaia, 2005a)</ref>, lexicographic strategies can save a lot of cognitive effort, especially when facing demanding environments consisting of many options described on multiple dimensions.</p><p>Integrative strategies and lexicographic heuristics alike, rely on knowledge about the structure of the environment to attain their predictive potential. Yet the type of knowledge they require is fundamentally different. Integrative strategies require precise values of cue weight, representing (partial) correlations between each cue and the criterion value. By contrast, lexicographic strategies need merely the order of cues, an estimate of how the cues rank in their ability to predict the criterion. Operating on cue orders has been argued to be one of the main advantages of lexicographic strategies (e.g. <ref type="bibr" target="#b19">Gigerenzer &amp; Brighton, 2009;</ref><ref type="bibr" target="#b85">Todd &amp; Gigerenzer, 2000)</ref>. The cue order approximates potentially complex cue-criterion relationships rather than trying to learn them precisely, such as with cue weights. Relying on cue order may prevent overfitting which tends to lead to worse performance when choosing among novel options. This argument has been a central-piece for explaining the surprising performance of the TTB heuristic <ref type="bibr" target="#b19">(Gigerenzer &amp; Brighton, 2009;</ref><ref type="bibr" target="#b85">Todd &amp; Gigerenzer, 2000)</ref>. Taken together, this implies an interaction between the strategy people use and the type of knowledge they acquire about the structure of the environment. People employing integrative strategies should learn cue weights, while those employing lexicographic strategies should learn cue order.</p><p>Hitherto, researchers have investigated the strategies that people should and do use (e.g., <ref type="bibr" target="#b20">Gigerenzer &amp; Goldstein, 1996;</ref><ref type="bibr" target="#b25">Hogarth &amp; Karelaia, 2005a;</ref><ref type="bibr" target="#b47">Martignon &amp; Hoffrage, 2002;</ref><ref type="bibr" target="#b58">Payne et al., 1993;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006)</ref>. However, the interaction between choice strategies and learning about the environment has not been investigated so far. Our primary goal is to address this conceptual and empirical gap. We study the knowledge that people using either integrative strategies or lexicographic heuristics acquire about the structure of the environment-whether they learn cue weights or cue order. We achieve that by introducing a new choice-learning-estimation paradigm where participants first complete a choice task, in which they simultaneously make choices and learn about cue weights or cue order through criterion value feedback. Using criterion value feedback allowed us to introduce a task where participants estimated the criterion values of new options. This estimation task immediately followed the choice task, and crucially, enabled us to identify whether participants learned the cue weights or only the cue order.</p><p>While there are no reasons to expect people using integrative strategyies to learn cue order, there are several good reasons why people using lexicographic strategies might learn cue weights rather than only order. First, learning cue weights provides people with a more flexible handle on strategy selection-equipped with cue weights people can switch between integrative and lexicographic strategies at will. <ref type="bibr" target="#b27">Hogarth and Karelaia (2007)</ref> showed that such flexibility can pay off: it is beneficial to adopt TTB at the beginning of a task, while cue weight knowledge is still poor, and switch to WADD later on when it is sufficiently developed. People then just need to learn to relate strategies with the environments where these strategies excel <ref type="bibr" target="#b42">(Lieder &amp; Griffiths, 2017;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006;</ref><ref type="bibr" target="#b80">Stojić, Olsson, &amp; Speekenbrink, 2016)</ref>. Second, cue weights can allow people to generalize to other types of tasks, beyond the choice task. In choice situations where criterion feedback is available cue weights allow predicting criterion values, something that is hard to achieve with cue order knowledge. Predicting the criterion value of an option has value of its own. For example, people might want to communicate their predictions to others, say quality of the movie <ref type="bibr" target="#b0">(Analytis, Barkoczi, &amp; Herzog, 2018)</ref>. Benefits of this type of generalization might be large enough to make cue weight learning a default whenever possible. Finally, cue weight learning may provide an effective shortcut for learning cue orders, as the latter can be easily obtained from cue weights. A convincing theory for learning cue order directly is still lacking and most methods have been shown to be data hungry, improving strategy performance at a slow pace <ref type="bibr" target="#b15">Dieckmann and Todd (2004)</ref>; <ref type="bibr" target="#b84">Todd and Dieckmann (2005)</ref>. Algorithms for learning cue weights on a trial-by-trial basis have a long tradition <ref type="bibr" target="#b69">(Rosenblatt, 1958;</ref><ref type="bibr" target="#b69">Rumelhart, Hinton, &amp; Williams, 1986;</ref><ref type="bibr" target="#b91">Widrow &amp; Hoff, 1960)</ref> and have been tested as models of human category and function learning <ref type="bibr" target="#b23">(Gluck &amp; Bower, 1988;</ref><ref type="bibr" target="#b32">Kelley &amp; Busemeyer, 2008;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010)</ref>, with convincing results about the match between the model and human behavior. Investigating the interplay between choice strategies and learning about the environment stands to improve our understanding of the nature of the strategy selection process. Obtaining a result that people using lexicographic strategies learn only cue orders would reveal a profound influence that choice strategies have on what people learn about the world. A result that people learn cue weights would on the other hand refine our view of strategy selection: people may choose strategies depending on the the weights they have learned and what these weights reveal about the choice setting.</p><p>Our second goal is to develop and test a lexicographic strategy that is well equipped for dealing with challenging choice environments. Most studies on inference, choice and learning have focused on problems with binary cues and two options <ref type="bibr" target="#b20">(Gigerenzer &amp; Goldstein, 1996;</ref><ref type="bibr" target="#b54">Nosofsky &amp; Bergert, 2007;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006)</ref>. In many real world settings, by contrast, people can choose among numerous options described by a number of cues, many of which are continuous (i.e. average movie rating or distance to the cinema). To increase the external validity in the study of lexicographic strategies we also need to devise heuristics that can cope with such challenging environments. Therefore, in our study we focus on an environment with three options described by continuous cues and criterion values, in which heuristics have not been put to test before.</p><p>What would be a good representative of lexicographic strategies that could perform competitively in settings with continuous cues and more than two options, and can match the ubiquitous character of WADD that can be applied across decision making settings? The TTB heuristic was developed for binary-valued cues <ref type="bibr" target="#b22">(Gigerenzer, Hoffrage, &amp; Kleinbölting, 1991</ref>) and collapses to a single-cue heuristic in environments with continuous cues. The ∆-inference heuristic effectively generalizes the principles of TTB to continuous environments by using minimal noticeable differences to control search <ref type="bibr" target="#b45">(Luan et al., 2014)</ref>. Still, the strategy can only be used to choose between two options. We propose deltaelimination (DE), a new lexicographic strategy that generalizes ∆-inference to any number of options by using an elimination mechanism, akin to that used in the eliminationby-aspects heuristic <ref type="bibr" target="#b86">(Tversky, 1972)</ref>. Since DE strategy nests ∆-inference and TTB, methods and insights produced in this study can be carried over to binary choice (or inference) problems with binary or continuous cues. We evaluate the DE strategy empirically as well, by comparing it to the WADD strategy in fitting choices of participants in our experiment. This development contributes to heuristic theories of choice and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice strategies and learning the structure of the environment</head><p>Over the last decades, mathematical models and simulation studies have been used to evaluate the performance of different strategies across decision making contexts (e.g,. <ref type="bibr" target="#b20">Gigerenzer &amp; Goldstein, 1996;</ref><ref type="bibr" target="#b25">Hogarth &amp; Karelaia, 2005a)</ref>. Depending on the structure of the (usually linear) environment (e.g., <ref type="bibr" target="#b26">Hogarth &amp; Karelaia, 2005b</ref><ref type="bibr" target="#b47">Martignon &amp; Hoffrage, 2002)</ref>, and the cost of cognitive processing (e.g., <ref type="bibr" target="#b42">Lieder &amp; Griffiths, 2017;</ref><ref type="bibr" target="#b58">Payne et al., 1993)</ref> people might be well-advised to rely on integrative WADD or lexicographic heuristic strategies. Experimental studies have followed up, assessing which of these strategies people actually use when they solve choice problems. In a typical experiment, participants are exposed to many trials with two or more options that are described by different cues, more or less predictive of the criterion value of the considered options. For instance, people may be asked to choose between two companies, that differ in their profitability <ref type="bibr" target="#b67">(Rieskamp &amp; Otto, 2006)</ref>, described by different cue values on a number of informative dimensions (e.g., capital structure, financial resources, efficiency).</p><p>When it comes to knowledge about the structure of environment, a crucial input for integrative and lexicographic strategies respectively, simulation studies directly endowed the models with the required information (e.g. learning optimal cue weights or orders from data) and did not specify the exact learning process (e.g., <ref type="bibr" target="#b20">Gigerenzer &amp; Goldstein, 1996;</ref><ref type="bibr" target="#b25">Hogarth &amp; Karelaia, 2005a</ref><ref type="bibr">Şimşek &amp; Buckmann, 2015)</ref>. In a similar vein, most empirical studies explicitly provided information about cue weights or order (e.g., <ref type="bibr" target="#b5">Bröder, 2000;</ref><ref type="bibr" target="#b7">Bröder &amp; Schiffer, 2003a;</ref><ref type="bibr" target="#b48">Mata, Schooler, &amp; Rieskamp, 2007;</ref><ref type="bibr" target="#b52">Newell, Weston, &amp; Shanks, 2003;</ref><ref type="bibr" target="#b64">Rieskamp, 2006;</ref><ref type="bibr" target="#b66">Rieskamp &amp; Hoffrage, 2008;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006)</ref>. 1 There is only a handful of studies that did not explicitly provide information about the cue weights or order. In these studies participants had to learn cue weights or order through, either (i) feedback about whether their choices were correct or not <ref type="bibr" target="#b40">(Lee &amp; Cummins, 2004;</ref><ref type="bibr" target="#b50">Newell, Rakow, Weston, &amp; Shanks, 2004;</ref><ref type="bibr" target="#b54">Nosofsky &amp; Bergert, 2007;</ref><ref type="bibr">Pachur &amp; Olsson, 2012;</ref><ref type="bibr" target="#b62">Rakow, Newell, Fayers, &amp; Hersby, 2005)</ref>, or (ii) feedback about both the choice correctness and the criterion values of the chosen option <ref type="bibr" target="#b9">(Bröder &amp; Schiffer, 2006a;</ref><ref type="bibr">Rakow, Hinvest, Jackson, &amp; Palmer, 2004)</ref>. Participants in these studies made better choices over time, a pattern that could be directly produced by learning either cue weights or cue orders. However, most of these studies did not examine the learning process beyond observing the raw learning effects, and focused on strategy selection instead <ref type="bibr" target="#b9">(Bröder &amp; Schiffer, 2006a;</ref><ref type="bibr" target="#b40">Lee &amp; Cummins, 2004;</ref><ref type="bibr" target="#b54">Nosofsky &amp; Bergert, 2007;</ref><ref type="bibr">Pachur &amp; Olsson, 2012)</ref>.</p><p>A small subgroup of these studies has examined learning in greater detail, but focused exclusively on cue order learning. For example, in their experiments <ref type="bibr" target="#b50">Rakow et al. (2004)</ref> and <ref type="bibr" target="#b50">Newell et al. (2004)</ref> compared the cue orders that people reported and people's information search to several objective statistics according to which people might be ordering <ref type="bibr">1</ref> Cue weights in many of these studies were represented with cue validities, a measure of cue goodness in choice environments where choice correctness information is available, rather than criterion value of the options. Cue validity is usually computed as R/(R + W), where R and W are the number of correct and incorrect choices, respectively, based on the cue. the cues -cue validity, success or discrimination rate ordering. They found that success measure corresponds better to people's self-reports and search patterns. Finally, <ref type="bibr" target="#b62">Rakow et al. (2005)</ref> compared the learned cue order to expected information gain, an information theory measure, and simple cue-outcome correlations, alongside the usual cue validity ordering. They found that cue-outcome correlation ordering corresponded the best to the ordering reported in the experiments. None of these studies compared learning between different strategy users, how strategy selection might interact with what is being learned or interact with the learning process. They also did not postulate a mechanism of how cue weights or cue order might be learned.</p><p>The lack of a convincing theory for learning cue orders has been the subject of an important critique of the TTB heuristic. <ref type="bibr" target="#b72">Shanks and Lagnado (2000)</ref> opened the critique by suggesting that the TTB heuristic is deceptively simple, hiding its complexity in the knowledge of cue orders. <ref type="bibr" target="#b22">Gigerenzer et al. (1991)</ref> originally suggested that cue validities, and thereby order, might be learned by a simple frequency counting mechanism. Yet <ref type="bibr" target="#b29">Juslin and Persson (2002)</ref> argued that much effort is needed to order cues as many events have to be stored in memory (see also <ref type="bibr" target="#b16">Dougherty, Franco-Watkins, &amp; Thomas, 2008;</ref><ref type="bibr" target="#b49">Newell, 2005)</ref>. There have been several lines of research grappling with this critique. First, <ref type="bibr" target="#b15">Dieckmann and Todd (2004)</ref> studied a series of simple methods for learning cue order from data and found that although learning cue orders directly is in principle possible, numerous observations are required to improve strategy performance. More recently, Gigerenzer and colleagues (see <ref type="bibr" target="#b21">Gigerenzer, Hoffrage, &amp; Goldstein, 2008;</ref><ref type="bibr" target="#b28">Hutchinson &amp; Gigerenzer, 2005)</ref> pointed out that cue order knowledge is not necessarily driven by individual learning -it can be hard-coded by evolution, or transmitted socially. Short after, <ref type="bibr" target="#b17">Garcia-Retamero, Takezawa, and Gigerenzer (2009)</ref> showed experimentally that social knowledge can indeed be beneficial -imitating the best decision maker or majority substantially accelerates individual learning. Regardless of the benefits of social knowledge transmission, knowledge about cue orders still has to be learned by some individuals (see <ref type="bibr" target="#b68">Rogers, 1988)</ref>. In a different line of research, <ref type="bibr" target="#b31">Katsikopoulos, Schooler, and Hertwig (2010)</ref> have provided some evidence that cue order might not be that crucial for the accuracy of the TTB heuristic. When very small sample sizes were used to estimate cue order and directions (10 observations or fewer), the correctness of cue directions rather than order correlated highly with accuracy. The argument does not seem to hold for larger samples, however, and even in small samples some information about the cue order is needed for the TTB heuristic to achieve higher accuracy. In summary, these studies focused on identifying channels for acquiring cue order information other than individual learning <ref type="bibr" target="#b17">(Garcia-Retamero et al., 2009;</ref><ref type="bibr">Gigerenzer et al., 2008, except for Dieckmann and</ref><ref type="bibr" target="#b15">Todd (2004)</ref>) or argued order information is actually not needed <ref type="bibr" target="#b31">(Katsikopoulos et al., 2010</ref>). All of them ignored possible interaction with strategy selection. Given that some studies did observe individual learning effects, the question of how individual learning of the cue information required for their choice strategies interacts with strategy selection still remains pertinent.</p><p>A key missing ingredient for studying the interaction between strategy selection and learning are plausible mechanisms for learning cue weights and/or cue order. We looked for inspiration in neighboring fields. In statistics, the least-mean-squares (LMS) algorithm has been a popular formalization for updating regression (i.e. cue) weights with each observation; the algorithm achieves that by leveraging the discrepancies between predicted and observed outcomes <ref type="bibr" target="#b69">(Rumelhart et al., 1986;</ref><ref type="bibr" target="#b91">Widrow &amp; Hoff, 1960</ref>, often called the Widrow-Hoff or Delta rule). Studies of human category and function learning have demonstrated that the LMS model is a plausible model of human learning (e.g., <ref type="bibr" target="#b23">Gluck &amp; Bower, 1988;</ref><ref type="bibr" target="#b32">Kelley &amp; Busemeyer, 2008;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010)</ref>. The settings in which these LMS models have been applied are similar to multi-cue choice tasks used to study integrative and lexicographic strategies. For instance, <ref type="bibr" target="#b23">Gluck and Bower (1988)</ref> examined category learning in a task that presented stimuli described on four cues with binary cue values and provided correct/incorrect feedback. Participants had to learn the relationship between the cues and correct responses. Categorization task such as the one examined by Gluck and Bower and inference and choice tasks (i.e. city population task) that have been extensively used to test lexicographic heuristics <ref type="bibr" target="#b20">(Gigerenzer &amp; Goldstein, 1996)</ref> have the same zero-one error function (a categorization, inference or choice will be right or wrong). Further, <ref type="bibr" target="#b32">Kelley and Busemeyer (2008)</ref> and <ref type="bibr" target="#b75">Speekenbrink and Shanks (2010)</ref> examined how people learn functions when they are presented with a single stimulus per trial and they have access to multiple continuous-valued cues that they can use to predict a continuous criterion. In these tasks, the participants observed criterion value after each prediction, not unlike choice experiments where participants receive feedback about the criterion value on the chosen option (as in, for example <ref type="bibr" target="#b7">Bröder &amp; Schiffer, 2003a</ref><ref type="bibr" target="#b9">, 2006a</ref><ref type="bibr" target="#b27">Hogarth &amp; Karelaia, 2007)</ref>. In our study the LMS model learns cue weights based on observed cue and criterion values and cue order can be obtained as a byproduct of learning cue weights. Cue orders can be easily extracted by ordering absolute cue weight values. Thus, the LMS model provides an attractive alternative to learning cue orders directly <ref type="bibr" target="#b15">(Dieckmann &amp; Todd, 2004)</ref>, allowing to easily go back and forth between integrative strategies that need cue weights and lexicographic strategies that require order, adaptively switching depending on each strategy utility <ref type="bibr" target="#b42">(Lieder &amp; Griffiths, 2017;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006;</ref><ref type="bibr" target="#b80">Stojić et al., 2016</ref>).</p><p>Here we built on previous theoretical and empirical work on the LMS model. Following function learning studies that examined mapping between multiple cues and continuous response <ref type="bibr" target="#b32">(Kelley &amp; Busemeyer, 2008;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010)</ref>, participants in our experiment received criterion value of the chosen option as a feedback in a choice task (same as in <ref type="bibr" target="#b7">Bröder &amp; Schiffer, 2003a</ref><ref type="bibr" target="#b9">, 2006a</ref><ref type="bibr" target="#b27">Hogarth &amp; Karelaia, 2007;</ref><ref type="bibr" target="#b50">Rakow et al., 2004)</ref>. An estimation task followed the choice task where participants predicted criterion value of new options that they had not seen during the choice task, and did not receive feedback after their predictions. The estimation task is essentially equivalent to a test phase commonly deployed in function learning tasks <ref type="bibr" target="#b32">(Kelley &amp; Busemeyer, 2008;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010</ref>). Introducing an estimation task after the choice task was a key innovation in our "choice-learning-estimation" paradigm. It allowed us to to uncover the knowledge participants acquired during the choice task, and crucially, to identify whether participants learned cue weights or cue order. In addition, to independently cross-check the inferences drawn from the estimation task, the participants gave self-reports on the strength of the relationship between the cues and the criterion in regular intervals during the choice task. Predictions in the estimation task allowed us to fit the LMS model and obtain evolution of participants' cue weights during the choice task. We then used the cue weights inferred by the LMS model to fit the WADD and DE models. Classifying participants as WADD or DE users then made it possible to compare the type and precision of knowledge acquired by the two groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The formal models</head><p>We describe the formal models with respect to their application to the choice-learning-estimation (from now on referred as CLE) experiment illustrated in <ref type="figure">Figure 1</ref>. In the first part of the CLE task participants repeatedly choose among three options; each varying along four continuousvalued cues and continuously along a criterion variable. Let i = 1, ..., N index the options and let j = 1, ..., M index the cues. By x i j,t we denote the value of the i-th option for the j-th cue at trial t. Criterion value of the i-th option at each trial t, Y i t , is a simple linear combination of option's cue values, x i j,t , and cue weights w j</p><formula xml:id="formula_0">Y i t = M j=1 w j x i j,t .</formula><p>After each choice participants learn the criterion value, Y i t , of the option they selected. Their goal is to maximize the sum of criterion values. To achieve that they can use the feedback from their choices to learn about cue weights or cue order. At each step, the acquired knowledge feeds in the choice models and results in selecting one of the options. After the choice task decision makers get a surprise estimation task where they repeatedly observe a single option and have to predict its criterion value.</p><p>Below we first introduce the LMS model with which we model the cue weight learning process. Key to this is the estimation task that gives us the observations required for fitting the LMS model. Next we describe the two choice models that we considered in this study, the WADD strategy and the heuristic DE strategy, with a focus on how these models employ cue weights inferred by the LMS model. We focus on the WADD and DE strategy as they can be taken as key representatives of the two qualitatively different classes of strategies -the integrative and lexicographic strategiesthat we are interested in. Many of the other strategies lie in between and some can even be expressed as special cases. For instance, equal weighting strategy is a special case of the WADD model and TTB heuristic is a special case of the DE strategy. We describe baseline models that we use as benchmarks in each task in Appendix A, while parameter estimation and model selection procedures can be found in Supplemental Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LMS Model</head><p>We use the LMS model, originally used by <ref type="bibr" target="#b23">Gluck and Bower (1988)</ref> for a category learning task, and subsequently for predicting continuous-valued outcomes in function learning tasks (e.g. <ref type="bibr" target="#b32">Kelley &amp; Busemeyer, 2008;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010)</ref>. The model is a single-layer feed-forward network with one input node for each cue and a single output node. Cue weight learning is modeled as a dynamic process where weights are updated from trial to trial based on prediction error, that is difference between predicted and true criterion value.</p><p>Input nodes in each trial t are activated by cue values x j,t , and the output node represents the predicted criterion valuê</p><formula xml:id="formula_1">Y i t :Ŷ i t = M j=1 x i j,t u j,t ,<label>(1)</label></formula><p>where u j,t denotes cue weight learned for cue j at trial t.</p><p>Weights are updated in every trial by the delta rule based on the difference between predicted criterion value,Ŷ i t and true criterion value, Y i t , that participant receives as a feedback during the choice task for chosen option i at trial t:</p><formula xml:id="formula_2">u j,t+1 = u j,t + η/t γ (Y i t −Ŷ i t )x j,t ,<label>(2)</label></formula><p>where η ∈ (0, 1) is a learning rate and γ ∈ (0, 1) specifies rate of decay of the learning rate. We initialize the weights to u j,0 = 0 for all j. If γ is set to zero, learning rates will be constant through all the trials, while for positive values learning rate will converge to zero over time. Thus, the LMS model provides us with cue weights for each trial, u j,1 , ..., u j,T . Note that the cue weight learning process is based only on the option for which participants receive feedback.</p><p>We allow for decaying learning rates as in previous experiments it has been found that the LMS model with a decay parameter can describe participants predictions better than without it <ref type="bibr" target="#b32">(Kelley &amp; Busemeyer, 2008)</ref>. This version could also potentially capture a different learning mechanism based on Bayesian principles, where learning rate decreases with decrease in uncertainty about weight estimates (see, for example, <ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010)</ref>. Hence, we have two versions of the LMS model -LMS without decay (where γ was set to zero) and LMS d with decay.</p><p>A key innovation in our CLE paradigm is that LMS models start learning the cue weights on data from the choice task, by observing the cues and criterion values of chosen option. These cue weights are then frozen and used to make predictions in the estimation task (participants do not receive feedback here), which we use to fit the model and obtain the parameters (for more details see Supplemental Material). Resulting fits then allow us to generate cue weights evolving throughout the choice task trials that we can use as input for the choice models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The weighted-additive model</head><p>The weighted-additive (WADD) decision making model <ref type="bibr" target="#b57">(Payne, Bettman, &amp; Johnson, 1988)</ref> takes into account information about all cues when making a decision. It is often considered a rational decision making and contrasted with lexicographic heuristic models such as TTB <ref type="bibr" target="#b20">(Gigerenzer &amp; Goldstein, 1996)</ref>.</p><p>In our setup, the WADD model uses the knowledge about cue weights completely by combining the weights learned by the LMS model with cue values in a linear fashion to produce predicted value of each option i in trial t:</p><formula xml:id="formula_3">Ŷ i t = M j=1 x i j,t u j,t .</formula><p>The WADD model then deterministically decides by maximizing among the options:</p><formula xml:id="formula_4">C max t = argmax iŶ i t , i ∈ 1, ..., N.</formula><p>To fit the model to choice data we need to assume additional error structure <ref type="bibr" target="#b43">(Loomes, Moffatt, &amp; Sugden, 2002;</ref><ref type="bibr" target="#b65">Rieskamp, 2008)</ref>. We assume a so-called "trembling hand" error which postulates that participants choose the best option with probability 1 − , otherwise they mistakenly choose either of the three options with probability . The final probability that an option i is chosen, P(C = i), taking into account the tremble error, , is given by:</p><formula xml:id="formula_5">P(C t = i) = (1 − ) × 1 C max t =i + N ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_6">1 C max t =i</formula><p>is an indicator function that equals 1 if the maximizing option is option i, 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Delta-Elimination model</head><p>We consider delta-elimination (DE), a strategy that relies on the sequential consideration of cues, as in the TTB and ∆-inference heuristics <ref type="bibr" target="#b20">(Gigerenzer &amp; Goldstein, 1996;</ref><ref type="bibr" target="#b45">Luan et al., 2014)</ref> and is endowed with an elimination mechanism as in elimination-by-aspects heuristic <ref type="bibr" target="#b86">(Tversky, 1972)</ref>. The strategy can be described formally as follows: let i = 1, ..., N index the options and let j = 1, ..., M index the cues from the most informative one to the least informative one. By x i j,t we denote the value of the i-th option for the j-th cue at trial t and by x max j,t we denote the value of the best option on the j-th cue at trial t. Finally by ∆ we denote a discriminatory threshold. We first eliminate all options such that x i 1,t &lt; x max 1,t −∆. If there more more than one options left, we proceed by eliminating all options such that x i 2,t &lt; x max 2,t − ∆ and so on. This process continues until there is only one option left or until we run out of cues, where an option is selected at random from the non-eliminated options. We denote the chosen option as</p><formula xml:id="formula_7">C max t .</formula><p>In our experiments we assume that in each trial the model orders the cues i = 1, ..., 4 using the weights u t provided by the LMS model: it first takes the absolute value of the weights, making the negative weights as predictive as the positive ones, and then ordering them from the largest weight to the lowest, producing a cue order r t that serves as an estimate of the relative importance of different cues. Further, the values of cues with negative weights are multiplied with −1. In sum, using only the order and the signs of the weights, the lexicographic model can perform well without knowing the exact cue weights.</p><p>The DE strategy effectively generalizes existing lexicographic strategies to settings with any type of the cues (binary, discrete or continuous) and any number of available options. The parameter Delta controls how frugal the strategy will be. For example, a small Delta value ensures that in large choice sets the model proceeds quickly in trimming down the choice set to the most promising options. The main building blocks of the strategy-sequential search and the use of perceptual thresholds-are common cognitive mechanisms in humans and have received ample empirical support in experimental studies (e.g. <ref type="bibr" target="#b2">Bettman, Johnson, &amp; Payne, 1990;</ref><ref type="bibr" target="#b35">Kohli &amp; Jedidi, 2007)</ref> Thus, the strategy is both psychologically plausible and can provide a strong competitor to compensatory strategies in realistic choice problems with continuous cues and more than two options.</p><p>Similar to the WADD model, DE makes deterministic choices, so we add a trembling hand error term to arrive at final choice probability (Equation 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method 2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Seventy-eight participants (49 female, M age = 21.8, age range: 17-54 years) took part in the experiment, recruited from the Pompeu Fabra University subject pool. They received a show-up fee of five Euros and a performance dependent bonus, an additional amount of 6.8 Euros on average. The experiment lasted for 43 minutes on average. We excluded from the analysis one participant that provided the same response in all trials in the estimation task, leaving us with 77 participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The choice-learning-estimation paradigm</head><p>The choice-learning-estimation (CLE) paradigm consisted of two parts: a choice task and an estimation task. In the choice task participants made choices and learned about the structure of the environment through outcome feedback. Estimation task that came after the choice task tested what they have learned during the choice task. This combination of the two tasks was a key innovation of the paradigm.</p><p>In the choice task participants repeatedly chose between three options ( <ref type="figure">Figure 1a</ref>). Options' criterion values were a function of four observable cues and participants observed only the criterion value of the option they chose. The goal was to maximize the sum of criterion values of the chosen options across trials. Criterion values of options, Y, were a simple linear combination of cue values, x, and cue weights w</p><formula xml:id="formula_8">Y = 4x 1 − 3x 2 + 2x 3 − x 4 + e,<label>(4)</label></formula><p>where cue weights, w = (4, −3, 2, −1), were kept fixed throughout the task and e was normally distributed error with mean 0 and standard deviation of 30. Positive weights indicate that the higher the cue values are, the higher the value of the option on average. We opted for some negative objective weights, as negative linear relationships are harder to learn and people seem to have a prior for positive linear relationships <ref type="bibr" target="#b4">(Brehmer, 1994;</ref><ref type="bibr" target="#b12">Busemeyer, Byun, Delosh, &amp; McDaniel, 1997)</ref>. Hence, the negative weights would facilitate detecting patterns of true learning in the estimation task and insight questions. For the choice task we generated 480 unique options by sampling cue values x from uniform distribution with range from 10 to 90, rounding them to the nearest integer, and computing the criterion values using Equation 4. Finally, we allocated options randomly across 160 trials, three options per trial. With this procedure we ensured that choosing any of the three options in the trial would yield on average equal amount of information with respect to learning the cue weights. Mean cue inter-correlation was −0.02 (SD = 0.05), ranging from a minimum of −0.08 to a maximum of 0.04. To reduce between-subject variance the stimuli were drawn once and all participants received the same set of stimuli. That is, the participants saw the same options in each trial.</p><p>The estimation task was comprised of 40 trials, where in each trial participants saw the cues characterizing a single option and their goal was to predict the criterion value of the presented option ( <ref type="figure">Figure 1b</ref>). To prevent people from learning in the course the estimation task no feedback was provided about the guessed criterion values. We incentivised truthful reporting of predictions by computing the payoff as a difference between the prediction P and the option's criterion value Y: 200 − |P − Y|.</p><p>Half of the 40 trials were interpolations, drawing the option's cue values from the same uniform distribution as in the choice task, U(10, 90), and the remaining half were extrapolations, drawing cue values from two intervals at the extreme ends, U(0, 10) and U(90, 100), that had not been experienced in the choice task. We then computed the criterion values according to Equation 4. We included extrapolation trials as they can be useful for discriminating between the models describing the learning process (e.g. DeLosh, . Same as in the choice task, here the stimuli was drawn once before the experiment and all participants received the same set of stimuli.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Insight questions</head><p>We divided the choice task into four blocks of 40 trials. After each block, participants answered insight questions where they reported their knowledge about the cue importance on simple Likert scale <ref type="bibr" target="#b37">(Lagnado, Newell, Kahan, &amp; Shanks, 2006;</ref><ref type="bibr" target="#b50">Rakow et al., 2004;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010)</ref>. Insight questions provided us with another window into participants' learning during the choice task, complementary to the estimation task that participants completed only after the choice task. The scale used in these questions is arbitrary. Therefore, there is no clear-cut mapping to the objective cue weights. Nonetheless, these self-reports can inform us about participants' subjective cue order and evolution over time. <ref type="bibr" target="#b37">Lagnado et al. (2006)</ref> used similar insight questions in a category learning task and systematically compared experiment with and without insight questions during learning. They found that insight questions did not affect either learning or strategy selection. This implies that insight questions should not affect learning in our task as well.</p><p>a b <ref type="figure">Figure 1</ref>. Screenshots from the choice-learning-estimation (CLE) paradigm. The CLE paradigm consists of two parts: a choice task followed by an estimation task. (a) In the first part participants encountered a choice task where in each trial they chose between three cheeses described by four cues -"Lactic", "Acetic", "Casein" and "Texture", and observed the enjoyment units (i.e., criterion value) of the chosen cheese. The participants' goal was to maximize the amount of enjoyment units collected throughout the 160 trials in the task. Unknown to them, enjoyment units were a linear function of the four cues. (b) In the second part participants completed an estimation task. Here we presented them with a single item in each trial, but now they had to predict the enjoyment units of the item. Participants were maximizing their earnings by making accurate predictions across 40 trials, matching the true criterion values of observed items. We did not provide them with feedback in this part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants completed the experiment on desktop computers, using a custom software written in Python, with the help of PsychoPy library <ref type="bibr" target="#b59">(Peirce, 2007)</ref>. The experiment was implemented in Spanish. We conducted the experiment in groups of about 15 people in BES laboratory at Universitat Pompeu Fabra.</p><p>We presented instructions about the experiment on the screen. We used a background story of a cheese loving consumer who in every trial faces a choice between three cheeses and whose goal is to maximize their enjoyment in cheese. We informed participants about the cues and the range of values they could take, and explicitly mentioned they could use this information in making their choices. We did not tell them anything else about the relationship between cue values and criterion values. We stressed that in each trial they would get three new cheeses that differ in their cue values. Participants had three practice trials where they could familiarize themselves with how the interface works. To motivate participants, we told them it is a difficult task, but that they will improve with practice.</p><p>During the choice task, every 40 trials participants answered insight questions. In the initial instructions we mentioned that we will interrupt the task on several occasions and ask them about their experience until that point, but without specifying details. When insight questions appeared during the choice task we gave the following instruction: "Please rate how strongly each feature relates to the amount of enjoyment (EU's) you get from the cheese. Please rate each feature on a scale from -10 (highly negative) to 10 (highly positive)." We presented questions for all four cues on the same screen, in the same order that was used to present the options.</p><p>We announced in the initial instructions that there will also be a second part of the experiment (the estimation task), saying only that it is much shorter than the first part and that performance will still count for their earnings. We did not inform them about the nature of the task, so the participants did not know that they would need to estimate the exact criterion values of the options. When they reached the second part of the experiment we eventually informed them about the details of the task, mentioned that we will present them a single cheese and ask them to estimate how tasty the cheese is going to be in terms of enjoyment units. We also mentioned that this time they will not be receiving any feedback.</p><p>We did not inform the participants about the exact number of trials in each task, instead we told them that it takes 60 minutes on average to complete the entire experiment. We carefully explained how we will calculate their earnings, illustrating the process with examples. We used enjoyment units (EU's) as a token in the experiment, and we stated that EU's will be transformed into Euro according to an exchange rate of 5000 EU's for 1 Euro. Participants started with an initial fund of 5000 EU's. During the choice task we displayed the total earnings on the screen at all times, but not in the estimation task. At the end of the experiment we showed the participants a breakdown of EU's earned in each phase and the earned sum in Euro.</p><p>For each participant we randomized the order in which options were presented on the screen and the order of cues at the beginning of the experiment and then kept the ordering fixed throughout. Attribute labels, "Lactic", "Acetic", "Casein" and "Texture", were also randomly attached to under-lying cues for each participant to reduce the influence of any prior information participants might have had about them.</p><p>For the sake of transparency we list all the variables we recorded: age, gender and educational background of the participants, their choices and insight ratings in the choice task, predictions in the estimation task and response times in both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and code availability</head><p>The data, code used for analyzing the data and other project related files are publicly available at the Open Science Framework website: https://osf.io/7yxrz .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results 3</head><p>Participants are learning cue weights rather than order Participant's performance in the estimation task is uniquely suitable for identifying whether they learned more than just the cue order during the choice task. Most participants were good at predicting the criterion values of options presented in the estimation task, as evidenced by the root mean square error (RMSE) and the correlation between each participant's predictions and criterion values <ref type="figure">(Figure 2a</ref>; LMS aspects of the figure will be addressed below). What would be a baseline performance in this task? Participants that learned only cue orders during the choice task, or did not learn how cues are related to criterion values at all, could of course make random guesses. They could, however, use a more sensible strategy that does not involve a sophisticated learning: keeping an estimate of a mean criterion value based on feedback in the choice task, and using this mean as a fixed prediction in the estimation task. We implemented this strategy in what we call a Baseline prediction model, one variant that perfectly computes the mean (BP f ) and another that learns the mean slowly trial-by-trial (BP l ; see Appendix A for details on benchmark models). The mean RMSE between such baseline predictions (best fitting BP model) and criterion values (202, SE = 0.54) was larger than the observed mean RMSE (154, SE = 4.59) across participants (one-tailed Wilcoxon signed rank test:</p><formula xml:id="formula_9">Median diff = −51.45, Z = 118, p ≤ .0001, CI = [−In f, −43.7])</formula><p>. Another way to look at the estimation task performance is through correlations between estimates and criterion values, that speak more toward consistency, rather than how close predictions were to criterion values. The mean Spearman correlation (0.63, SE = 0.07) was substantially higher than zero (one-tailed Wilcoxon signed rank test: Median diff = 0.67, Z = 3000, p ≤ .0001, CI = [0.61, In f ]). <ref type="figure">Figure 2a</ref> also shows that individual variation in performance was substantial -while most participants were doing well, exhibiting high correlations and low RMSE's, 14 participants performed poorly in the estimation task (worse or in par with the baseline prediction model), indicating that they did not acquire knowledge about the cue weights in the course of the choice task. Note that we designed the environment to be fairly predictable, with a relatively small error component. This can be seen from a high correlation between criterion values with and without error component for chosen items: mean across participants was 0.97 (SE = 0.02). Despite having an environment that in principle should be possible to learn, by the end of the choice task most participants were still far from perfect performance.</p><p>We obtained a more nuanced picture about participants' performance in the task by examining mean predictions across participants for each option (stimulus) in the estimation task <ref type="figure">(Figure 2b</ref>; the LMS aspects of the figure will be addressed below). Averaging the results across all options when computing RMSE and correlations can potentially obscure large differences between individual options. <ref type="figure">Figure 2b</ref> illustrates whether this was the case. We ordered options according to their criterion values and what is immediately obvious is that participants predictions were very close to criterion values for options with middle range criterion values, approximately from 0 to 200. Larger deviations occurred for options with more extreme values. Participants performed on average worse on items with extreme negative value than on items with extreme positive ones. This was likely due to having less experience with options with low criterion values. Participants were motivated to choose options with high criterion values in the choice task and over time they acquired a somewhat biased sample and had less observations about options with low values <ref type="bibr" target="#b81">(Stojic, Schulz, P. Analytis, &amp; Speekenbrink, 2020)</ref>. Even in the edges of the range, however, participants' average predictions were going in the right direction. They were much better than those of the baseline prediction (BP) models, that we would expect as answers from participants knowing only the cue order, and they were relatively close to the true criterion values.</p><p>Insight questions provided us with another window into participants' learning in the choice task. Every 40 trials in the choice task we asked participants to rate the strength of each cue's effect on option value. Previous research using such questions showed that people have good insight into what they have learned <ref type="bibr" target="#b37">(Lagnado et al., 2006;</ref><ref type="bibr" target="#b50">Rakow et al., 2004;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010)</ref>. From mean ratings for all four cues we see that participants got the order and directions partially right on average <ref type="figure">(Figure 3a</ref>). Ordering and direction were roughly established already after the first block of trials and the pattern got clearer as the choice trials  <ref type="figure">Figure 2</ref>. Participants learned cue weights rather than order. (a) Participants made good predictions in the estimation task, as indicated by the mean Spearman correlation and root mean square error (RMSE) between predictions and criterion values. Predictions were much better than what can be expected from knowing only the cue order -correlation of zero and the RMSE between the best fitting baseline prediction (BP) model and criterion values (continuous vertical line indicates the mean and shaded region the standard deviation). Points are individual results, while dashed horizontal and vertical lines are means across all participants. The different point shapes indicate the best fitting model for different participants -one of the BP or the least-mean-square models (LMS and LMS d ). (b) Mean predicted criterion values for individual options presented in the estimation task. Participants predicted well criterion values around the middle range (between 0 and 150), but overestimated criterion values at the lower end and underestimated them at the upper end. Options are sorted according to their criterion value (approximately diagonal black line), going from lowest to highest. Additional points denote mean predictions of the best fitting LMS model across participants (those fitted best by the BP model were excluded). Continuous horizontal line stands for the mean prediction for the best fitting BP model (line indicates the mean and shaded region the standard deviation). Standard errors of the means are smaller than the points. progressed. Participants did not learn that the second cue had larger weight (although negative), than the third cue. Moreover, participants did not detect that the fourth cue was negative, instead they thought it was weak but positive. These results echo classical function learning findings -negative linear relationships are harder to learn than positive linear ones <ref type="bibr" target="#b4">(Brehmer, 1994;</ref><ref type="bibr" target="#b14">DeLosh et al., 1997)</ref>. Insight questions used an arbitrary scale that does not map directly to objective cue weights. Thus, it would be premature to infer whether participants knew cue weights or only cue orders on the basis of insight questions alone and without an estimation task. The ratings are informative about the learning process, however, regardless of the exact type of cue knowledge. The ratings changed over time, suggesting that slow, gradual learning characterizes both types of cue knowledge <ref type="bibr" target="#b15">(Dieckmann &amp; Todd, 2004;</ref><ref type="bibr" target="#b23">Gluck &amp; Bower, 1988)</ref>.</p><p>The estimation task results established that most participants learned cue weights-to perform well in this task participants had to know cue weights rather than just cue order. Insight questions ratings, in particular their adjustment over time, indicate that cue knowledge evolved gradually during the choice task. Both the estimation task and the insight questions showed that participants' knowledge was far from perfect. Still, taken together these results suggest that participants may have learned cue weights irrespective of the choice strategy that they adopted. Since it is possible that all or most participants used a single strategy, we have to postpone a stronger conclusion until we analyze what strategies participants adopted. These results also justify our next step: modeling a mechanism of how participants learn the cue weights.</p><p>Least-mean-squares learning as a mechanism for learning cue weights and order</p><p>We inferred participants' subjective cue weights, and based on them the cue order as well, by fitting the LMS model to the estimation task while taking into account experiences in the choice task. This was a key innovation in our CLE paradigm: the LMS model learns weights from cues and criterion values that participants observed during  <ref type="figure">Figure 3</ref>. Participants knowledge of cue weights and order evolved during the choice task, but was still imperfect by the end of it. (a) Self-reports in insight questions that periodically appeared during the choice task (after trial 40, 80, 120 and 160) showed that participants acquired reasonably good knowledge of the cue order on average. The insight question scale captures how strongly each feature relates to the criterion values, on an arbitrary scale going from -10 (highly negative) to 10 (highly positive). The points indicate mean rating across participant while error bars represent standard errors of group means. To allow for easier discrimination, points are displaced horizontally and connected by lines. (b) Evolution of subjective cue weights inferred by the best fitting least-mean-squares model showed that participants learned the cue weights reasonably well, but did not reach the objective weights used for generating the stimuli. Lines are median cue weights across participants for each trial, smoothed with a moving average of ten trials, disregarding participants best fitted by one of the baseline models. the choice task while following their choice strategies, but the evolution of cue weights was uncovered using the responses participants provided in the estimation task-these appropriately constrained the model.</p><p>We fitted two versions of the LMS model to each individual's data -LMS and LMS d where learning rate also decays over time (see The formal models Section for details on LMS models and Supplemental Material for details on fitting procedure). To select the best model we used the Bayesian information criterion (BIC, the smaller the better; , as it takes into account differences in complexity of the models. Both versions fitted participants almost equally well on average <ref type="table">(Table S1</ref> in Supplemental Material), with slightly worse mean BIC score of 369 (SE = 2.87) for LMS than 365 (SE = 2.85) for LMS d . For comparison, the best performance that can be achieved with these models when fitted to perfect predictions (i.e. equal to criterion values; see perfect LMS and LMS d benchmark models in Appendix A), was a mean BIC score of 319 (SE = 1.06) and 306 (SE = 0.98) respectively. The LMS models outperformed the BP models, with a mean BIC score of 384 (SE = 3.33) for BP l and 405 (SE = 2.77) for BP f . Out of 14 participants that showed poor performance in the estimation task, 8 were best fitted by one of the BP models. Overall, the LMS model fits were closer to the BP model fits than to the best performance that can be achieved using the LMS learning, suggesting that participants' learning was comparatively slow.</p><p>How far were the model predictions from participants' responses in the estimation task? The RMSE for LMS (100.4, SE = 3.25) was slightly worse than for LMS d (91.5, SE = 3.12; two-tailed Wilcoxon signed rank test: Median diff = 6.66, Z = 2967, p ≤ .0001, CI = [4.42, 8.89]), both being substantially closer to participants predictions than the baseline prediction models, with RMSE of 157.1 (SE = 4.98) for BP f and 123.2 (SE = 4.32) for BP l . These differences were also reflected in the number of best fitting individuals per model. The largest number of participants was best fitted by the decay version (35, LMS d ), followed closely by nondecaying learning (31, LMS), and a much smaller subset by one of the BP models (11). When averaged only across participants best fitted by a model, the mean BIC weight of the model fit gives the mean probability with which that model was the best among the competing models . In other words, it tells us how confident we can be the categorization of participants was correct <ref type="bibr" target="#b7">(Bröder &amp; Schiffer, 2003a)</ref>. For example, a mean BIC weight close to 0 would mean negligible evidence for the model, while value close to 1 would mean that the evidence for best fitting model was overwhelmingly better than for the competing models. The mean BIC weight was 0.75 (SE = 0.02) for the participants best fitted with LMS and 0.89 (SE = 0.02) for participants best fitted with LMS d . This indicates that even though both LMS models fitted behavior equally well on average, there were substantial difference between the model fits at the individual level and we can be confident in our categorization of participants into LMS or LMS d users.</p><p>Next, we made predictions for the estimation task options using the best fitting LMS models <ref type="figure">(Figure 2b)</ref>. Mean predictions from the LMS models were close to the actual participants' predictions for most of the options. This was the case regardless of their criterion values, whether these were options with extreme values for which participants were less accurate or with middle values for which they were more accurate. This shows that the LMS models captured participants' predictions well. Model predictions were expectedly better for interpolation items (mean RMSE between participants' and model predictions: 77.6, SE = 2.92) than for extrapolation items (101.7, SE = 3.97; two-tailed Wilcoxon signed rank test:</p><formula xml:id="formula_10">Median diff = 23.07, Z = 2645, p ≤ .0001, CI = [16.96, 29.14]).</formula><p>We then examined in more detail how cue weight knowledge inferred by the best fitting LMS models evolved over time during the choice task <ref type="figure">(Figure 3b</ref>). On average participants' knowledge improved over time, but learning was slow and did not converge to the objective cue weights -distances from objective cue weights ranged from 0.91 to 2.09. Participants had easier time learning the positive weights than the negative weights, reflecting a well known finding in function learning literature <ref type="bibr" target="#b3">(Brehmer, 1974)</ref>. We also cross-checked the evolution of cue weights with patterns observed in the insight questions reports. In the LMS d model the positive decay parameter values are compensated by faster learning rates <ref type="table">(Table S1</ref> in Supplemental Material). This results in fast learning in the beginning of the choice task and slower changes later on. By contrast, the LMS model without decay learns slowly but steadily across the task, and has relatively poor cue weight knowledge in the first stages of the choice task ( <ref type="figure">Figure S2a</ref> in Supplemental Material). The insight question reports of participants best fitted with the LMS and LMS d model showed that these qualitative differences in learning patterns between LMS and LMS d model are accurately reflected in the insight questions as well ( <ref type="figure">Figure S2b</ref> in Supplemental Material). This cross-task comparison provides additional evidence that the LMS models successfully captured the cue weight learning during the choice task.</p><p>Lexicographic heuristics need cue order rather than cue weights. Although the LMS model does not learn cue order directly, these can be easily derived from cue weights. Thus, we examined the evolution of cue orders by looking at the inferred cue weights. For most people this order of cue weights was established quite fast. Participants established the first ranking cue in 21 trials (SE = 4.02) on average, that is, the rank stopped changing after that. The rank of other cue weights stopped changing later on, after 52 (SE = 5.41) trials for the second cue, 50 (SE = 5.98) for the third and 48 (SE = 4.62) for the fourth cue on average. Notably, individual variability on when ranks were established was substantial. The correctness of the established cue order varied -first ranking cue was correct in 0.99 (SE = 0.01) of cases, fourth in 0.57 (SE = 0.06), while second and third were confounded, being correct in 0.29 (SE = 0.05) and 0.29 (SE = 0.05) of cases. This pattern roughly corresponded to the insight questions results as well <ref type="figure">(Figure 3a</ref>).</p><p>The LMS model provided a good fit to the estimation task data. It also provided a reliable description of the evolution of cue weight knowledge during the choice task, as evidenced by cross-checks with insight question reports. Cue weights and order are crucial inputs for choice strategies. We next analyzed differences in knowledge of cue weights and order between participants using integrative and lexicographic strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differences in knowledge between WADD and DE strategy users</head><p>We examined the raw choice performance first and how it is related to performance in the estimation task. Cue weight knowledge is a crucial input for the choice strategies and the quality of choices depends on it. Therefore, we expected a high correlation between performances in the two tasks. We measured participants' performance in the choice task as the mean rank of options chosen in each block of 40 trials in the task. Rank was computed according to the expected values of the options present in a trial. Correct choices in all trials would yield mean rank of one, while random choices would yield a mean rank of two. The choice performance improved over time <ref type="figure">(Figure 4a</ref>; results related to WADD and DE perfect models are explained below), from 1.69 (SE = 0.03) in the first block, to 1.50 (SE = 0.03) in the fourth block (the lower the better; one-tailed Wilcoxon signed rank test: Median diff = 0.21, Z = 2125.5, p ≤ .0001, CI = [0.15, In f ]). <ref type="bibr">4</ref> We opted for the rank measure instead of percentage correct, because rank is more sensitive in choice sets with three options, where choosing a second best option is meaningfully better than the third best option. Nonetheless, we additionally examined the choice performance with a percentage correct measure that is somewhat  <ref type="figure">Figure 4</ref>. (a) Participants' performance improved over time in the choice task. Performance was measured as the mean rank of options chosen in all the trials of a block. Correct choices (i.e. those with the highest expected value) would yield mean rank of 1 while random choices would yield a mean rank of 2. Thus, participant performance in each block represents the mean of individual mean ranks across the 40 block trials (i.e 1-40, 41-80, 81-120, 121-160), and error bars represent the standard errors of the grand means. The shaded region represents the range of participant performance in the choice task, from the 10 th to 90 th percentile. The point marked with number five next to the y-axis illustrates the performance in the first five trials. We also illustrated the performance of the delta-elimination (DE) and weighted-additive (WADD) models fitted to perfect choices, using cue weights inferred by the least-mean-squares (LMS) model fitted to perfectly accurate predictions (dotted lines). (b) Participants who performed well in the estimation task tended to perform well in the choice task as well. Estimation task performance is expressed as a root mean squared error between predictions and criterion values (RMSE), and choice task performance is the mean rank of chosen options in the last block, to capture the stable part of the performance. Point shape denotes the best fitting choice model -WADD, DE or BC model (showing both BC model variants pooled together). Mean prediction from best fitting baseline prediction model (Mean BPM) and baseline choice model (Mean BCM; 4 th block) are illustrated as thick gray lines and (one) standard deviation around the means is denoted by lighter grey area stricter. There were only minor differences between measures and for brevity we do not report them here.</p><p>We fitted two baseline choice models, a random choice model (BC f ) where we fixed the probability of choosing any option to 1/3, and a more flexible variant (BC m ) where the probabilities of choosing different options were estimated from choice frequencies (see Appendix A). Participants did better than the baseline choice models already in the first five trials, with a mean rank of 1.71 (SE = 0.04; one-tailed Wilcoxon test: Median = 1.60, Z = 231, p ≤ .0001, CI = [−In f, 1.70]). This result concurs with previous findings, which suggest that people have a strong prior for positive linear relationships between cues and the criterion value <ref type="bibr" target="#b3">(Brehmer, 1974;</ref><ref type="bibr" target="#b12">Busemeyer et al., 1997)</ref>. The initial bias we identified matches the function we used to construct the stimuli (Equation 4); the cues with positive weights were stronger predictors than the cues with negative weights. As a result, the initial guesses of many participants that cues were positively correlated with the criterion value were on average correct.</p><p>Individual variability in choice performance was substantial; some participants got close to perfect choices, while others were still close to random by the fourth block, as indicated by the 10 th and 90 th percentile of performance (shaded region in <ref type="figure">Figure 4a</ref>). How was this variability related to variability in estimation task performance? Most of the people who performed well in the choice task also did well in the estimation task. This becomes immediately apparent by looking at individual performance on the choice task and performance on the estimation task jointly <ref type="figure">(Figure 4b</ref>) and is also supported by a strong Spearman rank correlation (0.77) between participants' performance in the two tasks. Further, many of the participants that performed close to the baseline or worse in the estimation task cluster close to random choice performance. It is likely that they were less motivated or attentive and consequently achieved low performances in both tasks.</p><p>While the WADD strategy requires cue weights, lexico-  <ref type="figure">Figure 5</ref>. Evolution of cue weights in the choice task, as inferred by the best fitting least-mean-squares model (LMS), shows that for both weighted-additive (WADD) and delta-elimination (DE) users cue weights were converging toward the objective ones, albeit at a slower pace for DE users. Weights are median cue weights across participants for each trial, smoothed with a moving average of ten trials.</p><p>graphic heuristic strategies such as DE can get away by only knowing the cue order <ref type="bibr" target="#b27">(Hogarth &amp; Karelaia, 2007;</ref><ref type="bibr" target="#b31">Katsikopoulos et al., 2010)</ref>. In <ref type="figure">Figure 4a</ref> we illustrated the best possible choice performances of DE and WADD -when fitted to correct choices, based on cue weights inferred by LMS models fitted to perfect predictions (i.e. criterion values) in the estimation task (see benchmark choice models in Appendix A). These provide a performance benchmark -the best possible that can be achieved by taking learning in this environment into account. Perfect DE, using only cue order, achieved choice performance of 1.29 (SE = 0.003) in the 4 th block, with whole performance curve being closer to most of participants' performances across blocks. An optimally tuned WADD strategy that fully uses cue weight knowledge achieved almost perfect choice accuracy, with mean rank of 1.05 (SE = 0.002) in the 4 th block. Some participants achieved accuracies that were higher than what was possible to achieve with perfect DE (mean rank &lt; 1.29, N = 17, <ref type="figure">Figure 4b</ref>), suggesting that they adopted the more demanding WADD strategy. For participants with performance around and worse than the DE perfect performance level (mean rank &gt; 1.29) it was less clear what strategy they adopted -they could be using DE or the WADD strategy but learning more slowly. To identify the strategy with greater certainty and examine the nature of their knowledge we modelled their choices, taking into account the evolution of each participant's knowledge.</p><p>We fitted WADD and DE model to each individual's data from the choice task (see The formal models Section for de-tails on choice models and Supplemental Material for fitting procedure). <ref type="bibr">5</ref> This analysis assumes that participants used a single strategy across the choice task, a common practical assumption in studies of strategy selection (for a different approach see <ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006)</ref>. Importantly, both models relied on the cue weight information supplied by the version of the LMS model that fitted a participant best in the estimation task. 6 The WADD model used the weights directly while the DE model extracted cue order from cue weights. The WADD model fitted participants' choices better, with mean BIC score of 302 (SE = 4.94) and BIC weight of 0.50 (SE = 0.05), but the DE was close behind, with mean BIC score of 306 (SE = 4.61) and BIC weight of 0.38 (SE = 0.05), both doing much better than the baseline choice model with BIC score of 352 (SE = 0; BC f variant, better of the two) and BIC weight of 0.11 (SE = 0.03) ( <ref type="table">Table S1</ref> in Supplemental Material). In absolute terms WADD and DE were predicting participants' choices equally well, with average probability of 0.46 (SE = 0.01) and 0.46 (SE = 0.01). <ref type="bibr">5</ref> We examined how well we can differentiate between the two strategies in the choice task by using the performance of ideal DE and WADD strategies (see <ref type="figure">Figure 4a</ref>). On average choices between the strategies differed for 0.20 (SE = 0.05) of trials in the choice task, 32 (SE = 0.41) trials on average.</p><p>6 Instead of removing participants who were best fitted with baseline prediction models rather than with one of the LMS models, we used their best fitting LMS model. We opted for this solution as these participants might have been heuristic users that potentially learned cue orders without learning weights.</p><p>For comparison, versions of WADD and DE that were fitted to perfect choices, relying on LMS based cue weights when fitted to perfect predictions in the estimation task (performance is illustrated in <ref type="figure">Figure 4a</ref>), achieved a mean BIC of 137 (SE = 4.64) and 221 (SE = 2.35), and predicted correct choices with average probability of 0.80 (SE = 0.009) and 0.66 (SE = 0.005), respectively. We also performed crossvalidation, an alternative model selection procedure, as a robustness check and it showed similar model selection results (see Supplemental Material).</p><p>We categorized participants as users of a certain strategy by selecting the strategy with the lowest BIC value for that participant. The largest group of participants were categorized as WADD users (38), whereas a sizable group were categorized as DE users (29). A smaller group were classified as BC users (10, two baseline choice models pooled together), five of which were also best fitted with one of the baseline prediction models in the estimation task. Mean BIC weight of the model fit, when averaged only across participants best fitted with a model, tells us how confident we can be in categorization results. Participants were classified with a good degree of confidence, as indicated by the mean BIC weight of 0.93 (SE = 0.01) for WADD, 0.94 (SE = 0.02) for DE. Visualizing the classification results jointly with choice and estimation task performance revealed that the classification yielded reasonable results <ref type="figure">(Figure 4b</ref>). Analysis of raw choice performance suggested that participants that achieved choice accuracy higher than what was possible to achieve with perfect DE (mean rank &lt; 1.29, <ref type="figure">Figure 4b</ref>) adopted the WADD strategy. Using model classification results we can confirm that indeed most of these decision makers were categorized as WADD users (14 out of 17). On average participants categorized as DE users achieved choice performance of 1.5 (SE = 0.03). There were also quite a few WADD users with relatively poor choice performance (6 out of 38). Most of them also performed poorly in the estimation task, suggesting that they possessed less accurate cue weight knowledge.</p><p>There were five participants that were classified as BC users and obviously had choice performance well below the random performance line. These cases are indicative of some limitations of the CLE paradigm. Since LMS models were fitted to the estimation task data, predictions in the choice data are not constrained. For most people LMS modeling worked fine, but in these few cases LMS produced unrealistically high or low weights in the first half of the choice phase, to which choice models dealt with by increasing error parameter almost to maximum, consequently leading to being best fitted with one of the BC models. Instead of trying out tailor-made fits for these participants we opted for leaving them as they are, to be as transparent as possible and illustrate the limits of our approach. There were also several participants who had performance close to random, but were not best fitted with the BC models. For some of them the WADD and DE strategies adopted very high error parameter values and were only marginally better than the BC models. For others the WADD and DE were much better than the BC models -cue knowledge of these participants was somewhat skewed and they were producing choices consistent with their knowledge, even if these were wrong choices, that is, close to random. Despite these limitations the modeling results were sensible for most of the participants and produced valuable insights to otherwise impervious cognitive processes.</p><p>We next examined the differences in cue weight knowledge between participants classified as DE or WADD strategy users. Broad patterns were visible from average estimation task performance <ref type="figure">(Figure 4b</ref>). Most importantly, DE users on average had estimation task performance that was substantially below the baseline prediction model performance, showing that DE users knew cue weights, rather than just the cue order. We obtained more detailed picture by examining cue weights inferred by the LMS models and insight question reports, separately for each strategy. Most interesting were again the DE users. Their cue weight evolution showed a slower convergence toward objective weights than of that by the WADD users, and by the end of the choice task their level of knowledge was somewhat worse than that of WADD users ( <ref type="figure">Figure 5</ref>). Based on the same LMS inferred cue weights we examined correctness of cue orders for participants in the two groups. Correct cue orders are particularly important for DE users to make accurate choices. For both strategy users the first rank cue was on average correct (0.97 (SE = 0.03) for DE and 1.00 (SE = 0) for WADD), while for all other cues DE users learned the correct order in smaller proportion (0.24 (SE = 0.08) for the second, 0.21 (SE = 0.08) for the third and 0.48 (SE = 0.09) for the fourth ranking cue) than WADD users (0.39 (SE = 0.08) for the second, 0.42 (SE = 0.08) for the third and 0.76 (SE = 0.07) for the fourth ranking cue). Overall, fewer DE users learned the correct cue order for all four cues (0.14, SE = 0.06), in comparison to WADD users (0.39, SE = 0.08; two-tailed proportion test, χ 2 (1) = 4.15, p = 0.042, CI = [−0.49, −0.03]). Insight questions of DE users on average pointed in the same direction: reports were almost the same as those of the WADD users, with the exception of slower learning of the weight for the second cue and wrong direction for the fourth cue ( <ref type="figure">Figure S3a</ref> in Supplemental Material). Insight questions and LMS weights of BC users showed that they indeed had much poorer knowledge about the cue weights ( <ref type="figure">Figure S3b</ref> and S3c in Supplemental Material).</p><p>In summary, we found both the WADD strategy and the DE strategy users among experiment participants; importantly, the DE group also learned cue weights rather than exclusively cue orders. However, we found differences in cue weight learning between strategy users. The cue weight  <ref type="figure">Figure 6</ref>. (a) The choice accuracy of the delta-elimination heuristic as a function of the discrimination threshold (∆) value, obtained in simulations on our choice task using objective cue weights. The choice accuracy of the strategy peaks for threshold value of 19 (vertical dashed line) and deteriorates rapidly afterwards, reaching random choice performance for values above 70 (horizontal dashed line). (b) The total number of elements considered, i.e. individual cue values inspected until decision was made, and the estimated threshold parameters for all participants. Shape of the point marks the model fitting the participant's choices best: weighted-additive (WADD), delta-elimination (DE) or one of the baseline choice (BC) models. All the participants who were best fitted by DE had threshold values between 0 and 29, in the region or close to the region where the effort/accuracy trade-off applies. Overall, they considered much less information than people relying on the WADD strategy. Dashed lines mark the optimal Delta value in terms of the achieved option rank and the associated number of elements inspected.</p><p>evolution and insight questions of DE users showed a slower cue weight learning. This result suggests an interaction between the two processes, even if the choice strategy does not affect the type of knowledge that people acquire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Delta-elimination and the effort/accuracy trade-off</head><p>Our second goal was developing a new lexicographic heuristic -the DE strategy -and testing it empirically. This new heuristic is well equipped to tackle challenging choice environments with more than two options and continuousvalued cues, in which heuristic strategies have rarely been put into test before. The DE strategy described well choices of a sizable group of participants. Here we discuss the prescriptive and descriptive performance of the strategy.</p><p>To examine the effects of the discrimination threshold (∆) on choice accuracy and search through the cues we simulated the DE strategy on our choice task. We used objective cue weight values and varied the discrimination threshold from 0 to 100. Choice accuracy and the number of informational elements considered by the DE strategy vary with the threshold value in a different way <ref type="figure">(Figure 6a</ref> and <ref type="bibr">Figure S1a in Supplemental Material)</ref>, producing an interesting effort/accuracy trade-off. The DE subsumes the TTB and single-attribute heuristics as a special case where ∆ = 0. At this point effort is at the lowest point, with the least amount of cues inspected. However, the accuracy is compromised and can be improved with somewhat larger threshold levels. The choice accuracy peaks at threshold value of 19, looking up only 4.8 cue values on average. For larger threshold values the accuracy of the strategy deteriorates, as it starts to rely increasingly on less important pieces of information to make a choice. The region between ∆ = 0 and ∆ = 19 is the Pareto efficient frontier in terms of the effort/accuracy trade-off -it is impossible to further increase the accuracy of the strategy without also increasing the implied effort. This is the region that we should expect to see populated by the participants relying on the DE rule. Overall, the strategy can capture different points on the effort/accuracy continuum, from the immediate choice implied by the TTB heuristic for continuous cues, to a more balanced trade-off implied by somewhat larger threshold levels.</p><p>The DE strategy fitted best 29 participants (from the remaining participants 38 were best modeled with WADD and 10 with the one of the baseline choice models). The mean threshold value for DE users was ∆ = 15.3 (SE = 1.85), close to the theoretically optimal value of 19 for this environment.</p><p>The maximum observed value was 28.7 and values were generally distributed close to the optimal value (participants marked with a circle, <ref type="figure">Figure 6b</ref>, see also <ref type="figure">Figure S1b</ref> in Supplemental Material where distribution is easier to discern). Slightly over half of the participants (15) had Delta values within the Pareto efficient effort/accuracy frontier (∆ &lt; 19) and the remaining slightly above it (from 19 to 29), which also corresponds to a relatively flat region on the performance function. Although none of the uncovered participant threshold values was exactly ∆ = 0, a cluster of eight participants had Delta values that were very close to it, with ∆ &lt; 5. People belonging to that group were very near to the absolute minimum of 3 pieces information that would be consumed by TTB in this environment-the Delta was sufficiently small that most cases were decided already on the first cue. Looking at participants best fitted with WADD, they were fitted with higher Delta values (mean of 35.8, SE = 3.95), with one subset of participants having much higher values than participants best fitted with DE. All participants best fitted with one of the BC models, reassuringly had Delta values larger than 70, same as in our simulations <ref type="figure">(Figure 6a</ref>; see also <ref type="bibr">Figure S1b in Supplemental Material)</ref>. How much information did people best described by the DE consume as compared to the more information hungry WADD strategy? Our results suggest that they inspected on average 4.6 (SE = 0.20) pieces of information and at most 6.1 pieces of information <ref type="figure">(Figure 6b</ref>), whereas people using the WADD strategy would consider all 12 of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>For most choices people make in their every-day life they can choose among several options and have access to numerous informative cues. People can integrate all the information at hand or they can use lexicographic heuristic strategies that omit most of it. Yet these two popular types of choice strategies require different forms of knowledge about the informational value of different cues. People using integrative strategies need to learn exact cue weights whereas people relying on lexicographic heuristics merely need to learn cue order. Here, we introduced the CLE paradigm that allowed us to investigate the interplay between strategy selection and learning about the structure of the environment. We used participants' responses in an estimation task deployed after they made choices and their periodical self-reports on cue importance while they were making choices. We found that almost all participants exhibited knowledge that goes beyond mere cue order -they learned cue weight values. We then postulated least-mean-squares learning as a mechanism of how cue weights are learned and uncovered how the weights evolved during the choice task while the participants were receiving feedback on chosen options. Feeding the obtained cue weights into the integrative WADD strategy and newly developed DE lexicographic strategy, we found that the WADD strategy described the largest group of participants. The DE heuristic best described a sizable group of participants, and more importantly, these participants learned cue weights as well. Nonetheless, the group that used the DE strategy performed worse in the estimation task and the insight questions showed weaker discrimination between the cues.</p><p>The adaptive appeal of learning cue weights Why would people using lexicographic heuristics such as the DE strategy learn cue weights when they only need cue order? Firstly, it has been argued and empirically demonstrated that people select their strategies adaptively, and they are more likely to choose a strategy in environments where this strategy excels (e.g. <ref type="bibr" target="#b42">Lieder &amp; Griffiths, 2017;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006)</ref>. For example, lexicographic strategies are known to perform well in settings where there is one very informational cue and there are high inter-correlations among the cues (e.g. <ref type="bibr" target="#b30">Katsikopoulos, 2011;</ref><ref type="bibr">Şimşek &amp; Buckmann, 2015)</ref>. In such settings people tend to use lexicographic heuristics more often. However, the structure of the environment, and consequently the best-performing strategy, might be unknown beforehand <ref type="bibr" target="#b80">(Stojić et al., 2016)</ref>. By learning cue weights people can switch between the different types of strategies as deemed appropriate, whereas by learning only cue order they would be locked into choosing among lexicographic strategies. <ref type="bibr" target="#b27">Hogarth and Karelaia (2007)</ref>, for instance, showed theoretically that it would be beneficial to adopt the TTB when people have little experience and their knowledge about the structure of the environment is poor, and switch to the WADD later on as they become more experienced. If TTB users learned only cue order such adaptive switch could not be executed.</p><p>Second, learning the cue weights has been shown to be an efficient way to learn cue orders. <ref type="bibr" target="#b84">Todd and Dieckmann (2005)</ref> designed a simulation in which they compared how fast a series of learning mechanisms learn cue order from choice feedback. The competing approaches included a model that directly learned cue validities, models that tallied how many times a cue led to correct decisions and reordered cues accordingly, simpler ordering rules that after each decision moved cues that led to correct decisions earlier in the cue order, and an associative LMS model that learned orders from weights. They found that the LMS model was the fastest cue order learner, despite learning orders indirectly. However, they argued that the LMS algorithm implies a high cognitive cost and memory load. One caveat of these cue order learning models is that they lack the mechanism for learning cue direction (i.e. whether positive or negative difference in cue values leads to a correct choice), instead assuming this information is known. By contrast, the LMS model simultaneously learns cue directions and takes them into account in computing cue order. More importantly, Todd and Dieckmann only investigated how these models learn when they are given feedback about whether choices were correct. This is somewhat limiting as people often do not experience options they do not choose, and therefore they can rarely learn whether their choices were correct. It is possible to extend the Todd and Dieckmann analyses in scenarios like the one we studied, where the models are provided with feedback about the criterion value of chosen option. The LMS model can operate well with either type of feedback-cue weights can be learned either from correctness or criterion value feedback. The models directly learning cue-orders studied by Todd and Dieckmann could leverage stored cue and criterion values of chosen options to simulate choices in memory. Thus, the fundamental learning events would be simulated choices, as opposed to finding out whether actual choices were correct. For instance, 10 choices imply an equal number of stored criterion values. These could be used to simulate 45 choices among 2 options and 120 choices among 3 options, a substantial increase in learning sample when compared to learning from choice feedback. Such an approach would also lead to orders of magnitude more computation for all models directly learning cue-orders, whereas the LMS approach would require exactly the same amount of computation. Thus, the LMS approach becomes the most costefficient approach in the setting with criterion value feedback, while there is no reason to expect it will be learning slower than models learning directly cue-orders.</p><p>Finally, in real life people do not tackle only choice problems and they might use the knowledge gained in other ways. One way the cue weight knowledge can be used is for predicting the quality of options, as in our estimation task. This is available in choice situations where feedback comes in terms of criterion values. This is always the case when people have only their experience to teach them, as opposed to having information about outcomes of actions that were not taken or an authority informing them whether their choice was correct or not. Ability to predict qualities of options has its own value; for example, people often have to communicate their predictions, say quality of a restaurant or price of a stock a year from now. Hence, by learning cue weights people can seamlessly transition between choice and estimation tasks. Another way is for tackling choices in other domains. Richer (generative) models of the environment can be used to form hierarchical representations that facilitate learning in related other problems. For example, <ref type="bibr" target="#b38">Lake, Salakhutdinov, and Tenenbaum (2015)</ref> showed that this mechanism might underlie human ability to successfully generalize their experience to new tasks based only on few observations, and illustrated how the same hierarchical representation can be used in multiple ways -action, imagination and explanation (for more general discussion, see also <ref type="bibr" target="#b39">Lake, Ullman, Tenenbaum, &amp; Gershman, 2017)</ref>. The benefits of generalization might be large enough to outweigh any potential costs (i.e. cognitive or memory costs). Thus, learning the structure of the choice environment in a detailed manner might be people's default, either hard-wired by evolution or learned through experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interactions between strategy selection and cue weight learning</head><p>Even though a choice of a particular strategy did not influence whether participants learned cue weights or cue order, we found differences in cue weight knowledge between strategy users, suggesting an interaction between strategy selection and cue weight learning. On average WADD users acquired better knowledge of cue weights than DE users, as evidenced by their estimation task performance, insight questions reports and LMS inferred cue weights.</p><p>One plausible explanation for this difference among strategies is that cue weight knowledge influences the adoption of a choice strategy <ref type="bibr" target="#b78">(Stojic, Olsson, &amp; Analytis, 2016)</ref>. In a theoretical analysis of strategy performance in choice tasks, <ref type="bibr" target="#b27">Hogarth and Karelaia (2007)</ref> showed that people should use a single variable heuristic while their knowledge of cue weights is imperfect and switch to the integrative strategy once they have learned the cue weights sufficiently well. Our results are consistent with this perspective. The DE users were learning at a slower pace and relied on that strategy because their knowledge was still imprecise. Given more time and observations their cue weight knowledge would improve and the linear integrative strategy would become more appealing in terms of maximizing utility. People potentially develop this strategy switching rule through their experiences with many environments. Instead of using a fixed switching rule, this could be a continuous optimization process. Along with learning of the cue weights there could be a simultaneous learning process of how effective the strategy is <ref type="bibr" target="#b42">(Lieder &amp; Griffiths, 2017;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006;</ref><ref type="bibr" target="#b80">Stojić et al., 2016)</ref>. Early in the learning process one of the strategies might yield better cost-accuracy trade-off, while another strategy could take over later when the knowledge improves. When coupled with individual variability in learning rates, commonly found in cue weight learning tasks, the causal link between strategy performance and cue weight knowledge could give rise to systematic differences between strategies observed in our data. What's more, this mechanism could explain variability in strategy adoption in empirical choice studies that allow learning, providing a potential explanation to an otherwise elusive phenomenon <ref type="bibr" target="#b6">(Bröder, 2012;</ref><ref type="bibr" target="#b10">Bröder &amp; Schiffer, 2006b;</ref><ref type="bibr" target="#b49">Newell, 2005)</ref>. However, it is also possible that the adopted strategy influenced how well the participants learned the cue weights in our task. For instance, using the DE strategy might result in paying attention to a subset of cues in each trial. This influence could be potentially captured with attention weighted updates of cue weights in the learning process of the LMS model <ref type="bibr" target="#b41">(Leong, Radulescu, Daniel, DeWoskin, &amp; Niv, 2017;</ref><ref type="bibr" target="#b46">Mackintosh, 1975)</ref>. The resulting bias in cue weight learning could explain why DE users were learning slower and consequently showed poorer performance in the estimation task. This mechanism would not be mutually exclusive with variability in learning rates influencing strategy selection, both mechanisms could play a role. With our data we cannot exclude either possibility. Evaluating an LMS model where cue weight updates are made dependent on cues examined by the DE strategy in each trial, would yield insights into these interactions. Collecting data on attention to cues, through eyeor mouse-tracking, would be indispensable to appropriately constrain and evaluate such a model. Studying the impact of the selected strategy on cue weight learning is an important direction for future research.</p><p>A recent study by <ref type="bibr" target="#b56">Parpart, Schulz, Speekenbrink, and Love (2017)</ref> also focused on interactions between strategy selection and learning the structure of the environment. They formulated active learning versions of WADD and TTB, assuming that people using the former will learn cue weights and the latter cue order. Then they investigated how people choose between two options, while they also strive to learn cue weights or order. Notably, in contrast to our approach, they tied strategies with the type of knowledge they require. They found that an active learning version of WADD described most of the participants. Our results show that even people that use lexicographic strategies such as TTB may preferentially learn cue weights, rather than order. Participants categorized as WADD users by <ref type="bibr" target="#b56">Parpart et al. (2017)</ref> may be people using lexicographic strategies who are learning the cue order by learning the cue weights first. In sum, we believe that our cue weight learning perspective and the active learning perspective of <ref type="bibr" target="#b56">Parpart et al. (2017)</ref> provide converging evidence that most people learn cue weights rather than directly learning order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From accidental errors to adaptive exploration</head><p>To fit the WADD and DE models to human data we assumed a trembling hand error. It is also well-known that parameters accounting for human errors improve the descriptive value of choice models (e.g. <ref type="bibr" target="#b43">Loomes et al., 2002;</ref><ref type="bibr" target="#b65">Rieskamp, 2008)</ref>. A trembling hand type of error introduces a free parameter , which assumes that participants choose the best option with probability 1 − , otherwise they mistakenly choose either of the three options with probability . This type of error has often been used in context such as ours (e.g. Bergert <ref type="bibr" target="#b7">Bröder &amp; Schiffer, 2003a</ref><ref type="bibr" target="#b8">, 2003b</ref><ref type="bibr" target="#b54">Nosofsky &amp; Bergert, 2007;</ref><ref type="bibr" target="#b64">Rieskamp, 2006;</ref><ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006)</ref>. In environments where there is no learning and the cue weights are already known, such as those used in most of the empirical comparisons of integrative and lexicographic strategies, a trembling hand parameter is undoubtedly sub-optimal and can be safely interpreted as lapse in judgment. By contrast, in environments where people have to learn the structure of the environment, such randomness in the choice process may reflect sensible and adaptive behavior. People may occasionally choose at random to explore the structure of the environment to gain information, that they could later on exploit to make better decisions. This is the so-called exploration-exploitation trade-off, a signature of reinforcement learning problems <ref type="bibr" target="#b53">(Niv, 2009;</ref><ref type="bibr" target="#b83">Sutton &amp; Barto, 2018)</ref>. In fact, the trembling hand parameter corresponds to the exploration parameter in the classicalgreedy model in the reinforcement learning literature <ref type="bibr" target="#b83">(Sutton &amp; Barto, 2018)</ref>. From the reinforcement learning point of view, the somewhat large parameter that we found in our modeling results might indicate a large exploration tendency, rather than an error in executing a choice strategy. Furthermore, choice tasks where options are characterized with multiple cues and cue-criterion relations have to be learned from experience is closely related to contextual multi-armed bandit tasks, a class of reinforcement learning problems that has been recently under focus (e.g. <ref type="bibr" target="#b70">Schulz, Konstantinidis, &amp; Speekenbrink, 2018;</ref><ref type="bibr" target="#b77">Stojic, Analytis, &amp; Speekenbrink, 2015;</ref><ref type="bibr" target="#b81">Stojic, Schulz, et al., 2020;</ref><ref type="bibr" target="#b92">Wu, Schulz, Speekenbrink, Nelson, &amp; Meder, 2018)</ref>. The link between multi-cue choice and reinforcement learning has been seldom made and there is potential for transferring insights from one field into the other in the future studies. For example, reinforcement learning models usually do not assume that individuals choose among multiple choice strategies, and heuristic strategies are rarely considered among the strategies that people may use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lexicographic heuristics for continuous multi-alternative environments</head><p>Up to now, the descriptive appeal of lexicographic heuristic strategies has been primarily assessed in choice environments with two options and binary cues describing them (e.g. <ref type="bibr" target="#b20">Gigerenzer &amp; Goldstein, 1996;</ref>. Although this setting has taken us a long way in the descriptive study of choice mechanisms, it is restrictive in the sense that it corresponds only to a subset of environments people experience in every-day life. Characteristically, when people have access to continuous cues, the TTB heuristic essentially reduces to a single-cue strategy and its prescriptive appeal is somewhat reduced <ref type="bibr" target="#b26">(Hogarth &amp; Karelaia, 2005b)</ref>. Assuming that people use only one cue in contexts with many continuous cues and many options is a strong, but potentially unrealistic assumption. Nonetheless, the informational and computational load of integrative strategies also increases in these contexts, making them much less appealing as well. Can lexicographic heuristic strategies provide good descriptive models in these settings? What type of strategies should we consider?</p><p>The ∆-inference strategy effectively generalizes TTB to continuous environments with the help of an additional discrimination parameter <ref type="bibr" target="#b45">(Luan et al., 2014)</ref>. Luan and col-leagues have showed that the strategy can achieve competitive performance in continuous environments. We equipped ∆-inference with an elimination mechanism, as implemented in the elimination-by-aspects strategy <ref type="bibr" target="#b86">(Tversky, 1972)</ref>. The resulting delta-elimination strategy can cope well with environments with more than two options and continuous cues. Our results show that DE described a sizable group of participants, even in an environment where an integrative strategy was bound to perform better. The strategy substantially reduced the pieces of information that people need to consider and the total number of cognitive operations performed. This is one of the few experiments where lexicographic heuristics have been tested and shown to capture people's behavior in scenarios with continuous cues where people choose among more than two options. Our work also corroborates and expands recent work by <ref type="bibr" target="#b44">Luan, Reb, and Gigerenzer (2019)</ref> showing that ∆-inference strategy describes well a large group of participants in binary choice problems. Based on previous results showing that people can adaptively switch decision strategies depending on the structure of the environment (e.g. <ref type="bibr" target="#b67">Rieskamp &amp; Otto, 2006)</ref>, we expect that in settings that are favorable to lexicographic strategies, such as environments with a skewed (J-shaped) distribution of cue importance or validities, DE would describe an even larger group of participants. Given our finding that DE users learned cue weights despite not needing them, we expect the same to happen in environments more favorable to lexicographic strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limits of the cue weight learning approach</head><p>We offered an account of how cue weight learning interacts with choice strategies in one linear environment. This raises several questions about the generalizability of our results and conclusions. First, the objective weights in our environment were fixed at 4, -3, 2, and -1. That is, there is a large dispersion in cue weights, and all cues make independent contributions. In such environments the WADD strategy is expected to thrive and therefore learning cue weights might be particularly beneficial. In settings where the cue dispersion is low and where there are high inter-correlations between cues, by contrast, lexicographic heuristic strategies are known to perform as well, and therefore, knowing cue weights would not confer a clear advantage. However, the DE users in our current experiment did not have a use of knowing cue weights and still learned them. In low cue dispersion or high cue inter-correlation environments we would expect to see more DE users, but we would expect them to still learn the cue weights rather than order. Earlier in the discussion we provided several arguments for people to learn cue weights even in settings where it is less beneficial to do so from a choice strategy point of view. Nonetheless, future experiments in settings with low cue dispersion and high inter-correlations among cues would provide a good robust-ness check of our results.</p><p>Further, our cue weight modeling approach is unlikely to work in more complex environments where cues are nonlinearly related to criterion. The LMS model provides a good approximation of what people know in linear environments, where there is a perfect match between the objective structure and the model <ref type="bibr" target="#b32">(Kelley &amp; Busemeyer, 2008;</ref><ref type="bibr" target="#b75">Speekenbrink &amp; Shanks, 2010</ref>). The LMS model belongs to a family of rule-based learning strategies, well known in category and function learning literature (e.g. <ref type="bibr" target="#b12">Busemeyer et al., 1997)</ref>. In nonlinear environments, by contrast, cue weights are not necessarily a good summary representation of the environment and people are more likely to learn in qualitatively different manner, better described with exemplar-based learning (e.g. <ref type="bibr" target="#b24">Hoffmann, von Helversen, &amp; Rieskamp, 2016)</ref>. Could people still rely on heuristic strategies? While knowledge in exemplar-based learning is contained in memories of encountered options there is an attention weight associated with each cue, presumably also learned through trial-and-error <ref type="bibr" target="#b36">(Kruschke, 1992)</ref>. These attention weights do not necessarily represent objective cue weights that determine relations between cues and criterion, but they do reflect their contribution and could be used as order information in lexicographic heuristics. Finally, even in these settings some people may learn using rule-based strategies (e.g. <ref type="bibr" target="#b24">Hoffmann et al., 2016;</ref><ref type="bibr" target="#b55">Olsson, Enkvist, &amp; Juslin, 2006)</ref>, and consequently, they may rely on heuristics for choosing among different options. Our understanding of how heuristics work in nonlinear environments, as well as how choices interact with learning of the structure of the environment, is still developing and constitutes an exciting venue for future research.</p><p>In our choice task participants got criterion values as feedback. Several studies found that with binary feedback people achieve high choice performance levels, implying that they successfully learned the cue validities (e.g. <ref type="bibr" target="#b40">Lee &amp; Cummins, 2004;</ref><ref type="bibr" target="#b54">Nosofsky &amp; Bergert, 2007)</ref>. Learning the structure of the environment with binary feedback proceeds differently. While cue weights can be learned <ref type="bibr" target="#b23">(Gluck &amp; Bower, 1988)</ref>, they do not necessarily correspond to the objective cue weights that determine the criterion values. This means that in a choice task with binary feedback people should have a hard time providing good estimates in the estimation task. However, Pachur and <ref type="bibr" target="#b55">Olsson (2012)</ref> found that participants show a good performance in an estimation task that followed a choice task with binary feedback. This could possibly be a consequence of the comparison of two objects fostering learning of how changes in cue values are associated with changes in the criterion, rather than learning the relations between cue values and the criterion <ref type="bibr" target="#b33">(Klayman, 1988a</ref><ref type="bibr" target="#b34">(Klayman, , 1988b</ref>). An interesting direction for future studies would be to examine in greater detail what underlies this performance by applying the same cue weight learning approach as done here.</p><p>There is scope for further development of the CLE paradigm we have used here. We noted that the LMS model fits of some participants produced unrealistic cue weights in the first half of the choice task, causing issues with fitting choice models. This is possible because the predictions the LMS makes for the choice task are not constrained. A potential remedy is to intersperse some estimation task trials in the choice task (e.g. <ref type="bibr" target="#b18">Gershman &amp; Niv, 2015)</ref>. <ref type="bibr" target="#b37">Lagnado et al. (2006)</ref> found that self-reports similar to our insight questions do not affect learning and strategy use, suggesting that such estimation task trials might not interfere either. Here we took a conservative approach, leaving the systematic examination of whether estimation task trials change how people go about their choices for future studies. In introducing insight questions during the choice task we relied on results by <ref type="bibr" target="#b37">Lagnado et al. (2006)</ref>. They examined learning and insight in a category learning task, which used four cues with binary cue values and correct/incorrect feedback. This task is structurally similar to the pairwise comparison tasks that have been extensively used to test integrative and lexicographic strategies <ref type="bibr" target="#b20">(Gigerenzer &amp; Goldstein, 1996)</ref>. In one of their experiments, exactly like in our study, they asked insight questions after each learning block. In another experiment they asked insight questions only at the end. They considered similar integrative and heuristic strategies with us and did not find any differences between experiments in people's strategy adoption, or in their learning performance overall. Given that the task in <ref type="bibr" target="#b37">Lagnado et al. (2006)</ref> was not exactly the same as ours, there is a small possibility that insight questions played a role in participants adopting cue weight learning independent of strategy use. Future studies using the CLE paradigm could also include control groups without insight questions to replicate the results from <ref type="bibr" target="#b37">Lagnado et al. (2006)</ref> in our setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This work contributes to our understanding of the strategy selection, in particular the interaction between choice strategy and learning of the structure of the environment. Our results showed that participants learned cue weights regardless of the choice strategy employed. Adopting a lexicographic strategy does not affect the type of knowledge about cues that participants acquired. The fact that lexicographic strategies require less knowledge to operate -the cue order -does not imply that people learn only the absolutely necessary knowledge. However, there was an interaction between adopted strategy and the cue weight learning process. Either individual variation in cue weight learning lead to differences in strategy selection, or strategy might have influenced how well participants learned the cue weights, or both; our design does not allow us to identify the direction. This work also contributes to development of heuristic strategies, both theoretically and empirically. The Delta-elimination strategy generalizes previous lexicographic strategies and can deal with choice environments with more than two options and continuous cues. Our findings show that it is an attractive strategy that substantial number of people adopted, thus providing empirical support for this new lexicographic heuristic. Our choice-learning-estimation paradigm is a small methodological contribution as well. Combining choice and estimation task allowed us to examine the extent and type of knowledge about the environment people acquired while they made choices. Our hope is that more studies will take the integrative approach and study strategy selection jointly with learning, as outlined here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark prediction models</head><p>To provide a benchmark to participants' performance in the estimation task and a comparison to the LMS and LMS d models, we use two baseline prediction (BP) models and perfect LMS and LMS d based learners. Baseline models provide a lower bound on the performance, the worst we would expect to see, while perfect learners provide an upper bound on the performance, the best we would expect to see.</p><p>Simplest baseline model would be a random guessing model. However, there is a more sensible strategy that still does not involve any learning of cue-criterion relationship. They could keep an estimate of a mean criterion value based on feedback in the choice task, and use this mean as a fixed prediction in the estimation task. It is a simple strategy that requires minimal learning and can provide better performance in the estimation task than random guesses. We formulate this strategy as one baseline prediction model that perfectly computes the mean (BP f ) and another that learns the mean slowly trial-by-trial (BP l ), potentially arriving at an imperfect estimate of the mean. These two strategies are the best that participants that learn only cue order during the choice task could do.</p><p>More precisely, the BP f model estimates the mean by taking the arithmetic average across all trials in the choice taskP = 1 T c T c t=1 Y t , while the BP l model updates the mean estimate after each observation according to the delta rulê</p><formula xml:id="formula_11">P t+1 =P t + η(Y t −P t )<label>(5)</label></formula><p>where η ∈ (0, 1) is a learning rate parameter. T c = 160 is the number of trials in the choice task. The perfect LMS and LMS d models provide an upper bound on prediction performance. They are fitted to predictions of a perfect learner, that is, a simulated participant that managed to produce completely accurate predictions in the estimation task. These models still learn the cue weights based on choices and feedback of each individual participant data from the choice task. However, they have learning rates that allow them to learn as much as possible from the feedback, trying to achieve perfectly accurate predictions in the estimation task.</p><p>For details on parameter estimation and model selection please see Supplemental Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark choice models</head><p>As for the estimation task, we provide benchmark models for the choice task, two baseline choice (BC) models and perfect WADD and DE models. Again, baseline models provide a lower bound on the performance, the worst we would expect to see, while perfect learners provide an upper bound on the performance, the best we would expect to see.</p><p>Baseline choice models consist of only basic information processing and do not require any knowledge about cues. The BC f model captures simple random choice, where the probability of choosing any option is equal and fixed at 1/3. The BC m model is more flexible. The probabilities of choosing options are also fixed, but rather than set to being equal they were estimated from the empirical frequencies of choosing them. This is the so-called multinomial model according to which participants choose randomly, but allowing for the possibility that participants have a response bias for either left, center or right option.</p><p>Perfect WADD and DE models are fitted to choices of a perfect decision maker, that is, a simulated participant that always made correct choices in the choice task, selecting options with highest criterion value in every trial. These models use cue weights learned by the best fitting perfect LMS model. Relying on the best possible cue weights for each individual, these models have tremble error (WADD and DE) and ∆ (DE) parameter that allow them to make choices as close as possible to the perfectly accurate choices.</p><p>For details on parameter estimation and model selection please see Supplemental Material.</p><p>Then we normalize the relative BIC scores to obtain the BIC weights</p><formula xml:id="formula_12">BICw i = ∆BIC i K k=1 ∆BIC k (6)</formula><p>where K ∈ {WADD, DE, BC f , BC m } in the choice task and K ∈ {LMS, LMS d , BP f , BP l } in the estimation task. This makes the weights dependent on models that are being compared, stressing the relative aspect of the model comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional details on results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-validation model selection results</head><p>We also performed cross-validation, an alternative model selection procedure, as a robustness check. Although BIC is widely applied and is supposed to approximate cross-validation in theory, it can be informative to compare our BIC based results to those obtained by cross-validation.</p><p>We estimated parameters of the choice models on the first three blocks of the choice task and tested their predictions on the fourth block. The results were similar to those obtained with model selection based on BIC. Mean log-likelihood deviance (computed for test trials) for DE was 78 while for WADD it was 74. Log-likelihood weights showed that the probability that DE was the best model was 0.30 while for WADD it was 0.54. These results show that the balance shifted further in favour of WADD, but not by much.</p><p>When we used cross-validation results to classify participants into strategy users we obtained 23 DE users, 44 WADD users and 10 baseline choice model users. These results are again similar to BIC based results, with the balance shifted more toward WADD. The confidence with which we classified participants was somewhat lower, as indicated by the mean log-likelihood weights (computed only for participants best fitted for a model) -0.73 for DE and 0.82 for WADD. This was to be expected, due to having less training data for fitting the models and generalization nature of the cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table S1</head><p>Results of modeling predictions in the estimation task and choices in the choice task. Choice models used the cue weights inferred by the best fitting LMS model for each participant. Note. BP = Baseline prediction model with estimated or learned mean (suffixes f and l respectively); LMS = Leastmean-squares network model with or without additional decay of the learning rate (suffix d); BC = Random choice model with fixed or estimated choice probabilities (suffixes f or m respectively); WADD = Weighted-additive model; DE = Delta-elimination model; N par = Number of free parameters of the model; BIC = Bayesian information criterion; BICw = Bayesian information criterion weights; N best = Number of participants best fitted by the model according to BICw; η and γ = Parameters in the LMS models; and ∆ = parameters in the WADD and DE models. In all columns except for the first two we display the mean and standard error of the mean in parenthesis below it, with exception for N best where in parenthesis we show mean BICw for those participants).  <ref type="figure">Figure S1</ref>. (a) The number of elements inspected by the delta-elimination (DE) heuristic as a function of the discrimination threshold (∆) value, obtained in simulations on our choice task using objective cue weights. The number of elements associated with the optimal threshold value of 19 (vertical dashed line), is 4.8 (horizontal dashed line). This is much fewer number of elements than the maximum of 12 for the weighted-additive strategy. (b) The model evidence, i.e. how well the fitted DE strategy predicts choices (the lower the better), and the estimated discrimination threshold (∆) parameter for all participants. The shape of the point marks the model fitting the participant's choices best: weighted-additive (WADD), DE or one of the baseline choice (BC) models.  <ref type="figure">Figure S2</ref>. (a) Participants best fitted with an LMS model with decaying learning rate (LMS d , N = 35) exhibited a faster evolution of subjective cue weights at the beginning and slower changes later on than those best fitted by the model without decay (LMS, N = 31). We illustrate median cue weight across participants for each trial, smoothed with a moving average of ten trials. (b) This pattern matched the differences in insight question ratings during the choice task when we divided participants into those best fitted with the LMS and LMS d model. Participants best fitted with LMS d model had more accurate ratings already in the first instance when the insight questions were asked and smaller changes later on, while participants best fitted with the LMS model exhibited more gradual changes throughout the choice task. In both panels participants best fitted with one of the baseline prediction models (BP f or BP l ) were not included.  <ref type="figure">Figure S3</ref>. (a) Insight questions data of both weighted-additive (WADD) strategy users (participants best fitted by WADD model) and delta-elimination (DE) users indicates they learned the cue order fairly well. (b) Insight questions data for baseline choice (BC) model users are mixed (pooled across both model variants). By the end of the choice task they seem to have gained some knowledge about the structure of the task. In (a) and (b) the points at trials 40, 80, 120 and 160 in the choice task are mean ratings from the arbitrary insight question scale, how strongly each feature relates to the criterion values, on a scale from -10 (highly negative) to 10 (highly positive). To allow for easier discrimination, ratings are displaced horizontally and connected by lines. Error bars represent standard errors of group means. (c) Evolution of cue weights in the choice task, as inferred by the best fitting least-mean-squares model (LMS or LMS d ), shown for participants best fitted with one of the BC models. They exhibit very limited knowledge by the end of the choice task. Weights are median cue weights across participants for each trial, smoothed with a moving average of ten trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>4, w 2 = − 3, w 3 = 2, w 4 = − 4, w 2 = − 3, w 3 = 2, w 4 = − 1</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In this experiment we had four other conditions that we will analyze and report separately. We designed these conditions to tackle a different question than the one we ask here: whether the act of choosing per se confers an advantage for acquiring knowledge about the environment.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">All the analysis and visualization of the results was implemented in R programming language, with the help of additional libraries<ref type="bibr" target="#b1">(Auguie, 2012;</ref><ref type="bibr" target="#b60">R Core Team, 2017;</ref><ref type="bibr" target="#b63">RevolutionAnalytics, 2014;</ref><ref type="bibr" target="#b73">Sharpsteen &amp; Bracken, 2015;</ref><ref type="bibr" target="#b88">Wickham, 2007</ref><ref type="bibr" target="#b89">Wickham, , 2009</ref><ref type="bibr" target="#b90">Wickham &amp; Francois, 2015;</ref><ref type="bibr" target="#b93">Wuertz, 2013)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The small decrease in choice performance in the last block probably occurred due to fluctuations in difficulty, although there was no significant difference between mean Euclidean norm of criterion values between 3 rd and 4 th block. We did not strictly control difficulty when constructing the stimuli, and since all participants received the same stimuli, this unlucky random draw was not canceled out.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional details on method</head><p>Parameter estimation in the estimation task</p><p>We fit each prediction model (LMS, LMS d , BP f and BP l ) to individual participant's predictions in the estimation task by minimizing the sum of squared error (SSE) between participant's predictions (P t ) and model predictions (P t ):</p><p>(1)</p><p>where P t is participant's prediction andP t is prediction of the model in trial t, while T e = 40 is the number of trials in the estimation task. We fit the perfect LMS and LMS d models by using criterion values Y t instead of individual predictions P t in Equation 1, essentially using a simulated participant that managed to make perfectly accurate predictions in the estimation task. Although there is a single set of criterion values in the estimation task across all participants, choice trajectories of participants differed and cue weight learning in the choice task could yield slightly different cue weights by the end of it, resulting in variation in fits of perfect LMS and LMS d across participants.</p><p>To optimize the parameters we use the Nelder-Mead simplex algorithm implemented in the optim function in R (R Core Team, 2017). We use multiple starting points that we choose by first evaluating a uniform distributed grid of initial parameters, performing K-means clustering on them and choosing the best parameter set in each cluster of points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter estimation in the choice task</head><p>We fit each choice model (WADD, DE, BC f and BC m ) to individual participant's choices in the choice task by minimizing the log likelihood of the data given the choice probabilities predicted by the model. The likelihood of the data set, L, is given by</p><p>where T c = 160 is the number of trials in the choice task, and P(M t = C t ) is probability of model making the same choice as participant made in trial t. We use the same algorithm and procedure as in the modeling of the estimation task to optimize the parameters.</p><p>We fit the perfect WADD and DE models by using choices corresponding to option i with maximum criterion value argmax i Y i t in each trial instead of participants' choices C t in Equation 2. In other words, we use a simulated participant that managed to make perfectly accurate choices in the choice task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Selection</head><p>As a measure of model performance we use Bayesian information criterion (BIC, the smaller the better; . The BIC score in the choice task is a monotonic transformation of the likelihood of the choice data</p><p>where ln(L) is the log transformation of the choice data likelihood, N par is the number of free parameters in the model, and T c = 160 is the number of trials in the choice task. The BIC score in the estimation task is a similar transformation of the SSE of the estimation data BIC = T e ln(SSE/T e ) + N par ln(T e )</p><p>where T e = 40 is the number of trials in the estimation task. While BIC scores take into account differences in complexity of the models by penalizing models with more parameters, differences between the models can be hard to interpret. Hence, for model comparison we use BIC weights, a simple transformation of BIC scores that can be directly interpreted as conditional probabilities that each model is the best one among the models compared .</p><p>First we subtract BIC score of the best model in the comparison set, BIC min , from BIC score of each model i</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social learning strategies for matters of taste</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Analytis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Barkoczi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Herzog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">415</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A response-time approach to comparing generalized rational and take-the-best models of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">; F B</forename><surname>Auguie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.33.1.107</idno>
		<ptr target="http://cran.r-project.org/package=gridExtraBergert" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="107" to="129" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>gridExtra: functions in Grid graphics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A componential analysis of cognitive effort in choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="111" to="139" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Hypotheses about relations between scaled variables in the learning of probabilistic inference tasks. Organizational Behavior and Human Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
		<idno type="DOI">10.1016/0030-5073(74</idno>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="90002" to="90008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The psychology of linear judgement models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Assessing the empirical validity of the &quot;takethe-best&quot; heuristic as a model of human probabilistic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1332" to="1346" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The quest for take the best -Insights and outlooks from experimental research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ecological rationality: Intelligence in the world</title>
		<editor>P. M. Todd, G. Gigerenzer, &amp; the ABC Research Group</editor>
		<meeting><address><addrLine>New York, NY, US</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="216" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian strategy assessment in multi-attribute decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.442</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="193" to="213" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Take The Best versus simultaneous feature matching: Probabilistic inferences from memory and effects of reprensentation format</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.132.2.277</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="277" to="293" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive flexibility and maladaptive routines in selecting fast and frugal decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.32.4.904</idno>
	</analytic>
	<monogr>
		<title level="m">Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="904" to="918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stimulus format and working memory in fast and frugal strategy selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<idno>doi: 10.1002/ bdm.533</idno>
	</analytic>
	<monogr>
		<title level="j">Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="361" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning functional relations based on experience with input-output pairs by humans and artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Byun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Delosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge, concepts and categories. studies in cognition</title>
		<editor>K. Lamberts &amp; D. R. Shanks</editor>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="408" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Us</surname></persName>
		</author>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Extrapolation: the sine qua non for abstraction in function learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Delosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="968" to="986" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple ways to construct search orders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dieckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
		<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Psychological plausibility of the theory of probabilistic mental models and the fast and frugal heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R P</forename><surname>Dougherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Franco-Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.115.1.199</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="199" to="213" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Does imitation benefit cue order learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garcia-Retamero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Takezawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="307" to="320" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Novelty and Inductive Generalization in Human Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<idno type="DOI">10.1111/tops.12138</idno>
	</analytic>
	<monogr>
		<title level="m">Topics in Cognitive Science</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="391" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Homo heuristicus: Why biased minds make better inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="107" to="143" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reasoning the fast and frugal way: Models of bounded rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="650" to="669" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fast and frugal heuristics are plausible models of cognition: reply to Dougherty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Franco-Watkins</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.115.1.230</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="230" to="239" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Probabilistic mental models: a Brunswikian theory of confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kleinbölting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="506" to="534" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">From conditioning to category learning: An adaptive network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Bower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="227" to="247" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Similar task features shape judgment and categorization processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Helversen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000241</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1193" to="1217" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ignoring information in binary choice with continuous variables: When is less &quot;more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="115" to="124" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple Models for Multiattribute Choice with Many Alternatives: When It Does and Does Not Pay to Face Trade-offs with Binary Attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.1050.0448</idno>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1860" to="1872" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Heuristic and linear models of judgment: matching rules and environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.114.3.733</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="733" to="758" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Simple heuristics and rules of thumb: Where psychologists and behavioural biologists might meet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioural Processes</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="97" to="124" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PROBabilities from EXemplars (PROBEX): A lazy algorithm for probabilistic inference from generic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Persson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="563" to="607" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Psychological heuristics for making inferences: Definition, performance, and the emerging theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Katsikopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="10" to="29" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The robust beauty of ordinary information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Katsikopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schooler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0020418</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="1259" to="1266" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A comparison of models for learning how to dynamically integrate multiple cues in order to forecast continuous criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2008.01.009</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="218" to="240" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cue discovery in probabilistic environments: Uncertainty and experimentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klayman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">317</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the how and why (not) of learning from outcomes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klayman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in psychology</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1988" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="115" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Representation and inference of lexicographic preference models and their variants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="380" to="399" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">ALCOVE: An exemplar-based connectionist model of category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.99.1.22</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="22" to="44" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Insight and strategy in multiple-cue learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lagnado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.135.2.162</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="162" to="183" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X16001837</idno>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">253</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Evidence accumulation in decision making: unifying the &quot;take the best&quot; and the &quot;rational&quot; models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D R</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="343" to="352" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dynamic interaction between reinforcement learning and attention in multidimensional environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radulescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dewoskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="451" to="463" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Strategy selection as rational metareasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">762</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A microeconometric test of alternative stochastic theories of risky choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Loomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Moffatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sugden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Risk and Uncertainty</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="103" to="130" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Ecological rationality: Fast-and-frugal heuristics for managerial decision making under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academy of Management Journal</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ja</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">From perception to preference and on to inference: An approach-avoidance analysis of thresholds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schooler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page">501</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A theory of attention: variations in the associability of stimuli with reinforcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mackintosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">276</biblScope>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fast, frugal, and fit: Simple heuristics for paired comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="29" to="71" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The aging decision maker: cognitive aging and the adaptive selection of decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Schooler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno type="DOI">10.1037/0882-7974.22.4.796</idno>
	</analytic>
	<monogr>
		<title level="j">Psychology and Aging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="796" to="810" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Re-visions of rationality?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2004.11.005</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="11" to="15" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Search strategies in decision making: The success of &quot;success</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rakow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="117" to="137" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Take the best or look at the rest? factors influencing &quot;one-reason&quot; decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Empirical tests of a fast-and-frugal heuristic: Not everyone &quot;takes-thebest&quot;. Organizational Behavior and Human Decision Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="82" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Reinforcement learning in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<idno>doi: 10.1016/ j.jmp.2008.12.005</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="139" to="154" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Limitations of Exemplar Models of Multi-Attribute Probabilistic Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Bergert</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.33.6.999</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="999" to="1019" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Type of learning task impacts performance and strategy selection in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Enkvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juslin</surname></persName>
		</author>
		<idno>doi: 10.1016/ j.cogpsych.2012.03.003</idno>
	</analytic>
	<monogr>
		<title level="m">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<editor>1371. Pachur, T., &amp; Olsson, H.</editor>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="207" to="240" />
		</imprint>
	</monogr>
	<note>Go with the flow: How to master a nonlinear multiple-cue judgment task</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Active learning reveals underlying decision strategies. bioRxiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Parpart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">239558</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Adaptive strategy selection in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="534" to="552" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">The adaptive decision maker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">PsychoPy -Psychophysics software in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Peirce</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jneumeth.2006.11.017</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience Methods</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="8" to="13" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Computer software manual</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Simple heuristics from the adaptive toolbox: Can we perform the requisite learning? Thinking &amp; Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austria</forename><surname>Vienna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><forename type="middle">T</forename><surname>Hinvest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<ptr target="https://www.r-project.org/Rakow" />
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Evaluating three criteria for establishing cue-search hierarchies in inferential judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rakow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fayers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hersby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1088" to="1104" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">doMC: Foreach parallel adaptor for the multicore package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Revolutionanalytics</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=doMC" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Perspectives of probabilistic inferences: Reinforcement learning and an adaptive network compared</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.32.6.1355</idno>
	</analytic>
	<monogr>
		<title level="m">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1355" to="1370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The probabilistic nature of preferential choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">1446</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Inferences under time pressure: how opportunity costs affect strategy selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.actpsy.2007.05.004</idno>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="258" to="76" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">SSL: a theory of how people learn to select strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Otto</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.135.2.207</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="207" to="236" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Does biology constrain culture?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Anthropologist</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="819" to="831" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel distributed processing, explotation in the microstructure of cognition</title>
		<editor>D. E. Rumelhart &amp; J. L. McClelland</editor>
		<meeting><address><addrLine>Cambridge, MA, US</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1958" />
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="154" to="172" />
		</imprint>
	</monogr>
	<note>Foundations</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Putting bandits into context: How function learning supports decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<idno>doi: 10.1037/ xlm0000463</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="927" to="943" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Memory, and Cognition</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Satistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Sub-optimal reasons for rejecting optimality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lagnado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="761" to="762" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">tikzDevice: R Graphics Output in LaTeX Format</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sharpsteen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bracken</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=tikzDevicȩ" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Learning from small samples: An analysis of simple decision heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Simşek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Buckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Learning in a changing environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0018620</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="266" to="298" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Project files for &quot;linear integration and lexicographic models of choice: A cue weight learning perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Analytis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<ptr target="Retrievedfromosf.io/7yxrz" />
	</analytic>
	<monogr>
		<title level="m">Open Science Framework</title>
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Human behavior in contextual multi-armed bandit problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Analytis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Seventh Annual Conference of the Cognitive Science Society</title>
		<meeting>the Thirty-Seventh Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2290" to="2295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Explaining interindividual variability in strategy selection: A cue weight learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Analytis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Cognitive Modeling</title>
		<meeting>the 14th International Conference on Cognitive Modeling</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="144" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Linear integration and lexicographic models of choice: A cue weight learning perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Analytis</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/yj2zc</idno>
		<ptr target="PsyArXiv.Retrievedfrompsyarxiv.com/yj2zcdoi:10.31234/osf.io/yj2zc" />
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Not everything looks like a nail: Learning to select appropriate decision strategies in multiple environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<idno type="DOI">10.17605/OSF.IO/FMA3P</idno>
		<ptr target="https://osf.io/fma3p/doi:10.17605/OSF.IO/FMA3P" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Analytis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">It&apos;s new, but is it good? How generalization and uncertainty guide the exploration of novel options</title>
		<idno type="DOI">10.1037/xge0000749</idno>
		<ptr target="http://dx.doi.org/10.1037/xge0000749" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General. doi</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Heuristics for ordering cue search in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dieckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1393" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Précis of Simple heuristics that make us smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="727" to="780" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Elimination by aspects: A theory of choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="page">281</biblScope>
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">AIC model selection using Akaike weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206482</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="192" to="196" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Reshaping Data with the reshape Package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="http://www.jstatsoft.org/v21/i12/" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">ggplot2: elegant graphics for data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="http://had.co.nz/ggplot2/book" />
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">dplyr: A Grammar of Data Manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Francois</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=dplyr" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Adaptive switching circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Hoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960" />
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>US: Stanford Univ Ca Stanford Electronics Labs</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Generalization guides human exploration in vast decision spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Meder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">915</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wuertz</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=fOptionsReferencesRCoreTeam" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>fOptions: Basics of Option Valuation. Computer software manual</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austria</forename><surname>Vienna</surname></persName>
		</author>
		<ptr target="https://www.r-project.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Satistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">AIC model selection using Akaike weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206482</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="192" to="196" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
