<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Aversion to option loss in a restless bandit task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
							<email>d.navarro@unsw.edu.au.author</email>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>2052</postCode>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>2052</postCode>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Baz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>2052</postCode>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>2052</postCode>
									<settlement>Sydney</settlement>
									<region>NSW, Australia</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Aversion to option loss in a restless bandit task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sequential decision making</term>
					<term>loss aversion</term>
					<term>dynamic environments</term>
					<term>reinforcement learning</term>
					<term>bandit tasks</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In everyday life people need to make choices without full information about the environment, which poses an explore-exploit dilemma in which one must balance the need to learn about the world and the need to obtain rewards from it. The explore-exploit dilemma is often studied using the multi-armed restless bandit task, in which people repeatedly select from multiple options, and human behaviour is modelled as a form of reinforcement learning via Kalman filters. Inspired by work in the judgment and decision-making literature, we present two experiments using multiarmed bandit tasks in both static and dynamic environments, in situations where options can become unviable and vanish if they are not pursued. A Kalman filter model using Thompson sampling provides an excellent account of human learning in a standard restless bandit task, but there are systematic departures in the vanishing bandit task. We explore the nature of this loss aversion signal and consider theoretical explanations for the results.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In everyday life we make a variety of decisions ranging from simple questions (e.g., what should I have for lunch?) to complex life choices (e.g., should I change jobs?). Often we need to make these choices without full information about what the payoffs will be, and in an environment where the payoff distribution itself can change over time -some careers might be lucrative today but irrelevant tomorrow -posing a complex explore-exploit dilemma for the decision maker <ref type="bibr" target="#b25">(Mehlhorn et al., 2015)</ref>. The explore exploit trade-off has been studied in a variety of literatures including machine learning <ref type="bibr" target="#b19">(Kaelbling, Littman, &amp; Cassandra, 1998)</ref>, statistics <ref type="bibr" target="#b43">(Wald, 1947)</ref> and psychology <ref type="bibr" target="#b45">(Wilson, Geana, White, Ludvig, &amp; Cohen, 2014)</ref>. In the psychological literature these problems are often studied using multi-armed bandit problems, where the decision maker is presented with several possible options that they must repeatedly choose between, and the distribution of rewards associated with each option is unknown to the decision maker (e.g., <ref type="bibr" target="#b0">Acuna &amp; Schrater, 2010;</ref><ref type="bibr" target="#b1">Anderson, 2012;</ref><ref type="bibr" target="#b2">Banks, Olson, &amp; Porter, 1997;</ref><ref type="bibr" target="#b4">Biele, Erev, &amp; Ert, 2009;</ref><ref type="bibr" target="#b9">Cohen, McClure, &amp; Yu, 2007;</ref><ref type="bibr" target="#b10">Daw, O'Doherty, Dayan, Seymour, &amp; Dolan, 2006;</ref><ref type="bibr" target="#b32">Reverdy, Srivastava, &amp; Leonard, 2014;</ref><ref type="bibr" target="#b36">Speekenbrink &amp; Konstantinidis, 2015;</ref><ref type="bibr">Steyvers, Lee, &amp; Wagenmakers, 2009;</ref><ref type="bibr" target="#b47">Yi, Steyvers, &amp; Lee, 2009;</ref><ref type="bibr" target="#b48">Zhang &amp; Yu, 2013)</ref>. For simpler versions of the multi-armed bandit problem, there are closed form solutions for optimal decisions <ref type="bibr" target="#b44">(Whittle, 1980)</ref> but in general this is not the case (see <ref type="bibr" target="#b7">Burtini, Loeppky, &amp; Lawrence, 2015)</ref>.</p><p>There is a relatively well-established pattern of findings for human performance in this kind of sequential decision task. For instance people typically show an inherent preference for information <ref type="bibr" target="#b3">(Bennett, Bode, Brydevall, Warren, &amp; Murawski, 2016;</ref><ref type="bibr" target="#b28">Navarro, Newell, &amp; Schulze, 2016)</ref>, though there are a number of learning and decision making problems that show different patterns <ref type="bibr" target="#b12">(Gigerenzer &amp; Garcia-Retamero, 2017;</ref><ref type="bibr" target="#b17">Iigaya, Story, Kurth-Nelson, Dolan, &amp; Dayan, 2016;</ref><ref type="bibr" target="#b49">Zhu, Xiang, &amp; Ludvig, 2017)</ref>. Moreover, the tendency to engage in exploratory behaviour changes systematically: it increases with cognitive capacity <ref type="bibr" target="#b15">(Hills &amp; Pachur, 2012)</ref>, aspiration level <ref type="bibr" target="#b14">(Hausmann &amp; Läge, 2008)</ref>, and level of resources <ref type="bibr" target="#b31">(Perry &amp; Barron, 2013)</ref>, decreases with age <ref type="bibr" target="#b24">(Mata, Wilke, &amp; Czienskowski, 2013)</ref>, and is influenced by prior knowledge about payoff distributions <ref type="bibr" target="#b27">(Mulder, Wagenmakers, Ratcliff, Boekel, &amp; Forstmann, 2012)</ref> and beliefs about the volatility of the environment <ref type="bibr" target="#b28">(Navarro et al., 2016;</ref><ref type="bibr" target="#b47">Yi et al., 2009)</ref>. Finally, the decision policies that human and machine agents employ typically shift when the environment is in some sense responsive (e.g. <ref type="bibr" target="#b5">Bogacz, McClure, Li, Cohen, &amp; Montague, 2007;</ref><ref type="bibr" target="#b13">Gureckis &amp; Love, 2009;</ref><ref type="bibr" target="#b16">Hotaling, Navarro, &amp; Newell, 2018;</ref><ref type="bibr" target="#b29">Neth, Engelman, &amp; Mayrhofer, 2014)</ref>.</p><p>In this paper we consider a related though somewhat distinct issue. The inherent viability of options in real life depends on the extent to which one pursues them. If I do not exercise, my ability to pursue an athletic career is greatly reduced, and if I do not show up for a first date I'm unlikely to be asked to go on a second. A house I wish to purchase will likely only remain on the market for a limited amount of time. In many situations the viability of an option is entirely beyond my control, but in others it is dependent on the investment of effort in pursuing the option. Perhaps I may not want to go to the workshop on Friday, but if I do not register my interest in it on Monday I will lose my place, so a modest amount of effort is required now in order to preserve my ability to pursue the option later.</p><p>This problem has not received as much interest as other variations on the exploreexploit dilemma, but there is some research on it. <ref type="bibr" target="#b35">Shin and Ariely (2004)</ref> presented people with a variation of the three-armed bandit task in which each option was associated with a fixed reward distribution, and all three options had the same expected value. The task imposed switching costs, with participants accruing a penalty (either monetary or opportunity cost) when switching between options. Whenever an option was left unchosen for a sufficiently long time it would "vanish" and subsequently become inaccessible to participants for the remainder of the task. In the original work human behaviour appeared irrational, with participants preferring to accrue considerable penalty in order to maintain all three options even though they had the same value. Later papers using a larger number of options that could differ in their value suggested a slightly more moderate view: people tend to prune the options down to a small number of relatively good options, but are reluctant to limit themselves to a single option <ref type="bibr" target="#b11">(Ejova, Navarro, &amp; Perfors, 2009)</ref>. Nevertheless, the central finding that people are reluctant to trim the option set down to the single best possibility has been replicated multiple times <ref type="bibr" target="#b6">(Bonney, Plouffe, &amp; Brady, 2016;</ref><ref type="bibr" target="#b11">Ejova et al., 2009;</ref><ref type="bibr" target="#b29">Neth et al., 2014)</ref>.</p><p>Theoretically, the explanation for this behaviour has tended to focus on loss aversion <ref type="bibr" target="#b35">(Shin &amp; Ariely, 2004)</ref> and the desire to preserve flexibility in future choices <ref type="bibr" target="#b29">(Neth et al., 2014)</ref>. Perhaps surprisingly, then, there are very few studies in the explore-exploit literature -at least to our knowledge -that have employed a "vanishing options" design in a restless bandit context. After all, one very obvious reason to show aversion to option loss is to hedge one's bets against the possibility that the payoff distributions might change. In an environment where good options can go bad simply due to unpredictable fluctuations, it is natural to want to keep options open. Suggestive evidence that people might be appropriately sensitive to this comes from <ref type="bibr" target="#b29">Neth et al. (2014)</ref>, who took an ecological perspective to the <ref type="bibr" target="#b35">Shin and Ariely (2004)</ref> task and found that when the rewards associated with each option would diminish the more they are chosen ("exhaustive" environments) people tended to switch between options in order to keep more options viable moreso than when the environment is stable or when options improved with use ("progressive" environments).</p><p>With this in mind we examine human performance on several variations of a vanishing bandits task, involving different levels of volatility (i.e., rate of change to the reward distribution), comparing it to a standard restless bandit task in which options do not vanish. To provide a point of comparison, we follow <ref type="bibr" target="#b36">Speekenbrink and Konstantinidis (2015)</ref> and apply a Bayesian reinforcement learning model employing a Kalman filter learning rule <ref type="bibr" target="#b10">(Daw et al., 2006;</ref><ref type="bibr" target="#b21">Kalman, 1960</ref>) and a Thompson sampling decision rule that selects options with probability proportional to the likelihood that they are the maximum utility option <ref type="bibr" target="#b8">(Chapelle &amp; Li, 2011;</ref><ref type="bibr" target="#b40">Thompson, 1933)</ref>. Using the Kalman filter as a quasi-ideal observer model -setting all parameters to veridical values for the task -we replicate earlier results showing that human performance in the standard restless bandit task is closely approximated by the Kalman filter model. Armed with this knowledge, we take the same model, apply it to the vanishing bandit task and investigate the systematic differences between the Kalman filter model and human performance in the vanishing bandit task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Task. The experimental task was designed to be a compromise between the so-called "doors" task used to study option loss <ref type="bibr" target="#b35">(Shin &amp; Ariely, 2004)</ref> and a more traditional multiarmed bandit task. Participants were presented with a simple experimental interface delivered through a web browser, that consisted of six distinct options labelled A to F that could be selected by clicking on the appropriate button, illustrated in <ref type="figure">Figure 1a</ref>. The instructions explained that during the "game" they would have a budget of 50 "actions" (button clicks), that every time they selected an option they would receive points, and that the goal of the task was to earn as many points as possible with their 50 clicks. On each trial they would be shown the points they received in a visually salient way (see <ref type="figure">Figure 1b</ref>) and feedback remained on screen for 800ms. The number of points accrued and the number of actions left stayed onscreen at all times.</p><p>The task as described closely mirrors a typical multi-armed bandit task. To introduce option loss into this task, a variant on the game introduced the concept of an "availability counter" displayed adjacent to the option. The instructions explained to participants that this counter indicated how long it would be (in terms of number of actions) before this option "vanished" if it was not selected. All six availability counters started at a value of 15. The availability counters for every non-selected option would decrease by one after every action, whereas the counter for the selected option would reset to 15. To ensure that the availability counters were visually salient, they were colour-coded: options that were close to vanishing (availability 1-3) were shown in red, options that would disappear soon (availability 4-6) were shown in orange, and other options were shown in green (availability 7-15). Once the availability of an option reached zero it "expired": the option and the corresponding response button both disappeared from the screen and could no longer be selected.</p><p>In all versions of the task, the rewards r generated by each option were sampled from a normal distribution with mean µ and fixed standard deviation σ n = 6. Two of the six options (randomly chosen) were initially set to have mean reward µ = 20, one had mean µ = 40, one had µ = 60 and the remaining two had µ = 80. However, for most participants the expected value of each option drifted randomly across trials: the mean µ t+1 for any given option on trial t + 1 was sampled from a normal distribution with centred on the mean from the previous trial µ t , with variability given by the standard deviation σ o (which differed between conditions).</p><p>Design. Both experiments employed a 2 x 3 between-subjects design, with the availability of options (constant or diminishing) and the rate of environmental change (static, slow and fast) as the manipulated variables. For the constant availability condition, options remained available throughout the task, whereas in the diminishing availability condition participants were given the version of the task in which options could vanish,  <ref type="figure">Figure 1</ref>. (a) Schematic illustration of the experiment as it appeared to participants in the decreasing availability condition. Each of the six options (A-F) is shown with a colour-coded "availability counter", indicating the number of trials left before the option vanishes if left unchosen. The color scheme used red for immediate (1-3), orange for soon (4-6), and green for later (7-15). The display for the constant availability condition removed the availability counters, but was otherwise identical (b) Feedback as it was shown to participants.</p><p>as described above. To create the three levels of environmental change, we set σ o = 0 in the static condition, σ o = 6 in the slow condition, and σ o = 12 in the fast condition.</p><p>The two experiments were matched in every detail except one. In Experiment 1, the rewards r were constrained to lie between 1 and 99 points, and a corresponding constraint was placed on the mean µ. 1 In Experiment 2 the upper bound was removed, allowing the rewards to increase well beyond the initial value. The original motivation for doing so was to see what effect the ceiling has on people strategies, but it quickly became apparent that removing the upper bound can change the dynamics of the task environment. An illustration of what the dynamic structure of the environment looked like for static, slow and fast conditions in both experiments is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. When the dynamics apply only over a bounded range (Experiment 1) it is quite typical to see the best options change: good options go bad and vice versa. When the bound is removed (Experiment 2) it is quite common to see a "runaway winner" where one option quickly dominates over all the others and remains dominant for the entire task. Accordingly, the main goal for pursuing both versions of the task was exploratory, to see how people respond to environments with these different dynamic structures.</p><p>Participants. Workers from Amazon Mechanical Turk were recruited to participate in the experiment (400 in Experiment 1, 300 in Experiment 2), and assigned randomly to conditions. Informed consent was obtained from all participants. As per the exclusion criteria, two participants were excluded from analyses because they selected the same option on every trial. For Experiment 1, 179 participants identified as female, 219 as male, and 2 selected other. Mean reported age was 34.9 (SD = 11.4; range = 18-76). For Experiment 2, 110 participants identified as female, 190 as male. Mean reported age was 34.4 (SD = 10.4; range 18-73). In both experiments participants were almost exclusively (&gt;95%) located in the United States. Tasks took about 10 minutes to complete and participants were paid US$1.70 for their time.</p><formula xml:id="formula_0">q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q</formula><p>Materials and procedure. Experiments were implemented as a custom web application hosted using Google Cloud Platform, and made available to participants via Amazon Mechanical Turk. At the beginning of the experiment, participants were told they were taking part in a decision-making game as part of a short psychological study investigating how people make decisions. They were then presented with a consent form which informed them about the study and its possible risks; the nature of confidentiality and disclosure of information; and their compensation for completing the task. After providing consent and demographic information, they received instructions corresponding to their assigned condition. To ensure that the participants understood the task, they then had to complete a knowledge check which consisted of three multiple choice questions. Failure to answer all three questions correctly resulted in participants being redirected back to the instructions page to recheck their knowledge before retaking the knowledge check. Participants were then directed to the actual game and completed it as per instructions of the previous page. Following the approach taken in earlier papers <ref type="bibr" target="#b16">(Hotaling et al., 2018;</ref><ref type="bibr" target="#b28">Navarro et al., 2016)</ref> each participant played the "game" three times (where each game is a 50 trial bandit task), always in the same condition. At the end of each game, participants were told how many points they had achieved, in comparison to the theo- retical maximum (and minimum) scores that could be achieved if one were to select the best (or worst) option on every trial. After participants had completed the three games, a completion screen appeared that signalled the end of the experiment. They were then given a completion code to receive payment through Amazon Mechanical Turk. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>As a simple measure of performance we calculated the average number of points per action that each participant received during the game. Illustrating this, the solid markers in <ref type="figure" target="#fig_2">Figure 3</ref> plot the mean score per action for every experiment, game, dynamic condition and availability condition; grey violin plots display kernel density estimates of the distribution across subjects. Although point scores are not easy to compare across conditions or experiments, they are comparable across games. As shown in <ref type="figure" target="#fig_2">Figure 3</ref> there is a slight tendency for scores to improve over games. In Experiment 1, the mean of points awarded per action rose from 65.5 in game 1 to 70.5 by game 3, with 283 of 400 (71%) of participants scoring higher on the final game than on the initial one. In Experiment 2, the numbers were 81.0 and 87.2 respectively, with 202 out of 300 (67%) of participants scoring higher on the final game. For simplicity our initial analyses aggregate performance across games, but we return to this topic when introducing model based analyses.  <ref type="figure">Figure 4</ref>. Human performance in the task. Panels plot the probability of choosing a "good" option (one of the top two) on every block of five trials, broken down by experiment, availability and dynamics.</p><formula xml:id="formula_1">q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q</formula><p>To examine performance at a finer grain, we classified individual responses as a "good" choice if it is among the two options with highest expected reward on that trial, including options that have been allowed to expire. Using this measure, the results for all six conditions in both experiments are plotted in <ref type="figure">Figure 4</ref>, aggregated across subjects and repeated games, and plotted in blocks of five trials. As is clear from inspection participants learned to make good choices. When the environment was static and option availability was constant, participants chose good options in the final block on 96% of cases in Experiment 1 and 93% in Experiment 2, but when options could vanish in the decreasing condition these numbers fell to 82% and 82% respectively. The same pattern is observed in the slowly-changing restless bandit task, with performance levels of 68% and 75% in the constant availability conditions in Experiments 1 and 2 falling to 54% and 60% in the decreasing condition. In the fast-changing environment there was a difference between Experiments caused by the fact that the unbounded drift in Experiment 2 allowed for the possibility of a "runaway winner" -where one option grows much faster than all the others as illustrated in the lower left panel of constant availability was only 50% in Experiment 1 but 70% in Experiment 2. Importantly, however, the effect of allowing options to become unviable was the same as in other cases: the performance drops to 41% and 53% respectively. In every case a Bayesian t-test found strong evidence for a difference in the proportion of good choices constant availability and decreasing availability (Bayes factors for the alternative, BF 10 , were never less than 47). <ref type="bibr">3</ref> To what extent do people keep options alive in the decreasing availability condition? <ref type="figure" target="#fig_3">Figure 5</ref> plots the average number of options still viable as a function of trial block, rate of change, and experiment. Visual inspection of the plot suggests that there are no differences between Experiments 1 and 2 for the static and slow change conditions (BF 01 = 4.8 and 5.1 respectively), but in Experiment 2 people retained fewer options in the fast change condition than they did in Experiment 1 (BF 10 =89). The latter is perhaps unsurprising in light of the fact that the dynamics of the fast change environment in Experiment 2 are rather different from those in Experiment 1, as depicted in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>One question of theoretical interest is whether the number of options that remain viable changes as a function of the dynamics of the environment. In Experiment 1, a 3 Analyses were conducted using the BayesFactor R package version 0.9.12-2 <ref type="bibr" target="#b26">(Morey &amp; Rouder, 2015)</ref>, using default priors in all cases (i.e., t-test analyses placed Cauchy priors with scale r = √ 2/2 over standardised effect sizes for H 1 , and ANOVA analyses used JSZ priors with medium scale value r = 1/2). See <ref type="bibr" target="#b34">Rouder, Speckman, Sun, Morey, and Iverson (2009)</ref> and <ref type="bibr" target="#b33">Rouder, Morey, Speckman, and Province (2012)</ref> for specifics. The t-tests reported here used the mean probability of a good choice across all trials as the dependent measure (in order to minimise sensitivity to noise), but the result is robust to the choice of operational measure: the same pattern of results is found if the analyses are conducted looking only at the final trial block.</p><p>Bayesian ANOVA suggests there is moderately strong evidence (BF 10 = 19.1) for the claim that on average people retained slightly more options -operationally defined as the average number of options still viable, taken across all trials -as the volatility of the environment increased, rising from 4.6 (SD = 0.9) in the static condition to 4.9 (SD = 1.1) in the slow change condition and 5.2 (SD = 0.8) in the fast change condition. In Experiment 2, however the evidence weakly favoured a null effect (BF 01 = 6.7): the average number of options retained shows no systematic pattern (mean = 4.7, 4.8 and 4.6 in static, slow and fast respectively; SD = 0.9, 1.1, 1.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model based analysis</head><p>The fact that performance declines when option threat is introduced to the task is consistent with previous literature, and is unsurprising. To obtain a more detailed perspective on how people respond to this manipulation, a computational approach is helpful. To minimise researcher degrees of freedom, our approach is derived from the systematic investigation of restless bandit tasks by <ref type="bibr" target="#b36">Speekenbrink and Konstantinidis (2015)</ref>. Specifically, we relied on the model that provided the best account of the largest number of individual participants in that paper, namely a Kalman filter learning model with a Thompson sampling decision rule. The Kalman filter learning rule provides a Bayesian approach to reinforcement learning <ref type="bibr" target="#b10">(Daw et al., 2006)</ref> that is well-suited to learning in dynamic environments. According the Kalman filter model, the learner's knowledge is represented by a posterior distribution over the expected reward associated with each option 4 , and under a Thompson sampling decision rule the model selects options with with probability proportional to the chance that they have maximum utility. See Appendix for details. <ref type="bibr">5</ref> To provide a strong test of the Kalman filter model's ability to capture human behaviour on a standard (i.e., constant availability) restless bandit task, we do not estimate any free parameters. Instead, all parameters associated with the noise and volatility in the environment were fixed a priori at the true values for each condition, and prior distributions were fixed to be very diffuse (see Appendix). Moreover, the model was not yoked to participant responses, and predicted the sequence of responses without being fed information about how human participants responded in the task (e.g., <ref type="bibr" target="#b37">Steingroever, Wetzels, &amp; Wagenmakers, 2014;</ref><ref type="bibr" target="#b46">Yechiam &amp; Busemeyer, 2005)</ref>. In all cases, model predictions are <ref type="bibr">4</ref> More generally one might use prospect theory <ref type="bibr" target="#b41">(Tversky &amp; Kahneman, 1992)</ref> to specify reference-point dependent nonlinear utility functions as Speekenbrink and Konstantinidis (2015) did, but in this case a simpler approach where the utility is assumed to be proportional to the number of points received provided a perfectly adequate account of the data, so we avoid introducing this complexity here.</p><p>5 It is worth noting that the manner in which we are using the Kalman filter model here is roughly in accordance with what <ref type="bibr" target="#b39">(Tauber, Navarro, Perfors, &amp; Steyvers, 2017)</ref> refer to as "descriptive Bayesian modelling". While we do use it as a sensible standard against which we can evaluate human behaviour, we do so because it has a track record of performing well as an empirical model of human reinforcement learning. The fact that it has a meaningful interpretation as a form of probabilistic Bayesian reasoning is an added bonus as it allows us to link model parameters to assumptions about the world. We do not claim that it should be viewed as a genuine normative standard for the task, though we note that in practice human performance rarely surpasses the Kalman filter in our data.  <ref type="figure">Figure 6</ref>. Human performance versus a Kalman filter model across all conditions and both experiments. The dependent variable plotted in this figure is the probability of making a "good" choice (operationally defined as one of the top two options). Each dot represents human and model performance aggregated across subject and across model runs, with each block of five trials, experiment and condition plotted separately. For the human data, the results are plotted separately by game (Kalman filter responses are the same in every game).</p><p>averaged across 500 independent simulations.</p><p>Proportion of good choices. Despite the somewhat stringent nature of the test, the Kalman filter model makes good predictions about human performance in the standard restless bandit task, as shown in the top row of <ref type="figure">Figure 6</ref>. These plots show every data point from the human data in <ref type="figure">Figure 4</ref> plotted on the y-axis, broken down by game number, against the corresponding choice probabilities that emerged from the Kalman filter model simulations on the x-axis. Across two experiments, three levels of volatility and ten trial blocks, the correlation between model predictions and human performance ranged from r = .93 to r = .96 across games. Perhaps more impressively, the best fitting regression line (solid line) is only slightly below the "perfect" regression line with slope zero and intercept one (dotted line). In light of this, it is not unreasonable to propose that the decision strategies that human participants applied in the standard restless bandit task are well-approximated by the Kalman filter model. With this in mind, we can take the Kalman filter model and apply it to the decreasing availability conditions, to obtain some insight into what "would have" happened if participants had employed the same strategies in both versions of the task. When we do this we obtain a systematic effect as illustrated in the lower panels of <ref type="figure">Figure 6</ref>. While the model still correlates well with human performance (ranging from r = .83 to r = .96) the regression line is now substantially shallower, especially for the earlier games. When compared against the Kalman filter model, people were much less likely to select a good option in the vanishing bandit task, despite the fact that in the standard task human performance and the Kalman filter were largely indistinguishable.</p><p>Switching between options. A slightly different perspective is offered by <ref type="figure">Figure 7</ref>, which plots the proportion of trials on which human participants switched options (i.e., made a different choice than the one made on the previous trial) against the corresponding proportion for the Kalman filter model. Again, the plots are shown separately for both experiments, all three games, all three dynamic conditions and both availability conditions, with separate markers for each block of five consecutive trials. When the environment is static and option availability is constant (top right panel), human participants switch between options at essentially the same rate as the Kalman filter throughout the task and across all three games: the plot markers lie close the dashed line in all cases. When volatility and option loss are introduced to the task, people switch between options in a fashion that differs from the model. Curiously, the two manipulations have different effects. First consider what happens when volatility is added within a standard (constant availability) restless bandit task. The top row of <ref type="figure">Figure 7</ref> shows that in the slow change or fast change conditions people tended to switch between options slightly less than the model (i.e., the markers tend to lie below the dashed lines), which might be expected if people underestimate the volatility of the environment. In contrast, consider the effect of adding option loss. Whereas previously people were switching at a similar or reduced rate to the model, in almost every case the plot markers in the bottom row of <ref type="figure">Figure 7</ref> lie above the dashed line, indicating that people now switch more often than the model. This would be expected if people are engaging in some deliberate strategy to retain options, or are in some respect averse to allowing the availability counter to drop too low.</p><p>Number of options retained. To explore how people adapted to the threat of option loss in more detail, <ref type="figure" target="#fig_6">Figure 8</ref> plots the average number of options that remain viable at every stage of the task, for both human participants and the model. As is clear from inspection in every case human participants retained more options than the model: by the end of the task, human participants typically have about 3-4 options still viable, whereas the Kalman filter typically retains only 1-2. Note also that although participants retained fewer options in later games (i.e., in all six panels, the curves shift downward from game 1 to game 3, in no case does the number of options retained fall to the same level as the Kalman filter model. Again this is suggestive of some form of aversion to option loss.</p><p>Choices by availability. If human participants are averse to option loss relative to the Kalman filter model, what precisely is the nature of this difference? Do people roughly follow the Kalman filter model on almost all trials, only occasionally shifting to "save" an option on the very last trial before it vanishes? Is the signal driven by perceptual cues, arising only when the option turns red (i.e., when availability drops to three or less)? Or is the effect more continuous, in which the subjective utility associated with choosing an option rises gradually the closer an option gets to vanishing? Although the task was not designed to explicitly test this, we can obtain a preliminary answer computing the aver- Game 3 <ref type="figure">Figure 7</ref>. Comparison of the probability of switching options, Kalman filter (x-axis) versus human (y-axis). Every panel displays six plots, one for each experiment and game. Within each plot, individual markers are shown for every block of five trials, with trial block number increasing from right to left. The panels separate the data by availability condition (rows) and dynamic condition (columns). Human participants switch more often than the Kalman filter in the decreasing availability condition (bottom row), but in the constant conditions (top row) the switch rates are similar, or show the opposite pattern with humans switching less often.</p><p>age probability of selecting any particular option as a function of its current availability level for both human participants and the Kalman filter model and look at the difference between the two, thereby controlling for the fact that both humans and the model will tend to ignore bad options. If participants are strategically "saving" options at the last moment, we should see a spike in human choice probability at availability level 1, whereas if the signal is perceptual this would appear over availability levels 1-3. Alternatively, if a rising urgency explanation is correct, we should see a more gradual bias where humans prefer to choose lower availability options than the model.</p><p>The results of this analysis are plotted in <ref type="figure">Figure 9</ref>. With one rather notable exceptionthe "spike" at availability 10 -the pattern of results closely mirrors what we might expect if loss aversion takes the form of a gradually rising signal. Across all three levels of volatility there is a smooth, roughly linear relationship between the availability level and the difference score. Visual inspection suggests the possibility that human performance may mirror the Kalman filter model more closely in highly dynamic environments, at least insofar as the correlation appears stronger on the left panel and the slope is flatter, but given the exploratory nature of the analysis this suggestion is somewhat speculative. Why does the spike at availability 10 occur? The answer is fairly unsurprising but perhaps important. When human participants solve the task, a very typical pattern is to cycle through the options A to F sequentially two or three times, strategically and systematically exploring all six options before making any decisions about which options are good and which are a bad. If one does this, the decrease in availability means that (with 6 options that reset to availability 15 after they are selected) people will produce a "run" of choices at availability 10 during the exploratory phase. The Kalman filter model has no equivalent behaviour. Because the model does not encode motor costs associated with switching (why jump from option A to option D when option B is closer?) and does not have any structured encoding of the task that would suggest that an "initial sweep" through the options would be a sensible exploratory strategy, it produces no such pattern. From the perspective of understanding aversion to option loss, the observed spike at 10 is somewhat uninteresting, but the strategic nature of the human behaviour that produces it is arguably of considerable interest for thinking about how people solve explore-exploit problems more generally.   <ref type="figure">Figure 9</ref>. Difference between human and Kalman filter choice probabilities in a vanishing bandit task (y axis), plotted as a function of option availability (x axis) and level of volatility in the environment (panels) and experiment (shape and shading). Averages are plotted as solid black markers, and the regressions (solid black lines) are computed without considering the outlier case at availability 10 (see main text for details).</p><formula xml:id="formula_2">q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Consistent with previous literature, human performance in short-horizon restless bandit tasks is captured remarkably well with a Kalman filter learning rule and Thompson sampling decision procedure <ref type="bibr" target="#b36">(Speekenbrink &amp; Konstantinidis, 2015)</ref>. Even without parameter estimation and making purely a priori model predictions, the correlation is very strong. When we introduce the threat of option loss to this task, there are systematic departures. While the correlation between the Kalman filter model and human data remains extremely strong there is a systematic shift in the regression line relating the model and human behaviour. Relative to this model, people retain more options and make lessrewarding choices.</p><p>These findings are consistent with the existing literature on option loss <ref type="bibr" target="#b6">(Bonney et al., 2016;</ref><ref type="bibr" target="#b11">Ejova et al., 2009;</ref><ref type="bibr" target="#b29">Neth et al., 2014;</ref><ref type="bibr" target="#b35">Shin &amp; Ariely, 2004)</ref>, but provide a stronger test of the claim. The simple fact that options can vanish in a vanishing bandit task means that two agents following the same underlying strategy might produce vastly different responses -by using the Kalman filter model as the basis for comparing the two conditions we can control for systematic differences in the structure of the task. Indeed, it is notable that the Kalman filter model also performs worse in the vanishing conditions than it does in the constant availability conditions even though (by design) it makes responses using precisely the same learning and decision rules in both cases. Even so, people's choices in the vanishing conditions tend to be poorer than those of the Kalman filter model, strongly suggesting that people employ different strategies when option loss is present.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explaining the effect of option threat</head><p>Why do people perform worse than the Kalman filter model in the decreasing availability conditions? The results seem intuitively plausible when viewed as a form of loss aversion, but there are other possibilities that should be considered. For instance, one possibility is that these tasks involve a form of "choice overload". Having too many options can be overwhelming or demotivating <ref type="bibr" target="#b18">(Iyengar &amp; Lepper, 2000)</ref>, and in a multi-armed bandit task, maintaining representations of six possibly volatile reward distributions is likely demanding and people need to trim down the options to something manageable. Though intuitively appealing in one sense -anecdotally, it does feel cognitively demanding to maintain representations of the values of six entities in working memory while doing this task -it is unclear why an explanation based on cognitive load would apply only when option viability is threatened.</p><p>Another possibility is the idea that people do not plan very effectively in the task. Other work on multi-armed bandit tasks has argued that people are myopic planners <ref type="bibr" target="#b48">(Zhang &amp; Yu, 2013)</ref> who do not look ahead very far when considering their next action. Taken literally, however, a myopic planner should allow options to expire extremely readily, especially when the environment is not too volatile. After all, an option that is currently quite poor is extremely unlikely to suddenly become better in the near future, and it would only be worthwhile retaining it if one's planning horizon were quite long. An alternative explanation, however, might acknowledge the possibility that people are aware of the limitations in their planning: that is, a "loss averse" strategy of retaining more options than one can foresee a use for might be viewed as a sensible hedge against computational limitations. If I know that my true planning horizon needs to be quite long but I am computationally limited, what should I do? Keeping one's options open, even if one is not quite sure why could be a very wise strategy, and is somewhat reminiscent of boundedly rational models of wishful thinking <ref type="bibr" target="#b30">(Neuman, Rafferty, &amp; Griffiths, 2014)</ref> and heuristic models of planning in machine learning <ref type="bibr" target="#b38">(Szita &amp; Lőrincz, 2008)</ref>. Indeed, to the extent that knowing when to allow an option to expire has an element of "predicting one's own future preferences" to it, it is very likely to be a difficult problem to solve <ref type="bibr" target="#b23">(Loewenstein &amp; Frederick, 1997)</ref> and one that might induce a certain amount of conservatism. Arguably this is not inconsistent with a loss aversion explanation, insofar as loss aversion might be viewed as a sensible adaptation in light of these computational limitations.</p><p>To the extent that the results do reflect loss aversion, it is worth thinking about the connection between aversion to option loss as it is formalised here and in related papers <ref type="bibr" target="#b11">(Ejova et al., 2009;</ref><ref type="bibr" target="#b35">Shin &amp; Ariely, 2004)</ref> and how loss aversion is more typically operationalised in restless bandit tasks. In <ref type="bibr" target="#b36">Speekenbrink and Konstantinidis (2015)</ref>, for instance, a prospect theory approach based on <ref type="bibr" target="#b41">Tversky and Kahneman (1992)</ref> was used as a mechanism for capturing the aversion to losing some abstracted notion of reward as-sociated with a choice -points, or monetary rewards -whereas in vanishing bandit tasks the losses operate at the level of entire options. If each option in a task is perceived as an affordance (mechanism for future actions in the environment), it seems plausible to think that the subjective feeling of loss aversion in this task is likely to be much stronger than in a typical restless bandit task. Indeed, the experimental design is somewhat reminiscent of tasks studying the endowment effect <ref type="bibr" target="#b20">(Kahneman, Knetsch, &amp; Thaler, 1990)</ref>. At the beginning of the task participants are "given" six labelled options: in one condition (constant availability) these options are presented as fixed and enduring characteristics of the world, and under these circumstances people value them "appropriately", at least in the sense of closely mirroring the pattern of behaviour shown by the Bayesian Kalman filter model. In another condition (decreasing availability) the options available to participants can be "taken away" by the experiment(er). It seems plausible that people feel a stronger sense of possession or entitlement to the affordances linked to response options than they do to more any abstract notion of points or even to modest amounts of money, producing a rather large and systematic deviation from the Kalman filter as typically implemented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Towards a computational account</head><p>Although the current work is limited in terms of the variety of modelling approaches we have considered, exploring the space of possible models is a natural direction to extend this work in the future. In this respect, our empirical data provide a number of hints. The (mostly) smooth pattern of deviation shown in <ref type="figure">Figure 9</ref> suggests that the value of returning to a diminishing option gradually increases with proximity to the disappearance. The one departure from that pattern (the spike at 10) is interesting in and of itself, as it strongly suggests a systematic exploratory strategy during the early stages of the task (see <ref type="bibr" target="#b0">Acuna &amp; Schrater, 2010)</ref>. Nevertheless, with the exception of this one systematic exploratory strategy, it does not seem technically difficult to capture the pattern of behaviour within the Kalman filter framework.</p><p>The simplest possibility would be to suggest that different Kalman filter parameter values apply when option threat is present. For instance, when options can vanish people might act as though the world is more volatile than they otherwise would (e.g., increase the parameter σ w that governs beliefs about the rate of change in reward rates). This would lead to increased exploration of alternatives, which in turn would ensure that fewer options disappear. Alternatively, one could capture the effect by modifying the reward function: the subjectively experienced reward r t associated with choosing an option might depend not only on the number of "actual" points received, but also upon the effect that the choice has on availability. That is, selecting an option that is about to expire might be inherently rewarding because of the gain to the availability total.</p><p>Looking beyond the Kalman filter, one possibility is to use dynamic programming to work out the optimal decision policy for the task under a variety of different assumptions (e.g., <ref type="bibr" target="#b22">Littman, 2009)</ref>. For example, if people believe that the reward rates are more volatile than it is (or the horizon for the task is longer than the 50 trials than it really is), a rational strategy would be to "cling" to more options than are really needed. This would produce sub-optimal behaviour in the task purely as a consequence of misconstruing the nature of the problem. Another alternative is to consider heuristic models. In option loss problems, after an initial exploratory sweep through the options, people might alternate between exploitation phases (always select the best option) and exploration phases (preserve/try all options). This two-mode strategy would be relatively simple to implement and could potentially describe performance in a variety of problems.</p><p>Finally, the fact that human performance improves across games provides an avenue for future modelling. The approach that we have taken in this paper is to give people a series of short sequential decision making tasks, and consistent with our earlier work adopting this approach <ref type="bibr" target="#b16">(Hotaling et al., 2018;</ref><ref type="bibr" target="#b28">Navarro et al., 2016)</ref> there is a small but consistent effect. In future work we hope to consider a wider variety of transfer effects in order to develop computational models that describe the higher order learning that people do within sequential decision tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How is option threat interpreted?</head><p>Regardless of what formal account best captures human behaviour in the task, it seems there is another puzzle: why does the signal scale in the linear fashion shown in <ref type="figure">Figure 9</ref>? In the task as currently operationalised, an option that has availability level 11 is no more likely to vanish in the short term than an option with availability level 15. At these levels, the "threat" of vanishing is so distant that it ought not to have any substantial effect on people's behaviour even if they are averse to option loss -after all, with a maximum of 6 options in the task, it would be possible for the decision maker to revisit every other response option twice without any risk of losing an option with availability 11. Realistically, it does not seem plausible to think that this task incorporates any meaningful difference in "threat" between availability levels 11 and 15. Nevertheless, the data do suggest that people treat these cases differently in the vanishing bandit task. Despite the fact that the availability counter merely expressed the known length of time before any losses would be incurred, and does not reflect any probability of immediate loss, people responded to the counter as if it represented something more akin to an increased hazard.</p><p>The reasons for this are not immediately apparent. In real life, of course, there are many situations in which proximity to a threat does imply increased hazard, and so it might be the case that people are simply over-generalizing from those situations. Sometimes proximity to a danger can increase the magnitude of the associated losses (e.g., being closer to a heat source increases the amount of burning), and at other times it affects probability of incurring a loss (e.g., the closer to a predator one gets the greater the likelihood of an adverse event). While this does sound plausible, it is also the case that there are other scenarios that do not work this way. For instance, except at very close distances, approaching the edge of a cliff does not increase the risk of falling off. The structure of the vanishing bandit task has more in common with "falling off a cliff" than it does with "being eaten by a tiger", yet people treat it more like the latter. It is not immediately obvious -to us at least -why falling off a cliff represents less of an ecologically plausible risk than being eaten by a tiger, so it is not clear why people appear to interpret the availability counter as if it reflected a rising hazard. This seems a worthwhile direction for further work. the Kalman gain, K jt = S j,t−1 + σ w 2 S j,t−1 + σ n 2 + σ w 2</p><p>In this expression σ n is the learners belief about the standard deviation of the noise and σ w is their belief about the rate of change in the underlying stochastic process. For our examples we fix these at their true (ideal observer) values, yielding σ n = 6 for all conditions, and a value of σ w that depends on the environment volatility: 0 in the static condition, 6 in the slow condition and 12 in fast condition. The value of S jt is the variance of the posterior distribution (after trial t) over the mean utility associated with option j and is given by</p><formula xml:id="formula_3">S jt = (1 − δ jt K jt )(S j,t−1 + σ w 2 )</formula><p>We set prior means and variances to E j0 = 50 and S j0 = 1000 respectively. The decision rule we used is a variation of the Thompson sampling rule, also known as probability of maximum utility, PMU. For option j on trial t, the learner's posterior belief about the mean reward associated with that distribution is Gaussian with mean E jt and standard deviation S jt . We assume a stochastic decision rule where the perceived value of this option v jt is represented by a single draw from this posterior <ref type="bibr" target="#b42">(Vul, Goodman, Griffiths, &amp; Tenenbaum, 2014)</ref>, and the decision maker always chooses the option with maximum perceived value (i.e., arg max j v jt ). In some versions of the Thompson sampling rule one samples proportional to the (posterior predictive) probability that the option will yield the highest actual reward r t on trial t, whereas another variation might sample proportional to the posterior probability that an option has the highest expected reward µ t on that trial. The latter version is implemented here.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of the dynamics used in both experiments and all three conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Average points awarded per action, plotted as a function of game, experiment and condition. Grey violin plots show kernel density estimates of the between subject distribution (averaged over trial), and solid markers show the average across participants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 2-so final performance in the The average number of options still viable in the decreasing availability condition, plotted separately for the three dynamic conditions, two experiment and for every block of five consecutive trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Average number of options remaining for human and model in the decreasing availability condition, aggregated across participants and model runs, and plotted separately for trial block, dynamics condition, experiment and game number. Trial block number runs from right to left within each plot.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This was implemented by forcing any values outside the range to lie at the boundary value, producing a slightly "sticky" boundary.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Source code for the experiments is included in the OSF repository along with data and analysis code, but for convenience demonstration versions of the experiment are available at http://compcogscisydney.org/ exp/#vanish</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>The Kalman filter provides a Bayesian reinforcement learning model that assumes the utility of options across time follows a Gaussian process, and as such is fairly well matched to the structure of the task. Our implementation of the Kalman filter model is taken from Speekenbrink and Konstantinidis (2015), with one simplification: we assume that the utility u t of the reward r t received on trial t is simply u t = r t , and do not fit a subjective prospect curve. The Kalman filter estimate of the expected utility E jt of option j on trial t is calculated via a simple update rule:</p><p>where E j,t−1 is the estimate of the expected utility from the previous trial, δ jt is an indicator function that equals 1 if arm j was chosen on trial t and 0 otherwise, and K jt describes</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Structure learning in human sequential decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schrater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1001003</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ambiguity aversion in multi-armed bandit problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="33" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An experimental analysis of the bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economic Theory</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="77" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Intrinsic valuation of information in decision making under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brydevall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Murawski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">1005020</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning, risk attitude and hot stoves in restless bandit problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Biele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="155" to="167" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Short-term memory traces for action bias in human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcclure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Research</title>
		<imprint>
			<biblScope unit="volume">1153</biblScope>
			<biblScope unit="page" from="111" to="121" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Investigations of sales representatives&apos; valuation of options</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bonney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Plouffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Academy of Marketing Science</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="150" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A survey of online experiment design with the stochastic multi-armed bandit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Burtini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Loeppky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lawrence</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.00757</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An empirical evaluation of Thompson sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems 24</title>
		<editor>J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, &amp; K. Q. Weinberger</editor>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2249" to="2257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcclure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="page" from="933" to="942" />
			<date type="published" when="1481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cortical substrates for exploratory decisions in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="issue">7095</biblScope>
			<biblScope unit="page" from="876" to="879" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">When to walk away: The effect of variability on keeping options viable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ejova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perfors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual meeting of the cognitive science society</title>
		<editor>N. Taatgen, H. Rijn, L. Schomaker, &amp; J. Nerbonne</editor>
		<meeting>the 31st annual meeting of the cognitive science society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1258" to="1263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cassandra&apos;s regret: The psychology of not wanting to know</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garcia-Retamero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="196" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Short-term gains, long-term pains: How cues about state aid learning in dynamic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Gureckis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="293" to="313" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sequential evidence accumulation in decision making: The individual desired level of confidence can explain the extent of information acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hausmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Läge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="243" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dynamic search and working memory in social recall</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Hills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pachur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">218</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Skilled bandits: Learning to choose in a reactive world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hotaling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual conference of the cognitive science society</title>
		<editor>C. Kalish, M. Rau, J. Zhu, &amp; T. T. Rogers</editor>
		<meeting>the 40th annual conference of the cognitive science society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1824" to="1829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The modulation of savouring by prediction error and its effects on choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Iigaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Story</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">When choice is demotivating: Can one desire too much of a good thing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Iyengar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="995" to="1006" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Planning and acting in partially observable stochastic domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Cassandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="99" to="134" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Experimental tests of the endowment effect and the Coase theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Knetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Thaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Political Economy</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1325" to="1348" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A new approach to linear filtering and prediction problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Basic Engineering</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A tutorial on partially observable markov decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="119" to="125" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Predicting reactions to environmental change. Environment, Ethics, and Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Loewenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frederick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="52" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Foraging across the life span: Is there a reduction in exploration with aging?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wilke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Czienskowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">53</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Unpacking the exploration-exploitation tradeoff: A synthesis of human and animal literatures. Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Braithwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="191" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">BayesFactor: Computation of Bayes factors for common designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=BayesFactor" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Computer software manual. R package version 0.9.12-2</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bias in the brain: A diffusion model analysis of prior probability and potential payoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mulder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Boekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2335" to="2343" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning and choosing in an uncertain world: An investigation of the explore-exploit dilemma in static and dynamic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schulze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="43" to="77" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Foraging for alternatives: Ecological rationality in keeping options viable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Neth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Engelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mayrhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual meeting of the cognitive science society</title>
		<editor>P. Bellow, M. Guarani, M. McShane, &amp; B. Scassellati</editor>
		<meeting>the 36th annual meeting of the cognitive science society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1078" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A bounded rationality account of wishful thinking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Neuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual meeting of the cognitive science society</title>
		<editor>P. Bellow, M. Guarani, M. McShane, &amp; B. Scassellati</editor>
		<meeting>the 36th annual meeting of the cognitive science society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1210" to="1215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neural mechanisms of reward in insects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Barron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Entomology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="543" to="562" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Modeling human decision making in generalized Gaussian multiarmed bandits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Reverdy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Leonard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="544" to="571" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Default Bayes factors for ANOVA designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Speckman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Province</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="356" to="374" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bayesian t tests for accepting and rejecting the null hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Speckman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Iverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="237" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Keeping doors open: The effect of unavailability on incentives to keep options viable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ariely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="575" to="586" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Uncertainty and exploration in a restless bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konstantinidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="351" to="367" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Absolute performance of reinforcement-learning models for the iowa gambling task. Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Steingroever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wetzels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J. ; M</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">161. Steyvers</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="168" to="179" />
		</imprint>
	</monogr>
	<note>A Bayesian analysis of human decisionmaking on bandit problems</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The many faces of optimism: A unifying approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Szita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lőrincz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on machine learning</title>
		<meeting>the 25th international conference on machine learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1048" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bayesian models of cognition revisited: Setting optimality aside and letting data drive psychological theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tauber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perfors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="410" to="441" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On the likelihood that one unknown probability exceeds another in view of the evidence of two samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="285" to="294" />
			<date type="published" when="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Advances in prospect theory: Cumulative representation of uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Risk and Uncertainty</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="297" to="323" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">One and done? Optimal decisions from very few samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="599" to="637" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Sequential analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1947" />
			<publisher>Dover</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multi-armed bandits and the gittins index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Whittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological</title>
		<imprint>
			<biblScope unit="page" from="143" to="149" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Humans use directed and random exploration to solve the explore-exploit dilemma</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2074" to="2081" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Comparison of basic assumptions embedded in learning models for experience-based decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yechiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="402" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Modeling human performance in restless bandits with particle filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Problem Solving</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Forgetful Bayes and myopic planning: Human learning and decisionmaking in a bandit setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2607" to="2615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Information seeking as chasing anticipated prediction errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th annual meeting of the cognitive science society</title>
		<editor>G. Gunzelmann, A. Howes, T. Tenbrink, &amp; E. Davelaar</editor>
		<meeting>the 39th annual meeting of the cognitive science society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3658" to="3663" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
