<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Running head: EFFECTS OF ADVISOR ACCURACY Effects of Advisor Accuracy on the Utilization of Algorithmic and Human Advice</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Möller</surname></persName>
							<email>malte.moeller@uni-passau.de.the</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Mayr</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Passau</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Malte Möller, Psychology and Human-Machine Interaction</orgName>
								<orgName type="department" key="dep2">Susanne Mayr, Psychology and Human-Machine Interaction</orgName>
								<orgName type="institution">University of Passau</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Passau</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Chair of Psychology and Human-Machine Interaction</orgName>
								<orgName type="institution">University of Passau</orgName>
								<address>
									<postCode>94032</postCode>
									<settlement>Passau</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Running head: EFFECTS OF ADVISOR ACCURACY Effects of Advisor Accuracy on the Utilization of Algorithmic and Human Advice</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>advice taking</term>
					<term>algorithm</term>
					<term>aversion</term>
					<term>appreciation</term>
					<term>decision making</term>
				</keywords>
			</textClass>
			<abstract>
				<p>While algorithmic decision making is frequently superior to human judgement, it has been repeatedly found that experiencing imperfect forecasts goes along with a decreased willingness to entrust decisions to an algorithm, constituting the so-called algorithm aversion (Dietvorst et al., 2015). In two experiments, it was investigated whether perceiving an algorithmic advisor as imperfect is sufficient for algorithm aversion to occur. All studies systematically varied the advisor (algorithm or human) in a within-subjects Judge-Advisor System paradigm (e.g., Logg et al., 2019). In Experiment 1, information about the advisor accuracy (low, high or no information available) was systematically manipulated within participants, while Experiment 2 demonstrated the performance of an algorithmic or human advisor of identical, but non-perfect accuracy prior to the task. Results of both experiments showed that participants adhered more strongly to advice given by an algorithmic as compared with a human advisor and were more willing to incorporate advice from highly as compared with less accurate advisors. Importantly, there was no indication of algorithm aversion in any of the results, strongly suggesting that imperfect algorithmic forecasting is not the sole determinant of algorithm aversion.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Running head: EFFECTS OF ADVISOR ACCURACY Effects of Advisor Accuracy on the Utilization of Algorithmic and Human Advice Algorithmic decision making is widely utilized in everyday life to e.g., propose music (Garcias de Assuncao &amp; Paula de Almeida Neris, 2018), match job offers to applicants <ref type="bibr" target="#b3">(Choung et al., 2023)</ref>, make financial decisions <ref type="bibr" target="#b10">(Downen et al., 2024)</ref>, or suggest the fastest route to a destination <ref type="bibr" target="#b0">(Agarwal et al., 2002)</ref>. In recent years, algorithms are increasingly involved in business <ref type="bibr" target="#b23">(Zhao et al., 2024)</ref>, governance <ref type="bibr" target="#b15">(Gritsenko &amp; Wood, 2022)</ref>, or health care decisions <ref type="bibr" target="#b5">(Damone et al., 2022)</ref>, rendering the interaction between human-and machine-made decisions a field with promising benefit, but also potential conflict <ref type="bibr" target="#b2">(Burton et al., 2020;</ref><ref type="bibr" target="#b18">Lee, 2018)</ref>. In that vein, despite the widespread (and sometimes even unnoticed) operation of algorithms, the general acceptance of algorithmic decisions as well as the confidence in their forecasts has been rather low (e.g., <ref type="bibr" target="#b1">Berger et al., 2021;</ref><ref type="bibr" target="#b2">Burton et al., 2020;</ref><ref type="bibr" target="#b8">Dietvorst et al., 2015;</ref><ref type="bibr" target="#b17">Kawaguchi, 2021)</ref>. Previous research in the field repeatedly found that decisions made by algorithms are perceived as less fair and trustworthy as compared with identical decisions made by a person or a group (see <ref type="bibr" target="#b22">Mahmud et al., 2022</ref>, for a recent review). This poses problems especially in situations in which human decision makers would actually benefit from algorithmic aids to inform their conclusions or could reallocate resources by confidently delegating decisions to an algorithm. Therefore, an investigation of the mechanisms guiding the use of algorithms in human decision making seems important to understand and potentially mitigate unjustified reservations against the use of algorithms in (assisted) decision making.</p><p>In an influential series of experiments by <ref type="bibr" target="#b8">Dietvorst et al. (2015)</ref>, participants performed a series of incentivized forecasts in real-life settings (e.g., predicting performance ranks of students in an MBA program) based on a set of relevant statistical information (e.g., their corresponding undergraduate degree, GMAT, and work experience). Importantly, participants had to decide Running head: EFFECTS OF ADVISOR ACCURACY whether they wanted to perform the task by themselves or delegate the forecasts to a pertinent algorithmic model that was specifically designed for that purpose. Depending on the experimental condition, participants were either familiarized with their own and the model's forecast performance in a separate phase prior to the actual decision or they directly started with the incentivized forecasting decisions. In the familiarization phase, participants always saw the correct solution for a forecasting. Depending on the experimental condition, they additionally saw their own just given estimate as well as the estimate of the statistical model (model-andhuman condition), saw their own just given estimate (human condition) or the model's forecast only (model condition). Finally, participants in the control condition were not required to enter their own estimate and did not see the model's forecasts prior to the decision. The results of the later decision phase revealed that participants were more willing to delegate the decisions to an algorithmic model (as compared with completing the task themselves), but only in the control and the human condition in which they did not experience any forecasts made by the algorithm.</p><p>Crucially, participants were significantly less likely to choose the algorithm after seeing it perform and inadvertently make inaccurate and non-perfect predictions in the human-and-model condition, as well as the model condition. This was true even though the algorithm's overall performance was superior to the participants in the task. This phenomenon of preferring human over algorithmic advice was termed algorithm aversion. <ref type="bibr" target="#b8">Dietvorst et al. (2015)</ref> assumed that by default humans expect a (near-)perfect (or superior) performance of algorithmic systems (as compared with human decisions) that leads to a general preference of algorithms when participants are naïve to the system's performance (as in the control condition as well as in the human condition). However, this preference turns into avoidance and disuse of algorithms when this expectation is violated by experiencing imperfect algorithmic judgement as in the human-5 Running head: EFFECTS OF ADVISOR ACCURACY and-model condition as well as in the model condition (see <ref type="bibr">Dietvorst &amp; Bharti, 2020, for further</ref> analysis of the potential mechanisms underlying the effect).</p><p>In contrast to the "algorithm aversion" found in the study by <ref type="bibr" target="#b8">Dietvorst et al. (2015)</ref>, related studies found the opposite pattern in decision preferences. For example, Experiment 1 of <ref type="bibr" target="#b21">Logg et al. (2019)</ref> employed a so-called Judge-Advisor System paradigm that required participants to estimate the weight of a person shown in a photograph. After entering their initial numerical estimate, participants received advice (also in the form of a numerical estimate) concerning the feature in question. Importantly, all participants received the same advice, but the advice was described as coming from another person or an algorithm. Participants were then allowed to modify their initial input. To measure the impact of the source of advice on human forecasting, the so-called Weight of Advice (WoA) measure was calculated by dividing the difference between the final estimate and the initial estimate by the difference between the advice and the initial estimate. WoA scores therefore reflect whether received advice was incorporated into own judgements, with scores of 0 showing that the final estimate was unaffected by the advice, while the final estimate matches the advice with WoA scores of 1. In contrast to the findings of <ref type="bibr" target="#b8">Dietvorst et al. (2015)</ref>, the results of <ref type="bibr" target="#b21">Logg et al. (2019)</ref> revealed that human decision makers relied more strongly on algorithmic as compared with human advice (i.e.</p><p>WoA scores were larger in the algorithmic than in the human advice condition), a phenomenon then coined "algorithm appreciation".</p><p>The opposing findings of "algorithm aversion" and "algorithm appreciation" raise questions about the crucial conditions that govern the (dis-)use of algorithmic advice in human decision making. To reiterate, participants in the study by <ref type="bibr" target="#b8">Dietvorst et al. (2015)</ref> only refrained from preferring an algorithmic decision (over their own decision) after having experienced its 6 Running head: EFFECTS OF ADVISOR ACCURACY imperfect performance. Instead, participants in the control condition and human condition were actually more likely to choose the algorithm over themselves to solve the upcoming forecasting trials. Importantly, participants in the Judge-Advisor System paradigm typically do not receive any information about actual or overall performance of the advisors (but see <ref type="bibr" target="#b9">Dietvorst et al., 2018</ref>), so that the task setting is comparable to the control or human condition employed by <ref type="bibr" target="#b8">Dietvorst et al. (2015)</ref>. Therefore, it might be argued that the occurrence of "algorithm appreciation" in tasks employing the Judge-Advisor System paradigm does not contradict the conclusions drawn by <ref type="bibr" target="#b8">Dietvorst et al. (2015)</ref>, because the perception of imperfect algorithmbased judgement, as a supposed precondition for "algorithm aversion" to occur, was not met.</p><p>Experiment 1 was set out to further test this assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>The goal of Experiment 1 was to test whether the occurrence of "algorithm appreciation" is due to the lack of information about the (in-)accuracy of algorithmic and human advisors. To this end, alleged advisor accuracy was systematically varied across three levels (i.e., "high", "low", and "no information available") in an otherwise standard Judge-Advisor System paradigm (e.g., <ref type="bibr">Logg et al., 2019, Experiment 1)</ref>. If participants adhere more strongly to advice coming from an algorithm (as compared with a human advisor) in situation with undisclosed advisor accuracy, "algorithm appreciation" is expected in the "no information" condition, indicated by larger WoA scores after receiving algorithmic as compared with human advice. However, if the failure to provide perfect judgement is sufficient to result in "algorithm aversion", WoA scores are expected to be smaller for the algorithmic as compared with the human source of advice, when both sources are described as imperfect in the "low" and "high" (but not perfect) accuracy conditions. Running head: EFFECTS OF ADVISOR ACCURACY</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants.</head><p>A total of 183 mainly student participants (primarily recruited by online advertisement at the University of Passau) completed the study. Data from two participants were excluded 1 due to their free-field comments submitted at the end of the study. Specifically, one participant stated awareness of the manipulations and hypotheses in question and another participant reported finishing the study without fully complying with the task instructions. Furthermore, data from eight participants were removed because they reported to have already participated in the study.     <ref type="bibr">3, 90.5, 57.5, 16.8, 216, and 53</ref>.9 cm, respectively. Object weight had to be estimated (in g) from the pictures showing a color tube, a speaker, coins, a flat iron, a chair and a punch with corresponding true weights of 99, 3720, 103, 1013, 4700, and 349 g, respectively. Alleged Advisor Accuracy was either described as being unavailable in the "no information" condition or presented as the average deviation (in percent) between the true values and the estimates given by an advisor "who had already completed the study". Note that the presented accuracies were solely determined by the experimental condition and did not match any actual previous performance of any advisor. Specifically, the average deviation was set to a random integer between 50% and 60% in the "low accuracy" and between 5% and 15% in the "high accuracy" condition. Advisor Accuracy (in terms of a percentage of deviation from the respective true values) was generated anew for each participant and trial. Each factorial combination of Advisor Type (Human vs. Algorithm) and Advisor Accuracy (No information vs.</p><p>Low vs. High) was presented twice, resulting in a total of 12 trials with size and weight as relevant object feature in six trials, respectively. Each picture was randomly assigned to an individual trial and all trials were presented in random order. The experiment took about 9 minutes to complete. Running head: EFFECTS OF ADVISOR ACCURACY</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure.</head><p>The study was administered as an online survey on the SoSciSurvey platform. A schematic illustration of the procedure employed in Experiment 1 and Experiment 2 is shown in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>After giving informed consent, participants were told that the study was concerned with the ability of humans and algorithms to estimate features of objects presented as pictures.</p><p>Afterwards, a basic description of an algorithm was presented, describing it as "an automated system that processes information with respect to predefined rules and returns a specific outcome". It was emphasized that humans as well as algorithmic systems are generally capable of analyzing picture content, and that both can vary in their ability to correctly assess object features. Participants worked through a total of 12 trials at their own discretion. Each trial began with the presentation of a picture showing the to-be-judged object. In addition, the object in question and the to-be-estimated feature (size or weight) were explicitly mentioned in a sentence above the picture. Depending on the task, participants were asked to enter the estimated size or weight of the object in a field below the picture. The required unit of measurement (i.e. cm or g) was shown next to the field and entered values could contain up to two decimal places.</p><p>Participants were instructed not to use any tools to solve the task, but solely rely on their own abilities or intuitive judgement. Moreover, participants were asked to indicate their confidence in the accuracy of their estimate by setting a slider to values between 0 (no confidence at all, leftmost position) and 100 (absolute confidence, rightmost position) with intermediate steps of 10. After proceeding to the next page, the initial estimate of the participants (but not the respective picture) was shown again. Depending on the experimental condition, a numerical Running head: EFFECTS OF ADVISOR ACCURACY estimate of the overall accuracy of the respective advisor (in previous tasks) was presented. In the "no information" condition, no estimated value was shown. In addition to the numerical values and depending on the condition, it was explicitly stated either "no information about the accuracy of the source is available", or that the estimates from the specific source (algorithm or human) were "not very accurate" or "very accurate", for the "low" and "high" accuracy conditions, respectively. Participants could then modify their initial estimate or reenter the value.</p><p>Also, they were asked again to indicate their confidence in their current estimate. Submitting the final estimate and the corresponding confidence rating concluded a trial. After the last trial, participants were asked about their demographic information (i.e., age and gender) and they could state whether they had already participated in the current experiment. Finally, they were informed about the purpose of the study, could enter a comment, and were given the option to withdraw their consent to analyze the data. In the case of withdrawal, the respective data set was not included in any analyses and was ultimately deleted from the platform. Overall, the experiment took about 9 minutes to complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design.</head><p>The experiment comprised a 2 × 3 design with Advisor Type (Human, Algorithm) and</p><p>Advisor Accuracy (No information, Low, and High) as within-subject variables. Mean Weight of Advice (WoA) was treated as primary dependent variable, but confidence ratings were also analyzed.</p><p>A power analysis <ref type="bibr" target="#b12">(Faul et al., 2007)</ref> showed that given a = b = .05 and a population correlation of ρ = .30 of the effect of Advisor Type (i.e., the difference between WoA values for human and algorithmic advisors) among the three levels of the Advisor Accuracy variable, a sample size of 164 was necessary to detect a two-way interaction of size f = 0.150 (small to Running head: EFFECTS OF ADVISOR ACCURACY medium effect in terms of <ref type="bibr" target="#b4">Cohen, 1988)</ref>. However, data of 171 participants were collected so that an effect of size f = 0.146 could be detected. The global a-level was maintained at .05. All follow-up t-tests were two-tailed. The Bonferroni-Holm method <ref type="bibr" target="#b16">(Holm, 1979)</ref> was applied to prevent a-error accumulation for the pairwise comparisons. The critical a-level for each comparison is reported in brackets after the p-value of each test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weight on Advice (WoA).</head><p>WoA scores were calculated using the rationale outlined by <ref type="bibr" target="#b21">Logg et al. (2019)</ref>. Before entering the statistical analyses, WoA scores were winsorized at -1 and 1 which affected 4.58 % of all trials. WoA results of Experiment 1 are shown in <ref type="figure">Figure 3</ref> and in the upper section of <ref type="table">Table   1</ref>.  <ref type="table">Table 1</ref> A 2 × 3 MANOVA (with Pillai's trace as criterion) on the WoA scores showed significant main effects of Advisor Type and Advisor Accuracy with F(1, 170) = 20.672, p &lt; .001, ! " = 0.108 and F(2, 169) = 43.105, p &lt; .001, ! " = 0.338, respectively, as well as a significant interaction between both factors, F(2, 169) = 3.857, p = .023, ! " = 0.044. On average, WoA scores were larger for advice coming from an algorithmic as compared with a human source. Also, larger</p><p>WoA scores were obtained when advisor accuracy was high as compared with low advisor </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confidence ratings.</head><p>The difference between final and initial confidence ratings was calculated to indicate any confidence changes after receiving advice in the task. Therefore, positive (negative) confidence changes indicated an increase (a decrease) of confidence in the judgement between the final and initial estimate. Confidence changes in Experiment 1 are shown in <ref type="figure">Figure 4</ref> and in the lower section of Table 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4</head><p>A 2 × 3 MANOVA on the confidence changes only revealed a significant main effect of Advisor Accuracy, F(2, 169) = 3.054, p = .049, ! " = 0.035. The effect of Advisor Type as well as the interaction between both factors was not significant, with F(1, 170) = 1.664, p = .199, ! " = 0.010 and F(2, 169) = 1.376, p = .255, ! " = 0.016, respectively. Even though the descriptive results suggested that the increase in confidence ratings was larger in the high accuracy as compared with the low accuracy or no information condition, all follow-up comparisons did not reach significance after applying the Bonferroni-Holm correction. Due to the sequential nature of the procedure, all rank-ordered comparisons following the non-significant comparison between Running head: EFFECTS OF ADVISOR ACCURACY high vs. low accuracy, with t(170) = 2.273, p = .024 [.017], dz = 0.174, are treated as nonsignificant, irrespective of their p-value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Experiment 1 tested the assumption that the presumed or perceived accuracy of an algorithm determines whether its advice is used to inform human decisions. Specifically, without any knowledge about the correctness of an advice or the general accuracy of an advisor, participants should adhere more strongly to advice coming from an algorithm (as compared with a human), giving rise to "algorithm appreciation" (cf. the control condition in Experiment 1 of <ref type="bibr" target="#b8">Dietvorst et al., 2015)</ref>. This might be explained by the presumption of (near-)perfect or at least superior forecasting by algorithms (as compared with humans), when no available information contradicts this belief. In turn, "algorithm aversion" was expected for non-perfect algorithms. To this end, the accuracy of an advisor source (algorithm or human) was systematically manipulated across three levels ("no information", "low", and "high"). In line with the assumption, higher</p><p>WoA values for algorithmic than human sources in the "no information" condition indicated "algorithm appreciation": Participants incorporated advice from an algorithm more strongly into their own estimates than advice coming from a human source. However, WoA scores in the "high accuracy" condition also showed reliable "algorithm appreciation", even though the overall forecasting accuracy of the algorithm was presented as imperfect. In the "low accuracy" condition, there was no difference between the incorporation of advice of algorithmic und human sources. Importantly, the overall pattern of results did not show any indication of "algorithm aversion", even when the specific forecast most likely deviated from the correct answer and the algorithm was described as "not very accurate" (i.e., in the "low accuracy" condition). Running head: EFFECTS OF ADVISOR ACCURACY Still, the interaction between "Advisor Type" and "Advisor Accuracy" revealed that the use of advice provided by an algorithm is modulated by the level of assumed accuracy of the respective sources. In that regard, no significant difference between the WoA scores for algorithmic and human sources was obtained in the "low accuracy" condition. While this could suggest that advice utilization started to pivot towards "algorithm aversion" in this condition, the finding presumably reflects a general reservation to adhere to any advice coming from a source of relatively low accuracy: If the accuracy of both available sources is low, then there might be no need to distinguish between the specific sources anymore to arrive at a forecast. Either source is associated with large uncertainty and therefore all advice should be taken with caution. In support of this explanation, the smallest overall WoA scores were obtained in the "low accuracy" condition, which were significantly lower than the overall WoA scores measured in the two other accuracy conditions. In that vein, the main effect of "Advisor Accuracy" clearly shows that participants considered the provided accuracy information when entering their final estimate.</p><p>Regarding the preconditions for the emergence of "algorithm aversion" or "algorithm appreciation", the present findings contradict the assumption that participants presume or expect (near-)perfect performance of algorithmic (as compared with human) advisors in conditions with undisclosed accuracy of the respective sources (e.g., <ref type="bibr" target="#b6">Daschner &amp; Obermaier, 2022;</ref><ref type="bibr" target="#b11">Dzindolet et al., 2003)</ref>. If that had been the case, WoA scores (as a metric of advice taking) should have been highest in the "no information" condition which was not observed in the present experiment.</p><p>However, it has to be noted that Advisor Accuracy was implemented as a within-subjects factor in the current experiment. Therefore, the majority of algorithmic or human sources in the current experiment were described as imperfect for each participant. This might have created the overall impression that advice from all sources is imperfect, even though no information about the Running head: EFFECTS OF ADVISOR ACCURACY specific accuracy was available in some conditions. In line with the assumption, overall WoA scores in the "no information" condition were higher than the in the "low accuracy" condition, but smaller than in the "high accuracy" condition, suggesting that participants presumed an intermediate accuracy for the advisors in the "no information" condition. Still, participants clearly distinguished between the levels of presented accuracy and, more importantly, "algorithm appreciation" was obtained in the "no information" condition even if the sources were likely perceived as imperfect. In sum, the findings from Experiment 1 show that erroneous forecasting by algorithmic sources is not sufficient for algorithm aversion to occur.</p><p>In Experiment 1, advisor accuracy was presented as a numerical value (in percent),</p><p>indicating the overall deviation between the true value of the feature in question and estimates obtained for each source in an already concluded task. Albeit the results clearly show that the levels of accuracy were noticed and plausibly utilized by participants to cast their final estimates, the way accuracy information was given differs from procedures typically used in pertinent paradigms (e.g., <ref type="bibr" target="#b8">Dietvorst et al., 2015)</ref>. Specifically, paradigms that have previously reported "algorithm aversion" usually established the notion of imperfect accuracy of the respective sources by actually demonstrating algorithmic and/or human performance over a sequence of trials, instead of providing a numerical summary of past performance. Therefore, it might be that "algorithm aversion" only occurs after participants "witnessed" inaccurate algorithmic judgement. Experiment 2 was set out to test this assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>The goal of Experiment 2 was to convey the information that advice given by an algorithmic or human source is not perfect by demonstrating the inaccurate performance of both advisors. To this end, Experiment 2 consisted of two sequentially-presented phases, a Running head: EFFECTS OF ADVISOR ACCURACY demonstration phase, followed by a testing phase. Specifically, the demonstration phase was modelled after the "model-and-human" condition from typical paradigms investigating "algorithm aversion" (e.g., <ref type="bibr" target="#b8">Dietvorst et al., 2015)</ref>, while the testing phase was similar to the Judge-Advisor System paradigm <ref type="bibr" target="#b21">(Logg et al., 2019)</ref> used in Experiment 1. In the demonstration phase, participants saw individual pictures of objects, together with numerical estimates of a certain object feature (size or weight) coming from an algorithmic or human source and, importantly, the true value of the feature in question. To establish that both advisors are nonperfect predictors, advice from both sources always differed from the true value of the feature (see Method section for details). Because its sole purpose was to convey the (in-)accuracy of advice given by the respective sources, participants did not submit own estimates during the demonstration phase. In line with the pertinent literature, but different from Experiment 1, both advisors had the same overall accuracy. The demonstration phase was followed by a testing phase, similar to the paradigm used in Experiment 1 with the main difference that only Advisor Type (Algorithm, Human) was systematically manipulated in the testing phase.</p><p>If algorithmic advice is avoided (as compared with human advice) after experiencing an algorithm making erroneous predictions, smaller WoA scores (as a measure of adherence to advice when formulating own judgements) are expected for algorithmic as compared with human advisors, giving rise to the "algorithm aversion" phenomenon. However, if incorrect predictions are not sufficient for aversion to occur, WoA values should either not differ between the advisors or be larger for algorithmic as compared with human advice (i.e. "algorithm appreciation"), which is commonly found in tasks employing the Judge-Advisor Systems paradigm (e.g., <ref type="bibr" target="#b21">Logg et al., 2019)</ref>.</p><p>Method Running head: EFFECTS OF ADVISOR ACCURACY</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants.</head><p>A total of 63 mainly student participants, mostly recruited by online advertisement at the university of Passau, participated in the study. Data from six participants were excluded from further analyses for the following reasons: One participant reported awareness about the hypotheses in question and four participants indicated previous participation in the study. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials.</head><p>The material of the testing phase was identical to Experiment 1. Color photos of eight new objects (i.e., ananas, apple, bush, eggs, headphones, hot-water bottle, lamp, and sunshade) were presented during the demonstration phase with 350 ppi and image sizes (width × height, in px) of either 999 × 1500 or 2253 × 1500. Pictures were resized prior to presentation by the experimental program (maintaining aspect ratios) to widths of either 450 px (apple, eggs, headphones), or 300 px (all remaining) to fit the layout of the survey page. Size (height or length) was the to-be-estimated feature for half of the pictured objects (i.e., ananas, bush, lamp, and sunshade), while weight had to be estimated for the remaining pictured objects (i.e., apple, eggs, headphones, and hot-water bottle). Corresponding true size (in cm) or weight values (in g) Running head: EFFECTS OF ADVISOR ACCURACY were 31.5, 228, 80.1, 253.5 cm and 248, 175, 403, and 305 g, respectively. Estimates given by an algorithmic or human advisor were either both below, both above, or one below and one above the true value of the feature in question. In addition, the estimate from one advisor (either algorithm or human) was always more extreme than the estimate coming from the other advisor.</p><p>This resulted in a total eight estimate relations, all presented once during the demonstration phase. To ensure that both advisors had the same overall estimate accuracy, estimation deviations were generated by the following rationale: First, a random value between 25 and 35 determined the deviation (in percent) of the estimate from the true value of an object feature for both sources. Then, estimate deviation of the human source was increased by 5 percentage points. This step was repeated four times to create four independent estimate deviation pairs with one deviation for each advisor. To create the corresponding four pairs with more extreme deviations for the algorithmic source, the identical estimate deviation values were exchanged between the sources. Estimate deviation pairs were randomly assigned to an individual demonstration object. Finally, numeric estimates (given by the algorithm and human advisor) of the object feature in question were calculated. To this end, the percentage set by the estimate deviation values were added to or deducted from the true value of the corresponding object feature, depending on whether the features should be over-or underestimated in the condition.</p><p>On average, advisor estimates deviated 32.5 % from the true value of the feature in question.</p><p>Only estimates, but not the estimate deviations, were available to participant in each demonstration trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure.</head><p>The procedure was identical to Experiment 1, with the following exceptions: After receiving general information about the experiment, a demonstration phase commenced. Within Running head: EFFECTS OF ADVISOR ACCURACY this phase, participants saw a total of eight pictures in sequence, each of them showing an everyday object with a to-be-estimated feature. In addition to the picture, they received estimates of the object feature in question, one given by an algorithm and another from a person that already completed a related study. Participants were informed that all estimates in the study would come from the same algorithm and the same person and that they would not be required to enter an own estimate during this first phase. In each trial of the demonstration phase, the algorithmic and human estimates were stated below each picture, followed by the true value of the respective feature. Estimates and true values included the respective units of measurement (i.e., cm or g) with up to two decimal places. Upon completion of the demonstration phase, participants then proceeded to the testing phase. Participants were informed again that the estimates in the testing phase were provided by the same algorithmic and human source that gave the estimates during the demonstration phase. The remainder of the testing phase (and the current study) was identical to the procedure of Experiment 1. The experiment took around 9 minutes to complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design.</head><p>The experiment comprised a repeated measures design with Advisor Type (Algorithm, Human) as single factor. Mean Weight of Advice (WoA) was treated as primary dependent variable, but confidence ratings were also analyzed. A power analysis <ref type="bibr" target="#b12">(Faul et al., 2007)</ref> showed that given a = b = .05 and a population correlation of ρ = .30 between WOA values for algorithmic and human advisors, a sample size of 53 was necessary to detect a main effect of Advisor Type of the size f = 0.30 (medium to large effect in terms of <ref type="bibr" target="#b4">Cohen, 1988)</ref>. However, data of 57 participants were collected so that an effect of the size f = 0.29 could be detected.</p><p>Results Running head: EFFECTS OF ADVISOR ACCURACY Following the rationale of Experiment 1, WoA scores were winsorized at -1 and 1 which affected 2.63 % of all trials. A one-factorial MANOVA (with Pillai's trace as criterion) on the WoA scores showed a significant effect of Advisor Type with F(1, 56) = 4.527, p = .038, ! " = 0.075. On average, WoA scores were larger when the advice came from an algorithmic as compared with a human source. The difference between final and initial confidence ratings was calculated to indicate any confidence changes after receiving advice in the task. A one-factorial MANOVA (with Pillai's trace as criterion) on the confidence changes showed no significant effect of Advisor Type with F(1, 56) = 0.403, p = .528, ! " = 0.007. Results of the WoA and the confidence changes of Experiment 2 are shown in <ref type="figure" target="#fig_6">Figure 5</ref> and <ref type="figure">Figure 6</ref>, as well as in <ref type="table">Table 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results of Experiment 2 are straightforward: Participants weighted advice coming from an algorithm more strongly than advice coming from a human source, even though the specific algorithm (as well as the human advisor) did not provide perfect estimates of the features in the demonstration phase. Even though the demonstration of imperfect predictions by an algorithm was deemed crucial to reduce the willingness to delegate decisions to an algorithm in related studies <ref type="bibr" target="#b7">(Dietvorst &amp; Bharti, 2020;</ref><ref type="bibr" target="#b8">Dietvorst et al., 2015</ref><ref type="bibr" target="#b9">Dietvorst et al., , 2018</ref>, the current results solely showed "algorithm appreciation" in the current task setting. Therefore, it can be concluded that imperfect forecasting is not a sufficient condition for algorithm aversion to occur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>In two experiments, the present study investigated the hypothesis that perceiving an algorithmic advisor as inaccurate reduces the willingness to incorporate their advice to cast own judgements as compared with a human advisor. To this end, a variant of the Judge-Advisor Running head: EFFECTS OF ADVISOR ACCURACY System paradigm (e.g., <ref type="bibr" target="#b21">Logg et al., 2019)</ref> was employed in both experiments, measuring the well-established Weight on Advice (WoA) score as an index of advice adherence as well as subjective confidence in their own judgements. In Experiment 1, accuracy information about the advisors was explicitly stated, while Experiment 2 demonstrated imperfect (but overall identical) performance of algorithmic and human advisors before entering the Judge-Advisor System paradigm. Irrespective of the way of implementation, no result showed evidence of "algorithm aversion". Instead, participants consistently (with the exception of the "low accuracy" condition in Experiment 2) adhered more strongly to advice coming from an algorithm as compared with a human forecaster, revealing "algorithm appreciation". These clear-cut results suggest that erroneous performance is not the sole determinant of algorithm aversion, but that other conditions must also be met before the willingness to adhere to algorithmic advice is affected. In that regard, it is informative to highlight further differences between tasks typically obtaining "algorithm aversion" <ref type="bibr" target="#b8">(Dietvorst et al., 2015)</ref> and "algorithm appreciation" <ref type="bibr" target="#b21">(Logg et al., 2019)</ref>.</p><p>Apart from the availability of knowledge about the accuracy of algorithmic and human performance, both task settings also differ with respect to the level of control over the required prediction(s). Specifically, forecasting tasks obtaining "algorithm aversion" (e.g., <ref type="bibr" target="#b8">Dietvorst et al., 2015)</ref>typically ask participants to decide whether they want to perform a series of judgements by themselves or delegate them to an algorithmic system. If they commit the latter, participants usually do not have any control over the respective judgements. However, in the Judge-Advisor System paradigm, participants can choose freely whether they want to fully stick to the offered advice, adjust their initial judgement towards or even away from the recommendation, or not follow it at all. In other words, they are not bound to an algorithmic forecast and can specify a response at their own discretion. Therefore, the option to control or adjust algorithmic Running head: EFFECTS OF ADVISOR ACCURACY predictions might be a crucial aspect for the utilization of an algorithm. In clear support of that notion, <ref type="bibr" target="#b9">Dietvorst et al. (2018)</ref> found in a series of experiments that the option to modify the output made by an algorithm in a forecasting task significantly increased the likelihood to entrust decisions to an automated algorithmic system. This held true even for conditions in which participants could only change the forecasted values to a minor degree or only deliberately modify some, but not all predictions. Overall, this shows that exerting some control over the results of an algorithmic system effectively counteracts the tendency to disregard algorithms in human decision making, even when the algorithm is perceived to be imperfect. This conclusion is further backed-up by the results of the Judge-Advisor System paradigm employed in the present study. The consistent finding of "algorithm appreciation" even in conditions with (allegedly) imperfect algorithms is well in line with the assumption that the discouraging effect of imperfect judgement on the use of algorithmic advice can be overshadowed by the beneficial effect of extensive control over the outcome, ultimately fostering the adherence to algorithmic over human advice. Coming back to the initial outset of the current study, neither imperfect forecasting, nor the need to fully adhere to an algorithmically-generated output can be viewed as sufficient, but rather necessary preconditions for algorithm aversion to occur. Further tests of this conclusion might focus on diminishing or reversing the reliable finding of "algorithm appreciation" in the Judge-Advisor System paradigm by eliminating or reducing the amount of control participants have over the use of the given advice. If an advisor is perceived as imperfect and participants are required to incorporate the advice (at least to some degree) in their final decision, the appreciation for algorithmic advice should be reduced or even turn to "algorithm aversion". In sum, the current findings add further support to the conclusion that the (dis-)use of Running head: EFFECTS OF ADVISOR ACCURACY algorithmic advice is determined by at least two crucial factors: The perceived accuracy of the respective sources and the option to modify the output by an automated system. Running head: EFFECTS OF ADVISOR ACCURACY Note. Pictures of two (out of 12) real-world objects used as stimuli in Experiment 1 and in the testing phase of Experiment 2. Participants had to judge the height and weight of the depicted hydrant and chair, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Note. Mean change in confidence ratings (final -initial) as a function of Advisor Type. Error bars represent the standard errors of the means.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Finally, two data sets were excluded due to disproportionately fast completion times indicated by relative speed indices above 2.0<ref type="bibr" target="#b20">(Leiner, 2019)</ref>. The final sample comprised 171 participants (113 female, 56 male, 1 diverse, and 1 other) ranging in age from 18 to 60 years (M = 27.22, SD = 8.67). Participants either received course credit for their participation or entered into a raffle to win 1 of 5 vouchers of 10 € each. All experiments were conducted in accordance with the ethical guidelines of the German Psychological Association (DGPs) and the Professional Association of German Psychologists (BDP) (2005, C.III) and with the 1964 Declaration of Helsinki. All participants gave informed consent before entering the study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>12 colored digital photographs showing real-life objects (i.e., bench, chair, coins, flat iron, hydrant, orchid, paint tube, perfume flask, punch, sign, speaker, and ukulele) in naturalistic settings. All pictures were taken for the purpose of the experiment with a resolution of 350 ppi and image sizes (width ×height, in px) of either 999 × 1500 or 2253 × 1500, depending on image alignment. Pictures were resized prior to presentation by the Running head: EFFECTS OF ADVISOR ACCURACY experimental program (maintaining aspect ratios) to widths of either 400 px (coins), 420 px (speaker) 450 px (color tube and flat iron), or 300 px (all remaining) to fit the layout of the survey page. Examples of the pictures are shown in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1</head><label>1</label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Following</head><label></label><figDesc>the procedure of Logg et al. (2019), true size or weight values of the depicted objects were presented as advisor recommendations. Object size (height or length) had to be estimated (in cm) from the pictures showing a bench, a hydrant, an orchid, a perfume flask, a sign, and an ukulele with true sizes of 180.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure</head><label></label><figDesc>Figure 3 &amp; Table 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>A final participant was excluded due to disproportionately fast completion times indicated by a relative speed index above 2.0 (Leiner, 2019). The final sample comprised 57 participants (36 female, 21 male) ranging in age from 20 to 54 years (M = 27.84, SD = 7.62). Participants either received course credit for their participation or entered into a raffle to win 1 of 5 vouchers of 10 € each. All experiments were conducted in accordance with the ethical guidelines of the German Psychological Association (DGPs) and the Professional Association of German Psychologists (BDP) (2005, C.III) and with the 1964 Declaration of Helsinki. All participants gave informed consent before entering the study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 ,</head><label>5</label><figDesc>Figure 6, &amp;Table 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 Note.Figure 5</head><label>45</label><figDesc>Mean change in confidence ratings (final -initial) as a function of Advisor Accuracy and Advisor Type. Error bars represent the standard errors of the means. Running head: EFFECTS OF ADVISOR ACCURACY Note. Mean WoA scores as a function of Advisor Type. Error bars represent the standard errors of the means. Running head: EFFECTS OF ADVISOR ACCURACY</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>accuracy, t(170) = 9.122, p &lt; .001[.017], dz = 0.698, or when no information about advisor accuracy was provided, t(170) = 7.432, p &lt; .001[.250], dz = 0.568. Moreover, WoA scores were larger in conditions without information about advisor accuracy as compared with low advisor Running head: EFFECTS OF ADVISOR ACCURACY the levels of Advisor Type were compared for each level of Advisor Accuracy. Advice coming from an algorithm (as compared with a human) lead to larger WoA scores, when Advisor Accuracy was high or when no information was provided, with t(170) = 4.492, p &lt; .001 [.017], dz = 0.343, and t(170) = 2.815, p = .005[.025], dz = 0.215, respectively. However, Advisor Type did not significantly affect WoA scores when Advisor Accuracy was described as being low, t(170) = 0.856, p = .393 [.050], dz = 0.066.</figDesc><table /><note>accuracy, t(170) = 3.787, p &lt; .001 [.050], dz = 0.290. To further elucidate the interaction pattern,</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">All data processing steps are documented in the provided analysis scripts.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>The research reported in this article was supported by a grant provided by the Federal Ministry of Transport and Digital Infrastructure to the first author. Running head: EFFECTS OF ADVISOR ACCURACY  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Algorithms for GPS operation indoors and downtown</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Basch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bharti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bloebaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Casadei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Van Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<idno type="DOI">10.1007/s10291-002-0028-0</idno>
		<ptr target="https://doi.org/10.1007/s10291-002-0028-0" />
	</analytic>
	<monogr>
		<title level="j">GPS Solutions</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="149" to="160" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Watch Me Improve-Algorithm Aversion and Demonstrating the Ability to Learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rühr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Benlian</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12599-020-00678-5</idno>
		<ptr target="https://doi.org/10.1007/s12599-020-00678-5" />
	</analytic>
	<monogr>
		<title level="j">Business and Information Systems Engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="68" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A systematic review of algorithm aversion in augmented decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Jensen</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.2155</idno>
		<ptr target="https://doi.org/10.1002/bdm.2155" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="220" to="239" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">When AI is Perceived to Be Fairer than a Human: Understanding Perceptions of Algorithmic Decisions in a Job Application Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Seberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2023.2266244</idno>
		<ptr target="https://doi.org/10.1080/10447318.2023.2266244" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Statistical power analysis for the behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Erlbaum</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Decision-Making Algorithm and Predictive Model to Assess the Impact of Infectious Disease Epidemics on the Healthcare System: The COVID-19 Case Study in Italy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Damone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vainieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Brunetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bonino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ciuti</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2022.3174470</idno>
		<ptr target="https://doi.org/10.1109/JBHI.2022.3174470" />
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3661" to="3672" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Algorithm aversion? On the influence of advice accuracy on trust in algorithmic advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Obermaier</surname></persName>
		</author>
		<idno type="DOI">10.1080/12460125.2022.2070951</idno>
		<ptr target="https://doi.org/10.1080/12460125.2022.2070951" />
	</analytic>
	<monogr>
		<title level="j">Journal of Decision Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">S1</biblScope>
			<biblScope unit="page" from="77" to="97" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">People Reject Algorithms in Uncertain Decision Domains Because They Have Diminishing Sensitivity to Forecasting Error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bharti</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797620948841</idno>
		<ptr target="https://doi.org/10.1177/0956797620948841" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1302" to="1314" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000033</idno>
		<ptr target="https://doi.org/10.1037/xge0000033" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="114" to="126" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overcoming algorithm aversion: People will use imperfect algorithms if they can (even slightly) modify them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.2016.2643</idno>
		<ptr target="https://doi.org/10.1287/mnsc.2016.2643" />
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1155" to="1170" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Algorithm aversion, emotions, and investor reaction: Does disclosing the use of AI influence investment decisions?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Downen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.accinf.2023.100664</idno>
		<ptr target="https://doi.org/10.1016/j.accinf.2023.100664" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Accounting Information Systems</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The role of trust in automation reliance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Dzindolet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Pomranky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Beck</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1071-5819(03)00038-7</idno>
		<ptr target="https://doi.org/10.1016/S1071-5819(03" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human Computer Studies</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="38" to="45" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G*</forename><surname>Power</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03193146</idno>
		<ptr target="https://doi.org/10.3758/bf03193146" />
	</analytic>
	<monogr>
		<title level="j">Behav Res Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An algorithm for music recommendation based on the user&apos;s musical preferences and desired emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Garcias De Assuncao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Paula De Almeida Neris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference Proceeding Series</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Running head: EFFECTS OF ADVISOR ACCURACY</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Algorithmic governance: A modes of governance approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gritsenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1111/rego.12367</idno>
		<ptr target="https://doi.org/10.1111/rego.12367" />
	</analytic>
	<monogr>
		<title level="j">Regulation and Governance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="62" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Simple Sequentially Rejective Multiple Test Procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Holm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">When will workers follow an algorithm? A field experiment with a retail business</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.2020.3599</idno>
		<ptr target="https://doi.org/10.1287/mnsc.2020.3599" />
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1670" to="1695" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data and Society</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/2053951718756684</idno>
		<ptr target="https://doi.org/10.1177/2053951718756684" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Too fast, too straight, too weird: Non-reactive indicators for meaningless data in internet surveys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Leiner</surname></persName>
		</author>
		<idno type="DOI">10.18148/srm/2019.v13i3.7403</idno>
		<ptr target="https://doi.org/10.18148/srm/2019.v13i3.7403" />
	</analytic>
	<monogr>
		<title level="j">Survey Research Methods</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="248" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Algorithm appreciation: People prefer algorithmic to human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Logg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Minson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.obhdp.2018.12.005</idno>
		<ptr target="https://doi.org/10.1016/j.obhdp.2018.12.005" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="90" to="103" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">What influences algorithmic decision-making? A systematic literature review on algorithm aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K M N</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smolander</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.techfore.2021.121390</idno>
		<ptr target="https://doi.org/10.1016/j.techfore.2021.121390" />
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Perceived opacity leads to algorithm aversion in the workplace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.3724/SP.J.1041.2024.00497</idno>
		<ptr target="https://doi.org/10.3724/SP.J.1041.2024.00497" />
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica Sinica</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="497" to="514" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">#</forename></persName>
		</author>
		<idno>3&amp;#45&amp;</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">3&amp;#45&amp;&quot;6</title>
	</analytic>
	<monogr>
		<title level="j">&lt;=#</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">3&amp;#45&amp;</title>
	</analytic>
	<monogr>
		<title level="j">&lt;=#</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">3&amp;#45&amp;&quot;6</title>
	</analytic>
	<monogr>
		<title level="j">&lt;=#</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<idno>3&amp;#45&amp;</idno>
	</analytic>
	<monogr>
		<title level="j">J&apos;K$</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<idno>3&amp;#45&amp;&quot;6</idno>
	</analytic>
	<monogr>
		<title level="j">&lt;=#</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>L'k$ !?451</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>No K$ J'k$</surname></persName>
		</author>
		<title level="m">3&amp;#45&amp;&quot;6 M2?&quot;&apos;=58</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<idno>3&amp;#45&amp;&quot;6</idno>
	</analytic>
	<monogr>
		<title level="j">&lt;=#</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>L'k$ !?451</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>No K$ J'k$</surname></persName>
		</author>
		<title level="m">3&amp;#45&amp;&quot;6 M2?&quot;&apos;=58</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<idno>3&amp;#45&amp;&quot;6</idno>
	</analytic>
	<monogr>
		<title level="j">&lt;=#</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>L'k$ !?451</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>No K$ J'k$</surname></persName>
		</author>
		<title level="m">3&amp;#45&amp;&quot;6 M2?&quot;&apos;=58</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title/>
		<idno>3&amp;#45&amp;&quot;6</idno>
	</analytic>
	<monogr>
		<title level="j">&lt;=#</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>L'k$ !?451</surname></persName>
		</author>
		<title level="m">3&amp;#45&amp;&quot;6 M2?&quot;&apos;=58?&quot;6 /NO K$ LJ</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">#</forename><surname>&amp;%4</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3&amp;#45&amp;&quot;6 .E&apos;,4</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Schematic illustration of the sequence of presentations in Experiment 1 and Experiment 2. Note that all advisor estimates</title>
		<imprint/>
	</monogr>
	<note>except in the</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
