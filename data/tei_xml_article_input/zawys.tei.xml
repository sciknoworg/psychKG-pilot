<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How Goals Erase Framing Effects in Risky Decision Making</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Marbacher</surname></persName>
							<email>laura.marbacher@unibas.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department for Psychology</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<addrLine>Missionsstrasse 62a</addrLine>
									<postCode>4055</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><forename type="middle">B</forename><surname>Jarecki</surname></persName>
							<email>jana.jarecki@unibas.ch</email>
							<affiliation key="aff1">
								<orgName type="department">Department for Psychology</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<addrLine>Missionsstrasse 62a</addrLine>
									<postCode>4055</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Rieskamp</surname></persName>
							<email>joerg.rieskamp@unibas.ch</email>
							<affiliation key="aff2">
								<orgName type="department">Department for Psychology</orgName>
								<orgName type="institution">University of Basel</orgName>
								<address>
									<addrLine>Missionsstrasse 62a</addrLine>
									<postCode>4055</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How Goals Erase Framing Effects in Risky Decision Making</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Version Accepted at the 43th Annual Meeting of the Cognitive Science Society, CogSci 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>risky choice</term>
					<term>framing</term>
					<term>energy budget rule</term>
					<term>risk sensitivity</term>
					<term>goals</term>
					<term>choice modeling</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Evidence has shown that goals systematically change risk preferences in repeated decisions under risk. For instance, decision makers could aim to reach goals in a limited time, such as &quot;making at least $1000 with ten stock investments within a year.&quot; We test whether goal-based risky decisions differ when facing gains as compared to losses. More specifically, we examine the impact of outcome framing (gains vs. losses) and state framing (positive vs. negative resource states) on goalbased risky decisions. Our results (N=100) reveal no framing effects; instead, we find a consistently strong effect of the goal on risk preferences independent of framing. Computational modeling showed that a dynamic version of prospect theory, with a goal-dependent reference point, described 87% of participants best. This model treats outcomes as gains and losses depending on the state-goal distance. Our results show how goals can erase standard framing effects observed in risky choices without goals.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In many situations, people make risky choices under consideration of a future goal and a finite time horizon, for instance when people make stock investments they often have a goal of a specific annual return. Such a goal-driven risky decision represents a dynamic problem of resource accumulation of interest for cognitive and economic psychologists. To date, the research on risk taking with goals has mainly focused on gain outcomes and little is known about the role of the outcome domain, such as gains versus losses. A vast literature in psychology discusses the effect of outcome domains on risky decisions without goals. Almost forty years of research and formal risky choice models, such as cumulative prospect theory <ref type="bibr" target="#b21">(Tversky &amp; Kahneman, 1992)</ref>, suggest increased risk taking (variance preference) in the loss compared to the gain domain (hereafter gain-loss framing effects, <ref type="bibr" target="#b9">Kühberger, 1998;</ref><ref type="bibr" target="#b20">Tversky &amp; Kahneman, 1981)</ref>. This research, however, has given little attention to the influence of goals.</p><p>The relevance of goals in risky choice has been highlighted in recent work. Results have shown that in the presence of goals people shift from risk aversion (variance avoidance) to risk seekingness as the risky option's chance to reach the goal increases over the safe option's chance <ref type="bibr" target="#b1">(Fujimoto &amp; Takahashi, 2016;</ref><ref type="bibr" target="#b4">Jarecki &amp; Rieskamp, 2020;</ref><ref type="bibr" target="#b7">Korn &amp; Bach, 2018</ref><ref type="bibr" target="#b8">, 2019</ref><ref type="bibr" target="#b16">Pietras et al., 2003;</ref><ref type="bibr" target="#b15">Pietras &amp; Hackenberg, 2001;</ref><ref type="bibr" target="#b18">Searcy &amp; Pietras, 2011)</ref>. Critically, the standard model for risk taking with goals does not account for gain-loss framing effects; rather, it treats behavior as guided only by the chance to reach the goal <ref type="bibr" target="#b3">(Houston &amp; McNamara, 1988)</ref>.</p><p>The few investigations of gain-loss framing effects in risky choices with goals <ref type="bibr" target="#b11">Mishra &amp; Fiddick, 2012)</ref> have yielded mixed results, and the generalizability of these tests is somewhat limited because the tasks were oneshot risky choice tasks with goals (e.g., "reach a goal of $11000 in one choice"). This one-shot task differs from almost all research into risky decisions with goals in which decision makers have a longer time horizon to reach the goal. The time horizon is crucial because a short time horizon drastically reduces the computational complexity of risky choices with goals <ref type="bibr" target="#b4">(Jarecki &amp; Rieskamp, 2020)</ref>.</p><p>We investigate if gain-loss framing effects that have been found in risky choices without goals generalize to risky choices with goals. To this end, we employ two frames to demonstrate framing effects (see Task Design): The outcome framing, which refers to a change in the option's outcomes from gains into losses, and the state framing, which refers to the resource states (hereafter states). The state framing alters the state at the beginning of a choice task and the goal (e.g., by an additive shift of the initial state and the goal), but importantly it does not change the distance between the initial state and the goal. In addition, we investigate how optimal people behave in framed risky choices with goals and compare three formal choice models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Risky Choice Models for Goals and Domains</head><p>The standard optimal choice model for risk taking with goals (risk-sensitive foraging model) can describe an effect of goals on risk taking but has not been specified in a way to deal with gains versus losses. A standard risky choice model for framing effects (cumulative prospect theory) can model the effect of gains and losses but cannot model goal-based shifts in risk taking. An extension of prospect theory (dynamic prospect theory) can describe goal-dependent risky choices that deviate from the optimal choice.</p><p>Optimal Risk-Sensitive Foraging Model. The benchmark model for risky choices with goals is the risk-sensitive foraging model <ref type="bibr" target="#b3">(Houston &amp; McNamara, 1988)</ref>, it provides an optimal model for risky choices with a goal and limited time. It yields the choice that maximizes the chance to reach the goal in the remaining time. We investigate repeated choices between two risky options that occur at discrete times (hereafter trials) until a time horizon T is reached. The optimal choice in trial t depends on the number of remaining trials, the options, the goal g, and the state st-1 prior to the t th choice. The model yields the chance to reach the goal for each possible state st in each trial t using stochastic dynamic programming via backward induction (for reasons of space we will describe the model only briefly here, for further details, see <ref type="bibr" target="#b3">Houston &amp; McNamara, 1988;</ref><ref type="bibr" target="#b4">Jarecki &amp; Rieskamp, 2020)</ref>. To this end, the model enumerates the possible future decisions and the obtainable future states for all trials. Given the obtainable states after the last choice sT, it calculates a reward, which we take to be an indicator of the state sT meeting the goal g:</p><formula xml:id="formula_0">( , ) = { 0, if &lt; 1, if</formula><p>≥ Based on the rewards for all possible states sT after the last choice, the model calculates the expected reward in trial T-1 for both options for each obtainable state sT-1 in the trial before the last. The expected reward is the expected probability to reach the goal by choosing an option in a state in a trial given future optimal choices. The expected reward for selecting the risky option R in a state s in T-1 is:</p><formula xml:id="formula_1">( , , − 1) = ∑ ( −1 + , ) × ,</formula><p>where xi and pi denote a risky option's ith outcomes and probabilities, g is the goal. The expected reward of the safe option, is computed analogously. The optimal choice * maximizes the expected reward for each state s in trial T-1:</p><formula xml:id="formula_2">* ( , − 1) = { , }.</formula><p>The optimal model assumes a deterministic choice of the optimal option. Based on the optimal choice * in T-1, the model then calculates the expected reward of both options for all possible states in T-2. For instance, for the risky option:</p><p>( , , − 2) = ∑ * ( −2 + , − 1) × , and the expected reward of the safe option, in T-2 is computed analogously. Based on the expected rewards in T-2, the optimal model defines the optimal choice * for all potential states s in T-2. Given the optimal choice * in T-2, the model determines the optimal choice * for all potential states in T-3. This process of backward optimal choice selection, given optimal future choices, repeats until the first choice in the first trial is reached. Thus, the optimal model returns the optimal option for each state in each trial and it assumes that the decision maker deterministically chooses the optimal option, which yields the highest probability to reach the goal conditional on selecting the optimal option in all subsequent trials.</p><p>Broadly speaking, in risky choice tasks with rather high goals (which makes goal achievement difficult) the risky option's expected reward is tendentially higher than the safe option's expected reward, and therefore the optimal model prescribes that decision makers favor the risky option over the safe option in difficult tasks, and vice versa for easy tasks. Framings such as the domain of the outcomes (gain vs. loss outcomes) or the domain of the state (positive vs. negative state) should not affect risk taking, if the conditional chance to reach the goal (expected reward) does not differ across the domains.</p><p>Cumulative Prospect Theory. Cumulative prospect theory is the standard model describing the effect of gain-loss framing on risky choice without goals <ref type="bibr" target="#b6">(Kahneman &amp; Tversky, 1979;</ref><ref type="bibr" target="#b21">Tversky &amp; Kahneman, 1992)</ref>. The theory assumes that people always choose the option with the highest subjective prospect. The utility u of an option o (i.e., "prospect") is calculated by the sum of the subjective values of the outcomes, each multiplied by a decision weight : ( ) = ∑ ( ) ( ), where xi and pi denote the risky option's ith outcomes and the probabilities, respectively. The value function is ( ) = for x  r and</p><formula xml:id="formula_3">( ) = −(− )  for x &lt; r, in</formula><p>which λ is the loss aversion parameter and r is a reference point. Outcomes below the reference point represent losses, and outcomes above the reference point represent gains. The</p><formula xml:id="formula_4">cumulative decision weight ( ) is defined by ( ) = ( ∑ )  − ( ∑ )  for x  r and ( ∑ )  − ( ∑ )  for x  r. The probability weighting function is ( ) = ( + (1 − ) ) 1⁄ ⁄ with  + for x  r and  − for x  r.</formula><p>Via the parameters α, β and  the shape of the value function ( ) can differ for gains and losses, and consequently, can produce risk aversion for gains and risk seekingness for losses. This can describe the observed framing effects in risky choices without goals in the sense of higher risk seeking for losses compared to gains <ref type="bibr" target="#b20">(Tversky &amp; Kahneman, 1981)</ref>. Importantly, cumulative prospect theory in its standard form does not consider goals, time horizons, or states in goal-based risky choices. Cumulative prospect theory therefore can predict gain-loss differences but cannot predict differences in risk taking based on the distance to goals when no modifications to the standard model are incorporated <ref type="bibr" target="#b2">(Houston et al., 2014;</ref><ref type="bibr" target="#b4">Jarecki &amp; Rieskamp, 2020;</ref><ref type="bibr" target="#b10">McDermott et al., 2008;</ref><ref type="bibr" target="#b14">Payne et al., 1980)</ref>. Dynamic Prospect Theory. Dynamic prospect theory (Jarecki &amp; Rieskamp, 2020) is an extension of cumulative prospect theory that specifies how goals change risk taking. Its prediction need not to correspond with optimal choices. Contrary to standard prospect theory it assumes a dynamic reference point rt that depends on the distance to the goal. The dynamic reference point corresponds to the average outcome <ref type="formula">1</ref>(2) (4) <ref type="formula">3</ref>necessary to obtain for reaching the goal. The dynamic reference point is defined by the distance between the current state st and the goal g, and the remaining number of trials (T-t):</p><formula xml:id="formula_5">= ( − ) − .</formula><p>For each trial the reference point rt is calculated and the outcomes of the options are transformed into gains or losses by subtracting the reference point rt from the outcomes: x -rt.</p><p>The dynamic reference point allows an adaption of risktaking behavior to the current state and the goal. A high distance between current state and goal, and few trials left, which is typical for a difficult choice problem, lead to a high reference point. For high difficulty the dynamic reference point rt tends to be higher than the outcomes, thus the outcomes are perceived as losses, resulting in risk seekingness according to standard prospect theory. Vice versa, for low difficulty (lower goals, higher state, or a longer time horizon) the reference point tends to be lower than the outcomes, outcomes are perceived as gains, resulting in risk-aversion.</p><p>In summary, dynamic prospect theory models the perception of outcomes as gains or losses relative to a dynamic reference point, which depends on the distance to the goal, and not on whether the outcomes are actually gains or losses. Dynamic prospect theory predicts that risk taking adapts to the difficulty of reaching the goal in the remaining time. It predicts no framing effect for the outcome domain (gain vs. loss) if the underlying mathematical structures of choice problems are identical, because in dynamic prospect theory the outcomes are transformed into gains and losses based on their distance to the reference point (Eq. 5). Similarly, the theory predicts no effect of the state domain (positive vs. negative resource state) if the distance between state and goal does not differ across domains, because a mere shift of the state or goal by an additive factor does not change the dynamic reference point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment</head><p>To examine framing effects in risky choices with goals, we conducted an experiment employing a risky choice task with goals and different outcomes and states (see <ref type="figure">Fig. 1</ref>).</p><p>Participants. 106 participants recruited from Prolific Academic completed an online study, six participants were excluded (because they failed multiple attention check choices), leaving a final sample of N = 100; 71 males, 29 females, the mean age was 26 years (Med = 23, SD = 9, range 19-58 years), data were collected from November 2020 to December 2020, the study was approved by the ethics committee of the Faculty of Psychology at the University of Basel. The mean study duration was 48 minutes (Med = 43, SD = 18.93). The study was incentivized (four randomly drawn problems were rewarded with a bonus payment when reaching the goals in the different problems).</p><p>Task Design. Our design manipulated the presentation (framing) of risky choices using 2x2 within-subject conditions ( <ref type="figure">Fig. 1)</ref>, keeping the mathematical properties of the choice problem equivalent across conditions. It involved 24 two-option risky choice problems with T=5 trials to reach goals; options had two outcomes, equal expected values but unequal variances. One experimental factor manipulated the outcome domain by presenting options with gain vs. loss outcomes ( <ref type="figure">Fig. 1b-c)</ref>. This allowed a test of the outcome domain's effect on goal-based risk taking, aligning with classic gain-loss framing. The second factor manipulated the state domain, where state refers to the experienced resource states <ref type="figure">(Fig. 1d)</ref>. We presented negative vs. positive/zero initial resource states, defined as the number of points at the start of the task. This allowed a test of the state domain's effect on goal-based risk taking.</p><p>Outcome framing and state framing were combined as follows. Half the problems (12 of 24) offered gains with a goal <ref type="figure">Figure 1</ref>. The 5-trial choice problems. (a) Example choice in a positively framed gain problem with a threshold of 22 in trial 2 of 5. The right option is chosen, an outcome is drawn and feedback is provided; the outcome raises the point state from 8 to 13, and the trial counter increases from 2 to 3. (b) Example gain task with positive state frame, an initial state of 0, and a threshold of 22. (c) Example loss task with positive state frame, an initial state of 28 points and a threshold of 0. (d) The negative state framed gain and loss problem corresponding to (b), and (c) respectively. (e) Experimental procedure, see text.</p><p>( <ref type="formula">5)</ref>to reach or exceed a point threshold (gain problems <ref type="figure">, Fig. 1b)</ref>; the remaining 12 problems offered losses with a goal to not fall below a point threshold (loss problems, <ref type="figure">Fig. 1c)</ref>. In half of the gain problems the points started with an initial state of 0 and moved upwards towards a threshold greater 0 (positive state problems), the remaining gain problems started in a negative state &lt; 0 moving towards a threshold of 0 (negative state problems). In half of the loss problems the points started from a positive state &gt; 0 moving to a threshold of 0 (positive state problems), the remaining loss problems started with a state of 0 moving towards a negative threshold &lt; 0 (negative state problems). A positive state frame means that state is primarily positive throughout the task, while a negative state frames means is primarily negative <ref type="figure">(Fig. 1d)</ref>. Overall, we presented 24 unique problems, repeated them three times, resulting in a total of 72 choice problems.</p><p>We optimized the design of the choice problems to be mathematically equivalent across the four framing conditions. This means that across gain-loss framing we selected the choice problems such that gain and loss problems had the same expected rewards (as per the optimal model) for each possible obtainable state for each possible trial. Also, across positive-negative state framing the states and thresholds differed only by an additive factor. The mathematical equivalence of problems across all framing conditions allows testing for framing effects while controlling for the risky and the safe option's expected rewards, that is the option's expected chance to reach the goal as per the optimal model (Eq. 4).</p><p>The choice problems had two levels of difficulty, measured as the best chance to achieve the goal as per the optimal model (the expected reward in the first trial, Eq. 4). Easy tasks had a 72%-79% chance, and hard tasks had only 47%-54%. These difficulty levels resemble the difficulty levels in previous goal-based risky choice experiments <ref type="bibr" target="#b4">(Jarecki &amp; Rieskamp, 2020;</ref><ref type="bibr" target="#b18">Searcy &amp; Pietras, 2011</ref>).</p><p>Procedure. After task familiarization, participants completed 72 choice problems with goals. They chose five times between two risky options instructed to achieve a goal; the screen displayed the point threshold, the point state, the options, and a trial counter, as shown in <ref type="figure">Fig. 1a</ref>. After participants made their choice, one outcome was drawn from the chosen option and the point state changed by the value of the outcome. After five choices, the point state was reset to the predefined initial state; no points were carried over between problems. New problems involved different options, thresholds, and initial states.</p><p>To avoid confusion about the goal in a particular problem, we presented the differently framed problems in blocks: gain tasks with positive states, gain tasks with negative states, loss tasks with positive states, and loss tasks with negative states.</p><p>The block order and the problem order within blocks was randomized across participants. Each block contained 6 unique problems repeated 3 times resulting in 18 problems per block <ref type="figure">(Fig. 1e)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Analyses were conducted in R (v4.0.2, R Core Team, 2020); inferential statistics are based on Bayesian models with a normal prior on the coefficients (µ = 0, σ = 10) using the brms package (v2.13.5, Bürkner, 2017); modeling used the cognitivemodels package (v0.0.10, Jarecki &amp; Seitz, 2020).</p><p>Risk Preferences. Overall, participants chose the risky option in 49% of all choices (SD = 9.5%). <ref type="table" target="#tab_0">Table 1</ref> shows that the participants selected the risky option equally often in each framing condition: Across conditions, the proportion of risky choices ranged from 0.48 to 0.49. A regression 1 revealed evidence for a null effect of the outcome domain ( = 0.00, 95% CI <ref type="bibr">[-0.05, 0.</ref> A comparison of models showed that a model including only the predictor difficulty outperformed the full model containing three predictors (BF &gt; 1000). Previous findings have shown that repeating conditions might change framing effects <ref type="bibr" target="#b9">(Kühberger, 1998)</ref>. Thus, we analyzed only the first block, treating the two framing conditions as between-subject variables. The results showed an effect opposite to the classic outcome framing effect ( = -0.11, 95% CI[-0.20, -0.03], BF(-) = 189.48) with higher proportion of risky choices for gains (M = 0.51, SD = 0.11) than for losses (M = 0.48 , SD = 0.13), and no effect state framing ( = 0.00, 95% CI[-0.08, 0.09], BF(0) = 248.36). Furthermore, because in trials 2-5 of a problem the states depend on the realized outcomes of previous trials we also run a robustness check 3 to control for path dependency. The results 4 regarding framing did not change substantially.</p><p>The finding that framing did not affect risky choices in risky choice tasks with goals are in line with the predictions of the optimal model and dynamic prospect theory and contrary to the predictions of cumulative prospect theory. The findings are also at variance with previous findings regarding framing effects and risk taking <ref type="bibr" target="#b20">(Tversky &amp; Kahneman, 1981)</ref>. The subsequent analysis will show the effect of framings on the task performance and choice optimality.</p><p>Task Performance. Collapsed across framing conditions participants achieved the goal in 52% of all choice problems (SD = 6.8%), which is smaller than the success rate of 63% effect predictors outcome domain + state domain + difficulty and the random effect predictor by-participant random intercept.</p><p>expected by the optimal model, BF(−) &gt; 1000. <ref type="table" target="#tab_0">Table 1</ref> displays the success rate separately by framing conditions. Gainloss framing seemed to affect successes: Participants achieved the goal more often in gain problems (M = 0.53, SD = 0.10) compared to loss problems (M = 0.50, SD = 0.09); regression  = -0.13 95% CI <ref type="bibr">[-0.23, -0.04]</ref>, BF(−) = 799.00).</p><p>We found no evidence for an effect of the state domain on the success rate ( = 0.00, 95% CI[-0.10, 0.09], BF(0) = 219.48). As expected by the optimal model participants reached the goal more often in easy (M = 0.64, SD = 0.09) than in hard problems (M = 0.39, SD = 0.09),  = -1.03 (95% CI <ref type="bibr">[-1.12, -0</ref>.93], BF(−) &gt; 1000).</p><p>Two aspects of these findings are worth highlighting: the observed success rate is smaller than the success rate expected by the optimal model, which is in line with previous results <ref type="bibr" target="#b4">(Jarecki &amp; Rieskamp, 2020;</ref><ref type="bibr" target="#b7">Korn &amp; Bach, 2018)</ref>. Moreover, the deviation from optimality seems more pronounced for losses than for gains, which we will analyze in more detail next. Shown are means and standard deviations (in parentheses); success rate = the proportion of successful problems. <ref type="bibr">1</ref> Predicted by the optimal model. Choice Optimality in Framed Choices with Goals. Overall, 68% of the observed choices aligned with the optimal model. A regression 5 showed that participants were less optimal in the loss domain ( = -0.08, 95% CI[-0.12, -0.03], BF(−) &gt; 1000) but the state domain did not affect optimality ( = 0.01, 95% CI[-0.03, 0.06], BF(0) = 391.17). To obtain a continuous measure of choice optimality, we calculated the predicted advantage a of the risky option over the safe option from the optimal model <ref type="bibr" target="#b4">(Jarecki &amp; Rieskamp, 2020)</ref>. The advantage is a continuous measure of whether the risky or the safe option yields a higher chance to achieve the goal. We computed the advantage a for all experienced states and trials by subtracting the risky option's expected reward (ERR) from the safe option's expected reward (ERs), a = ERR − ERS. For a &gt; 0, the risky option is advantageous over the safe option, a = 0 means no advantage, and for a &lt; 0, the safe option is advantageous. The higher the absolute value of a, the stronger the advantage. According to the optimal model, agents deterministically choose the advantageous option for a  0 and 5 Mixed effect regression; predicting optimality of choices from the fixed effect predictors outcome domain + state domain + difficulty and the random effect predictor by-participant random intercept. randomize for a = 0 independently of framing.</p><p>Contrasting the advantage with behavior, we found that participants followed the advantage in a soft-max fashion (Sshaped curve) rather than in a deterministic manner in each framing condition. <ref type="figure" target="#fig_1">Fig. 2</ref> shows that across framing conditions, the risky choice proportions at zero advantage were close to 50%, which corresponds to the optimal behavior. A regression 6 showed more risky choices with a higher advantage of the risky option, which is in line with the optimal model <ref type="bibr">( = 4.91,</ref><ref type="bibr">95% CI[4.71,</ref><ref type="bibr">5.11]</ref>, BF(+) &gt; 1000). But critically, neither the outcome domain ( = -0.03, 95% CI <ref type="bibr">[-0.07, 0.02]</ref>, BF(0) = 213.74) nor the state domain ( = 0.05, 95% CI[0.00, 0.09], BF(0) = 62.12) affected risky choice when controlling for advantage. A model comparison showed that exclusion of the outcome domain and the state domain greatly improved the model fit (BF &gt; 1000).</p><p>The choice optimality analysis seems to show less optimal choices in the loss domain, but this measure does not consider the strength of the advantage of the optimal option over the other option. Controlling for advantage, we found no substantial framing effects on choice optimality. Our results replicate previous research; the result revealed that risky choices follow the advantage in a soft-max fashion <ref type="bibr" target="#b4">(Jarecki &amp; Rieskamp, 2020)</ref>. Interestingly our results showed that human choices approximate optimality independent of the framing.</p><p>Model Comparison. To test which model best describes behavior in framed risky choices with goals we compared the performance of cumulative prospect theory (CPT), dynamic prospect theory (DCPT) and the optimal model (OPT). Each model was implemented with a soft-max choice rule <ref type="bibr" target="#b19">(Sutton &amp; Barto, 2018)</ref>. The OPT had one free parameter (choice rule parameter ), CPT and the DCPT had a total of six free parameters; parameters were estimated using maximum likelihood at the individual level. We included a random-choice model predicting Pr(Risky)=0.50 as baseline model (BASE). We compared the models using an individual-level strategy classification based on Akaike weights <ref type="bibr" target="#b22">(Wagenmakers &amp; Farrell, 2004)</ref> as measure of evidence strength (values of 1 indicate strong evidence for a model) and classified using a threshold of  0.75. The results <ref type="figure">(Fig. 3)</ref> show that DCPT described the majority of participants best (87 of 100), CPT described n=7, and OPT described n=2 best (BASE described n=2; n=4 were unclassified). The models' mean Bayesian information criterion (BIC) across all participants equaled BICDCPT = 424.04, BICOPT = 467.43, BICCPT = 498.06 and BICBASE = 499.07. The mean Akaike information criterion (AIC) was AICDCPT = 400.72, AICOPT = 463.54, AICCPT = 474.75 and AICBASE = 499.06 (lower values indicate better model fit).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Illustration of Differences Between Dynamic Prospect</head><p>Theory and Optimal Model. To illustrate the differences between DCPT and OPT, we take a closer look at the choices of participant 83, who is well described by the DCPT but not by the OPT. <ref type="figure" target="#fig_3">Fig. 4</ref> shows their choices in trial 1 in the gain problems compared to the model predictions. The DCPT parameters for participant 83 are =0.83, =0.58, =2.15,  + =2.00,  − =0.66 and =0.26, and =0.12 for OPT. Consider the choices in problem P4 that offered a risky option R "8 with 40% or 2," a safe option S "5 with 70% or 3," and a threshold of 22 points (option's EVs = 4.4). In P4 the participant consistently selected the safe option. DCPT describes this behavior, and OPT does not. According to the optimal strategy, OPT, the expected reward of a risky choice ERR = 0.72 is almost identical to the safe option's expected reward ERS = 0.70. Thus, OPT predicts a slight preference for the risky choice, Pr(R | OPT) = 0.53, which is not in line with the data. Unlike OPT, DCPT transforms the outcomes relative to the reference point as follows. Relative to DCPT's reference point (r=4.4, Eq. 5) the risky option is perceived as "3.6 with 40% or -2.4," and the safe option as "0.6 with 70% or -1.4." DCPT computes the risky option's utility 7 u(R) = -1.15 as lower than the safe option's utility u(S) = -0.43; thus, DCPT predicts a strong preference for the safe choice in line with the data; Pr(R | DCPT) = 0.06. the risky option are diminished to 2.9, whereas the safe option's 0.6 points are boosted to 0.65, increasing the safe option's relative attractiveness. Secondly, the participant underweights the risky option's 40% gain outcome stronger than the safe option's 70% gain; further the risky option's 60% loss weights stronger than the safe option's 30% loss. This enables DCPT to capture the preference for the safe option, although the options have the same EV. It is worth highlighting that the key mechanism of DCPT involves the conceptualization of outcomes in goal-based risky choices as psychological gains and losses relative to the dynamic reference point, that is the distance to the goal. In other words, DCPT can capture the absence of classic gain-loss framing effects by assuming a psychological re-framing of risky outcomes as a loss when the outcome falls short of the average goal distance in the remaining time horizon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In the current study, we have shown that classic gain-loss framing exhibits no systematic effect on goal-based risk taking. Rather than being affected by framing, risk preferences were sensitive to the goal. Participants were risk-seeking if the risky option increased the chance to meet a goal. This dynamic goal-induced change of risk preferences was not affected by framing: neither the outcome domain (gains vs. losses) nor the state domain (positive vs. negative) affected people's risk taking stronger than the goal. A dynamic version of prospect theory described behavior very well. It holds that choice outcomes are psychologically re-framed as a loss if outcomes fail to meet the average remaining goal distance. Importantly, in this study, we tested two specific difficulty levels in goal-based risk taking. We therefore cannot generalize our findings across different difficulties. It is conceivable that in extremely easy problems that involve very low goals, framing effects might be found because the goal becomes less important for decision makers in very easy goalbased risky choices. Further research is needed to address this question.</p><p>Taken together, the results show that goals, rather than presentation formats, serve as strong reference points in risky decision making. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>04], BF(0) = 498.53) and the state domain ( = 0.02, 95% CI[-0.02, 0.06], BF(0) = 296.74) on risky choice 2 . The proportion of risky choices increased with the difficulty from easy (M = 0.48, SD = 0.11) to hard (M = 0.50, SD = 0.11, estimated  = 0.10, 95% CI[0.06, 0.14], BF(+) &gt; 1000).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Observed risky choices across framing conditions by advantage (see text) of the risky option as per the optimal model. Lines = best-fitting regressions; colors = framing conditions; N = observation count at each advantage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>DCPT's parameters matter here. The value parameter 's diminishing marginal utility means the 3.6 points offered by 7 uRisky = υ(xR1)(pR1)+ υ(xR2)(pR2) = 2.9  0.22 + (-3.57)  0.50 = -1.15; uSafe = υ(xS1)(pS1)+ υ(xS2)(pS2) = 0.65  0.64 + (-2.61)  0.32 = -0.43</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Participant 83, model predictions (dots) and M across three observed choices (bars). OPT = optimal model, DCPT = dynamic prospect theoryFigure 3. Evidence strength by participant. BASE = baseline model, DCPT = dynamic prospect theory, CPT = cumulative prospect theory, OPT = optimal model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Proportion of risky choices and success rate</figDesc><table><row><cell cols="2">Framing</cell><cell>Success rate</cell><cell>Pr. of risky choices</cell></row><row><cell>Out-come</cell><cell>State</cell><cell>pre-dicted 1 observed</cell><cell>pre-dicted 1 observed</cell></row><row><cell cols="2">Gain positive</cell><cell cols="2">0.63 0.53 (0.13) 0.55 0.49 (0.11)</cell></row><row><cell cols="2">Gain negative</cell><cell cols="2">0.63 0.53 (0.12) 0.57 0.49 (0.11)</cell></row><row><cell cols="2">Loss positive</cell><cell cols="2">0.63 0.50 (0.11) 0.56 0.49 (0.15)</cell></row><row><cell cols="2">Loss negative</cell><cell cols="2">0.63 0.50 (0.13) 0.58 0.48 (0.15)</cell></row><row><cell>Note:</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Mixed effect regression; predicting choices from the fixed effect predictors outcome domain + state domain + difficulty and the random effect predictor by-participant random intercept.2 BF(0) = Bayes Factor for  = 0; BF(+) = Bayes Factor for  &gt; 0; BF(−) = Bayes Factor for  &lt; 0 3 Mixed effect regression; predicting choices in trial 1 from the fixed</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Outcome domain,  = -0.05, 95% CI[-0.15, 0.05], BF(0) = 119.43; State domain,  = -0.02, 95% CI[-0.12,0.08], BF(0) = 188.19; difficulty,  = -0.29 , 95% CI[-0.39, -0.18], BF(−) &gt; 1000.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Mixed effect regression predicting choices from the fixed effect predictors outcome domain + state domain + advantage the random effect predictor by-participant random intercept.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">brms: An R package for bayesian multilevel models using stan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Bürkner</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v080.i01</idno>
		<ptr target="https://doi:10.18637/jss.v080.i01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Flexible modulation of risk attitude during decision-making under quota</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fujimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takahashi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neu-roimage.2016.06.040</idno>
		<ptr target="https://doi.org/10.1016/j.neu-roimage.2016.06.040" />
	</analytic>
	<monogr>
		<title level="j">Neu-roImage</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="304" to="312" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Clarifying the relationship between prospect theory and risk-sensitive foraging theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Fawcett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E W</forename><surname>Mallpress</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcnamara</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.evolhumbehav.2014.06.010</idno>
		<ptr target="https://doi.org/10.1016/j.evolhumbehav.2014.06.010" />
	</analytic>
	<monogr>
		<title level="j">Evolution and Human Behavior</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="502" to="507" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A framework for the functional analysis of behaviour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcnamara</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X00053061</idno>
		<ptr target="https://doi.org/10.1017/S0140525X00053061" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="130" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Prospect theory and optimal risky choices with goals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Jarecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<ptr target="https://cog-sci.mindmodeling.org/2020/papers/0015/0015.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Conference of the Cognitive Science Society</title>
		<editor>S. Denison, M. Mack, Y. Xu, &amp; B. C. Armstrong</editor>
		<meeting>the 42nd Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="43" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cognitivemodels: An R package for formal cognitive modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Jarecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">I</forename><surname>Seitz</surname></persName>
		</author>
		<ptr target="https://iccm-conference.neocities.org/2020/papers/Contri-bution_229_final.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Cognitive Modelling</title>
		<editor>T. C. Stewart</editor>
		<meeting>the 18th International Conference on Cognitive Modelling</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="100" to="106" />
		</imprint>
		<respStmt>
			<orgName>University Park, PA: Applied Cognitive Science Lab, Penn State</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Prospect theory: An analysis of decision under risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<idno type="DOI">10.2307/1914185</idno>
		<ptr target="https://doi.org/10.2307/1914185" />
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="292" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Heuristic and optimal policy computations in the human brain during sequential decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-017-02750-3</idno>
		<ptr target="https://doi.org/10.1038/s41467-017-02750-3" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Minimizing threat via heuristic and optimal policies recruits hippocampus and medial prefrontal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0603-9</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0603-9" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="733" to="745" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The influence of framing on risky decisions: A meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kühberger</surname></persName>
		</author>
		<idno type="DOI">10.1006/obhd.1998.2781</idno>
		<ptr target="https://doi.org/10.1006/obhd.1998.2781" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="55" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the evolutionary origin of prospect theory preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Smirnov</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0022381608080341</idno>
		<ptr target="https://doi:10.1017/S0022381608080341" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Politics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="335" to="350" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Beyond gains and losses: The effect of need on risky choice in framed decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fiddick</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0027855</idno>
		<ptr target="https://doi.org/10.1037/a0027855" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1136" to="1147" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Framing effects and risk-sensitive decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gregson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Lalumière</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/j.2044-8295.2011.02047.x</idno>
		<ptr target="https://doi.org/10.1111/j.2044-8295.2011.02047.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Translation of gambles and aspiration level effects in risky choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Laughhunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crum</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.26.10.1039</idno>
		<ptr target="https://doi.org/10.1287/mnsc.26.10.1039" />
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1039" to="1060" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Risk-sensitive choice in humans as a function of an earnings budget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Pietras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Hackenberg</surname></persName>
		</author>
		<idno type="DOI">10.1901/jeab.2001.76-1</idno>
		<ptr target="https://doi.org/10.1901/jeab.2001.76-1" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Experimental Analysis of Behavior</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human risky choice under temporal constraints: Tests of an energy-budget model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Pietras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Locey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Hackenberg</surname></persName>
		</author>
		<idno type="DOI">10.1901/jeab.2003.80-59</idno>
		<ptr target="https://doi.org/10.1901/jeab.2003.80-59" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Experimental Analysis of Behavior</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="75" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<ptr target="https://www.r-project.org/" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimal risky choice in humans: Effects of amount of variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Searcy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Pietras</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.be-proc.2011.01.008</idno>
		<ptr target="https://doi.org/10.1016/j.be-proc.2011.01.008" />
	</analytic>
	<monogr>
		<title level="j">Behavioural Processes</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="99" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<title level="m">Reinforcement Learning: An Introduction</title>
		<imprint>
			<publisher>MIT Press Cambridge</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The framing of decisions and the psychology of choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.7455683</idno>
		<ptr target="https://doi.org/10.1126/science.7455683" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">211</biblScope>
			<biblScope unit="issue">4481</biblScope>
			<biblScope unit="page" from="453" to="458" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Advances in prospect theory: Cumulative representation of uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00122574</idno>
		<ptr target="https://doi.org/10.1007/BF00122574" />
	</analytic>
	<monogr>
		<title level="j">Journal of Risk and Uncertainty</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="297" to="323" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">AIC model selection using akaike weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206482</idno>
		<ptr target="https://doi.org/10.3758/BF03206482" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="192" to="196" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
