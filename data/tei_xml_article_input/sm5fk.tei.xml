<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A self-programming theory of perception</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangfang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Zhang</surname></persName>
						</author>
						<title level="a" type="main">A self-programming theory of perception</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>action-based theories</term>
					<term>cognition</term>
					<term>perception</term>
					<term>top-down processing</term>
					<term>subjective symbols</term>
					<term>Bayesian brain</term>
					<term>enactivism</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper relies on the self-programming mind hypothesis, providing a novel perspective on perception. According to this interpretation, the process of perception is essentially one of controlling the inflow of sensory information. Through this control, the mind can represent the current sensory input through known concepts. This further allows the mind to acquire the relationships that associate the perceived objects with other known concepts. Thus, consciously considered decisions can be made based on these relationships. The method by which the mind locates the known concepts for representing objects is by obtaining subjective symbol sequences generated from sensory input and top-down processing. These top-down processes for establishing and activating these subjective symbol sequences arise from the habitualization of actions obtained through historical conscious decision-making. This habitualization process applies to both action-based and non-actionbased perceptions. To show the evidence that this idea is aligned with the mechanism of perception, we compared it with predictive coding both theoretically and empirically. We show that this idea gives more plausible interpretations than predictive coding in both these two aspects. Through this novel understanding of perception, we have also revisited the process of object recognition. Furthermore, we discussed the relationship between cognition and perception, indicating that the core association between these two systems is that unconscious perceptual processes originate from conscious historical decisions. This suggests a new direction that empirical research about the relationships between cognition and perception should consider. Finally, we dissolved some significant issues faced by action-based theories of perception.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Understanding the nature of perception is one of the most pivotal inquiries in comprehending how the mind works. This article will present a fresh perspective on the nature of perception through the idea of the self-programming mind hypothesis <ref type="bibr" target="#b42">(Li &amp; Zhang, 2022)</ref>. The self-programming mind hypothesis is a philosophical standpoint offering insights into how the mind works. This supposition assumes that the task of the mind is to organize and utilize subjective symbols (fundamental elements of the selfprogramming mind ). And the self-programming mind hypothesis gives an approach to achieving this task. Since subjective symbols can directly correspond to neural processes, the self-programming mind hypothesis seamlessly integrates with cognitive science. Within this context, the article will elucidate: 1) What is the nature of perception? 2) Why is the function of perception significant for the mind? 3) Where does the process of perception originate from? Furthermore, by way of these understandings of perception, our theory can unify the emerging idea of action-based perception and traditional non-action-based perception into a single framework.</p><p>The traditional viewpoint posits that humans receive information from the world through perception, then modify the world through action. However, the past two decades of cognitive research have begun to refute this perspective. Researchers have discovered that action is also involved in the process of perception <ref type="bibr" target="#b44">(Noë, 2009;</ref><ref type="bibr" target="#b45">Nöe, 2006;</ref><ref type="bibr" target="#b47">O'Regan &amp; Noë, 2001</ref>). This implies that there is no simple dichotomy between perception and action in terms of distinguishing between the receipt of environmental information and the alteration of the environment.</p><p>While a substantial body of empirical evidence underscores the significance of action in perception, the exact role of actions within this process remains unclear to researchers due to a lack of a comprehensive understanding of how the mind operates. Furthermore, it's still uncertain how sensory information interacts with actions, let alone the mechanisms through which these interactions are established.</p><p>In previous studies, several approaches have been proposed to interpret the relationship between action and perception <ref type="bibr" target="#b13">(Buhrmann et al., 2013;</ref><ref type="bibr" target="#b26">Flament-Fultot, 2016)</ref>. Two of them are widely discussed. One is based on the Bayesian brain hypothesis <ref type="bibr" target="#b18">(Clark, 2013;</ref><ref type="bibr" target="#b32">Hohwy, 2013;</ref><ref type="bibr" target="#b59">Sanborn &amp; Chater, 2016;</ref><ref type="bibr" target="#b60">Seth, 2013)</ref>. The other is the enactive approach, which asserts that there is no internal representation of the relationship between action and sensation. According to this theory, humans are autonomous and autopoietic entities, capable of perceiving without the necessity for internal representation <ref type="bibr" target="#b16">(Chemero, 2009</ref><ref type="bibr" target="#b17">(Chemero, , 2016</ref><ref type="bibr" target="#b22">Degenaar &amp; O'Regan, 2017;</ref><ref type="bibr" target="#b35">Hutto &amp; Myin, 2013)</ref>.</p><p>The Bayesian brain hypothesis conceptualizes the brain as a Bayesian model. It posits the existence of beliefs used to predict which neurons will be triggered next under current neural activation. These beliefs are gradually updated as real-world events unfold. The initial models of the Bayesian brain could only account for passively received sensor input. However, by incorporating the counterfactual distributions, actions could also be included in the model <ref type="bibr" target="#b27">(Friston, 2009)</ref>. In this way, some studies have extended its application to explain the relationship between senses and actions in perception <ref type="bibr" target="#b61">(Seth, 2014)</ref>.</p><p>Although the Bayesian brain hypothesis might be able to address the issue of action in perception, the hypothesis itself harbors some fundamental problems. For instance, some recent research has pointed out at least four fundamental issues with the Bayesian brain hypothesis <ref type="bibr" target="#b7">(Brette, 2018;</ref><ref type="bibr" target="#b55">Rahnev, 2019;</ref><ref type="bibr" target="#b72">Yeon &amp; Rahnev, 2020)：</ref> 1) The internal response depends more than just the stimulus of interest.</p><p>2) Bayesian computations depend on the existence of a well-defined response. But, this is not the case for the brain activity.</p><p>3) Bayesian brain must assume that all possible stimuli are known. But this is impossible.</p><p>4) The Bayesian brain tries to compute with the full probability distribution. But this is not in accord with empirical findings.</p><p>In fact, from a philosophical standpoint, the Bayesian brain hypothesis is at the very least incomplete. It fails to effectively address the fundamental problem of induction, as pointed out by Hume.</p><p>Since the Bayesian brain relies on a statistical method based on samples, it's clear that it is induction. Therefore, it inevitably faces Hume's problem, that is, the conclusions drawn from induction may be erroneous. If humans operate based on a Bayesian brain, then when they move from one environment to another, many of the rules deduced from the past are likely to become invalid. Faced with this situation, a person operating on a Bayesian brain would need to consider all observed parameters as potential causes. However, this does not correspond with humans' actual experiences in reality. For example, when individuals transition into a new work environment and face changes in interpersonal relationships, there is no reason to consider changes in physical laws as potential causes.</p><p>Regarding the enactive approach, a pervasive issue is that its theories do not sufficiently clarify their relevance to exhibited intelligent behavior in humans, and often remain at the level of qualitative analogy. We do not know why an autonomous or autopoietic entity can exhibit human-like intelligence. For instance, a recent study in this area suggested that perception is like bodily skills <ref type="bibr" target="#b63">(Silverman, 2018)</ref>. However, Silverman did not explain why internal representation could not articulate bodily skill. In fact, any proposition that argues against the need for internal representation should at least outline its fundamental building blocks and the dynamic mechanisms among these blocks. It should then elucidate how this dynamic could form perception to distinguish it from a bowl of cell soup. Additionally, some studies have shown that methods without internal representation are not necessarily required <ref type="bibr" target="#b68">(Vernazzani, 2019)</ref>.</p><p>This article proposes a new way to understand perception, based on the self-programming mind hypothesis. The self-programming mind hypothesis is grounded in subjective symbols. It attempts to answer a normative question -how should senses and actions be organized and utilized to possess human-like intelligence? Furthermore, it should be capable of forming abstract concepts such as space, time, causality, and consciousness.</p><p>Given that this theory is rooted in subjective symbols, it significantly differs from current theories of mind. For example, relationships in this theory are established based on determinism rather than probability. This is because the ability that humans can consciously compute probabilities requires considerable knowledge accumulation. Thus, although probability (achieved through a combination of basic computational operations) could potentially be a type of relationship, it is highly unlikely to serve as a fundamental relation for how humans organize information.</p><p>Through the self-programming mind hypothesis, the most important achievement is the integration of perception into the entire operation of the self-programming mind. Furthermore, we arrived at the following conclusions:</p><p>1) Action in perception should be viewed as a special form of top-down neural modulation that requires the participation of action. 2) Sensor inputs, objectives, and context collectively determine the top-down modulations, and thereby also determine the action in perception. These actions, in turn, help the subject obtain more sensor information. This unconscious reciprocal process collectively determines the perceived object. 3) Unconscious top-down neural modulations, which include the actions in perception, are learned through the repetitive occurrence of conscious behavior under specific conditions.</p><p>To verify this idea of the mechanism of perception, we compare it with the predictive coding theory both empirically and theoretically. We show that it is aligned with the current neurological results and can offer more comprehensive interpretations than predictive coding in the relationship between expectation and attention.</p><p>In addition, we also explained the process of object recognition, as well as its distinction from object perception. Moreover, through the novel understanding of perception offered by the self-programming mind hypothesis, we have addressed and answered questions faced by action-based theories of perception. In the last, we also explore the implication of our theory to the traditional dichotomy of perception and cognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The hypothesis of self-programming mind</head><p>In this section, we briefly introduce the idea of the self-programming mind hypothesis. The self-programming mind hypothesis <ref type="bibr" target="#b42">(Li &amp; Zhang, 2022)</ref> originates from an answer to a normative question based on a novel metaphysical assumption: considering a system for which all known fundamental elements consist only of subjective senses and actions, how should a system operate to effectively discover, express, and apply the relationships among these fundamental elements?</p><p>The self-programming mind hypothesis proposes a subjective symbolic system based on recursive memory to deal with this question. This system uses the mutual coherence of beliefs as the standard for knowledge. This standard contrasts with the idea to define knowledge in mainstream epistemology <ref type="bibr" target="#b46">(Olsson, 2021)</ref>.</p><p>Specifically, the core conclusion of the self-programming mind hypothesis needs that the mind is capable of performing induction at two levels simultaneously:</p><p>1) It should be capable of inducing laws between subjective symbols that are related to the input from the external world.</p><p>2) It should also be able to induce the laws of among the representations obtained from the induction in 1). Moreover, the mind should express the results obtained from both types of inductions in the same manner. This needs 2) to be further expanded into a self-reference structure:</p><p>2) It should also be able to induce the laws of among the representations obtained from the induction in 1) and 2).</p><p>The key intuition behind this solution is that due to human limitations and biases in observing the world, the external world appears complex and mutable to human knowledge systems. In other words, problems like Hume's problem of induction are inevitable. However, the system's own manner of knowledge representation is fixed. Through this fixed mode of representation, the mind can discover when the expression of knowledge is deficient, incoherent, or need to be tested, etc. By identifying these characteristics, the system can construct a knowledge system that encompasses not only laws of the external world but also guidance on when these pieces of knowledge should be added, reassessed, revised, and so forth. In other words, the knowledge system of the self-programming mind is a system that organizes all past experiences in a coherent way, based on subjective symbols and its own mechanisms of representation.</p><p>In this knowledge system, a unit that represents a set of coexisting relationships is a concept in the self-programming system (a system that conforms to the self-programming mind hypothesis). The running of the self-programming system is a mapping from the currently activated concepts to specific operations that need to be performed. These mappings can be divided into two types: the first type of mapping depends on the relationships of the currently activated concept based on the entire knowledge system; the second type of mapping depends only on the current environment, and they function like conditioned reflexes.</p><p>The self-programming mind hypothesis argues that the first type of mapping needs the perception of the currently activated object. The second type of mapping is performed in an unconscious state. In other words, concepts are consciously perceived in order to obtain the relationship of the currently activated concepts based on the entire knowledge system.</p><p>Finally, the self-programming mind hypothesis posits that the first type of mapping will transform into the second type. The condition for this transformation is that if under a certain state, the action obtained from the first type of mapping is always the same, then that action will be directly connected with the current state, thereby transforming into the second type of mapping. In other words, when the action obtained by conscious thinking many times is always the same, it is unnecessary for the mind to retrieve it through the entire knowledge system again when faced with this situation next time, but to directly execute this action. In this way, the fully considered action caused by the perceivable object is transformed into an unconscious habitual action. We call this conversion the Law of Habituation.</p><p>The self-Programming mind hypothesis provides an answer to how the mind should operate if it is based on subjective symbols. However, a lingering question in the framework of this hypothesis is: how are subjective symbols and the structures they form, namely concepts, triggered by external information? According to the hypothesis's interpretation of consciousness, this triggering process corresponds to the process of perception. Therefore, this is the central problem that this article aims to address.</p><p>The self-Programming mind hypothesis is based on subjective symbols, but it does not impose any constraints on the specific objective meanings of these symbols. In other words, subjective symbols with any active condition can be used for induction in the selfprogramming mind hypothesis. However, considering human biological structure, a biologically plausible assumption would be that subjective symbols should correspond to a neuron or combinations of multiple neurons.</p><p>It's crucial to note that while subjective symbols may correspond to neurons, it doesn't imply that these symbols correspond to any specific objective entity. Consider the following example: suppose a region of activation in a circular neuron doesn't correspond to any actual shape. This is because the activation threshold can still be met even if any small part of the stimulation to it is missing. Therefore, even though the neuron's area of activation is circular, it does not correspond to this circular shape. In other words, subjective symbols do not correspond to any specific objective entities.</p><p>The self-programming mind hypothesis posits that the fundamental elements of thought originate not from the external but from the internal. This part is consistent with the idea of subjective physic <ref type="bibr" target="#b6">(Brette, 2016)</ref>. However, Brette disagrees with the notion of treating the operation mechanism of thought as a computer and believes that self-programming is not possible <ref type="bibr" target="#b8">(Brette, 2022)</ref>. His rationale is that if programming is to be carried out, there must be an object to be programmed and a programmer. If the brain embodies both roles, then the part of the program that plays the external programmer is unchangeable.</p><p>In the self-programming system, this problem is resolved through a recursive structure. Specifically, the operating mechanism of the programmer and the program to be programmed can be expressed in the same way. Attributed to the self-programming system's ability to observe its own historical behavior, thereby enabling the system to obtain and save the procedure of its own operation. This converts the behavior of the programmer into an ordinary programmable program. In other words, the selfprogramming system achieves the purpose of modifying itself by learning the mechanism of its own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The self-programming theory of perception</head><p>In this section, we will first identify the core computational problems confronted by perception. Subsequently, we will illustrate how the understanding of perception in a selfprogramming system can assist in addressing these challenges. In solving these problems, we will demonstrate a biologically plausible perception mechanism. By comparing this mechanism with empirical evidence, we contend that the perception in the selfprogramming system is consistent with perception in its conventional sense. Based on this consistency, we explain the nature of perception from the perspective of the selfprogramming mind hypothesis, while also clarifying the role of action within perception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The computational account of object perception</head><p>A significant amount of empirical evidence from past research suggests that top-down processing is a crucial component of perception. However, a definitive answer as to why top-down processing is so pivotal to perception remains elusive. Past studies on this question have focused on analyzing the effects produced by top-down processing, yet no comprehensive framework has been proposed to address this issue from the standpoint of computational necessity. Going forward, we will analyze this issue from this perspective, which will help us better understand the relationship between the two.</p><p>A significant task that the mind has done is effectively representing the observed information. It's well known that the sensors in the human body receive a wealth of information from the external environment every moment. However, our consciousness can explicitly remember only a very small number of independent objects. The mind reconciled this contradiction through perception. Specifically, perception uses concepts that are already known as mediums to convey the information currently observed. But how can the process of perception find the objects that can appropriately represent the information currently observed?</p><p>An intuitive solution would be to compare the currently observed information with all the information in memory, and ultimately select the object that best represents the current information as the messenger object for conveying the information. However, there are three obstacles to implementing it in practice:</p><p>1) Need to traverse all known concepts. This task is very difficult</p><p>2) The coordinate problem: the degree of match between the perceived information and known objects varies when coordinates change. For example, if the location where an object appears on the retina shifts, the degree to which it represents a particular object may change.</p><p>3) The mind cannot tell the discrepancy between the observed raw information and the messenger object.</p><p>To address the aforementioned challenges, a feasible solution includes: 1) Define a set of fundamental perceptual elements. 2) When the subject is observing, compare the currently observed information with this set of elements to determine the optimal element corresponding to the current observed information.</p><p>3) Based on the currently determined element, determine the operation that the mind needs to carry out for obtaining further information. This information might come from other parts of the currently received sensory information, or it might require certain body actions to participate in, such as obtaining more information by moving the eyes or the body.</p><p>4) The iterative execution of steps 2 and 3 can generate a fundamental element sequence (FES) composed of basic elements and operations of the mind.</p><p>5) It is worth noting that the above process can simultaneously apply to the establishment and triggering of the concept of objects. In other words, when a new object is observed for the first time, the concept of this object will establish a feature FES that identifies the object. During recognition, the task of the recognition process is to try to match the FES of the current information to the feature FES of the object.</p><p>The advantage of this approach is that the process of perception no longer requires comparing with all known concepts in memory. For instance, if the first element expressed by the current information is A, then the sequence in the feature FES whose first feature value is not A can be excluded. In this way, only the feature FES with the first feature value of A needs to be searched.</p><p>Secondly, since each observation only needs to make a selection among the fundamental perceptual elements, and the number of fundamental perceptual elements is far less than the number of concepts, the brain can allocate more resources to each fundamental perceptual element. For instance, a checking structure can be established at every position on the retina for each fundamental perceptual element. In this way, no matter where this element appears, it can be detected. This method can also be applied to situations with different sizes of the same element.</p><p>Thirdly, since each object's feature FES has an internal structure, by comparing the FES from the current observed information with the feature FES, both the similarities and differences between the current information and the known object's information can be identified.</p><p>Some might doubt the effectiveness of this approach. They may argue that an object may present radically different representations, resulting in completely different feature element sequences (FES). For example, observing the same object from different angles might yield entirely different FES. However, this creates no difficulties for this approach if a concept of an object is allowed to contain multiple feature FES.</p><p>In summary, this approach of implementing the process of perception can solve the problems brought about by the initial intuitive method. Moreover, this approach is not just an educated guess from the computational standpoint but also conforming to the empirical research which reveals that the brain does not process received information as a whole. Instead, it extracts part of the information first and then uses this information to top-down control the information received next. For example，Bar and his colleagues <ref type="bibr" target="#b3">(Bar, 2003;</ref><ref type="bibr" target="#b5">Bar et al., 2006)</ref> has showed that the orbitofrontal cortex (OFC) will be involved into the process of object recognition. Specifically, the low spatial frequencies information will be first send to the OFC as guidance for the high spatial frequencies information processing. Moreover, LSF stimuli activated the OFC in two distinct medial and lateral regions only if they resembled known visual objects <ref type="bibr" target="#b15">(Chaumon et al., 2014)</ref>.</p><p>Although the feature-FES-based approach can solve the computational challenges of perception, it also gives rise to two new significant issues: 1) How did the mind learn the way to obtain the FES, or say, control the sensory information inflow? 2) What is the nature of the fundamental perceptual elements ?</p><p>Since the information needs to be attention depends on the current situation, past experiences, and the subject's goal, the algorithms to control the sensory information inflow cannot be entirely innate. They must be acquired by learning. But, how could they be learned?</p><p>The second question is what is the nature of the fundamental perceptual elements that constitute the basis for the features of concepts? Can they really express all the characteristics that need to be expressed?</p><p>To answer these two questions, we need to analyze perception from a broader perspective, that is, the overall mechanism of how the mind works. In fact, the hypothesis of the selfprogramming mind has already provided answers to these two questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The theory of perception based on self-programming mind</head><p>In order to solve the two questions posed in the previous section, we need to understand how the self-programming system addresses the challenges of perception. Specifically, we need to delve into the form of concept representation and the executing processes in the self-programming system. The basic assumption of the self-programming mind is that whether it is passive triggered senses or actively pursuing goals, they are all subjective entities. Therefore, the purpose of the mind is to establish and utilize the relationships between senses and operations. The concepts of objective entities are just indirectly generated in pursuit of this subjective goal.</p><p>Based on this reason, the information organization of the self-programming mind is based on subjective symbols, not objective entities. Let's use a circle as an example to see the differences between the two approaches and how subjective symbols represent objective entities.</p><p>To objectively represent a circle, we know that it can be defined by using the center and radius. However, the subjective representation of a circle is completely different, it is the composition of subjective symbols. An illustrative subjective representation can be like this, first, there is a symbol that works like a neuron. It responds to a specific circular area on the retina. We know that the activation of this symbol does not necessarily mean this precise circle, because only a part of this circle needs to receive information for it to be activated. For example, if the circle is missing a small part, or if another shape that can cover the current circle is larger, it can also activate the circle. Therefore, to be able to represent this circle on the retina, other symbols are needed, for example, a group of more refined symbols can be used to represent the edge of this circle. By representing through this group of edges and the center, the circle can be represented better, but it should be noted that, as these symbols do not correspond to specific objective shapes, their combination is also not precise. When it is necessary for the shape to be more accurately determined, more symbols are required to provide more refined structures. We can see that the process of converting objective entities into subjective representations is an approximation process, but it can never be absolutely accurate.</p><p>If subjective representation is merely an approximation of the objective entities, a direct question arises: how can we distinguish between two different objective entities that are identical in terms of their subjective representation?</p><p>The self-programming system responds to this issue in two ways. First, such distinction needs to serve a certain purpose. If, from a functional perspective, there's no difference between objective entity A and objective entity B for the purposes of the subject, then this distinction is not necessary. Moreover, even if this distinction is needed, it applies only to the known objects in the current knowledge system. In other words, the representation of an object does not need to be able to differentiate it from all objects in the world; it merely needs to be distinguishable within the scope of currently known information.</p><p>Secondly, if the distinction between objects A and B becomes necessary, the self-programming system will extend the representation of A and B. For example, suppose someone mistakenly identifies object A as object B, falsely attributing B's functionalities to A. In such a case, the self-programming system would generate a state regarding the entire knowledge system, that is, the inability to correctly differentiate between A and B. This state would subsequently trigger behavior to distinguish between A and B, such as conducting more careful observations of A and B, thus discerning their differences. This would establish a more effective subjective symbols sequence for distinguishing between A and B. In summary, the self-programming system's representation of objects will deepen as the depth of observation of the world increases.</p><p>It's important to note that initially, the behavior of distinguishing between A and B is triggered by the state of the entire knowledge system. Following the idea of the selfprogramming mind hypothesis, the subject can consciously notice A, B, and action to distinguish them. However, as this action is repeatedly performed, according to the Law of Habituation, the appearance of the shared feature sequence of A and B will automatically trigger subsequent actions to further distinguish between A and B. In this stage, the action performed at the conscious level has become an automatic action at the unconscious level.</p><p>It's not hard to see that if we regard the subjective senses and subjective actions in subjective symbols as fundamental perceptual elements and the actions performed to acquire fundamental perceptual elements, respectively, then the subjective representation of objective entities in the self-programming system conforms to the feature FES described in the previous section. That is to say, the feature FES is essentially a sequence of subjective symbols. This also implies that the self-programming system can use the approach introduced in the previous section to establish and trigger concepts in the knowledge system. This integration not only extends the self-programming mind hypothesis, enabling it to trigger internal concepts from external information, but it also resolves the two missing points raised in the previous section regarding the computational account of perception.</p><p>Specifically, in response to the first question, i.e., how cognition establishes and acquires feature FES, the self-programming theory of perception proposes that the mind converts the high-level conscious subjective actions to automatic unconscious actions that are used to establish and match the feature FESs of objective entities. In fact, the learning process derived from this theory not only aligns with our daily experiences but also agrees with empirical evidence. For instance, recent research indicates that most of the top-down process originates from the selection history <ref type="bibr" target="#b0">(Awh et al., 2012;</ref><ref type="bibr" target="#b67">Theeuwes, 2018)</ref>.</p><p>Regarding the second question, what is the nature of fundamental perceptual elements? In the self-programming theory of perception, they are considered as basic symbols, essentially acting as the interface for conversion between the objective and subjective realms. The self-programming system organizes its subjective world around these interfaces, thus making them the building blocks of the subjective world. Indeed, regardless of the specific form of these building blocks, the algorithms of selfprogramming cognition can organize them and use them as the basis for guiding actions. Differences in the building blocks are ultimately offset by different ways of combination. This is analogous to how we can build houses of the same style using bricks or cement, with only the structure of their combinations differing.</p><p>However, we are not suggesting that the specific triggering conditions of fundamental perceptual elements are meaningless. In fact, a poorly configured set of fundamental perceptual elements could significantly impact the efficiency with which a subject represents objective entities. For instance, if minor variations in lighting could affect the features of fundamental perceptual elements of an object, then a vast number of these elements might be required to correctly identify suitable features. Clearly, this would greatly increase the complexity of achieving effective representation.</p><p>It's important to note that subjective actions in the self-programming theory of perception are not equivalent to actions in the general sense. This is because the self-programming system only needs to be concerned with whether specific information can be obtained through certain subjective actions, and hence it does not need to distinguish whether these actions are the control of the internal neural system or the control of the body. In other words, subjective actions not only include objective physical actions but also other mental actions for controlling the inflow of information, such as top-down neural modulation. From the subjective perspective of the self-programming system, all these are viable ways to actively control the inflow of information. This further implies that the learning of actions in perception and the learning of neural modulation in top-down processing will follow the same learning mechanisms.</p><p>Finally, this perspective of representing objective entities through subjective symbols is also compatible with the core idea of Gestalt perception, that is, the whole is greater than the sum of its parts <ref type="bibr" target="#b69">(Wagemans et al., 2012)</ref>. Following the method of subjective representations, an object as a whole can be captured by some subjective symbols that only match its overall features, like the overall profile of an object, while a combination of parts cannot trigger these subjective symbols. From this perspective, the whole is indeed greater than the sum of its parts.</p><p>Integrating the above analysis, we summarize the self-programming theory of perception as an extension of the self-programming mind hypothesis as follows: When adopting subjective representation, one core problem faced by the self-programming system is that the subjective expression structure of each object may be very complex. It is obviously unrealistic to consciously traverse all objects to determine the object currently being observed. Perception serves as the means to solve this problem. Specifically, perception is a way to quickly match the current observation to known concepts through an unconscious and fixed program in a specific scenario.</p><p>The very direct question that the process of perception needs to face here is that the information extraction process that perception deals with relies on the subjective representations of all known concepts. Therefore, it cannot be a predefined program, but can only be a program acquired through learning. Then the question arises, who or what is it learned from?</p><p>The self-programming mind theory posits that this learning is attributed to the transitions from conscious actions to unconscious habitual actions. In the self-programming system, conscious actions are intelligent and comprehensive actions that require relationships drawn from the entire knowledge system. Specifically, when the actions taken by the selfprogramming system are always the same under certain conditions, these specific conditions will become associated with the action, evolving into habitual unconscious actions. This unconscious action will spontaneously be conducted during the process of observation.</p><p>Finally, let's address a crucial issue in object recognition by our theory, namely, the existence of view-invariant structures. A significant school of thought in the field of object recognition posits that the representation of an object in the brain depends on a 3-D representation <ref type="bibr" target="#b49">(Peissig &amp; Tarr, 2007)</ref>. Through this 3-D representation, people can recognize an object from any perspective. This 3-D representation is a view-invariant structure.</p><p>However, from our previous discussion, we know that the self-programming theory of perception does not support the existence of such view-invariant structures. Humans are able to recognize objects from different perspectives simply because they have memorized the sequence of fundamental perceptual elements on that perspective. So the question here is, how do people manage to recognize objects from previously unseen perspectives?</p><p>Indeed, the ability to recognize objects from unseen perspectives does not originate from perception. Specifically, recognition is achieved through relationships from the entire knowledge system. This type of recognition is a conscious activity requiring effort. Let's illustrate this with an example.</p><p>Under the situation that one knows the side view of an object and also the side views of its parts but don't know the top view of the whole object. When she was shown the top view of this object, she cannot directly recognize it by perception. However, she can perceive the parts of this object. Then these perceived parts can trigger a state drawn from all known concepts in the knowledge system which can be described as there exists an object whose parts can be rotated to correspond to the current perceived objects. This state will further trigger an attempt to rotate these parts simultaneously in the mind to try to match the current perceived information. To be noted, because this implicit state is about all known objects, following the idea of the self-programming system, it is at the conscious level.</p><p>This conclusion about the view-invariant is both conformed to our daily experience and the mental rotation experiment which shows humans cannot immediately recognize complex 3D objects after rotation.</p><p>In summary, it is not correct to consider the process of object recognition as solely an unconscious perception task. The task of object recognition may concurrently involve both unconscious and conscious judgments.</p><p>In conclusion, the self-programming theory of perception can be summarized as follows: 1) Perception is the method of quickly locating known concepts based on the observed information in self-programming mind, enabling effective access to other related but unseen properties of the current environment.</p><p>2) The process of perception is a fixed program dependent on the current environment, purpose, and already acquired information. This program controls the inflow of information to achieve a representation of the current observed information that meets the needs of matching known concepts.</p><p>3) The fixed program of perception process is obtained by learning from past conscious judgments based on more comprehensive relationships drawn from the entire knowledge system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>The usual process of object recognition should not be equated with the process of object perception, as the process of object recognition may involve both unconscious perceptual and conscious reasoning processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Attention or Expectation: What does empirical evidence manifest ?</head><p>In this section, we first analyze the relationship between the idea of the self-programming theory of perception and attention. Then, we introduce the predictive coding theory, which is also a computational theory that attempts to account for the mechanism of perception and has steadily become more and more popular over the last fifteen years. By comparing the theoretical arguments and empirical evidence of these two theories, we demonstrate that the self-programming theory of perception is at least as sound as the predictive coding in terms of empirical validation. Moreover, it presents greater clarity and coherence than predictive coding in the theoretical aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Micro-attention</head><p>According to the Self-Programming Theory of Perception, the processes of perception are sequences of operations that control the influx of information. If we interpret attention as a method of selectively receiving information, then these processes can essentially be viewed as attention processes. However, it must be noted that such attention processes are not completely equivalent to the term 'attention' as traditionally used in cognitive science research.</p><p>The 'attention' referred to in traditional research actually denotes a phenomenon of attention. For instance, in the classic selective attention experiment -the Invisible Gorilla Test -whether the participants notice the gorilla reflects a phenomenological conclusion related to attention. This does not incorporate the internal mechanisms of thought that generate this phenomenon. On the other hand, the attention referred to in the selfprogramming process of perception are mechanisms of controlling the influx of information through top-down modulation. In fact, an experimental phenomenon of attention may involve processes composed of complex attention mechanisms. From this perspective, the mechanisms of attention are essentially the micro-structures of the attention phenomena. Therefore, to differentiate between these two types of attention, we may refer to the mechanisms of attention as 'micro-attention,' and the phenomena manifested as 'macro-attention.'</p><p>There are some fundamental differences between micro-attention and macro-attention.</p><p>The first one is that the traditional dichotomy that applies to macro-attention, namely the top-down and bottom-up attention, doesn't apply to micro-attention. Micro-attention is solely a mechanism that enhances or weakens specific signals through top-down processes. It is acquired through the habitualization of successful attention actions performed in the past under specific contexts, including top-down tasks, bottom-up physical stimuli, and mental status. In other words, the tasks and physically salient stimuli simultaneously influence the enactment of micro-attention.</p><p>Another crucial distinction lies in the fact that macro-attention is typically considered a neural process devoid of action involvement. However, this doesn't hold true for microattention. As we pointed out earlier, within the Self-Programming Theory of Perception, actions are merely viewed as special neural top-down modulations. Thus, micro-attention is compatible with both action-involved and action-free processes of controlling the influx of information.</p><p>For instance, consider someone driving a car, her objective of perception is to monitor the driving-related conditions, like the road and pedestrians. Suppose an unrelated salient stimulus, such as a blinding sun, appears. In response, the individual would lower the sun visor to better observe the driving-relevant external environment. Throughout this process, the act of lowering the sun visor is typically not regarded as part of the macro-attention process. However, for micro-attention, this action-involved process of controlling information influx is also considered part of the micro-attention process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Expectation and Predictive Coding</head><p>Next, let's examine another theory of perception that has gradually gained popularity over the last fifteen years: Predictive Coding. This theory proposes that, aside from the mechanism of attention, the brain possesses another parallel mechanism, namely expectation. The primary reasons they advocate for the existence of such a mechanism are twofold <ref type="bibr" target="#b66">(Summerfield &amp; Egner, 2009)</ref>: 1) Since raw sensory inputs are ambiguous (e.g., information arriving at the retina), the brain needs a means to ensure that this ambiguous information can be accurately interpreted. Expectation serves as an apt mechanism for this, as it can eliminate noise and retain primary information.</p><p>2) Expectation can guide information acquisition. For example, when a person enters a familiar environment, they can directly obtain information related to the current environment through expectation, obviating the need for repetitive observation.</p><p>Importantly, researchers on predictive coding consider expectation a separate brain mechanism that operates independently of the attention mechanism. The rationale is that expectation is based on prior probabilities, serving as a means to alleviate the computational burden of the brain. Conversely, attention functions to handle top-down tasks or respond to bottom-up external stimuli. Even though they often co-occur in practice, the two are not synonymous but complementary.</p><p>Based on the idea that the brain possesses an independent expectation mechanism, researchers have further outlined its specific operating mechanism. The process of realizing expectations can be simplified into the following three iterative steps:</p><p>1) Higher-level neural networks transmit the expectation of the signals that will manifest next to the lower-level networks. 2) Lower-level neural networks receive signals from the outside (or lower-level networks), and derive an error by comparing the external neural signals with the expectation. This error signal is then fed back to the higher-level neural networks. 3) Higher-level neural networks use the error signal to adjust the model of calculating expectations. In this way, higher-level neural networks become increasingly adept at predicting the signals that the lower-level networks or external environment will manifest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Theoretical and Empirical Comparation</head><p>Next, we will compare the two theories from both theoretical and empirical perspectives. As previously pointed out, according to the predictive coding theory, the main reasons the brain needs to undertake expectation are twofold: 1) the information received by neurons is ambiguous, and 2) expectation can help the brain infer information that has not been observed. However, in reality, both these points are problematic.</p><p>Indeed, the first point, arguing that the information received by neurons is ambiguous, can be more accurately articulated that the information represented by neurons is an ambiguous representation of objective world rather than an accurate one. However, does the brain truly require an accurate representation of objective things? In fact, for the brain, both the objectives it aims to achieve and the information it receives are represented by neurons. This implies that the brain could entirely abandon the attempt to represent objective entities accurately, and instead wholly focus on pursuing the relationships between neuronal triggers as its goal. In this case, the information represented by the neurons wouldn't be ambiguous at all. This approach is exactly the underlying presupposition of the Self-Programming Theory of Perception.</p><p>In fact, the idea that the brain needs to accurately represent objective reality is itself an unjustified conjecture. Even considering everyday experiences, it can be easily noticed that we can never accurately represent even the simplest objective entities. For example, can we accurately depict the coastline of Great Britain? In reality, we can only ever achieve a representation that is closer and closer to reality, not one that is entirely accurate. In other words, the accuracy of the representation of an objective entity entirely depends on specific requirements. Exact representations are both unnecessary and unachievable. And approximations are sufficient depending on the context and purpose. This understanding aligns more closely with the practical workings of the human cognitive system, as hypothesized in the Self-Programming Theory of Perception.</p><p>Regarding the second function of expectation, that is, the ability to help the brain infer unobserved information, we acknowledge that the brain can predict unobserved objects. However, this does not necessarily imply the need for an expectation mechanism that operates independently of attention. As pointed out in the Self-Programming Hypothesis <ref type="bibr" target="#b42">(Li &amp; Zhang, 2022)</ref>, the brain can also achieve the capability to predict unobserved phenomena by establishing and comparing existing concepts. Furthermore, such prediction is based on the coherence of all known experiences. In other words, the information and methods it relies on for making predictions involve a more comprehensive knowledge rather than just evidence with similar features that can be adopted by statistical methods.</p><p>In addition, the distinction between expectation and attention in predictive coding is founded on the traditional dichotomy of top-down and bottom-up attention processes. However, empirical evidence has shown that this dichotomy does not fully capture the behavior of attention. Another crucial form of attention, which goes beyond these two categories, depends on the history of past attention <ref type="bibr" target="#b0">(Awh et al., 2012)</ref>. This viewpoint aligns with the micro-attention based on past behavior as proposed by the Self-Programming Theory of Perception. From this perspective, micro-attentions can also be seen as an extension of attention based on historical selections.</p><p>In addition to the questionable necessity of an independent mechanism for expectation, the algorithmic solution for expectation through predictive coding also raises concerns. For instance, within the framework of predictive coding, what information should be classified as an error? An example that highlights this dilemma can be found in the Kanizsa illusory surface experiment. In this context, should the activation response of lower-level neurons to illusory contours be regarded as an error, or should it be considered an expression of the external environment? <ref type="bibr" target="#b36">(Kogo &amp; Trengove, 2015)</ref> Similarly, the specific form of top-down expectation within the predictive coding mechanism also presents perplexing questions. For example, suppose subjects are asked to observe two sequences that appear with the same 50% probability. These two sequences are identical except for the last entity, e.g., A, B, C and A, B, D. Then, when the subject observes A and B, what should her expectation be? Should it be an overlap of C and D or an overlap of the voids of C and D? In fact, either way evidently violates the principles of effective expectation.</p><p>The core issue highlighted by this example is that the expectation in predictive coding conflates two different dimensions of information, namely features, and frequencies, representing them within a single dimension. This representation leads to the loss of part of the information, and subsequently, it becomes impossible to infer either the features or frequencies from the expectation. However, to establish a useful model of the world, the brain actually needs both features and frequencies.</p><p>Having compared the theoretical rationales of predictive coding and the selfprogramming theory of perception, let us now turn to the empirical aspect. It must be first pointed out that due to technical limitations, current empirical research does not have the practical means to directly prove or disprove broad theories of perception like predictive coding. Therefore, all past empirical evidence that can support and refute the Predictive coding theory is exploratory and based on discrepancies from specific features that can distinguish it from other theories <ref type="bibr" target="#b30">(Heilbron &amp; Chait, 2018;</ref><ref type="bibr" target="#b70">Walsh et al., 2020)</ref>. The selfprogramming theory of perception, which, like predictive coding, attempts to comprehensively explain perception, will face the same problem of insufficient empirical methods. In other words, at this stage, empirical evidence for the self-programming theory can also only be obtained by verifying specific features, in an exploratory manner, and by comparing it with known theories. In this case, the predictive coding theory is a good candidate for such comparison, since it aims to provide a complete mechanism of perception, like the self-programming theory, rather than other theories that only provide interpretation to specific empirical phenomena or articulate not enough to give a computational account of perception.</p><p>From the previous discussions, we can see that both the Self-Programming Theory of Perception and Predictive Coding predict that neural top-down modulation will play a significant role in perception. However, a detailed analysis reveals that the functions they point to are entirely different. Specifically, Predictive Coding posits that the role of topdown modulation is to suppress stimuli that can be correctly predicted and to enhance those that cannot be predicted. In contrast, within the self-programming theory, the function of top-down modulation is to emphasize information related to current or historical tasks and to suppress information that is irrelevant to them.</p><p>A common experimental method used to test predictive coding is repetition suppression. In this type of experiment, the same external stimulus, such as an image, is repeatedly presented, and the population responses of lower-level neural areas, such as V1, are monitored by EGG, fMRI, or BOLD. The typical conclusion of the experiment is that the subject's response to the same stimulus becomes progressively weaker. The explanation provided by predictive coding is that the subject is increasingly able to predict the pattern of the image, thus the error becomes smaller, and the response in V1 diminishes. However, the self-programming theory of perception offers an alternative explanation: since the same external stimulus is repeatedly presented and does not indicate any information that requires attention, the pattern will be ignored.</p><p>Although both theories are consistent with the experimental results, we can conceive of another thought experiment to distinguish between the two. We can make slight modifications to the images used in the repetition suppression experiment. Specifically, the repeatedly presented images are not exactly the same but have very small variations in detail. Since the size of these variations can be arbitrarily adjusted, as long as the differences are small enough, the conditions for repetition suppression will still be met. The subjects are asked to report when a red center point appears.</p><p>In this scenario, since the learning mechanism in Predictive Coding is context-independent, the subjects' task would not affect the suppression. In other words, even if the subjects are instructed to pay attention to the center, subtle changes therein will be ignored, meaning that the subjects will not be able to report the red center.</p><p>However, for the Self-Programming Theory of Perception, the center would be attended to, and the variations in other parts would be suppressed to a lower response level. In this situation, we would confidently predict that the results conforming to the selfprogramming theory of perception would definitely occur.</p><p>Indeed, in almost all experiments that validate predictive coding, researchers have found that attention or task is a significant influencing factor <ref type="bibr" target="#b34">(Hsu et al., 2018;</ref><ref type="bibr" target="#b39">Larsson &amp; Smith, 2012;</ref><ref type="bibr" target="#b70">Walsh et al., 2020)</ref>. For example, in recent experiments involving mismatch negativity (MMN), researchers found that informing the subjects of the target greatly influenced the experimental results <ref type="bibr" target="#b65">(Solomon et al., 2021)</ref>.</p><p>However, in past research, scientists have typically considered the effects brought about by attention as interference with the experimental results. Researchers have believed that attention is unrelated to expectation, a significant reason being that experiments showing results like mismatch negativity or repetition suppression experiments still occur even when the subject is not explicitly under any task. However, if we consider the historical influence of micro-attention, we realize that the current explicit task is not the entirety of the task. In other words, even if the subject is not influenced by the attention generated by the current task, they may still be influenced by attention habits depending on the historical task.</p><p>The empirical literature that can corroborate the above viewpoint comes from a study investigating the attention-dependent effects of prediction suppression <ref type="bibr" target="#b34">(Hsu et al., 2018)</ref>. This research, through an analysis of existing empirical literature on predictive coding, discovered that attention affects two different situations of non-predicted stimuli.</p><p>Specifically, non-predicted stimuli can be divided into two categories: mis-predicted stimuli and unpredicted stimuli. Mis-predicted stimuli refer to those that have already appeared in the current experiment but were not anticipated by the subject. Unpredicted stimuli refer to completely random occurrences within the experiment, making it impossible for the subject to anticipate their appearance.</p><p>The study pointed out that in predicted-versus-nonpredicted experiments, the influence of mis-predicted stimuli is attention-independent, while the influence of unpredicted stimuli is attention-dependent. This experimental result is inconsistent with the theoretical underpinnings of predictive coding.</p><p>However, employing the self-programming theory of perception can easily explain this phenomenon. According to this theory, both unpredicted stimuli and mis-predicted stimuli would be influenced by micro-attention. The former's influence is directly generated by the task, while the latter's is affected by the attention shaped by historical habits. This is because, when a mis-predicted stimulus appears, it likely represents a signal that the subject needs to pay immediate attention to. This is because it signifies a signal that the subject might have a wrong understanding of the current environment. This type of error could symbolize a misunderstanding of the overall system. And it may lead to very severe mistakes in the future. Thus, from a historical perspective, focusing on such an error would be highly important.</p><p>Therefore, in this case, the historically-based implicit attention has already influenced the experimental results. This leads to the appearance that the mis-predicted situation seems unrelated to explicit attention.</p><p>In contrast, when an unpredicted stimulus appears, it essentially represents new information being displayed, but this new information does not necessarily need to attract attention. Therefore, there is no historically-based micro-attention that must focus on the newly revealed information. As a result, explicit attention plays a significant role in this category of experiments.</p><p>Indeed, theoretically speaking, if one considers the historical influences of micro-attention, viewing the expectation mechanism as independent makes it appear redundant. Since the way micro-attention operates can appropriately regulate the flow of bottom-up information in various specific situations, and since individuals are always in some specific situations, why would there be a need for a general, environment-independent learning method?</p><p>More importantly, micro-attention actually utilizes a more effective way of organizing information, capitalizing on the feature that historical tasks that have occurred in the past may recur. This is because the process of micro-attention is a synthesis of the historical process of attention; when information is gleaned using micro-attention, the extraction of external information is correlated with past tasks, making the information obtained through micro-attention directly applicable to future instances of the same tasks. In other words, if we acknowledge this regularity between the future and the past, the method of micro-attention stands as a more efficient approach of top-down modulation for coping with future tasks than a context-irrelevant expectation.</p><p>In conclusion, after briefly considering both the theoretical rationality and empirical evidence, although we cannot directly affirm the correctness of the Self-Programming Theory of Perception, the self-programming theory of perception is an idea that is at least as worthy of further development as predictive coding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implications for the distinction between cognition and perception</head><p>For a long time, an important notion in cognitive science has been the clear boundary between cognition and perception. This viewpoint is not only confined to theory but also significantly influences computational models in artificial intelligence. For instance, in designing intelligent systems, many solutions involve using separate systems to address recognition problems and then further utilizing the results from these recognition systems for additional cognitive tasks.</p><p>However, this view has been increasingly questioned in the recent two decades. One of the main reasons is the abundant discoveries of top-down processing in neural system studies. Numerous psychological experiments have tried to test the effects of cognition on perception from various perspectives. For instance, some experiments showed that desired objects may appear closer than undesired ones <ref type="bibr" target="#b2">(Balcetis &amp; Dunning, 2010;</ref><ref type="bibr" target="#b38">Krpan &amp; Schnall, 2014)</ref>. Other studies indicate that wearing heavy clothing can influence distance judgment <ref type="bibr" target="#b54">(Proffitt et al., 2003)</ref>. Some research demonstrated the impact of emotions and feelings on perception <ref type="bibr" target="#b20">(Cole et al., 2013;</ref><ref type="bibr" target="#b29">Harber et al., 2011)</ref>. Conversely, other studies have pointed out deficiencies in these experiments, attempting to refute the influence of cognition on perception <ref type="bibr" target="#b25">(Firestone &amp; Scholl, 2016)</ref>.</p><p>From the self-programming theory of perception, the conscious observation processes that are usually classified under cognition and determined by comprehensive thinking will become habitual and transform into unconscious processes. Therefore, cognition will affect perception significantly and directly on its process.</p><p>Past psychological experiments have primarily focused on the impact that changes in context have on the perception of objective measurements. In fact, factors within the context, such as emotions, have indirect and unstable impacts on perception. This is because the perceptual processes triggered in specific contexts differ from those triggered under general circumstances. However, these perceptual processes are not directly related to top-down processing, as top-down processing is also required under general circumstances. Furthermore, the appearance of other cues (since cognition will make judgments based on multiple factors) could potentially eliminate this effect. Therefore, we believe that neither these experiments nor their refutations can either prove or refute the connection between cognition and perception.</p><p>From the perspective of self-programming systems, the most direct impact of cognition on perception occurs in the internal representation of objective entities. In other words, topdown processing occurs simultaneously during the establishment and retrieval of an object's representation.</p><p>Viewing perception as an independent system also poses a practical issue: how is the perception of categories obtained? To perceive categories, at least, requires that a classification algorithm must exist in the perception system. But how is this algorithm obtained? If it learns like a classifier in computer science, then it must have a known training set that covers all categories, because such an algorithm cannot add new categories. This means that all category information must be innate. Clearly, this is highly unlikely to be an appropriate answer. The key reason here is that a perception system itself has no goals; it plays a completely passive role in receiving information. This role has no active need to establish new categories, leading to no clues to do this task.</p><p>If the mechanism of mind does have a clear distinction between cognition and perception, then it could be driven by cognition to form concepts and ways of triggering these concepts. For example, in the self-programming theory of perception, the establishment of concepts is for the purpose of differentiation of known concepts. This differentiation helps the establishment of the processing for perceiving objective entities. In this way, a perception system that is closely associated with the cognition system can be built.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion of the problems with action-based theories of perception</head><p>Given that the self-programming theory of perception resolves a significant issue by explaining the rationale behind actions in perception, it should also help address the problems faced by action-based theories of perception. Therefore, we have selected some of the most prominent questions in this regard for discussion. They include how the mind resolves visual jitter during eye saccades, the fact that the mind constructs perception through multiple factors rather than a single one, and the problem of dual-system of visual processing <ref type="bibr" target="#b12">(Briscoe &amp; Grush, 2020)</ref>.</p><p>The earliest action-based theory of perception was proposed to solve the problem of why eye saccades do not cause synchronous fluctuations in our visual perception. This theory suggests that the brain records the direction of eye movement to compensate for changes in visual direction, thus preventing the perceived image from moving when the eyeballs rotate. However, a wealth of subsequent evidence has shown that this perspective is untenable. For example, empirical evidence shows that subjects' perception of these visual changes is highly inaccurate <ref type="bibr" target="#b10">(Bridgeman et al., 1975;</ref><ref type="bibr" target="#b23">Deubel, 2004)</ref>.</p><p>However, according to the self-programming mind hypothesis, the problem of perceptual jitter during scanning is a pseudo-problem, as it's based on the camera hypothesis. This hypothesis suggests that human visual perception is like a screen, and our eyes are like cameras that display images on this screen without any change. In the self-programming mind hypothesis, perception is not a display of the eyes. Its essence is the representation of external objects that are activated and placed in a specific state space. This specific state space is used to trigger relationships among all known concepts. In other words, the mind only updates information from the eyes when an update is needed. Visual perception is not the direct input from the eyes but the information reconstructed from the known concepts triggered by the eyes. Saccade and fixation are just habitual methods of obtaining information. They are not used to compensate for changes in eye direction but are components of the representations of known concepts.</p><p>For instance, during dreaming, even though there is no visual input, there are still perceived objects. The movements of the eye are in accord with these perceived objects in dreams. <ref type="bibr" target="#b41">(Leclair-Visonneau et al., 2010)</ref> .</p><p>Another issue related to Action-based theories is that experiments show that the mind constructs perception through multiple factors, not just one. For example, in visual rearrangement experiments, the adaptation to rearranged vision in humans stems from kinesthetics rather than the vision itself. In the perception of objects, the way human constructs objects is not only by using the object's 2D appearance but also by visual depth <ref type="bibr" target="#b28">(Gibson, 2014;</ref><ref type="bibr" target="#b33">Hopp, 2013)</ref>. Similarly, there are multiple ways that the mind measures egocentric distance perception <ref type="bibr" target="#b24">(Dong et al., 2023)</ref>.</p><p>Although these phenomena pose challenges to traditional action-based theories' explanations in subtle, they actually serve as evidence supporting the self-programming mind hypothesis. In this hypothesis, the mind is unable to distinguish which specific factors are more suitable for constructing perception. Therefore, all potentially relevant factors could be utilized under different conditions. For example, solving visual distance doesn't necessarily require the triangulation method of binocular vision. It could also be achieved by comparing the size projected on the retina with the size in memory to obtain the corresponding proportion relationship, thereby determining the distance of the object. This method can help us make preliminary judgments about the distance of certain objects even when one eye is closed. In summary, the self-programming theory of perception suggests that perception is constructed by incorporating as many factors as possible. When access to some factors is restricted in certain circumstances, other factors can come into play to assist in perceptual judgments.</p><p>Another significant basis for refuting action-based perceptual theories is the dual systems theory of visual processing. This theory is grounded in behavioral science research that identified two distinct types of visual cognitive impairments: optical ataxia and visual form agnosia. Patients with optical ataxia can perceive the objects they are observing but are unable to perform appropriate actions. For example, they cannot light a cigarette correctly. Conversely, patients with visual form agnosia can execute physical actions, such as picking up a cup, but are not conscious of the cup's presence. Based on these phenomena, the dual systems model of visual processing was proposed, suggesting that visuomotor actions and visual consciousness are handled by two dissociated systems in the brain. Therefore, the notion that action and perception are interconnected is empirically doubtful.</p><p>However, recent empirical research indicates that using dual systems to understand these phenomena is an overly radical interpretation <ref type="bibr" target="#b57">(Rossetti et al., 2017)</ref>. Neither neurological nor behavioral scientific evidence is sufficient to support the dual systems model explanation.</p><p>Approaching from the perspective of the self-programming theory of perception, optical ataxia can be understood as the loss of the perception ability involving actions, which is only a part of the perception. Therefore, patients with optical ataxia can often still lead normal lives. On the other hand, patients with agnosia lose the ability to trigger relationships that are based on the entire knowledge system and make comprehensive decisions. This reduces their behavior to almost only autopilot mode. Therefore, the loss of this ability makes a normal life utterly inevitable. This reasoning based on the selfprogramming theory is consistent with clinical evidence <ref type="bibr" target="#b51">(Pisella et al., 2006</ref><ref type="bibr" target="#b53">(Pisella et al., , 2008</ref><ref type="bibr" target="#b56">Rossetti &amp; Pisella, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper relies on the self-programming mind hypothesis, providing a novel perspective on perception. According to this interpretation, the process of perception is essentially one of controlling the inflow of sensory information. Through this control, the mind can quickly position current sensory input within existing concepts. This positioning allows the perceived object to be associated with other known concepts and comprehensive decisions can be made through this association. The method by which the mind locates known concepts is by obtaining subjective symbol sequences generated from sensory input and top-down processing. The algorithm for establishing and activating these subjective symbol sequences arises from the habitualization of actions obtained through historical comprehensive decision-making.</p><p>According to this understanding of the perception process, action-based perception and non-action-involved perception can be considered within the same computational framework. Moreover, the self-programming theory of perception can solve theoretical problems faced by action-involved perception. Furthermore, our theory provides a novel approach to solving the object recognition problem. This approach refutes the traditional method of establishing a 3D model to explain the view-invariant phenomenon.</p><p>Most importantly, the self-programming theory of perception challenges the traditional dichotomy of perception and cognition systems and points out that the key influence of cognition on perception is that the observation process of perception arises from the inertia formed by purposeful actions produced by cognition. This suggests a new experimental direction for verifying the relationship between perception and cognition.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Top-down versus bottom-up attentional control: A failed theoretical dichotomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Awh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Belopolsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Theeuwes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="437" to="443" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.tics.2012.06.010</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2012.06.010" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Wishful seeing: Motivational influences on visual perception of the physical environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Balcetis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunning</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203848043</idno>
		<ptr target="https://doi.org/10.4324/9780203848043" />
	</analytic>
	<monogr>
		<title level="m">Social psychology of visual perception</title>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="77" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A cortical mechanism for triggering top-down facilitation in visual object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="609" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<idno type="DOI">10.1162/089892903321662976</idno>
		<ptr target="https://doi.org/10.1162/089892903321662976" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Top-down facilitation of visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Kassam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Ghuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boshyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Hämäläinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marinkovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Halgren</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0507062103</idno>
		<ptr target="https://doi.org/10.1073/pnas.0507062103" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="449" to="454" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Subjective Physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brette</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-0-12-802452-2.00011-1</idno>
		<ptr target="https://doi.org/10.1016/B978-0-12-802452-2.00011-1" />
	</analytic>
	<monogr>
		<title level="m">Closed Loop Neuroscience</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="145" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Is coding a relevant metaphor for the brain? The Behavioral and Brain Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brette</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X19000049</idno>
		<ptr target="https://doi.org/10.1017/S0140525X19000049" />
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Brains as Computers: Metaphor, Analogy, Theory or Fact? Frontiers in Ecology and Evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brette</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fevo.2022.878729</idno>
		<ptr target="https://www.frontiersin.org/articles/10.3389/fevo.2022.878729" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Failure to detect displacement of the visual world during saccadic eye movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bridgeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="719" to="722" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/0042-6989</idno>
		<ptr target="https://doi.org/10.1016/0042-6989" />
		<imprint>
			<biblScope unit="page" from="90290" to="90294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Action-based Theories of Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy</title>
		<editor>E. N. Zalta</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
		<respStmt>
			<orgName>Metaphysics Research Lab, Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Dynamical Systems Account of Sensorimotor Contingencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Buhrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Di Paolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Barandiaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">285</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fpsyg.2013.00285</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2013.00285" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visual predictions in the orbitofrontal cortex rely on associative content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chaumon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kveraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bht146</idno>
		<ptr target="https://doi.org/10.1093/cercor/bht146" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2899" to="2907" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Radical embodied cognitive science (pp. xiv, 252)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chemero</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sensorimotor empathy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chemero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consciousness Studies</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="152" to="152" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Whatever next? Predictive brains, situated agents, and the future of cognitive science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="204" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<idno type="DOI">10.1017/S0140525X12000477</idno>
		<ptr target="https://doi.org/10.1017/S0140525X12000477" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Affective signals of threat increase perceived proximity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Balcetis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="40" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0956797612446953</idno>
		<ptr target="https://doi.org/10.1177/0956797612446953" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Degenaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Regan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11245-015-9338-z</idno>
		<ptr target="https://doi.org/10.1007/s11245-015-9338-z" />
		<title level="m">Sensorimotor Theory and Enactivism. Topoi</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="393" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Localization of targets across saccades: Role of landmark objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Deubel</surname></persName>
		</author>
		<idno type="DOI">10.1080/13506280344000284</idno>
		<ptr target="https://doi.org/10.1080/13506280344000284" />
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="173" to="202" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Methods for measuring egocentric distance perception in visual modality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2022.1061917</idno>
		<ptr target="https://www.frontiersin.org/articles/10.3389/fpsyg.2022.1061917" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cognition does not affect perception: Evaluating the evidence for &quot;top-down&quot; effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Firestone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Scholl</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X15000965</idno>
		<ptr target="https://doi.org/10.1017/S0140525X15000965" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">229</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Counterfactuals versus constraints: Towards an implementation theory of sensorimotor mastery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Flament-Fultot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consciousness Studies</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="153" to="176" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The free-energy principle: A rough guide to the brain?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2009.04.005</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2009.04.005" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="293" to="301" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The Ecological Approach to Visual Perception: Classic Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315740218</idno>
		<ptr target="https://doi.org/10.4324/9781315740218" />
		<imprint>
			<date type="published" when="2014" />
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Psychosocial resources, threat, and the perception of distance and height: Support for the resources and perception model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Harber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iacovelli</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0023995</idno>
		<ptr target="https://doi.org/10.1037/a0023995" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1080" to="1090" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Great Expectations: Is there Evidence for Predictive Coding in Auditory Cortex?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heilbron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="page" from="54" to="73" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuroscience.2017.07.061</idno>
		<ptr target="https://doi.org/10.1016/j.neuroscience.2017.07.061" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The predictive mind (pp. ix, 282)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hohwy</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780199682737.001.0001</idno>
		<ptr target="https://doi.org/10.1093/acprof:oso/9780199682737.001.0001" />
		<imprint>
			<date type="published" when="2013" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">No such look: Problems with the dual content theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hopp</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11097-012-9287-6</idno>
		<ptr target="https://doi.org/10.1007/s11097-012-9287-6" />
	</analytic>
	<monogr>
		<title level="j">Phenomenology and the Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="813" to="833" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The processing of mispredicted and unpredicted sensory inputs interact differently with attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-F</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hämäläinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Waszak</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2018.01.034</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2018.01.034" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="85" to="91" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Radicalizing enactivism: Basic minds without content (pp. xxv, 206)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Myin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Trengove</surname></persName>
		</author>
		<title level="m">Is predictive coding theory articulated enough to be testable? Frontiers in Computational Neuroscience</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fncom.2015.00111</idno>
		<ptr target="https://doi.org/10.3389/fncom.2015.00111" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Too close for comfort: Stimulus valence moderates the influence of motivational orientation on distance perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krpan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schnall</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspa0000017</idno>
		<ptr target="https://doi.org/10.1037/pspa0000017" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="978" to="993" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">fMRI Repetition Suppression: Neuronal Adaptation or Stimulus Expectation?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<idno type="DOI">10.1093/cercor/bhr119</idno>
		<ptr target="https://doi.org/10.1093/cercor/bhr119" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Do the eyes scan dream images during rapid eye movement sleep? Evidence from the rapid eye movement sleep behaviour disorder model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leclair-Visonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Oudiette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gaymard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leu-Semenescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Arnulf</surname></persName>
		</author>
		<idno type="DOI">10.1093/brain/awq110</idno>
		<ptr target="https://doi.org/10.1093/brain/awq110" />
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1737" to="1746" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">The Self-Programming System: A Skepticism-conformed Computational Framework of the Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>PsyArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<idno type="DOI">10.31234/osf.io/f3ays</idno>
		<ptr target="https://doi.org/10.31234/osf.io/f3ays" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Out of our heads: Why you are not your brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noë</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Hill &amp; Wang</publisher>
		</imprint>
	</monogr>
	<note>and other lessons from the biology of consciousness (pp. xv, 214</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Action in Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nöe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Coherentist Theories of Epistemic Justification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Olsson</surname></persName>
		</author>
		<ptr target="https://plato.stanford.edu/archives/fall2021/entries/justep-coherence/" />
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy</title>
		<editor>E. N. Zalta</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
		<respStmt>
			<orgName>Metaphysics Research Lab, Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A sensorimotor account of vision and visual consciousness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>O'regan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noë</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="973" to="1031" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<idno type="DOI">10.1017/s0140525x01000115</idno>
		<ptr target="https://doi.org/10.1017/s0140525x01000115" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Visual Object Recognition: Do We Know More Now Than We Did 20 Years Ago?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Peissig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Tarr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="96" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<idno type="DOI">10.1146/annurev.psych.58.102904.190114</idno>
		<ptr target="https://doi.org/10.1146/annurev.psych.58.102904.190114" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">No double-dissociation between optic ataxia and visual agnosia: Multiple sub-streams for multiple visuomanual integrations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pisella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Binkofski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lasek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rossetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2734" to="2748" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.neuropsychologia.2006.03.027</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2006.03.027" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Optic ataxia and Balint&apos;s syndrome: Neuropsychological and neurophysiological prospects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pisella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vighetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rossetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbook of Clinical Neurology</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="393" to="415" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The role of effort in perceiving distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Proffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stefanucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Banton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Epstein</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9280.t01-1-01427</idno>
		<ptr target="https://doi.org/10.1111/1467-9280.t01-1-01427" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="106" to="112" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The Bayesian brain: What is it and do humans have it?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X19001377</idno>
		<ptr target="https://doi.org/10.1017/S0140525X19001377" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Chapter 11 -Optic ataxia: Beyond the dorsal stream cliché</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rossetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pisella</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-0-444-63622-5.00011-5</idno>
		<ptr target="https://doi.org/10.1016/B978-0-444-63622-5.00011-5" />
	</analytic>
	<monogr>
		<title level="j">Handbook of Clinical Neurology</title>
		<editor>G. Vallar &amp; H. B. Coslett</editor>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="225" to="247" />
			<date type="published" when="2018" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rise and fall of the two visual systems theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rossetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pisella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Mcintosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Physical and Rehabilitation Medicine</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="140" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.rehab.2017.02.002</idno>
		<ptr target="https://doi.org/10.1016/j.rehab.2017.02.002" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Bayesian Brains without Probabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Sanborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2016.10.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2016.10.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="883" to="893" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Interoceptive inference, emotion, and the embodied self</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Seth</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2013.09.007</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2013.09.007" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="565" to="573" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A predictive processing theory of sensorimotor contingencies: Explaining the puzzle of perceptual presence and its absence in synesthesia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Seth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="118" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<idno type="DOI">10.1080/17588928.2013.877880</idno>
		<ptr target="https://doi.org/10.1080/17588928.2013.877880" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Bodily skill and internal representation in sensorimotor perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phenomenology and the Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/s11097-017-9503-5</idno>
		<ptr target="https://doi.org/10.1007/s11097-017-9503-5" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Limited Evidence for Sensory Prediction Error Responses in Visual Cortex of Macaques and Humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kohn</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhab014</idno>
		<ptr target="https://doi.org/10.1093/cercor/bhab014" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3136" to="3152" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Expectation (and attention) in visual cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Egner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2009.06.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2009.06.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="403" to="409" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Visual Selection: Usually Fast and Automatic; Seldom Slow and Volitional</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Theeuwes</surname></persName>
		</author>
		<idno type="DOI">10.5334/joc.13</idno>
		<ptr target="https://doi.org/10.5334/joc.13" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The structure of sensorimotor explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vernazzani</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11229-017-1664-9</idno>
		<ptr target="https://doi.org/10.1007/s11229-017-1664-9" />
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4527" to="4553" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A century of Gestalt psychology in visual perception: II. Conceptual and theoretical foundations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wagemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gepshtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kimchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Pomerantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Van Der Helm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0029334</idno>
		<ptr target="https://doi.org/10.1037/a0029334" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1218" to="1252" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Evaluating the neurophysiological evidence for predictive processing as a model of perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Mcgovern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Connell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1464</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="242" to="268" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title/>
		<idno type="DOI">10.1111/nyas.14321</idno>
		<ptr target="https://doi.org/10.1111/nyas.14321" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The suboptimality of perceptual decision making with multiple alternatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3857</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41467-020-17661-z</idno>
		<ptr target="https://doi.org/10.1038/s41467-020-17661-z" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
