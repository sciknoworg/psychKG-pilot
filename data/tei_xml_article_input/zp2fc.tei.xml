<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Inverting cognitive models with neural networks to infer preferences from fixations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><forename type="middle">M</forename><surname>Russek</surname></persName>
							<email>erussek@princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Departments of Computer Science and Psychology</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Callaway</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departments of Computer Science and Psychology</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Departments of Computer Science and Psychology</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Inverting cognitive models with neural networks to infer preferences from fixations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fixation</term>
					<term>Cognitive Models</term>
					<term>Neural Networks</term>
					<term>Inverse Reinforcement Learning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Inferring an individual&apos;s preferences from their observable behavior is a key step in the development of assistive decision-making technology. Although machine learning models such as neural networks could in principle be deployed toward this inference, a large amount of data is required to train such models. Here, we present an approach in which a cognitive model generates simulated data to augment limited human data. Using these data, we train a neural network to invert the model, making it possible to infer preferences from behavior. We show how this approach can be used to infer the value that people assign to food items from their eye movements when choosing between those items. We demonstrate first that neural networks can infer the latent preferences used by the model to generate simulated fixations, and second that simulated data can be beneficial in pretraining a network for predicting human-reported preferences from real fixations. Compared to inferring preferences from choice alone, this approach confers a slight improvement in predicting preferences and also allows prediction to take place prior to the choice being made. Overall, our results suggest that using a combination of neural networks and model-simulated training data is a promising approach for developing technology that infers human preferences.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INFERRING PREFERENCES FROM FIXATIONS 3</head><p>Inverting cognitive models with neural networks to infer preferences from fixations Key to building systems that help people make better choices is inferring what people want from their behavior <ref type="bibr" target="#b14">(Hadfield-Menell et al., 2016)</ref>. How can this inference take place? Cognitive models, which specify how latent preferences generate behavior, could in principle be applied to this problem. By using Bayesian inference to invert such a model, we can infer preferences from behavior. However, cognitive models often fail to capture idiosyncratic relationships between preferences and behavior, and inverting such models is computationally burdensome. In contrast, machine learning models such as neural networks offer a way to make inference computationally feasible and have greater flexibility to capture arbitrary relationships. However, training such models requires vast amounts of behavioral data.</p><p>In this work, we propose and test a new solution to the problem of inferring preferences from behavior, combining the strengths of cognitive models and neural networks. Our approach is to satisfy the need for massive data to train neural networks by augmenting limited available real human data with simulated data from a cognitive model <ref type="figure" target="#fig_4">(Fig. 1</ref>). We apply this approach to the problem of inferring human preferences over food items from visual fixations between those items made during the decision-making process.</p><p>Our results demonstrate that neural networks are able to learn, from simulated data, to invert a computationally intensive cognitive model for how individuals decide where to fixate while making a decision given their preferences over items. Additionally, pretraining a network with simulated data and fine-tuning with limited human data allows prediction of people's self-reported preferences from their fixations. This demonstrates a new approach for how cognitive models can be used to address key limitations of deploying neural networks in human-interaction systems.</p><p>INFERRING PREFERENCES FROM FIXATIONS 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>We propose an approach to developing AI systems that estimate the latent variables that underlie human behavior. The approach is aimed at satisfying neural networks' need for massive data by using simulated data generated from a cognitive model. <ref type="bibr">First, limited</ref> human data is used to fit a cognitive model. In the example we tackle in this paper, human data consists of eye fixations between food items along with self-reported preferences over those items. The cognitive model is a resource-rational model specifying how individuals select fixations. Each fixation is modeled as an information-gathering action which decreases uncertainty around the utility of an item. Second, the cognitive model is then used to simulate massive amounts of simulated data. Third, this simulated data is used to pretrain neural networks. Finally, the neural networks are additionally fine-tuned with limited human data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>Our approach draws upon ideas from machine learning and cognitive modeling. In this section, we briefly review these ideas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inverse reinforcement learning</head><p>In machine learning, the problem of inferring another agent's preferences has been cast as inverse reinforcement learning (IRL; <ref type="bibr" target="#b25">Ng and Russell, 2000)</ref>. IRL specifies a generative model whereby agents have latent preferences (formalized as a utility function over task states and/or actions) and make decisions that maximize those preferences. This generative model, relating preferences to behavior, is inverted to predict the maximum a INFERRING PREFERENCES FROM FIXATIONS 5 posteriori (MAP) preferences that generated the observed behavior. This general framework of inferring preferences by inverting a decision model has also formed the basis of cognitive models for how individuals make inferences about others preferences based on their behavior <ref type="bibr" target="#b1">(Baker et al., 2017;</ref><ref type="bibr" target="#b19">Jara-Ettinger, 2019;</ref><ref type="bibr" target="#b20">Jern et al., 2017;</ref><ref type="bibr" target="#b24">Lucas et al., 2014)</ref>. Cognitive science has also recently provided more sophisticated models of how humans make decisions, which can provide more accurate models relating preferences to actions to guide inference <ref type="bibr" target="#b15">(Ho &amp; Griffiths, 2022)</ref>, and can expand the observables over which inference can occur to data beyond choices (e.g. response times; <ref type="bibr" target="#b7">Gates et al., 2021)</ref>.</p><p>Although IRL defines how preference inference can occur in principle, its practical use has been limited by the computational challenge of inverting decision models. Finding the MAP preferences typically involves searching over, and computing the likelihood of, candidate utility functions. For many cognitive process models, computing this likelihood for a single utility function can be quite computationally intensive. This makes a full search process too computationally expensive to be deployed in real-time inference settings. As a step toward making inference faster, recent work has shown that it is possible to implement IRL in neural networks, for which inference is fast <ref type="bibr" target="#b29">(Rabinowitz et al., 2018)</ref>.</p><p>However, this approach requires large amounts of labeled training data, which is often unavailable for real-life applications. Here, we test whether use of simulated data can alleviate this need for real human data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling the relationship between fixations and choice</head><p>Rather than trying to infer preferences purely from choices, we consider the problem of predicting preferences from visual fixations. When individuals make a choice between items, they tend to move their gaze between potential items in a stereotypic manner. This process has been studied experimentally in tasks where a participant is presented with a screen displaying snack items, and is required to select which of them they would prefer to eat at the end of the experiment . Recent work suggests that when making such decisions, people fixate on the different options in a INFERRING PREFERENCES FROM FIXATIONS 6 way that depends on independently provided ratings of how much they like those items <ref type="bibr" target="#b4">(Callaway et al., 2021;</ref><ref type="bibr" target="#b10">Gluth et al., 2020;</ref><ref type="bibr" target="#b18">Jang et al., 2021)</ref>. These relationships in principle make it possible to predict individuals' utility over items from their fixations.</p><p>Prior studies have found that it is possible to use the total as well as proportion of time individuals spend fixating on different items to predict, to some extent, individuals' preferences for those items <ref type="bibr" target="#b9">(Glaholt et al., 2009;</ref><ref type="bibr" target="#b13">Goyal et al., 2015)</ref>.</p><p>We aim to assess how a cognitive model of how individuals select fixations can be used to improve this inference. <ref type="bibr" target="#b4">Callaway et al. (2021)</ref> presented a resource-rational model for how individuals select both where to fixate at any point in time, and when to stop fixating and make a choice in such tasks. According to the model, eye movements reflect optimally selected information-gathering computations that improve the participant's beliefs about the utilities of different snack items <ref type="figure" target="#fig_5">(Fig. 2)</ref>. These computations can lead to a better ultimate decision, however they also incur a cognitive cost. By formalizing this process as a sequential decision problem (specifically, a meta-level Markov decision process), the optimal fixation policy can be identified. It was found that the sequences of fixations made by the optimal policy closely corresponded to participant's observed fixation behavior. We provide a brief summary of the model in the supplement and refer the reader to <ref type="bibr" target="#b4">Callaway et al. (2021)</ref> for further details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inverting cognitive models using neural networks</head><p>Directly inverting cognitive models, such as the model of fixations in choice proposed by <ref type="bibr" target="#b4">Callaway et al. (2021)</ref>, is computationally infeasible. We thus propose a new approach: using simulated data from this cognitive model to train neural networks to infer an individual's preferences given their fixations. Our task involves mapping a sequence (fixations) to a scalar (utility), so we use three types of neural networks that have been shown to be successful in handling sequence data: long-short-term-memory (LSTM) neural networks <ref type="bibr" target="#b17">(Hochreiter &amp; Schmidhuber, 1997)</ref>, gated recurrent unit (GRU) neural networks <ref type="bibr" target="#b5">(Cho et al., 2014)</ref> and <ref type="bibr">Transformers (Vaswani et al., 2017)</ref>. LSTMs and GRUs are both INFERRING PREFERENCES FROM FIXATIONS 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>We apply the proposed method to a rational model of attention allocation in preferential choice <ref type="bibr" target="#b4">(Callaway et al., 2021</ref> variants of recurrent neural networks (RNNs) which map inputs to a hidden-unit representation, which in turn is mapped both to an output estimate and also provided back INFERRING PREFERENCES FROM FIXATIONS 8 into itself as additional input for the next time-step. Through learning, the hidden unit representation comes to summarize the relevant input history of the sequence up to that time-point, thus enabling the output to be based not only on current input but also on a history of input. Whereas for original <ref type="bibr">RNNs (Rumelhart et al., 1986)</ref>, hidden units passed their activation to the next time-step through a set of learned weights, GRUs and LSTMs can learn gates and other structures that control how much past information in a sequence should be passed along to future time-steps in a contextual manner.</p><p>Unlike RNNs, which update an internal representation one step at a time, Transformers process the entire sequence at once, mapping it to an internal representation through a "self-attention" mechanism (at test time, the model makes predictions sequentially given the observations before the current predicted element). In self-attention, each item in the input sequence is represented as a weighted sum of values derived from the entire sequence. These values are learned, allowing the weighted sum to capture relevant information from both the current item and other items in the sequence.</p><p>The attention weights are determined by an attention score, which measures the relevance of each item to the current one. This score is computed based on the similarity between the "query" vector of the current item and the "key" vector of the other items.</p><p>Both key and query vectors are learned for each item to facilitate the task-specific relationships between items. Thus, each item's output representation is the sum of all items' value vectors, weighted by the attention scores between the current item's query vector and the other items' key vectors. This mechanism enables the model to incorporate relevant information from the entire sequence when representing each item.</p><p>We compare these sequence-based models to models using hand-defined sequential information (e.g., the sum of fixations up to a given time point) to estimate utilities. For these comparisons, we use multi-layer perceptrons (MLPs). MLPs are neural networks that map features at a single time point to a learned internal representation, which is then used to estimate the utility of each item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INFERRING PREFERENCES FROM FIXATIONS 9</head><p>Our approach builds on work in cognitive science and machine learning that has combined neural networks with simulated data to either invert complex generative models or to predict human choices. For fitting cognitive models to behavior, recent work has used neural networks to approximate likelihood functions that might otherwise be intractable <ref type="bibr" target="#b6">(Fengler et al., 2021)</ref>. Closer to our application here is work that has trained neural networks to directly estimate mean parameters or sample from posterior distributions of complex models, by training networks with simulated data labeled with corresponding parameters <ref type="bibr" target="#b8">(Ger et al., 2023;</ref><ref type="bibr">Gonçalves et al., 2020;</ref><ref type="bibr" target="#b26">Papamakarios &amp; Murray, 2016;</ref><ref type="bibr" target="#b30">Radev et al., 2022;</ref><ref type="bibr">Yildirim et al., 2020)</ref>. Neural networks used to predict human decisions have been pretrained with simulated data from cognitive models to make up for limited real human data <ref type="bibr" target="#b2">(Bourgin et al., 2019)</ref>. Finally, neural networks trained to predict human choices have in turn been used to improve cognitive models through a process referred to as Scientific Regret Minimization <ref type="bibr" target="#b0">(Agrawal et al., 2020;</ref><ref type="bibr" target="#b23">Kuperwajs et al., 2023;</ref><ref type="bibr" target="#b28">Peterson et al., 2021)</ref>.</p><p>We turn this approach toward the problem of estimating human preferences from eye fixations, training neural networks on simulated fixation and choice data from the model presented in <ref type="bibr" target="#b4">Callaway et al. (2021)</ref>. We first test whether we can simply invert the model; that is, we provide neural networks with a sequence of simulated fixations followed by a choice and test whether they output correct utilities over the three items. Following this, we validate the approach using real human data on a trinary choice task, reported in . We determine whether neural networks can predict people's reported utilities given their fixations and choices, how this compares to prediction using choice alone, and also whether simulated data complements using human data alone in training models on this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INFERRING PREFERENCES FROM FIXATIONS 10</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Data</head><p>Human data consisted of 2966 trials reported in  in which participants made choices over three food items after having the opportunity to engage in a sequence of fixations between them. Fixations, f jt i , reflect the item most fixated on in a .1 second bin. Prior to all choices, participants provided liking ratings (utilities) over the full set of items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulated Data</head><p>Simulated data was generated using the model described in Callaway et al. <ref type="formula">2021</ref>( <ref type="figure" target="#fig_5">Fig. 2</ref>). To simulate a single trial, j, a utility, u js , was drawn for each snack item, s, from P (u), which was defined by fitting a Gaussian distribution to the full set of item ratings from . Given such "true" utilities over items, the model generates a sequence of fixations, f jt i &lt;T , over by items, followed by a choice, c jt i ,</p><formula xml:id="formula_0">x j = (f jt 1 , f jt 2 , ..., c jt T )</formula><p>. At a high level, each simulated fixation on item s collects a sample from a distribution of item utilities centered on u js , with Gaussian noise. This sample is used to increase the accuracy of an estimate of that item's utility. Optimal fixations reflect the information gathering actions that balance the benefit of making a choice with a more accurate utility estimates with the cost of spending additional time. A detailed description of the generative model is presented in supplementary section "Optimal fixation model". Parameters of the model are reported in supplementary section "Parameters of optimal fixation model". Using this model, we simulated 1.5 million trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input and Target Data Representation</head><p>For each trial, j, consisting of T time-points, we represented that trial's sequence of fixations followed by a choice as a length-T sequence of 6-length vectors, x ji , for each time-point, i = 1 : T <ref type="figure" target="#fig_0">(Fig. 3a</ref>, "Input"). For each time-point, i &lt; T , the first 3 elements of</p><p>x ji designated which of the 3 food items was fixated on at that time-point. The last 3 elements, which were active only for the final time-point, T , designated which of the three items was chosen on that time-point. Sequence-based models were trained to make a prediction of each of the three item's utilities at each time-point, i, in the sequence, using all input data up to time-point i. The target sequence thus consisted of a length-3 vector where each element, j = 1 : 3 contained the true utility of item j, u j , repeated for each time-point in the sequence <ref type="figure" target="#fig_0">(Fig. 3a</ref>, "Target").</p><p>We compared models trained on both fixations and choice to a model trained on choice alone. For the model trained on choice alone, we trained a model that simply estimated two parameters reflecting the respective utilities of the chosen item and non-chosen items <ref type="figure" target="#fig_0">(Fig. 3c</ref>). We also defined a set of control models based on features that previous work has identified as predictive of preferences: the cumulative total and proportion fixation time on each item <ref type="bibr" target="#b9">(Glaholt et al., 2009;</ref><ref type="bibr" target="#b13">Goyal et al., 2015)</ref>. For each time point, we defined a length-9 vector, with three values indicating the current fixated item (ID), three indicating the total fixation time on each item (Sum), and three indicating the proportion fixation time on each item (Prop; <ref type="figure" target="#fig_0">Fig. 3b</ref>). We then trained multi-layer perceptrons to map these features at each time-point to utility estimates for each item.</p><p>Performance of these models is compared in <ref type="figure" target="#fig_4">Supplementary Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Procedure and Hyperparameter Selection</head><p>Both simulated and human data were split into training (50%), validation (25%) and testing (25%) sets. The human testing set did not include any data (even trials; N = 1482) used to estimate the generative fixation model parameters in <ref type="bibr" target="#b4">Callaway et al. (2021)</ref>.</p><p>Of the trials not used to estimate model parameters (odd trials), half (N = 742) were randomly selected as the test set, which was held constant across runs. The remaining odd trials (N = 742) were combined with the even trials to form training and validation sets (2224 total). Within each run, 1482 trials (67%) were used for training, and 742 trials (33%) were for validation to select hyperparameters.</p><p>We trained Transformers (Vaswani et al., 2017), GRUs <ref type="bibr" target="#b5">(Cho et al., 2014)</ref>, and LSTMs <ref type="bibr" target="#b17">(Hochreiter &amp; Schmidhuber, 1997)</ref>. Detailed descriptions of each model are provided in Supplementary section "Detailed information on model architectures". Because qualitative results were the same across architectures, we show only Transformer results in the main text and present results for all networks in the supplementary information ( <ref type="figure" target="#fig_1">Supplementary Figs. 2-4)</ref>. Control models used multi-layer perceptrons (MLPs). All networks were implemented in the Python package, PyTorch <ref type="bibr" target="#b27">(Paszke et al., 2017)</ref>. We used the Adam optimizer to identify network parameters that minimized the mean square error in predicting the set of training sequences. All training used a batch size of 32. For each task, for all networks, we used a grid search to identify the number of hidden units (and embedding dimensionality for transformers; out of <ref type="bibr">[8,</ref><ref type="bibr">16,</ref><ref type="bibr">32,</ref><ref type="bibr">62,</ref><ref type="bibr">128,</ref><ref type="bibr">256,</ref><ref type="bibr">512]</ref>) and learning rate (out of <ref type="bibr">[.00001, .0001, .001]</ref>). For each combination of these hyperparameters, we trained 5 models, each with different starting weights. Resultant best hyperparameters are reported in <ref type="table">Supplementary Tables 1-4.</ref> When training on simulated data alone, networks were trained with a single epoch through 1.5 million simulated training trials. Models trained on human data alone and those pretrained on simulated data followed by fine-tuning on human data both used the same number of human training examples (N = 1482 trials). When training on human data alone, networks were trained for up to 1350 epochs through the training dataset of 1482 human trials. When pretraining on simulated data and then finetuning with human data, networks were trained with a single epoch through 1.5 million simulated training trials and then were finetuned for up to 1350 epochs through the training dataset of 1482 human trials. For all approaches, for each hyperparameter combination we averaged the 5 error-vs-training-number curves, smoothed them with a Gaussian kernel (σ = 200 batches) and selected the hyperparameters and either the number of simulated training trials (for the simulated only case) or number of epochs through human data (for human only and simulated and human cases) that achieved minimum mean squared error under that approach and objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INFERRING PREFERENCES FROM FIXATIONS 14</head><p>For the Transformer networks, we set the number of attention heads to 4 and the number of layers to 2. All other parameters were set to PyTorch default values. All final results reflect using these hyperparameters and number of training sequences, averaged over 100 runs, each with randomized training data ordering and initial weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transformers trained on simulated data can predict latent utilities</head><p>We first examined the ability of Transformers trained on simulated fixation and choice data to predict corresponding latent utilities used to generate that data. An advantage for predicting utilities from fixations in addition to choices, as opposed to predicting from choices alone, is that prediction from fixations can be made prior to the choice occurring. Indeed, Transformers were able to predict latent utilities at time-points prior to choice occurrence, from fixations alone, with prediction accuracy increasing up until the time of choice occurrence ( <ref type="figure" target="#fig_1">Fig 4A)</ref>. This prediction accuracy prior to choice outperformed a variety of control models, which used multi-layer perceptrons to map hand-designed features at a single-time point to prediction of utilities (see Methods). The best performing control model was provided the current fixation identity, the sum of fixations on each item up to that time-point, and the proportion of fixations up to that time-point ( <ref type="figure" target="#fig_4">Supplementary Fig. 1A</ref>). This control model achieved worse prediction accuracy than the Transformers model (independent sample t-test comparing accuracy correlations aggregated across time-points, t(358) = 19.2, p &lt; .001) demonstrating that the Transformers can learn non-trivial sequential aspects of the relationship between fixations and preferences in the simulated data (see <ref type="figure">Supplementary Fig. 7</ref> for additional demonstration that networks learn non-trivial sequential aspects of the relationship).</p><p>Transformers trained on fixations in addition to choice also conferred an advantage in predicting preferences after a choice was made compared to predictions made using choice alone ( <ref type="figure" target="#fig_0">Fig 4B; t(358)</ref> = 88.1, p &lt; .001). This demonstrates an ability to learn about relationships between fixations and preferences in simulated data beyond just predicting which item will be chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INFERRING PREFERENCES FROM FIXATIONS 16</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulated data complements human data in predicting human utilities</head><p>We next sought to examine the ability of Transformers trained on fixation and choice data to predict human self-reported utilities of items from fixations and choices over those items. Additionally, we sought to determine whether training networks with simulated data provided a benefit over training with human data alone. We thus compared the ability of different Transformers to predict real human self-reported preferences, varying whether the Transformers were trained using simulated data only, human data only, or pretrained on simulated data and fine-tuned using human data. Networks pretrained on simulated data and finetuned with human data outperformed networks trained using either simulated data or human data alone, both when predicting preferences prior to a choice being made ( <ref type="figure" target="#fig_2">Fig. 5A</ref>; Simulated and Human vs Simulated Only: t(358) = 25.6, p &lt; .001;</p><p>Simulated and Human vs Human Only: t(358) = 30.8, p &lt; .001; see <ref type="figure">Supplementary Fig. 6</ref> for mean squared error of each approach) and also when predicting with knowledge of the choice <ref type="figure" target="#fig_2">(Fig. 5B</ref>; Simulated and Human vs Simulated Only: t(358) = 9.2, p &lt; .001;</p><p>Simulated and Human vs Human Only: t(358) = 45.4, p &lt; .001). This demonstrates that simulated data is beneficial in addition to human data in predicting real human preferences.</p><p>We additionally compared augmenting limited human data with simulated data to an alternative ways limited human data might be augmented (Supplementary section "Comparison with noise-based data augmentation"). Specifically, we implemented a form of data augmentation by repeating existing human trials, but modifying each example with noise. We find that models trained on simulated-augmented data outperform those trained using noise-augmented data, further demonstrating the utility of pretraining with simulated data ( <ref type="figure" target="#fig_2">Supplementary Fig. 5</ref>).</p><p>To assess overall accuracy at predicting human preferences from fixations alone, we compared Transformers trained on human and simulated data to control MLPs trained on hand-designed features. The best performing control model for predicting human preferences from fixations was provided the proportion of fixations up to that time-point ( <ref type="figure" target="#fig_4">Supplementary Fig. 1B</ref>). We note that because the Transformer is trained to maximize accuracy across all time-points, it is outperformed at the final time-point prior to choice by the best control model (note however that neither model knows at what time-point the choice will occur). Aggregated across all time-points however, this control model was outperformed by Transformers trained on simulated and human data ( <ref type="figure">Fig. 6A;</ref> t(358) = 37.3, p &lt; .001; see <ref type="figure">Supplementary Fig. 8</ref> for comparison against additional control model). As in the simulated data case, Transformers trained on simulated and human data, using both information about fixations and which item was chosen, performed better than a model that only used information about which item was chosen ( <ref type="figure">Fig. 6B;</ref> t(358) = 113.9, p &lt; .001). This demonstrates that, under this approach, using fixation data to predict preferences confers a slight benefit beyond simply predicting which item will be </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Cognitive models, which define the relationships between an individual's latent preferences and their behavior, offer a tremendous opportunity to infer the hidden variables that guide an individual's choice. However, standard approaches to performing probabilistic inference with such models are computationally prohibitive for practical applications. Here, we have proposed and implemented a new approach for using neural networks to perform inference in such cognitive models, which can make inference computationally feasible for online applications. In addition to demonstrating that neural networks can perform inference of latent preferences in such models, we have also shown that simulating data from such models can make up for limited human data in training neural networks to infer real human preferences from behavior.</p><p>We found robust results across LSTMs, GRUs, and Transformers, but Transformers benefited most from pretraining with simulated data. This is consistent with recent work showing that Transformers especially benefit from massive pretraining datasets (e.g. <ref type="bibr">Radford et al., 2018)</ref>. However, the similar qualitative effects across models suggest these are due to the data and any sufficiently capable architecture would show similar effects.</p><p>A key question for future analysis is what type of information neural network models utilize from the data-generative model. <ref type="bibr" target="#b4">Callaway et al. (2021)</ref> demonstrate that the optimal fixation model captures a rich and subtle relationship between preference and gaze, which has been validated in human data. It predicts, for example, that the duration of the first fixation to an item, the order in which it is re-fixated, and whether it is fixated last should all be informative of preference. While we do not show the exact features that neural network models utilize to predictions, we do show in supplementary analysis ( <ref type="figure">Supplementary Figures 7 and 8</ref>) that preserving the order of fixations and time-points is important for model performance, demonstrating that it picks up on fine-grained relationships between fixations and choice.</p><p>Overall, this approach is likely limited by the extent to which cognitive models can INFERRING PREFERENCES FROM FIXATIONS 20 capture idiosyncratic features of the relationship between human preferences and behavior.</p><p>In future work, we can improve this approach by identifying and understanding discrepancies between model generated datasets and real human fixation data. Identifying such discrepancies may enable the generation of new generative models of fixations. These models may relax the strong optimality assumptions of the model we currently use, but may in turn produce fixation data that is more useful for training neural networks for predicting preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code Availability</head><p>Analysis code is available at https://anonymous.4open.science/r/Inverse_Gaze_Neural_Networks-63B8 Radford, A., <ref type="bibr">Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018)</ref>. Improving language understanding by generative Pre-Training. Open AI Blog.</p><p>Rumelhart, D. E., <ref type="bibr">Smolensky, P., McClelland, J. L., &amp; Hinton, G. (1986)</ref>. Sequential thought processes in PDP models. Parallel distributed processing: explorations in the microstructures of cognition, 2, 3-57. <ref type="bibr">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017)</ref>. Attention is all you need. Advances in <ref type="bibr">Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</ref><ref type="bibr">, 30, 5998-6008. Yildirim, I., Belledonne, M., Freiwald, W., &amp; Tenenbaum, J. (2020</ref>. Efficient inverse graphics in biological face processing. Science Advances, 6 (10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimal fixation model</head><p>We consider simple choice problems in which an agent is presented with a set of items (e.g., snacks) and must choose one. Each item i is associated with some true but unknown value, u <ref type="bibr">(i)</ref> , the utility that the agent would gain by choosing it. Following previous work , we assume that the agent informs their choice by collecting noisy samples of the items' true values, each providing a small amount of information, but incurring a small cost. We model attention by assuming that the decision maker can only sample from one item at each time point, the one that is currently fixated.</p><p>The model is formalized as a "metalevel" Markov decision process <ref type="bibr" target="#b33">(Hay et al., 2012)</ref>. In this model, the states correspond to Bayesian estimates of the value of each choice option.</p><p>The actions correspond to fixating an option, drawing one noisy sample of its value, and integrating this sample into the estimated value distribution. A separate action corresponds to terminating the decision-making process and choosing the item with maximal expected value. The reward function assigns a cost for each sample drawn and an additional cost for switching between options; it additionally assigns a reward equal to the value of the chosen option when a choice is made.</p><p>We assume that the decisions about where to fixate and when to stop sampling are made optimally; that is, we assume people select their fixations according to the optimal policy of the metalevel Markov decision process. This policy is defined by a mapping from the value estimate of each option (and the identity of the currently fixated option) to a selection of which item to fixate next (or to continue fixating the current item). In broad strokes, applied to ternary choices such as we consider, the model predicts that attention will be drawn to items with higher estimated value and less precise value estimates. See  Results of training model on simulated data and testing on held-out simulated data for GRU and LSTM networks. Plot corresponds to <ref type="figure" target="#fig_4">Fig. 1, but with GRU (A,B)</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with noise-based data augmentation</head><p>We compared the approach of augmenting limited human data with simulated data to an alterantive approach where human data is augmented with independent noise added to repeating examples, with noise added. Our specific approach to creating additional augmented training data is as follows. For each of the human training trials, we create 5 additional trials by swapping the identity of some of the objects. Specifically, positions for objects 1, 2 and 3 can be permuted in 6 ways. As an example permutation, to swap positions of objects 1 and 2, the fixations and utility for object 1 are assigned to object 2 and vice-versa. Additionally, the reported utility of objects 1 and 2 would be swapped, and, if the participant chose either object 1 or 2, the choice would be correspondingly relabeled.</p><p>Making all possible permutations leads to multiplying the set of human trials by 6. For each trial in this expanded set, we then create N training trials by adding noise to both the trial's fixations and to each item's reported utility. Noise is added to fixations by specifying a fixed, independent probability of altering which item is fixated, which we refer to as "Fixation Noise". For the utilities, Gaussian noise is added, with standard deviation we refer to as "Utility Noise". N was selected to create a number of noise-augmented training trials equivalent to the number of simulated trials that we use (1.5 million). We use these noise-augmented training trials to pretrain models and then, equivalent to the simulated case, we finetune using all human train trials with no augmentation and no noise added.</p><p>We ran this analysis, varying Fixation Noise between 0, .125 and .25, and varying Utility Noise 0, .5 and 1. Because doing an entire new hyper-parameter search for each model at each setting of Fixation Noise and Utility Noise is computationally infeasible, we run each noise combination at two settings of hyper-parameters: those which were determined to be best when training on human data alone ("Best Human Only Parameters") and those which were determined to be best when training on both simulated and human data ("Best Simulated and Human Parameters"").</p><p>The results of this analysis are reported in <ref type="figure" target="#fig_2">Supplementary Fig. 5</ref>. Augmenting human SUPPLEMENTARY INFORMATION 7 training data along with the approach of combining pretraining and fine-tuning phases in some cases leads to better test performance than training on non-augmented human data alone. However, in general, adding noise beyond the first step of data augmentation (permuting item positions) does not improve prediction performance on the test set.</p><p>Notably, all models pretrained with noise-augmented human data perform worse than models pretrained with simulated data. This demonstrates the advantage of pretraining using simulated data from a cognitive model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 8</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5</head><p>Comparison of models trained with alternative data augmentation approaches to models pretrained on simulated data. To augment human training data, for each human training trial, we create 5 additional trials by swapping the identity of either one, two or three of the objects. This leads to multiplying the set of human trials by 6. For each trial in this expanded set, we create N training trials by adding noise to both the fixations and also the item's reported utility. Noise is added to fixations by having a fixed, independent probability of altering which item is fixated, which we refer to as "Fixation Noise". For the utilities, Gaussian noise is added, with standard deviation we refer to as "Utility Noise". N was selected to create a number of noise-augmented training trials equivalent to the number of simulated trials that we use (1.5 million).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 9</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Mean squared error for models trained on human data only and models pretrained on </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 10</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with models trained on time-shuffled data</head><p>To further test whether sequence models make use of sequential aspects of fixations to utilities, we trained additional control models. These control models utilized the same sequential architectures and hyperparameters presented in the main text. For each training sequence, for each time-point, we defined a training example with fixations shuffled up to that time-point. This required a slight modification to the training procedure used in the main analysis. Instead of training on every time-point using a single target vector containing item utilities at each time-point index, we defined a new training example and a single-time-point target for each time-point. To ensure comparability, we re-implemented the main analysis with non-shuffled fixations using this same procedure.</p><p>The results are presented in <ref type="figure">Supplementary Figs. 7 and 8</ref>. Models trained on non-shuffled fixations outperformed those trained on shuffled fixations for predicting both simulated and human data. However, when predicting human utilities post-choice, results were inconsistent across models, suggesting that sequential information is less critical once choice data is included. Nevertheless, the best performing model (the transformer) was slightly more accurate with unruffled sequences, suggesting that this information does have some predictive value even after observing the choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 11</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 7</head><p>Comparison of models trained on shuffled fixations up to some time-point with those trained on non-shuffled fixations. Models are trained on simulated data and evaluated on stimulated data. Models tested are Transformers <ref type="bibr">(A,B)</ref>, <ref type="bibr">GRUs (B,C)</ref> and <ref type="bibr">LSTMs (E,F)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 12</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 8</head><p>Comparison of models trained on shuffled fixations up-to some timepoint with those trained on non-shuffled fixations. Models are trained on simulated and human data and evaluated on human data. Models tested are Transformers <ref type="bibr">(A,B)</ref>, <ref type="bibr">GRUs (B,C)</ref> and <ref type="bibr">LSTMs (E,F)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 13</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detailed information on model architectures</head><p>Here, we provide detailed description of each model's architecture. All models were implemented in PyTorch. Layers refer to PyTorch functions. All models trained on fixation followed by choice took in a 6-dimensional input <ref type="figure" target="#fig_4">(Fig. 1)</ref>.</p><p>In the main text, we present results using a transformer architecture. The transformer architecture consisted of a linear encoder which mapped the 6-dimensional input to a D dimensional embedding (where D was a hyperparameter). This embedding was then passed through a positional encoder, which had the same dimension as the embedding, and used sin and cosine functions to inject information about the position of each fixation in the sequence. This encoding was then passed through a transformer encoder. The transformer encoder contained 4 heads, 2 layers, and a feedforward dimensionality equal to 4 times the embedding dimensionality (D). The output of the transformer encoder was then passed to a linear decoder, which mapped from dimensionality D to a 3-dimensional output consisting of a prediction for each item.</p><p>We also examine results using LSTM and GRU models in the supplement. LSTM and GRU models consisted respectively of either LSTM or GRU layers which mapped the 6-dimensional input to a D dimensional hidden representation, where D is a hyper-parameter. This hidden representation was passed to a linear layer which mapped it to a 3-dimensional output consisting of a prediction for each item.</p><p>MLP control models consisted a linear mapping from 6-dimensional input to D dimensional hidden layer. This hidden layer was then passed through a rectified linear unit function and was then passed through a linear layer mapping it to a 3-dimensional output consisting of a prediction for each item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY INFORMATION 14</head><p>Hyperparameters for sequential models Hyperparameters were selected as those that maximized accuracy on validation data. Separate hyperparameters were selected for each training setting and prediction objective.</p><p>Best hyperparameters for each model are reported in <ref type="table">Tables 1 -4</ref>  <ref type="table">Table 1</ref> Hyperparameters for training on simulated data and predicting simulated data. All models were trained on a single epoch of 1.5 million simulated training examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameters of optimal fixation model</head><p>The model was fit to the even-numbered trials in two snack-choice datasets, one for binary choice  and one for trinary choice . As in Callaway et al., 2021b paper, we generate predictions using a mixture of the top 30 parameter configurations, to account for noise in the model fitting procedure. The parameter estimates were (mean ± std) σ x = 2.6 ± 0.216, α = 0.581 ± 0.118, </p><formula xml:id="formula_1">γ</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3</head><label>3</label><figDesc>Input and target data representation for an example trial. In this example trial, the participant fixated for two time-steps on item 1, one time-step on item 3, two time-steps on item 2, and then chose item 2. A. Representation of example trial's input sequence and target sequence for training sequence-based models (e.g. Transformers). Note that to predict each item's utilities at time-point i, sequence-based models can make use of all time-points in input sequence up to and including time-point i. B. Representation of example trial's input and target sequence for non-sequential control model with hand-designed features. Input representation of a time-point includes hand-designed features pertaining to cumulative information about fixations up to and including that time-point. Unlike sequence-based models, here multi-layer perceptrons have to map a single-time point's input representation to a prediction of each item's utilities. Note that this model uses only fixation, but not choice information. C. Example trial's input and target representation for model trained on choice alone. This model just learns two parameters: one for the utility of the chosen item and one for the utility of the two unchosen items. Note that although in this case two unchosen items have different utility values, the choice-only model will assign the same prediction to these two items.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4</head><label>4</label><figDesc>Results of training model on simulated data and testing on held-out simulated data. A. Predictive accuracy of neural networks at predicting simulated data utilities, at each time-point prior to a choice being made. Gray markers denote different control models that use MLPs to map handcrafted features to estimates of utility (Plus: current item, Triangle: proportion of time spent on each item, Square: cumulative time spent on each item, Circle: all prior features together). B. Predictive accuracy after the choice is made. Transformers trained on simulated fixation and choice data outperform a model which only uses the choice that was made.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5</head><label>5</label><figDesc>Testing on human data under different training regimes. Transformers were trained using either simulated data alone, human data alone, or were pretrained with simulated data and finetuned with human data. Networks trained with both simulated and human data outperformed networks trained with either alone. A. Predictive accuracy of neural networks at predicting self-reported human item utilities, at each time-point prior to a choice being made. B. Predictive accuracy of neural networks at predicting utilities of human data after choice is made, using both fixation and choice information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure</head><label></label><figDesc>Comparison of Transformers trained on simulated and human data to control model using hand-crafted features and also model which uses choice alone. A. Predictive accuracy of neural networks at predicting self-reported human item utilities, at each time-point prior to a choice being made. Gray markers denote different control models that use MLPs to map handcrafted features to estimates of utility (Plus: current item, Triangle: proportion of time spent on each item, Square: cumulative time spent on each item, Circle: all prior features together) B. Predictive accuracy on human data after the choice is made. Transformers trained on simulated and human fixation and choice data outperform a model which only uses the choice that was made. chosen.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1</head><label>1</label><figDesc>Performance of non-sequential control models. Control models are all multi-layer perceptrons (MLPs) which take in pre-defined features and output predictions of each item's utility. The Current Item (ID) model maps the current fixated item (represented as a length-3 one-hot vector) to a prediction of item utilities. Sum of Time on Item (Sum) and Proportion of Time on Item (Prop) map either the cumulative sum or cumulative proportion of time thus-far into the trial fixated on each item to a prediction of the item utilities. ID + Sum + Prop stitches these different representations together into a length-9 vector. A) Performance when trained and tested on simulated data. B) Performance when trained on simulated and human data and tested on human data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2</head><label>2</label><figDesc>Figure 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3</head><label>3</label><figDesc>and LSTM (C,D) networks. A) GRU networks outperform control models at predicting from fixations prior to choice (t(358) = 16.7, p &lt; .001). B) GRU networks utilizing fixation and choice data outperform predicting preferences from choice alone (t(358) = 93.0, , p &lt; .001). C) LSTM networks outperform control models at predicting from fixations prior to choice (t(358) = 19.5, p &lt; .001). D) LSTM networks utilizing fixation and choice data outperform predicting preferences from choice alone (t(358) = 96.2, p &lt; .001). Testing on human data under different training regimes for GRU and LSTM networks. Plot corresponds to Fig. 2 but with GRU (A,B) and Transformer (C,D) networks. GRUs trained on simulated and human data outperforms GRUs trained on either simulated or human data only both prior to choice (A; Simulated and Human vs Simulated Only: t(358) = 15.9, p &lt; .001; Simulated and Human vs Human Only: t(358) = 28.4, p &lt; .001) and following choice (B; Simulated and Human vs Simulated Only: t(358) = 5.0, p &lt; .001; Simulated and Human vs Human Only: t(358) = 19.4, p &lt; .001). LSTMs trained on simulated and human data outperforms LSTMs trained on either simulated or human data only both prior to choice (C; Simulated and Human vs Simulated Only: t(358) = 21.0, p &lt; .001; Simulated and Human vs Human Only: t(358) = 11.2, p &lt; .001) and following choice (D; Simulated and Human vs Simulated Only: t(358) = 38.0, p &lt; .001; Simulated and Human vs Human Only: t(358) = 40.8, p &lt; .001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4</head><label>4</label><figDesc>Results of training model on simulated and human data and testing on held-out human dataforGRU and Transformer networks. Plot corresponds to Fig. 3, but with GRU (A,B) and LSTM (C,D) networks. A) GRU networks outperform control models at predicting from fixations prior to choice (GRU vs Best Control: t(358) = 23.4, p &lt; .001). B) GRU networks utilizing fixation and choice data outperform predicting preferences from choice alone (t(358) = 19.3, p &lt; .001). C) LSTM networks outperform control models at predicting from fixations prior to choice (LSTM vs Best Control: t(358) = 19.2, p &lt; .001). D) LSTM networks utilizing fixation and choice data outperform predicting preferences from choice alone (t(358) = 4.81, p &lt; .001) SUPPLEMENTARY INFORMATION 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>simulated data. A-C) Comparison of validation error over training epochs for three different sequential models. Vertical lines show points of lowest validation error where test performance is assessed. D) Test error performance for each different model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>switch = 0.00995 ± 0.001, γ sample = 0.00373 ± 0.001, and β = 364.0 ± 81.2 The units of these parameter estimates are standard deviations of utility rating (i.e.,σ). See Callaway et al. (2022) for details of the fitting procedure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>.</figDesc><table><row><cell>Parameter</cell><cell cols="3">Transformer LSTM GRU</cell></row><row><cell>D</cell><cell>32</cell><cell>512</cell><cell>128</cell></row><row><cell>Learning Rate</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head><p>Transformer LSTM GRU    <ref type="table">Table 4</ref> Hyperparameters for training on simulated and human data and testing on human data. All models were pretrained on a single epoch of 1.5 million simulated training examples.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scaling up psychology via scientific regret minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U. S. A</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="8825" to="8835" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rational quantitative attribution of beliefs, desires and percepts in human mentalizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Bourgin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reichman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cognitive model priors for predicting human decisions</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="5133" to="5141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fixation patterns in simple choice reflect optimal information sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the properties of neural machine translation: Encoder-Decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SSST@EMNLP 2014, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>SSST@EMNLP 2014, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Likelihood approximation networks (LANs) for fast inference of simulation models in cognitive neuroscience. eLife</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fengler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Govindarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A rational model of people&apos;s inferences about others&apos; preferences based on response times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="page">104885</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Harnessing the flexibility of neural networks to predict dynamic theoretical parameters underlying human choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shahar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Predicting preference from fixations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Glaholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Reingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PsychNology Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="158" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Value-based attention but not divisive normalization influences decisions with multiple alternatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kortmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Vitali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="634" to="645" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Lueckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deistler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nonnenmacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Öcal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bassetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chintaluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">F</forename><surname>Podlaski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Vogels</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Training deep neural density estimators to identify mechanistic models of neural dynamics. eLlife</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Macke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting consumer&apos;s behavior using eye tracking data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Miyapuram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Lahiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Conference on Soft Computing and Machine Intelligence (ISCMI)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="126" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cooperative inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hadfield-Menell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dragan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3909" to="3917" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cognitive science as a source of forward and inverse models of human decisions for robotics and control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Control Robot</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Auton. Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Optimal policy for attention-modulated decisions explains human fixation behavior. eLlife</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Drugowitsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Theory of mind as inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">People learn other people&apos;s preferences through inverse decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="page" from="46" to="64" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Visual fixations and the computation and comparison of value in simple choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Armel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1292" to="1298" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U. S. A</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="13852" to="13857" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Using deep neural networks as a guide for modeling human planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kuperwajs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Schütt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The child as econometrician: A rational model of preference understanding in children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fawcett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kushnir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Markson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">92160</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Algorithms for inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Conference on Machine Learning</title>
		<meeting>the Seventeenth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="663" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fast ϵ-free inference of simulation models with bayesian conditional density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1028" to="1036" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;</forename><forename type="middle">.</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NPS 2017 Autodiff Workshop: The Future of Gradient-based Machine Learning Software and Techniques</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Using large-scale experiments and machine learning to discover theories of human decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Bourgin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reichman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="issue">6547</biblScope>
			<biblScope unit="page" from="1209" to="1214" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Machine theory of mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perbet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Francis Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="4215" to="4224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">BayesFlow: Learning complex stochastic models with invertible neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">K</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ardizzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Netw Learn Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1452" to="1466" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fixation patterns in simple choice reflect optimal information sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1008863</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fixation patterns in simple choice reflect optimal information sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Selecting computations: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tolpin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Shimony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence</title>
		<editor>N. de Freitas &amp; K. Murphy</editor>
		<meeting>the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012-08" />
			<biblScope unit="page" from="346" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visual fixations and the computation and comparison of value in simple choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Armel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1292" to="1298" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U. S. A</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="13852" to="13857" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
