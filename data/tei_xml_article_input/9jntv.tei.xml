<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tasks for aligning human and machine planning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-04-08">April 8, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bas</forename><surname>Van Opheusden</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><forename type="middle">Ji</forename><surname>Ma</surname></persName>
						</author>
						<title level="a" type="main">Tasks for aligning human and machine planning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-04-08">April 8, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T12:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">The challenge of aligning tasks between fields</head><p>Research on artificial intelligence and research on human intelligence rely on similar conceptual foundations and have long inspired each other <ref type="bibr" target="#b49">[Turing, 1950</ref><ref type="bibr" target="#b28">, Lake et al., 2017</ref>. However, achieving concrete synergy has been difficult, with one obstacle being a lack of alignment of the tasks used in both fields. Artificial intelligence research has traditionally focused on tasks that are challenging to solve, often using human performance as a benchmark to surpass <ref type="bibr" target="#b47">[Tesauro, 1995</ref><ref type="bibr" target="#b7">, Campbell et al., 2002</ref><ref type="bibr" target="#b33">, Mnih et al., 2013</ref><ref type="bibr" target="#b41">, Silver et al., 2016</ref><ref type="bibr" target="#b42">, Silver et al., 2017</ref>. By contrast, cognitive science and psychology have moved towards tasks that are simple enough to allow for detailed computational modeling of people's choices. These divergent objectives have led to a divide in the complexity of tasks studied, both in perception and cognition. The purpose of this paper is to explore the middle ground: are there tasks that are reasonably attractive to both fields and could provide fertile ground for synergy?</p><p>In perception, object recognition has emerged as a central task for aligning the studies of biological and machine vision. For biological vision, object recognition is a core task used to understand representations of visual stimuli in the ventral stream and specifically the infero-temporal cortex <ref type="bibr" target="#b37">[Riesenhuber and</ref><ref type="bibr">Poggio, 2000, DiCarlo et al., 2012]</ref>. In machine vision, object recognition has proven to be an equally fruitful test bed <ref type="bibr" target="#b27">[Krizhevsky et al., 2012</ref><ref type="bibr" target="#b29">, LeCun et al., 2015</ref>. This alignment of tasks has led to great synergy, for example in the form of comparisons between cortical activity and the activity of units in trained neural networks <ref type="bibr" target="#b54">[Yamins and</ref><ref type="bibr">DiCarlo, 2016, Kriegeskorte, 2015]</ref>.</p><p>In this paper, we focus on planning, which we roughly define as any cognitive process in which the decision-maker mentally simulates future states, actions or outcomes in a decision tree. These decision trees can often become exponentially large, and strategies for efficiently searching decision trees and making fast and accurate decisions are of interest for artificial intelligence and cognitive psychology. In the artificial intelligence of planning, the game of chess has long taken center stage, from Shannon <ref type="bibr">[Shannon, 1950]</ref> to DeepBlue <ref type="bibr" target="#b7">[Campbell et al., 2002]</ref> to AlphaZero <ref type="bibr" target="#b42">[Silver et al., 2017]</ref>. The cognitive psychology of chess has lagged behind. Chase and Simon advocated for chess as a "standard task environment" similar to Drosophila in genetics <ref type="bibr" target="#b10">[Chase and Simon, 1973]</ref>. Researchers have attempted to measure depth of thought in chess through clever experimental methods such as board reconstruction <ref type="bibr" target="#b15">[de Groot, 1946]</ref>, "thinking aloud" <ref type="bibr" target="#b10">[Chase and</ref><ref type="bibr">Simon, 1973, Campitelli and</ref><ref type="bibr" target="#b8">Gobet, 2004]</ref>, playing under cognitive load <ref type="bibr" target="#b21">[Holding, 1989]</ref> or time pressure <ref type="bibr" target="#b9">[Chabris and Hearst, 2003</ref><ref type="bibr" target="#b4">, Burns, 2004</ref><ref type="bibr" target="#b50">, Van Harreveld et al., 2007</ref>. Overall, however, the prominence of chess as an experimental paradigm in cognitive science has declined. One potential reason for this decline is the difficulty of developing a computational model for human chess play, and a simpler game is needed.</p><p>In the following sections, we will reflect on the notion of task complexity and review sequential decisionmaking tasks that have been used in computational cognitive science to test hypotheses about planning. We will then examine candidate tasks for aligning human and machine planning, and set an agenda for how such alignment could be achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Defining task complexity</head><p>The complexity of a decision-making task can be defined in multiple ways. We focus on state space complexity, the number of different states that a decision-maker can reach in any sequence of actions starting from the initial state 1 . We choose this metric since it is often easy to compute or approximate, and in practice closely matches with intuitive notions of task difficulty. In two-player games, state space complexity is often correlated with game tree complexity <ref type="bibr" target="#b1">[Allis et al., 1994]</ref>. Using state space complexity, however, ignores important elements of difficulty, such as how easily people can learn the task rules, or whether the task requires managing uncertainty, learning models of one's opponent, and potential symmetries in the state or action space. A more principled complexity metric measures the size of a compressed state space, with abstracted states and actions, which preserve as much as possible the task structure <ref type="bibr">[Botvinick, 2012</ref><ref type="bibr" target="#b39">, Sanborn et al., 2018</ref>. Therefore, the exact numbers should be taken as only a rough quantification of the intuitive notion of complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State space complexity</head><p>Human cognition studies AI studies  <ref type="bibr" target="#b10">and Simon, 1973]</ref> [ <ref type="bibr" target="#b7">Campbell et al., 2002</ref>] <ref type="bibr" target="#b21">[Holding, 1985]</ref> [Silver et al., 2017] Go 2.1 â€¢ 10 170 <ref type="bibr" target="#b41">[Silver et al., 2016]</ref> Table 1: Tasks and their complexities. Artificial intelligence studies tend to focus on complex tasks, whereas cognitive scientists favor simplicity. State space complexity for chess and go are taken from <ref type="bibr" target="#b11">[Chinchalkar, 1996]</ref> and <ref type="bibr" target="#b48">[Tromp, 2016]</ref> 3 Tasks used to study human planning</p><p>The study of human planning is rich and has used many experimental tasks. A core challenge across tasks is that researchers can only observe people's decisions, and not the cognitive processes (planning algorithms) that generated them. A principled method to infer planning algorithms is by fitting a computational model to individual player's choices. Here, we review a selection of tasks that have been used to study human planning within a computational framework. The tasks are roughly sorted by increasing state space complexity. Solway and Botvinick task ( <ref type="figure" target="#fig_0">Fig. 1A)</ref>. <ref type="bibr" target="#b45">[Solway and Botvinick, 2015</ref>] This paper used a task in which participants choose between up to 4 consumer items that they previously ranked by desirability. Crucially, they presented items in two groups on either side of a computer screen, and participants reported their choice sequentially, by first selecting a group and afterwards an item within that group. This task is equivalent to navigating a decision tree with up to 3 internal nodes, and Solway and Botvinick found that people's behavior can be captured by noisy evidence integration, which treats each path through the decision tree as a competitor in a bounded accumulation process. <ref type="bibr">Daw et al. task (Fig. 1B)</ref>   In the two-step task, participants make a sequence of two binary choices. In the first decision stage, the participant might choose between stimuli A1 and A2. Stimulus A1 usually (on 70% of trials, labelled "common" transitions) leads to the state B, and stimulus A2 to state C. However, occasionally (on 30% of trials, "rare" transitions), A1 leads to C, or A2 to B. In the second stage, participants make another choice between two stimuli, which yields a monetary reward with some probability. The reward probabilities fluctuate slowly, so participants have to constantly adapt the values they associate with the stimuli and adjust their policy accordingly. The two-step task has state space complexity 3 (1 first-level state and 2 second-level states). This simplicity is intentional, as the two-step task is the simplest task that distinguishes model-free and modelbased learning. (However, it has been argued that sophisticated model-free learning can masquerade as model-based learning in this task <ref type="bibr" target="#b0">[Akam et al., 2015]</ref>.) Specifically, when an agent receives a reward at a second-level state, a model-based learner takes into account whether it arrived there through a "common" or "rare" transition, whereas a model-free learner does not. This task has been used to demonstrate that people use a mixture of model-based and model-free learning <ref type="bibr" target="#b14">[Daw et al., 2005</ref>, that the relative usage of each system depends on the reliability of their respective predictions <ref type="bibr" target="#b29">[Lee et al., 2014]</ref> in an on-line cost-benefit analysis <ref type="bibr" target="#b25">[Kool et al., 2016]</ref>, and that people's arbitration between these systems changes under cognitive load <ref type="bibr" target="#b34">[Otto et al., 2013]</ref> or when they receive a dopamine precursor <ref type="bibr" target="#b53">[Wunderlich et al., 2012b]</ref>. <ref type="bibr">GlÃ¤scher et al. task (Fig. 1C</ref>) <ref type="bibr" target="#b19">[GlÃ¤scher et al., 2010]</ref>. Their task preceded the two-step task and differed from it in two ways: first, there are 4 second-level states, and each combination of a first-level choice and a "common" or "rare" transition leads to a different state. Second, instead of a second-level state leading to a reward with some probability, the choice leads probabilistically to a third state, and then deterministically to a reward. These modifications allowed GlÃ¤scher et al. to dissociate neural correlates of reward prediction errors and state prediction errors. Wunderlich et al. task <ref type="figure" target="#fig_0">(Fig. 1D</ref>) <ref type="bibr" target="#b52">[Wunderlich et al., 2012a]</ref> In this variant of the two-step task, the transitions from the first to second level were made by an adversarial computer agent, creating a two-player game. This allowed them to study the computational processes underlying forward planning by searching for neural correlates of values of individual branching steps in a minimax decision tree. Callaway et al. task <ref type="figure" target="#fig_0">(Fig. 1E</ref>) <ref type="bibr" target="#b6">[Callaway et al., 2017</ref><ref type="bibr" target="#b5">, Callaway et al., 2018</ref> To more directly measure the planning process, they employed a process tracing method inspired by the "Mouselab" paradigm <ref type="bibr" target="#b35">[Payne et al., 1988]</ref>. Participants navigate a directed graph, in which each node is associated with a reward. Although all nodes and edges of the graph are always visible to the participant, rewards are only revealed when the participant clicks or hovers over the corresponding node. The sequence in which participants choose to reveal rewards provides insight in the cognitive process by which participants plan their actions. Although the paradigm scales in principle to arbitrary graphs, Callaway et al. study graphs with up to 20 nodes. Snider et al. task <ref type="figure" target="#fig_0">(Fig. 1F)</ref>. <ref type="bibr" target="#b44">[Snider et al., 2015]</ref> Participants watch a triangular grid of 12 rows of variable-sized disks scroll down a touchscreen, and at each downward step, participants control whether the grid moves right or left by pointing with a stylus. Thus, the participant traces out a trajectory through the grid of disks, and they receive reward proportional to the size of all disks on that trajectory. To plan optimally, participants have to navigate a decision tree with 66 internal nodes, making this one of the most complex tasks in which human planning has been quantitatively modeled. Huys et al. task <ref type="figure" target="#fig_0">(Fig. 1E</ref>) <ref type="bibr" target="#b22">[Huys et al., 2012]</ref> Participants make a sequence of up to 8 binary decisions, through which they traverse a graph of 6 states. Each transition incurs a reward that can be either positive or negative, and the task is designed such that the optimal policy requires taking large negative rewards to obtain later positive rewards. This task has been used to study how people prune decision trees following a large loss <ref type="bibr" target="#b22">[Huys et al., 2012]</ref>, how they decompose a task into a hierarchy of subtasks <ref type="bibr" target="#b23">[Huys et al., 2015]</ref>, and to develop planning algorithms that optimally trade off speed and accuracy <ref type="bibr" target="#b40">[Sezener et al., 2019]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Candidate tasks for aligning human and machine planning</head><p>Most cognitive science studies use tasks with single-digit state space complexity, and studies with more complex tasks are relatively rare. By contrast, AI researchers study games many orders of magnitude more complex. To connect these fields, we argue for tasks with an intermediate level of complexity. In particular, we propose a task that we have studied ourselves, namely four-in-a-row.</p><p>Even apart from the objective of aligning fields, cognitive scientists might have a good reason to study tasks of intermediate complexity: there likely is a categorical difference in algorithms people use for simple and complex tasks. When the number of states in a task exceeds 10-20, it becomes implausible that people are able to represent all states in working memory and exhaustively search the tree <ref type="bibr" target="#b32">[Miller, 1956]</ref>. Instead, working memory constraints may force people to use tree search algorithms with constant memory and computational time requirements, such as Monte Carlo Tree Search <ref type="bibr" target="#b24">[Kocsis and SzepesvÃ¡ri, 2006]</ref> or heuristic search <ref type="bibr" target="#b36">[Pearl, 1984]</ref>. This possibility should make such tasks interesting to cognitive science.</p><p>Four-in-a-row. To study human planning with exponentially large decision trees, we studied human decision-making and learning in two-player deterministic game. In this game, two players compete to create four-in-a-row on a 4-by-9 board ( <ref type="figure" target="#fig_1">Fig. 2A)</ref>. This game, part of the family of (m, n, k) games <ref type="bibr" target="#b2">[Beck, 2008]</ref> is considerably more complex than most cognitive science tasks, as it contains 1.1812 â€¢ 10 18 non-terminal states.</p><p>We were able to predict individual participants' choices on individual moves with a computational model that combines a feature-based heuristic for state evaluation, a best-first search algorithm for planning, and feature dropout as a mechanisms for lapses of attention <ref type="figure" target="#fig_1">(Fig. 2B)</ref>. Moreover, this model could generalize from predicting people's in-game decisions to predicting their choices on a two-alternative forced-choice task, board evaluations, response times and eye movements. Finally, by fitting the model parameters to data from participants in consecutive sessions, or when with limited allotted thinking time, we found large and robust effects of expertise and thinking time on people's policy, and in particular the estimated size of their mental decision trees <ref type="figure" target="#fig_1">(Fig. 2C-D)</ref>.</p><p>Mazes and grid worlds. Mazes and grid worlds are an important collection of tasks used to study human and machine planning. These tasks have been used to study human <ref type="bibr" target="#b43">[Simon and Daw, 2011]</ref> and animal reinforcement learning <ref type="bibr" target="#b36">[Pfeiffer and Foster, 2013]</ref>, or to develop and benchmark novel reinforcement learning algorithms <ref type="bibr" target="#b46">[Sutton and</ref><ref type="bibr">Barto, 1998, Mattar and</ref><ref type="bibr" target="#b31">Daw, 2018]</ref>. Planning has been studied in the motor domain using a space similar to a grid world <ref type="bibr" target="#b15">[Diamond et al., 2017]</ref>.</p><p>However, grid worlds are far from a representative sequential decision-making task, as the decision tree contains many transpositions (different action sequences leading to the same state) and cycles. Therefore, these tasks often have relatively low state space complexity and lend themselves uniquely to be solved by dynamic programming algorithms <ref type="bibr" target="#b46">[Sutton and Barto, 1998</ref>] that use memory proportional to the number of states. Since we focus on tasks for which forward planning at decision time is necessary to curtail the complexity, mazes and grid worlds may not be an ideal unifying task.</p><p>Atari games. Another recent proposal for a task to study deep neural networks and their relation to human intelligence are Atari games and in particular the game Frostbite <ref type="bibr" target="#b28">[Lake et al., 2017]</ref>. Deep Qlearning networks can learn these games <ref type="bibr" target="#b33">[Mnih et al., 2013]</ref> and outperform human players, but training them requires an exceedingly large amount of simulated games. One reason for this slow learning is that these networks are often initialized randomly, whereas people approach Atari games with strong inductive biases <ref type="bibr" target="#b17">[Dubey et al., 2018]</ref>. Although we are excited to see a convergence of cognitive and AI research on Atari games, as a paradigm to study forward planning they might prove too difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">What it means to align human and machine intelligence</head><p>Similarities and differences between human and machine intelligence have been much discussed <ref type="bibr" target="#b26">[Kriegeskorte, 2015</ref><ref type="bibr" target="#b20">, Hassabis et al., 2017</ref><ref type="bibr" target="#b30">, Marblestone et al., 2016</ref><ref type="bibr" target="#b28">, Lake et al., 2017</ref>. Here, we focus on what we believe to be necessary conditions for alignment between studies of human and machine planning in a given task, in particular what requirements an AI algorithm needs to satisfy to be a successful cognitive model. We believe that understanding human cognition requires a computational model which makes predictions for individual participants' choices on single trials, in multiple experimental conditions. A computational model may take the form of an explicit algorithm that people mentally execute, or a neural network. In either case, the model should include a description of how its policy changes after each experienced episode.</p><p>The main requirement for a computational model to be successful is that, when presented with the same stimuli that a participant experienced in a given condition in a task, its trajectory through policy space should match that participant's trajectory. This requirement encompasses several conditions that are difficult for AI algorithms to satisfy: 1. The model's trajectory should start from a policy that matches people's inductive biases in people's decision-making <ref type="bibr" target="#b28">[Lake et al., 2017</ref><ref type="bibr" target="#b17">, Dubey et al., 2018</ref><ref type="bibr" target="#b12">, Colunga and Smith, 2005</ref><ref type="bibr" target="#b18">, Feinman and Lake, 2018</ref>, and converge to one that matches people's behavior including their task performance.</p><p>2. The model should improve on the task at the same rate as human participants.</p><p>3. Finally, the model needs to satisfy these requirements for each individual participant in different experimental conditions, forcing it to match not just one trajectory but also capture individual differences in participant's trajectories.</p><p>One method to constrain individual variability is to construct models with a small number of parameters, which limits the set of policies the model can express to a low-dimensional manifold. This is the strategy employed by traditional computational cognitive science: the model is carefully chosen so that all participant's policies lie on its manifold, and policy trajectories can be translated to trajectories in a small space of parameters.</p><p>Another method would be to use infinitely expressible models such as deep neural networks, but include hyper-parameters in their dynamics or initial policy, to match different people's trajectories with minimal adjustments.</p><p>Although developing an AI algorithm that satisfies these conditions on even a single task will be challenging, doing so would enable a "cognitive psychology of artificial intelligence" <ref type="bibr" target="#b38">[Ritter et al., 2017]</ref>, in which researchers subject AI algorithms to new psychological experiments. For example, one can characterize changes in the AI's policy trajectory in response to manipulations of the input data or constraints on its use of memory or computational time. These changes can then be compared to the changes in humans doing the same experiments. We believe that this approach will deepen understanding of the correspondence between human and machine intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have argued that to align studies of artificial intelligence with studies of human intelligence, there needs to be a focus on finding tasks that are of interest to both fields. In doing so, both fields might have to compromise a little. Cognitive scientists might have to go out of their comfort zone in terms of experimental control and theoretical tractability: suitable tasks are likely orders of magnitude higher in complexity than common in cognitive science, and human behavior is likely far from optimal. AI researchers might have to settle for tasks that might not be the most challenging in terms of achieving high task performance but that offer more opportunities for systematic analysis of learned policies and linking those to human cognition. While chess might be too complex from both an experimental and modeling point of view, simpler tasks such as four-in-a-row might fit the bill. Once a suitable task has been chosen, we have laid out an agenda for using experimental manipulations in that task to reach a deeper understanding of the correspondence between human and machine intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>This work was supported by grants IIS-1344256 from the National Science Foundation and R01MH118925-01 from the National Institutes of Health.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Annotations</head><p>Two stars:</p><p>â€¢ <ref type="bibr" target="#b51">[van Opheusden et al., 2017]</ref>: This paper introduced a sequential decision task of a level of complexity that is unusually high for cognitive science (10 16 ), and showed that people's choices matched those of a best-first search algorithm with attentional oversights and pruning. We used this model to show that tree size decreased with time pressure and increased with expertise.</p><p>â€¢ <ref type="bibr" target="#b44">[Snider et al., 2015]</ref> By comparing human behavior with optimal models in a complex sequential decisionmaking task, the authors were able to identify people's planning strategies and in particular estimate their depth of computation. They found that people's behavior was consistent with a complete, bruteforce exploration of all possible paths in decision tree up to a resource-limited finite depth.</p><p>â€¢ <ref type="bibr" target="#b5">[Callaway et al., 2018]</ref> This paper employs a process tracing paradigm that forces participants to reveal which states they consider in a sequential decision-making task with an information-gathering component. Based on this data, they propose a resource-rational model for human planning, in which people make rational meta-decisions about which nodes in a decision tree to explore, and when to stop planning.</p><p>â€¢ <ref type="bibr" target="#b45">[Solway and Botvinick, 2015]</ref> This paper studies the dynamics of reward-based, goal-directed decisionmaking in a multi-step choice task, and find that human behavior can be understood in terms of evidence integration. Their model poses that people accrue noisy evidence for different trajectories through a decision tree, and make decisions when that evidence clearly favor one choice.</p><p>One star:</p><p>â€¢ <ref type="bibr" target="#b28">[Lake et al., 2017]</ref> This paper outlines challenges to building artificial systems that mimic human intelligence. They emphasize causal models of the world, learning from few examples, and rapid generalization.</p><p>â€¢ <ref type="bibr" target="#b38">[Ritter et al., 2017]</ref> This paper proposed an agenda of interrogating deep neural networks as if they are human subjects. Specifically, as humans learn, they exhibit inductive biases; for example, they prefer to categorize objects according to shape rather than color. The authors find that deep neural networks trained on ImageNet vary widely in their ability to reproduce this bias.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Decision trees in some tasks used to study human planning. Each node represents a task state. Solid arrows indicate transitions that are under the subject's control, dashed arrows transitions that are not.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Four-in-a-row. (A) Example board position. Black moves first, and the goal is to get four in a row. (B) Board position with overlaid in false color a map of the probabilities that a heuristic search model fitted to one individual's play predicts for that individual's next move. (C-D) The heuristic search model allows us to estimate the size of the tree built by human players as they learn across sessions (C) or have different time limits (D). Panels (B-D) adapted from<ref type="bibr" target="#b51">[van Opheusden et al., 2017]</ref>.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Traditionally, state space complexity refers to the number of all possible game states, we count only non-terminal states.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simple plans or sophisticated habits? state, transition and learning interactions in the two-step task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Akam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1004648</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Searching for solutions in games and artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allis</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>Rijksuniversiteit Limburg</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Combinatorial games: tic-tac-toe theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beck ; Beck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">114</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hierarchical reinforcement learning and decision making</title>
	</analytic>
	<monogr>
		<title level="j">Current opinion in neurobiology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="956" to="962" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The effects of speed on skilled chess performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="442" to="447" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A resource-rational analysis of human planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Callaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 40th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mouselab-mdp: A new paradigm for tracing how people plan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Callaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 3rd multidisciplinary conference on reinforcement learning and decision making</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deep blue. Artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Campbell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="57" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adaptive expert decision making: Skilled chess players search more and deeper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Campitelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gobet ; Campitelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visualization, pattern recognition, and forward search: Effects of playing speed and sight of the position on grandmaster chess errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hearst ;</forename><surname>Chabris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Chabris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="637" to="648" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Perception in chess</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="81" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An upper bound for the number of reachable positions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chinchalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICGA Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="183" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">From the lexicon to expectations about kinds: A role for associative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smith</forename><forename type="middle">;</forename><surname>Colunga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Colunga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">347</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Modelbased influences on humans&apos; choices and striatal prediction errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1204" to="1215" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1704</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rapid target foraging with reach or gaze: The hand looks further ahead than the eye</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Groot ; De Groot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noord-Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uitgev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maatschappij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Diamond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">1005504</biblScope>
			<date type="published" when="1946" />
		</imprint>
	</monogr>
	<note>Het Denken van den sckaken</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How does the brain solve visual object recognition?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Dicarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="415" to="434" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Dubey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.10217</idno>
		<title level="m">Investigating human priors for playing video games</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Feinman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lake ; Feinman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.02745</idno>
		<title level="m">Learning inductive biases with simple neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>GlÃ¤scher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="585" to="595" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neuroscienceinspired artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="258" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The psychology of chess skill. Lawrence Erlbaum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Holding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of the Psychonomic Society</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="421" to="424" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
	<note>Counting backward during chess move choice</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bonsai trees in your head: how the pavlovian system sculpts goal-directed choices by pruning decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1002410</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Interplay of approximate planning strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3098" to="3103" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bandit based monte-carlo planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kocsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>SzepesvÃ¡ri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on machine learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="282" to="293" />
		</imprint>
	</monogr>
	<note>Kocsis and SzepesvÃ¡ri</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">When does model-based control pay off?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1005090</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep neural networks: a new framework for modeling biological vision and brain information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kriegeskorte ; Kriegeskorte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of vision science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="417" to="446" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Krizhevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural computations underlying arbitration between model-based and model-free learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="687" to="699" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Deep learning. nature</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Toward an integration of deep learning and neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Marblestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in computational neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">94</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Prioritized memory access explains planning and hippocampal replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1609</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Mattar and Daw</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The magical number seven, plus or minus two: Some limits on our capacity for processing information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">81</biblScope>
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mnih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602</idno>
		<title level="m">Playing atari with deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The curse of planning: dissecting multiple reinforcement-learning systems by taxing the central executive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Otto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="751" to="761" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adaptive strategy selection in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Payne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">534</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Hippocampal place-cell sequences depict future paths to remembered goals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">497</biblScope>
			<biblScope unit="issue">7447</biblScope>
			<biblScope unit="page">74</biblScope>
			<date type="published" when="1984" />
			<publisher>Pfeiffer and Foster</publisher>
		</imprint>
	</monogr>
	<note>Heuristics: intelligent search strategies for computer problem solving</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Models of object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">11s</biblScope>
			<biblScope unit="page">1199</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Riesenhuber and Poggio</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cognitive psychology for deep neural networks: A shape bias case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ritter</surname></persName>
		</author>
		<ptr target="JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2940" to="2949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Representational efficiency outweighs action efficiency in human program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Sanborn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.07134</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optimizing the depth and the direction of prospective planning using information values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Sezener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="256" to="275" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
	<note>PLoS computational biology</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mastering chess and shogi by self-play with a general reinforcement learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Silver</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.01815</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neural correlates of forward planning in a spatial decision task in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="5526" to="5539" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Simon and Daw</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Prospective optimization with limited resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Snider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1004501</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evidence integration in model-based tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botvinick ;</forename><surname>Solway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">37</biblScope>
			<biblScope unit="page" from="11708" to="11713" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barto ;</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press Cambridge</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Temporal difference learning and td-gammon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tesauro ; Tesauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="58" to="68" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The number of legal go positions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tromp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computers and Games</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="183" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Computing machinery and intelligence. Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1950" />
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="433" to="460" />
		</imprint>
	</monogr>
	<note>Turing, 1950</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The effects of time pressure on chess skill: an investigation into fast and slow processes underlying expert performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Harreveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="591" to="597" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A computational model for decision tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Opheusden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 39th Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1254" to="1259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Mapping value based planning and extensively trained choice in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wunderlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">786</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dopamine enhances model-based over model-free choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wunderlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="418" to="424" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Using goal-driven deep learning models to understand sensory cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dicarlo ;</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">356</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
