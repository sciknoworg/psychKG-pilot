[
  {
    "topic_or_construct": [
      "Exploratory tendencies"
    ],
    "measured_by": [
      "proportion of trials switching between options in the four-armed bandit task"
    ],
    "justification": "\u201cThe primary planned behavioral analyses were to examine \u2026 (2) the proportion of trials that participants switched between different options as an indicator of exploratory tendencies.\u201d"
  },
  {
    "topic_or_construct": [
      "Exploitation tendency"
    ],
    "measured_by": [
      "proportion of highest-value option choices in the four-armed bandit task"
    ],
    "justification": "The authors state that they examined \u201c(1) the proportion of the highest-value option choices over the course of the experiment as an indicator of exploitation.\u201d"
  },
  {
    "topic_or_construct": [
      "Memory for reward values"
    ],
    "measured_by": [
      "follow-up memory test recalling how many candies each option gave"
    ],
    "justification": "\u201cFollowing the main experiment, a subset \u2026 completed a follow-up memory test. The experimenter pointed to each of the four locations in turn and asked the child how many candies they would get if they chose that option.\u201d"
  },
  {
    "topic_or_construct": [
      "Systematic exploration"
    ],
    "measured_by": [
      "f parameter (lag weight) in the reinforcement-learning model"
    ],
    "justification": "\u201cTwo free parameters,  f  and  \u03b2, determine the levels of exploitation, systematic exploration, and random exploration. Specifically,  f \u2026 mediated the relative weights of expected value and lag \u2026 Higher values of  f  indicate greater influence of the lag, and hence more systematic exploration.\u201d"
  },
  {
    "topic_or_construct": [
      "Random exploration"
    ],
    "measured_by": [
      "\u03b2 inverse-temperature parameter in the reinforcement-learning model"
    ],
    "justification": "\u201c\u03b2 was the inverse temperature parameter that controlled the extent that choices were deterministic or stochastic \u2026 Lower values of \u03b2 capture more \u2018random\u2019 choices (i.e., random exploration).\u201d"
  }
]