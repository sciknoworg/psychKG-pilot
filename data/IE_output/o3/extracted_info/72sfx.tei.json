[
  {
    "measured_by": "proportion of trials switching between options in the four-armed bandit task",
    "justification": "“The primary planned behavioral analyses were to examine … (2) the proportion of trials that participants switched between different options as an indicator of exploratory tendencies.”",
    "construct": "Exploratory tendencies"
  },
  {
    "measured_by": "proportion of highest-value option choices in the four-armed bandit task",
    "justification": "The authors state that they examined “(1) the proportion of the highest-value option choices over the course of the experiment as an indicator of exploitation.”",
    "construct": "Exploitation tendency"
  },
  {
    "measured_by": "follow-up memory test recalling how many candies each option gave",
    "justification": "“Following the main experiment, a subset … completed a follow-up memory test. The experimenter pointed to each of the four locations in turn and asked the child how many candies they would get if they chose that option.”",
    "construct": "Memory for reward values"
  },
  {
    "measured_by": "f parameter (lag weight) in the reinforcement-learning model",
    "justification": "“Two free parameters,  f  and  β, determine the levels of exploitation, systematic exploration, and random exploration. Specifically,  f … mediated the relative weights of expected value and lag … Higher values of  f  indicate greater influence of the lag, and hence more systematic exploration.”",
    "construct": "Systematic exploration"
  },
  {
    "measured_by": "β inverse-temperature parameter in the reinforcement-learning model",
    "justification": "“β was the inverse temperature parameter that controlled the extent that choices were deterministic or stochastic … Lower values of β capture more ‘random’ choices (i.e., random exploration).”",
    "construct": "Random exploration"
  }
]