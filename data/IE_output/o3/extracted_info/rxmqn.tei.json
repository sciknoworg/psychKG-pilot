[
  {
    "measured_by": "probability of choosing the low-mean option (p(low mean)) in the equal [2-2] condition of the Horizon Task",
    "justification": "“Random exploration is quantified as the probability of choosing the option that has the lower average payout in the forced-choice plays in the equal, or [2 2], condition, p(low mean).”",
    "construct": "Random exploration"
  },
  {
    "measured_by": "probability of choosing the high-information option (p(high info)) in the unequal [1-3] condition of the Horizon Task",
    "justification": "“Directed exploration is quantified as the probability of choosing the more informative option p(high info) in the unequal, or [1 3], condition.”",
    "construct": "Directed exploration"
  },
  {
    "measured_by": "decision noise parameter σ in the logistic choice model",
    "justification": "“Model-based measure of behavioral variability, decision noise σ, increases with horizon.”",
    "construct": "Behavioral variability (random exploration)"
  },
  {
    "measured_by": "information bonus parameter A in the logistic choice model",
    "justification": "“The free parameters of this model are: the information bonus A, which controls the level of directed exploration.”",
    "construct": "Directed exploration"
  },
  {
    "measured_by": "standard deviation σ_det estimated in the modified logistic choice model",
    "justification": "“n_det denotes the deterministic noise … n_det and n_ran are assumed to come from logistic distributions with mean 0, and standard deviations σ_det and σ_ran.”",
    "construct": "Deterministic noise"
  },
  {
    "measured_by": "standard deviation σ_ran estimated in the modified logistic choice model",
    "justification": "“n_ran denotes random noise … n_det and n_ran are assumed to come from logistic distributions with mean 0, and standard deviations σ_det and σ_ran.”",
    "construct": "Random noise"
  }
]