[
  {
    "measured_by": "four-armed “Time Bandit” task (repeated bandit rounds)",
    "justification": "“We use multiple four-armed bandit tasks, where across four payoff conditions … This allows us to dissociate value-directed and uncertainty-directed choices.”",
    "construct": "human exploration behavior"
  },
  {
    "measured_by": "Shannon entropy of choice distributions",
    "justification": "“We assessed the overall diversity of choices by calculating the Shannon entropy of choice distributions in each round … This provides initial evidence for reduced exploration under time pressure.”",
    "construct": "overall exploration diversity"
  },
  {
    "measured_by": "number of repeat choices in a round",
    "justification": "“Additionally, we modeled the number of repeat choices in each round as a measure of sequential dependency between choices.”",
    "construct": "choice perseveration (stickiness)"
  },
  {
    "measured_by": "α parameter of the hierarchical softmax choice model",
    "justification": "“Larger α estimates indicate more value-directed choices, whereas lower α suggest more random choices, which are not explainable by reward expectations or uncertainty estimates.”",
    "construct": "value-directedness vs. random exploration"
  },
  {
    "measured_by": "β (uncertainty bonus) parameter of the hierarchical softmax model",
    "justification": "“More positive β estimates indicate a higher level of uncertainty-directed exploration.”",
    "construct": "uncertainty-directed exploration"
  },
  {
    "measured_by": "γ (stickiness bonus) parameter in softmax model",
    "justification": "“Higher estimates of γ indicate more perseveration in choice behavior, with more frequent repetitions of previous choices.”",
    "construct": "choice stickiness (perseveration tendency)"
  }
]