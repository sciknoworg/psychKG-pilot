[
  {
    "measured_by": "Affectiva face-recognition software (iMotions)",
    "justification": "“Videos of the faces of both participants can then be analysed with specialized tools such as Affectiva, a face recognition software from iMotions … to automate recognition of specific facial expressions.”",
    "construct": "facial expressions"
  },
  {
    "measured_by": "Hume AI automatic vocal classification",
    "justification": "“Software, such as Hume AI … can automatically identify and classify non-verbal utterances that appear in recordings of longer duration into 24 distinct emotional dimensions.”",
    "construct": "non-linguistic vocalizations / emotional vocalisations"
  },
  {
    "measured_by": "OpenAI Whisper speech-transcription system",
    "justification": "“Recent advances in AI, e.g., OpenAI Whisper, can be incorporated to automate speech transcription, allowing researchers to time lock speech to the temporal properties of stimulus presentation and response timing.”",
    "construct": "linguistic vocalizations / speech content"
  },
  {
    "measured_by": "head-mounted eyetrackers (e.g., Pupil Labs Core / Tobii glasses)",
    "justification": "“Modern binocular head-mounted eyetrackers allow researchers to collect participants' gaze behaviour in the real world … enable the tracking of gaze to the social partner's hand movements towards the screen.”",
    "construct": "gaze behaviour / visual attention"
  },
  {
    "measured_by": "image-based photoplethysmography (iPPG)",
    "justification": "“Image-based photoplethysmography (iPPG) … allowing the extraction of pulse information from videos of a subject’s face.”",
    "construct": "physiological arousal / heart rate"
  }
]