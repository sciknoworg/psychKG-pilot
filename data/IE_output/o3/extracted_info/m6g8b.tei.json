[
  {
    "measured_by": "Brier score",
    "justification": "“For the scorable forecasts, Brier scores were calculated… The Brier score, B, is a proper scoring rule equal to the squared deviation between probabilities assigned to forecasts and outcomes.”",
    "construct": "forecasting accuracy"
  },
  {
    "measured_by": "correct classification rate",
    "justification": "“To use a perhaps more intuitive scoring rule, the correct classification rate was 94%.”",
    "construct": "forecasting accuracy"
  },
  {
    "measured_by": "normalized discrimination index",
    "justification": "“Using another standard metric, the normalized discrimination index (Yaniv et al., 1991), which computes discrimination over uncertainty… was found that 76% of outcome variance was explained by the forecasts.”",
    "construct": "discrimination skill"
  },
  {
    "measured_by": "area under the receiver-operator characteristic curve (AUC)",
    "justification": "“Discrimination in both groups was very good. For instance, the slight difference in area under the receiver-operator characteristic curve (0.96 for MEA forecasts and 0.93 for non-MEA forecasts)….”",
    "construct": "forecast discrimination"
  }
]