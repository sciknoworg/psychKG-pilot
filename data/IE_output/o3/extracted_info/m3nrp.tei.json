[
  {
    "measured_by": "Three-item slider scale (e.g., “SigmaEvalu8 discriminated against women”, “treated people differently according to their gender”, “treated men and women differently”)",
    "justification": "“Assessing perceived discrimination. We assessed perceived discrimination with three items: ‘SigmaEvalu8 (The HR specialist) discriminated against women’, ‘…treated people differently according to their gender’ and ‘…treated men and women differently’.”",
    "construct": "Perceived discrimination"
  },
  {
    "measured_by": "Three-item scale about being data-driven, relying on facts, and being unaffected by personal opinions",
    "justification": "“Assessing perceptions of objectivity. We assessed perceptions of objectivity with three items: ‘SigmaEvalu8 is data-driven’, ‘…relies on facts’, and ‘…is unaffected by personal opinions’.”",
    "construct": "Perceptions of objectivity"
  },
  {
    "measured_by": "Four-item scale (e.g., “SigmaEvalu8 is sexist”, “does not want to hire women”, “dislikes women”, “is prejudiced”)",
    "justification": "“Assessing perceived prejudiced motivation… with four items: ‘SigmaEvalu8 is sexist’, ‘…does not want to hire women for high-skilled jobs’, ‘…dislikes women’, and ‘…is prejudiced’.”",
    "construct": "Perceived prejudiced motivation"
  },
  {
    "measured_by": "Three-item slider scale rating anger, outrage and disgust toward the discriminatory actions",
    "justification": "“Measuring Moral Outrage… items: ‘I am angry at the HR specialist’s/the algorithm’s discriminatory actions’, ‘I am outraged…’, and ‘I am disgusted…’, averaged into a moral outrage index.”",
    "construct": "Moral outrage at discriminatory actions"
  },
  {
    "measured_by": "Single item: “The HR specialist/the algorithm intended not to hire women”",
    "justification": "“We then measured perceived intentionality by asking participants to rate their agreement with the following item: ‘The HR specialist/the algorithm intended not to hire women’.”",
    "construct": "Perceived intentionality"
  },
  {
    "measured_by": "Three-item scale (e.g., appropriateness, should screen resumes, should be forbidden—reverse)",
    "justification": "“Permissibility… measured with three items such as ‘It is appropriate for SigmaEvalu8 to screen resumes’, ‘SigmaEvalu8 should be the one to screen resumes’ and ‘SigmaEvalu8 should be forbidden from screening resumes’ (reverse scored).”",
    "construct": "Permissibility of agent screening resumes"
  },
  {
    "measured_by": "Three-item scale: anger, outrage, disgust toward AeonTech’s hiring practices",
    "justification": "“We measured participants’ initial moral outrage at the company by asking them to rate agreement with three items: ‘I am angry at AeonTech’s hiring practices’, ‘I am outraged by AeonTech’s hiring practices’ and ‘I am disgusted by AeonTech’s hiring practices’.”",
    "construct": "Moral outrage at company hiring practices"
  },
  {
    "measured_by": "Four-item scale adapted from Newman et al. (e.g., “The way AeonTech decides who to hire seems fair”)",
    "justification": "“Fairness. We then measured how fair participants thought the company’s hiring process was, by asking agreement with four items adapted from Newman et al., such as ‘The way AeonTech decides who to hire seems fair’.”",
    "construct": "Perceived fairness of hiring process"
  },
  {
    "measured_by": "Single self-report item comparing respondent’s AI knowledge to the average Norwegian (1=much less – 7=much more)",
    "justification": "“Knowledge about AI. We then asked participants ‘compared to the average Norwegian, how knowledgeable are you about AI’ (1 = much less knowledgeable; 7 = much more knowledgeable).”",
    "construct": "Knowledge about AI"
  },
  {
    "measured_by": "Five-item scale including acceptability, moral outrage, justice, morality and wrongness ratings of discriminatory actions",
    "justification": "“To assess moral outrage we used five items… ‘Which of the following best expresses your opinion of the discriminatory actions…’, plus ‘I am morally outraged…’, ‘actions are unjust’, ‘actions were immoral’ and ‘actions were wrong’.”",
    "construct": "Moral outrage (five-item version)"
  },
  {
    "measured_by": "Two-item scale asking how worried and how concerned participants were about such discrimination",
    "justification": "“We asked participants how worried and how concerned they would be about such discrimination (inter-item correlation: r = .61).”",
    "construct": "Concern about discrimination"
  },
  {
    "measured_by": "Three-item slider scale (e.g., support for verdict of discriminatory intent, liability because of intentional prejudice, reverse-scored ‘no evidence of intentional discrimination’)",
    "justification": "“Assessing liability… participants rated agreement with: ‘I would support a verdict that said the company had discriminatory intent’, ‘The company is liable because it acted out of intentional prejudice’ and ‘The company is not liable, because there is no evidence of intentional discrimination’.”",
    "construct": "Perceived company liability for intentional discrimination"
  },
  {
    "measured_by": "Three positive items: deserves praise, should be rewarded, happy with hiring decisions",
    "justification": "“We then measured participants’ positive evaluations… with statements like ‘AeonTech deserves praise for its hiring decisions’, ‘…should be rewarded’ and ‘I am happy with AeonTech’s hiring decisions’.”",
    "construct": "Positive evaluation of company hiring decisions"
  },
  {
    "measured_by": "Three negative items: deserves blame, should be punished, angry with hiring decisions",
    "justification": "“Negative evaluation was assessed with three items: ‘AeonTech deserves blame’, ‘AeonTech should be punished’, and ‘I am angry at AeonTech’s hiring decisions’.”",
    "construct": "Negative evaluation of company hiring decisions"
  }
]