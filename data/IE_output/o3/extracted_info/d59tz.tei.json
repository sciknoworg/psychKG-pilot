[
  {
    "measured_by": "Q-learning model estimates from Learning (LE) phase choices / prediction-error–minimizing reinforcement learning model",
    "justification": "“Concerning the LE phase, we leveraged on a classical associative learning approach… We were able to infer p(win) attributed to each E-option… by fitting this, rather parsimonious and standard, model.”",
    "construct": "experiential option value / subjective probability of winning"
  },
  {
    "measured_by": "indifference points derived from logistic choice curves in the Experiential–Symbolic (ES) phase",
    "justification": "“Concerning the ES phase, subjective p(win) estimates were inferred… we fitted those logistic functions… and used them to extrapolate the indifference points indexing E-options’ subjective p(win).”",
    "construct": "experiential option value / subjective probability of winning"
  },
  {
    "measured_by": "Stated Probability (SP) rating scale based on a probability-matching procedure",
    "justification": "“Finally, we assessed the stated probability (SP) of winning for each symbol by asking participants to explicitly rate each E-option, following a probability matching procedure.”",
    "construct": "experiential option value / subjective probability of winning"
  },
  {
    "measured_by": "choices between known lotteries and fully ambiguous grey pie-chart lotteries in Experiential-Ambiguous (EA) and Symbolic-Ambiguous (SA) phases",
    "justification": "“In a final experiment we included choices with ambiguous lotteries… The results… indicate that ambiguity aversion was not detectable in our set up,” showing that attitudes toward ambiguity were evaluated through these choice trials.",
    "construct": "ambiguity aversion"
  }
]