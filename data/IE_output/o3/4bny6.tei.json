[
  {
    "topic_or_construct": [
      "Absolute value learning"
    ],
    "measured_by": [
      "novel-pair testing trials in the multi-day reward learning task"
    ],
    "justification": "\u201cCritically, the multi-session design allowed us to assess the formation of absolute values by asking subjects to choose between images that were never directly paired together during learning.\u201d"
  },
  {
    "topic_or_construct": [
      "Relative preference learning"
    ],
    "measured_by": [
      "rank bias in choices between similarly rewarded images"
    ],
    "justification": "\u201cExamining subjects' choices between similarly rewarded images from low-concurrent-diversity conditions showed that subjects indeed preferred images that ranked higher during learning.\u201d"
  },
  {
    "topic_or_construct": [
      "Generalization of learned preferences"
    ],
    "measured_by": [
      "accuracy drop between learnt-pair and novel-pair testing trials"
    ],
    "justification": "\u201cWe compared subjects' accuracy on these trials to accuracy in choosing between images that subjects had encountered during learning ('learnt-pair' testing trials)\u2026 this result shows that subjects generalized their preferences well, but did not do so perfectly.\u201d"
  },
  {
    "topic_or_construct": [
      "Influence of other options' outcomes on choice"
    ],
    "measured_by": [
      "Bayesian logistic mixed model coefficients for \u2018other images\u2019 reward history"
    ],
    "justification": "\u201cTo control for this confound, we used a Bayesian logistic mixed model that predicted subjects' choices \u2026 and the reward history from trials in which the currently available images were rejected in favor of any other image. Importantly, only the latter regressor unequivocally captures the effect of other images' outcomes.\u201d"
  }
]