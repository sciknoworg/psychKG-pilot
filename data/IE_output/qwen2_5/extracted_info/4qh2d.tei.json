[
  {
    "topic_or_construct": "outcome reference point-dependence",
    "measured_by": "REFERENCE model",
    "justification": "The REFERENCE model captures the way outcomes are encoded as a function of a reference point, successfully explaining symmetrical gain-loss performance in the learning phase and suboptimal preference patterns in the transfer phase of human reinforcement learning."
  },
  {
    "topic_or_construct": "outcome range-adaptation",
    "measured_by": "RANGE model",
    "justification": "The RANGE model incorporates context-level variables related to the range of possible outcomes, effectively explaining the patterns of accuracy and choice-elicited preferences in learning contexts with different outcome ranges."
  },
  {
    "topic_or_construct": "dependence of irrelevant alternatives",
    "measured_by": "IA--js",
    "justification": "The study on dependence of irrelevant alternatives in reinforcement learning demonstrates that contextual effects induced by the choice set also lead to classic violations of the independence of irrelevant alternatives axiom (IIA) in reinforcement learning scenarios."
  }
]