[
  {
    "topic_or_construct": "Speed-accuracy trade-off",
    "measured_by": "Response time (RT)",
    "justification": "The paper discusses the speed-accuracy trade-off as a key construct in decision-making and uses response times (RTs) to measure its effects. For instance, it states that 'Acting faster can yield greater time-averaged reward under some task conditions (short ITIs or set sizes), but necessitates a commitment to greater errors through lower policy complexity.' This indicates that RT is used as an instrument to assess the speed dimension of the speed-accuracy trade-off."
  },
  {
    "topic_or_construct": "Policy complexity",
    "measured_by": "Mutual information between states and actions",
    "justification": "Policy complexity is a central construct in the paper and is measured using mutual information. The text specifies, 'We defined policy complexity as the mutual information between the observed states and chosen actions. Following prior work, we estimated the policy complexity of each participant in each ITI condition using the Hutter estimator, which computes the posterior mean value of mutual information under a symmetric Dirichlet prior.' This indicates that mutual information serves as a measurement instrument for policy complexity."
  },
  {
    "topic_or_construct": "Perseveration",
    "measured_by": "Probability of repeating the same action",
    "justification": "Perseveration is a construct examined in the context of how humans adhere to patterns of previous actions. The paper measures it by assessing the probability of repeating the same action across trials. For example, 'Since higher policy complexity dictates a more deterministic mapping from states to actions, we predict 3) decreased action stochasticity (the conditional entropy of actions conditioned on state, H(A|S)) with longer ITIs. As detailed in the Introduction, the optimal policy is proportional to the exponentiated action values, weighted by an inverse temperature parameter \u03b2, and the marginal action distribution. At higher policy complexity, \u03b2 increases, which decreases the influence of the marginal action distribution P (a) on the policy.' This indicates that the model specifically focuses on the probability of action repetition as a means to measure perseveration."
  },
  {
    "topic_or_construct": "Time-averaged reward",
    "measured_by": "Trial-averaged reward",
    "justification": "Time-averaged reward, an important construct for evaluating the performance of decisions made under various conditions, is measured through the trial-averaged reward. As per the analysis in the text, 'To see how the theory predicts a speed-accuracy trade-off, we can visualize the relationship between time-averaged reward and policy complexity in Figure 1F, where we varied the ITI. To maximize time-averaged reward, humans should decrease policy complexity when ITIs are short; although these policies result in less trial-averaged reward, they increase time-averaged reward because they allow agents to perform more actions due to smaller decoding time cost.' This indicates that the trial-averaged reward is used as an instrument to evaluate time-averaged reward."
  }
]