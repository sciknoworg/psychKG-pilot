[
  {
    "topic_or_construct": "conceptual knowledge",
    "measured_by": "category and feature norms data",
    "justification": "The paper fine-tuned BERT on sentences generated from existing datasets of subject-generated category and feature norms. The model was trained to predict the truth or falsity of concept-feature pairs generated from these norms, indicating its use as a measure of conceptual knowledge."
  },
  {
    "topic_or_construct": "semantic verification",
    "measured_by": "sentence truth prediction by BERT",
    "justification": "The authors evaluated BERT's ability to make accurate predictions of truth or falsehood judgments for simple natural language propositions involving common concepts and features, demonstrating its application to semantic verification tasks."
  },
  {
    "topic_or_construct": "typicality ratings",
    "measured_by": "BERT model's activation probabilities",
    "justification": "The paper compared the full BERT model's predictions with human typicality ratings for exemplars in various categories, showing positive correlations and replicating patterns of typicality in conceptual knowledge."
  },
  {
    "topic_or_construct": "feature distribution across concepts",
    "measured_by": "BERT's binarized predictions",
    "justification": "BERT's binarized predictions were used to calculate measures of feature overlap, replicating Rosch & Mervis's (1975) findings on the relationship between typicality and feature overlap."
  },
  {
    "topic_or_construct": "asymmetric similarity",
    "measured_by": "BERT's predicted correlations for word pairs",
    "justification": "The authors tested BERT's ability to capture observed asymmetries in similarity judgment using data from Whitten et al. (1979), showing positive correlations between BERT's predictions and asymmetric similarity effects."
  }
]