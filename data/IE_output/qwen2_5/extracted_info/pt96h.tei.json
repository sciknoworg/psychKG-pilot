[
  {
    "topic_or_construct": "human-bot trust",
    "measured_by": "proportion of times a participant decided to adopt or rely on the bot's recommendation",
    "justification": "The preliminary measure of trust was based on the percentage of times participants chose to adopt the bot's recommendation, indicating how much they trusted the bot. However, it's acknowledged that this is a coarse measure since participants might not genuinely trust the bot but lack a reason to distrust it."
  },
  {
    "topic_or_construct": "human-bot trust",
    "measured_by": "Judge Advisor System (JAS) variants",
    "justification": "The paper adopted variations of the Judge Advisor System (JAS) to obtain a continuous and more precise measure of trust, calculating the degree to which participant judgments were adjusted toward the recommended values."
  },
  {
    "topic_or_construct": "trust dynamics",
    "measured_by": "binary choices (broken/not broken classification) with an additional 'don't know' option",
    "justification": "In Experiment 1, trust was measured through participants' decisions to classify items as 'broken' or 'not broken,' with the option to choose 'don't know' added for a more nuanced measure of their trusting behavior toward bot recommendations."
  },
  {
    "topic_or_construct": "advice taking",
    "measured_by": "weight of advice (WoA) in JAS",
    "justification": "The paper explored how participants integrated advice from a recommendation into their judgment using the JAS framework, with the weight of advice representing the degree to which the second response incorporated recommendations."
  },
  {
    "topic_or_construct": "humantrust",
    "measured_by": "distribution of response types (stay, shift, adopt, overshoot, distrust) in JAS",
    "justification": "In Experiments 2 and 3, responses were categorized into types such as 'stay,' 'shift,' 'adopt,' etc., providing insights into how participants integrated or rejected recommendations, reflecting their trust dynamics."
  }
]