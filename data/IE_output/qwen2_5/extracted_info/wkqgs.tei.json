[
  {
    "topic_or_construct": "Wisdom of the Crowd (WoC)",
    "measured_by": "Simple Voting, Confidence Weighted Voting, and Confidence Slated Voting algorithms",
    "justification": "The study used various WoC algorithms including Simple Voting, Confidence Weighted Voting, and Confidence Slated Voting to aggregate decisions from multiple individuals. These algorithms were applied to expert and novice participants' responses to demonstrate the improvement in diagnostic accuracy when multiple judgments are combined, especially when confidence judgments were factored in."
  },
  {
    "topic_or_construct": "Wisdom of the Inner Crowd (WoIC)",
    "measured_by": "Maximum Confidence Slating Algorithm",
    "justification": "The researchers employed the Maximum Confidence Slating Algorithm to aggregate repeated decisions from the same individual. By using more confident classifications as final decisions, this approach showed improvements in diagnostic accuracy for both novice and expert participants, highlighting the effectiveness of WoIC in medical image decision-making."
  },
  {
    "topic_or_construct": "Metacognitive Abilities",
    "measured_by": "Self-Reported Confidence Judgments",
    "justification": "Participants provided self-reported confidence ratings on a scale of 50-100, with 50 indicating a guess and 100 indicating certainty. These confidence judgments were used to weigh decisions and demonstrate the relationship between confidence and accuracy across various algorithms, emphasizing the role of metacognition in improving decision-making."
  },
  {
    "topic_or_construct": "Intra-rater Disagreement",
    "measured_by": "Calculation of Response Differences for Same Stimuli",
    "justification": "The study measured intra-rater disagreement by calculating the rate at which a single individual's responses varied when presented with the same image in different blocks or conditions. This measure provided insight into the consistency of individual judgments and the potential for improvement through WoIC methods."
  },
  {
    "topic_or_construct": "Inter-rater Disagreement",
    "measured_by": "Calculation of Response Differences Between Different Individuals",
    "justification": "Inter-rater disagreement was assessed by comparing responses from different participants on the same images. Higher inter-rater disagreement suggested that combining judgments from multiple individuals could potentially lead to greater accuracy than relying on a single decision maker."
  }
]