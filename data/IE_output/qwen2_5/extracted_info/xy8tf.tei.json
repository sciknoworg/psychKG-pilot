[
  {
    "topic_or_construct": "Calibrated trust in AI systems",
    "measured_by": "Confidence reports and metacognitive sensitivity",
    "justification": "The article argues that AI should report its confidence and metacognitive sensitivity (correspondence between confidence and accuracy) to calibrate human trust, based on insights from human metacognition and perceptual decision-making (Fleming & Lau, 2014; Maniscalco et al., 2016)."
  },
  {
    "topic_or_construct": "Metacognitive sensitivity in humans and AI",
    "measured_by": "Meta-d' and M-ratio",
    "justification": "Metacognitive sensitivity is measured using meta-d', which evaluates how effectively confidence ratings distinguish between correct and incorrect responses. The M-ratio adjusts meta-d' for task performance level, providing an interpretable metric for users evaluating AI trustworthiness (Fleming & Lau, 2014; Maniscalco & Lau, 2012)."
  },
  {
    "topic_or_construct": "Optimal joint human-AI decision-making",
    "measured_by": "Weighted confidence sharing model",
    "justification": "Research by Bahrami et al. (2010) showed that, in joint decision-making tasks, communicating confidence judgments (weighted confidence sharing model) was key for collective benefits, suggesting that reporting metacognitive sensitivity can aid in optimal decisions between humans and AI."
  },
  {
    "topic_or_construct": "Metacognition in LLMs",
    "measured_by": "Confidence judgments and retrospective metacognitive accuracy",
    "justification": "Studies indicate that LLMs show comparable metacognitive sensitivity to humans in certain tasks but lower sensitivity in retrospective judgments. This ability depends on the type of judgment and calibration with task experience, highlighting the importance of these measures for LLMs in human-AI collaboration (Cash et al., 2024; Zhou et al., 2024)."
  }
]