You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Moral hypocrisy is commonly reviled. Philosophers and psychologists have identified multiple forms of hypocrisy 
(Alicke et al., 2013;
Effron et al., 2018;
Graham et al., 2015;
Monin & Merritt, 2012)
. One form of hypocrisy involves double standards or discrepancies between judgments of oneself and others, such as claiming that certain actions are forbidden for others but permissible for oneself 
(Graham et al., 2015;
Valdesolo & DeSteno, 2007)
. Another involves discrepancies between moral judgments and behaviors, such as "saying one thing and doing another" 
(Dover, 2019;
Howe & Monin, 2017;
Laurent & Clark, 2019)
. A paradigmatic example of the latter is hypocritical blame, where someone blames others for transgressions that they themselves previously committed 
(Tognazzini & Coates, 2018)
. Consider politicians who have extramarital affairs while condemning adultery in others or environmental activists who jet-set to exotic destinations but vociferously shame others for flying.
Philosophers argue that hypocritical blame is morally wrong because hypocrites do not really care about the moral standards that they express and apply to others, and therefore do not feel any conflict or guilt when their own behaviors fall short of these moral standards 
(Kittay, 1982;
Szabados & Soifer, 1999)
. On this view, hypocrites condemn others' moral failures as a trick to convince observers (or even themselves) that they do care about moral standards, while their transgressive behavior implies a lack of commitment to those same standards 
(Fritz & Miller, 2018;
Todd, 2019;
Wallace, 2010)
.
Similarly, psychological research demonstrates that laypeople judge hypocrisy to be morally wrong, partly because they see hypocrites as falsely signaling a commitment to moral standards that they do not actually possess 
(Effron et al., 2018;
Jordan et al., 2017;
Laurent & Clark, 2019)
.
Vignette studies show that a mere discrepancy between moral judgment and behavior is sufficient to produce perceptions of hypocrisy. Importantly, perceptions of hypocrisy generate other inferences about moral character: hypocrites are perceived as dislikable, immoral and untrustworthy 
(Barden et al., 2005;
Jordan et al., 2017;
O'Connor et al., 2020)
.
While much is known about the psychology of perceiving hypocrisy in others, less is known about the psychology underlying hypocritical blame itself. Central to many philosophical and psychological accounts as well as common folk intuitions of hypocrisy is the assumption that hypocrites do not think of themselves as blameworthy for violating the standards that they blame others for violating, and so do not feel any conflict or guilt when they act hypocritically 
(Tognazzini & Coates, 2018)
. How accurate are such assumptions? That is, are discrepancies between moral judgments of others and moral behavior by oneself necessarily attributable to a lack of caring about moral standards for oneself? No previous studies have empirically examined this critical assumption. Here we investigate the possibility that at least some people who engage in hypocritical blame do feel that the moral standards they apply to others are also binding for themselves. Some hypocritical blame might arise from weakness of will if people succumb to temptation when they choose to perform actions that they later condemn in others, even though they really do believe that both their own and others' acts are morally wrong.
One challenge in studying moral hypocrisy is the ample disagreement over what "counts" as hypocrisy -even philosophers lack consensus over a definition 
(Fritz & Miller, 2018;
Kittay, 1982;
Szabados & Soifer, 2004;
Wallace, 2010)
. To sidestep this problem, we measured folk intuitions about hypocrisy. We operationalized hypocritical blame as blaming others for making the same decisions oneself has made previously, and then verified that such a discrepancy between blame judgments and behavior meets participants' own definition of hypocrisy. By grounding our study of moral hypocrisy in folk intuitions, we do not need to commit to a single normative account of hypocrisy, of which there are many. Instead, we simply investigate the neurocognitive processes of people who appear hypocritical to most observers.
A second challenge in determining whether people who blame hypocritically actually care about moral standards is that such concerns are easy to fake 
(Batson et al., 1997
(Batson et al., , 1999
(Batson et al., , 2002
Batson & Thompson, 2001;
FeldmanHall et al., 2012)
. Therefore, behavioral and self-reported measures alone are not adequate for probing the underlying moral beliefs and concerns. To address this challenge, we triangulate across self-reports, behavior, and brain activity to obtain convergent evidence. Our methods can reveal relations between hypocritical blame and neural representations of moral standards and guilt for violating those moral standards. These neural representations should be more difficult-if not impossible-to fake.
Past work has demonstrated the engagement of the dorsolateral prefrontal regions in representing social and moral norms (e.g., fairness), and more specifically, activity patterns in these regions suggest that they may represent moral standards distinctively from material values 
(Buckholtz & Marois, 2012;
Carlson & Crockett, 2018;
Crockett et al., 2017;
Zoh et al., 2022)
. We therefore predicted that this region would be responsible for the representation of moral rules and standards.
When people violate moral standards that they care about, they experience feelings of conflict and guilt 
(Baumeister et al., 1994;
Green et al., 2012;
Lythe et al., 2015;
Tangney et al., 2007;
Yu et al., 2014;
Zahn et al., 2009)
. Here we tested the hypothesis that some blamers do find the moral standards that they apply to others also binding for themselves. If this hypothesis is correct, then these blamers would show strong neural responses to moral standards and guilt when they make the same decisions that they later blame others for making 
(Bartel, 2019;
Mele, 1989;
O'Connor et al., 2020)
.


Method
Open Practices Statement. The study materials, behavioral data, and analysis codes are publicly accessible at https://osf.io/ardcu. The studies were not formally pre-registered.
Overview of research. We tested our predictions in a paradigm that allowed us to quantify hypocritical blame in terms of a discrepancy between moral behavior and moral blame judgments of the same behavior in others. In Study 1 (behavioral; N = 188), we described this paradigm to a separate group of participants and verified that our operationalization of hypocritical blame was indeed perceived as hypocritical by our participants. In Study 2, participants (N = 62) completed a moral decision task in the fMRI scanner 
(Crockett et al., 2017)
, where they decided whether to seek profit by inflicting pain on either themselves or an anonymous receiver ( 
Fig. 1 left panel)
. At least one week after scanning, participants returned to the lab and completed a moral blame task, where we presented them with the same set of trials that they had previously seen in the moral decision task 
(Fig. 1 right panel)
. On each trial, we highlighted the more harmful option (inflicting pain on the receiver for profit) and asked them to judge how blameworthy it would be for others to choose that option. We calculated, for each participant, a 'hypocritical blame' index that quantified discrepancies between their current blame judgments and the choices they made a week earlier. 
Figure 1
. Procedure of the moral decision task and the moral judgment task. (Left panel) In the moral decision task, participants chose between a harmful option and a helpful option. The harmful option contained more money and more electric shocks. On half of the trials the shocks were for the decider (Self condition) while on the other half of the trials the shocks were for the receiver (Other condition). Participants were instructed that one of their choices would be randomly selected and implemented at the end of the scanning session. We created the trial set so that the difference in shocks and difference in money were orthogonal across the trials. (Right panel) At least one week following the scanning session, we presented a series of decisions to the participants and asked them to judge how blameworthy it would be for someone to choose the harmful options on those trials (Other condition only). Although this was not made explicit to the participants, the set of trials that they judge were the same as those that they had faced during the fMRI session. In both the decision-making task and the moral judgment task, participants' decisions and judgments were private and unobserved.
Participants. For Study 1, 188 U.S. adult participants, who were recruited from Amazon Mechanical Turk, completed the task (125 males; mean age 36.3 years). This study was approved by the Yale University Human Subjects Committee (approval number: HSC 2000022385). For Study 2, eighty healthy volunteers aged 18-38 years were recruited from the University of Oxford and local residents of Oxford, the U.K. This recruitment was designed to achieve a target sample size, after accounting for expected participant dropout (based on 
Crockett et al. 2017)
, of 64 participants, which is sufficient for detecting brain-behavior correlations of r = 0.3 with 80% power. Data collection was terminated once we reached the predetermined sample size (N = 80).
The study was conducted at the Wellcome Centre for Integrative Neuroimaging (WIN) and the Department of Experimental Psychology, University of Oxford, the U.K. and approved by the University of Oxford ethics committee (approval number: R50262/RE001). All participants gave written informed consent and were compensated for their time. Individuals who had a history of neurological or neuropsychiatric disorders, used psychoactive medication or drugs, were pregnant, or had studied psychology for more than two years were excluded from participation; participants who had previously participated in studies involving social interaction or electric shocks were also excluded due to concerns that prior experience with similar experimental settings would influence psychological and brain processes in the current task. Eight participants had excessive head motion in the scanner (3mm translation or 3-degree rotation within one scanning session). Two participants expressed doubts regarding whether the receiver participant would actually receive the electric shocks. One participant's neuroimaging data was not registered due to technical issue of the scanner. Four participants failed to show up to the moral judgment session. Three participants produced judgment data that was uninterpretable (i.e., delivering more shocks for less money was judged less blameworthy). These participants were excluded from further analysis, leaving 62 participants for the final fMRI data analysis (27 males; mean age 22.7 years).
Moral decision task and fMRI testing session. Prior to attending the fMRI testing session, participants first completed a battery of online personality questionnaires (data to be reported separately). At least 1 week later (interval ranges from 7 to 74 days, with a median of 13 days), they attended an MRI scanning session at the Wellcome Centre for Integrative Neuroimaging (WIN) in Oxford, U.K. After giving informed consent, participants went through a pain thresholding procedure (for details, see 
(Crockett et al., 2014)
). The purpose of this procedure was twofold: (1) to familiarize participants with experience of the shocks, which they would later take into account in their decision-making; and (2) to determine the physical intensity of the shocks so that their subjective intensity is matched across participants. After the thresholding, participants were instructed they would be randomly assigned to roles of either decider or receiver using a procedure that has been described in detail elsewhere 
(Crockett et al., 2014
(Crockett et al., , 2017
. In reality, participants were always assigned to the role of decider and the role of receiver was played by a confederate.
Following role assignment, participants received instructions for the moral decision task (full instructions for this task can be found in the Supplemental Online Materials: Instructions for the decision task), answered comprehension questions, and practiced outside the scanner for 6 trials.
Participants were instructed that one of their choices would be randomly selected and implemented at the end of the scanning session. They were informed that their choices would be anonymous and they would not meet or interact with the receiver. This was to minimize concerns about reputation or reciprocity in their decision-making. They then completed the moral decision task in the fMRI scanner. In this task, participants made a series of binary choices where one option contained more electric shocks and amounts of money (i.e., harmful option) and the other option contained fewer shocks and less money (i.e., helpful option). The money was always for the participant (i.e., decider), but the shocks were allocated to the receiver in half of the trials (i.e., Other condition) and to the participant in the other half of the trials (i.e., Self condition).
The procedure for generating the choice options is described in detail elsewhere 
(Crockett et al., 2017)
. Specifically, we created a set of 72 trials according to the criteria reported in . Four "catch" trials, where the more harmful option contained a smaller amount of money were inserted, resulting in 76 trials in the set. Half of the trials were randomly selected to present the more harmful option on the right-hand side of the screen, whereas in the other half of the trials the more harmful option were presented on the left-hand side of the screen. Then the 76 trials were duplicated to constitute the Self and the Other conditions. Trials were then distributed into two scanning runs of 76 trials each; each run contained equal numbers of Self and Other trials.
Four different trial sets were created in this way, which were randomly assigned to the participants.
Our trial optimization procedure 
(Crockett et al., 2017)
 ensured that the amount of profit that would result from choosing the harmful option was uncorrelated with the amount of shocks (|r| < 0.07, ps > 0.525).
After the moral decision task, participants exited the scanner, and one trial from the task was randomly selected and implemented outside the scanner. Participants then completed a series of self-report measures about their experiences during the decision-making task, including a measure of conflicted feeling they experienced about their choices (1 = not at all, 7 = very much). They also answered debriefing questions that assessed their beliefs of the experimental setup. In the debriefing session, we did not include questions that explicitly asked whether the participants doubted about the veracity of the paradigm, as these questions may cue feelings of doubt in the participants. Instead, we included indirect questions about the clarity of our instructions regarding the presence of the Receiver, the delivery of electric shocks to the Receiver, and the confidentiality of the participants' decisions. Participants responded to these questions on 7-point Likert scales (1 = yes fully, 7 = no not at all). The majority of the responses to these questions are "1 -yes fully", with very few "2" and only two "3". The average scores of these questions are below 1.1. None of the participants reported equal or higher than the midpoint of the scale on any of these questions, indicating that our instructions are clear.
In addition to these questions, the participants also provided open-ended comments about the study, where they could express their feelings, experience, and questions regarding any part of the study.
The authors read these comments and flagged expressions of doubt regarding the presence of the receiver or the delivery of electric shocks to the Receiver. Two participants explicitly mentioned "doubt" and being "skeptical" about the experimental setup (e.g., whether the Receiver exists).
These participants were therefore excluded. Two other participants did not explicitly mention "doubt" or "skepticism", but their responses to the open-ended questions suggested that whether the Receiver was present was something on their mind. In our analysis, we included these two participants to maximize the size and diversity of our sample. However, excluding them did not change the patterns of the results (see the 
Table S2
).
Moral judgment task and behavioral testing session. At least one week after the fMRI session, participants were invited to participate in a behavioral experiment session at their earliest available time. During the behavioral experiment session, participants completed a battery of behavioral and psychophysiological tasks, the first of which was a moral judgment task. In this task, participants were presented with a subset of the choice sets that they faced in the scanning session, namely all of the trials in the Other condition where the money was for the decider and the shocks were for the receiver. We did not explicitly measure whether participants recognized these trials. However, if they indeed remembered their choices in most of the trials, we would expect to see much less hypocritical blame than what we actually observed, because people have the tendency to appear consistent 
(Gawronski, 2012)
, and exhibiting hypocrisy is something people hate 
(Jordan et al., 2017)
. In both the decision-making task and the moral judgment task, participants' decisions and judgments were private and unobserved.
On each trial of the moral judgment task, the harmful option (i.e., more money for the decider and more shocks for the receiver) was highlighted. Participants were asked to judge the blameworthiness of each harmful choice on that specific trial on a visual analog scale ranging from "not at all blameworthy" to "extremely blameworthy". Full instructions for this task can be found in the Supplemental Online Materials: Instructions for the judgment task.


MRI acquisition and preprocessing. Functional MRI scanning was performed on a 3-Tesla
Siemens Prisma scanner at the Wellcome Centre for Integrative Neuroimaging (WIN) at The University of Oxford. Functional images were obtained with multiband T2*-weighted echo-planar imaging (EPI) sequence. The EPI images were acquired in an ascending manner, at an oblique angle (approximately 30°) to the AC-PC plane to minimize the signal dropout in the orbitofrontal areas. The following acquisition parameters were used: 72 slices in interleaved ascending order; matrix size: 108 ×108; voxel size: 2 × 2 × 2 mm 3 with 1 mm gap; echo time (TE) =30 ms; repetition time (TR) = 1,570 ms; flip angle = 70°; field of view (FOV) = 216 * 216 mm 2 . The structural image was taken using a magnetization prepared rapid gradient echo (MPRAGE) sequence with 192 slices; TR=1,900 ms; TE = 3.97 ms; field of view = 192 × 192 mm 2 ; voxel size = 1 × 1 × 1 mm 3 resolution. We also acquired a field map (short TE = 4.92 ms; long TE = 7.38 ms; TR = 482.0 ms; resolution = 2 × 2 × 2 mm 3 ; FOV = 219 × 219 mm2) to correct distortions in the functional images.
MRI data were preprocessed and analyzed using SPM12 (www.fil.ion.ucl.ac.uk/spm). Functional images were realigned and unwarped with reference to the fieldmap and co-registered to the participant's own structural image. The structural images underwent routine preprocessing steps, including segmentation, bias correction, and spatial normalization to the Montreal Neurological Institute (MNI) template. Finally, images were spatially smoothed with an SPM default Gaussian kernel (8-mm full-width at half-maximum).
General Linear Model 1 (GLM1): model of trial-wise anticipated blameworthiness judgments. We constructed the first GLM to obtain for each participant a representation map of trial-wise judgments of how blameworthy it would be to choose the more harmful option relative to the less harmful option (or participant-specific moral standards). In this model, blood-oxygenlevel-dependent (BOLD) signals were regressed against 4 critical first-level regressors containing the onsets of Self trials where the left (i) or right (ii) option was selected, and Other trials where the left (iii) or right (iv) option was selected. Duration of these 4 regressors was set to the participant's reaction time on that trial (i.e., the interval between the presentation of options and button press). For this analysis, what we looked for at the individual level was the neural signal at the time of decision-making that scales with the relative blameworthiness of the more harmful option relative to the less harmful option, as judged by the participants themselves. To this end, for the two regressors corresponding to the trials in the Other condition, we included a parametric modulator that contained each participant's judgment on that trial of the relative blameworthiness of the more vs. less harmful option (collected in the behavioral session at least a week following scanning). In GLM1, this relative blameworthiness rating is treated as an attribute of the trial, independent of what the participant actually chose on that trial. The parametric analysis, therefore, captured the neural correlates of a crucial element of moral decision-making: assessing the relative blameworthiness of choosing the more profitable but more harmful option, relative to the less harmful and profitable option. We expect this evaluative process to be present during all choices, regardless of what the participant ultimately chooses. We additionally included regressors of no interest corresponding to onsets of button presses, cue for transitions between conditions, and missing trials, as well as 6 nuisance regressors to control for head motion. For the second-level (or group-level) analysis, we included participants' degree of hypocritical blame as a parametric regressor while controlling for their moral preferences (κother). We constructed the GLM this way deliberately because the second-level modulator, hypocritical blame, is dependent on participants' behaviors. The brain activities captured by the first-level GLM therefore should not be dependent on behavior. This approach is widely adopted in fMRI studies of value-based choice in moral 
(Crockett et al., 2017)
, social 
(Ruff & Fehr, 2014)
, and economic domains 
(Rangel et al., 2008)
.
Participant-specific representation of blame was defined as the positive effect of the blameworthiness judgment parametric modulator, collapsing across help and harm decisions. For whole-brain analyses, we adopted family-wise error (FWE)-corrected PFWE < 0.05 at the cluster level and uncorrected P < 0.001 at peak voxel level. The cluster with the largest cluster-level PFWE value (0.040) that still passes this threshold has 113 contiguous voxels.


GLM2: model of decision parameters.
We built a GLM to obtain for each participant representation maps of the objective amounts of money difference (Δm) and shock difference (Δs) between the harmful option and the helpful option in the Self and Other conditions. In this model, we included the same four critical regressors as in GLM1. Each of these regressors was further associated with four parametric modulators: the amount of money and shocks for the harmful option and the helpful option. Critically, custom scripts ensured that these two parametric modulators competed for variance during the estimation, rather than being serially orthogonalized as is standard in SPM. We included the same set of regressors of no interest as in GLM1. To obtain representation maps of Δm and Δs, we defined first-level contrast of moneyharmful option > moneyhelpful option and shockharmful option > shockhelpful option for both Self and Other regressors, collapsing across help and harm decisions. Individual representation maps to Δm and Δs were used, together with the guilt signature (see below), to calculate guilt-related pattern expression associated with each representation map.
Multivariate analysis with Guilt-Related Brain Signature. We adopted multivariate decoding approach to probe guilt-related neurocognitive processes associated with choice attributes Δm and Δs. Specifically, we utilized a previously validated brain-based signature of guilt 
(Yu et al., 2020)
.
Based on two independent neuroimaging datasets that used interpersonal interactions to evoke guilt, Yu et al. (2020) identified a guilt-related brain signature (GRBS) that discriminated conditions associated with different level of interpersonal guilt. Specifically, in the training dataset, the participants were either completely, or partially responsible for an anonymous stranger's pain 
(Yu et al., 2014)
. Participants' self-reported guilt feelings was positively associated with their responsibility. The GRBS was trained to discriminate the completely responsible from the partially responsible conditions and was able to do so accurately (accuracy = 88%) in a cross-validated manner (i.e., leave-one-subject-out cross-validation). Moreover, the predictive power (or sensitivity) of GRBS can be generalized to a neuroimaging study that adopted a similar interpersonal harm task, where the participants were from a different cultural background relative to the training dataset 
(Koban et al., 2013)
. However, a useful brain-based signature of a psychological construct (e.g., guilt in social interactions) should not be sensitive to other negative experiences, otherwise it would be difficult to infer what neurocognitive processes the signature captures 
(Wager et al., 2013;
Woo et al., 2017)
. To demonstrate that this signature does not simply pick up any negatively valenced experiences, but is only sensitive to guilt experience elicited in social interactions (i.e., specificity), in Yu et al. (2020) we tested its predictive power when applied to a few other fMRI datasets when the participants have negatively valenced experience but are not engaged in live social interactions. These include physical pain, vicarious pain, and recall of past negatively valenced experiences. In Yu et al. 
2020
, we found that the GRBS cannot distinguish different levels of physical pain or vicarious pain, but it can distinguish different levels of guilt in a social interactive task. This suggests the GRBS is specific to guilt. In addition, we find evidence that the GRBS is specific to guilt that is experienced during a real social interaction: the GRBS cannot distinguish the brain activity pattern when the participants recalled a past experience of guilt from the brain activity pattern when the participants recalled a past experience of sadness or shame.


Results


Blaming others for behaving similarly to oneself appears hypocritical to observers
In Study 1, participants (N = 188) read a vignette describing a protagonist who took part in an experiment where they decided to deliver 10 electric shocks to another person in exchange for $1.
After the protagonist made his decision, he learned of another person who made the same decision.
In the discrepant condition (N = 95), the protagonist judged this person's decision to be extremely morally blameworthy, while in the consistent condition (N = 93) the protagonist judged this decision to be not at all morally blameworthy. Participants then were asked to indicate to what extent they thought the protagonist was hypocritical, moral, and trustworthy on 7-point Likert scales (1 = not at all, 7 = extremely) (see Supplemental Online Materials: Vignettes for folk intuitions of discrepant blamers for full text of vignettes).
As expected, participants in the discrepant condition judged the protagonist to be more hypocritical (M±s.d. = 6.1±1.5) than participants in the consistent condition (M±s.d. = 3.0±2.3, t = 11.4, p < 0.001, Cohen's d = 1.64; 
Fig. 2a
). In addition, participants judged the protagonist to be less moral  


Quantifying hypocritical blame in the laboratory
Having confirmed in Study 1 that observers perceive hypocrisy when someone blames another person for making the same decision they made themself, in Study 2 we sought to examine the neural correlates of moral decision-making in so-called hypocritical blamers. Because we assessed participants' actual decisions and moral judgments of others' decisions in the same set of trials (see Materials and Methods for details), we were able to quantify each participant's degree of hypocritical blame by comparing (a) their own likelihood of making a harmful decision on each trial of the decision-making task with (b) the blameworthiness they assign to another person for a harmful decision on each trial of the moral judgment task. Specifically, for (a), we computed each participant's likelihood of harming another person on a given trial with a well-established computational model for this type of moral decision making 
(Crockett et al., 2014
(Crockett et al., , 2015
(Crockett et al., , 2017
).
In this model, the probability of choosing to inflict pain for profit is a softmax transformation of the subjective value of the harmful relative to the helpful option, ΔV. For participant j and trial i:
!" = $1 − " ( !" − " !" (ℎ ) !" = 2 1 1 + #$ ! •&' "! 5 $1 − 2 " ( + "
Here Δm and Δs denote the additional money and shocks associated with the harmful relative to the helpful option. The harm aversion parameter, κ, indicates the relative weight participants place on shocks over money in the valuation process. κ takes on different values in the Self and Other conditions (κself and κother), thereby reflecting different decision preferences when harming oneself versus harming another person. We used a softmax function to convert ΔV into the probability of choosing the harmful option over the helpful option. Here, β is a participant-specific inverse temperature parameter that characterizes the steepness of the softmax curve. We also included a lapse rate parameter ε that captures task-irrelevant noise such as inattention (cf. 
Crockett et al., 2014)
. Since the task and computational framework has been established in a number of studies across multiple labs, we did not plan to compare multiple models in a data-driven manner.
However, when estimating the model without the lapse rate, we found that it had a higher BIC value (2963) than the one with the lapse rate (2833), indicating that including the lapse rate improved the model.
We replicated key findings from past studies using this task 
(Crockett et al., 2014
(Crockett et al., , 2017
Volz et al., 2017)
: Specifically, on the aggregate level, participants were more averse to harming other people than harming themselves for money (see 
Fig. S1
). For our analysis of hypocritical blame, we focused here solely on participants' decisions to inflict pain on others for profit. We observed wide variation in harm aversion: some participants refused to inflict a single additional shock on a stranger for a profit of £19 while others were willing to inflict 20 additional shocks on a stranger in exchange for 10 pence. Because κother was not normally distributed (Kolmogorov-Smirnov test = 0.11, p = 0.05), in the following we used Spearman tests for the correlational analyses that involved κother.
After computing each participant's likelihood of choosing the harmful option for each trial in the decision-making task, we computed a hypocritical blame score for each participant by combining the data from the moral judgment task with the data from the decision-making task. Specifically, we computed the hypocritical blame score by summing across trials the amount of blame assigned on each trial of the judgment task, weighted by the participants' own likelihoods of choosing selfishly on the same trial in the decision task:
" = A !" ! * (ℎ ) !"
Here, blameij denotes participant j's blameworthiness judgment on trial i of the judgment task.
Pij(harm) is the likelihood that participant j would choose the harmful option on the same trial in the moral decision-making task computed based on the value function and softmax function.
Weighting the blame judgments by the choice likelihoods captures the logic that it is more hypocritical to blame someone for an action that oneself has previously taken confidently than tentatively or accidentally 
(Alicke et al., 2013;
Dover, 2019;
Laurent & Clark, 2019;
Wallace, 2010
). According to our definition of hypocritical blame, it is critical to keep blameworthy judgments on the same scale across participants. Therefore, we did not normalize blameworthiness judgments within participants before calculating hypocritical blame because doing so would take away our ability to compare participants' blame tendency on the same scale.
As 
Figure 3
 illustrates, participants who assign a high level of blame on trials where they themselves are likely to choose the harmful option will have a high hypocritical blame score based on our model ( 
Fig. 3b and 3d)
. In contrast, participants who almost never assign blame on the trials where they themselves are likely to choose the harmful option will have a low hypocritical blame score based on our model 
(Fig 3a and 3c)
. With this operationalization of hypocritical blame, 97% of participants displayed at least some level of hypocritical blame. However, we observed a wide range of individual variation in the degree of hypocritical blame that could be described by a normal distribution (M±s.d. = 12.9±7.5; Shapiro-Wilk normality test, p = 0.248) ( 
Fig. 3e)
. Given the way we defined hypocritical blame, it is not surprising that hypocritical blame was negatively correlated with κother (Spearman ρ = -0.57, p < 0.001, 
Fig. 3f
). Therefore, we controlled for κother in all subsequent analyses involving hypocritical blame scores (see Supplemental Online Materials:
Robustness test for statistically controlling for κother and 
Table S3
 for robustness check). Our definition of hypocritical blame takes advantage of the fact that people do not blame identically and captures the individual differences in the discrepancy between one's moral behaviors and their propensity to assign blame to others. Indeed, when we controlled for participants' average blame, the negative correlation between κother and hypocritical blame became stronger (Spearman ρ = -0.81, p < 0.001). Note that hypocritical blame was not correlated with participants' overall blameworthiness judgments (Spearman ρ = 0.09, p = 0.476). Two representative participants (one whose behavior is described in panels (a) and c) and the other in panels (b) and (d)) illustrating how hypocritical blame is defined in our formula. These two participants have comparable harm aversion in Other condition (κother = 0.37 and κother = 0.39, respectively). The x-axis indicates the κ value [Δm/(Δm + Δs)] of each trial. Higher trial κ value means choosing the more harmful option will confer a large amount of monetary gain for the decider by increasing the receiver's harm by a small degree. The y-axes on the left indicate the model-derived probability of choosing the harmful option. The red curves are the best-fit softmax curves. In (a) and (b), the blue dots indicate participants' blameworthiness judgment ratings. In (c) and (d), the magenta dots represent the product of blameworthiness judgment and the model-derived, participant-specific probability of choosing the more harmful option on the same trial (weighted blame). In our definition, the participant's hypocritical blame is the sum of weighted blame across all the trials. As can be seen, the participant described in (b) exhibited more hypocritical blame by our definition than the participant described in (a) because they indicated substantial degree of blameworthiness judgment on the trials where they were very likely to choose the harmful option themselves. Panel (e): Distribution and inter-individual variability of hypocritical blame. The brown and the green vertical lines indicate the hypocritical blame score of the low (hypocritical blame = 0.7) and high (hypocritical blame = 16.8) hypocritical blame participants, respectively. Panel (f): hypocritical blame score was negatively correlated with κother (Spearman ρ = -0.57, p < 0.001).


Hypocritical blame is associated with conflicted moral decision-making
We next turned to data concerning the mental states of hypocritical blamers when they blamed others for what they themselves had done. To test the possibility that at least some people who engage in hypocritical blame do feel that the moral standards they apply to others are also binding for themselves, we first examined the prediction that those who exhibit more hypocritical blame, relatively to those who behave similarly but do not find it blameworthy, feel more conflicted about their own decision-making when failing to live up to their own moral standards.
To obtain a measure of conflicted feelings, after participants completed the moral decision-making task in the scanner, they indicated their subjective perception of "facing a moral dilemma" during the task on a 7-point Likert scale. Conflicted feelings varied substantially across participants, covering the entire range of the scale with a mean±s.d. of 3.7±1.6. Controlling for participants' moral behavior (as indexed by κother), we observed a positive correlation between conflicted feelings and hypocritical blame (Spearman's ρ = 0.39, t = 3.22, p = 0.002; 
Figure S2
). This means that, consistent with our prediction, hypocritical blamers reported feeling more rather than less conflict during their moral decisions, controlling for the decisions they actually made.
Next, we tested a hypothesis that subjective feelings of conflict result from failures to live up to one's own moral standards. Our decision model specifies that participants will sometimes make choice errors, where they select the option that is less subjectively valuable to them (Supplemental Online Materials: Analysis of the number of harmful and helpful errors). Choice errors are particularly likely to occur around a participant's indifference point, where participants face the highest levels of decision conflict 
(Fig. 4a)
. Past work distinguishes between "harmful errors"
(erroneously choosing the harmful option) versus "helpful errors" (erroneously choosing the helpful option) and suggests that participants who value helping over harming should be more likely to make harmful errors 
(Hutcherson et al., 2015)
. Accordingly, here we found that harmful errors were more common than helpful errors during moral decision-making (  
Fig. 4b
).
Harmful errors during moral decision-making represent cases where participants harm others even though helping is more aligned with their overall moral preferences. One potential explanation of these errors is weakness of will-that is, these participants succumb to temptation to gain money even though they judge their harmful acts to be morally wrong. If hypocritical blame arises from weakness of will, harmful errors should be positively correlated with both feelings of moral conflict and with hypocritical blame. We found support for both predictions: the number of harmful errors in the Other condition was positively correlated with both conflicted feelings ( 
Fig.   4c
) and hypocritical blame ( 
Fig. 4d)
, after controlling for participants' moral preferences 
(κother)
 and the number of helpful errors (Spearman's ρ = 0.35, t = 2.85, p = 0.006 for conflicted feelings;
Spearman's ρ = 0.26, t = 2.05, p = 0.045 for hypocritical blame). Conflicted feelings were not correlated with helpful errors in the Other condition (Spearman's ρ = 0.03, t = 0.25, p = 0.808) nor with harmful or helpful errors in the Self condition (Spearman's ρ = 0.02, t = 0.18, p = 0.855 for harmful errors; Spearman's ρ = 0.04, t = 0.28, p = 0.779 for helpful errors), suggesting that posttask subjective feelings of conflict arose from failures to live up to one's own moral standards specifically, rather than from choice errors more generally. indicates the probability of choosing the harmful option. Blue dots indicate "correct" choices, where the chosen option has higher subjective value for the decider than the unchosen option. Errors occur when the decider chooses the option that has the lower subjective value than the other option. The green and yellow checks indicate harmful errors and helpful errors, respectively. (b) Numbers of harmful and helpful errors in the Self and Other condition. (c-d) The number of harmful errors in the Other condition is positively correlated with conflicted feelings (c) and hypocritical blame (d) after controlling for κother and the number of erroneous help choices. ***: p < 0.001, n.s.: not significant.


Hypocritical blame is positively correlated with neural representations of moral standards
We for selecting the harmful option on each trial, which was obtained in the moral judgment task a
week after scanning 
(Fig. 5a)
. Participants with higher moral standards should, on average, judge harmful choices to be more blameworthy than participants with lower standards 
(Crockett et al., 2017)
. This was indeed what we found -participants' overall blameworthiness judgments were positively associated with their harm aversion in the Other condition 
(B ± s.e. = 34.88±5.56,
b = 0.29,
95% CI of b [0.20,
0.38]
, t = 6.28, p < 0.001). However, because individuals vary in how they assign blame judgments as a function of pain inflicted and profits gained 
(Siegel et al., 2017)
, a more precise index of moral standards would consider each participant's trial-specific blame judgments, rather than their overall propensity to blame. Because each participant provided a blame judgment for every trial they faced in the scanner, we therefore treat these judgments as participant-specific, trial-wise indicators of moral standards.
To examine the relationship between brain responses to moral standards and individual differences in hypocritical blame, we conducted a group-level analysis that included participants' degree of hypocritical blame as a second-level parametric regressor while controlling for their moral preferences (κother). A positive effect of this group level parametric regressor will identify voxels in which neural responses to moral standards (i.e., blameworthiness judgments of harm choices) scale positively with participants' hypocritical blame. In a whole-brain analysis (pFWE < 0.05, whole-brain corrected at the cluster level after voxel-wise thresholding at p < 0.001), the parametric contrast revealed a positive relationship between hypocritical blame and BOLD responses to moral standards in the anterior cingulate cortex (ACC), bilateral lateral prefrontal cortex (LPFC), and left inferior temporal cortex ( 
Fig. 5b
; 
Table S1
). The reverse contrast did not identify any significant cluster, indicating that there were no brain regions showing a significant negative relationship between hypocritical blame and BOLD responses to moral standards.
The positive relationship between hypocritical blame and BOLD responses to moral standards (i.e., blameworthiness judgments of harm choices) in ACC, LPFC and left inferior temporal cortex could not be explained by decision difficulty (i.e., the reverse of subjective value difference between the chosen and the unchosen options): responses in these areas did not scale with trialwise decision difficulty, and the strength of responses to decision difficulty did not predict individual differences in hypocritical blame (Supplemental Online Materials: GLM 3; 
Figure S3
).
Thus, hypocritical blame was positively associated with neural responses to moral standards during moral decision-making. In a general linear model, we regressed BOLD responses at decision trial onset against the blameworthiness judgment the participant made on the corresponding trial in the judgment task (at least 1 week later). HRF: hemodynamic response function. (b) At decision onset, responses to trial-wise blameworthiness in ACC and bilateral LPFC positively correlated with hypocritical blame (pFWE < 0.05, whole-brain corrected at the cluster level after voxel-wise thresholding at p < 0.001).


Hypocritical blame is associated with a neural signature of guilt during moral decision-making
Folk intuitions about hypocritical blamers suggest that hypocritical blamers are less moral than people who behave equally badly but do not find their behavior blameworthy. This implies that hypocritical blamers will experience weak (or absent) feelings of guilt when they consider harming others for profit. In contrast, our hypothesis that some hypocritical blame is due to weakness of will predicts a positive relationship between guilt and hypocritical blame. To avoid inducing demand effects or social desirability concerns, we did not ask participants to directly report feelings of guilt during the moral decision-making task. Instead, we leveraged a multivariate brainbased classifier trained on two independent datasets to identify brain states that positively predict guilt evoked by interpersonal interactions (Guilt-Related Brain Signature, GRBS; 
(Yu et al., 2020)
).
GRBS corresponds to a distributed brain network that exhibits only weak spatial similarity with other social and affective brain signatures, suggesting that guilt is associated with a specific pattern of neural activity 
(Yu et al., 2020)
. Signatures of different psychological constructs have different distributions of prediction weights across the brain. The primary goal of developing a brain signature is to predict neurocognitive processes and behaviors of out-of-sample observations based on brain activation patterns, not to localize structures whose univariate activation strength is sensitive to experimental manipulations 
(Wager et al., 2013;
Woo et al., 2017)
. Therefore, the signature is a map of prediction weights that is distributed across the whole brain 
(Fig. 6a)
. The GRBS offers a sensitive and specific brain-based indicator of guilt-related neurocognitive processes. In the context of our moral decision-making task, guilt-related neurocognitive processes should be positively associated with the amount of additional pain inflicted (Δs), and/or negatively correlated with the amount of additional profit gained (Δm), since these factors are positively and negatively correlated with blameworthiness judgments, respectively 
(Crockett et al., 2017;
Siegel et al., 2017)
, and guilt is reliably evoked by anticipated blame 
(Baumeister et al., 1994;
Ferguson et al., 1997;
Parkinson & Illingworth, 2009)
.
A separate GLM was constructed to obtain brain response maps associated with Δs and Δm in the Self and the Other condition (GLM 2; see Materials and Methods). The dot-product of GRBS and participants' brain maps of Δs and Δm is a scalar value, pattern expression, which reflects the spatial resemblance between neural responses to Δs and Δm and the brain-based signature of guilt 
(Fig. 6a)
. After calculating these values, we then asked whether guilt pattern expressions associated with shocks and money in the Other condition, relative to those in the Self condition (i.e., Δsother > Δsself for shocks and Δmother > Δmself for money), were positively or negatively correlated with hypocritical blame, controlling for moral preference (κother). Contrary to folk intuitions and consistent with our hypothesis, guilt pattern expressions evoked by shocks ( 
Fig. 6b;
 GRBSΔs, Spearman's ρ = 0.34, t = 2.74, p = 0.008) were positively correlated with hypocritical blame. We did not observe a similar relationship for guilt pattern expressions evoked by money (GRBSΔm, Spearman's ρ = 0.09, t = 0.69, p = 0.492). Together these findings reflect a positive relationship between guilt pattern expressions evoked by harm to others and hypocritical blame.
Because we observed that self-reported feelings of conflict about the moral decision task were positively associated with hypocritical blame, we next considered whether those conflicted feelings could be explained by guilt-related neurocognitive processes at the time of decision.
Consistent with this prediction, we observed a positive correlation between self-reported conflicted feelings and GRBS pattern expression related to shocks ( 
Fig. 6c;
 for GRBSΔs, Spearman's ρ = 0.42, t = 3.51, p < 0.001; for GRBSΔm, Spearman's ρ = -0.06, t = -0.45, p = 0.655). Next, we tested whether self-reported feelings of conflict mediated the positive relationship between GRBSΔs and hypocritical blame in a mediation analysis 
(Imai et al., 2010)
 where GRBSΔs was entered as the independent variable, participants' conflicted feelings as the mediator, and hypocritical blame as the dependent variable. As in the regression analysis, κother was included as a covariate. We found a significant mediation effect of conflicted feelings ( 
Fig. 6d;
 average mediation effect = 1.80, CI = [0.36, 3.77], p = 0.02; average direct effect = 2.16, CI = [-0.97, 5.61], p = 0.186), indicating that guilt-related neurocognitive processes evoked by harm to others may lead to participants' conflicted feelings after the task, which in turn positively predict hypocritical blame. 


A note on achieved power
We did not pre-register our studies. Based on the observed data, the sample sizes are generally good for the analysis we carried out. For Study 1, the achieved powers (assuming α = 0.05) for the comparison of hypocrisy and trustworthiness across groups are 1.00 and 0.81, respectively. The effect size of the comparison of morality was smaller (d = 0.24), so the achieved power for this analysis is low (0.37). We acknowledge that this result should be interpreted with caution. For Study 2, our critical analysis is the correlation between hypocritical blame and guilt pattern expressions evoked by shocks. Given the effect size of the correlation, our final sample (N = 62) achieved a power of 0.8 in detecting the correlation.


Discussion
In this study, we developed a laboratory paradigm to precisely quantify hypocritical blame, where people blame others for committing the same transgressions they committed themselves 
(Todd, 2019)
. At the core of this operationalization of hypocrisy is a discrepancy between participants' moral judgments and their behaviors in a moral decision-making task. Therefore, we measured participants' choices in an incentivized moral decision-making task that they believed had real impact on their own monetary payoff and painful electric shocks delivered to a Receiver. We then compared those choices with moral judgments they made a week later of other people in the same choice context. By comparing participants' judgments with their own behaviors, we are able to quantify the degree to which they judge other people more harshly for making the same choices they themselves made previously (i.e., hypocritical blame).
We found that hypocritical blame is positively associated with feelings of moral conflict arising from failures to live up to one's own moral standards, and positively associated with neural representations of moral standards and guilt during moral decision-making. This suggests that at least some instances of hypocritical blame are not attributable to a lack of moral standards for oneself, but instead may manifest from failures to consistently live up to one's own moral standards.
Our results also shed new light on the neural basis of moral standards. Past work has implicated lateral and medial prefrontal regions in representing moral values 
((Crockett et al., 2017;
FeldmanHall et al., 2015;
Qu et al., 2019;
van Baar et al., 2019)
; for a review, see 
(Carlson & Crockett, 2018)
). Here, we extend these findings by showing that activity in these regions is also sensitive to the spectrum of moral attitudes behind the same external behavioral pattern. Holding constant the behavioral preference for avoiding harm to others (κother), LPFC and ACC responses to moral standards predicted how far one's moral judgments ultimately deviated from their behavior. This relationship is in line with our finding that individuals exhibiting more hypocritical blame also reported more conflicted feelings during decision-making, and it fits well into a broader context of LPFC and ACC functions in conflict monitoring, in both non-moral domains 
(Botvinick et al., 2001;
Etkin et al., 2006)
 and moral domains 
(Buckholtz et al., 2015;
Carlson & Crockett, 2018;
Van Bavel et al., 2015)
.
To further characterize the neurocognitive processes underlying hypocritical blame, we adopted a multivariate approach to the neuroimaging data, applying an independently trained brain signature of interpersonal guilt to the representation of moral standards. This brain-based signature enables us to draw conclusions about the underlying neurocognitive processes from patterns of activity in the whole brain, thereby avoiding inferring cognitive processes based solely on the location of brain activations 
(Poldrack, 2011;
Wager et al., 2013)
. Some theorists have postulated that apparently hypocritical blamers are not really hypocritical if they experience guilty feelings for violating the moral standards, because hypocrites do not sincerely endorse the moral value in question but express it only for strategic reasons 
(Bartel, 2019;
Bell, 2013;
Wallace, 2010)
. Our multivariate analysis provided empirical evidence supporting this theoretical conjecture by showing that guilt-related processes evoked by consideration of harm to others tracks individual differences in hypocritical blame. Our mediation analysis further uncovered the guilt-related processes associated with the encoding of harm as a potential source of conflicted feelings reported by more hypocritical blamers.
Taken together, our findings may have implications for lay and philosophical debates about who can legitimately blame others. According to some accounts, the legitimacy of blame depends not just on facts about the target of blame, but also on facts about the blamer 
(Todd, 2019;
Tognazzini & Coates, 2018)
. For example, some argue that hypocritical blame is illegitimate because "blame carries with it a kind of practical commitment to critical self-scrutiny" 
(Wallace, 2010)
. This argument implies that all hypocritical blamers lack legitimacy to blame others if they do not blame themselves as much as they blame others. However, our findings from Study 2 suggest that at least some instances of apparently hypocritical blame may not in fact be disqualifying for standing to blame, a philosophical concept indicating whether it is appropriate for a person to engage in a particular instance of blame 
(Todd, 2019)
, because they are associated with signs of self-scrutiny (e.g., feeling guilt and regret for one's past wrongdoing) that are required for standing to blame 
(Wallace, 2010;
Bell, 2013;
Todd, 2019)
.
Several limitations of this work are worth noting. First, our findings do not directly speak to the precise neurocognitive mechanisms that give rise to moral judgments that conflict with past moral behaviors. While our data provide evidence that at least some instances of hypocritical blame cannot be explained by an absence of moral standards, we cannot definitively conclude that such cases are attributable to weakness of will 
(Bartel, 2019;
Batson & Thompson, 2001;
Mele, 1989)
, though our finding that hypocritical blame is positively associated with harmful errors does provide some preliminary evidence for this claim. Future studies might investigate this question with causal interventions designed to induce mental fatigue 
(Inzlicht et al., 2014;
Schmidt et al., 2012)
. Second, our work cannot shed light on the neural mechanisms that underlie the construction of hypocritical blame judgments. While the current investigation focused on the neurocognitive processes underlying moral decision-making and how they are related to subsequent hypocritical blame, future studies could scan participants while they are making blame judgments that are either consistent or inconsistent with their past behavior. Third, we can draw conclusions about hypocritical blame only in the context of physical harm, which is just one of many types of moral transgressions 
(Graham et al., 2013;
Schein & Gray, 2017)
. However, in philosophy 
(McKinnon, 1991;
Moberg, 1987;
Shklar, 1984)
 and psychology 
(Ji et al., 2006;
Yousaf & Gobet, 2013)
, hypocritical blame has also been widely associated with violation of religious beliefs, sexual norms, and moral concerns unrelated to physical harm (e.g., purity, loyalty, self-discipline, and so on).
Future work could adopt our computational operationalization and multivariate neuroimaging approach to investigate whether similar or distinct neurocognitive processes characterize hypocritical blame across a variety of moral domains, thereby ascertaining the conceptual and mechanistic complexity involved.
To conclude, we developed a model of hypocritical blame that allowed us to quantify a tendency to blame others for the same behaviors that oneself committed and test several common assumptions about hypocritical blamers. We showed, in marked contrast to the intuitions of observers, that hypocritical blamers' self-reports and neural activity during moral decision-making is consistent with the presence rather than absence of moral standards. Participants with higher levels of hypocritical blame reported more intense conflicted feelings and showed heightened guilt-related neural responses when considering harming others. Thus, contrary to the common assumption that hypocritical blamers do not really accept the moral standards that they apply to others, our data suggest that many people who engage in hypocritical blame do hold and care about moral standards and apply these moral standards to themselves as well as to others.


Supplementary Methods


Instructions for the decision task
We detailed our instructions for the decision task below: On some trials ("Self"), the shocks will be for you. On other trials ("Receiver"), the shocks will be for the Receiver. As the Decider, you always receive the money. So, on "Self" trials, you would receive the money and the shocks, but on "Receiver" trials, you would receive the money but the Receiver would receive the shocks.
You
The shock intensity level is always set to level 8 -i.e., just below the "intolerable" pain level. For "Self" trials, we use the voltage setting that corresponds to your level 8 rating, and for the "Receiver" trials, we In between rounds, there will be a delay that can vary from round to round. So don't worry if you experience a long delay in between rounds -this is normal.
Before you start the actual task, you will try a few practice rounds. These rounds will not count, but will familiarize you with the task set-up. For the practice, use left and right buttons on the mouse.
After you complete the decision-making task, you will complete a few questionnaires outside of the scanner. Please notify the experimenter if you have any questions.


Instructions for the judgment task
We detailed our instructions for the judgment task below:
You previously participated in our neuroimaging study. At that time you were randomly assigned to the role of Decider. Another participant in that session was randomly assigned to the role of Receiver. 


Vignettes for folk intuitions of discrepant blamers


Discrepant blame condition
Joe participates in an experiment where he has the opportunity to earn $1 for himself in exchange for delivering 10 painful electric shocks to another person. He decides to take the money by delivering the shocks.
One week later, Joe learns of another person who also decides to take $1 by delivering 10 shocks to another person. Joe judges this decision to be extremely morally blameworthy.


Consistent blame condition
Joe participates in an experiment where he has the opportunity to earn $1 for himself in exchange for delivering 10 painful electric shocks to another person. He decides to take the money by delivering the shocks.
One week later, Joe learns of another person who also decides to take $1 by delivering 10 shocks to another person. Joe judges this decision to be not at all morally blameworthy.
Participants were asked to answer to following questions on a 7-point Likert scale (1 = Not at all, 7 = Extremely):
• How moral is Joe?
• How trustworthy is Joe?
• How hypocritical is Joe?


Robustness test for statistically controlling for κother
Because hypocritical blame was negatively correlated with κother, in the main text, we controlled for κother in all regression and correlation analyses involving hypocritical blame scores. However, there is some concern for statistically controlling for a covariate that is itself correlated with the main variable (e.g., 
Miller & Chapman, 2001
). For example, it is argued that such 'statistical control' often renders the grouping variable uninterpretable, or at least not something the researchers intend it to be. There are two key concerns involved in this issue, one psychological (or substantive), one statistical. The substantive concern is that the covariate and the primary independent variable are so inherently tied, that taking out the variance of one will render the other meaningless. The statistical concern is that the two variables are extremely highly correlated, therefore eliminating the variance of one will eliminate the variance of the other.
Inspecting the current study, neither of these key concerns seems to hold. For the substantive concern, although the operationalization of hypocritical blame has κother in it, it is not inherently impossible to think of two participants who have the same (or very similar) κother, but differ substantially in hypocritical blame.
In fact, the comparison between such two participants is the essence of our analysis-do people with the same preference in their own moral behaviors vary in their attitudes and emotions towards their behaviors as a function of how they morally judge those behaviors (or their moral standards)? For the statistical aspect, the correlation between κother and hypocritical blame (0.57) is not in the extremely high range. The variance inflation factor (VIF), an index of collinearity, between the two variable is 1.57, well below the recommended threshold of collinearity, which is 5 
(O'Brien, 2007)
.
To further address the statistical concern, we did some supplementary analysis. Inspecting the scatter plot of κother and hypocritical blame, the two variables are less statistically dependent in the low κother range (e.g., when κother < 0.5). Indeed, the correlation between the two variables is not significant (ρ = -0.27, p = 0.09) in the subset of participants whose κother is smaller than 0.5. This should satisfice the prerequisite of covariate analysis as outlined in 
Miller and Chapman (2001)
. We therefore ran the key partial correlation analysis ("controlling κother") on this subset of participants to test the robustness of our results. We replicated the key correlations findings we reported in the manuscript in this subset of participants 
(Table S3
).


Analysis of the number of harmful and helpful errors
Choice error was defined as the trial where the option with lower subjective value was chosen. Generalized linear mixed effect model was used to examine how the number of choice errors asymmetrically distributed across conditions (Self vs. Other) and choices (harmful vs. helpful). The dependent variable was the number of choice errors in each possible combination of conditions and choices. The independent variables included condition, choice, and their interaction. Participants' κother was included as a covariate. Participant ID was included as a random intercept.
We used partial Spearman correlation to examine the correlations between the harmful and helpful errors in the Other condition and Self condition, on the one hand, and participants' discrepant blame and selfreported conflicted feelings, on the other hand. Participants' κother was included as a covariate. When the correlation was related to the number of harmful errors in the Self condition and Other condition, the number of helpful errors in the Self condition and Other condition, respectively, were also included as covariates. Similarly, when the correlation was related to the number of helpful errors in the Self condition and Other condition, the number of harmful errors in the Self condition and Other condition, respectively, were also included as covariates. 
Figure S1
. Behavioral results of the moral decision-making task. (a) Replicating previous studies using this task, we found that participants were more averse to harming others than for themselves, namely, hyperaltruistic (κother > κself, M = 0.129, standard deviation (s.d.) = 0.265, Wilcoxon Test Z = -3.68, p < 0.001). (b) Distribution of "hyperaltruism" moral preferences (κotherκself) among participants. This 'hyperaltruistic' pattern of behaviors was present in the majority of the participants (42 out of 62, or 68%), resulting in participants paying, on average, an extra 30 pence per shock to prevent shocks to others relative to themselves. As in previous studies (e.g., 
(Crockett et al. 2014
   and supragenual ACC were modulated by participants' hypocritical blame. 
Supplementary Table 1
. Regions in which responses to moral standards (i.e., blameworthiness judgment) is positively correlated with the model-based measure of hypocritical blame.  
Table S1
.


SI figures


Regions
(
M±s.d. = 2.4±1.7; Fig. 2b) and less trustworthy (M±s.d. = 2.2±1.6; Fig. 2c) in the discrepant condition relative to the consistent condition (moral: M±s.d. = 2.8±1.8, t = -2.22, p = 0.028, Cohen's d = 0.24; trustworthy: M±s.d. = 2.9±1.7, t = -3.39, p < 0.001, Cohen's d = 0.42). These findings demonstrate that people ascribe hypocrisy based on a mere behavioral description of a discrepancy between blame and behavior, even in the absence of information about the discrepant blamer's mental state. In addition, people infer that discrepant blamers are less moral and trustworthy than consistent blamers, controlling for the amount of harm inflicted.


Figure 2 .
2
Folk intuitions about hypocritical blame. An independent group of participants (N = 188) judged a protagonist who blamed another person for making the same decision that they made themself to be more hypocritical (a), less moral (b), and less trustworthy (c) than a protagonist who blamed consistently. Red and blue bars indicate means, and dots indicate individual data. Error bars represent s.e.m.


Figure 3 .
3
Definition and distribution of hypocritical blame. Panels (a-d):


Figure 4 .
4
Hypocritical blame is associated with harmful errors during moral decisionmaking and with subsequent conflicted feelings. (a) The choices made by a representative participant in the Other condition. The x-axis indicates trial κ and the y-axis


Figure 5 .
5
Hypocritical blame is associated with stronger neural responses to moral standards. (a) Analysis strategy.


Figure 6 .
6
Hypocritical blame is associated with neural signature of guilt at the time of decision. (a) Schematic illustration of the definition of pattern expression. (b-c) GRBS pattern expression associated with the brain responses to shocks for the receiver (relative to shocks for themselves) is positively correlated both with hypocritical blame (b) and conflicted feeling (c). (d) A mediation analysis provided further evidence that conflicted feeling mediates the relationship between guilt-related processes associated with receiver's harm and hypocritical blame.


)), hyperaltruism (κother -κself) was positively correlated with affective empathy (measured by the QCAE scale, see (Reniers et al. 2011); Spearman's ρ = 0.31, p = 0.013). Error bars indicate s.e.m. *** p < 0.001.


Figure S2 .
S2
After controlling for individual's harm aversion in the Other condition (κother), hypocritical blame was correlated with conflicted feeling (Spearman's ρ = 0.39, t = 3.22, p = 0.002).


Figure S3 .
S3
Dissociable brain response patterns associated with hypocritical blame and decision difficulty. Blue: Decision difficulty, as indicated by the difference in the subjective value of the unchosen option and the chosen option, was correlated with brain activities in bilateral anterior insula and dorsal anterior cingulate cortex/supplemental motor area (dACC/SMA) at the time of decision-making. Yellow: neural responses to the blameworthiness judgment in the bilateral LPFC


standards, neural representations of moral standards should be observable in hypocritical blamers. To test these predictions, we modeled participants' neural activity at decision onset, focusing on the Other condition where participants traded off money for themselves against pain to others, since the equivalent trials in the Self condition would not be considered morally blameworthy. In our first general linear model (GLM 1; see Materials and Methods), decision onsets were modulated by a first-level parametric regressor indicating each participant's own judgments of blameworthiness
next investigated how brain activity during moral decision-making relates to individual
differences in hypocritical blame. If participants' inferences in Study 1 are accurate -that is, if
hypocritical blamers are indeed less moral and trustworthy -then hypocritical blame should be associated with weak or absent neural representations of moral standards. In contrast, if hypocritical blame arises from failing to live up to one's own moral


Many people find decisions like these difficult. On the one hand, if you choose to maximize your profit, you or the Receiver will receive more shocks. On the other hand, the shocks do not cause any tissue damage;the Receiver did, after all, volunteer to participate in this study after being fully informed of the possibility of receiving shocks, and has consented to receiving all possible levels of pain that could be delivered.
Your choices are up to you, and they are completely confidential. The computer will record your decisions
in the task, and this data will not be linked to your name, so the experimenters will not be able to observe
your choices. The Receiver will receive the shocks but will not know what your alternative option was, so
won't be able to know whether you made a helpful or harmful choice. The Receiver will never learn your
identity, and you will never learn the Receiver's identity, because you will exit the building at different times.
This strict confidentiality was required by the Oxford Ethics Committee to approve this study.
Remember, on each trial you will see:
• Whether the shocks are allocated to you or the Receiver
• Your choice options
Use your left index and middle fingers to select the left or right option. In the scanner, you will respond on
a button-box.
You will have a maximum of 6 seconds to make your decision. If the time runs out before you indicate your
choice, that set of options will be presented again later.
use the voltage setting that corresponds to the Receiver's level 8 rating. This accounts for individual
differences in pain tolerance.
Next let's see what the computer screens will look like.


If you think the choice was extremely nasty and deserves a lot of blame, you should respond at the extreme right side of the scale. If you think the choice was not blameworthy at all, you should respond at the extreme left side of the scale.
As the Decider, you made some decisions where you had to trade off money for yourself against shocks for
the Receiver. Today, instead of making decisions, we would like you to make moral judgments about
decisions another person might make on this task.
In today's task, we will present to you a series of decisions in a task similar to the one you completed in the
fMRI scanner. We would like you to judge how blameworthy these decisions are, one at a time. In these
decisions, the money is for the Decider and the shocks are for the Receiver.
To indicate your judgment, we would like you to respond on a scale ranging from not at all blameworthy
to extremely blameworthy. When making your judgments, please consider what you believe to be morally blameworthy, rather than
considering what you would do in the situation.
After you observe each choice, you will use the mouse to indicate your judgment of the choice. Here is what
the screens will look like...


Supplementary Table 2. Correlation analysis after excluding two more participants who might be skeptical of the experimental set up.
Variable
Cluster size (voxels) Spearman's ρ
Hemi t value p value t value MNI coordinates
Conflicted feelings 0.37
3.00
0.004
x
y
z
Superior medial frontal L LPFC* 0.27 cortex R LPFC* 0.30
579
R 2.10 2.35
4.68 0.041 0.022
15
50 2
ACC*
0.38
R 3.07
3.96 0.003
3
56 29
Middle frontal gyrus GRBSΔs
0.32
138
L L 2.53
4.18 4.40 0.014
-9 -24
35 20 56 32
GRBSΔm
0.10
L 0.77
4.25 0.442
-33
35 14
Inferior temporal cortex *Region-of-interest (ROI) beta values were extracted from 27 voxels 216 L 4.00 -33 -4 -25
L surrounding the peak coordinates reported in
4.25
-18
2
-25








Throughout the study you will make a series of decisions like these (approximately 150 trials). However, no shocks will be delivered during the decision-making task.
Instead, at the end of the task, one trial will be randomly selected, and your decision from that trial will be actually implemented. If the selected trial is a "Self" trial, you will receive both the money and the shocks from that trial. If the selected trial is a "Receiver" trial, you will receive the money and the Receiver will receive the shocks from that trial.
Note that only one decision will count "for real", so you do not need to worry about spreading the money or the shocks across the different trials. Since you will not know which trial will count, you should treat each decision as if it were the only one.






Supplemental Online Materials for


Neural and cognitive signatures of guilt predict hypocritical blame
This PDF file includes:


Supplementary Methods
Figs. S1 to S3 Tables S1 to S3 
Supplementary Table 3
. Correlation analysis based on participants with lower κother (< 0.5).  
Table S1
.


Variable
 










Hypocrisy: What counts?




M
D
Alicke






E
Gordon






D
Rose




10.1080/09515089.2012.677397








Philosophical Psychology




26


5
















Saying one thing and doing another": Examining the impact of event order on hypocrisy judgments of others




J
Barden






D
D
Rucker






R
E
Petty








Personality and Social Psychology Bulletin




31


11
















Hypocrisy as Either Deception or Akrasia




C
Bartel








The Philosophical Forum




50


2
















In a very different voice: unmasking moral hypocrisy




C
D
Batson






D
Kobrynowicz






J
L
Dinnerstein






H
C
Kampf






D
Wilson




10.1037/0022-3514.72.6.1335








Journal of Personality and Social Psychology




72


6
















Why Don't Moral People Act Morally? Motivational Considerations




C
D
Batson






E
R
Thompson








Current Directions in Psychological Science




10


2


















10.1111/1467-8721.00114














Moral hypocrisy: Addressing some alternatives




C
D
Batson






E
R
Thompson






H
Chen




10.1037//0022-3514.83.2.330








Journal of Personality and Social Psychology




83


2
















Moral hypocrisy: appearing moral to oneself without being so




C
D
Batson






E
R
Thompson






G
Seuferling






H
Whitney






J
A
Strongman








Journal of Personality and Social Psychology




77


3


525














Guilt: An interpersonal approach




R
F
Baumeister






A
M
Stillwell






T
F
Heatherton




10.1037/0033-2909.115.2.243








Psychological Bulletin




115


2
















The standing to blame: A critique. Blame: Its Nature and Norms




M
Bell




















Conflict monitoring and cognitive control




M
M
Botvinick






T
S
Braver






D
M
Barch






C
S
Carter






J
D
Cohen








Psychological Review




108


3


624














The roots of modern justice: cognitive and neural foundations of social norms and their enforcement




J
W
Buckholtz






R
Marois








Nature neuroscience




15


5
















From blame to punishment: disrupting prefrontal cortex activity reveals norm enforcement mechanisms




J
W
Buckholtz






J
W
Martin






M
T
Treadway






K
Jan






D
H
Zald






O
Jones






R
Marois








Neuron




87


6
















The lateral prefrontal cortex and moral goal pursuit




R
W
Carlson






M
J
Crockett








Current Opinion in Psychology




24
















Harm to others outweighs harm to self in moral decision making




M
J
Crockett






Z
Kurth-Nelson






J
Z
Siegel






P
Dayan






R
J
Dolan




10.1073/pnas.1408988111








Proceedings of the National Academy of Sciences




111


48
















Moral transgressions corrupt neural representations of value




M
J
Crockett






J
Z
Siegel






Z
Kurth-Nelson






P
Dayan






R
J
Dolan








Nature Neuroscience




20


6


















10.1038/nn.4557














Dissociable Effects of Serotonin and Dopamine on the Valuation of Harm in Moral Decision Making




M
J
Crockett






J
Z
Siegel






Z
Kurth-Nelson






O
T
Ousdal






G
Story






C
Frieband






J
M
Grosse-Rueskamp






P
Dayan






R
J
Dolan








Current Biology




25


14


















10.1016/j.cub.2015.05.021














The walk and the talk




D
Dover








Philosophical Review




128


4
















From inconsistency to hypocrisy: When does "saying one thing but doing another" invite condemnation? Research in Organizational Behavior




D
A
Effron






K
O'connor






H
Leroy






B
J
Lucas








38














Resolving emotional conflict: a role for the rostral anterior cingulate cortex in modulating activity in the amygdala




A
Etkin






T
Egner






D
M
Peraza






E
R
Kandel






J
Hirsch








Neuron




51


6
















Empathic concern drives costly altruism




O
Feldmanhall






T
Dalgleish






D
Evans






D
Mobbs








Neuroimage




105
















What we say and what we do: The relationship between real and hypothetical moral choices




O
Feldmanhall






D
Mobbs






D
Evans






L
Hiscox






L
Navrady






T
Dalgleish




10.1016/j.cognition.2012.02.001








Cognition




123


3
















Temporal dynamics of guilt: changes in the role of interpersonal and intrapsychic factors




T
J
Ferguson






T
Oothof






H
Stegge








European Journal of Social Psychology




27


6


















10.1002/(SICI)1099-0992(199711/12






27






6%3C659::AID-EJSP837%3E3.0.CO;2-K/abstract








Hypocrisy and the Standing to Blame




K
G
Fritz






D
Miller








Pacific Philosophical Quarterly




99


1
















Back to the future of dissonance theory: Cognitive consistency as a core motive




B
Gawronski








Social Cognition




30


6
















Moral foundations theory: The pragmatic validity of moral pluralism




J
Graham






J
Haidt






S
Koleva






M
Motyl






R
Iyer






S
P
Wojcik






P
H
Ditto








Advances in experimental social psychology




Elsevier




47
















J
Graham






P
Meindl






S
Koleva






R
Iyer






K
M
Johnson




10.1111/spc3.12158




When Values and Behavior Conflict: Moral Pluralism and Intrapersonal Moral Hypocrisy. Social and Personality Psychology Compass






9














Guilt-selective functional disconnection of anterior temporal and subgenual cortices in major depressive disorder




S
Green






M
A L
Ralph






J
Moll






J
F W
Deakin






R
Zahn








Archives of General Psychiatry




69


10
















Practicing what you preach" backfires by increasing anticipated devaluation




L
C
Howe






B
Monin








Journal of Personality and Social Psychology




112


5


718








Healthier than thou?








A neurocomputational model of altruistic choice and its implications




C
A
Hutcherson






B
Bushong






A
Rangel








Neuron




87


2
















Causal mediation analysis using R




K
Imai






L
Keele






D
Tingley






T
Yamamoto








Advances in social science research using R




Springer
















Why self-control seems (but may not be) limited




M
Inzlicht






B
J
Schmeichel






C
N
Macrae








Trends in Cognitive Sciences




18


3
















Religiosity, altruism, and altruistic hypocrisy: Evidence from Protestant adolescents




C.-H
C
Ji






L
Pendergraft






M
Perry








Review of Religious Research


















Why do we hate hypocrites? Evidence for a theory of false signaling




J
J
Jordan






R
Sommers






P
Bloom






D
G
Rand








Psychological Science




28


3
















On hypocrisy




E
F
Kittay








Metaphilosophy




13


3-4
















Integration of error agency and representation of others' pain in the anterior insula




L
Koban






C
Corradi-Dell'acqua






P
Vuilleumier








Journal of Cognitive Neuroscience




25


2
















What makes hypocrisy? Folk definitions, attitude/behavior combinations, attitude strength, and private/public distinctions




S
M
Laurent






B
A M
Clark








Basic and Applied Social Psychology




41


2
















Self-blame-selective hyperconnectivity between anterior temporal and subgenual cortices and prediction of recurrent depressive episodes




K
E
Lythe






J
Moll






J
A
Gethin






C
I
Workman






S
Green






M
A L
Ralph






J
F W
Deakin






R
Zahn








JAMA Psychiatry




72


11
















Hypocrisy, with a note on integrity




C
Mckinnon








American Philosophical Quarterly




28


4
















Akratic feelings




A
R
Mele








Philosophy and Phenomenological Research




50


2
















Holy masquerade: Hypocrisy in religion




D
O
Moberg








Review of Religious Research


















Moral hypocrisy, moral inconsistency, and the struggle for moral integrity




B
Monin






A
Merritt


















Moral cleansing as hypocrisy: When private acts of charity make you feel better than you deserve




K
O'connor






D
A
Effron






B
J
Lucas








Journal of Personality and Social Psychology
















Guilt in response to blame from others




B
Parkinson






S
Illingworth








Cognition and Emotion




23


8
















Inferring mental states from neuroimaging data: from reverse inference to largescale decoding




R
A
Poldrack








Neuron




72


5
















Neurocomputational mechanisms at play when weighing concerns for extrinsic rewards, moral values, and social image




C
Qu






E
Météreau






L
Butera






M
C
Villeval






J.-C
Dreher








PLoS Biology




6


17














A framework for studying the neurobiology of valuebased decision making




A
Rangel






C
Camerer






P
R
Montague








Nature Reviews Neuroscience




9


7


















10.1038/nrn2357














The neurobiology of rewards and values in social decision making




C
C
Ruff






E
Fehr








Nature Reviews Neuroscience




15


8
















The theory of dyadic morality: Reinventing moral judgment by redefining harm




C
Schein






K
Gray








Personality and Social Psychology Review
















Neural mechanisms underlying motivation of mental versus physical effort




L
Schmidt






M
Lebreton






M.-L
Cléry-Melin






J
Daunizeau






M
Pessiglione








PLoS Biology




2


10














Ordinary vices




J
N
Shklar








Harvard University Press












Inferences about moral character moderate the impact of consequences on blame and praise




J
Z
Siegel






M
J
Crockett






R
J
Dolan








Cognition




167


















10.1016/j.cognition.2017.05.004














Hypocrisy, Change of Mind, and Weakness of Will: How to Do Moral Philosophy with Examples. Metaphilosophy




B
Szabados






E
Soifer




10.1111/1467-9973.00112








30














Hypocrisy: ethical investigations




B
Szabados






E
Soifer








Broadview Press












Moral emotions and moral behavior




J
P
Tangney






J
Stuewig






D
J
Mashek








Annu. Rev. Psychol




58
















A unified account of the moral standing to blame




P
Todd








Noûs




53


2


















N
Tognazzini






D
J
Coates






Blame. Stanford Encyclopedia of Philosophy
















Moral hypocrisy: social groups and the flexibility of virtue




P
Valdesolo






D
Desteno








Psychological Science
















The computational and neural substrates of moral strategies in social decision-making




J
M
Van Baar






L
J
Chang






A
G
Sanfey








Nature Communications




10


1
















The neuroscience of moral cognition: From dual processes to dynamic systems




J
J
Van Bavel






O
Feldmanhall






P
Mende-Siedlecki








Current Opinion in Psychology




6
















Harm to self outweighs benefit to others in moral decision making




L
J
Volz






B
L
Welborn






M
S
Gobel






M
S
Gazzaniga






S
T
Grafton








Proceedings of the National Academy of Sciences




114


30
















An fMRI-based neurologic signature of physical pain




T
D
Wager






L
Y
Atlas






M
A
Lindquist






M
Roy






C.-W
Woo






E
Kross








New England Journal of Medicine




368


15
















Hypocrisy, moral address, and the equal standing of persons




R
J
Wallace








Philosophy & Public Affairs




38


4
















Building better biomarkers: brain models in translational neuroimaging




C.-W
Woo






L
J
Chang






M
A
Lindquist






T
D
Wager








Nature Neuroscience




20


3


365














The emotional and attitudinal consequences of religious hypocrisy: Experimental evidence using a cognitive dissonance paradigm




O
Yousaf






F
Gobet








The Journal of Social Psychology




153


6
















The voice of conscience: neural bases of interpersonal guilt and compensation




H
Yu






J
Hu






L
Hu






X
Zhou








Social Cognitive and Affective Neuroscience




9


8


















10.1093/scan/nst090














A generalizable multivariate brain pattern for interpersonal guilt




H
Yu






L
Koban






L
J
Chang






U
Wagner






A
Krishnan






P
Vuilleumier






X
Zhou






T
D
Wager








Cerebral Cortex




30


6
















The Neural Basis of Human Social Values: Evidence from Functional MRI




R
Zahn






J
Moll






M
Paiva






G
Garrido






F
Krueger






E
D
Huey






J
Grafman




10.1093/cercor/bhn080








Cerebral Cortex




19


2
















The prefrontal cortex and (uniquely) human cooperation: a comparative perspective




Y
Zoh






S
W
Chang






M
J
Crockett








Neuropsychopharmacology




47


1
















On each trial you will see two options with different amounts of shocks for the Receiver and money for the












The more harmful option (the one with more shocks) will always be selected




Decider








We are interested in








In this model, as in GLM 1, BOLD signals were regressed against 4 critical regressors containing the onsets of Self trials where the left (i) or right (ii) option was selected, and Other trials where the left (iii) or right (iv) option was selected. Duration of these 4 regressors was set to the participant's reaction time on that trial (i.e., the interval between the presentation of options and button press). For each regressor, we included a parametric modulator that contained the relative value on that trial






GLM to obtain for each participant a brain response map of trial-wise relative value (i.e., absolute subjective value difference between the two potions)






We included regressors of no interest corresponding to onsets of button presses, cue for transitions between conditions, and missing trials, as well as 6 nuisance regressors to control for head motion. Brain response to decision difficulty was defined as the negative effect of the relative value parametric modulator (Fig. S3)









"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]