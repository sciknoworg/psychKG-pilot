You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1â€“3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
decision-maker's awareness. 
24
 In the intelligence context, they undermine the requirement for policy neutrality. 
25
 Intelligence organizations have naively assumed that they can quash the unruliness of linguistic probabilities simply by stating their intended meaning. 
26
 Yet ample research shows that when people have direct access to a translation table, a large proportion still interprets linguistic expressions inconsistently with the prescribed meanings. 
27
 These findings have been shown in the domain of climate science and, more recently, intelligence production. 
28
 Noting the abysmal rates of shared understanding when probability lexicons are provided, researchers have recommended that numeric ranges be reported alongside linguistic probabilities in assessments. 
29
 However, this approach has yielded only modest improvements in shared understanding. 
30
 It also risks miscommunication because readers could easily interpret such intervals as issue-specific credible intervals rather than clarifications of the meaning of the associated terms.
The intelligence community's recognized need to clarify linguistic probabilities with numeric ranges calls their use into question. Decision-makers want useful (i.e., timely, relevant, and accurate) information to support their decisions; they don't wish to be reminded repeatedly what probability terms should mean to them when consuming intelligence. Any standard that encourages analysts to express anything other than their best probability estimate for the event being judged is suboptimal. In place of linguistic probabilities, analysts should be encouraged to assign numeric probability intervals, which can be as precise as is appropriate under the circumstances. For instance, an analyst could provide a credible interval of 65-85% that a given event will occur (or that a given claim is true). This signifies clearly that the probability is believed to lie between 65% and 85%. Presented with such an interval, one can easily derive a best


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
estimate from the midpoint (i.e., 
[65 + 85]
/2) and an associated margin of error (i.e., 
[85 -65]
/2), in this case yielding an equivalent point estimate of 75% plus or minus 
10%. 31
 This mode of uncertainty communication would address most of the issues hitherto identified. Numeric probability intervals would help clarify the analyst's assessment and attenuate the vagueness intrinsic in linguistic uncertainty expressions. 
32
 This would diminish the impact of inter-standard inconsistencies and linguistic or cultural barriers, thereby promoting interoperability. Of course, numeric probabilities are not perfectly transparent. People vary in their assumptions about distributions underlying numeric intervals. 
33
 Numeric quantifiers can also be ambiguous and contextdependent. 
34
 Nevertheless, compared to linguistic probabilities, numeric probabilities are far less susceptible to context effects and elastic redefinition. 
35
 Unlike linguistic probabilities, numeric probabilities have a transparent ordering that users agree upon.
Numeric probabilities also enable analysts to convey extreme probabilities with as much precision as warranted. They do not force a collapse of the base-10 logarithmic scale to a single value such as "remote chance," as current standards do.


Confusion over Confidence
Another shortcoming of the intelligence community's approach to uncertainty handling is its treatment of analytic confidence. Current standards require analysts to convey their confidence using coarse ordinal ratings that usually have low, medium, and high levels. 
36
 Perhaps worse, analysts are usually instructed to assess probability and confidence as if they were independent constructs. Such standards fail to explain that confidence is a second-order judgment of uncertainty capturing one's subjective margin of error in a probabilistic estimate. 
37
 That is, the less confident analysts are in their estimates, the wider their credible intervals should be. An analyst who believes the probability of an event lies between 50% and 90% (i.e., 70% plus or minus 20%) is less


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
confident than an analyst who believes that the probability lies between 65% and 75% (i.e., 70% plus or minus 5%). The analyst providing the wider margin of error plays it safer than the analyst providing the narrower interval, presumably because the former is less confident than the latter. If this weren't true, the former analyst would be imposing an unfair cost on the end-user since increasing imprecision reduces informativeness. 
38
 Current standards send mixed messages about confidence. When analysts select a probability phrase, the numeric range given in a lexicon could be misinterpreted as a confidence interval. Since decision-makers are presumably more interested in the substantive issues covered in an intelligence report than how the meanings of vague words are resolved, they might misinterpret the ranges. Advice to analysts to treat confidence ratings as independent of probability assessments also can yield nonsensical estimates at both ends of the probability scale. For instance, if a judgment of highly likely, interpreted as "more than 90%" in the NATO standard, is made with low confidence, the only way to translate the confidence level into variation of the stipulated range (90-100%) is to go downwards. This is almost certain to confuse decision-makers.
Historical evidence shows that intelligence practitioners misunderstand the probability-confidence dissociation. In the 2007 NIE on Iranian nuclear capabilities, probabilistic expressions (e.g., probably, unlikely) are said to "reflect the 
[Intelligence]
 Community's estimates of the likelihood of developments or events." 39 Meanwhile, confidence levels indicate the extent to which "assessments and estimates are supported by information that varies in scope, quality and sourcing." 40 Despite this guidance being prominently featured in the product, Friedman and Zeckhauser observed 19 instances in the declassified key judgments section where "confidence" is used to express probability, rather than qualify it. 
41
 At no point in the key judgments are expressions of


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
probability and confidence used to jointly characterize uncertainty as officially intended. 
42
 Decision-makers also seem to find the current distinction confusing and would benefit from a unified quantitative expression of probability and confidence. For instance, during a 2013 US congressional hearing, Rep. Doug Lamborn inadvertently disclosed a line from a Defense Intelligence Agency (DIA) assessment stating, "DIA assesses with moderate confidence the North [Korea] currently has nuclear weapons capable of delivery by ballistic missiles." 43 According to DIA standards from the time, moderate confidence meant: "partially corroborated information from good sources, several assumptions, and/or a mixture of strong and weak inferences." 44 Despite this guidance, several hearing members dismissed the assessment outright, apparently assuming that judgments issued with less than high confidence could be disregarded. 
45
 Nor do quantitative assessments preclude clear prose explaining the bases for judgment. Explanation is vital to intelligence since without it, a decision-maker would not know how the particular assessment was reached. Numeric assessments and clear explanations should work together to yield effective intelligence. Offering a useful template for intelligence narratives about analytic confidence, Friedman and Zeckhauser propose three central components: 1) the reliability of evidence supporting an assessment; 2) the range of reasonable opinion surrounding an assessment; and 3) the extent to which analysts believe an assessment could change given additional information. 
46
 Forecasters reliably discriminated between these components and decision-makers used them reliably. 47 Therefore, analysts might benefit from training that exposes them to frameworks for thinking systematically about these components of confidence. On the job, analysts could be incentivized to provide rationales outlining how these considerations shaped the width of their credible intervals. This approach


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
should improve accountability, facilitating post-mortem analyses that gauge the degree to which analysts were miscalibrated. It could also help consumers decide whether to act on intelligence or to task additional collection and analytic capabilities. 48


UNCERTAINTY COMMUNICATION REFORM


Why It's Needed
Intelligence producers and consumers are periodically required to combine multiple probabilistic estimates. 
49
 For instance, averaging is relevant when consumers must integrate assessments from multiple advisors. As a case study of President Barack Obama's decision-making during the search for Osama bin Laden highlighted, Obama was frustrated by the disparate set of estimates he received. 50 Such frustration might have been alleviated had the estimates been conveyed as an average with a margin of error. The ability to multiply probability estimates can play a vital role in estimating the conjunctive probability of threat scenarios that require multiple necessary conditions to be met for the threat to manifest. For example, analysts might assess the probability of a terrorist attack based on the product of the individual probabilities of adversarial intent, adversarial capability, and one's own vulnerability to attack. Methods, such as interval analysis, permit arithmetic operations with numeric intervals to be easily computed. 
51
 In contrast, fuzzy-logic methods enabling arithmetic operations on linguistic probabilities require considerable knowledge about how the sender interprets these probabilities. 
52
 This approach is infeasible and has not been applied in intelligence practice. Nor are people adept at averaging or multiplying linguistic probabilities. In recent experiments, people were more accurate and coherent when averaging and multiplying probabilities if they were presented numerically rather than linguistically. 
53
 


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
Numeric probabilities also have advanced applications. They support Bayesian networks, through which analysts can coherently pool and revise judgments. 54 Numeric probabilities would also allow intelligence organizations to exploit accuracy-boosting post-analytic methods that can be applied to judgments from one or more analysts.
Unlike structured analytic techniques that attempt to debias the analyst prior to and during assessment, post-analytic methods improve the quality of assessments after they are made. 
55
 For example, numeric estimates can be mathematically recalibrated to correct for observable biases such as underconfidence or overconfidence. 56 They can also be recalibrated so that they are coherent, respecting axioms of probability calculus, a process that also improves accuracy. Barnes observed superb accuracy coupled with substantial underconfidence (i.e., analysts assigned more uncertainty than required given their high degree of accuracy), which was correctable through a recalibration procedure. 61 Such monitor-and-adjust procedures support active organizational learning. In contrast, intelligence communities currently lack the means of objectively, systematically, and proactively measuring the quality of analytic judgment. 
62
 They instead rely on process-based accountability


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
procedures that direct analysts to "be accurate" or to use structured analytic techniques, which research suggests may be unhelpful if not outright detrimental. 
63
 In short, using numeric probabilities would not only improve uncertainty communication, it would improve the quality of intelligence analysis and intelligence oversight.


Obstacles
Given the shortcomings of the current approach to uncertainty communication and the clear benefits of using numeric probabilities, why hasn't effective reform happened? In part, organizational inertia reflects the fact that most intelligence consumers have limited time in office, finite political capital, and crowded agendas. 
64
 Efforts to tackle intelligence-community esoterica deplete resources and promise little in the way of electoral payoff. 
65
 High turnover of elected officials also ensures short collective memory; practitioners can count on mistakes being forgotten without having to modify their tradecraft. 
66
 Even when commissions are expressly tasked with intelligence reform, they often lack the requisite knowledge base, resulting in superficial solutions. 
67
 The introduction of embedded translation guides that gloss over the fundamental problems of vague and leading language while introducing new avenues for error is a case in point.
Similar factors impede reform driven internally by intelligence practitioners. 
68
 As a former intelligence director, Alan Barnes required the use of numeric probabilities among his analysts. 
69
 While Barnes found that skeptical analysts quickly adapted to their use, his reforms were abandoned after his retirement, and applications of his approach in other parts of the Canadian intelligence community have been partial, modified in questionable ways, and generally short-lived. 
70
 James Marchio described a similar experience at DIA, where internal support for numeric probabilities rose in the


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
1970s (coinciding with increased demand from consumers) but then lost momentum following turnover of agency leadership. 
71
 While leadership turnover and resource constraints impede meaningful reform in most large bureaucracies, these factors are compounded, in the US at least, by the fragmented and adversarial nature of the federal system. 
72
 Examining 14 major reviews of the intelligence community conducted between 1947 and 2005, 
Warner and
 McDonald found that only four produced noteworthy organizational change. 
73
 Substantive reform was generally contingent on sustained support from the White House and/or Congress; concurrent studies endorsed by present and future leaders of the intelligence community; and a war or crisis serving as a catalyst. 
74
 Even when these conditions were met, reforms were modest compared to what was originally proposed, reflecting the abundance of veto players and the depth of partisan division. 
75
 Beyond these institutional barriers, intelligence producers and consumers alike may view it in their best interests to sacrifice epistemic quality in intelligence to better serve other pragmatic goals. 
76
 For consumers, linguistic probabilities provide wiggle room to interpret intelligence estimates in ways that align with their policy preconceptions and preferences-and if things go wrong, they have the intelligence community to blame for its lack of clarity. 
77
 Historically, intelligence consumers have exploited imprecision to justify decisions and deflect blame when they produced negative outcomes. 
78
 
79
 After the Iraq Survey Group failed to locate any WMD, decision-makers scapegoated the intelligence community by reframing its fuzzy conclusions as overconfident. 
80
 When the


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
intelligence community accurately characterizes uncertainty and forces consumers to consider alternative outcomes, it undermines their ability to oversell policies. 
81
 The imperatives of leadership survival may clash with the intelligence community's oftcited mission to "speak truth to power," and can create perverse incentives for vague communication.
Self-interested intelligence producers may also believe that they benefit from the interpretive flexibility afforded by linguistic probabilities. 
82
 By hedging their estimates, analysts can effectively avoid falsification; an estimate that a focal event could happen cannot be found definitively "wrong." 
83
 Many of the forecasts that Mandel and Barnes excluded from their quantitative analyses of accuracy were removed for this reason. 
84
 This self-protective strategy is not unique to the intelligence domain, nor is it irrational, given the tendency of some consumers to shoot the messenger when estimates are carefully qualified or misaligned with their policy preferences. 
85
 Several studies challenge conventional wisdom that fuzzy estimates shield analysts from blame.
Dieckmann and colleagues observed that, when dealing with higher probability events, decision-makers rated judgments qualified with numeric uncertainty ranges as more useful and credible than those without. 
86
 Other studies find that erroneous judgments expose analysts to less criticism when communicated numerically than linguistically, although the relation between communication format and credibility is moderated by other factors. 
87
 In sum, using linguistic probabilities to deflect blame is a tactic that often backfires.
Intelligence directors may similarly resist reforms that expose their units to outcome-based accountability metrics. 
88
 Generally speaking, intelligence organizations are wary of any mechanism that facilitates objective evaluation, especially if it exposes inferior performance relative to rival agencies. 
89
 This anxiety is pronounced in the US


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
intelligence community, where intelligence functions are split between 17 agencies, resulting in zero-sum "turf wars" over resources and jurisdiction. 
90
 Charged with ensuring analytic quality across the community, ODNI maintains a parochial focus on process, such as promoting compliance with prescribed analytic methods and issuing goal directives without specifying viable means of achieving them, rather than outcome accountability, which would involve tracking judgment accuracy. 
91
 This may reflect the fact that assessing accuracy can bureaucratically threaten intelligence agencies and sow discord between them. 
92
 In the intelligence community and beyond, the imperative to deflect blame drives organizations to embed defensive tactics (e.g., the use of vague linguistic probabilities) into their standard operating procedures. 
93
 Similar forces contribute to institutional isomorphism, the tendency of bureaucracies towards homogenization in terms of structure and output. 
94
 Isomorphism is pronounced in organizational fields characterized by ambiguous goals and uncertain operating environments-two defining features of intelligence. 95 According to this explanation, linguistic probabilities are not the prevalent mode of uncertainty communication across the intelligence community due to their effectiveness but because no agency wants to draw scrutiny by deviating from established protocols.


Correcting Correctable Ignorance
Organization inertia also reflects widespread but correctable ignorance regarding the shortcomings of existing methods, the risks that they pose to decision quality, and the Kent identified forecasts as the most important type of estimate the intelligence community could deliver to policymakers. 
101
 Numeric probability intervals are equally applicable whether referring to past, present, or future states of the world under conditions of epistemic uncertainty; there is no situation in which an analyst can coherently provide a linguistic probability but not a numeric one. 
102
 That said, there are reasonable bases for practitioners' discomfort with numeric probabilities. Assigning numeric probabilities requires more mental effort than assigning linguistic probabilities. People regularly use linguistic probabilities to signal intent. It is not only harder to determine that one has an 80% probability or even a 60-80% chance of going to a meeting than to judge it likely, it may also feel unnecessary to


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
expend the additional effort. The speaker may intend likely to mean little more than "I think I will go, but I am not sure." When this level of precision suffices, there are arguments for using linguistic probabilities. 
103
 Certain situations in intelligence production may fall into this category, but most don't. It is implausible that the cases where greater precision, granularity, and clarity are warranted are so few in number and collectively so inconsequential as to merit the continuation of the current approach.
Compounding the intelligence community's misunderstanding of probabilities is the widespread belief that intelligence consumers prefer linguistic probabilities, or alternatively, that they are unable to make effective use of numeric estimates. 
104
 While declassified intelligence products reveal a strong institutional preference for communicating probabilities linguistically, the claim that this reflects widespread consumer preferences relies heavily on anecdotal evidence. 
105
 Studies show that people generally prefer to communicate probabilistic information linguistically, but that they also prefer to receive it numerically. 
106
 These preferences are exhibited across a range of expert judgment communities, but are particularly pronounced when judgments are based on unreliable or incomplete information, as is characteristic of intelligence analysis. 
107
 Experiments conducted in the context of intelligence forecasting indicate that decision-makers are not averse to numeric probability ranges and can reliably detect subtle differences between numeric estimates, even when devoting limited effort to the task. 
108
 Concerns that numeric expressions render consumers overconfident and excessively risk seeking also lack empirical support. In one study, national security officials receiving numeric probability assessments were less prone to support risky actions and more amenable to gathering additional information prior to decisionmaking. 109


UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE


CONCLUSION
Extensive research has shown that linguistic probabilities are inherently vague, they convey implicit recommendations, and they serve other pragmatic functions that can mar the integrity of policy-neutral assessments aimed at supporting sound decisionmaking. The mandated dissociation of probability and confidence assessments also undermines communication fidelity and fosters an incoherent understanding of the relation between these distinct, but related concepts. A quantitative approach to uncertainty communication that uses numeric probability intervals complemented with written rationales would be more informative and less vulnerable to misinterpretation (accidental or deliberate). Numeric probabilities would also enable intelligence agencies to objectively monitor their forecasting accuracy and leverage a suite of accuracyboosting techniques, with downstream benefits for decision-making quality.
Despite the strong empirical case for using numeric probabilities, persistent barriers to intelligence reform remain. Political and bureaucratic realities constrain prospective reformers and foster a cynical, risk-averse culture. The status quo also persists due to ignorance about uncertainty, which manifests itself in a variety of erroneous claims about uncertainty that go unchallenged inside the intelligence community's cultural echo chamber. The intelligence community now operates in a post-Moneyball, post-FiveThirtyEight world. It faces growing competition from alternative information brokers that are exploiting forecasting science to make sophisticated predictions. 110 If the intelligence community hopes to maintain its analytic relevance this century, it must provide unique and actionable insights. A clear sign of added value is intelligence that is as precise, granular, accurate, and informative as the evidence warrants. The proposal to use numeric probability ranges supplemented with clear explanatory text would support those objectives.
57 Further research shows how combining postanalytic methods can boost intelligence analysts' accuracy, whereas much-touted intelligence methods like Analysis of Competing Hypotheses paled in comparative effectiveness. 58 Numeric probabilities also enable systematic monitoring of assessment accuracy based on well-established quantitative scoring rules. 59 These measures provide an audit trail for assessments and discourage play-it-safe tactics by incentivizing accuracy. 60 Accuracy monitoring empowers intelligence organizations to identify areas for improvement and permits empirical validation of corrective policies. For instance, in an analysis of the accuracy of six years of classified intelligence forecasts, Mandel and


viability of alternative modes of uncertainty communication. People generally have trouble acquiring a sound understanding of probabilistic concepts-experts (including those routinely dealing with uncertain estimates) aren't exempt from statistical illiteracy. 96 Most objections raised by such experts to using numeric probabilities belie UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE popular misconceptions about probability and their bearing on decision quality. 97 A common dissent is the "false precision" argument. Since Kent first proposed pairing linguistic expressions with numeric equivalents, critics have insisted that communicating judgments with numbers exaggerates precision and wrongly implies scientific rigor. 98 Former US Deputy Secretary of State James Steinberg conveyed this view when he cautioned, "I am somewhat skeptical of what I believe is a false sense of correctness implied by assigning numerical probabilities to individual events." 99 Variants of the false precision argument also arise in intelligence studies, and in other fields resistant to numeric probability expressions, such as medicine. 100 Proponents of such arguments seem unaware (or unwilling to admit) that uncertainty may be quantified with varying degrees of precision. An offshoot of the false precision argument is the claim that numbers are inappropriate because not all analytic judgments are forecasts. This is a strawman argument. No one claims otherwise, although Mandel and Barnes found that threequarters of judgments made in strategic intelligence reports were in fact forecasts, and


For example, in building a case for the invasion of Iraq, US decision-makers made conclusive claims about Saddam Hussein's WMD programs based on vague intelligence estimates, particularly those presented in the 2002 NIE Iraq's Continuing Programs for Weapons of Mass Destruction.


 Friedman, Lerner, and Zeckhauser, "Behavioral Consequences."   110  Marcos Degaut, "Spies and Policymakers: Intelligence in the Information Age," Intelligence and NationalSecurity, Vol.31, No.4 (2015): pp.509-31.








Funding information: This work was supported by the Canadian Safety and Security Program under Project #2018-TI-2394 (Decision Science for Superior Intelligence Production).
 










Words of Estimative Probability




Sherman
Kent














in Sherman Kent and the Board of. see also discussion of intelligence "batting averages" in Richard K








Enemies of Intelligence: Knowledge and Power in American National Security




Betts








Columbia University Press


New York
















Karvetski
Mandel






Dhami








Boosting Intelligence












The Efficacy of ACH in Mitigating Serial Position Effects and Confirmation Bias in an Intelligence Analysis Scenario




Martha
Whitesmith








Intelligence and National Security




34


2
















The 'Analysis of Competing Hypotheses' in Intelligence Analysis




K
Mandeep






Ian
K
Dhami






David
R
Belton






Mandel








Applied Cognitive Psychology




33


6
















Improving Probability"; for analysis




Mandel
Karvetski






Irwin
;






Chang








Restructuring




Mandel






Occasional Maverick








September 11 and the Adaptation Failure of U.S. Intelligence Agencies




Amy
B
Zegart








International Security




29


4




















Ibid














The Intelligence of Fear




John
A
Gentry








Intelligence and National Security




32


1
















A Shock Theory of Congressional Accountability for Intelligence




K
Loch






Johnson




Loch K. Johnson








New York: Routledge






Handbook of Intelligence Studies








Toward a Revolution in Intelligence Affairs




Deborah
G
Barger








Santa Monica, CA






RAND National Security Research Division
















Michael
Warner






J














US Intelligence Community Reform Studies Since




Kenneth
Mcdonald








Center for the Study of Intelligence


Washington, DC
















Mcdonald
Warner






;
Us Intelligence






"
Marchio






Weatherman














Making Intelligence




Barnes














Variants




Ibid






David
R
Irwin






Mandel




















UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
















Zegart




















Mcdonald
Warner






Us Intelligence


















Ibid














Intelligence Reform and the Politics of Entrenchment




Ibid






A
Michael






Turner








International Journal of Intelligence and CounterIntelligence




18


3
















The Intelligence Reform Quandary




Robert
D
Vickers








International Journal of Intelligence and CounterIntelligence




19


2
















Why is the Intelligence Community so Difficult to Redesign? Smart Practices, Conflicting Goals, and the Creation of Purpose Based Organizations




H
Thomas






Hammond








Governance




20


3
















The Struggle to Reform Intelligence After 9/11




J
Richard






James
A
Harknett






Stever








Public Administration Review




71


5
















Social Functionalist




Tetlock














Motivated Reasoning




Piercey


















Gentry








Intelligence of Fear
















War
Friedman






Chance


















Assessing Intelligence Performance




John
A
Gentry








The Oxford Handbook of National Security Intelligence


Loch K. Johnson


New York




Gentry




















War
Friedman






Chance






















War
Friedman






Chance






















Ibid


















How Bad Things Happen to Good Analysts




Jack
Davis








Analyzing Intelligence: Origins, Obstacles, and Innovations


nd ed., ed. Roger Z. George and James


Washington, DC




Georgetown University Press




2














Why Intelligence and Policymakers Clash




Robert
Jervis








Political Science Quarterly




125


2


















Joshua
Rovner




Fixing the Facts: National Security and the Politics of Intelligence


Ithaca, NY




Cornell University Press
















Why Presidents Sometimes Do Not Use Intelligence Information




Patrick
S
Roberts






Robert
P
Saldin








Political Science Quarterly




131


4
















Superforecasting: The Art and Science of Prediction




Philip
E
Tetlock






Dan
Gardner








Crown Publishers/Random House




New York












Use and Communication of Probabilistic Forecasts




Adrien
E
Raftery








Statistical Analysis and Data Mining




9


6
















Here (Very Likely) Be Dragons: The Challenges of Strategic Forecasting




Rex
Brynen








Strategic Analysis in Support of International Policy Making: Case Studies in Achieving Analytical Relevance


Thomas Juneau


Lanham, MD




Rowman & Littlefield
















Intelligence of Fear




Gentry




















UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE
















Ibid


















Barnes
Mandel








Accuracy












Geopolitical Forecasting




Barnes
Mandel














Tribal Tongues: Intelligence Consumers, Intelligence Producers




M
Mark






Lowenthal








The Washington Quarterly




15


1




















Philip
E
Tetlock






Barbara
A














Intelligent Management of Intelligence Agencies: Beyond Accountability Ping-Pong




Mellers








The American Psychologist




66


6




















Gentry








Intelligence of Fear












Why Strategic Intelligence Analysis has Limited Influence on American Foreign Policy




Stephen
Marrin








Intelligence and National Security




32


6
















Effects




Mauro
Dieckmann






Slovic














Maintaining Credibility When Communicating Uncertainty: The Role of Communication Format




Sarah
C
Jenkins






Adam
J L
Harris






R
Murray
Lark








Proceedings of the 39th Annual Conference of the Cognitive Science Society


Glenn Gunzelmann, Andrew Howes, Thora Tenbrink, and Eddy J. Davelaar


the 39th Annual Conference of the Cognitive Science Society
London




Cognitive Science Society
















When Unlikely Outcomes Occur: The Role of Communication Format in Maintaining Communicator Credibility




Sarah
C
Jenkins






Adam
J L
Harris






R
Murray
Lark








Journal of Risk Research: Cambridge 'Risk and Uncertainty' Conference Special Issue




22


5




















War
Friedman






;
Chance






Mandel
Collins








Cultivating Credibility




















C
Sarah






Adam
J
Jenkins














Maintaining Credibility when Communicating Uncertainty: The Role of Directionality




L
Harris








Thinking & Reasoning


















Intelligence of Fear




Gentry














US Intelligence and its Future: Aligning with a New and Complex Environment




Ibid






William Nolte








Intelligence and National Security




34


4




















Zegart
















A Cultural Evolution




Robert
Cardillo








Studies in Intelligence




54


2










Intelligent Management. Gentry, "The Intelligence of Fear








Has the ODNI Improved U.S. Intelligence Analysis?




John
A
Gentry








International Journal of Intelligence and CounterIntelligence




28


4










Gentry, "Intelligence of Fear








] run the risk of conveying to the policy client a degree of precision that does not exist




Christopher
Hood








The Blame Game: Spin, Bureaucracy, and Self-Preservation in Secrets to Policy, warns that numeric probabilities "may be more satisfying than words






5








Decision Maker, Quantify Thyself!












Danielle
R














Lost for Words: Using Verbal Terms to Express Probabilities in Oral Radiology




M
Timmermans






Philip
A
Mileman








Dento Maxillo Facial Radiology




22


4




















Kent








Words












Accuracy




Barnes
Mandel


















War
Friedman






Chance






67












Processing Linguistic Probabilities: General Principles and Empirical Evidence




Thomas
S
Wallsten






David
V
Budescu








Psychology of Learning and Motivation




32
















Communicating Uncertainty




Weiss


















War
Friedman






Chance
























UNCORRECTED POSTPRINT ACCEPTED FOR PUBLICATION IN INTERNATIONAL JOURNAL OF INTELLIGENCE AND COUNTERINTELLIGENCE












Assessing Uncertainty




Zeckhauser
Friedman


















Teigen
Brun








Verbal Probabilities












Verbal Versus Numerical Probabilities: Efficiency, Biases, and the Preference Paradox




Ido
Erev






Brent
L
Cohen








Organizational Behavior and Human Decision Processes




45


1




















S
Thomas














Preferences and Reasons for Communicating Probabilistic Information in Verbal or Numerical Terms




David
V
Wallsten






Rami
Budescu






Steven
M
Zwick






Kemp








Bulletin of the Psychonomic Society




31


2
















Most Family Physicians Report Communicating the Risks of Adverse Drug Reactions in Words (vs. Numbers)




Marie
Juanchich






Miroslav
Sirota








Applied Cognitive Psychology




34


2




















Emily
D
Lenhardt






Rachael
N
Cross






Makenzie
J
Krocak






Joseph
T
Ripberger






Sean
R
Ernst






Carol
L
Silva






Hank
C














How Likely is That Chance of Thunderstorms? A Study of How National Weather Service Forecast Offices Use Words of Estimative Probability and What They Mean to the Public




Jenkins-Smith








Journal of Operational Meteorology




8


5


64














Patterns of Preference for Numerical and Verbal Probabilities




J
Michael






David
V
Olson






Budescu








Journal of Behavioral Decision Making




10


2




















Mauro
Dieckmann






Slovic








Effects












Behavioral Consequences of Probabilistic Precision: Experimental Evidence from National Security Professionals




Jeffrey
A
Friedman






Jennifer
S
Lerner






Richard
Zeckhauser








International Organization




71


4

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]