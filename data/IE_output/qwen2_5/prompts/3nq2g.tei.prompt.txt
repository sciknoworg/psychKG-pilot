You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



speed-accuracy trade-off 
(Bogacz et al., 2006;
Pleskac & Busemeyer, 2010;
Vickers et al., 1985)
.
Sequential sampling models of decision making can be classified in (1) one dimensional diffusion models and (2) multidimensional race models. The first class of sequential sampling models assume one process that evolves in a diffusion-like manner with either a positive or negative drift depending on the stimulus. Each direction on the dimension represents support for one of two stimulus alternatives. There are two boundaries, one above and the other one below the starting point of the process, and when the process hits one of them for the first time a decision is triggered for the corresponding alternative.
Diffusion models thus apply only to binary decisions. The different models in this class vary with respect to the stochastic process included (Wiener or Ornstein-Uhlenbeck process) or whether the boundaries are time-constant or collapsing, which is a popular assumption in value-based decisions 
(Milosavljevic et al., 2010;
Ratcliff et al., 2016;
Tajima et al., 2016;
Zhang et al., 2014)
 The drift diffusion model is characterized by a Wiener process with drift depending on stimulus discriminability and time-constant boundaries ( 
Fig. 1
). This approach is justified by the interpretation of evidence accumulation as updating a log-likelihood ratio test statistic and of the decision process as the continuous limit of a sequential probability-ratio test, that implements an optimal policy for a speed-accuracy trade-off 
(Bogacz et al., 2006;
Wald & Wolfowitz, 1948;
Wald, 1947)
. In addition, the drift diffusion model includes a non-decision time component of observable reaction times that represents time spent on encoding and producing the motor response 
(Ratcliff & McKoon, 2008)
. Furthermore, inter-trial variations in drift rate, starting point and non-decision time were added to deal with empirically observed patterns like fast or slow errors depending on task difficulty 
(Ratcliff & Rouder, 1998;
Starns et al., 2012)
. 
Figure 1
 visualizes the model and all its parameters. Although the drift diffusion model provides an accurate explanation of reaction time distributions in perceptual as well as memory tasks 
(Ratcliff, 1978;
Ratcliff et al., 2016)
, the only signal available for confidence judgments is decision time, which was considered not realistic 
(Ratcliff et al., 2016)
. 
Pleskac and Busemeyer (2010)
 suggested a two-stage dynamical signal detection model (2DSD) by adding a postdecisional period of additional evidence accumulation to a drift diffusion. After this second stage the final evidence is compared to a set of criteria, as in static models of confidence (see e.g. 
Rausch et al., 2018)
.
The second class of sequential sampling models is formed by race models 
(Gold & Shadlen, 2007)
.
These models assume one process or dimension for each available alternative and are thus applicable to multi-alternative decisions. There is again a boundary on the processes and the process that hits its boundary first determines the decision. Model variants differ in whether they assume independent or correlated noise in the diffusion of the processes 
(Kiani et al., 2014;
Moreno-Bote, 2010;
van den Berg et al., 2016;
Zylberberg et al., 2012)
 and can also include inhibitory interactions or decay 
(Usher &
  Evidence Note. The process starts at a location which is uniformly distributed around z with a range of sz. The drift rate is normally distributed around ν with standard deviation sν. The sign of ν depends on the stimulus identity, which is A in this case. The Wiener process evolves with a diffusion coefficient set to 1 until it hits either the lower (0) or upper (a) boundary, at which time point a decision for the respective alternative is initiated. The observable reaction time is the decision time t plus a uniformly distributed non-decision time component, which is uniformly distributed with minimum t0 and range st0. 
McClelland, 2001
). According to the balance of evidence hypothesis, confidence is a function of the difference between amount of evidence accumulated in the different processes until time of the decision 
(Vickers et al., 1985)
. However, it seems that the decision time influences confidence judgments in addition to the difference between the two accumulators 
(Kiani et al., 2014)
. Another version of a sequential sampling model with multiple accumulators, which was constructed to account for confidence judgments, is the RTCON model 
(Ratcliff & Starns, 2009;
Starns et al., 2012)
. In the present study, we compare diffusion-like confidence models with a set of race models, in which processes accrue evidence for their respective alternatives with either uncorrelated (ρ = 0) or anti-correlated (ρ = −0.5) noise and opposite drift directions. Confidence is either computed according to the balance of evidence hypothesis or as a function of decision time and state of the loosing accumulator at decision time.
Here, we present a dynamical version of the WEV model (dynWEV). It is based on a drift diffusion


Figure 2
Dynamic weighted evidence and visibility model.
Note. The decision process follows the drift diffusion model (top path). After the initial decision time T dec , there is a constant time period of length τ , in which the evidence process continues to accumulate. In parallel, another process accrues information about stimulus visibility (bottom path). At the end the final states of both processes is read out to calculate the confidence measure and formulate a confidence report.
decision mechanism with postdecisional accumulation as in 2DSD but in addition, it includes a process that acquires information about stimulus reliability, which contributes to the computation of the confidence measure. The dynWEV adopts the idea of WEV by assuming that there is a second source of information contributing to confidence. In contrast to static dual-channel like models 
(Mamassian & de Gardelle, 2021;
, it carries not only task relevant evidence but information about perceptual quality of the stimulus. This information is also gathered dynamically over the time course of a trial in a second accumulation process 
(Fig. 2)
. The precise formulation of the model can be found in the Analysis section. The postdecisional accumulation allows for changes-of-mind 
(Moran et al., 2015;
Pleskac & Busemeyer, 2010;
Resulaj et al., 2009;
van den Berg et al., 2016)
. Particularly in incorrect decisions, the process sometimes tends to the opposite direction than the initial decision. If the postdecisional evidence strongly contradicts the initial decision the observer may change its mind and choose the other alternative.


Rationale of the present study
The aim of the present study was to investigate which model provides the best explanation for the joint distribution of choice, reaction time, and confidence. For this purpose, we compared the fit to empirical data of the dynWEV model with 2DSD and several versions of race models, including independent and anti-correlated processes. We expected that the dynWEV would be more precise in the prediction of reaction time and confidence distributions compared to the alternative models and produce the best fit when compared in terms of the Bayesian information criterion 
(BIC, Schwarz, 1978)
 and the Akaike information criterion (AIC, 
Akaike, 1974)
. We also expected that dynWEV would be able to reproduce empirical patterns of the relationship between stimulus discriminability, confidence, and response time distribution. The reason is that only the dynWEV model includes a seperate accumulation process for visibility, giving the model sufficient flexibility to account for the relationship between choice, reaction time, and confidence. The race models were included as possible alternatives to dynWEV as they were previously found to be able to produce a double-increase pattern of confidence as well 
(Kiani et al., 2014)
.
On the other hand, 2DSD may only predict a folded-X-pattern 
(Desender et al., 2021)
. With respect to the relationship of confidence and stimulus discriminability, particularly for small inter-trial variation of drift rate, 2DSD is similar to dual-channel like static models of confidence, where confidence is based on an independent or at least partially independent evidence sample 
(Mamassian & de Gardelle, 2021;
Moran et al., 2015)
.
To compare the performance of the models in explaining empirical data, we analyzed data from two visual discrimination tasks with confidence judgments using either masked sinusoidal gratings or random dot kinematograms as stimuli. Model specification and analyses for all experiments were preregistered at the Open Science Framework website OSF.


Experimental Method
We analyzed data from two visual discrimination tasks with confidence judgments. Both experiments involved a within-subject manipulation of stimulus discriminability. The first experiment was a masked orientation discrimination tasks where stimulus discriminability was manipulated by varying stimulus-onset-asynchrony. The second experiment was a motion direction discrimination task with coherence as manipulation of discriminability.


Participant recruitment
Participants were recruited using a derivative of the Online Recruitment System for Economic Experiments 
(Greiner, 2015)
 at the Catholic University Eichstätt-Ingolstadt. Participation was compensated either with 8 per hour or with course credits (for undergraduate students). Before the experiment, participants were informed about the possibility of leaving the experiment without any negative consequences. They also provided written informed consent for participating in the experiment.
They reported normal or corrected-to-normal vision, no history of neuropsychological or psychiatric disorders, and also not being on psychoactive medication. All participants were ignorant of the hypotheses of the study. The study protocol was approved by the Ethics Committee of the Katholische Universtität Eichstätt-Ingolstadt.


Apparatus
All experiments were performed in a darkened room on a Display++ LCD monitor (Cambridge Research Systems, UK) with a screen diagonal of 81.3 cm, set at a resolution of 1,920×1,080 pixels and a refresh rate of 120 Hz. The participants were seated at an approximate distance of 60 cm from the monitor. The experiments were conducted with PsychoPy 
(Peirce, 2007
(Peirce, , 2009
) on a Fujitsu ESPRIMO P756/E90+ desktop computer with Windows 8.1. Participants used a Cyborg V1 joystick (Cyborg Gaming, UK) for the response.


Experiment 1: Masked orientation discrimination
Participants. We collected data from 16 participants (15 female, 1 male) aged between 18 and 28 (M = 20.4, SD = 2.4) over three sessions.


Stimuli.
The target stimulus was a square sinusoidal grating with a size of 3 • × 3 • and one cycle per degree (maximal luminance: 64 cd/m 2 ; minimal luminance: 21 cd/m 2 ) presented in front of a gray background (44 cd/m 2 ). The orientation was randomly set, either horizontal or vertical. The mask was a checkerboard pattern (size: 4 • × 4 • , five rows and columns) with black (0 cd/m 2 ) and white (88 cd/m 2 ) boxes.
Trial Structure and Design. All trials started with a white fixation cross for one second in the center of the screen followed by the target stimulus with random, horizontal or vertical orientation. After a variable stimulus-onset-asynchrony (SOA) a mask replaced the target. Five levels of SOA were used: 8.3, 
16.7, 33.3, 66.7, and 133.3
 ms. After the mask, which was visible for 500 ms, two scales were presented.
The one on the upper part on the screen was labeled vertical, the one on the lower part horizontal. The left end of both scales additionally had the label unsure while the right end was labeled sure. Participants had to indicate the perceived orientation of the grating together with their confidence using a joystick that moved a mark to the scale of their choice and the position representing their degree of confidence. The participant confirmed their response by pulling the trigger of the joystick. If the choice was incorrect the word Error! was presented for one second. Participants were instructed to report the orientation of the grating and their confidence as accurately as possible without time pressure.
In each session the participant went trough one training block and nine experimental blocks with 60 trials each. In the experimental block, each possible SOA appeared 12 times in a random order. Only the data from these blocks are used for analysis. With three sessions per participant, this results in a total of 1620 trials per participant. Each session took between 45 and 50 minutes.


Experiment 2: Motion direction discrimination
Participants. We collected the data for the second experiment in two different time periods, separated by several months. The final sample consists of 42 participants (17 male, 25 female) of age 19 to 54 (M = 23.3, SD = 6.0). In the first data collection period, 30 participants each took part in one session of the experiment. Four participants conducted more trials because of a technical issue in the beginning of the experiment. All trials were used for analysis for these participants. In the second data collection period, eight participants ran through three sessions, two completed two sessions and two participants completed one session. Data from six additional participants, who aborted the experiment before finishing all blocks, was not considered in the analyses.
Stimuli. In this experiment, the target stimulus were white dots (111 cd/m 2 ) moving within a circular patch of 5 • diameter presented on a black background (0 cd/m 2 ). In each frame, there were 262 dots with a size of two pixels. The noise dots were drawn at a random location in each frame, the target dots were moving either up or down at a constant speed of 5 • per second. If they reached the border of the stimulus region or after 100 frames, the target points were reinitialized at random locations. The proportion of target points, i.e. the motion coherence, was varied randomly from trial to trial in five levels:
1.6%, 3.2%, 6.4%, 12.8%, and 25.6%.
Trial Structure and Design. All trials started with a white fixation cross presented for one second in the center of the screen followed by the target. The target stimulus was presented on the screen until a response was given. Motion coherence was varied between trials. Together with the target stimulus, two horizontal scales were presented above and below the stimulus, labeled upwards and downwards respectively. The left end of both scales was labeled unsure while the right end was labeled sure.
Participants indicated their perceived motion direction and confidence simultaneously with a joystick by moving a mark to the scale corresponding to their choice and position on the scale corresponding to the degree of their confidence and confirmed their response by pulling the trigger of the joystick. If the choice was incorrect the word Error! was presented for one second after the trial. Participants were instructed to report the direction of motion and their confidence as accurately as possible without time pressure.
Each session took about 45 minutes and consisted of one training block and eight experimental blocks. In each experimental block, each coherence level and motion direction combination was presented eight times in random order, resulting in 80 trials per block. Thus, depending on the number of sessions, participants completed 640 to 1920 trials.


Analysis
The free software for statistical computing R was used for all analyses (R Core Team, 2021).


Data exclusion and preprocessing
Participants were to be excluded if their overall accuracy was not above chance. Specifically, if their accuracy was below 50% or if the Bayes factor for the comparison against 50% in a binomial model assuming a logistic prior with a scale factor of 0.5 on the log-odds is less than 3. For the computations we used the function proportionBF from th BayesFactor package in R 
(Morey et al., 2018)
. Moreover, if the confidence ratings were equal in at least 90% of the trials the participant was excluded. However, none of the participants met the exclusion criteria so we analyzed the full sample.
In addition, we excluded trials in which the participants' reaction time was smaller than 300 ms or grater than the mean plus four times the standard deviation of the participants' individual reaction time distribution. These criteria were previously used by 
Pleskac and Busemeyer (2010)
 and similar exclusion is common in the literature (e.g. . If the minimal number of trials for each stimulus identity and discriminability condition was below 20 after the trial level exclusion we intened to drop the participant from further analyses. However, no participant was excluded from analysis due to fewer observations. Overall, on average 0.69% and 0.88% of trials were eliminated in experiment 1 and 2, respectively.
All mathematical models were constructed to predict discrete confidence judgments. Therefore, the confidence reports on the analogue scale were binned to a five level discrete variable with breaks at 20%, 40%, 60%, and 80% of the continuous scale length, the same number of levels as had been used in previous studies 
(Rausch et al., 2018
(Rausch et al., , 2021
.


Mathematical model formulation
Two-stage dynamical signal detection model. The 2-stage dynamical signal detection model (2DSD) assumes that evidence is accumulated as a Wiener process with constant drift. There are two time constant decision thresholds, each corresponds to one choice option of the binary task. At the time the accumulation process reaches one of the thresholds for the first time, the decision for the respective alternative is triggered. Afterwards, there is a constant period in which the diffusion process continues. At the end of this postdecisional period the state of the process is read out and compared to a set of criteria. This comparison finally determines the confidence judgment. We implemented the 2DSD model consistent with the standard formulation of the drift diffusion decision model 
(Ratcliff et al., 2016)
 using the ddiffusion function from the R package rtdists 
(Singmann et al., 2020)
. This means, we included also the inter-trial variability of drift rate, starting point and non-decision time for the motor response in the decision task. These additional parameters are known to increase the fit to real reaction time distributions considerably as without them response time distributions of correct and wrong decisions would be identical 
(Ratcliff et al., 2007)
. The process describing the evidence accumulation is
X(t) = x 0 + W (t), with starting point x 0 , which is drawn from a uniform distribution U nif [z − sz 2 , z + sz 2 ]
, and a Wiener process W with diffusion constant 1 and drift rate µ. The diffusion constant is set to 1 because it acts as a scaling factor in the model. The drift rate varies across trials according to a normal distribution with mean drift rate ν and standard deviation s ν , which is denoted as drift rate variation. The mean drift rate ν depends on stimulus category and discriminability. For binary decision tasks stimulus category may be represented by S ∈ {−1, 1} and determines the sign of ν. The magnitude of ν depends on stimulus discriminability and therefore varied between experimental conditions, while the other parameters were kept constant. Thus, there was one parameter ν i for each of the five levels of stimulus discriminability. In a trial with discriminability level i, the mean drift rate is therefore equal to Sν i . The decision time is
T dec := min {t|X ϑ (t) / ∈ [0, a]} with response R = 1, if X(T dec ) ≥ a and R = −1, if X(T dec ) ≤ 0.
This means, the process generating a perceptual decision is identical to the popular drift diffusion model for decision tasks 
(Ratcliff et al., 2016)
, in which the process is killed after reaching the upper or lower boundary. In contrast to the drift diffusion model, 2DSD assumes that the process continues diverging for a constant time period τ , when the state of the process is read out and used as measure for confidence c := X(T dec + τ ). This is compared to the set of criteria, depending on the decision, such that
C = i, if c ∈ [θ R,i−1 , θ R,i ), with θ 1,0 , θ −1,5 = −∞ and θ 1,5 , θ −1,0 = ∞.
As in experiments of this study decision and confidence judgments are reported simultaneously, a response is assumed to be triggered after these processes have both finished, such that observed response time is the sum of decision time, postdecisional accumulation period plus a non-judgment component T err . The non-decision time component is assumed to vary uniformly between trials,
T err ∼ U nif [t 0 , t 0 + s t0 ]
. All in all, for five different levels of discriminability, the model has following parameters
ϑ = (z, s z , a, ν 1 , ..., ν 5 , s ν , t 0 , s t0 , τ, θ 1,1 , , θ 1,4 , θ −1,1 , , θ −1,4
). An overview of all parameters can be found in 
Table 1
.  
(Rausch et al., 2018;
Rausch et al., 2020)
. In the present study we propose a new sequential sampling model that incorporates these developments and enhances the static WEV model 
(Rausch et al., 2018)
 to take reaction times into account. The dynamical weighted evidence and visibility model (dynWEV) includes not only task relevant evidence for one of the two stimulus categories but also the visibility of the stimulus as a measure of the quality of perceptual input in the computation of confidence. The dynamic WEV model combines this idea with 2DSD 
(Pleskac & Busemeyer, 2010)
. This means that for the accumulation of decision-relevant evidence, we assume a drift diffusion process until a decision is made and a fixed time period of postdecisional evidence accumulation in line with the 2DSD model. However, we also assume that there is a second process assessing the reliability of the stimulus.
This process is denoted visibility process as its the dynamical equivalence of visibility in the WEV model 
(Rausch et al., 2018)
. We propose this process is again an independent Wiener process V (t) with drift µ V and diffusion constant σ 2 V . The state of the visibility process is also read out at time T dec + τ . The internal confidence variable is a weighted sum of the form
c = wRX(T dec + τ ) + (1 − w)V (T dec + τ ),
with the weight on the decision evidence w ranging between 0 and 1. This parameter represents the degree to which confidence judgments are based on the internal strength of decision relevant (X) or decision-irrelevant (V ) stimulus features. Thus, if w = 1, dynWEV is equivalent to 2DSD, as the visibility process has no influence on confidence. Note, that the decision evidence is multiplied by R, because a very low value supports a decision R = −1, while a high value would contradict the decision. The opposite holds for a decision R = 1. The final categorization of the confidence variable is equivalent to 2DSD. For the present study, we assume that stimulus reliability is varied with stimulus discriminability in the way that stimuli that are easier to discriminate are also perceived as more reliable. The average drift in the visibility process is therefore assumed to be equal to the average drift of the decision process |ν|, such that stimulus reliability is independent of stimulus identity, which is represented by the sign of the mean drift rate in the decision process. In addition, include drift rate variation in the visibility process s V similar to the drift rate variation in the decision process. For the purpose of the present study, we assume that the drift is normally distributed with mean |ν| and standard deviation s V and that the drift variation in the visibility process is independent of the drift variation in the decision process (see also Discussion). Therefore, dynWEV includes three more parameters, (w, σ V , s V ), in addition to the parameters of 2DSD. An overview of all parameters can be found in 
Table 1
.
Race Models. In contrast to the drift diffusion model, race models (RM) assume two accumulation processes, one for each decision alternative. In the present study, following Moreno-Bote (2010), we model the two processes as Wiener processes, each starting at 0 and having upper boundaries A and B respectively. Evidence is thus described as two-dimensional Gaussian process
X(t) = (X 1 (t), X 2 (t))
with constant drift µ = (µ 1 , µ 2 ) and covariance matrix Σ = σ
2 ( 1 ρ ρ 1 )
. Because σ is just a scaling parameter in this model, we set it to 1. The parameter ρ represents the correlation of the two processes. The sign and magnitude of drift rates is determined by the stimulus category and discriminability, respectively, similar to the mean drift rate in 2DSD and dynWEV. Precisely, µ = (Sν i , −Sν i ) for stimulus category S ∈ {−1, 1}
and discriminability level i ∈ {1, ..., 5}. This means that the first accumulator indicates evidence in favor of stimulus category 1 and the second for category −1. The time of decision is defined as
T dec := min {t | X 1 (t) > A ∨ X 2 (t) > B} and the response is 1, if X 1 (T dec ) > A and -1, if X 2 (T dec ) > B.
We also assume a uniformly distributed non-decision component of the reaction time, like in dynWEV and 2DSD.
For the generation of confidence, we took two possible models into consideration. According to the Balance of Evidence (BoE) hypothesis, confidence is a monotone function of the state of the loosing accumulator 
(Vickers et al., 1985)
. This follows the idea that the difference in the final amount of evidence is a clue for perceptual ambiguity. In easy decisions, evidence should exclusively support the chosen alternative while an ambiguous stimulus produces similar amounts of evidence for all possible choices. In the race model, the state of the winning accumulator is fixed at the threshold, so the difference indicating the BoE is completely determined by the state of the loosing accumulator. Yet, previous studies provided evidence that subjects additionally take the reaction time into account 
(Kiani et al., 2014)
. This behavior seems also plausible, since low intensity stimuli lead not only to a low precision but also to long periods of accumulation until a threshold is met. In addition, Moreno-Bote (2010) showed that in a Bayesian framework, the posterior of a correct decision, say for alternative 1, is a function of the final state of the loosing accumulator divided by the square root of decision time, X 2 (T dec )/ √ T dec . Therefore, we included the race model with a time-dependent confidence variable by combining the two indicators and the decision time as additional indicator in a linear way, such that
c := w X X 2 (T dec ) + w RT 1 √ T dec + w Int X 2 (T dec ) 1 √ T dec .
The parameters w X , w RT , and w Int are weight parameters indication how strong the confidence variable is influenced by the BoE, decision time, or the optimal ratio. Thus, the model may represent and individual trade-off between these indicators for choice accuracy. Similar to 2DSD and dynWEV, the confidence variable is compared against a set of criteria. For the model comparison, we use two different fixed values for ρ as analytical solutions were available only for ρ = 0 and ρ = −.5. We refer to the model characterized by ρ = 0 as independent race model (IRM), and for ρ = −.5 as partially anti-correlated race model (PCRM). Both are implemented representing the Balance of Evidence hypothesis (i.e. w X = 1, w RT = w Int = 0) and with a time-dependent confidence variable (w X , w RT , w Int ∈ R + ), leading to four different variations of the race models. We denote models implementing the Balance of Evidence hypothesis as IRM and PCRM and the models with time-dependent confidence variable as IRMt and PCRMt, respectively. For models with time-dependent confidence variable, we set
w X + w RT + w Int = 1.
This prevents an arbitrary scaling of the process parameters, coefficients and confidence thresholds and is similar to fixing one of the coefficients to 1 (but delivers a more intuitive interpretation of the coefficients as weights, similar to the weight in dynWEV). An overview of all parameters can be found in 
Table 1
.


Parameters and Fitting Procedure
The various models share many parameters. and fitted for each level of discriminability an intensity parameter ν i ≥ 0, i = 1, ..., 5. For 2DSD and dynWEV, the mean drift rate in a specific trial is accordingly set to ν = Sν i . In RMs, the drift rate is set to µ = (Sν i , −Sν i ). The choices were denoted similarly as R ∈ {−1, 1}, where the upper bound in 2DSD
and dynWEV and the first accumulator in RM drive decision R = 1 and the lower bound and second accumulator R = −1, respectively. Moreover, the parameters for the non-decision time t 0 and s t0 are shared across models. As all models were formulated to produce discrete confidence outcomes, we discretized the judgments in the empirical data to get five confidence levels. Confidence thresholds to separate between these levels, and w Int (19 effective parameters in total, because we fixed the sum of weight parameters to 1).
θ R,k , R ∈ {−1, 1}, k ∈ {1, ...,
The parameters were fitted separately for each participant using a maximum likelihood procedure assuming independence across trials. This method uses the full information available in the data but has the drawback of being sensitive to outliers 
(Ratcliff & Tuerlinckx, 2002)
, which is why we excluded excessively slow and fast responses (see above). For model m, a set of parameters ϑ and data vectors, consisting of stimulus category S, stimulus discriminability Q, observed decisions R, reaction times T and confidence ratings C (the dependent variables), we used the negative log-likelihood
L m (ϑ) = − N ∑ n=1 log(P m (R n , T n , C n |ϑ, S n , Q n ))
as loss function, where n = 1, ..., N are the different trials. The derivation of probability densities is provided in the Supplementary Material. The minimization procedure started with a broad grid search in which the likelihood is computed for different parameter constellations. After the grid search, the five best parameter sets were used as initial values for a optimization algorithm. We used the BOBYQA algorithm for box constrained optimization implemented in the bobyqa function of the minqa package 
(Bates et al., 2015;
Powell, 2009)
. Details for the settings of this routine can be found in the code. We restarted the optimization four times, using the previously found result as initial value for the next iteration to prevent the algorithm from getting stuck in a local minimum.


Model comparison
For a quantitative comparison of the fits of the models, we used the Bayesian information criterion (BIC) and Akaike information criterion (AIC). The BIC is derived using Laplace's method for approximating the marginal likelihood in a Bayesian context. Both criteria take the likelihood of the data as well as the number of parameters into account to avoid overfitting due to unnecessary freedom. Thus, BIC and AIC implement a trade off of parsimony and model fit 
(Schwarz, 1978)
. They are defined by
BIC = 2L(θ) + k log(N ),
and
AIC = 2L(θ) + 2k,
where k is the number of parameters in the respective model andθ is the maximum likelihood parameter estimation. A low BIC or AIC indicate a better model as the data is captured without introducing unnecessary complexity in a model.
We computed BIC and AIC for each participant and model. To compare the quantitative fit of the dynWEV to that of the other models, we performed Bayesian paired t-tests for the mean difference information criteria assuming a standard Cauchy distribution with scale parameter 1 as prior distribution for the standardized effect size 
(Rouder et al., 2009)
. For this purpose we use the function ttestBF from the BayesFactor package in R. Bayes factors were interpreted with respect to their statistical evidence according to established guidelines . Reported 95% equal-tailed CIs were generated using 10 6 samples from the posterior distribution using the same prior as for the Bayes factors.


Model identification analysis
Because of the possibility that the best fitting model is not the generative model that underlies the data, we conducted a model mimicry analysis. Previous studies of sequential sampling models showed that there are parameter regions where there is a high level of model mimicry when models are fitted only to accuracy and reaction time data 
(Bogacz et al., 2006;
Bose et al., 2020)
. Because of the high complexity of the models used in this study, it is not possible to find parameter regions a priori where specific models are equivalent, besides the obvious exception that dynWEV is equivalent to 2DSD if the weight on the visibility accumulator is 0, i.e. w = 1. Therefore, we relied on simulating artificial data, fitting and comparing the resulting information criteria to examine whether the generative model also achieves the best quantitative model fit. We generated simulations from the overall second best fitting model using the fitted parameters and the same number of trials as in the empirical data. With this method we replicated the situation of the experiments as accurately as possible. Then, we fitted the best and second-best fitting model to the simulations and compared which model is preferred by comparing the BIC.


Results


Experiment 1: Masked orientation discrimination
All participant were included in the analysis. The maximum proportion of trials excluded for each participant was 1.05%.


Behavioral results
Accuracy did not vary between sessions BF = .11. Accuracy was at chance level at the minimal SOA of 8.3 ms (M = 50.4%, SD = 2.9%) and close-to-perfect (M = 99.6%, SD = .6%) at the maximum SOA of 133.3 ms 
(Fig. 3A)
. Mean confidence increased in correct responses from 14.7% (SD = 8.63%) of the visual scale for the shortest SOA to 92.2% (SD = 2.39%) for the highest SOA. Similarly, confidence increased also in error trials from the hardest condition (M = 13.7%, SD = 8.13%) to the easiest condition (M = 59.3%, SD = 3.08%, 
Fig. 3B
). Response times also increased in incorrect responses from low discriminability (M = 2.44 s, SD = 0.13 s) to high discriminability (M = 3.08 s, SD = 0.63 s). In spite of that, reaction times varied only slightly for correct trials ranging from 2.40 s (SD = 0.11 s) in the lowest SOA to 2.39 s (SD = 0.28 s) in the highest SOA ( 
Fig. 3C)
. 


Model results


Figure 4
Observed   were not able to account for the double increase pattern. Indeed, only the dynWEV model was able to reproduce the increase of confidence with discriminability in incorrect trials. Although the prediction of the model was accurate, it underestimated the increase in confidence in incorrect trials. It should be noted that the number of errors for the two highest SOA levels was only 1.5% (see 
Figure 3A)
. Therefore, the likelihood as objective function put a smaller weight on these points, which is why predictions may be less accurate in this region. The race models with time dependent confidence (IRMt and PCRMt) both produced constant confidence in incorrect decisions and on the other hand underestimated the steepness of the correct response curve. The deviation of race models from the empirical confidence reports is particularly visible in the joint distribution of confidence and correctness (Suppl. 
Fig. 1)
. 
Supplementary   Figure 1
 also shows that all models except for dynWEV failed to account for the data in the same way: For difficult stimuli, the probability of high confidence reports was systematically overestimated and the prevalence of low confidence was underestimated whereas the opposite is true for the easiest two conditions.
Concerning reaction times as a function of confidence, only the BoE race models deviated considerably from the empirical pattern by an overall increasing response time in high confidence trials 
(Fig. 5)
. The other models fitted the data well with the most deviations on the very left side, which represents the few observations of confident errors (1.2% of observations). Empirical quantiles were computed from the whole data set without regarding for participants. Predicted quantiles were computed after aggregating the individual response time densities.
Model comparison in terms of information criteria. We compared the model fits for AIC and BIC. In terms of BIC, dynWEV was preferable over the other five models and achieved the smallest value for all participants (see also Suppl. 
Fig. 3)
. The second best model was 2DSD (mean BIC difference to dynWEV:  
> 10 7
 ). The dynWEV model outperformed the other models by an even larger margin in terms of AIC, as the BIC has a higher penalty for the parameters and therefore dynWEV gets the higher penalty in the BIC.
M ∆ =


Experiment 2
For analysis the samples from the two data collection periods were combined to one sample but model results were very similar for the two subsets. All of the participants who had finished the experiment, performed above chance overall. From the individual number of trials a maximum proportion of 1.6% was excluded because of extreme response times. All participants were included in the analyses.


Behavioral results
Accuracy ranged from 57.6% (SD = 9.0%) for minimal motion coherence to 99.3% (SD = 1.6%)
for the maximal motion coherence 
(Fig. 6A)
. Again, mean confidence increased in both correct and incorrect responses from 41.6% (SD = 7.28%) and 38.7% (SD = 9.25%), respectively of the visual scale at 1.6% coherence to 93.5% (SD = 18.4%) and 87.1% (SD = 19.2%), respectively at 25.6% coherence 
(Fig. 6B
). In the second experiment response times decreased in correct trials from a mean 3.38 s (SD = 0.44 s) in the hardest condition to 2.31 s (SD = 0.81 s) in the easiest condition. Here, mean response times decreased also for errors from 3.451 s (SD = 0.54 s) for the lowest coherence level to 2.14 s (SD = 0.51 s) for the highest coherence 
(Fig. 6C)
. 


Model results
Visual comparison of empirical data and model predictions. Similarly to experiment 1, dynWEV seemed to best approximate mean confidence judgments across conditions 
(Fig. 7)
, while 2DSD
and race models based on balance of evidence missed the increase in confidence with stimulus discriminability in wrong decisions completely. Although showing a slight increase, IRMt and PCRMt underestimated the slope of confidence in incorrect trials as a function of coherence. Wrong decisions in the easiest condition (25.6% coherence) form 0.1% of all observations. Therefore, mean confidence in incorrect decisions for the highest coherence did not strongly influence model fitting. With respect to the discrete empirical response distribution, the deviation was most apparent in the most extreme conditions and extreme confidence reports. All models tended to underestimate high confidence in easy conditions while for hard conditions they overestimated high confidence trials in correct as well as wrong decisions (see also Suppl. 
Fig. 2
). For very low confidence, the opposite is the case. These deviations were more pronounced in race models and barely visible for dynWEV. Concerning response times, diffusion based models, i.e. dynWEV and 2DSD, were more accurate in fitting response time quantiles than race models 
(Fig. 8
). Race models with time dependent confidence (IRMt and PCRMt) overestimated response times, especially in low confidence trials, but they captured the overall pattern of the relationship between response time and confidence, that is higher confidence was linked to faster decisions and particularly a shorter tail of the distribution as indexed by the upper quantiles. Time-independent confidence race models seem to have missed this pattern as decision time increases for extreme high and extreme low confidence. It can also be seen that dynWEV and 2DSD, the two models based on the drift diffusion process, tended to overestimate the tail in high confidence errors. Note, that high confidence errors form only 2.7% of the data.
Model comparison in terms of information criteria. Similar to experiment 1, we only report BIC results, here, as the comparison using AIC delivers similar results. The BIC favored dynWEV above the other models for 28 of the total 42 participants (Suppl. 
Fig. 4
). For the other participants, in 10 cases 2DSD and in 4 cases PCRMt delivered the best fit. In terms of the mean BIC, dynWEV obtained the best fit and 2DSD the second best fit (M ∆ = 28, SD ∆ = 35). Among the race models the ones with   Empirical quantiles were computed from the whole data set without regarding for participants. Predicted quantiles were computed after aggregating the individual response time densities.


Model identification analysis
In both experiments dynWEV was the best and 2DSD was the second best performing model in terms of BIC and AIC. Thus, we simulated artificial data using the fitted parameters and number of trials for each participant. Then, we fitted the generative model and dynWEV to the simulated data and compared the model fit using the BIC. In this situation model mimicry is obvious as the 2DSD is a special case of dynWEV when the weight on the evidence accumulator w is equal to 1. However, for none of the participants of both experiments the dynWEV performed better than 2DSD, if the data was generated by 2DSD. More precisely, in dynWEV the fitted weight parameter w was close to 1 for most participants (M = .96, SD = .09), which means that dynWEV would also prefer a single-process architecture, if it is the best explanation.
A second mimicry analyses was performed to investigate whether one of the race models was falsely classified, we performed another model identification analysis with PCRMt as generative model. We chose to include PCRMt as a generative model into model identification analysis because PCRMt was the best performing model among the different flavors of the race model according to Bayes factors. For none of the simulated data sets dynWEV achieved a lower BIC compared to PCRMt. Moreover, the maximum likelihood achieved by the fits was higher for PCRMt compared to dynWEV for all artificial participants, indicating that dynWEV is not able to produce the same or similar joint distributions of decisions, response times and confidence. Thus, the models seem to be identifiable by the fitting procedure in the present study.


Discussion
The modeling analysis revealed a better fit of the dynWEV model compared to other dynamic models of decision confidence in both the masked orientation discrimination task and the random dot motion task. Specifically, only dynWEV and 2DSD, the two models assuming that the choice is based on a drift diffusion process, were able to accurately fit the response time distributions as a function of different levels of confidence, while all four race models considered in the present study failed to account for response time distributions. However, only dynWEV but not 2DSD was able to account for the increase in confidence with stimulus discriminability in both correct and incorrect decisions.


Implications of the dynWEV model
The accurate fit of the dynWEV model has some theoretical implications how human observers compute confidence judgments.
Close relationship between decision dynamics and confidence. First, the dynWEV model demonstrates that dynamical decision models can be extended to accurately describe the distribution of choices, confidence and response times at the same time. Moreover, this study demonstrates that a single model is able to account for experiments where the response time distributions are similar across different levels of confidence as well as experiments where the distributions change as a function of confidence. The two best-fitting models, 2DSD and dynWEV generally provided a good fit to response times as a function of confidence by assuming that confidence is generated by a similar dynamical process as the decision itself.
In spite of that, in contrast to previous studies, the winning models do not imply a direct causal connection between confidence and decision time (cf. 
Kiani et al., 2014)
. Given there is converging evidence that confidence and reaction times are related (e.g. 
Kiani et al., 2014;
Rahnev et al., 2020)
, it seems problematic to model confidence ignoring reaction times as many static models of confidence do. Previous studies aiming to extend dynamical models to account for confidence often did not use the rich information provided by the joint distribution of choices, confidence, and response times to estimate parameters and examine model fit. For example, previous studies fitted only response times 
(Kiani et al., 2014)
, used aggregated data, like decision probabilities and average response times 
(van den Berg et al., 2016)
, used only the quantiles of the reaction time distribution 
(Pleskac & Busemeyer, 2010;
Ratcliff & Starns, 2013)
, or fitted first the drift diffusion model parameters to the choice and response time data, and used the confidence data only to fit the confidence-specific parameters 
(Desender et al., 2021;
Moran et al., 2015)
.
Postdecisional accumulation of evidence. Second, the present study supports previous findings that confidence is informed by additional evidence about the choice alternatives that is not involved in the decision process 
(Moran et al., 2015;
Pleskac & Busemeyer, 2010;
Resulaj et al., 2009;
van den Berg et al., 2016)
, because the two best-fitting models, 2DSD and dynWEV share the assumption of a postdecisional period of evidence accumulation. A period of postdecisional accumulation is absolutely necessary in 2DSD to account for variation in confidence judgments. But also for dynWEV, the fitted parameters indicate that there is a prolonged period of postdecisional accumulation. The postdecisional period constitutes on average 67.4% of the overall response times in experiment 1 and 46.3% in experiment 2 (see also Suppl. 
Table 1
 and Suppl. 
Table 2
 for summaries of parameter fits). In line with a contribution of postdecisional accumulation, some but not all electrophysiological markers of perceptual confidence are not found until after the response 
(Boldt & Yeung, 2015;
Rausch et al., 2020)
. Although participants in the present experiments reported decisions and confidence at the same time, which is why changes-of-mind
were not possible, dynWEV and 2DSD may account for these in a straightforward way. During the period of postdecisional accumulation the additional evidence may contradict the previous decision which would lead to a change-of-mind if this evidence is strong enough.
Parallel estimation of stimulus reliability. Third, the accurate fit of the dynWEV provides strong evidence that information about stimulus reliability is involved in the computation of confidence 
(Rausch et al., 2018;
Rausch et al., 2020)
. Information about stimulus reliability is at least in parts accumulated independently of decision evidence. Thus, the dynWEV model is consistent with probabilistic theories of perception, according to which observers take into account knowledge about the uncertainty associated with observations 
(Ma, 2012)
. A possible neural mechanism may involve posterior parietal cortex and ventral striatum, which were found to track sensory reliability independently of the choice 
(Bang & Fleming, 2018)
. Evidence about stimulus reliability seems to be an adequate explanation for the double increase pattern observed in previous studies 
(Kiani et al., 2014;
Rausch et al., 2018;
Rausch et al., 2020)
. A previous study had proposed that the double increase pattern can be explained by a combination of balance-of-evidence and decision time 
(Kiani et al., 2014)
. However, in the present study no race model with time dependent evidence was able to reproduce the double increase pattern of confidence, although confidence was computed as a combination of terms including Balance of Evidence and decision time and therefore these models are in principle able to produce a double increase pattern (e.g. if confidence was solely a function of decision time, i.e. with w RT = 1, w X = 0, and w Int = 0). The additional constraints put on the parameters by fitting the whole joint distribution of decisions, response times, and confidence reports are likely to cause the discrepancies between empirical and predicted mean confidence 
(Figures 4   and 7)
. This again emphasizes the necessity of fitting the joint distribution of choice, response time and confidence to identify the complete cognitive architecture underlying perceptual decisions.
Specification of the dynWEV model. It should be noted that the dynWEV model presented here is only one possibility to formulate a dynamic version of a weighted evidence and visibility model of confidence. There were some choices made in the concrete formulation that were somehow arbitrary. Most importantly, we included trial-to-trial variation of the drift rate of the visibility accumulation. Variability of drift rate in the visibility process seems plausible since effects similar to the ones causing the drift variation in decision evidence accumulation should also be present in the visibility accumulation. However, although dynWEV implies that the variations of drift rates in the decision process and in the visibility process are independent, it might be assumed that these variations of drift rates in the decision and visibility process are in fact correlated. The plausibility of independent drift rate variability depends on the origin and nature of drift rate variation. In the drift diffusion model, variation in drift rates is often used to account for large reaction times in incorrect responses and to ensure a finite asymptote of accuracy when the boundary separation increases arbitrarily 
(Ratcliff & Rouder, 1998;
Starns et al., 2012)
. It was previously proposed that the variability in the drift rate arises from noise in visual and memory encoding of the stimuli and the variation in accumulation from the actual comparison process, for example in a word-matching task 
(Ratcliff, 1981)
 or an orientation discrimination task 
(Smith et al., 2004)
. This interpretation would support correlated drift rates in visibility and evidence accumulation. On the other hand, there are some arguments for an independent variation. First, in an object identification task, drift rate variability in the diffusion model seems to arise from late processing of the task relevant features of the stimulus and seems to be part of the neural process of decision making . In addition, there is evidence that different stimulus features are processed independently and in parallel in the visual system if stimulus are presented briefly 
(Kyllingsbaek & Bundesen, 2007)
, which supports our approach as the visibility process incorporates task-irrelevant and thus different features than the decision accumulator.
Besides the drift rate variation there is the possibility that the diffusion noise is not independent as in our formulation but that process noise is shared between the accumulation processes. To substantiate the model specification future research may try to independently manipulate specific parameters of dynWEV through experimental conditions 
(Voss et al., 2004)
.


Limitations and open questions
Although there is strong evidence in favor of dynWEV compared to all other models presented here, there are some limitations of the present study and open questions, which should be pointed out here.
Response times in high confidence errors. First, despite of providing the best fit to response times of all models tested, the dynWEV model still overestimates response times for high confidence errors (see 
Fig. 5 and 8)
. Although these observations form a rather small proportion of observations, the pattern is apparent in both experiments. In previous studies, the pattern of response times for high confidence errors was not consistent and may be influenced by stimulus properties and task setting like instruction 
(Ratcliff & Starns, 2009;
Starns et al., 2012)
. Future studies will require an extraordinary number of trials to investigate how these differences in response times for high confidence errors are explained by the properties of the decision process. Gamma 
(Nelson, 1984)
 and the area under type-2 ROC curve 
(Fleming et al., 2010)
. However, there are also measures of metacognitive accuracy that rely on specific confidence models to disentangle between metacognitive accuracy and subjective criteria, for example meta-d'/d' 
(Maniscalco & Lau, 2012)
, σ meta 
(Shekhar & Rahnev, 2021)
, or confidence efficiency 
(Mamassian & de Gardelle, 2021)
. Future studies are needed to investigate how these measures of metacognitive accuracy are related to the parameters of the dynWEV model (or other dynamical models of confidence) to see if measures of metacognitive accuracy are contaminated by parameters specific to the dynamic decision process.
Other sequential sampling models of confidence. Third, we restricted the comparison of models in this study to models for which solutions to likelihood functions are available and did not include models for which we would have to approximate the likelihood by sampling. Thus, models such as RTCON 
(Starns et al., 2012)
 and the bounded accumulation model proposed by 
Kiani et al. (2014)
 were not considered in the present study. Finally, we also did not consider other decision architectures except for the drift diffusion model and the race model such as the leaky competing accumulator model 
(Usher & McClelland, 2001
).
Multiple alternative decisions. The dynWEV model shares a drawback with all drift diffusion based models, namely it applies to binary decisions. Though the excellent fit in experimental paradigms that often use binary decisions diffusion models lack some external validity since real world decisions most often include multiple if not a continuous scale of possible alternatives. Race models may be applied to multiple alternatives in a straightforward way since every alternative has its accumulator but perform worse in fitting response time distributions. One possible explanation of the better fit of diffusion models is the inter-trial variations that make is very flexible. Indeed, most of these additional parameters are included to gather all empirical patterns of response times 
(Ratcliff & Rouder, 1998;
Ratcliff et al., 2016)
. Inter-trial variability in stating point (s z ) should allow for fast errors while variation in drift rate (s ν ) makes small errors possible. It may be possible that race models can achieve equally good fits when provided with this additional freedom. Furthermore, the visibility accumulation may be also incorporated in such a model, which would be a possible alternative candidate for the dynWEV model presented in this study.
Magnitude Sensitivity. Finally, while dynWEV is applicable to a broad range of psychophysical tasks, there is one empirical phenomenon that can not be explained by the current version of the model: magnitude sensitivity. Magnitude sensitivity describes the effect of faster decisions in decision tasks when the stimulus magnitude (e.g. illumination or numerosity in a respective task) or value (e.g. reward in points) is increased for all available alternatives 
(Pirrone et al., 2021)
. This effect is well studied in detection tasks 
(Pins & Bonnet, 1996;
van Maanen et al., 2012)
 and can be observed in various value-based and perceptual decision tasks in humans and animals 
(Ratcliff et al., 2018;
Teodorescu et al., 2016;
van Maanen et al., 2012)
 even if both alternatives are equal in magnitude 
(Kirkpatrick et al., 2021;
Pirrone, Azab, et al., 2018;
Pirrone, Wen, et al., 2018)
. Recent studies examined different possible sequential sampling accounts for this effect. Drift diffusion models with intensity dependent noise parameters and leaky competing accumulator models both deliver explanations for the data but clear evidence in favor of a specific model is missing 
(Ratcliff et al., 2018;
Teodorescu et al., 2016)
, as there is a high degree of model mimicry 
(Bogacz et al., 2006;
Bose et al., 2020)
.
A similar effect as magnitude sensitivity has been reported with confidence reports. By separately manipulating signal strength and signal to noise ratios, it is possible to manipulate confidence without affecting accuracy 
(Koizumi et al., 2015;
Odegaard et al., 2018;
Samaha et al., 2016)
. Given that the effects of magnitude sensitivity can be explained by the dynamics of decision making, it seems necessary to investigate if the effects on confidence can be explained by these dynamics as well. The present study
shows that the cognitive modeling of the joint distribution of choice, response time and confidence is a powerful tool for model comparison.


Conclusion
We proposed a sequential sampling model, the dynamical weighted evidence and visibility model, to account for the joint distribution of decisions, response times, and confidence judgments in binary perceptual decision tasks. In two different perceptual decision tasks with simultaneous confidence reports, the model fitted the empirical data better than five alternative models and captured all relevant relationships between decision, response time and confidence judgment. These observations indicate that confidence is not exclusively based on evidence utilized in the decision process, but incorporates also postdecisional evidence as well as independent evidence about the reliability of the stimulus. Moreover, we demonstrated that using the all the information available in the data in form of the full joint distribution of all dependent variables is both feasible and advantageous for model fitting and comparison.
Figure 1
1
Example for one realization of a drift diffusion process.


Mean accuracy (A), confidence ratings (in % of visual scale, B) and response times (C) for different levels of stimulus onset asynchrony (SOA). Error bars represent within-subject standard errors.


Empirical (points) and fitted (lines) mean confidence ratings as function of stimulus onset asynchrony for correct (green, circles) and incorrect (orange, triangles) decisions. Error bars represent within-subject standard errors. Visual comparison of empirical data and model predictions.


Figure 4shows the observed and fitted patterns of mean confidence judgments for different discriminability levels and correctness of the response. As expected, 2DSD and the race models without time dependent confidence (IRM and PCRM)


Figure 5 anti
5
Observed response time quantiles vs. quantiles predicted by model fits for experiment 1 Empirical (black triangles and dashed lines) and fitted (solid lines) response time quantiles (probabilities: .1, .3, .5, .7, .9) across confidence judgments for correct (right half of x-axis) and incorrect (left half of x-axis) answers.


Mean accuracy (A), confidence ratings (in % of visual scale, B) and response times (C) for different levels of motion coherence. Error bars represent standard errors.


time-dependent confidence measures, IRMt (M ∆ = 170, SD ∆ = 135) and PCRMt (M ∆ = 191, SD ∆ = 179), performed best. The Bayesian t-test comparison revealed decisive evidence for dynWEV compared to 2DSD (BF 10 = 3.35 × 10 3 , posterior CI δ = [0.44, 1.13]), to PCRMt (BF 10 = 6.21 × 10 5 , posterior CI δ = [0.66, 1.42]), and to IRMt (BF 10 = 3.22 × 10 7 , posterior CI δ = [0.83, 1.64]). Similarly, the evidence was decisive compared to the race models representing the balance of evidence hypothesis (BF 10 > 10 8 ). When analyzing the data separately for the two data collection periods Bayes factors also CONFIDENCE AND RT DISTRIBUTIONS 26 indicated at least strong evidence in favor of dynWEV. For the first data collection period, which included 30 participants, Bayes factor for the comparison of dynWEV with 2DSD was 14.46 (posterior CI δ = [0.20, 0.97]) and for the comparison with the race model variations at least 3.02 × 10 5 . For the second collection period with 12 participants and different number of sessions, the comparison of dynWEV to PCRMt resulted in the lowest Bayes factor (BF 10 = 45.06, posterior CI δ = [0.43, 1.96]) still indicating very strong evidence for dynWEV. The comparison with the other models delivered again decisive evidence in favor of dynWEV (BF 10 > 1.14 × 10 2 ).


Figure 7 anti
7
Observed mean confidence vs. confidence predicted by model fits for experiment 2 Empirical (points) and fitted (lines) mean confidence ratings as function of stimulus onset asynchrony for correct (green, circles) and incorrect (orange, triangles) decisions. Error bars represent within-subject within-subject standard errors.


Figure 8 anti
8
Observed response time quantiles vs. quantiles predicted by model fits for experiment 2 Empirical (black triangles and dashed lines) and fitted (solid lines) response time quantiles (probabilities: .1, .3, .5, .7, .9) across confidence judgments for correct (right half of x-axis) and incorrect (left half of x-axis) answers.


Metacognitive
Sensitivity. Second, the present study may also have implications for the large research program relying on measurements of metacognitive accuracy. A large number of different measures of metacognitive accuracy exist, some of which are model free, such as Goodman and Kruskals


Table 1
1
List and short description of all parameters fitted for the different models. Recent studies suggested that confidence is not exclusively determined by task relevant evidence but incorporates information about stimulus reliability
Parameter
Description
Models using the
parameter
ν i
mean drift rates for drift diffusion (2DSD, dynWEV)
all
or correct accumulation process (Race Models),
i = 1, ..., 5 (one parameter per stimulus
discriminability)
t 0
minimal non-decision time
all
s (confidence is discretized into five steps)
all
a
distance between upper and lower decision boundary
2DSD, dynWEV
for decision process
z
mean starting point of decision process
2DSD, dynWEV
s z
range of uniform distribution for starting point in
2DSD, dynWEV
decision process
τ
length of inter-rating period
2DSD, dynWEV
w
weight on decision evidence for confidence variable
dynWEV
σ V
variability in visibility process
dynWEV
s V
variation in drift rate of visibility process
dynWEV
A, B
thresholds for the two accumulation processes
IRM, PCRM,
IRMt, PCRMt
w X , w RT and w Int
weights on loosing accumulator, decision time and
IRMt, PCRMt
interaction for the confidence variable
t0 range of uniformly distribution for non-decision time all θ R,k set of confidence criteria, R = −1, 1, k = 1, ..., 4Dynamical weighted evidence and visibility model.


Table 1
1
shows an overview and a short description of all parameters. Both experiments had five steps of stimulus discriminability (i.e. SOA in Exp. 1 and confidence in Exp. 2) and two opposite categories (i.e. horizontal vs. vertical orientation in Exp. 1 and upwards vs. downwards motion in Exp. 2). Therefore, we modeled the stimulus categories as S ∈ {−1, 1}


4}, may vary between the decision response options and are present in all models. In summary, there are 15 parameters common to all models. 2DSD contains 4 additional parameters: a, z, s z , and τ (19 in total). Additional to the parameters of the 2DSD model, dynWEV requires w, σ V , and s V (21 in total). IRM and PCRM require only A and B, which are equivalent to a and z in 2DSD and dynWEV (17 in total), and IRMt and PCRMt in addition w X , w RT


mean confidence vs. confidence predicted by model fits for experiment
dynamical weighted evidence
two-stage dynamical
and visibility
signal detection
independent race model
independent race model
(time-dependent confidence)
(Balance of Evidence)
anti-correlated race model
anti-correlated race model
(time-dependent confidence)
(Balance of Evidence)
8.3
16.7
33.3
66.7
133.3
8.3
16.7
33.3
66.7
133.3


256, SD ∆ = 120). Among the race models IRMt performed best (M ∆ = 892, SD ∆ = 245). The BIC was smaller for the dynWEV model compared to all other models for all participants. A Bayesian t-test was conducted to compare the BIC values for the dynWEV model with the other models. For the comparison with the 2DSD the Bayes factor revealed decisive evidence in favor of dynWEV (BF 10 = 5.2 × 10 4 , CI of posterior for δ : [1.13, 2.92]). The results for the other comparisons were more extreme (BF 10








Acknowledgments
We are grateful to Carolina Ehret, Florian Sprang and Veit Zehentmaier for help with data collection.












Doubly bayesian analysis of confidence in perceptual decision-making




L
Aitchison






D
Bang






B
Bahrami






P
E
Latham




10.1371/journal.pcbi.1004519








Article e1004519






11












A new look at the statistical model identification




H
Akaike




10.1109/TAC.1974.1100705








IEEE Transactions on Automatic Control




19


6
















Distinct encoding of decision confidence in human medial prefrontal cortex




D
Bang






S
M
Fleming




10.1073/pnas.1800795115








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






115














Minqa: Derivative-free optimization algorithms by quadratic approximation




D
Bates






K
M
Mullen






J
C
Nash






R
Varadhan




















The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks




R
Bogacz






E
Brown






J
Moehlis






P
Holmes






J
D
Cohen




10.1037/0033-295X.113.4.700








Psychological review




113


4
















Shared neural markers of decision confidence and error detection




A
Boldt






N
Yeung




10.1523/JNEUROSCI.0797-14.2015








Journal of Neuroscience




35


8
















Comparison of magnitude-sensitive sequential sampling models in a simulation-based study




T
Bose






A
Pirrone






A
Reina






J
A
Marshall




10.1016/j.jmp.2019.102298








Journal of Mathematical Psychology




94














Dynamic expressions of confidence within an evidence accumulation framework




K
Desender






T
H
Donner






T
Verguts








Cognition




207
















10.1016/j.cognition.2020.104522














Relating introspective accuracy to individual differences in brain structure




S
M
Fleming






R
S
Weil






Z
Nagy






R
J
Dolan






G
Rees




10.1126/science.1191883








Science




5998
















The neural basis of decision making. Annual review of neuroscience




J
I
Gold






M
N
Shadlen




10.1146/annurev.neuro.29.051605.113038








30














Subject pool recruitment procedures: Organizing experiments with orsee




B
Greiner




10.1007/s40881-015-0004-4








Journal of the Economic Science Association




1


1
















A computational framework for the study of confidence in humans and animals




A
Kepecs






Z
F
Mainen




10.1098/rstb.2012.0037








Philosophical Transactions of the Royal Society B: Biological Sciences




367
















Neural correlates, computation and behavioural impact of decision confidence




A
Kepecs






N
Uchida






H
A
Zariwala






Z
F
Mainen








Nature




7210


















10.1038/nature07200














Choice certainty is informed by both evidence and decision time




R
Kiani






L
Corthell






M
N
Shadlen




10.1016/j.neuron.2014.12.015








Neuron




84


6
















Equal evidence perceptual tasks suggest a key role for interactive competition in decision-making




R
P
Kirkpatrick






B
M
Turner






P
B
Sederberg




10.1037/rev0000284








Psychological review




128


6
















Does perceptual confidence facilitate cognitive control? Attention, perception & psychophysics




A
Koizumi






B
Maniscalco






H
Lau








77
















10.3758/s13414-015-0843-3














Parallel processing in a multifeature whole-report paradigm




S
Kyllingsbaek






C
Bundesen








Journal of experimental psychology. Human perception and performance




33


1


















10.1037/0096-1523.33.1.64














Quantitative models of attention and response processes in shape identification tasks




D
Laberge




10.1006/jmps.1994.1015








Journal of Mathematical Psychology




38


2
















Midbrain dopamine neurons signal belief in choice accuracy during a perceptual decision




A
Lak






K
Nomoto






M
Keramati






M
Sakagami






A
Kepecs




10.1016/j.cub.2017.02.026








Current biology




27


6






CB












Bayesian cognitive modeling: A practical course




M
D
Lee






E.-J
Wagenmakers




10.1017/CBO9781139087759








Cambridge University Press












Organizing probabilistic models of perception




W
J
Ma




10.1016/j.tics.2012.08.010








Trends in cognitive sciences




16


10
















Detection theory: A user's guide




N
A
Macmillan






C
D
Creelman








Lawrence Erlbaum Associates Publishers






2nd ed.








Modeling perceptual confidence and the confidence forced-choice paradigm. Psychological review, Advance online publication




P
Mamassian






V
De Gardelle




10.1037/rev0000312


















A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings




B
Maniscalco






H
Lau








Consciousness and cognition




21


1


















10.1016/j.concog.2011.09.021














The signal processing architecture underlying subjective reports of sensory awareness




B
Maniscalco






H
Lau




10.1093/nc/niw002








Neuroscience of consciousness




1


2016














Heuristic use of perceptual evidence leads to dissociation between performance and metacognitive sensitivity




B
Maniscalco






M
A K
Peters






H
Lau




10.3758/s13414-016-1059-x








Perception, & Psychophysics




78


3










Attention








The drift diffusion model can account for the accuracy and reaction time of value-based choices under high and low time pressure




M
Milosavljevic






J
Malmaud






A
Huth






C
Koch






A
Rangel




10.2139/ssrn.1901533








Judgment and Decision Making




5


6
















Post choice information integration as a causal determinant of confidence: Novel data and a computational account




R
Moran






A
R
Teodorescu






M
Usher




10.1016/j.cogpsych.2015.01.002








Cognitive psychology




78
















Decision confidence and uncertainty in diffusion models with partially correlated neuronal integrators




R
Moreno-Bote




10.1162/neco.2010.12-08-930








Neural computation




7


22














Bayesfactor: Computation of bayes factors for common designs




R
D
Morey






J
N
Rouder






T
Jamil






S
Urbanek






K
Forner






A
Ly




















A comparison of current measures of the accuracy of feeling-of-knowing predictions




T
O
Nelson








Psychological bulletin




95


1
















Superior colliculus neuronal ensemble activity signals optimal rather than subjective confidence




B
Odegaard






P
Grimaldi






S
H
Cho






M
A K
Peters






H
Lau






M
A
Basso








Proceedings of the National Academy of Sciences




115


7


















10.1073/pnas.1711628115














The importance of falsification in computational cognitive modeling




S
Palminteri






V
Wyart






E
Koechlin




10.1016/j.tics.2017.03.011








Trends in cognitive sciences




21


6
















Psychopy-psychophysics software in python




J
W
Peirce




10.1016/j.jneumeth.2006.11.017








Journal of neuroscience methods




162


1-2
















Generating stimuli for neuroscience using psychopy




J
W
Peirce




10.3389/neuro.11.010.2008








Frontiers in neuroinformatics




2


10
















Neural representation of task difficulty and decision making during perceptual categorization: A timing diagram




M
G
Philiastides






R
Ratcliff






P
Sajda




10.1523/JNEUROSCI.1655-06.2006








Journal of Neuroscience




26


35
















On the relation between stimulus intensity and processing time: Piéron's law and choice reaction time




D
Pins






C
Bonnet








Perception & Psychophysics




58


3


















10.3758/BF03206815














Evidence for the speed-value trade-off: Human and monkey decision making is magnitude sensitive. Decision




A
Pirrone






H
Azab






B
Y
Hayden






T
Stafford






J
A R
Marshall




10.1037/dec0000075








5




Washington, D.C.












Magnitude-sensitivity: Rethinking decision-making




A
Pirrone






A
Reina






T
Stafford






J
A
Marshall






F
Gobet








Trends in Cognitive Sciences




1


















10.1016/j.tics.2021.10.006














Single-trial dynamics explain magnitude sensitive decision making




A
Pirrone






W
Wen






S
Li




10.1186/s12868-018-0457-5








BMC Neuroscience




19


1














Two-stage dynamic signal detection: A theory of choice, decision time, and confidence




T
J
Pleskac






Busemeyer




10.1037/a0019737








Psychological review




3


117














Confidence and certainty: Distinct probabilistic quantities for different goals




A
Pouget






J
Drugowitsch






A
Kepecs




10.1038/nn.4240








Nature neuroscience




19


3
















The BOBYQA algorithm for bound constrained optimization without derivatives




M
J D
Powell




















R: A language and environment for statistical computing




R Core Team




















The confidence database




D
Rahnev






K
Desender






A
L F
Lee






W
T
Adler






D
Aguilar-Lleyda






B
Akdoan






P
Arbuzova






L
Y
Atlas






F
Balc






J
W
Bang






I
Bègue






D
P
Birney






T
F
Brady






J
Calder-Travis






A
Chetverikov






T
K
Clark






K
Davranche






R
N
Denison






T
C
Dildine






.
.
Zylberberg






A








Nature human behaviour




4


3


















10.1038/s41562-019-0813-1














A theory of memory retrieval




R
Ratcliff




10.1037/0033-295X.85.2.59








Psychological review




85


2
















A theory of order relations in perceptual matching




R
Ratcliff




10.1037/0033-295X.88.6.552








Psychological review




88


6
















Dual diffusion model for single-cell recording data from the superior colliculus in a brightness-discrimination task




R
Ratcliff






Y
T
Hasegawa






R
P
Hasegawa






P
L
Smith






M
A
Segraves




10.1152/jn.00393.2006








Journal of neurophysiology




97


2
















The diffusion decision model: Theory and data for two-choice decision tasks




R
Ratcliff






G
Mckoon




10.1162/neco.2008.12-06-420








Neural computation




20


4
















Quality of evidence for perceptual decision making is indexed by trial-to-trial variability of the EEG




R
Ratcliff






M
G
Philiastides






P
Sajda




10.1073/pnas.0812589106








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






106














Modeling response times for two-choice decisions




R
Ratcliff






J
N
Rouder




10.1111/1467-9280.00067








Psychological Science




5
















A comparison of sequential sampling models for two-choice reaction time




R
Ratcliff






P
L
Smith




10.1037/0033-295X.111.2.333








Psychological review




111


2
















Diffusion decision model: Current issues and history




R
Ratcliff






P
L
Smith






S
D
Brown






G
Mckoon




10.1016/j.tics.2016.01.007








Trends in cognitive sciences




4
















Modeling confidence and response time in recognition memory




R
Ratcliff






J
J
Starns




10.1037/a0014086








Psychological review




116


1
















Modeling confidence judgments, response times, and multiple choices in decision making: Recognition memory and motion discrimination




R
Ratcliff






J
J
Starns




10.1037/a0033152








Psychological review




120


3
















The effects of aging on reaction time in a signal detection task




R
Ratcliff






A
Thapar






G
Mckoon




10.1037/0882-7974.16.2.323








Psychology and Aging




16


2
















Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability




R
Ratcliff






F
Tuerlinckx




10.3758/bf03196302








Psychonomic bulletin & review




9


3
















Modeling 2-alternative forced-choice tasks: Accounting for both magnitude and difference effects




R
Ratcliff






C
Voskuilen






A
Teodorescu








Cognitive psychology




103


















10.1016/j.cogpsych.2018.02.002














Confidence in masked orientation judgments is informed by both evidence and visibility. Attention, Perception, & Psychophysics




M
Rausch






S
Hellmann






M
Zehetleitner




10.3758/s13414-017-1431-5








80














Modelling visibility judgments using models of decision confidence. Attention, Perception, & Psychophysics




M
Rausch






S
Hellmann






M
Zehetleitner








83
















10.3758/s13414-021-02284-3














The folded x-pattern is not necessarily a statistical signature of decision confidence




M
Rausch






M
Zehetleitner




10.1371/journal.pcbi.1007456








Article e1007456






15












Cognitive modelling reveals distinct electrophysiological markers of decision confidence and error monitoring. NeuroImage, 218, Article 116963




M
Rausch






M
Zehetleitner






M
Steinhauser






M
E
Maier




10.1016/j.neuroimage.2020.116963


















Changes of mind in decision-making




A
Resulaj






R
Kiani






D
M
Wolpert






M
N
Shadlen




10.1038/nature08275








Nature




7261
















Bayesian t tests for accepting and rejecting the null hypothesis




J
N
Rouder






P
L
Speckman






D
Sun






R
D
Morey






G
Iverson








Psychonomic Bulletin & Review




16


2


















10.3758/PBR.16.2.225














Dissociating perceptual confidence from discrimination accuracy reveals no influence of metacognitive awareness on working memory




J
Samaha






J
J
Barrett






A
D
Sheldon






J
J
Larocque






B
R
Postle




10.3389/fpsyg.2016.00851








Frontiers in psychology




7














Signatures of a statistical computation in the human sense of confidence




J
I
Sanders






B
Hangya






A
Kepecs




10.1016/j.neuron.2016.03.025








Neuron




90


3
















Estimating the dimension of a model




G
Schwarz




10.1214/aos/1176344136








The Annals of Statistics




6


2
















The nature of metacognitive inefficiency in perceptual decision making




M
Shekhar






D
Rahnev




10.1037/rev0000249








Psychological review




128


1
















Rtdists: Response time distributions




H
Singmann






S
Brown






M
Gretton






A
Heathcote






A
Voss






J
Voss






A
Terry


















Attention orienting and the time course of perceptual decisions: Response time distributions with masked and unmasked displays




P
L
Smith






R
Ratcliff






B
J
Wolfgang




10.1016/j.visres.2004.01.002








Vision research




44


12
















Evaluating the unequal-variance and dual-process explanations of zroc slopes with response time data and the diffusion model




J
J
Starns






R
Ratcliff






G
Mckoon




10.1016/j.cogpsych.2011.10.002








Cognitive psychology




64


1-2
















Optimal policy for value-based decision-making




S
Tajima






J
Drugowitsch






A
Pouget




10.1038/ncomms12400








Article 12400






7












Absolutely relative or relatively absolute: Violations of value invariance in human decision making




A
R
Teodorescu






R
Moran






M
Usher




10.3758/s13423-015-0858-8








Psychonomic Bulletin & Review




23


1
















The time course of perceptual choice: The leaky, competing accumulator model




M
Usher






J
L
Mcclelland








Psychological review




108


3


















10.1037/0033-295x.108.3.550


















R
Van Den Berg






K
Anandalingam






A
Zylberberg






R
Kiani






M
N
Shadlen






D
M
Wolpert


















A common mechanism underlies changes of mind about decisions and confidence. eLife, 5, Article e12192


10.7554/eLife.12192














Piéron's law and optimal behavior in perceptual decision-making




L
Van Maanen






R
P P P
Grasman






B
U
Forstmann






E.-J
Wagenmakers




10.3389/fnins.2011.00143








Frontiers in Neuroscience




5














Experimental paradigms emphasising state or process limitations: Ii effects on confidence




D
Vickers






P
Smith






J
Burt






M
Brown








Acta Psychologica




59


2


















10.1016/0001-6918(85)90018-6


















Interpreting the parameters of the diffusion model: An empirical validation




A
Voss






K
Rothermund






J
Voss




10.3758/BF03196893








Memory & Cognition




32


7
















Optimum character of the sequential probability ratio test




A
Wald






J
Wolfowitz




10.1214/aoms/1177730197








The Annals of Mathematical Statistics




19


3
















Sequential analysis




A
Wald








John Wiley














K
Zawadzka






P
A
Higham






M
Hanczakowski




10.1037/xlm0000321




Confidence in forced-choice recognition: What underlies the ratings? Journal of experimental psychology. Learning, memory, and cognition






43














Time-varying boundaries for diffusion models of decision making and response time




S
Zhang






M
D
Lee






J
Vandekerckhove






G
Maris






E.-J
Wagenmakers




10.3389/fpsyg.2014.01364








Frontiers in psychology




5














The construction of confidence in a perceptual decision. Frontiers in integrative neuroscience, 6, Article 79




A
Zylberberg






P
Barttfeld






M
Sigman




10.3389/fnint.2012.00079



















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]