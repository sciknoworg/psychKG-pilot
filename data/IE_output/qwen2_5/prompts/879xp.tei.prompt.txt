You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



The Special Section
The section opens with a focus on research design and conduct. Chalmers and Glasziou 
[2]
 identified four sources of research waste starting off with not asking the right research question. The first paper 
[11]
 in this special section explored the extent to which research questions in journals focused on PROs were clearly stated. The authors found that almost half of research questions were poorly framed or unframed. Even "adequately framed" questions rarely stated what researchers wanted to know a priori, increasing the risk of biased reporting. Despite standards for framing research questions being in use for over 30 years, researchers still often fail to include key elements when stating their research question. The first paper in the section summarizes existing frameworks available for formulating research questions and sets out two criteria for a good research question in the context of health outcomes research.
Further sources of research waste include poorly designed or conducted studies 
[12]
. Systematic reviews have shown that trial protocols often lack important information regarding PROs 
[13]
[14]
[15]
. To equip trialists with the motivation, knowledge and resources to write PRO content in trial protocols, the SPIRIT (Standard Protocol Items: Recommendations for Interventional Trials)-PRO guidance was developed 
[16,
17]
. The second paper 
[18]
 in this special section assessed whether 2-day educational workshops intended to educate researchers on key considerations for designing a PRO study and how these aspects should be addressed in a clinical trial protocol improved the PRO completeness of protocols against consensus-based minimum standards provided in the SPIRIT-PRO Extension 
[17]
. Although participants were highly satisfied with the workshops, completeness of PRO protocol content generally did not improve. Adverse consequences of not considering these minimum standards during study design and conduct may result in gathering inadequate or misleading information and lack of statistical precision or power. The authors highlighted the inadequacy of study protocols, failure to involve experienced PRO methodologists, and failure to train clinical researchers and statisticians in relevant PRO research methods and design, and provide suggestions for how future educational efforts may be more effective 
[18]
.
The third paper 
[19]
 addresses the importance of considering adequate sample size during study design to ensure research resources are utilized in an ethical manner and maximize impact and replicability. Common misconceptions related to sample size planning specific to (HR)QL/PRO studies and non-technical corrections to these misconceptions are discussed, including a sample size reporting checklist, to help researchers have a more nuanced understanding of sample size planning and items to consider during (HR)QL/PRO study design and reporting.
The second set of papers focuses on research waste related to reporting. Despite a number of guidelines developed to encourage better reporting across research designs 
[20,
21]
, research waste continues to be a major problem for (HR)QL/PRO research. Systematic reviews consistently report poor PRO reporting according to CONSORT (CONsolidated Standards for Reporting)-PRO reporting standards 
[20]
; studies either do not report PRO results or PRO results are inadequately reported 
[6,
22,
23]
, resulting in PRO results being unusable or not replicable, and calls into question the ethics of collecting PRO data that will not be used 
[2]
.
Three papers address the issue of inadequate reporting. The first paper 
[24]
 reports a systematic review of papers reporting EQ-5D utility weights in patients with coronary artery disease and highlights the difficulties researchers face when trying to retrieve and reuse published (HR)QL/PRO data. A major contributor of research waste is the inability to reuse and/or include published studies in meta-analyses due to insufficient reporting, threatening the reliability of meta-analysis results, and wastes researcher time and cost reviewing poorly reported papers. As the authors found, missing about half of the data points that might otherwise have been included is problematic and potentially harmful through reliance on such meta-analyses 
[25]
. Poor reporting is leading to similar problems in the context of cancer research 
[26]
[27]
[28]
. To reduce waste, the authors recommend that studies using the EQ-5D (or any PRO measure (PROM) for that matter) should report appropriate summary statistics to enable reuse in meta-analyses and include the PROM in the title or abstract in line with current reporting guidelines (CONSORT-PRO and SPIRIT-PRO Extensions).
The second paper 
[29]
 appraises the use of the CONSORT-PRO Extension as an evaluation tool for assessing the reporting of PROs in publications and describes the reporting of PRO research across reviews. The authors found that many PRO studies published after the release of CONSORT-PRO in 2013 did not report recommended CONSORT-PRO items, and studies reviewing PRO publications omitted or largely modified recommended items from their evaluations. Such variation in evaluations impacts knowledge translation and may lead to potential misuse of the CONSORT-PRO Extension.
The third paper 
[30]
 describes a project undertaken to develop a clear, unified, universally applicable approach for the translation, dissemination, and impact of research undertaken by Health Service Evaluation staff and organizations. The authors provide a threefold approach of providing information, guidance, and training in the form of an explainer video, guidance, and learning modules to those who create and use research knowledge. However, the authors caution that a knowledge translation approach on its own does not guarantee research findings will be implemented. Patient and public involvement is necessary during research design to ensure that research conducted is relevant, reflects patient priorities, and that appropriate PROs are assessed and PROMs used. The results from the three papers reinforce the need for better reporting, implementation and translation of (HR)QL/PRO results to practice to maximize the value of research informing health service delivery and policy and reducing avoidable research waste.
The section closes with papers on usability of results. The first paper 
[31]
 discusses how validity theory provides a framework to evaluate whether re-purposing and adapting an existing PROM for a new use (e.g., new patient population, altered recall period), rather than creating a new one, is needed. Four examples of modifications including changing mode of administration, the recall period, extending from one clinical indication to another, and adapting a "general" PROM to encompass disease-specific aspects of the concept of interest are presented to demonstrate these ideas in practice. The authors propose that rather than assuming any change to an existing PROM requires the entire development process to be repeated, which consequently requires extensive resources, we can consider the nature of the proposed change and use validity theory to evaluate which inference/claim is impacted (and to what extent), limiting development of de novo PROMs to when such development is absolutely necessary 
[31]
.
The special section closes with a paper 
[32]
 focused on inefficient research regulation and management practices as sources of research waste, and discusses opportunities in (HR)QL/PRO research enabled by data linkage and data registries; barriers to data access and use and the implications for waste in (HR)QL/PRO research; and proposed legislative reforms. The authors argue that rather than investing in (HR)QL/PRO data infrastructure to support multiple studies, there is reliance on collecting data de novo for discrete studies, resulting in research waste that arises "from questions being overlooked or unnecessarily addressed, research being underpowered or done too slowly, and research being too costly" 
[33]
.


Editorial Commentary
Research waste relating to the production and reporting of health and medical research is a major problem. It has been recognised that "[h]uge sums of money are spent annually on research that is seriously flawed through the use of inappropriate designs, unrepresentative samples, small samples, incorrect methods of analysis, and faulty interpretation" 
[34]
. In 2014, the Lancet series about increasing value and reducing waste in medical research estimated that 85% of research is wasted because studies ask the wrong questions 
[35]
, are poorly designed or conducted 
[12]
, are inefficiently regulated and managed 
[33]
, produce inaccessible information 
[25]
, and are not appropriately reported, disseminated, or translated into decision-making 
[10]
. These issues are pertinent to (HR)QL/PRO research. In an attempt to reduce waste and maximise efficiency, the Lancet's REWARD (REduce research Waste And Reward Diligence) Campaign invited everyone involved in research to critically examine how they work to reduce waste and maximise efficiency, and to strive to improve the value of the funds invested in the research we commission, deliver, publish, and implement 
[36]
. However, despite nearly a decade since the Lancet series, research waste is still a major problem. We therefore felt that a call for papers reporting current and innovative thinking, evidence, and approaches to reducing research waste and maximizing (HR)QL/PRO data would continue the effort. Papers in this special section discuss the many contributors to research waste and we take the opportunity to highlight what we think are ongoing issues that as researchers should all be mindful of, and potential ways in which we could all do our bit to reduce research waste in our field.
Poor (HR)QL/PRO study design, analysis, reporting, and application all contribute to research waste and reduce the benefit of (HR)QL/PRO data. As researchers and editors, we still see problems with study design across the (HR)QL/PRO literature. Firstly, better use of theoretical frameworks would allow researchers and practitioners to design better quality studies. For example, key terms in our field such as the PRO(M)s and (HR)QL are often used interchangeably or without clear definitions 
[37]
[38]
[39]
 when actually frameworks for these terms exist that could be used 
[40]
[41]
[42]
. Well-developed theoretical frameworks inform what needs to be assessed and when, and how constructs are operationalized in a specific setting. Use of theoretical frameworks could also help identify study design problems early on that arise from using PROMs for assessing the study's independent and dependent variables, whose items are in their entirety or in parts assessing the same construct(s). Such overlap leads to spuriously inflated relationships which have wide-ranging impacts on the interpretation of results 
[43]
.
A second set of problems directly related to these first considerations concerns the PROs assessed within studies and how to increase their relevance and appropriateness: 1) Uninformative PROs assessed -for example, likely intervention effects might include pain, fatigue and sexual dysfunction but only global HRQL is assessed;
2) Inappropriate PROMs used -for example, study outcomes of interest are stated as pain, fatigue and sexual dysfunction but only a generic HRQL instrument is used, which does not assess fatigue or sexual function; or using a PROM not well-targeted at the intendend population(s) and therefore unable to detect an intervention effect due to floor or ceiling effects. Related is the problem of jingle-jangle fallacies when different constructs are incorrectly assumed to be the same because of a shared label ("jingle", most commonly in our field is probably not differentiating between HRQL and QOL 
[37]
); or where different terms are used when describing in fact the same construct 
[44,
45]
;
3) Uninformative time-points for PRO assessment -for example, likely intervention effects occur 1 month post-intervention but PROs are assessed at baseline before intervention and then 6 months after intervention when intervention effects are diluted or resolved.
Planning PRO assessments informed by theoretical frameworks, be it for research or practice, will not only reduce research waste as an academic exercise, but likely increase the relevance of the research findings for clinical practice and policy. And in particular for HRQL research, it is during these stages of study design where input from key stakeholders including co-creation and coproduction is most beneficial for designing better quality studies and avoiding research waste 
[46]
.
A third problem area is study samples. While reporting guidelines 
[21]
 emphasise the importance of detailing how study participants were approached and any reductions in sample size from recruitment to the final analytic sample, this information is often not reported. Failure to report this limits transparency and the ability for readers to assess both quality and relevance of the sample for a particular research context and conceales the need for exploring the effects of such selection processes with appropriate additional details and/or sensitivity analyses. The problem with sampling is additionally conflated with exclusion of participants with missing PRO data, as it can cause loss of power and bias and seriously affect the external validity (generalizability) of the results. Strategies for reducing the instance and impact of missing PRO data have been summarised 
[47,
48]
, and methods to explore the impact of missing data on study results have been developed 
[49,
50]
. Finally, small sample sizes may be underpowered for confirmatory PRO objectives and hypotheses. Especially in medical research where sample sizes are based on clinical endpoints such as survival or biomedical indicators, the resulting sample size may be insufficient for PROs as secondary outcomes. All relevant study outcomes should be considered during study design and planning a priori. In our continued effort to give PROs a prominent role in studies evaluating patient-facing health care interventions, we have previously argued 
[51]
 that short of achieving this goal, registered papers or Registered Reports in particular offer new ways of: (i) gathering early feedback on publication plans, (ii) using writing resources earlier in the study process, and (iii) ensuring timely dissemination.
Inadequate or inappropriate analysis of PRO data is another source of research waste. For example, not considering confounders or multicollinearity in the analysis increases the chance of false positive findings, resulting in potentially misleading findings 
[52]
. From our experience, studies may also recruit patient samples with mixed disease type (e.g. breast, colon and lung cancer patients), stage (e.g. early stage disease vs advanced stage disease) and treatment, and/or with a wide variation of time since end of treatment to data collection but pool their data for analysis rather than report their results separately 
[26]
[27]
[28]
. These analyses are problematic as we cannot assume that their experiences and treatment impacts are equal and precludes observations due to specific treatment and disease type and stage. Pooling PRO data collected at widely variable times since diagnosis/end of treatment obscures patterns of adjustment over-time and rates of recovery, and tells us little about PRO trajectories but rather simply describes PROs in a sample of patients, which may have a purpose, but is not very useful for clinical decision making 
[26-28, 52, 53]
.
Many of these analysis problems could be mitigated with greater consideration of a study's theoretical foundation and research question(s). Analyses are the operational reflection of these aspects of the research process. An area where this becomes especially apparent are nonrandomised comparisons between participant groups. Such study designs are especially common in practice settings and can generate important insights with high relevance for implementation and application. But the descriptive report of causal differences between two groups (e.g. patients receiving two different treatments for the same condition) rarely results in actionable information.
And it almost surely does not inform any causal differences about the differential effectiveness of the compared treatments. Existing frameworks for determining causal effects are available 
[54]
[55]
[56]
[57]
, and considering them when developing observational research is crucial. These 'design' issues can all lead to inaccurate conclusions about the benefits and harms of interventions and could be potentially harmful to future patients. We propose that all researchers consider 'what is the purpose for collecting PROs', 'what information would be informative', and 'how will the PRO data be used' when designing their studies. This will then in turn inform sample size and analytical considerations, and lead to better quality PRO data.
Another important source of research waste is poor reporting. Reporting issues pertinent to our field include lack of critical details, failure to publish PRO results, over-interpretation (e.g. overemphasis on positive results/benefits, gloss over harms/negative findings, causal interpretation of non-causal findings), selective reporting (e.g. unpublished hidden PRO data, not analysed or not reported), the spin, and manipulation of data 
[22,
34,
36,
[58]
[59]
[60]
[61]
. Disappointingly, reporting guidelines exist but are not adhered to 
[29]
. A noteworthy finding from one of the papers in this special section 
[29]
, of 13 journals that published reviews synthesizing PRO studies, none recommended use of the CONSORT-PRO reporting guidelines specifically; five recommended use of EQUATOR or CONSORT guidelines, and nine did not mention either in their instructions to authors. It seems journals publishing PRO studies have not endorsed use of the CONSORT-PRO. Author instructions and administrative checks by journals may be potential mechanisms/forcing functions to ensure better reporting. We would argue that a paper that adheres to reporting guidelines better places a reader to assess the quality of the study design and conduct and to interpret its findings accurately, improving the potential of the research to be impactful and meaningful to patients and clinical practice.
Not only does poor (HR)QL/PRO study design, conduct, analysis and reporting contribute to research waste, they limit the extent to which PRO data can benefit patients and inform clinical practice. Increasing the quality, availability and use of (HR)QL/PRO data may ultimately enable this data to inform public health, clinical practice and health policy. Assessment of PROs in a study should only be included if they will inform future decision making. Assessing outcomes such as HRQL requires time and effort. Researchers need to plan the HRQL data collection, and then enter the data, analyse it and report it. Patients spend their time completing the PROM(s) and staff at sites need to ensure that the PRO assessments are completed at scheduled time-points and record reasons for noncompletion if they are not. And collecting PROs is expensive -there are costs associated with PROM licencing, staff time and administration costs. So all this needs careful thought and planning so that PRO data are collected in a scientifically robust and meaningful way.
Resources exist to help researchers design (HR)QL/PRO studies, such as what to include in a PRO study protocol 
[16]
 and recommendations for selecting PROMs 
[62,
63]
, analysizing PRO data 
[52]
, and reporting PRO studies 
[20]
. A new initiative, PROTEUS (Patient-Reported Outcomes Tools: Engaging Users & Stakeholders), is promoting the systematic use of available tools to optimize the design, analysis, reporting, and interpretation of PROs in clinical trials 
[64]
. The PROTEUS website includes checklists, web tutorials, and other resources to support the optimal use of PROs. And the individual papers in this special section provide additional resources for reducing research waste in our field. However, without education about robust PRO methodology, appreciation for the importance of high-quality research design, conduct and reporting, and dissemination and use of available resources, we will continue to contribute research waste and not realise the value of PRO data. Study design tools and reporting guidelines are just one part of the job. It is ultimately the responsibility of researchers to ensure appropriate methods are applied in any specific study, and it is ultimately the responsibilty of authors to ensure their study methods and conduct are adequately justified and reported.
We are grateful for the excellent range of submissions received and to all authors and reviewers involved in selecting the published papers. The issues raised in our commentary are only a small selection relevant to us as HRQL/PRO researchers, editors, and to the whole research and practice field. The papers in this special section further highlight sources of research waste and provide resources, recommendations and possible solutions for reducing research waste and maximizing PRO data. However, discussion of research waste since Chalmers and Glasziou 
[4]
 introduced the problem, highlights other areas that impact on the available resources we have to conduct research such as time needed for grant writing and peer-review in funding processes 
[65,
66]
; and not least at ourselves, with view to the peer-review of publications 
[67,
68]
. These issues become even more pertinent when we consider that "health" is a global priority needing a global agenda 
[69]
[70]
[71]
. We expect therefore that the topic of research waste related to (HR)QL/PRO research and practice will remain an important issue on our community's agenda.
 












Research waste is still a scandal-an essay by Paul Glasziou and Iain Chalmers




P
Glasziou






I
Chalmers








BMJ




363


4645














Avoidable waste in the production and reporting of research evidence




I
Chalmers






P
Glasziou








Lancet




374


9683
















The impact of patient-reported outcome data from clinical trials: perspectives from international stakeholders




Cruz
Rivera






S
Mcmullan






C
Jones






L
Kyte






D
Slade






A
Calvert






M








Journal of Patient-Reported Outcomes




4


1


51














A systematic evaluation of compliance and reporting of patient-reported outcome endpoints in ovarian cancer randomised controlled trials: implications for generalisability and clinical practice




R
Mercieca-Bebber






M
Friedlander






M
Calvert






M
Stockler






D
Kyte






P-S
Kok








Journal of Patient-Reported Outcomes




1


1


5














Establishing the values for patient engagement (PE) in health-related quality of life (HRQoL) research: an international, multiple-stakeholder perspective




K
Haywood






A
Lyddiatt






S
J
Brace-Mcdonnell






S
Staniszewska






S
Salek








Quality of Life Research




26


6
















Preliminary evidence on the uptake, use and benefits of the CONSORT-PRO extension




R
Mercieca-Bebber






J
Rouette






M
Calvert






M
T
King






L
Mcleod






P
Holch








Qual Life Res




26


6
















Patient-reported outcome measures in older people with hip fracture: a systematic review of quality and acceptability




K
L
Haywood






J
Brett






E
Tutton






S
Staniszewska








Quality of Life Research




26


4
















Minimising research waste and maximising the impact of patient reported outcome trial results




M
Calvert






M
King






M
Brundage








Quality of Life Research




27


3














Biomedical research: increasing value, reducing waste




M
R
Macleod






S
Michie






I
Roberts






U
Dirnagl






I
Chalmers






J
P
Ioannidis








Lancet




383


9912
















Reducing waste from incomplete or unusable reports of biomedical research




P
Glasziou






D
G
Altman






P
Bossuyt






I
Boutron






M
Clarke






S
Julious








Lancet




383


9913
















Reducing research wastage by starting off on the right foot: optimally framing the research question




N
E
Mayo






N
Ow






M
Asano






S
Askari






R
Barclay






S
Figueiredo




10.1007/s11136-022-03117-y








Quality of Life Research
















Increasing value and reducing waste in research design, conduct, and analysis




J
P
Ioannidis






S
Greenland






M
A
Hlatky






M
J
Khoury






M
R
Macleod






D
Moher








Lancet




383


9912
















Systematic evaluation of the patient-reported outcome (PRO) content of clinical trial protocols




D
Kyte






H
Duffy






B
Fletcher






A
Gheorghe






R
Mercieca-Bebber






M
King








PLoS One




9


10


110229














Systematic Evaluation of Patient-Reported Outcome Protocol Content and Reporting in Cancer Trials




D
Kyte






A
Retzer






K
Ahmed






T
Keeley






J
Armes






J
M
Brown








J Natl Cancer Inst




111


11
















The patientreported outcome content of international ovarian cancer randomised controlled trial protocols




R
Mercieca-Bebber






M
Friedlander






P
S
Kok






M
Calvert






D
Kyte






M
Stockler








Qual Life Res




25


10
















SPIRIT-PRO Extension explanation and elaboration: guidelines for inclusion of patient-reported outcomes in protocols of clinical trials




M
Calvert






M
King






R
Mercieca-Bebber






O
Aiyegbusi






D
Kyte






A
Slade








BMJ Open




11


6


45105














Guidelines for Inclusion of Patient-Reported Outcomes in Clinical Trial Protocols: The SPIRIT-PRO Extension




M
Calvert






D
Kyte






R
Mercieca-Bebber






A
Slade






A
W
Chan






M
T
King








Jama




319


5
















Improving the patientreported outcome sections of clinical trial protocols: a mixed methods evaluation of educational workshops




M
T
King






M
A
Tait






R
Campbell






F
Müller






C
Rutherford






C
Beckmore




10.1007/s11136-022-03127-w








Qual Life Res
















Power(ful) myths: misconceptions regarding sample size in quality of life research




S
F
Anderson




10.1007/s11136-021-03020-y








Quality of Life Research
















Reporting of patientreported outcomes in randomized trials: the CONSORT PRO extension




M
Calvert






J
Blazeby






D
G
Altman






D
A
Revicki






D
Moher






M
D
Brundage








Jama




309


8
















EQUATOR network














A systematic evaluation of compliance and reporting of patient-reported outcome endpoints in ovarian cancer randomised controlled trials: implications for generalisability and clinical practice




R
Mercieca-Bebber






M
Friedlander






M
Calvert






M
Stockler






D
Kyte






P
S
Kok








J Patient Rep Outcomes




1


1


5














Patient-reported outcomes in head and neck and thyroid cancer randomised controlled trials: A systematic review of completeness of reporting and impact on interpretation




R
L
Mercieca-Bebber






A
Perreca






M
King






A
Macann






K
Whale






S
Soldati








Eur J Cancer




56
















Reducing waste in collection of quality-of-life data through better reporting: a case study




V
Mccreanor






E
Lum






N
Graves






N
Luo






W
Parsonage






A
Barnett








Qual Life Res


















10.1007/s11136-022-03079-1














Increasing value and reducing waste: addressing inaccessible research




A
W
Chan






F
Song






A
Vickers






T
Jefferson






K
Dickersin






P
C
Gøtzsche








Lancet




383


9913
















Patient-reported outcomes and experiences from the perspective of colorectal cancer survivors: meta-synthesis of qualitative studies




C
Rutherford






F
Müller






N
Faiz






M
T
King






K
White








J Patient Rep Outcomes




4


1


27














Patient-reported outcomes in non-muscle invasive bladder cancer: a mixed-methods systematic review




C
Rutherford






M
I
Patel






M
A
Tait






D
P
Smith






Dsj
Costa






S
Sengupta








Qual Life Res




30


2
















Patient-reported outcomes in ductal carcinoma in situ: A systematic review




M
T
King






Z
E
Winters






I
A
Olivotto






A
J
Spillane






B
H
Chua






C
Saunders








Eur J Cancer




71
















Knowledge translation concerns for the CONSORT-PRO extension reporting guidance: a review of reviews




R
Mercieca-Bebber






O
L
Aiyegbusi






M
T
King






M
Brundage






C
Snyder






M
Calvert




10.1007/s11136-022-03119-w








Qual Life Res
















Supporting researchers in knowledge translation and dissemination of their research to increase usability and impact




V
Minogue






M
Morrissey






A
Terres








Qual Life Res


















10.1007/s11136-022-03122-1














Using validity theory and psychometrics to evaluate and support expanded uses of existing scales




C
R
Houts






E
N
Bush






M
C
Edwards






R
J
Wirth








Quality of Life Research


















10.1007/s11136-022-03162-7














Challenges and opportunities for using population health data to investigate cancer survivors' quality of life in Australia




I
Ramsey






N
Corsini






A
Hutchinson






J
Marker






M
Eckert




10.1007/s11136-022-03112-3








Qual Life Res
















Increasing value and reducing waste in biomedical research regulation and management




Al-Shahi
Salman






R
Beller






E
Kagan






J
Hemminki






E
Phillips






R
S
Savulescu






J








Lancet




383


9912
















The scandal of poor medical research




D
G
Altman








Bmj




308


6924
















How to increase value and reduce waste when research priorities are set




I
Chalmers






M
B
Bracken






B
Djulbegovic






S
Garattini






J
Grant






A
M
Gülmezoglu








Lancet




383


9912


















The Lancet. The REWARD Statement












How is quality of life defined and assessed in published research? Quality of Life Research




Dsj
Costa






R
Mercieca-Bebber






C
Rutherford






M-A
Tait






M
T
King








30














How is subjective well-being related to quality of life? Do we need two concepts and both measures?




S
M
Skevington






J
R
Böhnke








Social Science & Medicine




206
















A systematic review of quality of life research in medicine and health sciences




K
Haraldstad






A
Wahl






R
Andenaes






J
R
Andersen






M
H
Andersen






E
Beisland








Quality of Life Research




28


10
















Advances and Open Questions in the Science of Subjective Well-Being




E
Diener






R
E
Lucas






S
Oishi








Collabra: Psychology




4


1














Linking clinical variables with health-related quality of life. A conceptual model of patient outcomes




I
B
Wilson






P
D
Cleary








Jama




273


1
















World Health Organisation. International Classification of Functioning, Disability and Health (ICF














Overlap of Depressive Symptoms with Health-Related Quality-of-Life Measures




R
D
Hays






P
M
Fayers








Pharmacoeconomics




39


6
















Grand Challenges for Positive Psychology: Future Perspectives and Opportunities




L
E
Van Zyl






S
Rothmann








Frontiers in Psychology




13














Sport Motivation Orientations: Beware of Jingle-Jangle Fallacies




H
W
Marsh








Journal of Sport and Exercise Psychology




16


4
















Patient and public involvement in reducing health and care research waste




V
Minogue






M
Cooke






A-L
Donskoy






P
Vicary






B
Wells








Research Involvement and Engagement




4


1


5














Design, implementation and reporting strategies to reduce the instance and impact of missing patientreported outcome (PRO) data: a systematic review




R
Mercieca-Bebber






M
J
Palmer






M
Brundage






M
Calvert






M
R
Stockler






M
T
King








BMJ Open




6


6


10938














Practical and statistical issues in missing data for longitudinal patientreported outcomes




M
L
Bell






D
L
Fairclough








Stat Methods Med Res




23


5
















Handbook of Missing Data Methodology 1st Edition




G
Molenberghs






G
Fitzmaurice






M
G
Kenward






A
Tsiatis






G
Verbeke








Chapman and Hall CRC


Boca Raton












Flexible Imputation of Missing Data




S
Van Buuren








Chapman and Hall/CRC


New York












Registered Reports at "Quality of Life Research




J
R
Boehnke






C
Rutherford








Quality of Life Research




29


10
















International standards for the analysis of quality-of-life and patient-reported outcome endpoints in cancer randomised controlled trials: recommendations of the SISAQOL Consortium




C
Coens






M
Pe






A
C
Dueck






J
Sloan






E
Basch






M
Calvert








Lancet Oncol




21


2
















Comprehensive review of statistical methods for analysing patient-reported outcomes (PROs) used as primary outcomes in randomised controlled trials (RCTs) published by the UK's Health Technology Assessment (HTA) journal




Y
Qian






S
J
Walters






R
Jacques






L
Flight








BMJ Open




11


9


51673














DAG-informed regression modelling, agent-based modelling and microsimulation modelling: a critical comparison of methods for causal inference




K
F
Arnold






W
J
Harrison






A
J
Heppenstall






M
S
Gilthorpe








International Journal of Epidemiology




48


1
















Causal Effects in Clinical and Epidemiological Studies Via Potential Outcomes: Concepts and Analytical Approaches




R
J
Little






D
B
Rubin








Annual Review of Public Health




21


1
















On the limitations of comparative effectiveness research




D
B
Rubin








Statistics in Medicine




29
















Mostly Harmless Econometrics: An Empiricist's Companion




J
D
Angrist






J-S
Pischke








Princeford University Press


Princeton and Oxford












Research: increasing value, reducing waste








The Lancet
















The importance of patient-reported outcomes in clinical trials and strategies for future optimization




R
Mercieca-Bebber






M
T
King






M
J
Calvert






M
R
Stockler






M
Friedlander








Patient Relat Outcome Meas




9
















False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant




J
P
Simmons






L
D
Nelson






U
Simonsohn








Psychol Sci




22


11
















HARKing: hypothesizing after the results are known




N
L
Kerr








Pers Soc Psychol Rev




2


3
















Choosing patient-reported outcome measures for cancer clinical research--practical principles and an algorithm to assist non-specialist researchers




T
Luckett






M
T
King








Eur J Cancer




46


18
















Patient-reported outcome instrument selection: designing a measurement strategy




C
F
Snyder






M
E
Watson






J
D
Jackson






D
Cella






M
Y
Halyard








Value Health




10


2










Suppl
















PROTEUS Consortium. About PROTEUS
















Science funders gamble on grant lotteries




D
Adam








Nature




575
















NIH peer review percentile scores are poorly predictive of grant productivity




F
C
Fang






A
Bowen






A
Casadevall








eLife




5


13323














A billion-dollar donation: estimating the cost of researchers' time spent on peer review




B
Aczel






B
Szaszi






A
O
Holcombe








Research Integrity and Peer Review




6


1


14














Does it take too long to publish research?




K
Powell








Nature




530


7589
















Reform of research funding processes could pave the way for progress in global health. The Lancet Global Health




G
Ashuntantang






V
Luyckx






S
Naicker






S
Venkatapuram








9














Global health research funding applications: brain drain under another name? The Lancet Global Health




A
Bekele






K
Chu






D
'ambruoso






L
Davies






J
I
Ferriolli






E
Greig






C








10














Transforming global health through equitydriven funding




J
O
Olusanya






O
I
Ubogu






F
O
Njokanma






B
O
Olusanya








Nature Medicine




27


7

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]