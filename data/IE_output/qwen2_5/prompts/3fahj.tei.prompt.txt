You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
How do people choose between sets of options, such as when selecting between restaurants with different menus or shops with different products? Comparing sets of items is complex and may depend on internal cohesion; a shop with similar items may be preferable to one with dissimilar items. In economic decisions, sets following simple organizing principles tend to be liked better than sets that do not 
(Evers et al., 2014;
Winkielman & Cacioppo, 2001;
Chernev & Gal, 2010;
Karmarkar et al., 2021;
Walker & Vul, 2014;
Yadav, 1994)
. For example, when selecting a fruit basket for the holidays, the relations between fruits might contribute to the overall attractiveness of the basket.
Factors like similarity can impact choice between bundles 
(Agarwal & Chatterjee, 2003;
Gaeth et al., 1991;
Harlam et al., 1995;
Karataş & Gürhan-Canli, 2020;
Friedman et al., 2018)
. Together, the takeaway from previous work is that people evaluate sets by grouping individual items to facilitate processing, and that the similarity within such groups can increase their attractiveness.
A large body of research has explored how people assess similarity among objects 
(Goldstone & Son, 2005;
Shepard, 1987;
Barsalou, 1982;
Markman & Gentner, 1993;
Medin et al., 1993;
Tversky, 1977;
Nosofsky, 1992)
. Several leading theories predict that similarity among individual objects in a set can facilitate processing 
(Koffka, 1935;
Kahneman et al., 1992;
Ariely, D. 2001;
Bhatia & Mullett, 2018;
Wagemans et al., 2012;
Bhui, 2018)
, supporting the idea that similarity can benefit set choices.
Unfortunately, research on set choice has been limited by the lack of a widely accepted definition of similarity. Many studies investigating similarity in choices between sets rely on stylized examples, such as selecting between two patterns of dots, strings of numbers, groups of faces, or sets of pens (for reviews, see 
Goldstone & Son, 2005;
Hahn, 2014)
. While such work is informative for sets comprising identical items vs. oddballs or items varying across categorical boundaries 
(Evers et al., 2014)
, it may not provide a generalizable account for how people evaluate sets of items with varying degrees of similarity.
To address some of these limitations, we turn to network-based models, which can flexibly represent not only the nature of a "set" as a collection of items, but also the inter-item relationships in a way that can accommodate gradients of similarity. These models construct networks of nodes (i.e., items) connected by edges that represent relationships between those items. Network-based approaches for studying cognition have a rich history within psychology 
(Borgatti et al., 2009;
Baronchelli et al., 2013;
Collins & Loftus, 1975;
Steyvers & Tenenbaum, 2005)
. Specific to our application, abstract relations between objects, sometimes called semantic representations, can be modeled as networks 
(Zemla, 2022)
. Although chiefly applied to studying language and memory (for review, see 
Kumar et al., 2021)
, cognitive network modeling approaches have also been used to study a range of phenomena, such as creative problem-solving 
(Kenett et al., 2014)
, similarity judgments 
(De Deyne et al., 2016)
, risk attitudes 
(Wulff & Mata, 2022)
, and moral beliefs 
(Turner-Zwinkels et al., 2021)
. In value-based decision-making, network-based approaches have been underutilized, with the exception of work using distributional semantic models to understand representations in decisionmaking 
(Bhatia & Aka, 2022;
Gandhi et al., 2022)
.
By constructing networks from related items, we can extract information about individual nodes and edges as well as information about the set as a whole 
(Siew et al., 2019)
. Specifically, we can assess an item's "importance" via the centrality of that node's position in the network 
(Borgatti et al., 2009;
Dalege et al., 2017)
. We can also measure the connectedness of a subset of items using subgraphs 
(Siew et al., 2019)
.
In this paper we construct networks based on liking ratings, i.e., two strongly connected items tend to have coupled ratings. We use liking ratings rather than commercial category information or general semantic relations because a liking rating is a simple summary statistic that can be easily measured for any item and is directly relevant to preferential choice. Similarity is not a fixed relationship between items; it strongly depends on the context in which it is evaluated 
(Hahn, 2014)
. We call our version "preference similarity", because it is derived from preference data. Using network-based approaches, we leverage a suite of well-developed quantitative tools from graph theory and network science to capture relationships between items based on correlations in their liking ratings 
(Siew et al., 2019)
. We can then test whether those relationships influence decision-making.
Past work on set choice has mostly focused on experimentally varying aspects of single sets, sometimes referred to as bundles, to examine how people evaluate them.
When studies do examine choices between sets, it's often to serve a larger goal, such as identifying differences in sequentially creating sets from scratch 
(Simonson, I. 1990;
O'Donnell, M., 2023)
 or investigating phenomena like variety-seeking 
(Read, D., & Loewenstein, G., 1995;
Zhang, Y, 2022)
. In our work, rather than focusing on the evaluation of single sets, we aim to understand the factors at play when comparing between them. We examine cases where the decision-makers feel they are choosing all the items in the set or choosing the set to access just one item.
Here, we analyze both node-level and set-level network measures derived from preferences to assess their impact on decisions between sets of items, specifically snack foods. We first propose an application of network analysis as a measure for preference similarity. We validate this using three pre-existing datasets (Rating Studies) and two new experiments (Set-Choice Studies 2-3). Then, we test the hypothesis that people prefer sets with items that are more well connected, i.e., more similar. Using our model of preference similarity, we find little evidence for such a set-level effect. Based on the results of Set-Choice Study 1, we formulate a second hypothesis that people prefer sets containing more central items. We find evidence for this node-level effect in Set-Choice Studies 2-3. Finally, using two pre-existing datasets (Single-Choice Studies 1-2), we demonstrate that the item-level centrality effects are mostly specific to set-based choice.


General Methods
We utilize data from five publicly available datasets and three newly acquired datasets as summarized in 
Table 1
. Of the existing datasets, three comprise liking ratings for food items (Rating Studies 1-3), while the remaining two involve binary choices between individual food items (Single-Choice Studies 1-2). The newly acquired datasets, Set-Choice Studies 1-3, involve liking ratings, similarity judgments, and binary choices between sets of food items. To determine the required sample size for Set-Choice Study 2, we ran a simulation-based power analysis using the model specification for the mixed-effects logistic regression from Set-Choice Study 1. Using the R package simr 
(Green et al., 2016
) and data from Set-Choice Study 1, we simulated datasets with the specified fixed and random effect structure and varying sample size. We determined that to have 80% power to detect a significant minimum effect size of interest with 100 trials, we would need at least 75 participants. Therefore, we determined that a sample size of 75 would give us adequate power. Similarly, for Set-Choice Study 3, using the same procedure, we determined that a sample size of 100 would be sufficient for adequate power.
However, during data collection, the research lab relocated to a different university, and the IRB-approved protocol expired before we could complete data collection. As a result, we were unable to meet our preregistered sample size, which we acknowledge as a potential limitation.
Design and procedure. All Set-Choice Studies began with an exposure and rating task.
Participants first passively observed images of 60 food items. Each food was presented for 750 ms at a resolution of 520 x 650 px, centered on a white background. The purpose of this task was to familiarize participants with the full set of items.
Next, in the rating task, participants were asked to rate how much they would like to eat each food "right now" 
(Fig. 4A
). The rating scale ranged from to 100, corresponding to ratings from "Not at all" to "Very much!". Participants were able to revise their rating as many times as they liked before clicking a "continue" button.
Next, participants completed a binary choice task between sets of six foods ( 
Fig.   4B
; detailed below).
Finally, in Set-Choice Studies 2-3, participants were asked to assess preference similarity for 100 sets of six items 
(Fig. 4C
). For each set, participants were asked: "if someone likes one of the foods, how likely is it that they also similarly like the other foods?" The rating scale ranged from 1 to 100, corresponding to ratings from "Not at all likely" to "Very likely". To motivate participants to take the task seriously, we incentivized them with a bonus task-based payment. At the end of the study, we randomly selected a pair of sets and compared their reported preference similarity ratings. If the participant correctly identified the set with less variance in ratings (as determined from Lee & Holyoak 2021), they received a bonus of $2.
Materials. All Set-Choice Studies were conducted online through a web application built using JSPsych (de 
Leeuw, 2015)
. Our stimulus set consisted of 60 foods. These foods were drawn from a larger set of 200 digital images 
(Lee & Coricelli, 2020)
, each representing a distinct snack food. Our subset of 60 items provides the least variable ratings (within each item) across participants 
(Lee & Holyoak, 2021)
. Using these foods we constructed 100 sets, each consisting of six food items. We generated these 100 sets quasi-randomly from the estimated association network, subject to a few constraints that ensured that they differed in set-level network organization (for details, see Supplemental Materials). We presented each set in a 2x3 array centered in front of a white background. All images were displayed in the same size and resolution (197 x 600 px).


Association Networks Characterize Preference Relations
We first establish the feasibility of our computational approach for characterizing similarity in preferences, doing so in three parts. In the first part, we used liking-rating data collected in prior research 
(Lee & Holyoak, 2021)
 to generate a network that we could use to capture similarity. Our basic argument is that two items whose liking rating are coupled, i.e., that tend to both be liked or both be disliked, are almost by definition, similarly liked. To validate this argument, in the second part, we had participants perform a subjective similarity task. We then tested whether our model's preference-similarity estimate correlated with the observed subjective similarity (Zelma, 2022). The third part further validated the generality of the computational approach beyond food items by applying the method to liking-rating data for a wide range of products. The rating scale ranged from 1 to 100, corresponding to ratings from "Not at all" to "Very much!". In Rating Study 2, participants viewed a series of 211 consumer products and were instructed to rate how much they would like to have each one, by clicking on an analog liking scale from (not at all) to 10 (a lot). In Rating Study 
(Li, X., et al., 2023)
, participants rated 138 food items on a scale from 0 (least) to 10 (most) for how much they would prefer to eat that food today. A score of 0 indicated they did not want to eat that food at all, while 10 indicated that they most strongly preferred to eat that food.


Methods
Computational approach. We used network modeling of Lee and Holyoak 2021 to determine similarity between items using an association network. Sometimes referred to as a Gaussian Graphical Model 
(Lauritzen, 1996)
, an association network is a weighted graph = ( , , ), where V represents the set of variables, E denotes the edges (i.e., dependencies) between them, and W indicates the strength of these dependencies. In our case, nodes represent food items and edges represent the correlations between them 
(Fig. 4D
).
To construct our association network, we applied the graphical least absolute shrinkage and selection operator (GLASSO; 
Friedman, Haste, & Tibshirani, 2008
. The LASSO is a regularization technique that reduces small parameter estimates to zero 
(Tibshirani, 1996)
. The GLASSO uses a parameter ( ) to control the sparsity of the network. Following previous work, we computed network models across 100 values of and selected the model that minimized the extended Bayesian information criterion (EBIC; 
Chen & Chen, 2008;
Epskamp & Fried, 2018)
. EBIC model selection uses a hyperparameter gamma ( ) to control how much it prefers simpler models (i.e., models with fewer edges; 
Foygel & Drton, 2010)
. Larger values lead to sparser models, while smaller values lead to denser models. When = 0, the EBIC equals the Bayesian information criterion. We followed recommendations from previous work and set to 0.5 
(Epskamp & Fried, 2018)
.
Having constructed the network, we next aimed to demonstrate that the network provides information that maps onto similarity. Specifically, we sought to partition the estimated network into groups of nodes that are 1) well connected among themselves and 2) relatively well separated from the remaining nodes. To do so, we conducted an Exploratory Graph Analysis (EGA) 
(Golino & Epskamp, 2016)
. EGA first applies a network estimation method (in our case, GLASSO) followed by a community detection algorithm, in our case, the Walktrap algorithm 
(Pons & Latapy, 2006;
Fortunato, 2010)
, which is recognized for its robustness in accurately recovering underlying community structure 
(Brusco et al., 2022)
.
To evaluate and ensure robustness in our estimation and partitioning of the network, we employed Bootstrap Exploratory Graph Analysis (bootEGA). BootEGA involves generating a series of bootstrap samples and applying EGA to each sample, thereby creating a sampling distribution of EGA results 
(Christensen & Golino, 2021)
.
This procedure leverages the initial correlation matrix to generate new replicate data from a multivariate normal distribution. EGA is then applied to these replicate data sets iteratively, until the desired number of samples is reached (e.g., 1000). The result is a sampling distribution of association networks. From this distribution, we extracted the median number of communities, the 95% confidence intervals around this median, and the frequency of certain community counts being replicated. We estimated a median association network structure by computing the median value of each edge across the replicate networks, resulting in a single network that represents the typical structure within the sampling distribution.
Analytical approach. To characterize set-level similarity for the stimuli in Set-Choice Studies 1-3, we needed to extract and compute a similarity score for each 6-item set. For each set we created a subgraph from the median network by extracting the six items and all the non-zero edges between them (for mathematical details, see Supplemental Materials online). We then computed set-level scores for each subgraph. These scores use associative properties to capture the relationships between the items in a set. For instance, the average strength of a subgraph indicates the magnitude of connections between the nodes. In our context, a higher average strength indicates stronger correlations between food items 
(Fig. 1C
).
We next investigated how these set-level scores from the network analysis corresponded to participants' set-level similarity judgments. For our Bayesian correlations, we specified a noninformative prior for ρ based on previous work 
(Wagenmakers et al., 2016)
. We report the median of the posterior distribution and its 95% HDI (Highest Density Interval), along with the probability of direction (pd, 
Makowski et al., 2019)
.
We used R (version 4.0.2). To compute the correlation matrix and network estimation GLASSO we used the qgraph package 
(Epskamp et al., 2012)
. We applied EGA using the EGAnet package (version 1.0.0; 
Golino & Christensen, 2023)
. The Walktrap algorithm was implemented using the igraph package 
(Csardi & Nepusz, 2006)
. Centrality measures were computed using the igraph package 
(Csardi & Nepusz, 2006
) and the NetworkToolbox package 
(Christensen, 2018)
.


Results
The bootEGA analysis resulted in a median association network with seven communities 
(Fig. 1a)
. The majority of EGA community estimates aligned with the median solution in bootstrapped samples, with small corresponding CIs, suggesting satisfactory structural stability, which is the extent to which food items within a community are homogeneous and interrelated given the structure of the set of items. More specifically, the structural stability of a given communitydetection partition is defined as the proportion of times each empirically derived community is recovered from the replicate bootstrap samples with an identical item composition. We explored the stability of these community estimates, finding that the most frequent number of detected communities in the bootstrap-samples was seven (more precisely, seven communities were found in 31.9% of replica samples), which is close to the median value (six communities were found in 31.7% of replica samples) of the same distribution with a moderately narrow 95% confidence interval of (lower = 3.84% and upper = 8.16%; for details see Supplemental materials). It is important to note that since community detection was applied to the extracted median association network, the resulting number of detected communities can deviate from median number derived from the bootstraps. Notably, the distribution of different food items into communities aligns well with the kinds of foods they arewe observe communities for meat/cheese, fruits/vegetables, sweet pastries, chocolate, chips, crackers, and bread ( 
Fig. 1d
). Intuitively, this means that people's preferences are relatively consistent within each of these communities. For instance, a positive edge between blackberries and raspberries indicates that a person who likes blackberries also probably likes raspberries. Conversely, a negative edge between fruit and ice cream indicates that a person who likes fruit probably dislikes ice cream. Intriguingly, we see little to no evidence of negative associations in the network.   
Fig. 1a, center)
. Crucially, the assigned communities align with our intuition. Communities such as "recreational" contain items like golf balls and fishing rods, while "kitchen" includes items like a French press and Instant Pot. Using data from
Rating Study 3, we return to food items, but with an entirely new set of stimuli and a new participant sample. The analysis again results in a median association network with seven communities 
(Fig. 1a)
 


Set Choice Is Predicted by Node (item) Properties, Not Subgraph (set) Properties
The prior section shows that preference similarity derived from correlations in liking ratings align well with subjective similarity. Here, we directly test the hypothesis that in decisions between sets of items, more similar (i.e., well-connected) sets will be chosen more often and more quickly.


Methods
Participants. We used Set-Choice Studies 1-3 which had samples of 30, 75, and 79 participants respectively.
Design and procedure. In each trial, participants were presented with two sets, one on each side of the screen and were instructed to choose the set that they preferred.
Participants used the F key to choose the set on the left and the J key to choose the set on the right. Participants were instructed to make selections at their own pace. No pair of sets was shown more than once. Participants completed a total of 99, 100 and 100 trials in Set-Choice Studies 1, 2, and 3 respectively.
Set-Choice Study 3 was incentive compatible; for one in ten participants, we randomly selected one trial and a food from the chosen group of six items and shipped that food to the participant directly (via Amazon Fresh).
Materials. For the choice task, two sets were positioned side by side, centered in front of a consistent white background. Each set consisted of six food images arranged in a 2x3 array. All images were displayed in the same size and resolution (197 x 600 px).
Analytic approach. We used the median network resulting from the modeling above to select the food items for the Set-Choice Studies, computed similarity scores, and related those scores to the choices made between sets and individual items. Initially, we used the set-level scores from the association network to assess the impact of set similarity (as determined by set-level network measures) on participants' choices and response times (RT).
To test our hypotheses, we ran Bayesian hierarchical models, specifically a logistic regression for the choice data. In the choice models, we included participantlevel liking ratings and set-level scores from the association network:
( ℎ ) = 0 + 1 + 2 ℎ + 3 + 4 ℎ + 5 × + 6 ℎ × ℎ
The rating variables were calculated by summing the six food ratings within a set. The network variables were calculated using the induced subgraph. For example, edge density, which is the ratio of actual edges to the total possible edges, is determined by first inducing subgraphs from the food association network and then computing the statistic for the subgraph. It is important to note that the network scores were derived from Rating Study 1 (Lee & Holyoak 2021), not the ratings from our experiments. We conducted a linear regression for the log-transformed RT which included the absolute difference in ratings (|vd|), the absolute difference in network scores (|nd|), and the summed ratings across both sets (i.e., overall valueov):
log = 0 + 1 | | + 2 | | + 3
For both choice and RT models regressors were standardized participant-wise, by the participant's mean and standard deviation. We ran these regressions at the grouplevel, allowing for full participant random effects.
We fit the models using brms version 2.18.0, an interface to fit Bayesian generalized (non-) linear multivariate multilevel models using Stan, a C++ package for performing Bayesian inference. We ran four parallel chains for 10,000 iterations each.
The first halves of each chain were the warm-up samples and were discarded. We used recommended default weakly informative priors specified by the brms package for each model 
(Bürkner, 2017)
. To assess the convergence and stability of the Bayesian sampling algorithm, we computed the Gelman-Rubin convergence diagnostic, which should be below 1.01 
(Vehtari et al., 2019)
, and Effective Sample Size (ESS), which should be greater than 1000 
(Bürkner, 2017)
.
Next, we assessed the impact of node centrality on set choice. The hypothesis here was that sets with more well-connected items might be more attractive because they seem to generally fit well in sets. To test this hypothesis, we ran additional regression models similar to those above, but replaced the network variables with centrality variables. Given the range of possible measures available, we used a principal component analysis rather than relying solely on any single measure of centrality. Since Principal Components (PCs) PC1 and PC2 jointly account for more than 80% of the total variances in centrality measures under consideration, these two PCs act as our network scores for our behavioral analysis. We assessed the effect of node centrality by PC 1 and PC2 alone or by PCs 1 and 2 combined (for additional details, see the Supplemental Material available online). For our main analysis below, we control for PC1 but only report PC2 (see the Supplementary Material for PC1 and individual centrality measure results).
Our pre-registration specified exclusion of participants whose overall choice consistency was not significantly better than chance. For each participant's choice data, to measure choice consistency, we conducted an initial logistic regression. If the preliminary logistic regression analysis did not reveal a significant main effect of rating value difference (left set minus right set; p < .05), it is likely they failed to complete the task correctly (i.e., did not select sets that corresponded with their preferences).
Participants for whom the individual-level logistic regression main effect of value rating difference was not significant were excluded from the main behavioral analysis.
In accordance with our pre-registration outlier trials were identified by focusing on response times (RTs) using the interquartile range (IQR) method at the participant level 
(Ratcliff, 1993)
. The IQR method eliminates trials when RTs are above the 0.75 quantile by more than times the IQR or below the 0.25 quantile by more than 2 times the IQR. Additionally, trials were removed if RTs were less than 0.25s or above 9s after the IQR treatment. Using this method, we removed 9.1%, 9.3%, and 11.5% of trials in Set-Choice Study 1, 2, and 3, respectively.
Overall, in Set-Choice Study 1, four participants were excluded from our main analysis. In Set-Choice Study 2, one participant was excluded due to 99% of trials being removed using our response time cutoff, while another 23 participants were excluded based on our preregistered accuracy exclusion criteria. In Set-Choice Study 3, three participants were excluded due to over 50% of trials being removed using our response time cutoff, while another nine participants were excluded based on our preregistered accuracy exclusion criteria.


Results
For each Set-Choice experiment we fitted a Bayesian logistic mixed model to predict choice with standardized regressors. The estimation for each parameter successfully converged (̂ > 1) and the indices were reliable (ESS > 1000). Priors over parameters were set as student t (location = 0.00, scale = 2.50) distributions.
As expected, participants tended to select the sets that aligned with their reported liking ratings 
(Fig 4a)
. In Set-Choice Study 1, as the value of the left set increased,  Participants also generally took longer on more difficult decisions, that is, ones between sets that had similar liking ratings 
(Fig. 4b)
. We found an inverse relationship between the absolute value of the liking rating difference between sets and log- In addition, we found no relationship between participants within-set similarity ratings and the between-set choice. Because in Set-Choice Studies 2 and 3 participants explicit rated the similarity of each set, we were able to replace the network variables with those similarity ratings. We did not find evidence for an effect of reported Taken together, we failed to find conclusive evidence for set-level effects.
As a contrast to the hypothesized benefits of set properties, we next examined the coefficients on the item-based centrality scores. A set with a high centrality score contains more individual items that have strong associations with other items presented in the study though not necessarily included in the set.
Examining choice effects, we find partial support for centrality-score effects in Set-Choice Study 1. Participants were marginally more likely to choose the left set as its item-level centrality score increased (left option: = 0.12, 95% HDI 
[-0.12, 0.35
 Since these centrality scores capture clustering variances related to edge weights, our findings suggest that sets containing items that were more closely clustered in the full association network, were more frequently chosen 
(Fig. 5)
.
We were mostly able to replicate these findings in two follow-up, pre-registered experiments (Set-Choice Studies 2-3; 
Fig. 5
). In Set-Choice Study 2, controlling for liking ratings and reported preference similarity, participants were more likely to choose the left option as the left set increased in centrality (left option: = 0.12, 95% HDI that trials with more central items elicited faster responses. We note that when we look at RT conditioned on the correct response, we fail to find much evidence in Set-Choice Study 1 (β = -0.00647, 95% HDI [-0.03, 0.02], pd = .69). However, in Set-Choice Studies 2 and 3, we observed stronger evidence of effects (β = -0.00752, 95% HDI [-0.02, 0.0086], pd = .82; β = -0.01, 95% HDI [-0.03, 0.000849], pd = .97).
To estimate the average effect size across studies and understand its distribution, we employed a Bayesian meta-analysis 
(Williams et al., 2018)
. We modeled the standardized beta coefficients from each regression as a function of their standard errors, with random effects for experiments (Set-Choice Studies) and outcomes (each networkrelated regressor) to account for potential variability between studies 
(Fig. 6)
. The model was implemented using the brms package in R 
(Bürkner, 2017)
. In addition to the estimated effects reported throughout, we also report the meta-analytic estimated effect size and the associated 95% HDI (see Figs. 5 and 6). Together, these results provide novel evidence for the role of network effects in determining set choice. In particular, they indicate that when two sets are equivalent in value, people prefer sets that contain central items.  


Node Properties Appear Mainly in Set Choice Context
In the Set-Choice Studies, participants chose between sets of items. In the following section, we test the possibility that item-level centrality is predictive in settings where people choose between individual options. data. To avoid this, we used the liking ratings that we collected in Set-Choice Studies 1-3 to build a new association network. These ratings can be evaluated in relation to the patterns captured in our initial association network analysis. To achieve this, we used the loadings computed from the principal component analysis on item-level scores. We projected the centrality measures, estimated from the new association network, onto the principal component axes defined by the original association network. This allowed us to stick with the same principal components as before, but using a new independent set of input rating data. Then to investigate how these item-level scores corresponded to single-item choices, we once again used the same Bayesian hierarchical model specifications from the Set-Choices Studies (see analytical approach). The estimation for each parameter successfully converged (̂ > 1) and the indices were reliable (ESS > 1000).


Methods


Results
Single-Choice Study 1 
(Lee & Hare, 2023)
. Participants tended to select the option that aligned with their reported liking ratings. As the left item increased in value, participants were more likely to choose left ( = 1.80, 95% HDI [1.55, 2.07], pd = 1) while as the right item increased in value participants were less likely to choose left ( = -1.92, 95%
HDI 
[-2.19, -1.69]
, pd = 1).
We found little evidence of a centrality effect on binary choice or RT.
Controlling for the liking ratings, we found mixed evidence that participants were more likely to choose the left option when the centrality score (based on PC2) was higher 
(
  Colors denote different datasets. Using results from Single-Choice Studies 1-2 we once again conducted a metaanalytic analysis and found effect sizes consistent with our initial findings, this time showing that the average posterior effect sizes are essentially zero (see 
Fig. 7
). We found that across the effect sizes of interest, on average, no samples had non-zero posteriors. Overall, applying item-level scores to different single-item choice datasets consistently suggests that between-item choices are less sensitive to centrality than between-set choices.


Single-Choice Study 2 (Lee & Holyoak, 2021


General Discussion
Using a novel computational network approach, we find limited support for the importance of preference similarity in between-set value-based choice, in contrast to predictions from prior research. To accomplish this, we first demonstrated how associative representations can be derived from liking data. For sets of items, the strength of these network-defined associations correlate with people's subjective similarity ratings. However, this method found limited support for the idea that people prefer more similar sets (i.e., sets that are themselves well-connected at the subgraph level). Instead, we found that people prefer sets containing items that the association network identifies as generally being better connected to other itemswhether or not those other items are also present in the set. Furthermore, we provided evidence suggesting that these item-level characteristics might only affect choices between sets rather than choices between single items.
Our network-based connectivity measures allow quantification of preference similarity, reflecting correlations in liking ratings. Notably, our approach allows us to calculate the similarity not just between a pair of items but between sets of items. This measure correlates strongly with subjective set-similarity reports, suggesting we can use these network measures to estimate preference similarity without needing to collect setlevel ratings or evaluations. While not perfect, our tool could be used to quickly estimate the preference similarity for any number or size of sets.
However, set-level preference similarity largely did not predict choice, with the possible exception of Set-Choice Study 3. Prior literature that suggests increased preferences for sets that fit together (e.g., 
Evers et al., 2014)
 
(Langlois, 1990;
Knobe & Cushman, 2023)
. Prototypicality is particularly relevant for complex stimuli, such as consumer products or faces, where people tend to favor the prototypical. For example, prototypical faces are generally preferred 
(Langlois, 1990)
, and this preference extends to other domains like animals and cars 
(Halberstadt, 2003)
. Our findings are consistent with a preference for prototypicality, as people tend to choose sets with more central items more quickly and more often 
(Posner, 1968;
Reber, 1998;
Winkielman et al., 2006
Winkielman et al., , 2011
. However, it should be noted that the use of centrality measures in psychology is still debated 
(Neal et al., 2021
(Neal et al., , 2022
Bringmann et al., 2019)
.
Prior work has mostly focused on how people choose when selecting a single item from two or more alternatives 
(Krajbich et al., 2010;
Krajbich & Rangel, 2011;
Louie & Glimcher 2013;
Gluth et al. 2020;
Reutskaja et al. 2011;
Bakkour et al. 2019;
Thomas et al., 2021)
, but little is known about how people choose between sets of items.
Here, we found that, similar to single item decisions, there is a negative relationship between total value difference and RT 
(Busemeyer & Townsend, 1993;
Philiastides & Ratcliff, 2013;
Konovalov & Krajbich 2019
; for review, see 
Clithero, 2018)
. However, we also found suggestive evidence that node centrality only plays a role in set choice, not single item choice. Thus, an item's connectivity may only be important when it is being considered along with other items, not when it is being considered in isolation.
More generally, network models have been used in a variety of domains, e.g., to study the internet 
(Barabási & Albert, 1999)
, neuroscience 
(Bullmore & Sporns, 2009;
Medaglia et al., 2015)
, language 
(Arbesman et al., 2009)
, social information technologies 
(Borgatti et al., 2009)
, and a wide-range of psychological phenomena and cognitive processes (for reviews, see 
Borsboom et al., 2021 and
Siew et al., 2019, respectively
). Here we've taken early steps in extending this approach to the study of preferences, showing that it is possible to characterize similarity structure with associations learned directly from human choice behavior 
(Hebart et al., 2020)
. Our study showcases applying network modeling to value-based choices providing initial evidence that reported values and network structure play a role in decision-making between sets, while providing a tool for measuring value-based similarity judgments.


Footnotes
Figure 1 .
1
Association network. Visualization of the median association network (a) estimated from the Bootstrap Exploratory Graph Analysis. Food items (left), consumer products (center), and alternative food items (right) are colored based on the most frequent number of detected communities in the bootstrap samples. Edges indicate associations between items. Item-level scores (b) are calculated by first computing each network measure on the association network and then summing the scores. Set-level scores (c) are calculated by first selecting a set of foods from the network and then computing network measures on the set.(d) Rating study 1 food association network community detection assignment from median association network estimated from the Bootstrap Exploratory Graph Analysis.


Figure 2 .
2
Sensitivity of Similarity Judgments to Network Statistics. A linear correlation between averagesubgraph strength and similarity judgments across Set-Choice Studies 2-3. Red circles represent data from Set-Choice Study 2, and blue triangles represent data from Set-Choice Study 3. Error bars on each data point indicate the standard deviation. The data reveal that the average similarity score increases with the average strength of a subgraph, suggesting that sets with stronger connections within a subgraph are judged to be more similar. Superimposed are the best-fit regression lines for each experiment, with shaded regions around these lines indicating the standard errors associated with the regression estimates.


Figure 3 .
3
Illustrated Experimental Design and Association Network. (a) In the Rating task, participants rated each of food items. (b) Participants made binary choices between sets. (c) In Set-Choice Study 2-3, participants also rated the preference similarity of sets. (d) Illustrated example of a preference association network where nodes are food items and edges are positive or negative associations between.


participants were more likely to choose it ( = 0.97, 95% HDI [0.76, 1.20], pd = 1), while an increase in the value of the right set made participants less likely to choose left ( = -0.83, 95% HDI [-1.06, -0.62], pd = 1). These effects were present in Set-Choice Study 2 (left option: = 0.8, 95% HDI [0.68, 0.92], pd = 1, right option: = -0.81, 95% HDI [-0.94, -0.70], pd = 1) and Set-Choice Study 3 (left option: = 0.96, 95% HDI [0.85, 1.06], pd = 1, right option: = -0.99, 95% HDI [-1.14, -0.85], pd = 1).


Figure 4 .
4
Set based decisions show prevalent relationships between liking ratings and behavior. (a) The probability of choosing the left item as a function of the difference in the sum of liking ratings for the left and right sets. (b) Response time as a function of liking ratings, measured by the absolute value of the difference between the left and right sets. Error bars represent standard errors of the mean across participants. The x-axis units of Set-Liking are determined by summing the six food ratings within a set. Colors denote different experiments.


preference similarity on choice in Set-Choice Study 2 (left option: = 0.02, 95% HDI [-0.05, 0.08], pd = .69, right option: = 0.03, 95% HDI [-0.03, 0.10], pd = .83) nor in Set-Choice Study 3 (left option: = -0.03, 95% HDI [-0.09, 0.03], pd = .81, right option: = -0.001, 95% HDI [-0.06, 0.06], pd = .52). We also did not find any effect of similarity ratings on RT in either Set-Choice Study 2 (β = -0.003, 95% HDI [-0.02, 0.01], pd = .68) nor Set-Choice Study 3 (β = 0.004, 95% HDI [-0.009, 0.02], pd = .71).


], pd = .84, right option: = -0.18, 95% HDI [-0.41, 0.05], pd = .94). Furthermore, we found partial support that the centrality scores also interacted with value (left option: = 0.19, 95% HDI [0.06, 0.32], pd = 1, right option: = -0.04, 95% HDI [-0.17, 0.09], pd = .70).


[ 0 .
0
03, 0.21], pd = .99, right option: = -0.10, 95% HDI [-0.20, 0.005], pd = .97). However, there was only a marginal interaction with value (left option: = -0.04, 95% HDI [-0.12, 0.03], pd =.88, right option: = 0.05, 95% HDI [-0.03, 0.12], pd = .90). In Set-Choice Study 3, there was weaker support for the main effect of centrality (left option: = 0.04, 95% HDI [-0.05, 0.14], pd = .82, right option: = -0.02, 95% HDI [-0.12, 0.07], pd = .68), but we found evidence for an interaction with value (left option: = 0.09, 95% HDI [0.02, 0.16], pd = 1, right option: = -0.06, 95% HDI [-0.13, 0.003], pd = .97).Examining RT, we also find item-level centrality scores effects in Set-Choice Study 1 (β = -0.02, 95% HDI [-0.04, 0.005], pd = .94), indicating that trials with sets containing more central food items were responded to more quickly. In Set-Choice Studies 2 & 3, we observed similar, but somewhat weaker effects (β = -0.009, 95% HDI[-0.02, 0.004], pd = .92; β = -0.01, 95% HDI [-0.03, -0.002], pd = .99), again indicating


Our meta-analytic results are consistent with our findings, showing that when the reported effect sizes are properly aggregated, the average posterior effect sizes remain non-zero. Specifically, we found that 94% of samples for the left option and 84% of samples for the right option had non-zero average posterior effect sizes (left option: β = 0.076, 95% HDI [-0.031, 0.19], right option: = -0.045, 95% HDI [-0.15, 0.069]). For the interaction terms, 90% of the samples for the left option (β = 0.047, 95% HDI [-0.054, 0.15]) and 60% for the right option ( = -0.0074, 95% HDI [-0.11, 0.099]) were non-zero.


Figure 5 .
5
Forest plot of choice regression coefficients. Displays the posterior distribution of each standardized regression weight from Set-Choice Studies 1-3. The dependent variable is choose left, while set refers to the preference similarity estimate for a set, and centrality refers to the average centrality estimate for a set. Meta-analytic effect sizes for each term are displayed to the right. Filled points and intervals represent posterior means and 80/95% credible intervals. Colors denote different Set-Choice experiments.


Figure 6 .
6
Forest plot of response time regression coefficients. Displays the posterior distribution of each standardized regression weight from Set-Choice Studies 1-3. The dependent variable is response time, while set refers to the preference similarity estimate for a set, and centrality refers to the average centrality estimate for a set. Meta-analytic effect sizes for each term are displayed to the right. Filled points and intervals represent posterior means and 80/95% credible intervals. Colors denote different Set-Choice experiments.


left option: = -0.15, 95% HDI [-0.27, -0.03], pd = .99, right option: = -0.01, 95% HDI [-0.14, 0.12], pd = .56), or that there was an interaction between centrality and value (left option: = -0.02, 95% HDI [-0.15, 0.10], pd = .63, right option: = 0.03, 95% HDI [-0.10, 0.17], pd = .68). Similarly for RT, PC2 had little effect in single-item choice ( = -0.0059, 95% HDI [-0.02, 0.008], pd = .79).


Figure 7 .
7
Single item choices are less sensitive to centrality scores. Displays the posterior distribution of each standardized regression weight from Single-Choice Studies 1-2. Meta-analytic effect sizes for each term are displayed to the right. Filled points and intervals represent posterior means and 80/95% credible intervals.


Table 1 -Summary of datasets
1
Name
Binary
Similarity
Receive all
Choice
Set or
N
Source
Choices
ratings
or one item
Incentives
single
Rating Study
No
No
-
-
-
267
Lee &
1
Holyoak
2021
Rating Study
No
No
-
-
-
312
Leng &
2
Shenhav, in
prep
Rating Study
No
No
-
-
-
138
3
Li et al. 2023
Set-Choice
Yes
No
All
No
Set
30
-
Study 1
Set-Choice
Yes
Yes
One
No
Set
75
-
Study 2
Set-Choice
Yes
Yes
One
Yes
Set
79
-
Study 3
Single-Choice
Yes
No
One
No
Single
93
Lee & Hare
Study 1
2023
Single-Choice
Yes
No
One
No
Single
267
Lee &
Study 2
Holyoak


Our network measure of subgraph connection strength correlated well with participants' set similarity ratings, indicating that similarity estimated from one set of participants' liking ratings predicted a second set of participants' similarity reports. This indicates that preference similarity shows a meaningful relationship with the subjective criteria people apply when asked "if someone likes one of the foods, how likely is it that they also similarly like the other foods?".
In Set-Choice Study 2, participants reported higher
similarity ratings for subgraphs with stronger connections (ρ = 0.42, 95% HDI [0.25,
0.55], pd = 1). This effect replicated in Set-Choice Study 3 (ρ = 0.48, 95% HDI [0.32,
0.61], pd = 1) and held under equivalent non-parametric tests (Fig. 2; Supplementary
Materials).
Lastly, we assess the generality of our computational approach on separate and distinct collections of items from Rating Studies 2 and 3. Using Rating Study 2, we demonstrate that our network analysis generalizes to an entirely different class of items (i.e., durable goods), resulting in a median association network with ten communities (lower = 8.13%, upper = 13.87%;


. Notably, in Rating Study 3, where the number of items is double that from Rating Study 1, we observe greater modularization among categories that were previously classified into a single community. For instance, in the Rating Study 3 network, vegetables and fruits are identified as separate communities. For further details, including a list of item-wise community assignments for Rating Studies 2 and 3, see the Supplementary Materials.


, right option: = -0.04, 95% HDI[-0.15, 0.07], pd = 0.77). This was mostly consistent across our two follow-up pre-registered experiments. In Set-Choice Study 2 we did not find evidence for a main effect of set-level scores (left option: = -0.02,
= .7895% HDI [-0.09, 0.05], pd = .68, right option: = -0.0031, 95% HDI [-0.08, 0.07], pd =
.53) nor an interaction with value (left option: = 0.0077, 95% HDI[-0.06, 0.08], pd =
.59, right option: = 0.02, 95% HDI [-0.04, 0.09], pd = .76). However in Set-Choice
Study 3 while we did not find a main effect on choice (left option: = -0.03, 95% HDI
[-0.10, 0.03], pd = .85, right option: = -0.04, 95% HDI [-0.10, 0.03], pd =0.86)
average subgraph strength did interact with value (left option: = 0.15, 95% HDI [0.08,
0.22], pd = 1, right option: = -0.09, 95% HDI [-0.17, -0.02], pd = .99).
Consistent with this we did not find significant evidence for set-level preference
similarity effects on RT in either Set-Choice Study 1 (β = -0.0025, 95% HDI [-0.02,
0.02], pd = .60), Study 2 (β = -0.0074, 95% HDI [-0.02, 0.0068], pd = .86) nor Study 3
(β = -0.0063, 95% HDI [-0.02, 0.0066], pd = .83).
transformed RT across Set-Choice Study 1 ( = -0.03, 95% HDI [-0.06, -0.01], pd = 1),
Study 2 ( = -0.04, 95% HDI [-0.05, -0.02], pd = 1) and Study 3 ( = -0.07, 95% HDI [-
0.08, -0.05], pd = 1).
In direct tests of our experimental hypotheses, we failed to find conclusive
evidence for set-level effects. We examined the coefficients on our network variable
representing within-set similarity, subgraph connection strength. In Set-Choice Study 1,
we found no significant set-level effects on choice (left option: =-0.05, 95% HDI [-
0.16, 0.06], pd = .81, right option: = 0.03, 95% CI[-0.10, 0.15], pd = .68) and no
evidence for an interaction with value (left option: = -0.04, 95% HDI [-0.15, 0.07], pd


). Participants tended to select the option that aligned with their reported liking ratings. As the left item increased in value participants were more likely to choose left ( = 1.36, 95% HDI [1.23, 1.51], pd = 1) while as the right item increased in value participants were less likely to choose left ( = -1.36, 95% HDI [-1.50, -1.23], pd = 1).
Here we found no evidence of a centrality effect on binary choice or RT.
Controlling for reported value, we found no evidence that PC2 affected single-item
choice (left option: = 0.02, 95% HDI [-0.06, 0.09], pd = .67, right option: = -0.02,
95% HDI [-0.09, 0.05], pd = .70) nor that its interaction with value had any effect (left
option: = -0.006, 95% HDI [-0.07, 0.08], pd = .56, right option: = -0.01, 95% HDI
[-0.08, 0.06], pd = .63). For RT, PC2 did not have an effect either ( = 0.003, 95% HDI
[-0.005, 0.01], pd = .79) (though PC1 did appear to have an effect; see supplements).


may arise from different forms of similarity-perhaps semantic or visual alignment. Thus, modeling preference similarity may open a promising avenue for future work on the relationship between choice and different definitions of similarity. Instead of similarity, we find that people choose sets containing more central items, suggesting that item-level properties of the association network are important in shaping choices. It may be that sets with more central items are easier to process. Items with high network strength and local clustering coefficients are notably informative about other items. They are not only well-connected, but their associations (magnitude of correlation) are also stronger. Thus, these items provide denser information about similarly liked items, enabling people to utilize existing knowledge about similarly preferred items to inform their choices. In that way, we interpret centrality as indicating what is typical or representative of other similarly preferred items. People often conceptualize what is typical or representative as more prototypical, having common and valuable features








Acknowledgments
We thank Doug G. Lee and Xiamin Leng for sharing their data and Miruna Cotet, Irfan Khan, Xiaozhi Yang, and Minhee Yoo for helpful comments and discussions.


Transparency






ORCID iDs
Kianté A. Fernandez: https://orcid.org/0000-0002-8493-880X Uma R. Karmarkar: https://orcid.org/0000-0003-0547-5243 Ian Krajbich: https://orcid.org/0000-0001-6618-5675
 










Complexity, uniqueness, and similarity in between-bundle choice




M
K
Agarwal






S
Chatterjee




10.1108/10610420310498795








Journal of Product & Brand Management




12


6
















The Structure of Phonological Networks across Multiple Languages




S
Arbesman






S
H
Strogatz






M
S
Vitevitch








Int. J. Bifurc. Chaos




20
















Seeing Sets: Representation by Statistical Properties




D
Ariely




10.1111/1467-9280.00327








Psychological Science




12


2
















Emergence of Scaling in Random Networks




A.-L
Barabási






R
Albert




10.1126/science.286.5439.509








Science




286


5439
















Networks in Cognitive Science




A
Baronchelli






R
Ferrer-I-Cancho






R
Pastor-Satorras






N
Chater






M
H
Christiansen




10.1016/j.tics.2013.04.010








Trends in Cognitive Sciences




17


7
















Context-independent and context-dependent information in concepts




L
W
Barsalou




10.3758/BF03197629








Memory & Cognition




10
















Cognitive Modeling With Representations From Large-Scale Digital Data




S
Bhatia






A
Aka








Current Directions in Psychological Science




31


3


















10.1177/09637214211068113














Similarity and decision time in preferential choice




S
Bhatia






T
L
Mullett








Quarterly Journal of Experimental Psychology




71


6


















10.1177/1747021818763054














Case-based decision neuroscience: Economic judgment by similarity




R
Bhui








Goal-Directed Decision Making: Computations and Neural Circuits


R.W. Morris, A.M. Bornstein, & A. Shenhav


















The hippocampus supports deliberation during value-based decisions




A
Bakkour






D
J
Palombo






A
Zylberberg






Y
H
Kang






A
Reid






M
Verfaellie






M
N
Shadlen






D
Shohamy








8


46080
















S
P
Borgatti






A
Mehra






D
J
Brass






G
Labianca








Network Analysis in the Social Sciences. Science




323


5916


















10.1126/science.1165821


















D
Borsboom






M
K
Deserno






M
Rhemtulla






S
Epskamp






E
I
Fried






R
J
Mcnally






D
J
Robinaugh






M
Perugini






J
Dalege






G
Costantini






A.-M
Isvoranu






A
C
Wysocki






C
D
Van Borkulo






R
Van Bork






L
J
Waldorp


















Network analysis of multivariate data in psychological science


10.1038/s43586-021-00055-w








Nature Reviews Methods Primers




1


1












What do centrality measures measure in psychological networks




L
F
Bringmann






T
Elmer






S
Epskamp






R
W
Krause






D
Schoch






M
Wichers






J
T W
Wigman






E
Snippe








Journal of Abnormal Psychology




128


8


















10.1037/abn0000446














A comparison of spectral clustering and the walktrap algorithm for community detection in network psychometrics




M
J
Brusco






D
L
Steinley






A
L
Watts








Psychological methods
















Complex brain networks: Graph theoretical analysis of structural and functional systems




E
Bullmore






O
Sporns








Nature Reviews Neuroscience




10


3
















Decision field theory: a dynamic-cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend








Psychological review




100


3
















brms: An R Package for Bayesian Multilevel Models using Stan




P
C
Bürkner




.org/10.18637/jss.v080.i01






Journal of Statistical Software




80


1
















Extended bayesian information criteria for model selection with large model spaces




J
Chen






Z
Chen




10.1093/biomet/asn034








Biometrika




95


3
















Categorization effects in value judgments: Averaging bias in evaluating combinations of vices and virtues




A
Chernev






D
Gal




https://psycnet.apa.org/doi/10.1509/jmkr.47.4.738








Journal of Marketing Research




47


4
















Comparing community detection algorithms in psychometric networks: A Monte Carlo simulation




A
P
Christensen






L
E
Garrido






K
Guerra-Peña




10.3758/s13428-023-02106-4








Behav Res
















Estimating the stability of the number of factors via Bootstrap Exploratory Graph Analysis: A tutorial




A
P
Christensen






H
Golino




10.3390/psych3030032








Psych




3


3
















NetworkToolbox: Methods and Measures for Brain, Cognitive, and Psychometric Network Analysis in R




A
P. ; R J
Christensen








10


422












Response times in economics: Looking through the lens of sequential sampling models




J
A
Clithero




https://psycnet.apa.org/doi/10.1016/j.joep.2018.09.008








Journal of Economic Psychology




69
















A spreading-activation theory of semantic processing




A
M
Collins






E
F
Loftus




10.1037/0033-295X.82.6.407








Psychological Review




82
















The igraph software package for complex network research. InterJournal, Complex Systems




G
Csardi






T
Nepusz










1695














Network Structure Explains the Impact of Attitudes on Voting Decisions




J
Dalege






D
Borsboom






F
Van Harreveld






L
J
Waldorp






Van Der






H
L J
Maas




10.1038/s41598-017-05048-y








Scientific Reports




7


1














Predicting human similarity judgments with distributional models: The value of word associations




S
De Deyne






A
Perfors






D
J
Navarro








Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers


COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers


















qgraph: Network visualizations of relationships in psychometric data




S
Epskamp






A
O
Cramer






L
J
Waldorp






V
D
Schmittmann






D
Borsboom








Journal of Statistical Software




48
















A tutorial on regularized partial correlation networks




S
Epskamp






E
I
Fried




10.1037/met0000167








Psychological Methods




23


4
















Set-fit effects in choice




E
R K
Evers






Y
Inbar






M
Zeelenberg








Journal of Experimental Psychology: General




143


2


















10.1037/a0033343














Apples, Oranges, and Erasers: The Effect of Considering Similar versus Dissimilar Alternatives on Purchase Decisions




E
M
Friedman






J
Savary






R
K
Dhar








Journal of Consumer Research




45
















Community detection in graphs




S
Fortunato




10.1016/j.physrep.2009.11.002








Physics Reports




486


3-5
















Extended Bayesian information criteria for Gaussian graphical models




R
Foygel






M
Drton








Advances in neural information processing systems


J. D. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. S., Zemel, & A. Culotta


















Sparse inverse covariance estimation with the graphical lasso




J
Friedman






T
Hastie






R
Tibshirani




10.1093/biostatistics/kxm045








Biostatistics




9


3
















Consumer evaluation of multi-product bundles: An information integration analysis




G
J
Gaeth






I
P
Levin






G
Chakraborty






A
M
Levin




10.1007/BF00435195








Marketing Letters




2


1
















Computational Methods for Predicting and Understanding Food Judgment




N
Gandhi






W
Zou






C
Meyer






S
Bhatia






L
Walasek




10.1177/09567976211043426








Psychological Science




33


4
















The influence of clustering coefficient on word-learning: How groups of similar sounding words facilitate acquisition




R
Goldstein






M
S
Vitevitch




10.3389/fpsyg.2014.01307








Frontiers in Psychology
















The Cambridge handbook of thinking and reasoning




R
L
Goldstone






J
Y
Son




K. J. Holyoak & R. G. Morrison












Similarity








EGAnet: Exploratory Graph Analysis -A framework for estimating the number of dimensions in multivariate data using network psychometrics




H
Golino






A
P
Christensen














R package version 2.0.3








Exploratory graph analysis: A new approach for estimating the number of dimensions in psychological research




H
F
Golino






S
Epskamp








PLoS ONE




12














Investigating the performance of exploratory graph analysis and traditional techniques to identify the number of latent factors: A simulation and tutorial




H
F
Golino






D
Shi






A
P
Christensen






L
E
Garrido






M
D
Nieto






R
Sadana






J
A
Thiyagarajan






A
Martínez-Molina












Psychological methods








SIMR: an R package for power analysis of generalized linear mixed models by simulation




P
Green






C
J
Macleod








Methods in Ecology and Evolution




7
















U
Hahn




Similarity. Wiley interdisciplinary reviews. Cognitive science






3














Impact of bundle type, price framing and familiarity on purchase intention for the bundle




B
A
Harlam






A
Krishna






D
R
Lehmann






C
Mela




10.1016/0148-2963(94)00014-6








Journal of Business Research




33


1
















It's not just average faces that are attractive: Computermanipulated averageness makes birds, fish, and automobiles attractive




J
Halberstadt






G
Rhodes




















Psychonomic Bulletin & Review




10


















10.3758/BF03196479














Revealing the multidimensional mental representations of natural objects underlying human similarity judgments




M
N
Hebart






C
Y
Zheng






F
Pereira






C
I
Baker








Nature human behaviour




4
















The reviewing of object files: Object-specific integration of information




D
Kahneman






A
Treisman






B
J
Gibbs








Cognitive Psychology




24
















When Consumers Prefer Bundles with Noncomplementary Items to Bundles with Complementary Items: The Role of Mindset Abstraction




M
Karataş






Z
Gürhan-Canli








Journal of Consumer Psychology




30


1


















10.1002/jcpy.1125














Category Congruence of Display-Only Products Influences Attention and Purchase Decisions




U
R
Karmarkar






A
L
Carroll






Burke
M
Hijikata






S




10.3389/fnins.2021.610060






Front. Neurosci




15


610060














Investigating the structure of semantic networks in low and high creative persons




Y
N
Kenett






D
Anaki






M
Faust




10.3389/fnhum.2014.00407








Frontiers in Human Neuroscience
















The common effect of value on prioritized memory and category representation




J
Knobe






F
A
Cushman








Trends in cognitive sciences
















Principles of Gestalt psychology




K
Koffka








720


Harcourt, Brace












Revealed strength of preference: Inference from response times




A
Konovalov






I
Krajbich








Judgment and Decision Making
















Visual fixations and the computation and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel




10.1038/nn.2635








Article 10






13












Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions




I
Krajbich






A
Rangel








Proceedings of the National Academy of Sciences




108


33


















10.1073/pnas.1101328108














Semantic memory: A review of methods, models, and current challenges




A
A
Kumar








Psychonomic Bulletin & Review




28


1


















10.3758/s13423-020-01792-x














Attractive Faces Are Only Average




J
H
Langlois






L
A
Roggman




10.1111/j.1467-9280.1990.tb00079.x








Psychological Science




1


2
















Graphical models




S
L
Lauritzen








Clarendon Press


Oxford, UK












jsPsych: A JavaScript library for creating behavioral experiments in a Web browser




J
D
Leeuw








Behavior Research Methods




47
















Item memorability has no influence on valuebased decisions




X
Li






W
A
Bainbridge






A
Bakkour




10.1038/s41598-022-26333-5








Sci Rep




12


22056














An Empirical Test of the Role of Value Certainty in Decision Making




D
Lee






G
Coricelli




https://www.frontiersin.org/article/10.3389/fpsyg.2020.574473








Frontiers in Psychology




11














Value certainty and choice confidence are multidimensional constructs that guide decision-making




D
G
Lee






T
A
Hare




10.3758/s13415-022-01054-4








Cognitive, Affective, & Behavioral Neuroscience
















Coherence shifts in attribute evaluations




D
G
Lee






K
J
Holyoak




10.1037/dec0000151








Decision




8


4














Normalization is a general neural mechanism for context-dependent decision making




K
Louie






M
W
Khaw






P
W
Glimcher








Proceedings of the National Academy of Sciences




110


15
















Indices of Effect Existence and Significance in the Bayesian Framework




D
Makowski






M
S
Ben-Shachar






S
H A
Chen






D
Lüdecke




https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02767








Frontiers in Psychology




10














Structural Alignment during Similarity Comparisons




A
B
Markman






D
Gentner








Cognitive Psychology




25


4


















10.1006/cogp.1993.1011














Cognitive network neuroscience




J
D
Medaglia






M.-E
Lynall






D
S
Bassett








Journal of Cognitive Neuroscience




27


8
















Respects for similarity




D
L
Medin






R
L
Goldstone






D
Gentner




10.1037/0033-295X.100.2.254








Psychological Review




100
















Critiques of network analysis of multivariate data in psychological science




Z
P
Neal






M
K
Forbes






J
W
Neal






M
J
Brusco






R
Krueger






K
Markon






D
Steinley






S
Wasserman






A
G C
Wright




10.1038/s43586-022-00177-9








Nature Reviews Methods Primers




2


1














Out of bounds? The boundary specification problem for centrality in psychological networks




Z
P
Neal






J
W
Neal




10.1037/met0000426








Psychological Methods, No Pagination Specified-No Pagination Specified
















Similarity Scaling and Cognitive Process Models




R
M
Nosofsky








Annual Review of Psychology




43
















Bundle selection and variety seeking: The importance of combinatorics




M
O'donnell






C
R
Critcher






L
D
Nelson








Journal of Consumer Research




49


5
















Influence of Branding on Preference-Based Decision Making




M
G
Philiastides






R
Ratcliff








Psychological Science




24


7


















10.1177/0956797612470701














Computing communities in large networks using random walks




P
Pons






M
Latapy




10.7155/jgaa.00124








Journal of Graph Algorithms and Applications




10


2
















On the genesis of abstract ideas




M
I
Posner






S
W
Keele








Journal of experimental psychology




77


3p1


353














R: A language and environment for statistical computing. R Foundatin for Statistical Computing




R Core Team










Vienna, Austria












Methods for dealing with reaction time outliers




R
Ratcliff








Psychological bulletin




114
















Diversification bias: Explaining the discrepancy in variety seeking between combined and separated choices




D
Read






G
Loewenstein








Journal of Experimental Psychology: Applied




1


1


34














Effects of Perceptual Fluency on Affective Judgments




R
Reber






P
Winkielman






N
Schwarz








Psychological Science




9


1


















10.1111/1467-9280.00008














Search Dynamics in Consumer Choice under Time Pressure: An Eye-Tracking Study




E
Reutskaja






R
Nagel






C
F
Camerer






A
Rangel










The American Economic Review




101


2
















The analysis of proximities: multidimensional scaling with an unknown distance function. I




R
N
Shepard








Psychometrika




27


2


















C
S Q
Siew






D
U
Wulff






N
M
Beckage






Y
N
Kenett




10.1155/2019/2108423








Cognitive Network Science: A Review of Research on Cognition through the Lens of Network Representations, Processes, and Dynamics
















The effect of purchase quantity and timing on variety-seeking behavior




I
Simonson








Journal of Marketing research




27


2
















The large-scale structure of semantic networks: Statistical analyses and a model of semantic growth




M
Steyvers






J
B
Tenenbaum




10.1207/s15516709cog2901_3








Cognitive Science




29


1
















Uncovering the computational mechanisms underlying many-alternative choice. ELife, 10




A
W
Thomas






F
Molter






I
Krajbich




10.7554/elife.57012


















Regression shrinkage and selection via the lasso




R
Tibshirani




10.1111/j.2517-6161.1996.tb02080.x








Journal of the Royal Statistical Society. Series B (Methodological)




58


1




















F
M
Turner-Zwinkels






B
B
Johnson






C
G
Sibley






M
J
Brandt


















Moral Foundations Are More Densely Connected Than Liberals' Moral Foundations




Conservatives








Personality and Social Psychology Bulletin




47


2
















10.1177/0146167220916070














Features of similarity




A
Tversky




10.1037/0033-295X.84.4.327








Psychological Review




84
















Rank-Normalization, Folding, and Localization: An Improved Rˆ for Assessing Convergence of MCMC (with Discussion)




A
Vehtari






A
Gelman






D
P
Simpson






B
Carpenter






P
Burkner












Bayesian Analysis








A century of Gestalt psychology in visual perception: II. Conceptual and theoretical foundations




J
Wagemans






J
Feldman






S
Gepshtein






R
Kimchi






J
R
Pomerantz






P
A
Van Der Helm






C
Van Leeuwen








Psychological bulletin




138


6
















Hierarchical Encoding Makes Individuals in a Group Seem More Attractive




D
E
Walker






E
Vul








Psychological Science




25
















Collective dynamics of 'small-world' networks




D
J
Watts






S
H
Strogatz




10.1038/30918








Nature




393


6684








Article 6684








Bayesian Meta-Analysis with Weakly Informative Prior Distributions




D
R
Williams






P
Rast






P.-C
Bürkner






















10.31234/osf.io/7tbrm














Mind at ease puts a smile on the face: Psychophysiological evidence that processing facilitation elicits positive affect




P
Winkielman






J
T
Cacioppo








Journal of Personality and Social Psychology




81


6


















10.1037/0022-3514.81.6.989














Prototypes Are Attractive Because They Are Easy on the Mind




P
Winkielman






J
Halberstadt






T
Fazendeiro






S
Catty




10.1111/j.1467-9280.2006.01785.x








Psychological Science




17


9
















On the semantic representation of risk




D
U
Wulff






R
Mata




10.1126/sciadv.abm1883








Science Advances




8


27














How to quantify the evidence for the absence of a correlation




E
J
Wagenmakers






J
Verhagen






A
Ly




10.3758/s13428-015-0593-0








Behav Res




48
















How Buyers Evaluate Product Bundles: A Model of Anchoring and Adjustment




M
S
Yadav








Journal of Consumer Research




21
















Knowledge Representations Derived From Semantic Fluency Data




J
C
Zemla




https://www.frontiersin.org/articles/10.3389/fpsyg.2022.815860








Frontiers in Psychology




13














Variety-seeking behavior in consumption: a literature review and future research directions




Y
Zhang








Frontiers in Psychology




13


87444















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]