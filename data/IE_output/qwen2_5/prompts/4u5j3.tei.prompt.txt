You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Explaining the description-experience gap in risky decision-making: Learning and memory retention during experience as causal mechanisms
In modern life, we make numerous decisions between competing options despite probabilistic outcomes and incomplete knowledge surrounding their potential outcomes. Indeed, whether we are deciding between movies, car insurance plans, or even serious medical procedures, we frequently seek out statistics to help evaluate the probability of various good or bad outcomes. In these situations, in the absence of prior experience and where probabilities are explicitly described (description-based decisions or DBDs), people appear to act as if they overestimate or overweight low probability events. This has led to the idea that people assign weights to explicitly described likelihoods, resulting in risk-seeking choices for low-probability gains due to overweighting of rare events and risk-averse behavior for high-probability gains due to underweighting of common events 
(Kahneman & Tversky, 1979;
Scholten & Read, 2014)
.
Notably, this probability weighting bias has long been thought to play a primary role in how people evaluate real-world phenomena, including the prevalence rates for rare causes of death 
(Lichtenstein, Slovic, Fischhoff, Layman, & Combs, 1978)
, the value of insurance policies for rare events 
(Friedman & Savage, 1948)
, and changes in preferences for political and economic policies (Quattrone 
& Tversky, 1988)
.
Recently, however, it has become clear that the format in which probabilities are presented to us can dramatically affect our apparent preferences. Specifically, people act as if they underweight low probabilities when they are learned through experience (experience-based decision or EBD), a paradoxical reversal of traditional probability weighting bias now termed the description-experience gap 
(Barron & Erev, 2003;
Hertwig, Barron, Weber, & Erev, 2004;
Ungemach, Chater, & Stewart, 2009;
Weber, Shafir, & Blais, 2004;
Wulff, Mergenthaler-Canseco, & Hertwig, 2018)
. Drawing from the examples above, we would expect more people to purchase rare event insurance or opt out of a medical procedure with rare harmful side effects if they are making a decision based purely on described probabilities rather than based on their previous experiences of these events.
As inference on parameters derived from computational models of both DBD and EBD tasks becomes increasingly common to assess clinical (e.g., 
Ahn & Busemeyer, 2016;
Montague et al., 2012)
, social (e.g., 
Chung, Christopoulos, King-Casas, Ball, & Chiu, 2015)
, affective (e.g., 
Eldar, Rutledge, Dolan, & Niv, 2016;
Etkin, Büchel, & Gross, 2015)
, developmental (e.g., 
Steingroever, Jepma, Lee, Jansen, & Huizenga, 2019)
, and medical decision-making 
(Lejarraga, Pachur, Frey, Hertwig, 2016)
, it is becoming increasingly important that we identify the potential mechanism(s) that gives rise to the description-experience gap to ensure that variation in key model parameters is driven by individual characteristics (e.g., cognitive development, clinical status, personality traits) rather than task-specific design choices. Therefore, given the importance of the description-experience gap for understanding real-world human decisionmaking, we aimed to develop an explanatory cognitive mechanism linking preferences in DBDs to those of EBDs.


Mechanisms of the Description-Experience Gap
Although many explanations of the gap have been proposed, three mechanisms in particular have been the focus of much prior research: (1) reliance on small samples and sampling bias when learning probabilities (i.e., sampling error), (2) reliance on more recently experienced samples, and (3) changes in the psychological representation of probability (see 
Fig. 1
; 
Fox & Hadar, 2006;
Hertwig & Erev, 2009)
. Regarding (1), the format of the tasks used to assess EBDs (i.e., sampling paradigms with optional stopping) is such that some participants either never or less frequently encounter the "rare event" when drawing samples from a choice option, which naturally leads to apparent underweighting of low probability events once making a choice 
(Hau, Pleskac, & Hertwig, 2010;
Hertwig et al., 2004)
. Such biased sampling occurs because rare event frequency follows a binomial distribution, which is heavily skewed when few samples are drawn (i.e., n is low), meaning that the actual experienced proportion of encounters with a given outcome will often be biased relative to the true outcome probability 
(Hertwig, Barron, Weber, & Erev, 2004)
. For similar reasons, (2) can lead to an apparent underweighting because higher probability outcomes are more likely to be recently observed relative to lower probability outcomes in small sample settings, and people tend to place higher weight on more recent outcomes or simply ignore or forget less recent outcomes when making EBDs 
(Hertwig et al., 2004)
. Finally, although less parsimonious than (1) or (2), (3) suggests that people evaluate probabilities differently between tasks, assigning less weight to low-probability outcomes in EBDs relative to DBDs (see 
Fig. 1
 for a graphical example). 
Ungemach et al. (2009)
 showed that when using an experimental design to eliminate sampling bias (by matching the experienced proportion of each outcome to its respective objective probability of occurring), cumulative prospect theory modeling still revealed underweighting of rare events in EBDs. Many studies have since followed suit, and a recent meta-analysis of over 6,000 individual participants draws similar conclusions 
(Wulff et al., 2018)
.
Altogether, available evidence suggests that sampling biases and recency contribute to the description-experience gap, but also that probabilities or rewards are fundamentally different when evaluated based on description compared to experience 
(Hertwig & Erev, 2009;
Kellen et al., 2016;
Wulff et al., 2018)
. This begs the question-how does context affect something as fundamental to preferential decision-making as the value of rewards and probabilities?


Modeling the Gap
In one of the first studies of its kind, 
Glöckner et al. (2016)
 examined differences in CPT valuation parameters between description and experience tasks from multiple previous studies and found that rare events carried more weight for EBDs relative to DBDs-a reversal of the typical description-experience gap. Follow-up analyses revealed that the type of gamble was a significant moderator of the size and direction of the gap, such that analyses of "reduced" gambles including at least one certain option produced a traditional gap, and "non-reduced" gambles containing no certain options predicted a reversal of the gap 
(Glöckner, Hilbig, Henninger, & Fiedler, 2016)
 2 . Using a within-subject design, 
Kellen et al. (2016)
 replicated and expanded 
Glöckner et al.'s (2016)
 findings of a reversed description-experience gap using hierarchical Bayesian modeling of CPT parameters across over 100 participants who underwent the same set of 114 gambles for both description and experience presentations, concluding that "Our results suggest that outcome and probability information translate into systematically different subjective representations in description-versus experience-based choice." 
(Kellen et al., 2016, p. 126)
. These foundational applications of CPT to model the description-experience gap-which moved away from heuristic methods of testing hypotheses in favor of more formalized, substantive models of psychological processes-led to novel and counterintuitive insights into a previously well-replicated behavioral phenomenon.


Learning and Memory as Causal Mechanisms
Similar to Regenwetter & Robinson (2017), we argue that the most commonly used method of modeling EBDs with CPT relies on a set of strong assumptions that introduce bias into the estimation of probability weighting due to model mis-specification. Specifically, to control for participants' unique learning history in EBDs, the probability of each outcome is assumed to be equal to the experienced proportion of outcomes observed for each participant-gamble pair (e.g., 
Camilleri & Newell, 2011;
Glöckner, Hilbig, Henninger, & Fiedler, 2016;
Kellen, Pachur, & Hertwig, 2016)
. For example, if a person draws samples ∈ {$4, $4, $4, $0} for gamble , the probability for each outcome is heuristically set to the empirical proportion of samples that it was observed before CPT modeling (if = 1 indicates $4, and = 2 indicates $0, then ,1 = .75 and ,2 = .25). However, this heuristic method implicitly makes three strong assumptions, all of which are difficult to reconcile with learning and memory research:
(1) Learning and memory for all past samples is perfect,
(2) There are no individual differences in trial-by-trial learning across participants, and
(3) Learning occurs through a single, static mechanism.
These assumptions are easier to scrutinize if we formalize the implicit learning and memory models underlying them. Note that readers can refer to 
Table 1
 for an overview of the model terms and interpretations while reading through the next section.
If we assume learning progresses through a strength-based learning mechanism, the following delta learning rule is implied as samples are experienced (a.k.a. a simplified Rescorla-Wagner updating rule; 
Rescorla & Wagner, 1972)
: which can be re-written as follows to better correspond to memory models that we discuss later on:
p g,j := p g,j + A ⇥ (I g,j,s p g,j )
(1)
< l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t >
p g,j := (1 A) ⇥ p g,j + A ⇥ I g,j,s
(2)
< l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > Above, is a learning rate, indicates the outcome within a given gamble , indicates the sample number, and , , is an indicator that equals 1 or 0 if outcome is observed or unobserved on the given sample, respectively 
(Ahn et al., 2012;
Haines et al., 2019)
. In this formulation, irrespective to the initial value for , , if the learning rate is set such that = 1 , then , will always be equivalent to the proportion of times that outcome is observed up to sample , resulting in the same behavioral predictions (perfect knowledge and memory of all previous outcomes) as the heuristic CPT implementation.
We could equivalently formalize the heuristic CPT analyses with an instance-based memory model (e.g., 
Gonzalez, Dutt, & Lejarraga, 2011)
. For example, if we assume that each encounter with an outcome leaves a memory trace of that outcome, that each trace decays exponentially in time (indexed by sample number), and that the salience of each outcome is determined by the relative strength of its memory traces compared to traces for alternative outcomes within the given choice option, then we can use the following simplified decay memory rule to generate outcome probabilities:
Here, , indicates the number of times that outcome has been observed for gamble up to the current sample , (1 − ) is a memory trace decay rate, is the number of different outcomes that can be observed within the given gamble, and , , is the same indicator as described above.
If (1 − ) = 1, then , will always equal the objective number of times that outcome has been observed up to sample , and the summation (i.e. "blending") will subsequently return the proportion of times that outcome is observed across trials, akin to the delta learning rule above.
n g,j := (1 A) • n g,j + I g,j,s p g,j := n g,j P J k=1 n g,k
(3)
< l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t >
Note that in this specific setting, the delta learning and decay memory rules are equivalent except that in the decay memory rule, the experienced outcome is given a weight of 1 as opposed to being weighted in proportion to the learning rate. There are more general relationships between the delta and decay rule, but they are not relevant for the current analyses (see 
Turner, 2019)
.
Given these formal definitions, we now turn back to assumptions 1-3 listed above.
Assumptions 
(1) and
(2) imply that either = 1 or = 0 for all participants in the case of the delta learning or decay memory rules, respectively, thus giving equivalent weight to all experienced outcomes irrespective to the time at which they were experienced. However, it is well known that people place higher weight on more recent samples when making EBDs and that there are substantial individual differences in learning rate or memory decay between people. In fact, individual differences in learning rate or memory decay during EBDs are associated with neurodegenerative disease status (e.g., 
Busemeyer & Stout, 2002)
, delinquent behavior 
(Yechiam, Busemeyer, Stout, & Bechara, 2005)
, and age-related changes in impulsive decisionmaking (e.g., 
Wood, Busemeyer, Koling, Cox, & Davis, 2005)
. More generally, there is an extensive and longstanding literature on the basic psychological mechanisms underlying frequency or probability learning that reveals biases (e.g., toward recently experienced outcomes, attention to wins versus losses, etc.) in how people estimate probabilities or assign salience to outcomes (see, e.g., 
Estes, 1976;
Gonzalez, 2013;
Zacks & Hasher, 2002)
.
Regarding assumption (3), there is growing evidence that people learn at different rates for positive versus negative surprises (i.e., prediction errors) or outcomes, which can lead to riskseeking or risk-averse behavior 
(Christakou et al., 2013;
Daw, Kakade, & Dayan, 2002;
Doll, Jacobs, Sanfey, & Frank, 2009;
Haines, Vassileva, & Ahn, 2018;
Niv, Edlund, Dayan, & O'Doherty, 2012;
Turner, 2019)
. In fact, the magnitude of such individual differences in learning rates is genetically linked to striatal dopamine functioning 
(Cox et al., 2015;
Frank, Moustafa, Haughey, Curran, & Hutchison, 2007;
Frank, Seeberger, & O'Reilly, 2004)
.
Moreover, learning from positive outcomes is associated with Striatal D1 receptor density, while learning from negative outcomes is associated with D2 receptor binding. Although both are modulated by dopamine, this dissociation implies that the two components of learning -positive and negative -correspond to physiologically 
(Cox et al,
201)
 and genetically 
(Frank et al, 2007)
 distinct processes. Converging evidence from fMRI BOLD analyses showed that manipulations of reward variance led to distinct prediction error signals in nucleus accumbens corresponding to rates of positive and negative prediction errors, favoring a model with distinct positive and negative learning rates (Niv et al., 2012).


The Current Study
Altogether, most approaches to studying the description-experience gap assume that people have optimal learning rates, decay-free memory representations of experienced outcome frequencies (which we term "imperfect learning and memory"), and no individual differences in learning or decay rates. These tenuous assumptions can both lead to biased inferences on performance differences between DBDs and EBDs when using the heuristic CPT method.
Furthermore, there is growing neural and behavioral evidence that people learn asymmetrically from positive versus negative predictions errors. As demonstrated in 
Fig. 2
, such biased learning can partially explain changes in behavior consistent with the description-experience gap, yet typical approaches to modeling the gap fail to account for asymmetric learning.
Here, we examine the consequences of removing these assumptions by integrating learning and memory models with decision-making theories. Our core argument is that, rather than estimating additional parameters in the CPT utility function to describe the description-experience gap, it is more fruitful to explain the gap by identifying and modeling psychological learning or memory mechanism(s) that lead to preference differences across description and experience. To do so, we first conduct a simulation study to determine how individual differences in learning during the sampling phase of EBDs (and asymmetric learning in particular) can bias CPT parameters when using the heuristic method that assumes no learning or memory effects. Next, we develop a variety of computational models that instantiate different learning or memory mechanisms and determine which model provides the best joint statistical account of behavior in DBDs and EBDs. This latter model comparison approach allowed us to test specific hypotheses regarding differences between DBD and EBD tasks, including whether the proposed learning mechanism described true behavior better than CPT models assuming differences in probability weighting, risk aversion, or loss aversion in addition to other mechanism we describe below.
Inspired by the results of our simulation study, we next fit a series of competing models to empirical within-subject data collected from 104 participants across 114 unique description-and experience-based gambles to determine the degree to which people engage in behavior consistent with the integrated learning and decision-making models we propose.
Finally, we conclude with a discussion of how formalizing and quantitatively comparing competing hypotheses can enhance our understanding of complex psychological phenomena in a way not afforded by experimental design alone. We begin below with a mathematical overview of the models used throughout both our simulation and empirical study.


Mathematical Models


Cumulative Prospect Theory
The core of CPT contains three main parameters, namely: (1) probability weighting (0 < < 5), risk sensitivity (0 < < 5), and loss sensitivity (0 < < 10 where , and , are the probability (e.g., 0.8) and objective payoff value (e.g., $4) for each possible outcome within a given gamble . CPT assumes that people subjectively weight the probability of each outcome such that:
Here, values for < 1 indicate overweighting of low-probability events and values for > 1 indicate underweighting of low probability events (see 
Fig. 1
). has the opposite interpretation 4 Note that we do not include problem and participant indices to facilitate readability. Fully written out, the probability of outcome , within gamble , within problem , and for participant , would be indicated by , , , .
V g = J X j=1 W (p g,j )U (x g,j )
(4)
< l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t >
W (p g,j ) = p g,j p g,j + (1 p g,j )
(5)
< l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > for high probability events (see 
Fig. 1
). Note also that Equation 5 is a single-parameter version of 
Goldstein & Einhorn's (1987)
 probability weighting function (see also 
Karmarkar, 1978;
Gonzalez & Wu, 1999)
, which is different from the original CPT probability weighting in that it is symmetric around the objective probability (i.e., omitting the 1/ exponent on the denominator). We used this single-parameter version because we were most interested in changes in probability weighting rather than probability elevation, and the symmetry allows for easier interpretation compared to CPT's original instantiation 5 . Importantly, Equation 5 is a key component of CPT, which is necessary to capture the well-known fourfold pattern of risk attitudes .
Additionally, CPT assumes that payoff values are evaluated non-linearly such that the subjective utility of , is given by where values for < 1 indicate risk-aversion (i.e., insensitivity to differences between largemagnitude values), and values for > 1 indicate risk-seeking behavior. Loss-aversion is captured by > 1 (i.e. losses are weighted more heavily than gains), whereas loss-seeking is captured by < 1. Hence, the subjective value in Equation 4 is computed as a weighted sum of probability weights and subjective utilities for each gamble.
Although the original CPT model is deterministic, we employ a commonly used probabilistic choice rule to convert the subjective values for each option (from Equation 4) to expected choice
U (x g,j ) = ( x ↵ g,j , if x g,j 0 |x g,j | ↵ , otherwise
(6)
probabilities that sum to one (see 
Stott, 2006)
. Specifically, we use a multinomial logistic function-also known as the softmax function-which is closely related to the Luce choice rule:
Here, the probability (Pr) of choosing gamble is determined as a function of its subjective value relative to all gambles available within the current problem. Note that we focus only on choices where 2 competing gambles are considered. The choice sensitivity parameter (0 < < ∞) controls how deterministically (larger ) versus randomly (smaller ) an individual makes choices according to the subjective value of each gamble. For the simulation study, we set = 1 for convenience and did not estimate it as a free parameter. For the empirical study, we estimated as a free parameter. Our use of the logistic choice rule as opposed to the original Luce choice rule allows for the model to capture individual differences in maximization behavior through the use of the choice sensitivity parameter ( ). The Luce choice rule of the form
Pr[ ℎ = ] = ∑ 2 =1
is scale invariant, such that multiplying each term by a constant factor (i.e. a choice sensitivity or inverse temperature parameter) has no effect on the resulting probabilities. Additionally, the logistic rule has many practical benefits-namely, it (1) is a key component of many models of EBDs that generalize well to novel data 
(Erev et al., 2010)
; 
2
captures variation in choice across multiple decision domains (e.g., 
Friedman & Massaro, 1998)
;
and (3) is a well-studied probabilistic extension of traditional 
CPT (e.g., Nilsson, Rieskamp, & Wagenmakers, 2011)
.


Reinforcement Learning CPT Hybrid Model
The RL-CPT model extends CPT from pure description-based tasks into experience-based tasks by assuming that the probability ( , ) for each choice outcome is learned through
Pr[Choice = g] = exp( ⇥ V g ) P 2 k=1 exp( ⇥ V k )
(7)
experience during sampling for EBDs. Therefore, RL-CPT assumes that traditional CPT parameters ( , , ) are equivalent across DBDs and EBDs, and any differences in preferences between tasks are captured by the effects of a dynamic learning mechanism. When , is given (i.e. DBDs), the RL-CPT model simply reduces to traditional CPT, with a single set of valuation parameters estimated for each participant. Conversely, when , is not given, the RL-CPT learns , through repeated sampling using the strength-based learning rule described in the introduction (see Equation 1-2). Specifically, we assume that , = .5 once the given outcome is observed-indicating maximum uncertainty-and is then updated after each sample with a different learning rate depending on whether the observed outcome is better or worse than expected. If outcome is not observed while sampling option , then , remains at 0 and the outcome subsequently plays no role in the final preference judgement. Additionally, we assumed that, if one outcome has already been observed such that ,1 has already taken on some value different from 0 or .5, then upon observing outcome ,2 for the first time, updating begins from ,2 ≔ 1 − ,1 rather than from ,2 ≔ .5. Setting the initial values for , in this way assumes that people keep track of how likely various outcomes within a given option are relative to one another, such that if one outcome is very common, the other must be rare and vice versa. Further, this scheme ensures that if people observe more than one outcome for a given option, that the outcome probabilities sum to 1 (i.e. ,1 + ,2 = 1). The learning rule is then:
Here, + (0 < + < 1) and -(0 < -< 1) are learning rates for positive and negative prediction errors, respectively, and = ( ) − is the prediction error generated
8j 2 J, p g,j := p g,j + ( A + ⇥ (I g,j,s p g,j ), if P E 0 A ⇥ (I g,j,s p g,j ), otherwise
(8)
after observing the outcome of sample . The first term, ( ), is the utility (see Equation 6) of the experienced outcome upon drawing sample . Then, is the expected value (see Equation 4) for gamble that was sampled. Intuitively, the learning rule described by Equation 8 assumes that people update their expectations for how likely each outcome is to occur differently based on whether the observed outcome was better ( ≥ 0) or worse ( < 0) than expected. If + = − , then Equation 8 is identical to the single learning rate learning rule described in the introduction (see Equation 1). However, when + < − , higher negative relative to positive learning rates leads to an underestimation of the high outcome probability and therefore produces risk-averse behavior.
After iterating through each sample a participant draws before making a choice, the resulting , estimates from Equation 8 are entered into Equation 5. This explicit learning mechanism contrasts the traditional heuristic analyses of EBDs where , is simply set to the experienced proportion of each outcome (e.g., 
Glöckner, Hilbig, Henninger, & Fiedler, 2016;
Kellen, Pachur, & Hertwig, 2016
). As we described in detail in the introduction, the heuristic method of setting , to the experienced proportion of each outcome is analytically equivalent to a special case of the RL-CPT model wherein + = − = 1 . This mathematical correspondence allows us to find evidence for traditional probability weighting and mean-tracking models (described below) as special / nested cases of the RL-CPT model. All other aspects of RL-CPT are equivalent to standard CPT.
The RL-CPT differs from other learning and memory models of EBDs in two important ways. First, learning and memory models including the scanning model (e.g., 
Estes, 1976)
,
Value-updating Model (e.g., 
Hau et al., 2008)
, Decay-reinforcement model (e.g., 
Erev & Roth, 1998)
, delta-rule learning model (e.g., 
Busemeyer & Myung, 1992)
, prospect valence learning model (e.g., 
Ahn, Busemeyer, Wagenmakers, & Stout, 2008)
, and the ACT-R inspired Instance-Based Learning model (e.g., 
Gonzalez, Dutt, & Lejarraga, 2011)
 do not directly estimate probabilities. Instead, they assume that people either learn the expected average return of an option (in the case of learning models) or sample memory traces of previously encountered stimuli to evaluate the relative frequency of potential outcomes (in the case of memory models).
By contrast, the RL-CPT model assumes that people directly learn the probability of each outcome occurring before integrating probabilities with their respective outcome values (see also 
Haines et al., 2018)
. Despite making different mechanistic assumptions, models that update toward the average value of an option (e.g., the delta-rule learning model) produce the same behavioral predictions as a special case of the RL-CPT, where learning rates are equivalent ( + = − ) and all CPT valuation parameters ( , , ) are set to 1. In this reduced case, the RL-CPT model will update toward the objective expected value of an option. More generally, the explicit tracking of probabilities in the RL-CPT is necessary to both: (1) model DBDs, which ask people to integrate potential outcomes with their explicitly given probabilities; and (2) compare probability weighting across DBDs and EBDs. Therefore, the RL-CPT can only be compared to the above learning and memory models in the context of EBDs because other learning and memory models do not make clear predictions for DBDs. However, because memory decay is a reasonable competing explanation for differences between DBDs and EBDs, we also tested an instance-based model that estimates outcome probabilities using a memory decay mechanism as a competing mechanism to the RL-CPT model. We describe this model in the next section.
Second, the RL-CPT includes a pair of learning rates to account for asymmetric learning of positive versus negative predictions errors (e.g., 
Mihatsch, & Neuneier, 2002;
Niv, Edlund, Dayan, & O'Doherty, 2012)
, whereas the abovementioned models contain only a single learning or memory decay mechanism. The asymmetric learning mechanism in the RL-CPT is qualitatively different from attention mechanisms in other models, which assume that people differentially attend to gains versus losses (e.g., 
Busemeyer & Stout, 2002;
Estes, 1976)
.
Specifically, because the learning rate is dependent on the sign of the sample-to-sample prediction error rather than the outcome domain (see Equation 8), a learning asymmetry can lead to biased probability expectations within any domain (e.g., for gains, losses, or mixed gambles).
Conversely, asymmetric attention to gains versus losses is necessarily a between-domain effect.
In sum, the RL-CPT can produce biased expectations of outcome probabilities (see 
Fig. 2
), which allows it to account for preference differences between DBDs and EBDs in a way that alternative models are unable to capture. Further, because traditional CPT characterizes risk sensitivity through valuation parameters alone, it follows that any changes in risky behavior resulting from an asymmetric learning mechanism may lead to biased inferences in CPT valuation parameters.


Instance-Based Memory CPT Hybrid Model
As a competing mechanism to strength-based updating rule in the RL-CPT, we also developed an instance-based memory and CPT hybrid model (IB-CPT) that estimates the probability ( , ) for each choice outcome in EBDs using the memory decay plus normalization step described in the introduction (see Equation 3). From the instance-based perspective, , is thought of as the memory salience of a given outcome relative to other possible outcomes. All other aspects of the IB-CPT model are equivalent to the RL-CPT model described abovetraditional CPT parameters ( , , ) are assumed to be equivalent across DBDs and EBDs, and differences in preferences between contexts are captured by the effects of the dynamic memory decay mechanism. As described in the introduction, the memory decay rule in the IB-CPT reduces to the heuristic CPT implementation when the memory decay rate is set to 0.
Despite sharing core features with other instance-based models, the IB-CPT differs from other instance-based models in one important way. For example, the Instance-Based Learning model is one extant model that assumes that people multiply (i.e. "blend") probabilities and their respective outcomes to determine the subjective value for each gamble 
(Gonzalez, Dutt, & Lejarraga, 2011)
. The probabilities are determined by sampling memory traces of experienced outcomes, which allows the model to capture deviations of individuals' choices from the objective expected value of each gamble-the use of memory decay and "blending" to arrive at outcome probabilities and expected values is equivalent to our formulation of the IB-CPT. For DBDs, however, the memory trace sampling process in the Instance-Based Learning model drops out of the equation (there are no prior experiences to sample), reducing to a simple expected value model which assumes that people make choices to maximize the objective expected value of each pair of gambles. Because this assumption is: (1) inconsistent with research on DBDs, (2) is contained as a special case of the CPT model that we tested (when = = = 1), and (3) extends to all instance-based models described above, we did not test 
Gonzalez et al.'s (2011)
 specific implementation of an instance-based learning model in the current study, opting instead for the formulation of the IB-CPT described above.
In summary, the traditional CPT, RL-CPT, and IB-CPT models are all equivalent in the context of DBDs, but they differ in how they assume people learn to integrate experienced outcomes into their decision process in the context of EBDs. Therefore, comparing the models allows for us to determine how well each of the proposed learning and memory mechanisms can account for the description-experience gap. Before fitting the models to empirical data, however, we conducted a simulation study to determine what the heuristic CPT analyses will reveal if data are actually generated by the learning model instantiated by the RL-CPT.


Simulation Study
We focus our simulations on the RL-CPT due to the relationships between asymmetric learning and risk aversion, which could drive differences in probability weighting (and outcome valuation more generally) between DBDs and EBDs. However, we emphasize that memory decay in the IB-CPT could give rise to similarly biased estimates.
For our simulation study, we first simulated both description-and experience-based choices from the RL-CPT model using a single set of CPT parameters with separate positive and negative learning rates. Next, we fit the simulated data with a traditional CPT model using the heuristic method of setting , to the experienced proportion of rare events. The traditional CPT model assumed differences in probability weighting ( ), risk sensitivity ( ), and loss sensitivity ( ) between DBDs and EBDs, which is consistent with previous computational analyses of the description-experience gap 
(Glöckner, Hilbig, Henninger, & Fiedler, 2016;
Kellen, Pachur, & Hertwig, 2016)
. With this design, any preference differences inferred across DBDs and EBDs are wholly attributable to the proposed learning mechanism as opposed to true differences in CPT valuation parameters. Further, by keeping the valuation parameters constant while varying the learning rates, we were able to determine exactly how much (and in what direction) learning during EBDs could bias traditional CPT valuation parameters in the context of EBDs.


Simulation Experiment Design
The problem set used for the simulation study was taken directly from 
Kellen et al. (2016)
, and we refer the reader to the original study for details (see also 
Table S1
 for all gamble pairs).
We used this specific problem set because it encompasses gambles used in many studies on both DBDs and EBDs, many of which were selected for estimating important parameters in CPT.
Briefly, there are 114 different gambles, where each gamble was used for description (i.e., a oneshot preference judgement) and experience (i.e., repeated sampling before preference judgement). Individual gambles include those that were:
(1) used in original studies on the description-experience gap,
(2) randomly generated across gain, loss, and mixed gains and loss domains,
(3) selected to measure loss and risk aversion,
used in previous EBD studies,
a mix between those with safe versus risky options (reduced gambles), and (6) those composed of two risky options (non-reduced gambles).
Because previous studies suggest that the description-experience gap may vary across reduced and non-reduced gambles (e.g., 
Glöckner, Hilbig, Henninger, & Fiedler, 2016)
, we ran separate simulations for the reduced and non-reduced sets of gambles from 
Kellen et al. (2016)
 to determine if asymmetric learning could account for such differences.


Simulation Model Specification
We generated pseudo-participants' person-level RL-CPT valuation parameters using random draws from group-level normal distributions with means of = .88, = 2.25, and = .65, and with SDs of ≈ ≈ .10 and ≈ .3 (see Supplementary Text for full details). Note that these specific group-level means were chosen to match those estimated in the original CPT study , and SDs were chosen to ensure a realistic amount of variability across individuals. For learning rates, we generated a grid of all possible combinations of grouplevel learning rates for + ∈ {.25, .5, .75} and -∈ {.05, .15, … , .95}, totaling 30 unique group-level combinations. Additionally, we simulated choices (i.e., preference judgements in 
Fig. 1
) after pseudo-subjects drew either 19 or 99 total random samples from either choice option, where Equation 8 was used to update , after each sample. We chose these specific sample sizes based on both meta-analytic estimates of the number of samples typically drawn during free sampling (see 
Wulff et al., 2018)
, and to determine whether effects change when a larger number of samples are drawn. Finally, we simulated data separately for reduced (nreduced = 19) and non-reduced (nnon-reduced = 95) sets of gambles. Altogether, the simulations amounted to a 30×2×2 design (i.e., learning rates by sample size by gamble type), where each cell is a full set of simulated choices across 100 pseudo-participants. We refer the reader to the Supplementary Text for more specific details on simulation model parameters.


Simulation Results
Probability weighting. 
Fig. 3
 shows that asymmetric learning leads to biased estimates of CPT probability weighting ( ) when using the traditional heuristic method of setting , to the experienced proportion of outcomes observed within participant-gamble pairs 6 . For reduced gambles, probability weighting for EBDs-but not DBDs-is significantly biased by asymmetric learning in small sample settings, such that it is over-estimated when learning occurs more rapidly for positive prediction errors and under-estimated when learning occurs more rapidly for negative prediction errors. Further, as participants draw more samples, the effect reverses such that more rapid learning from negative prediction errors leads to over-estimation of probability weighting in EBDs. We did not observe this differential bias when both learning rates were closer to 1, in which case EBD probability weighting ( ) was more consistently overestimated.
Because the overestimate was close to = 1, these results may reflect uncertainty in estimates caused by rapid updating (i.e., high variation) of the outcome probability that, on average, will tend to drive estimates toward .5.
The results are different for non-reduced gambles, which lead to more consistent overestimation of probability weighting for EBDs in small sample settings (except when learning rates are lower and equal, or + = − ≈ .25). In larger samples, however, non-reduced gambles tend to produce accurate recovery of probability weighting estimates when learning rates are equivalent, but biased estimates when learning is asymmetric (where the direction of bias depends on the strength of both learning rates). 
Fig. 3
 suggests that if people do learn asymmetrically from positive versus negative prediction errors, then (1) a single pair of learning rates can lead to biased probability weighting estimates for EBDs using traditional CPT modeling, and (2) the same pair of learning rates has different effects on probability weighting estimates across reduced and non-reduced sets of gambles (i.e. "contextual" effects), where the direction of the bias is dependent on the number of samples that participants draw. For example, in small sample settings when both learning rates are approximately .5, traditional CPT modeling leads to linear probability weighting ( ≈ 1) for reduced gambles, but apparent overweighting of rare events ( < 1) for non-reduced gambles.
Risk aversion. 
Fig.'
s S1 and S2 show traditional CPT estimates of risk-and loss-aversion between description and experience generated by participants who learn at different rates for positive and negative prediction errors. For risk-aversion, there are two general trends worth noting. First, is consistently under-estimated for experience-based decisions (EBDs), whereas it is accurately estimated for description-based decisions (DBDs). A small exception is that for non-reduced gambles, there is a tendency for to be slightly under-estimated even for DBDs.
Second, across both reduced and non-reduced sets of gambles, biased estimates of are most extreme when both learning rates are low (i.e. less than .25), become less pronounced as learning rates become more rapid (i.e. greater than .25), and sometimes become more biased as learning again becomes more rapid (i.e. both learning rates greater than .75). However, this latter trend is minor.
Loss aversion. Results were different for loss-aversion. For reduced gambles, is consistently under-estimated when both learning rates are low (i.e. less than .25), but becomes better estimated as the negative prediction error learning rate ( -) becomes increasingly large.
Further, as the positive prediction error learning rate ( + ) increases, becomes increasingly under-estimated irrespective to -. Conversely, for non-reduced gambles, estimates showed the opposite pattern, where is increasingly under-estimated asbecomes increasingly large.
Overall, like for , is generally under-estimated for EBDs, particularly for non-reduced gambles where is often estimated to be less than 1. In fact, such apparent reversals of loss aversion (i.e. < 1) in non-reduced EBDs may explain the apparent loss-seeking behavior found in studies that use prospect theory valuation functions to model EBDs (e.g., .


Interim Summary of Simulation Study
Our simulation study confirmed that, if people do learn in a way consistent with the RL-CPT while sampling gambles (i.e. they are most sensitive to recent outcomes and update expectations differently based on whether outcomes were better or worse than expected), then heuristic applications of CPT are bound to reveal differences in valuation parameters across DBDs and EBDs even when there are no true differences in valuation. Further, the direction and magnitude of this bias is not initially intuitive-it is dependent on both the average value of learning rates, the magnitude of the difference in learning from positive versus negative predictions errors, the number of samples that a person draws, and features of the specific gambles that people are given (i.e. reduced versus non-reduced). However, as opposed to designing an experimental manipulation to control these various factors to explore the description-experience gap, we can explicitly model the learning and memory mechanisms underlying EBDs to identify potential invariances in valuation between DBDs and EBDs. Without an explicit model of learning, we risk misinterpreting CPT valuation parameters estimated in the context of EBDs due to our inability to experimentally control for complex learning and memory effects. Following this rationale, we next conducted a model comparison study using empirical data to determine the extent to which asymmetric learning captures observed within-person preference differences between DBDs and EBDs. For empirical model comparisons, we include the IB-CPT model as a competing learning/memory mechanism to the RL-CPT.


Empirical Study


Participants and Experiment
For the empirical study, we used actual participant data from 
Kellen et al. (2016)
. A total of 104 participants underwent all 114 description-and experience-based gambles as described above (see Simulation Experiment). We refer readers to the original study for more details on participants' characteristics, and provide summary statistics for the choice proportions within description and experience for each pair of gambles in 
Table S1
. For description-based gambles, participants were presented with gamble pairs one at a time, and they were instructed to choose the option that they preferred. For experience-based gambles, participants were allowed to sample from each option in whatever order and for how ever many trials they preferred before making a final preference judgement. Importantly, the order of description and experience was counter-balanced across participants, and the description and experience sessions were separated by at least one full week within each participant to minimize potential order effects. For EBDs, participants drew an average of 21.04 (SD = 9.4) samples before making a contingent choice (i.e., preference judgement). Previous CPT modeling of these data revealed an overweighting of rare events in EBDs relative to DBDs (i.e., < < 1; 
Kellen, Pachur, & Hertwig, 2016
).
Our simulations above indicated that an asymmetric learning mechanism could produce this overweighting result if: (1) learning rates are both below .75, (2) people learn more rapidly from negative relative to positive prediction errors, and (3) people draw around 20 samples on average (see the top row in 
Fig. 3)
. Conversely, the traditional description-experience gap arising from apparent underweighting of rare events in EBDs can occur if: (1) learning rates are both above .75, (2) people learn more rapidly from positive relative to negative prediction errors and draw around 20 samples (see the bottom panel in 
Fig. 3
), or (3) people learning more rapidly from negative prediction errors and draw a large number (~100) of samples.
Although 
Kellen et al. (2016)
  This finding that the same exact participants show variation in both the magnitude and direction of the description-experience gap across different sets of gambles is consistent with our simulation study-the contextual nature of learning during EBDs gives rise to apparent differences in valuation across different sets of gambles despite the underlying cognitive mechanisms being invariant. Although experimental designs such as the matched sampling paradigm can partially control for these factors, they still succumb to the unrealistic assumptions described in the introduction (i.e. perfect learning and memory). Therefore, we compared various models that make explicit assumptions about learning and memory during sampling on the dataset as a whole and individually to each of the four sets. We compared models both across and within sets to determine whether the same model (or class of model) could best capture performance across gambles that do versus do not show the traditional description-experience gap.


Competing Model Specifications
We developed three classes of competing models to determine which cognitive mechanisms provided the best statistical account of within-person preference differences between DBDs and EBDs. 
Table 1
 describes each of the models considered in the current study, which we describe in more detail below.
CPT models. First, we fit an array of traditional CPT models using the heuristic method of setting , to the proportion of samples that it was experienced for the given participant. To determine which particular valuation mechanism best accounted for preference differences between DBDs and EBDs according to traditional CPT, we developed models for each combination of differences in probability weighting, risk sensitivity, loss sensitivity, choice sensitivity, or probability elevation for positive and negative outcomes (described in more detail below). We also developed a base model that assumed CPT valuation parameters were identical within-participants across tasks. Of the CPT models, we were particularly interested in the variant with different valuation parameters across DBDs and EBDs (model Δ , Δ , Δ in 
Table   1
). This model is theoretically important because, as outlined in the introduction, prior research has suggested that differences in risk sensitivity, loss sensitivity, or probability weighting could explain the description-experience gap.
RL-CPT models. Second, we tested three different variants of the RL-CPT model, including a version with a single learning rate for positive and negative prediction errors, a version with a different learning rate for each positive and negative prediction errors, and a version including probability elevation parameters (see section below titled The Role of Probability Elevation).
Throughout our results, we focus our attention on the RL-CPT variant used in our simulation study (model ± in 
Table 1
) due to its theoretical relevance.
IB-CPT models. Third, we tested two variants of the IB-CPT model, including the version described in the introduction (i.e. a memory decay rate with a single set of valuation parameters across description and experience; model in 
Table 1
) in addition to one with probability elevation parameters. As with the RL-CPT model, we focus attention on the variant due to its theoretical relevance.
The Role of Probability Elevation. Although we did not consider it in our simulation study, we tested variants of 
Kellen et al.'s (2016)
 CPT formulation in our empirical model comparisons, which included a probability elevation parameter in the CPT probability weighting function. In particular, Equation 5 can be expanded as follows:
where (0 < < +∞) is an added probability elevation parameter that is often interpreted as optimism ( > 1) versus pessimism ( < 1) toward probabilistic outcomes. Mathematically,
W (p g,j ) = p g,j ( p g,j + (1 p g,j ) )
(10)
when > 1, the probability weighting function is shifted upward, indicating a general overestimation of the strength of probabilities (i.e. optimism); when < 1, the function is shifted downward, indicating a general under-estimation (i.e. pessimism). Oftentimes, a separate parameter is estimated for gains and losses to capture differential optimism or pessimism towards gains versus losses. 
Kellen et al. (2016)
 included probability elevation for gains + (0 < + < +∞) and for losses -(0 < -< +∞) according to the following rule:
which sets from Equation 10 to + when the potential outcome , for the respective probability , is positive, and tootherwise. We tested variants of the CPT, RL-CPT, and IB-CPT models that included differential probability elevation for gains versus losses that either varied or were set to be the same across description and experience.
In addition to including probability elevation parameters, 
Kellen et al.'s (2016)
 CPT formulation assumed differences in all parameters across DBDs and EBDs, including all CPT valuation parameters and the choice sensitivity parameter. We term this model the Saturated CPT model, given that it includes both probability elevation parameters described above and assumes that all within-person valuation and choice mechanisms vary across DBDs and EBDs. Saturated CPT contains 12 parameters per person 
( , , , , , , + , + , -, -, , )
.


Empirical Model Fitting
As with the simulated model fitting, we used hierarchical Bayesian modeling of all models listed in 
Table 1
. We assumed the same hierarchical structure, with person-level parameters drawn from group-level normal distributions. Likewise, we assumed that group-level means and
= ( + if x g,j 0 - otherwise
(11)
standard deviations also followed normal distributions centered around 1 for valuation parameters ( , , ; see Equation 9), and learning rates normally distributed around 0.5. We parameterized learning rates using the same scheme as described by Equation 9, but with grouplevel means distributed as + ∼ Normal(0, 0.2) and + ∼ half-Normal(0, 0.2). Unlike in the simulation study, we estimated the choice sensitivity parameter ( ) for all empirical models, with priors ∼ Normal(−0.87, 0.2) and ∼ half-Normal(0, 0.2), where person-level parameters followed the non-centered parameterization described in Equation 9 (but replacing the inverse probit transform and scaling factor with the exponential transform to ensure 0 < < +∞). We used the same prior distribution for a given parameter across all models in order to minimize the potential effects of our choice of prior distribution on model performance (e.g., the prior for was the same for all models, etc.).
We fit each model using 3 sampling chains for 3,000 total iterations each, 1,000 of which were discarded from each chain as warm-up samples, resulting in 6,000 total samples for each estimated posterior. To assess model convergence, we visually checked traceplots, and ensured that all ̂ values were under 1.1 .


Empirical Model Comparison
We used the leave-one-out information criterion (LOOIC) to determine which model provided the best fit to the data while penalizing for model complexity 
(Vehtari, Gelman, & Gabry, 2017)
. LOOIC is a fully Bayesian information criterion that estimates true leave-one-out cross validation; LOOIC is therefore an estimate of how well a model will perform relative to competing models on out-of-sample data. To compute LOOIC, we first computed the loglikelihood of each participant's choices given their estimated parameters for each posterior sample (i.e. log pointwise predictive density or LPPD) and gamble (e.g., 
Ahn, Haines, & Zhang, 2017;
Haines et al., 2018)
. This procedure results in separate posterior samples by participant by gamble ( × × ) LPPD arrays for description-and experience-based gambles. We then combined both arrays on the gamble dimension and input the resulting array in the loo R package 
(Vehtari et al., 2017)
  We caution that a lower LOOIC (or higher pseudo-BMA+ weights) does not indicate that a model is "true" or a better representation of the cognitive processes of interest in an absolute sense. Instead, we believe that such model comparison metrics are useful to compare the relative predictive performance of various models, and that the theoretical value of each model includes both predictive performance and other more qualitative considerations (e.g., assumptions they make about learning and memory, connections with the broader literature; Navarro, 2019).


Empirical Results
Model Comparison. 
Fig. 4
  Posterior Predictions. To better understand the absolute performance of the models, we focus attention on posterior predictions derived from the model in each class that we deemed most theoretically relevant given prior research on the description-experience gap: (1) the ∆ , ∆ , ∆ variant of CPT;
(2) the ± variant of RL-CPT; and (3) the variant of IB-CPT.
Despite these models not showing the best fit to empirical data within a given gamble set, we believe they best instantiate competing theories of the description-experience gap as detailed in the introduction. 
Fig. 5
 shows the group-level predictive performance for each of the three models. Notably, the models are almost indistinguishable in the description condition, yet the RL-CPT shows generally better predictive performance in the experience condition. For a more fine-grained view of 
Fig. 5
, 
Table S1
 includes the group-level observed and predicted choice proportions for each individual gamble and for each model.


Interpreting Model Parameters. The posterior distributions for group-and person-level
parameters from the ± variant of RL-CPT model are shown in 
Fig. 6
. The group-level negative prediction error learning rate is larger than the group-level positive prediction error learning rate (95% highest density interval 
[HDI]
 of -− + = [0.13, 0.24]), which is consistent with previous literature and indicates risk-averse learning (e.g., 
Cox et al., 2015;
Doll et al., 2009;
Frank et al., 2004;
Mihatsch, & Neuneier, 2002;
Niv, Edlund, Dayan, & O'Doherty, 2012
 
Fig. 3
), a finding that is consistent with previous applications of CPT to these data 
(Kellen, Pachur, & Hertwig, 2016
 


Discussion
In the current study, we used a combination of computational model simulations and empirical model fitting to show that preference differences between description-and experiencebased gambles can be attributed to an asymmetric learning mechanism rather than contextdependent changes in psychological valuation across tasks. We developed a hybrid reinforcement learning and cumulative prospect theory (RL-CPT) model that used separate learning rates for positive and negative prediction errors and assumed that probabilities and outcomes are valued equivalently across DBDs and EBDs. Through Bayesian model comparison, we found that the ± variant of the RL-CPT model (see 
Table 1
) provided a better account of within-subject differences in DBDs versus EBDs when compared to traditional CPT models that assume perfect learning and memory with differences in risk aversion, loss aversion, probability weighting, choice sensitivity, and probability elevation for gains and losses (i.e.


Saturated CPT).
Put together, the RL-CPT offers improved performance for EBDs without compromising performance on DBDs relative to traditional CPT models (see 
Fig. 5
). The RL-CPT with asymmetric learning also performed better than a competing instance-based memory model ( from 
Table 1
). While other studies have shown that learning and memory models can account for EBDs (e.g., 
Busemeyer & Myung, 1992;
Erev & Roth, 1998;
Estes, 1976;
Gonzalez et al., 2011;
Hau et al., 2008)
, they did not demonstrate any ability to capture the description-experience gap.
To our knowledge, this is the first study to directly and quantitatively compare a variety of computational models that make explicit assumptions regarding how learning and memory can give rise to preference differences between DBDs and EBDs. This was only possible because the learning and memory models that we developed directly estimate the payoff probabilities associated with each outcome, which allows for them to simultaneously capture decisions from both description-and experience-based tasks in a straightforward manner.
The RL-CPT ( ± variant) suggests that foundational cognitive biases including risk aversion, loss aversion, and overweighting of rare events hold true across both DBDs and EBDs when asymmetric learning during sampling in EBDs is accounted for (see 
Fig. 6
). Further, our finding that people learn more rapidly from negative as opposed to positive predictions errors extends previous findings (e.g., 
Cox et al., 2015;
Doll et al., 2009;
Frank et al., 2004;
. A higher learning rate for negative as opposed to positive prediction errors produces "risk sensitive" decision-making (e.g., 
Mihatsch & Neuneier, 2002)
. Conceptually, it follows that typical CPT valuation parameters-which also capture risk sensitivity-could be poorly estimated in EBDs if asymmetric learning occurs. Indeed, our simulations confirmed this quantitatively, predicting that more rapid learning of negative relative to positive prediction errors will lead to an underestimation of probability weighting in EBDs relative to DBDs when using traditional CPT modeling (see 
Fig. 3
), which can explain contextual effects of more overweighting of rare events in EBDs compared to DBDs (e.g., 
Glöckner, Hilbig, Henninger, & Fiedler, 2016;
Kellen, Pachur, & Hertwig, 2016)
. To the extent that these learning rates vary across the lifespan, we might observe apparent differences between older and younger adults that are specific to experience-based decisions and physiological measures 
(Rosenbaum et al, 2021)
.
Responses to positive and negative surprises will impact not only probability weighting and value sensitivity, but also measures like pupil dilation that are known to reflect the magnitude prediction errors during learning on these types of tasks 
(Braem et al, 2015;
Lavin et al, 2014)
.
Given prior findings that people learn more rapidly when experiencing intense negative rather than positive affect 
(Haines et al., 2019)
, future research may explore the relationships between physiological states and learning throughout EBDs. Such studies may reveal insights into the known differences in risky decision-making between healthy and clinical populations (e.g., 
Maner et al., 2007;
Yechiam, Busemeyer, Stout, & Bechara, 2005)
.
Lastly, because both valuation and learning mechanisms interact to produce behavior, the competing effects of overweighting rare events and risk-averse learning may produce the expected-value maximizing behavior that is often observed in EBDs (see 
Wulff et al., 2018
 
(Kopsacheilis, 2018)
. Despite this, models including search or optional stopping rules show promising results (e.g., 
Busemeyer, 1985;
Markant, Pleskac, Diederich, Pachur, & Hertwig, 2015;
Wulff, Markant, Pleskac, & Hertwig, 2019)
 and may be well-suited to integrate with models such as the RL-CPT.
Nevertheless, RL-CPT does account for variation in behavior across participants by leveraging the information that they gain across samples to estimate the learning rates (see Equation 8).
Further, the learning mechanism of the RL-CPT is generalizable in the sense that it can be applied to both sampling EBDs, repeated choice EBDs, and EBDs with more than two choices.
Specifically, if each sample that participants draw is treated as a choice (i.e., preference judgement in 
Fig. 1
), the probability estimates and resulting expected values on each sample (or trial in repeated choice tasks) can be used to estimate the likelihood of repeated, trial-by-trial choices for each choice option (e.g., 
Haines et al., 2019;
Niv, Edlund, Dayan, & O'Doherty, 2012)
. Therefore, we view the addition of an optional stopping rule as a taskspecific extension, and not a competing mechanism, of the RL-CPT.
In summary, our findings suggest that future research on the description-experience gap should focus on learning, memory, search (i.e., during sampling), and optional stopping mechanisms, all of which could lead to deeper insights into human decision-making under risk.
Additionally, future studies could use experimental manipulations that are known to influence learning rates to determine if the RL-CPT can capture subsequent changes in risk preferences.
More broadly, our findings demonstrate the benefits of using formal computational cognitive models of behavior to understand how individual differences at one level-of-analysis (e.g., psychological mechanisms) can affect inferences made at another level (e.g., behavioral differences). Computational modeling allowed us to merge different areas of research (i.e., reinforcement learning and risky decision-making) in a formalized, straightforward way, which led to circumscribed predictions regarding the relationship between psychological mechanisms (i.e., probability and outcome valuation), neural mechanisms (i.e., differential dopamine response to positive versus negative prediction errors), and an observed behavioral phenomenon (i.e., the description-experience gap). We then leveraged Bayesian model comparison of multiple competing theoretical models to determine which theory was most consistent with the data. This work therefore extends the past modeling work on the essential learning component of EBDs 
(Busemeyer & Myung, 1992;
Erev & Roth, 1998;
Gonzalez et al, 2011;
Haines, Vassileva, & Ahn, 2018;
Hau et al., 2008)
 in a theoretically-motivated way to solve an empirical paradox.


Conclusion
Asymmetric learning offers causal mechanisms to explain the apparent changes in probability weighting-and valuation more generally-across both description-and experiencebased decisions and different forms of experience-based decisions. Classic findings of riskaversion, loss-aversion, and overweighting of rare events can apply for both description-and experience-based decisions, but only when asymmetric learning is appropriately incorporated.
More work needs to be done to refine joint models of description and experience that are both predictively powerful and psychologically realistic with regard to mechanisms underlying learning and memory in addition to valuation and action selection. More broadly, computational models offer a formalized way to combine substantive theories from different areas of research, which can reveal simple rules underlying otherwise complex, context-dependent psychological effects inferred using theoretically inconsistent statistical procedures.


Open Practices Statement
The data used within this article are already published and available at the following address:
https://raw.githubusercontent.com/dwulff/dwulff.github.io/master/_data/WulffEtAl2018TwoMo  Note. Examples of description-versus experience-based decisions for a gamble between winning $4 with probability .8 ($0 with probability .2) versus $3 for certain. As depicted, people tend to choose the safe option when the probability is given. Conversely, when people must sample both options to learn the probabilities of each outcome (i.e., sampling paradigm), they tend to choose the risky option. Such preference differences are often interpreted as differences in evaluating the probability of rare events. Multiple mechanisms have been proposed to explain this difference including sampling error and recency, which will lead to experienced probabilities that are different from the true probabilities when people draw low numbers of samples (e.g. ~20) before making a contingent choice (i.e. preference judgement). Alternatively, people may actually weight probabilities differently between task presentations, which can be captured by the parameter from cumulative prospect theory. Specifically, < 1 indicates overweighting of rare events while > 1 indicates underweighting of rare events.


Figure 2. Effect of asymmetric learning on probability estimation
Note. The above graph shows model-predicted probability of the high outcome [Pr(H)] occurring for both the "reduced" gamble (i.e. one option is certain and the other risky/probabilistic) exemplified in 
Fig. 1
 and another "non-reduced" gamble (i.e. both options are probabilistic/risky). To generate sample-to-sample probabilities, we used a simple strength-based reinforcement learning model with separate learning rates for positive ( + ) and negative ( -) prediction errors (see Equation 8 in the Method section), where option A and B were sampled with equal probability. All outcome probabilities are updated after each sample in proportion to both the difference between the expected and actual outcome (prediction error) and the learning rate-we show only Pr(H) for visual purposes. Panels denote each combination of + andwith values of .1, .3, and .5, and shaded intervals around predicted values indicate ±2 standard errors of the mean across repeated iterations. The shaded region highlights the first 20 samples.
Probability estimates converge to true values for certain options (irrespective to the learning rates), but converge to biased estimates when outcomes are probabilistic and learning rates are not equivalent. Additionally, effects of sampling error and recency are apparent even when learning rates are equivalent, where the random nature of the sampling process has not yet allowed for learning to converge to the true outcome probability and estimates are subsequently biased toward .5. Details on how we generated the above predictions are described in the Supplementary Text for the sake of brevity. Note. Estimates for group-level CPT probability weighting in DBDs and EBDs when setting , to the experienced proportion of rare events. Because was left unchanged across all simulations of the RL-CPT, all deviance between EBD probability estimates and the true values reflect biases induced by the asymmetric learning mechanism (Equation 8). For reduced gambles, when learning rates are generally lower (i.e. < .5) and participants draw fewer samples, is overestimated (underestimated) when learning occurs more rapidly for positive (negative) prediction errors. Importantly, this effect reverses in larger sample settings, revealing an interaction between learning asymmetry and sample size. For non-reduced gambles, probability weighting is more consistently overestimated across all levels of learning rates relative to reduced gambles only (particularly in small sample settings), leading to apparent underweighting of rare events for EBDs relative to DBDs in the absence of a true difference in probability weighting. Therefore, the same pair of learning rates can lead to different biases in probability weighting across reduced and non-reduced gambles for EBDs, particularly in small sample settings (cf. + = .25 and + = .5 across reduced and non-reduced gambles). Shading indicates the 95% HDI of the posterior estimate. (with probability elevation for gains/losses)
Notes. CPT models all assume that the probability of each outcome ( , ) is the objective proportion of samples which resulted in the respective outcome (i.e. perfect learning/memory).
They differ with respect to which CPT parameters differ within-subjects across DBDs and EBDs.
RL-CPT models all assume that all CPT parameters are constant within-subjects across DBDs and EBDs, and instead assume that , is learned through sampling for EBDs. Consequently, RL-CPT models assume that differences in preference judgements are wholly attributable to individual differences in learning rather than valuation. However, we tested variants of RL-CPT where valuation parameters are allowed to vary across DBDs and EBDs as in the CPT models, which are denoted by Δ. ± subscripts denote models with separate positive and negative learning rates. IB-CPT models are akin to RL-CPT models, but assume that , is determined by an instance-based memory decay mechanism as opposed to the strength-based learning mechanism assumed by the RL-CPT.  
Table 1
 for model notation and descriptions). Numbers in each row indicate the pseudo-BMA+ weights for each model within the given set. Sets 1 and 3 show the traditional description-experience gap, and Sets 2 and 4
show a reversed gap (see Participants and Experiment section; 
Wulff et al., 2018)
. Error bars reflect ±1 standard errors of the difference between the best fitting model within each gamble Set and the respective competing model.
.00
.00
.00
.00
.00
.00
.00
.00
.00
.04
.00
.00
.96
.00
.00
.00
.00
.00
.00
.00
.00
.09
.00
.00
.00
.00
.00
.01
.


19
.70
.00
.00
.00
.06
.00
.00
.00
.00
.00
.


60
.00
.01
.10
.00
.22
.00
.00
.00
.00
.00
.00
.00
.00
.00
.00
.00
.


85
.15
.00
.00
.00
.00
.00
.00
.00
.00
.00
.00
.00
.


64
.00
.00
.


26
.00
.10
All Sets Set 1 Set 2 Set 3 Set 4 0 5 0 0 1 0 0 0 1 5 0 0 0 1 0 2 0 3 0 4 0 5 0 0 2 5 0 5 0 0 7 5 0 0 2 0 0 4 0 0 6 0 0 0 5 0 1 0 0 1 5 0 2 0 0 2 5 0 Note. Posterior predictive distributions for both CPT (the ∆ , ∆ , ∆ variant from  included as a visual reference, indicating .5 for the learning rates and 1 for the valuation/choice parameters. Note that the group-level valuation parameters are in the same direction as those found in  original analyses of DBDs, indicating risk aversion ( < 1), loss aversion ( > 1), and overweighting of rare/low probability events ( < 1) across both DBDs and EBDs.
A IB , d ± A IB A ±, d ± A ± A RL a D , l D , g D , f D , d +D , d −D a D , l D , g D , f D a D , l D , g D l D , g D a D , g D a D , l D g D l D a
Simulating Probability Learning 
Fig. 2
 (main text) shows the effects of asymmetric learning on estimating a probability. We generated estimates in 
Fig. 2
 


Details on RL-CPT Simulation
To ensure that parameters were appropriately bounded, we: (1) sampled pseudo-participants'
individual-level parameters from group-level normal distributions, and then 
2
 , respectively). Note that after being inverse probit-transformed and scaled by the upper bound, the group-level means are equivalent to those derived in the original CPT study as described in the main text (i.e. = .88, = 2.25, and = .65; . As described in the main text, we generated a grid of all possible combinations of group-level learning rates for + ∈ {.25, .5, .75} and -∈ {. 
05, .15, .25, .35, .45, .55, .65, .75, .85, .95}
, totaling 30 unique group-level combinations. Individual-level learning rates were drawn from a multivariate normal distribution with means for positive and negative learnings rates set to those in the above grid (e.g., + , -= {. 25, .05}, {. 25, .15}, … , {. 75, .95}), SDs both set to .05, and the correlation between learning rates within-subjects ( ) set to .5 (SDs and indicate the values before being inverse probit-transformed). As with the valuation parameters,
individual-level learning rates were first sampled directly from the multivariate normal distribution before being inverse probit-transformed to ensure + , -∈ [0, 1].


Fitting the Model to Simulated Data
For each of the cells in our 30×2×2 design, we used hierarchical Bayesian modeling of CPT with different parameters estimated for description ( , , ) versus experience ( , , ).
We assumed that person-level parameters were drawn from group-level normal distributions, with group-level means and standard deviations also following normal distributions. We centered priors for all group-level parameters around 1, which effectively assumes that pseudoparticipants make choices based on the objective utility of each option across both task variants.
Additionally, we (1) estimated parameters in an unconstrained space before inverse probittransforming and scaling them to the correct parameter bounds, and (2) used non-centered parameterizations to decrease the dependence between group-level means and standard deviations (e.g., 
Ahn, Haines, Zhang, 2017;
Haines, Vassileva, Ahn, 2018
)-this parameterization scheme allows for more efficient sampling from high-dimensional models with correlated parameters 
(Betancourt & Girolami, 2013)
. Using as an example, we specified the prior as follows:
We parameterized using the same priors as in Equation 9. For , we set ∼ Normal(−1.33, 1.0), and the scaling factor was 10 as opposed to 5 (meeting the appropriate bounds). We used the same prior parameterization across description ( , , ) and experience ( , , ) parameters. We chose these prior distributions to minimize any potential directional biases that could otherwise be induced with more informative prior distributions. Because the group-level means for all valuation parameters are centered around 1 and equivalent across DBDs and EBDs, we can be sure that any parameter estimates we get on either side of 1 can be interpreted as information gained through the data, rather than through the choice of prior (e.g., an estimate of < 1 indicates that there is evidence for risk aversion for DBDs in the data). We chose the specific parameter bounds 0 < , < 5 and 0 < < 10 because we deem values outside of this range highly unlikely based on previous applications of CPT. Finally, for each combination of learning rates, we fit the CPT model using 2 sampling chains for 2,000 total iterations each, 500 of which were discarded from each chain as warm-up samples (3,000 total samples for each parameter). We visually checked trace plots of group-level parameters, and ensured that all ̂ values (i.e., Gelman-Rubin statistics) were under 1.1, suggesting that the variance between sampling chains is similar to the variance within chains and therefore indicates convergence to the same distribution .


Simulation Results for Risk-and Loss-Aversion
Fig.'s S1 and S2 show traditional CPT estimates of risk-and loss-aversion between description and experience generated by participants who learn at different rates for positive and negative prediction errors. For risk-aversion, there are two general trends worth noting. First, is consistently under-estimated for experience-based decisions (EBDs), whereas it is accurately estimated for description-based decisions (DBDs). A small exception is that for non-reduced gambles, there is a tendency for to be slightly under-estimated even for DBDs. Second, across both reduced and non-reduced sets of gambles, biased estimates of are most extreme when both learning rates are low (i.e. less than .25), become less pronounced as learning rates become more rapid (i.e. greater than .25), and sometimes become more biased as learning again becomes more rapid (i.e. both learning rates greater than .75). However, this latter trend is minor.
Results were different for loss-aversion. For reduced gambles, is consistently underestimated when both learning rates are low (i.e. less than .25), but becomes better estimated as the negative prediction error learning rate ( -) becomes increasingly large. Further, as the positive prediction error learning rate ( + ) increases, becomes increasingly under-estimated irrespective to -. Conversely, for non-reduced gambles, estimates showed the opposite pattern, where is increasingly under-estimated asbecomes increasingly large. Overall, like for , is generally under-estimated for EBDs, particularly for non-reduced gambles where is often estimated to be less than 1. In fact, such apparent reversals of loss aversion (i.e. < 1) in non-reduced EBDs may explain the apparent loss-seeking behavior found in studies that use prospect theory valuation functions to model EBDs (e.g., .
Overall, our simulations show that heuristic CPT modeling is likely to reveal strong riskaversion ( ) and reductions/reversals of loss-aversion ( ) in EBDs relative to DBDs. In general, is consistently under-estimated across all possible combinations of learning rates and gambles, and also tends to be under-estimated except in the very specific case when: (1) participants draw around 20 samples, (2) + ≈ .25, and (3) -> .25. Assuming that the average participant learns more rapidly from negative as opposed to positive predictions errors-consistent with both our results reported in the main text and those of others (e.g., Gershman, 2015)-our simulations suggest that reductions/reversals of loss-aversion found in prior studies of EBDs (e.g., 
Erev, Ert, & Yechiam, 2008)
 may actually be the result of biased inference due to asymmetric learning (see 
Fig. S2
).


Probability Elevation Priors
To determine if the inclusion of probability elevation affected our empirical model comparison results, we fit both (1) the Saturated CPT model, and (2) a version of the RL-CPT model with separate learning rates for positive and negative prediction errors that includes probability elevation for gains ( + ) and losses ( -) according to eq.'s S1 and S2 (see 
Table S2
).
Note that as in the main text, and unlike the Saturated model, the RL-CPT with probability elevation for gains and losses assumes that + andare shared across DBDs and EBDs, and that the learning mechanism alone captures preference differences between tasks.
We assigned the prior distributions for the Saturated CPT and RL-CPT with probability elevation models in the same way as described in the main text. Using the probability elevation parameter for gains as an example:
As with all models in the main text, we fit both models using 3 sampling chains for 3,000 total iterations each, 1,000 of which were discarded from each chain as warm-up samples (i.e., resulting in 6,000 total samples for each estimated posterior). To assess model convergence, we visually checked traceplots, and ensured that all ̂ values were under 1.1 .


Parameter Identifiability
Given the relative complexity of the models we fit to data, a natural question arises regarding the identifiability of model parameters-particularly when these parameters are used to make inference, as is the case with the RL-CPT model. Although we did not perform a full parameter recovery or simulation-based calibration analysis, we did explore the joint posterior distribution of the following three primary models depicted in In particular, there are moderate trade-offs between person-level and parameters across all models, although the trade-offs are strongest for the learning models. This is a common finding in decision models that have both inverse temperature/choice sensitivity and valuation parameters (e.g., 
Molloy et al., 2020;
Krefeld-Schwalb et al., 2022)
. This trade-off occurs because changes in either parameter can influence the likelihood in similar ways-a decrease in makes differences in subjective values smaller, which produces more ambivalent choice between competing gambles. Similarly, decreases in produce more ambivalent choices between gambles (i.e. the probability of choosing the gamble with higher expected value decreases). Given the similar effects that these parameters have on behavior, they show a strong negative correlation in the joint posterior-when is higher, a lower value of can produce an equivalent likelihood, and vice-versa.
Despite these moderate parameter trade-offs, the joint posteriors reveal that the direction of the parameter values remains consistent across the entire range that they trade off. Specifically, the posteriors for both and are entirely below 1, indicating risk aversion ( < 1) and diminishing sensitivity to changes in expected value ( < 1) across all models. More generally, the joint posteriors on learning parameters for both learning models are generally well-behaved.
The only pattern worth noting is the minimal correlation between person-level + and − parameters in the RL-CPT model, which we would expect to see given that, in our study design, the relationship between + and − indicates changes in preference across description-and experience-based tasks. Therefore, higher values for one learning rate must be accompanied by higher values for the other to preserve the observed changes in behavior across task formats. The fact that learning rates are not highly correlated provides some evidence that they are identifiable in a local sense, at least to the extent that is necessary for making inference on their difference. Notes. All 114 gamble pairs (Prob = Choice Problem) used for both the simulation and empirical study in the main text. Empirical and model-predicted choice proportions (True) for both description and experience are shown on the right-hand side (Pr(Choose A)). The CPT and RL-CPT models correspond to the Δ , Δ , Δ and ± variants from 
Table 1
 in the main text, respectively. In the Prob column, (*) indicates that the particular problem was of the 10 worse predicted by the RL-CPT model in the experience condition, and ( †) indicates the same for the CPT model. B; AL = low payoff for gamble A; BL = low payoff for gamble B; PrH = probability of high payoff for gamble A; PrH = probability of high payoff; PrL = probability of low payoff.       
found a reversal of the traditional description-experience gap in their aggregate data using CPT modeling, non-computational analyses (i.e. those relying on the heuristic prediction-focused method critiqued by Regenwetter & Robinson, 2017) of their data reveal the traditional description-experience gap as reported by
Hertwig et al. (2004)
. As we described in our simulation study, Kellen et al.'s dataset contains four distinct sets of gambles.
Wulff et al. (2018)
 showed in their meta-analysis that two of these gamble sets show a traditional description-experience gap when analyzed separately: (a) Set 1, which is comprised of the gambles used in the original work by
Hertwig et al. (2004)
 on the description-experience gap, and (b) Set 3, which is comprised of gambles that were chosen to optimize estimation of risk and loss aversion.


., Pleskac, T. J., Diederich, A., Pachur, T.,& Hertwig, R. (2015).Modeling choice and search in decisions from experience: A sequential sampling approach. In 37th Annual Meeting of the Cognitive Science Society (pp. 1512-1517). Cognitive Science Society. Mihatsch, O., & Neuneier, R. (2002). Risk-sensitive reinforcement learning. Machine Learning, 49, 267-290. doi:10.1023/A:1017940631555 Montague, P. R., Dolan, R. J., Dolan, R. J., Friston, K. J., Friston, K. J., & Dayan, P. (2012). Computational psychiatry. Trends in Cognitive Sciences, 16, 72-80. doi:10.1016/j.tics.2011.11.018 Navarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28-34. Nilsson, H., Rieskamp, J., & Wagenmakers, E.-J. (2011). Hierarchical Bayesian parameter estimation for cumulative prospect theory. Journal of Mathematical Psychology, 55, 84-93. doi:10.1016/j.jmp.2010.08.006 Niv, Y., Edlund, J. A., Dayan, P., & O'Doherty, J. P. (2012). Neural prediction errors reveal a risk-sensitive reinforcement-learning process in the human brain. Journal of Neuroscience, 32, 551-562. doi:10.1523/JNEUROSCI.5498-10.2012 Regenwetter, M., & Robinson, M. M. (2017). The construct-behavior gap in behavioral decision research: A challenge beyond replicability. Psychological Review, 124, 533-550. doi:10.1037/rev0000067 Rescorla, R. A., & Wagner, A. R. (1972). A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement. Classical conditioning II: Current research and theory, 2, 64-99.


Figure 1 .
1
Description-versus Experience-based Decisions


Figure 3 .
3
Biases in experience-based CPT probability weighting ( ) estimates


Figure 4 .
4
Comparison of competing models Note. Relative difference in leave-one-out information criterion (LOOIC) between the best fitting model and all other models within each gamble Set, where lower LOOIC values indicate better model fit while penalizing for model complexity (see


Figure 5 .
5
Posterior predictive distributions derived from CPT and RL-CPT across description and experience


Figure 6 .
6
Posterior distributions of group-and person-level RL-CPT parameters Note. Posterior distributions for each group-and person-level parameter from the ± variant of the RL-CPT. The group-level panels show the posterior density of the group-level mean for each parameter. The annotation on each panel represents that posterior mean and 95% HDI of the corresponding group-level mean parameter. Points and intervals for the bottom panel indicate the means and 95% HDI for each of the person-level parameters. The dashed gray line is simply


using the following four steps. First, we created a 3 × 3 grid of positive ( + ) and negative ( -) prediction error learning rates where each cell contained a unique combination of + ∈ {.1, .3, .5} and -∈ {.1, .3, .5}. Second, we drew a sequence of 100 "samples" from a binomial distribution with a success probability of .2, resulting in a 100-length vector of 0's and 1's. Third, we used eq. 5 from the main text to update the estimate of the success probability ( ) while iterating through each of sample s, where = ( ) − ( ) ( indicating a successful [1] or unsuccessful [0] sample from the vector). Fourth, we iterated steps 2-3 50 times within each of the cells from step 1, and then averaged across the sample-to-sample estimates of within cells. Fig. 2 shows the averaged estimates and SEs across the 50 iterations within each cell.


transformed resulting individual-level parameters to the appropriate bounds. For the first step, group-level means were sampled from normal distributions with ′ = −.93, ′ = −.76, and ′ = −1.13, and with SDs of ′ = ′ = ′ = .1. Second, we used the inverse cumulative distribution function of the normal distribution (i.e. inverse probit-transformation) to transform individuallevel parameters on [0, 1]. Next, we scaled the resulting inverse probit-transformed individuallevel parameters by multiplying them by the appropriate upper bound (5, 10, and 5 for , , and


Figures 4-5 of the main text: (1) the CPT model, (2) the RL-CPT model, and (3) the IB-CPT model. Figures S3-S8 show the joint posterior distributions of the group-and example person-level parameters for each of the models. In general, group-level parameters appear to follow a well-behaved multivariate normal distribution-group parameters show little to no correlation in the joint posterior across all models. Person-level joint posteriors begin to show more signs of trade-offs between parameters.


Figure S1 .
S1
Biases in experience-based CPT risk-aversion ( ) estimates Note. Shading indicates the 90% HDI.


Figure S2 .
S2
Biases in experience-based CPT loss-aversion ( ) estimates Note. Shading indicates the 90% HDI.


Figure S3 .
S3
Joint posterior of group-level parameters for the CPT model.


Figure S4 .
S4
Joint posterior of example person-level parameters from the CPT model.


Figure S5 .
S5
Joint posterior of group-level parameters for the RL-CPT model.


Figure S6 .
S6
Joint posterior of example person-level parameters from the RL-CPT model.


Figure S7 .Figure S8 .
S7S8
Joint posterior of group-level parameters for the IB-CPT model. note Joint posterior of example person-level parameters from the IB-CPT model.


shows the estimated differences in model fit between the best fitting model and all competing models, both across all 114 gambles and within each of the 4 gamble sets. Within each gamble set, LOOIC results showed that learning and memory models (RL-CPT and IB-CPT models) performed equal to or better than those assuming perfect learning with changes in valuation parameters across DBDs and EBDs (traditional CPT models). Across all sets, the RL-CPT with asymmetric learning and a single set of valuation and choice parameters across DBDs and EBDs (model ± inTable 1) performed better than all variants of CPT, including the most complex CPT model (i.e. the Saturated CPT model with 12 free parameters per person). Similarly, the IB-CPT model with probability elevation parameters showed better performance than all CPT models, although it performed worse than the RL-CPT model with asymmetric learning rates. This latter finding demonstrates the importance of asymmetric learning for predicting behavior in EBDs.
Overall, our model comparison results offer strong evidence that people do have imperfect
learning and memory while sampling during EBDs-asymmetric learning alone (model
± in Table 1) can better capture within-person changes in behavior across DBDs and EBDs than a model assuming perfect learning/memory and changes in all valuation and choice mechanisms (the Saturated CPT model).


). Further, the magnitudes of the learning rates for positive (95% HDI of + =
[0.19, 0.25]) and negative (95% HDI of -= [0.35, 0.45]) prediction errors were consistent with
what our simulations predicted based on previous studies. Specifically, traditional CPT modeling
would indicate more overweighting of rare events in EBDs relative to DBDs given the absolute magnitude and the differences between learning rates (see top panels in


" overweighting of rare events from CPT may still be present in EBDs, but that it is masked by the presence of asymmetric learning in the sampling process. The personlevel posterior distributions demonstrate that there are strong individual differences in learning rates and valuation parameters alike, which provides further evidence against the assumption that people have perfect learning and memory during EBDs.
).
Lastly, the valuation parameters from the RL-CPT resemble those classically found for DBDs-
we found evidence for risk aversion (95% HDI of = [0.61, 0.65]), loss aversion (95% HDI of
= [1.14, 1.35]), and overweighting of rare events (95% HDI of = [0.62, 0.72]). This indicates
that the "traditional


). Indeed, it is an open question why people make more choices that maximize expected value in EBDs relative to DBDs, and risk-averse learning mechanisms may provide a partial explanation.
An important limitation of the current study is that the RL-CPT model does not predict
participant's sampling behavior, which means that it is not a full generative model of how people
behave during EBDs. Part of the reason for this is that sampling behavior is intensely
idiosyncratic, with information search varying according to momentary fluctuations in
experienced sample variance, participants working memory capacity, and sampling heuristics
that vary widely across participants or even within a session


Table 1 .
1
Competing models and assumptions
Model Name
Assumed Differences (and details)
Base
None
∆
Risk sensitivity
∆
Loss sensitivity
∆
Probability weighting
∆ , ∆
Risk sensitivity and loss sensitivity
CPT
∆ , ∆ ∆ , ∆
Risk sensitivity and probability weighting Loss sensitivity and probability weighting
∆ , ∆ , ∆
Risk sensitivity, loss sensitivity, and probability weighting
∆ , ∆ , ∆ , ∆
Risk sensitivity, loss sensitivity, probability weighting, and choice sensitivity
∆ , ∆ , ∆ , ∆ , + ∆ , − ∆
Risk sensitivity, loss sensitivity, probability weighting, choice sensitivity, and probability elevation for gains/losses
Strength-based learning of , during
experience
(with separate learning rates for
RL-CPT
±
positive/negative prediction errors)
(with separate learning rates for
± , ±
positive/negative prediction errors and
probability elevation for gains/losses)
Instance-based memory decay determines
IB-CPT
, during experience
, ±


Table 1
1
Light red points and intervals indicate the model-predicted means and 95% highest density intervals of Pr(Choose B), and the annotated text in each panel is the posterior mean and 95% HDI (in square brackets) for the correlation between observed and posterior-predicted Pr(Choose B). The models are practically indistinguishable in the description condition, yet the RL-CPT exhibits generally more accurate predictions in the experience condition relative to both other models.
), RL-


Table S1 .
S1
Problem set and observed choice proportions across description and experience
Pr(Choose A)
Prob A H (Pr H )
A L
(Pr L )
B H (Pr H )
B L
(Pr L )
Description
Experience
True
CPT
RL-CPT
True
CPT
RL-CPT
1
3 (1)
--
4 (.8)
0 (.2)
.75 .54 .53 .54 .55 .55
2
--
-3 (1)
0 (.2)
-4 (.8)
.25 .49 .49 .4 .47 .5
3
3 (.25)
0 (.75)
4 (.2)
0 (.8)
.47 .51 .51 .41 .49 .49
4* †
0 (.8)
-4 (.2)
0 (.75)
-3 (.25)
.43 .49 .49 .28 .51 .5
5
3 (1)
--
32 (.1)
0 (.9)
.62 .5
.5 .63 .55 .52
6 †
0 (.9)
-32 (.1)
0 (.9)
-3 (.1)
0
.44 .45 .17 .39 .37
7* †
3 (.25)
0 (.75)
32 (.025)
0 (.975) .58 .48 .48 .74 .54 .51
8* †
0 (.975)
-32 (.025)
0 (.75)
-3 (.25)
.46 .47 .47 .76 .53 .44
9* †
.5 (.75)
0 (.25)
6 (.15)
0 (.85)
.26 .48 .48 .29 .5 .49
10
0 (.85)
-6 (.15)
0 (.25)
-.5 (.75)
.43 .47 .47 .34 .5 .48
11
.9 (.7)
0 (.3)
13 (.15)
0 (.85)
.27 .46 .47 .31 .47 .46
12
0 (.85)
-13 (.15)
0 (.3)
-.9 (.7)
.38 .48 .49 .43 .49 .45
13
770 (.1)
20 (.9)
400 (.1)
320 (.9)
.01 .06 .05 .02 .1 .07
14
770 (.2)
20 (.8)
400 (.2)
320 (.8)
.02 .11 .09 .03 .18 .11
15
770 (.3)
20 (.7)
400 (.3)
320 (.7)
.03 .16 .14 .15 .24 .15
16
770 (.4)
20 (.6)
400 (.4)
320 (.6)
.09 .23 .21 .19 .31 .22
17
770 (.5)
20 (.5)
400 (.5)
320 (.5)
.14 .35 .32 .2 .39 .28
18
770 (.6)
20 (.4)
400 (.6)
320 (.4)
.25 .49 .48 .28 .44 .33
19
770 (.7)
20 (.3)
400 (.7)
320 (.3)
.46 .61 .6 .46 .52 .43
20
770 (.8)
20 (.2)
400 (.8)
320 (.2)
.64 .75 .75 .5 .65 .52
21
770 (.9)
20 (.1)
400 (.9)
320 (.1)
.71 .83 .83 .66 .73 .64
22
770 (1)
--
400 (1)
--
1
.95 .95 .99 .93 .93
23
-20 (.9)
-770 (.1)
-320 (.9)
-400 (.1)
.95 .96 .97 .9 .93 .87
24
-20 (.8)
-770 (.2)
-320 (.8)
-400 (.2)
.92 .93 .95 .75 .86 .77
25
-20 (.7)
-770 (.3)
-320 (.7)
-400 (.3)
.83 .92 .92 .74 .82 .72
26
-20 (.6)
-770 (.4)
-320 (.6)
-400 (.4)
.74 .82 .83 .56 .73 .6
27
-20 (.5)
-770 (.5)
-320 (.5)
-400 (.5)
.57 .71 .74 .51 .68 .54
28
-20 (.4)
-770 (.6)
-320 (.4)
-400 (.6)
.51 .54 .57 .37 .55 .38
29
-20 (.3)
-770 (.7)
-320 (.3)
-400 (.7)
.2 .35 .38 .29 .42 .31
30
-20 (.2)
-770 (.8)
-320 (.2)
-400 (.8)
.16 .23 .23 .17 .32 .19
31
-20 (.1)
-770 (.9)
-320 (.1)
-400 (.9)
.1 .11 .11 .1 .23 .14
32
--
-770 (1)
--
-400 (1)
0
.02 .03
0
.04 .03
33
0 (1)
--
50 (.5)
-100 (.5)
.76 .72 .71 .73 .7 .75
34
0 (1)
--
100 (.5)
-100 (.5)
.64 .61 .59 .62 .57 .65
35
0 (1)
--
150 (.5)
-100 (.5)
.47 .5 .47 .53 .51 .58
36
0 (1)
--
200 (.5)
-100 (.5)
.38 .41 .38 .5 .47 .54
37
0 (1)
--
220 (.5)
-100 (.5)
.31 .42 .39 .53 .43 .49
38
0 (1)
--
240 (.5)
-100 (.5)
.33 .38 .35 .44 .4 .49
39
0 (1)
--
300 (.5)
-100 (.5)
.26 .32 .28 .41 .4 .51


Within both description and experience, bold indicates better performance for a given model and choice problem. AH = high payoff for gamble A; BH = high payoff for gamble
86
380 (.91)
-730 (.09)
540 (.94)
-820 (.06)
.08 .12 .11 .2 .28 .34
87
930 (.35)
-850 (.65)
980 (.21)
-700 (.79)
.72 .77 .79 .44 .52 .52
88
230 (.87)
-390 (.13)
520 (.63)
-80 (.37)
.19 .15 .17 .25 .26 .24
89
710 (.5)
-260 (.5)
960 (.61)
-670 (.39)
.7 .52 .46 .58 .52 .56
90
140 (.98)
-690 (.02)
630 (.57)
-470 (.43)
.76 .74 .76 .74 .74 .68
91
80 (.3)
-370 (.7)
190 (.61)
-700 (.39)
.35 .23 .19 .53 .42 .51
92
150 (.53)
-730 (.47)
810 (.41)
-1000 (.59)
.63 .49 .45 .49 .45 .5
93
160 (.11)
-480 (.89)
960 (.08)
-730 (.92)
.82 .77 .76 .68 .63 .66
94
260 (.36)
-480 (.64)
270 (.11)
-310 (.89)
.67 .72 .76 .55 .64 .57
95
80 (.8)
-880 (.2)
830 (.14)
-390 (.86)
.74 .67 .71 .5 .56 .5
96
750 (.67)
-70 (.33)
770 (.74)
-230 (.26)
.81 .58 .55 .8 .61 .65
97
90 (.27)
-670 (.73)
280 (.09)
-330 (.91)
.19 .15 .18 .1 .27 .19
98
960 (.87)
-890 (.13)
750 (.93)
-900 (.07)
.48 .42 .43 .68 .58 .57
99
740 (.68)
-20 (.32)
670 (.99)
-30 (.01)
.03 .07 .06 .19 .15 .15
100
960 (.6)
-400 (.4)
580 (.48)
-50 (.52)
.3 .47 .52 .33 .41 .29
101
990 (.52)
-130 (.48)
950 (.93)
-550 (.07)
.18 .08 .05 .3
.3 .29
102
460 (.32)
-890 (.68)
300 (.03)
-510 (.97)
.79 .84 .89 .62 .77 .62
103
310 (.4)
-390 (.6)
820 (.14)
-260 (.86)
.58 .5 .55 .5 .49 .47
104
140 (.2)
-860 (.8)
880 (.12)
-900 (.88)
.38 .48 .49 .51 .44 .47
105
830 (.12)
-690 (.88)
450 (.13)
-780 (.87)
.94 .8 .78 .81 .69 .67
106
840 (.51)
-600 (.49)
170 (.96)
-480 (.04)
.12 .15 .13 .21 .26 .24
107
0 (1)
--
100 (.5)
-100 (.5)
.6
.6 .58 .58 .59 .65
108
100 (1)
--
200 (.5)
0 (.5)
.88 .66 .68 .77 .64 .62
109
0 (1)
--
200 (.5)
-200 (.5)
.62 .67 .64 .57 .59 .66
110*
200 (1)
--
400 (.5)
0 (.5)
.96 .73 .74 .86 .68 .66
111
40 (1)
--
140 (.5)
-60 (.5)
.83 .78 .79 .86 .75 .79
112*
140 (1)
--
240 (.5)
40 (.5)
.83 .56 .56 .72 .55 .49
113
20 (.5)
-20 (.5)
100 (.5)
-100 (.5)
.56 .61 .58 .5 .54 .59
114
120 (.5)
80 (.5)
200 (.5)
0 (.5)
.87 .65 .66 .8 .67 .74


It is worth noting that this moderation of the description-experience gap by reduced versus non-reduced gambles was not calculated using CPT probability weighting. Instead, it was calculated using a heuristic method and therefore relies on all of the assumptions about learning/memory outlined in the following section.


For modeling empirical data, we conducted a sensitivity analysis by testing the classic probability weighting function of CPT (i.e. including the 1/ exponent on the denominator). Results were consistent with the original parameterization, but we report the symmetric version here due to the more simplistic interpretation. We additionally tested a model including probability elevation parameters for gains and losses, which did not substantially improve model fit. Therefore, we relegate discussion of models with probability elevation to the Supplementary Text for brevity.


< l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " > ( n u l l ) < / l a t e x i t >


Effects of asymmetric learning on and are shown inSupplementary Fig.'s S1 and S2.














Challenges and promises for translating computational tools into clinical practice. Current Opinion in Behavioral Sciences




W.-Y
Ahn






J
R
Busemeyer




10.1016/j.cobeha.2016.02.001






11














Comparison of decision learning models using the generalization criterion method




W.-Y
Ahn






J
Busemeyer






E.-J
Wagenmakers






J
Stout




10.1080/03640210802352992






Cognitive Science




32
















Revealing neurocomputational mechanisms of reinforcement learning and decision-making with the hBayesDM package




W.-Y
Ahn






N
Haines






L
Zhang




10.1162/CPSY_a_00002






Computational Psychiatry




1
















Emotionbased reinforcement learning




W.-Y
Ahn






O
Rass






Y.-W
Shin






J
Busemeyer






J
Brown






B
Donnell








Proceedings of the 34th Annual Conference of the Cognitive Science Society


the 34th Annual Conference of the Cognitive Science Society


















Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users




W.-Y
Ahn






G
Vasilev






S.-H
Lee






J
R
Busemeyer






J
K
Kruschke






A
Bechara






J
Vassileva




10.3389/fpsyg.2014.00849






Frontiers in Psychology




5


1376














Small feedback-based decisions and their limited correspondence to description-based decisions




G
Barron






I
Erev




10.1002/bdm.443






Journal of Behavioral Decision Making




16
















Open your eyes for prediction errors




S
Braem






E
Coenen






K
Bombeke






M
E
Van Bochove






W
Notebaert








Cognitive, Affective, & Behavioral Neuroscience




15
















Decision making under uncertainty: A comparison of simple scalability, fixed-sample, and sequential-sampling models




J
R
Busemeyer




10.1037/0278-7393.11.3.538






Journal of Experimental Psychology: Learning, Memory, and Cognition




11
















An adaptive approach to human decision making: Learning theory, decision theory, and human performance




J
R
Busemeyer






I
J
Myung




10.1037/0096-3445.121.2.177






Journal of Experimental Psychology: General




121
















A contribution of cognitive decision models to clinical assessment: Decomposing performance on the Bechara gambling task




J
R
Busemeyer






J
C
Stout




10.1037/1040-3590.14.3.253






Psychological Assessment




14


253262














The role of representation in experience-based choice




A
R
Camilleri






R
Ben






Newell








Judgement and Decision Making




4
















When and why rare events are underweighted: A direct comparison of the sampling, partial feedback, full feedback and description choice paradigms




A
R
Camilleri






R
Ben






Newell




10.3758/s13423-010-0040-2






Psychonomic Bulletin & Review




18
















Neural and psychological maturation of decision-making in adolescence and young adulthood




A
Christakou






S
J
Gershman






Y
Niv






A
Simmons






M
Brammer






K
Rubia




10.1162/jocn_a_00447






Journal of Cognitive Neuroscience




25
















Social signals of safety and risk confer utility and have asymmetric effects on observers' choices




D
Chung






G
I
Christopoulos






B
King-Casas






S
B
Ball






P
H
Chiu




10.1038/nn.4022






Nature Neuroscience




18


















S
M L
Cox






M
J
Frank






K
Larcher






L
K
Fellows






C
A
Clark






M
Leyton






A
Dagher




10.1016/j.neuroimage.2014.12.070






Striatal D1 and D2 signaling differentially predict learning from positive and negative outcomes






109














Opponent interactions between serotonin and dopamine




N
D
Daw






S
Kakade






P
Dayan




10.1016/S0893-6080(02)00052-7






Neural Networks




15
















Instructional control of reinforcement learning: A behavioral and neurocomputational investigation




B
B
Doll






W
J
Jacobs






A
G
Sanfey






M
J
Frank




10.1016/j.brainres.2009.07.007






Brain Research




1299
















Mood as representation of momentum




E
Eldar






R
B
Rutledge






R
J
Dolan






Y
Niv




10.1016/j.tics.2015.07.010






Trends in Cognitive Sciences




20
















Predicting how people play games: Reinforcement learning in experimental games with unique, mixed strategy equilibria




I
Erev






A
E
Roth




10.2307/117009






The American Economic Review




88


4
















A choice prediction competition: Choices from experience and from description




I
Erev






E
Ert






A
E
Roth






E
Haruvy






S
M
Herzog






R
Hau




10.1002/bdm.683






Journal of Behavioral Decision Making




23
















The cognitive side of probability learning




W
K
Estes




10.1037/0033-295X.83.1.37






Psychological Review




83
















The neural bases of emotion regulation




A
Etkin






C
Büchel






J
J
Gross




10.1038/nrn4044






Nature Reviews Neuroscience




16
















Decisions from experience"= sampling error+ prospect theory: Reconsidering Hertwig




C
R
Fox






L
Hadar








Judgement and Decision Making




1






Weber & Erev












Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning




M
J
Frank






A
A
Moustafa






H
M
Haughey






T
Curran






K
E
Hutchison




10.1073/pnas.0706111104






Proceedings of the National Academy of Sciences




104
















By carrot or by stick: Cognitive reinforcement learning in Parkinsonism




M
J
Frank






L
C
Seeberger






R
C
Reilly




10.1126/science.1102941






Science




306
















Understanding variability in binary and continuous choice




D
Friedman






D
W
Massaro




10.3758/BF03208814






Psychonomic Bulletin & Review




5
















The utility analysis of choices involving risk




M
Friedman






L
J
Savage




10.1086/256692






Journal of Political Economy




56
















Inference from iterative simulation using multiple sequences




A
Gelman






D
B
Rubin




10.2307/2246093






Statistical Science




7
















Type S error rates for classical and Bayesian single and multiple comparison procedures




A
Gelman






F
Tuerlinckx








Computational Statistics




15
















Do learning rates adapt to the distribution of rewards?




S
J
Gershman




10.3758/s13423-014-0790-3






Psychonomic Bulletin & Review




22
















The reversed descriptionexperience gap: Disentangling sources of presentation format effects in risky choice




A
Glöckner






B
E
Hilbig






F
Henninger






S
Fiedler




10.1037/a0040103






Journal of Experimental Psychology: General




145
















Expression theory and the preference reversal phenomena




W
M
Goldstein






H
J
Einhorn




10.1037/0033-295X.94.2.236






Psychological Review




94
















Effects of emotional valence and arousal on recollective and nonrecollective recall




C
F A
Gomes






C
J
Brainerd






L
M
Stein




10.1037/a0028578






Journal of Experimental Psychology: Learning, Memory, and Cognition




39
















The boundaries of Instance-based Learning Theory for explaining decisions from experience




C
Gonzalez




10.1016/B978-0-444-62604-2.00005-8






Progress in Brain Research


V. S. Pammi, & N. Srinivasan


Amsterdam




Elsevier




202














A loser can be a winner: Comparison of two instance-based learning models in a market entry competition




C
Gonzalez






V
Dutt






T
Lejarraga




10.3390/g2010136






Games




2
















On the Shape of the Probability Weighting Function




R
Gonzalez






G
Wu




10.1006/cogp.1998.0710






Cognitive Psychology




38
















Regret induces rapid learning from experience-based decisions: A model-based facial expression analysis approach. bioRxiv




N
Haines






O
Rass






Y.-W
Shin






J
R
Busemeyer






J
W
Brown






B
F
O'donnell






W.-Y
Ahn




10.1101/560011






560011












The Outcome-Representation Learning model: A novel reinforcement learning model of the Iowa Gambling Task




N
Haines






J
Vassileva






W.-Y
Ahn




10.1111/cogs.12688






Cognitive Science




47
















Decisions from experience and statistical probabilities: Why they trigger different choices than a priori probabilities




R
Hau






T
J
Pleskac






R
Hertwig




10.1002/bdm.665






Journal of Behavioral Decision Making




23
















The description-experience gap in risky choice: the role of sample size and experienced probabilities




R
Hau






T
J
Pleskac






J
Kiefer






R
Hertwig




10.1002/bdm.598






Journal of Behavioral Decision Making




21
















The description-experience gap in risky choice




R
Hertwig






I
Erev




10.1016/j.tics.2009.09.004






Trends in Cognitive Sciences




13
















Decisions from experience and the effect of rare events in risky choice




R
Hertwig






G
Barron






E
U
Weber






I
Erev




10.1111/j.0956-7976.2004.00715.x






Psychological Science




15
















Prospect Theory: An analysis of decision under risk




D
Kahneman






A
Tversky




10.2307/1914185






Econometrica




47
















Subjectively weighted utility: A descriptive extension of the expected utility model




U
S
Karmarkar




10.1016/0030-5073(78






Organizational Behavior and Human Performance




21
















How (in)variant are subjective representations of described and experienced risk and rewards? Cognition




D
Kellen






T
Pachur






R
Hertwig




10.1016/j.cognition.2016.08.020






157














Violation of utility theory in unique and repeated gambles




G
Keren






W
A
Wagenaar




10.1037/0278-7393.13.3.387






Journal of Experimental Psychology: Learning, Memory, and Cognition




13
















The role of information search and its influence on risk preferences




O
Kopsacheilis








Theory and Decision




84


3
















Pupil dilation signals uncertainty and surprise in a learning gambling task




C
Lavín






R
San Martín






E
Rosales Jubal








Frontiers in Behavioral Neuroscience




7


218














Decisions from experience: From monetary to medical gambles




T
Lejarraga






T
Pachur






R
Frey






R
Hertwig




10.1002/bdm.1877






Journal of Behavioral Decision Making




29
















Judged frequency of lethal events




S
Lichtenstein






P
Slovic






B
Fischhoff






M
Layman






B
Combs




10.1037/0278-7393.4.6.551






Journal of Experimental Psychology: Human Learning and Memory




4
















Dispositional anxiety and risk-avoidant decision-making




J
K
Maner






J
A
Richey






K
Cromer






M
Mallott






C
W
Lejuez






T
E
Joiner






N
B
Schmidt




10.1016/j.paid.2006.08.016






Personality and Individual Differences




42
















Do adolescents always take more risks than adults? A within-subjects developmental study of context effects on decision making and processing




G
M
Rosenbaum






V
Venkatraman






L
Steinberg






J
M
Chein








PLOS One




16


8


255102














Prospect theory and the "forgotten" fourfold pattern of risk preferences




M
Scholten






D
Read








Journal of Risk and Uncertainty




48


1
















Detecting Strategies in Developmental Psychology




H
Steingroever






M
Jepma






M
D
Lee






B
R J
Jansen






H
M
Huizenga




10.1007/s42113-019-0024-x






Computational Brain & Behavior




113
















Cumulative prospect theory's functional menagerie




H
P
Stott




10.1007/s11166-006-8289-6






Journal of Risk and Uncertainty




32
















Toward a common representational framework for adaptation




B
M
Turner




10.1037/rev0000148






Psychological Review




126
















Advances in prospect theory: Cumulative representation of uncertainty




A
Tversky






D
Kahneman




10.1007/BF00122574






Journal of Risk and Uncertainty




5
















Are probabilities overweighted or underweighted when rare outcomes are experienced (rarely)?




C
Ungemach






N
Chater






N
Stewart




10.1111/j.1467-9280.2009.02319.x






Psychological Science




20
















Practical Bayesian model evaluation using leaveone-out cross-validation and WAIC




A
Vehtari






A
Gelman






J
Gabry




10.1007/s11222-016-9696-4






Statistics and Computing




27
















Predicting risk sensitivity in humans and lower animals: Risk as variance or coefficient of variation




E
U
Weber






S
Shafir






A.-R
Blais




10.1037/0033-295X.111.2.430






Psychological Review




111
















Older adults as adaptive decision makers: Evidence from the Iowa Gambling Task




S
Wood






J
Busemeyer






A
Koling






C
R
Cox






H
Davis




10.1037/0882-7974.20.2.220






Psychology and Aging




20
















Adaptive exploration: What you see is up to you




D
Wulff






D
Markant






T
J
Pleskac






R
Hertwig








The Center for Adaptive Rationality, Taming Uncertainty


R. Hertwig, T. J. Pleskac, T. Pachur


Cambridge, MA




MIT Press














A meta-analytic review of two modes of learning and the description-experience gap




D
U
Wulff






M
Mergenthaler-Canseco






R
Hertwig




10.1037/bul0000115






Psychological Bulletin




144
















Using cognitive models to map relations between neuropsychological disorders and human decision-making deficits




E
Yechiam






J
R
Busemeyer






J
C
Stout






A
Bechara




10.1111/j.1467-9280.2005.01646.x






Psychological Science




16
















Frequency processing: A twenty-five year perspective




R
T
Zacks






L
Hasher


















ETC. Frequency Processing and Cognition


Sedlmeier & T. Betsch
















72) -830 (.28) -150 (.16) -670 (.84) .31 .16 .18 .26 .28




N
Y
York






Us




10.1093/acprof:oso/9780198508632.003.00020(1)--400(.5)-100(.5).23.22.18.37.25.3613.12.14.16.17621000(.85)20(.15)650(.32)410(.68).74.78.79.68.67


03 .04 .04 .05 .06 .03 69 -480 (.28) -740 (.72) -150 (.48) -910 (.52) .29 .12 .13 .33 .18 .28 70 -520 (.8) -930 (.2) -260 (.47) -930 (.53) .62 .32 .34 .36 .36 .4




Oxford University Press


58


460












17) -690 (.83) -380 (.37) -960 (.63) .82 .91 .89 .8 .83


24) -570 (.76) -350 (.39) -720 (.61) .94 .77 .74 .84 .7 .73 82 -340 (.23) -480 (.77) -260 (.51) -760 (.49) .68 .68 .65 .65 .67 .72 83 -420 (.17) -700 (.83) -540 (.27) -730 (.73) .79 .63 .61 .71 .63 .62 84 -340 (.22) -970 (.78) -660 (.49) -920 (.51) .52 .58 .57 .59 .6 .54 85 240 (.73) -830 (.27) 630 (.57) -910 (.43) .72 .56 .55 .41 .46 .47




53








07) -420 (.93) -80 (.66) -950 (.34) .4 .3 .27 .43 .4 .








Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users




W.-Y
Ahn






G
Vasilev






S.-H
Lee






J
R
Busemeyer






J
K
Kruschke






A
Bechara






J
Vassileva




doi:1.3389/fpsyg.2014.00849






Frontiers in Psychology




5


1376














Loss aversion, diminishing sensitivity, and the effect of experience on repeated decisions




I
Erev






E
Ert






E
Yechiam




doi:1.1002/bdm.602






Journal of Behavioral Decision Making




21
















Inference from iterative simulation using multiple sequences




A
Gelman






D
B
Rubin




doi:1.2307/2246093






Statistical Science




7
















Do learning rates adapt to the distribution of rewards?




S
J
Gershman




doi:1.3758/s13423-014-0790-3






Psychonomic Bulletin & Review




22


















M
F
Molloy






R
J
Romeu






P
D
Kvam






P
R
Finn






J
R
Busemeyer






B
M
Turner




Hierarchies improve individual assessment of temporal discounting behavior. Decision






7














Structural Parameter Interdependencies in Computational Models of Cognition




A
Krefeld-Schwalb






T
Pachur






B
Scheibehenne








Psychological Review




129
















Advances in prospect theory: Cumulative representation of uncertainty




A
Tversky






D
Kahneman




doi:1.1007/BF00122574






Journal of Risk and Uncertainty




5

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]