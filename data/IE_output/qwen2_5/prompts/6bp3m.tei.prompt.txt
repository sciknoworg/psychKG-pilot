You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



How do we make choices in the face of cognitive load? Imagine the stock-market trader faced with multiple computer screens displaying slow fluctuations of several stocks. Before deciding what to buy and sell, the trader needs to monitor what value is produced by what stock, and in so doing needs to integrate the conjunction of various stimulus features -e.g., the stock's name, value and position on the screen. Encoding the conjunction of various features for each stock requires multiple mental operations that place demands on the stock-trader's limited cognitive capacity. We assume that each mental operation introduces processing noise into the decision processi.e., choice problems that require multiple mental operations to form a decision should introduce more noise than choice problems that require fewer mental operations.
We base our predictions about the effects of processing noise in risky choice on findings from previous work, where extreme outcomes (from the edges of a distribution) often appear to have a greater impact on choice than inliers 
(Lieder, Griffiths & Hsu, 2018;
Ludvig, Madan, McMillan, Xu & Spetch, 2018;
). These effects appear to manifest when challenges to cognitive capacity are imposed, and are attributable to extreme-outcomes being more likely to attract attention under those challenges 
(Glickman, Tsetsos & Usher, 2018;
Kunar, Watson, Tsetsos & Chater, 2017;
Tsetsos, Chater & Usher, 2012;
Vanunu, Hotaling, Le Pelley & Newell, 2021;
Vanunu, Hotaling & Newell, 2020)
. For example, when participants were asked to rate their liking of slot-machines, displayed as sequences of possible outcomes, they seemed to give higher ratings to high-variance machines when four sequences were displayed together (intermittently at each corner of the screen) than displayed individually, which indicates a risk-seeking behavior 
(Vanunu, Pachur & Usher, 2019
; see also 
Erev, Ert, Plonsky & Cohen, 2017;
Hills, Noguchi & Gibbert, 2013)
. These results imply that extreme outcomes were prioritized in choices when more mental operations were required. In the individual display, participants had to encode the outcome values alone and in the intermixed display they had to encode both value and position on screen.
In risky choices, the attraction to high extreme-outcomes is intuitive because when it is difficult to encode all relevant information, high extremes represent "the best" possible 'wins' in the experimental environment 
(Vanunu et al., 2020
; see also 
Payne, Bettman & Johnson, 1993)
. However, a similar mechanism was also found in perceptual tasks in which participants were required to estimate the averages of numerical sets 
(Rosenbaum, de Gardelle & Usher, 2021;
Tsetsos et al., 2012;
Vanunu et al., 2020)
. For example, Spitzer, Waschke and Summerfield (2017) asked participants to determine which numerical sequence had a greater average. On each trial, two sequences in two different colors were interwoven into a single display at the center of the screen. Hence, participants were required to encode the conjunction of value and color of stimuli to form a decision. To account for choice, the authors presented a simple model in which the sequences' averages in each color were compared. However, prior to calculating the averages, each value was transformed with an exponential function that gives more (less) weight to larger values if the exponent was larger (smaller) than 1. Findings from modeling and a simulation analysis suggested that larger values were often assigned with larger weights, and in doing so, one could overcome processing noise when identifying which sequence has a higher average. In a follow-up study, a simpler version of the task, in which participants had to estimate whether the average of the sequence across colors was larger than a reference value, was compared to the complex version described above 
(Clarmann von Clarenau, Pachur & Spitzer, 2022)
. Findings from a similar analysis showed that larger values were overweighted in the complex version but underweighted in the simpler version. This pattern supports the notion that people assign greater weight to larger values in complex choice environments. Consequently in risky choices, it seems that allocating more attention to larger values is not only consistent with the goal of winning the best rewards 
(Vanunu et al, 2020)
, but it could also serve as an optimal strategy to overcome processing noise when evaluating the expected values (i.e., averages) of slot-machines.
The examples above focused mostly on manipulating the number of outcomes to monitor, in the current work we take a different approach, by keeping the number of options constant but varying their screen-location in an attempt to increase processing noise.
Specifically, we adapt a two-armed bandit task, in which participants are asked to play a "Safer" or a "Riskier" slot-machine. To manipulate risk, the machines generated outcomes from low-variance (Safer) or high-variance (Riskier) distributions, respectively. 
Figure 1A
 shows how we manipulated processing noise. One group of participants received full feedback of outcomes from both machines (i.e., the chosen and the forgone options) in either the Congruent locations to the machines, the Incongruent locations to the machines, or Mixed between congruent and incongruent locations across plays. The correspondence of each outcome to its respective machine was marked by its matching colour ( 
Figure 1A
). The experiment began with a block of trials of the simplest condition assumed from a processing noise perspective (Congruent), followed by one of assumed intermediate difficulty 
(Incongruent)
 and ended with the one we assumed to be hardest (Mixed).
We predicted that monitoring which machine produced the respective outcome would be challenging if the locations of the outcomes did not match the locations of the machines.
Specifically, in the Incongruent and Mixed conditions the outcome's location on the screen would no longer always be indicative of its source, encouraging the participants to adapt and to focus on other differentiating features like stimulus-colour. Hence, to determine the goodness of each machine, participants have to encode the conjunction of the outcomes' value and colour while ignoring their locations -a procedure that should require more mental operations than encoding the conjunction of value and location alone (i.e., the Congruent condition). Consequently, we predicted that with changes in the feedback's congruency, people would invest more resources to encode goal-relevant itemsthe high-extreme outcomeswhich might induce participants to choose the Riskier machine more often. To control for simple practice effects, a second group of participants followed a similar procedure but with full-feedback in the Congruent locations across all three blocks. In the following, we will refer to the first group of participants as the Congruent-Incongruent-Mixed group (C-I-M group), and to the second group as the Congruent-Congruent-Congruent group (C-C-C group).


Method


Transparency and openness
Ethical approval for the experiment was obtained through the institutional review boards of the School of Psychology at the University of New South Wales (UNSW). Informed consent was provided by all participants. The data that support the findings and the R code used to analyze this data are available. The power of the current design to find significant effects was estimated using the simr package in R 
(Green & MacLeod, 2016)
. This study was not preregistered.
Participants. Eighty-one first-year students from the University of New South Wales participated in either the C-I-M or the C-C-C condition, (68 females, age: 17-29 years, M = 19.31, SD=2.27), in exchange for course credit and an incentivization bonus. Normal colour vision was set as an eligibility requirement. Initially, 41 participants were recruited for the C-I-M group. Later, we recruited an additional group of 40 participants for the C-C-C condition.
The sample size was set to exceed the sample sizes in similar previous studies 
(Vanunu et. al., 2019)
. Block (First, Second and Third; within-subjects) and Mean-differences (Below, Above and Approximately equal; within-subjects) referring to the differences in the mean payoffs between the Riskier and Safer machine (i.e., Below is when the mean of the riskier machine is lower than the mean of the safer machine).
Slot-machine properties: Three values were drawn randomly from a uniform distribution, U(50,60), and were set as the means for the Safer machines (μSafer), one for each experimental block. For each round, two sets of twenty numbers (ranged 10-99) were drawn from one of four Gaussian distributions ( 
Figure 1B)
. Numbers for the Safer machine were drawn from a low-variance distribution (SD=5) with a fixed mean (μSafer). Numbers for the Riskier machine were drawn from high-variance distributions (SD=15), with means set to be either Below (μRiskier=μSafer -7), Above (μRiskier=μSafer +7) or Approximately equal (-1≤μRiskier-μSafer≤1) to the mean of the Safer machine. The number of rounds in a block was equally divided among the three conditions of Mean-differences. The two slot-machines were presented as blue and red squares, with colour randomly assigned between rounds. The outcomes were displayed in the matching colours of their respective machines (e.g., blue machine produced blue outcomes; 
Figure 1A
). Finally, the position of the two machines on the choice screen (i.e. left or right) was randomized within rounds, but their colour was consistent. Procedure. For both the C-I-M and C-C-C groups, the experiment was divided into three blocks. Each block contained fifteen rounds. In each round, participants were asked to choose between one of the two slot-machines displayed on screen with no time-constraints imposed on choice (i.e., self-paced); they did this 20 times per round (total trials of 3×15×20=900). They were informed that each play granted them a reward in AUD, and after twenty plays, a new round would start with different slot-machines. Critically, participants were told that on each round there is one machine that often produces larger rewards than the other (but they were not told which one). Finally, participants were told that at the end of the experiment, a random play would be selected by the computer, and 10% of this play's outcome would be granted to them as a reward in AUD. Following the instructions, participants completed two practice rounds with twenty plays each.
In the C-I-M condition, two new slot-machines were displayed on each round, and participants were asked to play one of the machines by clicking it with the mouse. Following their decision, full-feedback of the outcomes from both machines appeared inside the colored squares for 1 second ( 
Figure 1A
). In the First block, the outcomes appeared in the Congruent locations to the machines; in the Second block it appeared on the Incongruent locations to the machines (i.e., the opposite locations); and in the Third block the locations of the outcomes were Mixed randomly across plays. The number of remaining plays within a round was displayed on the top-left corner of the screen. The procedure in the C-C-C group was identical to the C-I-M group, except that in all three blocks, full-feedback of the outcomes appeared in the Congruent locations on every play.
Power analyses. There is no agreed-upon analytic solution for calculating effect sizes in mixed-effects models. Therefore, we used a simulation to estimate the power of the current design and statistical models to find significant effects among the conditions (simr package in R; 
Green & MacLeod, 2016)
. Across a hundred simulations, we found 100% power to find an interaction effect between Block and Mean difference in the C-I-M group (i.e., improved performance with increasing processing noise); and 94% power to find a three-way interaction among all variables.


Results
The first part of the analysis focused on the proportion of choice for the Riskier option within each round (i.e., p[Riskier]), separately for conditions ( 
Figure 2)
. We analysed the data using a mixed-effects probit regression model with p(Riskier) as the dependent variable; Feedback group, Block and Mean-differences as fixed factors; and Participant-ID as random intercepts.
There was a main effect for Mean-differences (χ 2 (2)=4313.60, p<.001), indicating that participants chose more often the machine with the greater mean across blocks and groups (MR<S=.35, SD=.12; MR≈S=.52, SD=.06; MR>S=.65, SD=.11). Furthermore, we found two-way interactions between Feedback group and Mean-differences (χ 2 (2)=184.25, p<.001) and Block and Mean-differences (χ 2 (4)=14.27, p<.01), and a three-way interaction among all three variables (χ 2 (4)=20.23, p<.001). Importantly, a significant interaction between Block and Mean-differences in the C-I-M group (χ 2 (4)=32.46, p<.001) suggested that as the congruency between the choice and the feedback screens changed from congruent to incongruent to mixed, participants were more likely to avoid the Riskier option if its mean was lower than the Safer option (χ 2 (2)=23.77, p<.001; leftmost bars, left panel 
Figure 2
), but to prefer the Riskier option if its mean was higher than the Safer option (χ 2 (2)=13.17, p<.01; rightmost bars, left panel 
Figure 2
). In contrast, a non-significant interaction in the C-C-C group suggested that participants showed similar levels of preference for the riskier and safer options across all three Congruent blocks (χ 2 (4)=2.01, p=.733; 
Figure 2
, right panel).
These findings are consistent with the notion that participants assign greater weight to larger outcomes as processing noise increases. Specifically, when the Riskier option was superior (Safer<Riskier), high extreme-outcomes from the Riskier machine (e.g., '83') had a greater impact on choice than mid-range outcomes from the Safer machine. This impact was exacerbated when the locations of the outcomes did not match with the machines -increasing p(Risky) as processing noise increased. However, when the Riskier option was inferior (Safer>Riskier), mid-range outcomes from the Safer machine attracted more attention than low-extreme outcomes from the Riskier machine (e.g., '15') -decreasing p(Risky) as processing noise increased (see the example in the Modelling section for additional details).
The fact that in the C-C-C group we found similar choice patterns across blocks speaks against a simple practice effect being the cause of the differentiation seen in the C-I-M group. The second part of the analysis focused on participants' performance by calculating the proportion of choices for the machine with the higher mean, and using it as the dependent variable in the mixed effects probit model. We excluded trials in which Mean-differences were approximately equal (i.e., less than one) because this condition was designed to make it difficult for participants to discern the superior option, thus their inclusion introduces noise and impacts the possibility of seeing an effect of Feedback group and Block on the trials with a clear difference between means. The results indicate a main effect of Feedback group (χ 2 (1)=5.85, p=.016) and Block (χ 2 (2)=14.57, p<.001), and a two-way interaction between both (χ 2 (2)=18.62, p<.001). Hence, suggesting that participants in the C-I-M group improved with Blocks (MCon.=.66, SD=.14; MInc.=.68, SD=.13; MMix=.70, SD=.13; χ 2 (2)=33.12, p<.001), but the C-C-C group did not (M1st=.62, SD=.12; M2nd=.62, SD=.11; M3rd=.62, SD=.13; χ 2 (2)=0.08, p=.963). Finally, a three-way interaction among all variables (χ 2 (2)=8.17, p=.017) suggests that the increased performance across blocks in the C-I-M group was more prominent when the Riskier machine was superior than when the Safer machine was superior, whilst differences among Blocks and Mean-difference conditions were minor in the C-C-C group. It is important to note that we found no significant differences between the First blocks in each group (i.e. with Congruent feedback; χ 2 (1)=1.78, p=.182), ruling out the possibility of differences in baseline performance between groups.
Taken together, these analyses suggest that when it was presumably difficult to assign outcomes to their respective machines, participants seemed to focus on information that is consistent with their goal of winning the best outcomethe largest rewards. As a result, participants improved their performance in the task by taking more risks when the expected value of the Riskier machine was larger than the safer one, but fewer risks when the expected value of the Riskier machine was lower.


Computational modelling
A sensible next question to ask is how participants manage to differentiate between the goodness of the machines under increasing processing noise. One possibility is that they learn to prioritize larger, more desirable outcomes. A candidate computational mechanism that can reflect this increased attention is a convex exponential weighting function that gives greater weight to larger outcomes 
(Clarmann von Clarenau et al., 2022;
Spitzer et al., 2017;
Vanunu et al., 2019)
. This type of function is based on the common idea that attention amplifies value 
(Krajbich, Armel & Rangel, 2010;
Smith & Krajbich, 2019)
, and by doing so, it polarizes the difference between the machines' expected values (i.e., the average reward). As a result, evidence for the superiority of one machine over the other increases. Further, previous research suggested that attention to outcome-feedback diverges between the chosen and forgone options 
(Ashby & Rakow, 2015)
. Therefore, the current model applies two separate exponent functions for the chosen and forgone options.
We contrast the account of selective-attention to larger outcomes with the idea that imposing higher demands on processing simply encouraged some of the participants to be more engaged in the task, thus leading to the observed performance improvements. We assume that general engagement should be captured by an even distribution of attention and increased sensitivity to evidence, implemented by a linear amplification of the attention paid to all types of outcomes. Note that we do not assume that the exponential (or linear) weighting function is an additional mental operation people do in their heads when encoding the values, but a mathematical description of how attention is allocated among values to amplify the signal over processing noise.
According to the following model, people accumulate information for each slotmachine separately by summing the time-discounted displayed outcomes. Critically, each outcome is transformed by an exponential function to describe its weight in respect to its value (Eq. 1).
(1)
= ∑ − × =1
where V is the subjective valuation of a slot-machine and Xi is the machine's outcome for play i within a total number of plays N. The free parameters α is a weighting parameter, which ranges from 0 to 5, and describes overweighting of high extreme-outcomes for α>1 (holds for Xi≥0). The allocation of attention to feedback between the chosen and forgone options is described by two α values for each option -i.e., αc for chosen and αf for forgone. The parameter λ, which ranges from 0 to 1, applies temporal decay for λ<1 by reducing the impact of earlier outcomes on the total sum. The summed values from each accumulator are compared and transformed into choice probability for the Riskier option with the logistic function in Eq. 2:
(2) ( ) = 1 (1+ −[ ×( [ ]− [ ])] )
where V(R) and V(S) are the subjective valuations of the Riskier and the Safer slot-machines, respectively, and σ is a sensitivity parameter, which ranges from 0 to 1, determines randomness in participants' choices. Here, larger σ values indicates higher sensitivity to evidence and smaller σ values indicates more random choice. Another way to describe σ is as the ratio  
-50.4
], respectively. Thus, with an increase in α, evidence for choosing the Riskier option (i.e., Riskier-Safer) increases if its mean is larger, but decreases if its mean is smaller -i.e., polarizing the differences between the machines.


Modelling results
To estimate the parameter values, we fit the model to each participant and each block separately, using a bounded Nelder-Mead optimization routine 
(Nelder & Mead, 1965)
, implemented in Matlab's fminsearch function. The model's predictions are displayed by asterisks in 
Figure 2
, showing high similarity to the behavioural data. Moreover, a model
comparison analysis for the current model with nested models and alternative mechanisms revealed that the current model produced the best account for the data across all comparisons.
Finally, a parameter recovery analysis showed strong correlations between the original and the recovered parameters. For a full report of the model comparison analysis and the parameter recovery analysis see sections A1 and A2 in the Appendix.
The average parameter values and the proportion of participants that exhibited a convex exponent weighting function (e.g., p[αc>1]) among blocks and groups are presented in 
Table   1
. To test the difference in α values among the conditions, we tested a linear mixed-effects model with Feedback group, Block and Option -i.e., attention to chosen (αc) or forgone (αf) options -as fixed factors, and Participant-ID as random intercepts. A significant interaction effect between Feedback group and Block (χ 2 (1)=5.34, p=.021) suggested that mean α values in the C-I-M group increased with Block (χ 2 (1)=8.70, p=.003) towards a convex exponential weighting (i.e., α>1), while this trend was absent in the C-C-C group (χ 2 (1)=0.10, p=.749). In addition, p(αc>1) and p(αf>1) clearly increased with Block in the C-I-M group, but showed small or no change across blocks in the C-C-C group. These results thus support a qualitative change in the number of participants in the C-I-M group that were best described by a convex exponential weighting function as processing noise increased -capturing the increased performance, on average, across blocks in the C-I-M group. Curiously, we did not find a significant difference between the two exponent functions (χ 2 (1)=0.82, p=.366), nor an interaction with Feedback Group (χ 2 (1)=0.26, p=.609) or Block (χ 2 (1)=0.03, p=.861).
Nevertheless, including two exponent functions in the model improved the fit significantly in comparison to nested models with a single or no exponent functions (see model comparisons in the Appendix).
For σ mean values, a similar linear mixed effect model indicated no differences across all conditions. This finding was mirrored at the individual level, with approximately half of the participants in the C-I-M group (51%) and in the C-C-C group (50%) showing larger σ values in the third block compared with the first block, and the rest showing the opposite trend. These results speak against the possibility that participants got better at the task due to practice.
Furthermore, these null results also imply that even if participants in the C-I-M group were more engaged in the task in response to higher demands, it was not sufficient to overcome the increase in processing noise across blocks. Finally, a linear mixed-effects model for differences in lambda values produced null results across all conditions; although including the decay function in the model improved the fit significantly (see model comparisons in the Appendix). These results suggest that later outcomes in the sequence had a larger impact on choice than earlier outcomes, but the patterns of increased performance in the C-I-M data could not be explained by a systematic change in the decay function with increased processing noise. 


Discussion
The current study examined how people might adapt to increases in processing noise in a riskychoice task. Participants in the Congruent-Incongruent-Mixed group made better choices as processing noise increased with Blocks -choosing to play the machine with the greater longrun average more often if inconsistencies between the locations of outcomes and machines were imposed. By contrast, participants in the Congruent-Congruent-Congruent group showed no significant differences in risky choice among blocks, ruling out the possibility that people improved in the task due to practice.
These results converge with recent findings 
(Spitzer et al., 2017;
Vanunu et al., 2019;
Vanunu et al., 2020)
, and suggest that an increase in processing noise led participants to assign greater weights to high extreme-outcomes in choice. In support of this claim, a modelling analysis revealed that under higher task demands, the majority of participants made choices that are consistent with a convex exponential transformation of outcomes, which in turn polarized the differences in evidence between the two machines. Moreover, we found no evidence for the alternative account that task performance increased due to practice or engagement. We therefore infer that participants allocated more attention to larger outcomes not only because they represent the best rewards 
(Vanunu et al., 2020)
, but also as part of a strategy to differentiate between the goodness of the machines under processing noise. To illustrate with an analogy, the differentiation might be thought of as similar to how an astronomer could increase the contrast-ratio of an obscure telescope image to determine which star is brighter. If the contrast-ratio of the stars is exponentially increased, the differences between them should be polarized (i.e., the brighter star would become very bright on the dark background, but the dimmer star would become only slightly brighter).
Although surprising, this is not the first evidence in the literature for apparent improvements in performance as the demands of a task increase. For example, 
Wolford, Newman, Miller and Wig (2004)
 found that people were more likely to maximize profit under a dual-task format than a single-task format, by switching to a simpler but optimal strategy.
Interestingly, it seems that this switch was more likely to be driven by the "simplicity" of the strategy rather than its "optimality", as when constraints on executing a maximization strategy were imposed, people were less inclined to employ it under cognitive load 
(Schulze & Newell, 2016
; see also Schulze, James, Koehler & Newell, 2019 for a failure to replicate 
Wolford et al., 2004)
. In other words, it seems that people are likely to adopt a simpler mechanism in response to enforced limitations on cognitive capacity 
(Gigerenzer & Todd, 1999;
Payne et al., 1993;
Tversky & Kahneman, 1974)
, which under specific settingscould improve performance.
At odds with the current findings, similar studies have found that under a different operationalization of cognitive load, which enforces division of attention across the visualdisplay, participants chose the riskier option more often than the safer one, irrespective of the average reward 
(Tsetsos et al., 2012;
Vanunu et al., 2020)
. This tendency improved performance when the riskier option was superior, but decreased performance when it was inferior. 
Vanunu et al. (2020)
 have suggested that under conditions of divided attention, participants employ a selective-mechanism that prioritizes the highest outcomes while disregarding the lowest outcomes in choice, which induced risk seeking. By contrast, the current manipulation of screen locations should not have enforced divided attention across the display, since choice was self-paced and outcomes were displayed for longer (display-time was up to four times slower than in Tsetsos et al.'s study). Thus, our design allowed all items to be attended and processed before making a choice. Curiously, it seems that in both cases participants aimed to prioritize the highest outcomes in choice, but the execution of this mechanism was different in response to task demands. We leave it to future research to further explore the differences between the tasks and the potential cognitive mechanisms that underlie them.
What are the implications of our results for real-world experience-based decisions like stock-market trading? Here the value of a stock is directly affected by the action of trade, thus introducing further complexities and dependencies. Research on the conjunction of cognitive psychology and finance have discussed the role of attention 
(Barber & Odean, 2008;
DellaVigna & Pollet, 2009)
, learning 
(Choi, Laibson, Madrian, & Metrick, 2009;
Kuhnen, 2015;
Payzan-LeNestour & Bossaerts, 2014)
 and complexity 
(Brunnermeier & Oehmke, 2009;
 Carlin, Kogan & Lowery, 2013) on economic decisions like stock-trading (for a review see 
Frydman & Camerer, 2016)
. However, further research is required to understand how these three factors interact with each other to influence the fluctuation of stock-values. Considering the current framework, it seems that overweighting the extremes when monitoring the goodness of multiple stocks should lead to greater polarization in stock's valuations, which in turn might produce erratic fluctuations over time. Understanding this mechanism more closely could contribute to developing efficient actions to control for undesirable biases.
The aggregated loglikelihood values and AIC scores across participants are presented in 
Table A1
. A likelihood ratio test between the full and nested models showed that including two exponent functions in the model improved the fit significantly in comparison to models with one exponent function (χ 2 (3)=6374.1 , p<.001) or without an exponent function (χ 2 (6)=7163.3 , p<.001). We also found that including the decay function improved the fit significantly (χ 2 (3)=5672.9 , p<.001). Finally, the current model produced the best account for the data across all the alternative mechanisms tested.


Table A1
The aggregate loglikelihood values and AIC scores across participants for the nested and alternative models tested. N. para. Indicates the number of free parameters in each model. Models N. para. lnL AIC than the original data-set. Then, we retested the model on the synthetic data set to examine whether the resulting parameter values match with the original values. The correlation values between the original and the recovered parameters in each condition are displayed in 
Table A2,
 showing a successful recovery with a significant strong correlation across all comparisons.


Table A2
The correlation values between the original and recovered parameters in each condition. 
Materials.
The experiment had a 2×3×3 factorial design, with factors Feedback group (Congruent-Incongruent-Mixed and Congruent-Congruent-Congruent; between-subjects),


Figure 1 .
1
A) Example choice display and the full-feedback display that follows in the Congruent and Incongruent locations to the machines. The colour of the outcome corresponds to the colour of the machine that produced it. In the Congruent condition the location of the machine remained constant between the screen when the option was selected and the screen where feedback was delivered (i.e., the 48-point outcome appears in blue in the same location on the feedback screen as the blue square was on the choice screen). In the Incongruent condition the location of the machine switched between the choice screen and the feedback screen. In Mixed plays there was an equal probability on each play that the feedback screen would be Congruent or Incongruent. No time limits were imposed on executing choice. The outcomes were displayed for 1s. B) Example outcome distributions for the Safer and the Riskier machines when the Riskier machine's mean is either Below, Above or Approximately equal to the Safer machine's mean.


Figure 2 .
2
The average proportion of times participants chose the riskier option over the safer option between conditions. In both groups, the blue, orange and tan bars correspond to the First, Second and Third blocks respectively. In the C-I-M Group, the feedback-display differed in the three blockscongruent, incongruent and mixed with Block, whereas in the C-C-C group all blocks featured the Congruent feedback-display. The asterisks indicate the model's predictions for each condition. Error bars correspond to within-subjects' standard errors.


Assuming evidence for choosing the Riskier option is determined by the difference between the sums of the high-variance and low-variance sets, this difference should be amplified if each item is transformed by a convex exponential function (i.e. α>1). For example, if α=1.1, the differences in sums between the sets are [33.7] when the high-variance
between Engagement and Noise (i.e., σ=Engagement/Noise) -where Noise is a constant
determined by task demands and Engagement is under the participant's control. Consequently,
increased engagement in the task should amplify all outcomes in a linear fashion over
processing noise (as opposed to the exponential function in Eq. 1 that gives greater weights to
larger outcomes if α>1).
Within the current modelling framework, allocating more attention to larger values with
an increase in processing noise should produce α values that increase with Block in the C-I-M
group. Choice patterns that are consistent with this prediction would exhibit an increase in
p(Riskier) if the mean of the Riskier machine is larger, but a decrease in p(Riskier) if the mean
of the Riskier machine is smaller. To illustrate these patterns, consider the following three sets
of numbers representing the outcomes of three example machines: [52, 54, 56, 58], [35, 45, 55,
65] and [45, 55, 65, 75]. The first set has low-variance (Safer) and a mean of 55. The second
and the third sets have high-variance (Riskier), and means of 50 (Below) and 60 (Above),
respectively.
set has a greater mean, and [-31.9] when the low-variance set has a greater mean. Whereas if α=1.2, the differences between the sets are [56.2] and [


Table 1
1
The parameters' mean values and the proportion of participants in each condition that
exhibited a convex exponent weighting function (α>1) among blocks and feedback groups.
Feedback
group
Block
αc
αf
σ
λ
p(αc>1) p(αf>1)








Appendix


A1. Model comparisons
In the following section we tested the current model assumptions against alternative accounts.
First, we tested the contribution of the free parameters by applying a likelihood ratio test between the full model and nested versions, in which one of the parameters was constrained.
We also compared the fit of the current model to alternative mechanisms that could possibly account for the data better (in AIC scores; 
Akaike, 1973)
. We tested four candidate models: i) A multiplier model in which a multiplication function is used to describe the amplification of attention instead of an exponent function. ii) The Selective-Integration Model (SI) 
(Glickman et al., 2018
; see also 
Tsetsos et al., 2012)
 is a similar decay model which assumes that on each play participants use attention to filter out the lower outcome between the two. Hence, unlike the current model that applies the exponent transformation across all outcomes, the SI model implements the attentional transformation to one of the outcomes while the other remains intact. iii) The REFERENCE model is a Reinforcement Learning model which assumes that people evaluate outcomes in respect to a reference point -determined by the context of earlier learned outcomes 
(Palminteri, Khamassi, Joffily & Coricelli, 2015;
Palminteri & Lebreton, 2021)
. Learning rate is estimated as a free parameter, which offers an alternative account for the decay function. iv) Outcomes-irrelevant learning is another Reinforcement Learning model which assumes that options' expectancies are partly updated by irrelevant information 
(Shahar et al., 2021;
Shahar et al., 2019)
. For example, when an outcome from one machine updates the expectancy of another, a mistake that could easily occur when inconsistencies in congruency are imposed. All models were fitted to each participant and Block condition separately.
 










Information theory and an extension of the maximum likelihood principle




H
Akaike


















Proceedings of the Second International Symposium on Information Theory


B. N. Pet rov & F. Caski


the Second International Symposium on Information Theory
Budapest




Akademiai Kiado














Eyes on the prize? Evidence of diminishing attention to experienced and foregone outcomes in repeated experiential choice




N
J
Ashby






T
Rakow








Journal of Behavioral Decision Making




29


2-3
















All that glitters: The effect of attention and news on the buying behavior of individual and institutional investors. The review of financial studies




B
M
Barber






T
Odean








21














Complexity in financial markets




M
Brunnermeier






M
Oehmke








Princeton University, 8












Trading complex assets




B
I
Carlin






S
Kogan






R
Lowery








The Journal of finance




68


5
















Reinforcement learning and savings behavior




J
J
Choi






D
Laibson






B
C
Madrian






A
Metrick








The Journal of finance




64


6
















Over-and Underweighting of Extreme Values in Decisions from Sequential Samples




V
Clarmann Von Clarenau






T
Pachur






B
Spitzer


















Investor inattention and Friday earnings announcements




S
Dellavigna






J
M
Pollet








The Journal of Finance




64


2
















From anomalies to forecasts: Toward a descriptive model of decisions under risk, under ambiguity, and from experience




I
Erev






E
Ert






O
Plonsky






D
Cohen






O
Cohen








Psychological Review




124


4
















The psychology and neuroscience of financial decision making




C
Frydman






C
F
Camerer








Trends in cognitive sciences




20


9
















Fast and frugal heuristics: The adaptive toolbox




G
Gigerenzer






P
M
Todd








Simple heuristics that make us smart




Oxford University Press
















Attentional Selection Mediates Framing and Risk-Bias Effects




M
Glickman






K
Tsetsos






M
Usher








Psychological science




29


12
















SIMR: an R package for power analysis of generalized linear mixed models by simulation




P
Green






C
J
Macleod








Methods in Ecology and Evolution




7


4
















Information overload or search-amplified risk? Set size and order effects on decisions from experience




T
T
Hills






T
Noguchi






M
Gibbert








Psychonomic Bulletin & Review




20


5
















Visual fixations and the computation and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel








Nature neuroscience




13


10
















Asymmetric learning from financial information




C
M
Kuhnen








The Journal of Finance




70


5
















The influence of attention on value integration




M
A
Kunar






D
G
Watson






K
Tsetsos






N
Chater








Perception, & Psychophysics




79


6










Attention








Overrepresentation of extreme events in decision making reflects rational use of cognitive resources




F
Lieder






T
L
Griffiths






M
Hsu








Psychological review




125


1
















Living near the edge: How extreme-outcomes and their neighbors drive risky choice




E
A
Ludvig






C
R
Madan






N
Mcmillan






Y
Xu






M
L
Spetch








Journal of Experimental Psychology: General




147


12
















Extreme outcomes sway risky decisions from experience




E
A
Ludvig






C
R
Madan






M
L
Spetch








Journal of Behavioral Decision Making




27


2
















Remembering the best and worst of times: Memories for extreme outcomes bias risky decisions




C
R
Madan






E
A
Ludvig






M
L
Spetch








Psychonomic bulletin & review




21


3
















A simplex method for function minimization




J
A
Nelder






R
Mead








The computer journal




7


4
















Contextual modulation of value signals in reward and punishment learning




S
Palminteri






M
Khamassi






M
Joffily






G
Coricelli








Nature communications




6


1
















Context-dependent outcome encoding in human reinforcement learning. Current Opinion in Behavioral Sciences




S
Palminteri






M
Lebreton








41














The adaptive decision maker




J
W
Payne






J
R
Bettman






E
J
Johnson








Cambridge university press












Learning about unstable, publicly unobservable payoffs




E
Payzan-Lenestour






P
Bossaerts








The Review of Financial Studies




28


7
















Ensemble perception: extracting the average of perceptual vs numerical stimuli




D
Rosenbaum






V
De Gardelle






M
Usher


















Probability matching does not decrease under cognitive load: A preregistered failure to replicate




C
Schulze






G
James






D
J
Koehler






B
R
Newell








Memory & cognition




47


3
















Taking the easy way out? Increasing implementation effort reduces probability maximizing under cognitive load




C
Schulze






B
R
Newell








Memory & Cognition




44


5




















N
Shahar






T
U
Hauser






R
Moran






M
Moutoussis






E
T
Bullmore






R
J
Dolan


















Assigning the right credit to the wrong action: compulsivity in the general population is associated with augmented outcome-irrelevant value-based learning






Translational psychiatry




11


1














Credit assignment to state-independent task representations and its relationship with model-based decision making




N
Shahar






R
Moran






T
U
Hauser






R
A
Kievit






D
Mcnamee






M
Moutoussis






.
.
Dolan






R
J








Proceedings of the National Academy of Sciences


the National Academy of Sciences






116














Gaze amplifies value in decision making




S
M
Smith






I
Krajbich








Psychological Science




30


1
















Selective overweighting of larger magnitudes during noisy numerical comparison




B
Spitzer






L
Waschke






C
Summerfield








Nature Human Behaviour




1


8
















Salience driven value integration explains decision biases and preference reversal




K
Tsetsos






N
Chater






M
Usher








Proceedings of the National Academy of Sciences




109


24
















Judgment under uncertainty: Heuristics and biases. science




A
Tversky






D
Kahneman








185














How top-down and bottom-up attention modulate risky choice




Y
Vanunu






J
M
Hotaling






M
E
Le Pelley






B
R
Newell








Proceedings of the National Academy of Sciences




39


118














Elucidating the differential impact of extreme-outcomes in perceptual and preferential choice




Y
Vanunu






J
M
Hotaling






B
R
Newell








Cognitive Psychology




119


101274














Constructing Preference From Sequential Samples: The Impact of Evaluation Format on




Y
Vanunu






T
Pachur






M
Usher








Risk Attitudes Decision




6


3
















Searching for Patterns in




G
Wolford






S
E
Newman






M
B
Miller






G
S
Wig


















We conducted a parameter recovery analysis on a synthetic data-set -generated by using the participants' best-fitting parameter values to simulate binary-choice for each trial. Hence, we used the same stimuli the participants saw during the experiment to generate their synthetic choices according to the model's predictions. To control for noise in generating binary-choice






we repeated this procedure 100 times -creating a synthetic data set that was 100 times larger









"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]