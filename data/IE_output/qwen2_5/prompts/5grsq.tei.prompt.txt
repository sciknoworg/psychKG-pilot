You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
In this paper, we investigate whether professional moral philosophers are experts at making intuitive judgements about hypothetical moral cases. To advance the metaphilosophical discussion, we present new findings from a large and comprehensive online experiment performed with expert ethicists and lay subjects. In doing so, we will largely sidestep a controversial issue in the epistemology of ethics: the status of moral expertise and testimony.
Ethicists tend to be sceptical of the possibility of gaining moral knowledge through 
(expert)
 testimony in the same way that we acquire knowledge from experts in, say, palaeontology or physics (see, for example, 
Hopkins [2007]
; 
Lewis [2020]
). However, certain limited forms of reliance on expert testimony seem possible in the moral domain as well (see, for example, 
Jones [1999]
; 
Jones and Schroeter [2012]
). We thus assume merely that professional ethicists may have intuitive expertise in their judgements about typical moral thought experiments.
Paradigmatic examples would be Thomson's violinist 
[Thomson 1971]
 or the various trolley cases 
[Foot 1967;
Thomson 1985]
. Given that such thought experiments often involve unusual or even far-fetched scenarios, it seems prima facie plausible that the relevant intuitive judgements of professional ethicists are superior to those of laypeople. Therefore, intuitive moral expertise concerning ethical thought experiments should at least be a realistic possibility.
The question of whether expert (moral) philosophers really have such intuitive expertise has acquired special prominence in the metaphilosophical debate about experimental philosophy (see, for example, 
Weinberg et al. [2010]
). Since findings from experimental philosophy suggest that intuitive judgements about hypothetical cases vary with philosophically irrelevant factors, some experimental philosophers have claimed that we should stop appealing to such judgements in philosophical theorizing (see, for example, 
Alexander et al. [2009]
; 
Machery [2017]
). Probably the most influential reply to this claim is the expertise defence (see, for example, 
Horvath [2010]
; 
Ludwig [2007]
; 
Williamson [2011]
), which is based on the observation that most studies from experimental philosophy are performed with philosophical laypeople. According to this defence, professional philosophers' intuitive judgements in their respective areas of expertise are superior to those of untrained laypeople, in analogy with other domains of academic expertise (compare Hales 
[2006]
). The relevant claim for our purposes is that moral philosophers' intuitive judgements about ethical thought experiments can be expected to vary much less with morally irrelevant factors than those of laypeople. As a consequence, professional ethicists can ignore troubling experimental studies that are performed with lay subjects-and moral philosophy can carry on as before. Unfortunately, the empirical claim that moral philosophers enjoy intuitive expertise of the relevant kind has been undermined by recent studies in experimental metaphilosophy (see, for example, 
Wiegmann et al. [2020]
). In the following, we will first present the empirical case against intuitive expertise in ethics, and then add our own, somewhat more complicated findings to the debate. Even in the light of our own findings, however, the prospects of the expertise defence in moral philosophy remain dim.


Intuitive Expertise and the Expertise Defence
Various findings from experimental philosophy suggest that intuitive judgements about hypothetical cases vary with philosophically irrelevant factors. For example, intuitive judgements about moral cases have been found to be sensitive to order of presentation (see, for example, 
Liao et al. [2012]
; 
Wiegmann and Waldmann [2014]
), even though the order of the cases has no obvious bearing on what is morally right or wrong in them (compare 
Wiegmann et al. [2020]
). Other examples of arguably irrelevant factors are cultural background (see, for example, 
Machery et al. [2004]
), affective content (see, for example, 
Nichols and Knobe [2007]
), and heritable personality traits (see, for example, 
Feltz and Cokely [2019]
).
According to experimental philosophers of a restrictionist stripe, such findings suggest that intuitive judgements about philosophical thought experiments are untrustworthy (see, for example, 
Weinberg [2007]
) or even flat-out unreliable (see, for example, 
Machery [2017]
). If that is so, then the standard philosophical method of appealing to intuitions about hypothetical cases 1 should either be abandoned 
[Machery 2017
], or at least seriously restricted until empirical research reveals which intuitions can be trusted 
[Weinberg 2015
].
However, experimental restrictionism has met strong resistance, and the expertise defence has emerged as probably the most popular reply (see, for example, 
Alexander [2016]
; 
Horvath [2010]
; 
Ludwig [2007]
; 
Machery [2017]
; 
Nado [2014]
; 
Weinberg et al. [2010]
; 
Wiegmann et al. [2020]
; 
Williamson [2011]
). According to this defence, only the intuitive judgements of philosophical experts-that is, moral philosophers in the case of ethical thought experiments-matter for philosophical theorizing, just as in other respectable academic fields like mathematics or law (compare 
Hales [2006]
). Since mathematicians typically ignore the mathematical intuitions of laypeople as irrelevant to their practice, professional philosophers can do likewise in their respective areas of expertise. This defence assumes that expert philosophers are less likely to be influenced by philosophically irrelevant factors than laypeople. If that is so, then expert philosophers can simply ignore problematic experimental results, which are usually obtained from philosophically untrained participants.
One important point is that the expertise defence is not concerned with the broader question of whether philosophers have some professional expertise or other, which they surely do-if only by knowing more about philosophy than laypeople. Rather, the key issue 
1
 In recent metaphilosophy, there has been some controversy about whether it is in fact standard philosophical practice to appeal to intuitions about hypothetical cases (cf. 
Cappelen [2012]
; 
Deutsch [2015]
; Horvath [Unpublished Manuscript]; 
Horvath and Koch [2020]
). For the purposes of this paper, we will ignore this strand of the metaphilosophical debate and simply assume that appealing to intuitions about cases as evidence is indeed standard philosophical practice-as continues to be the mainstream view in contemporary analytic philosophy.
is whether philosophers have specific intuitive expertise for judging hypothetical cases in their respective areas of philosophical competence, such as ethics or epistemology 
[Weinberg et al. 2010]
. Even if there is a certain presumption that professional philosophers have this expertise 
[Horvath 2010;
Williamson 2011]
, it is still an empirical question whether they actually have it-and experimental metaphilosophy has already begun to investigate this question. We will now briefly discuss the relevant findings, with a special focus on intuitive expertise in ethics.


Intuitive Expertise in (Moral) Philosophy
The seminal study of intuitive expertise in (moral) philosophy is by 
Schwitzgebel and Cushman [2012]
, 2 who found equally large order effects in expert ethicists and laypeople for standard ethical cases, including trolley cases of the type that we used in our own experiment (see below). Schwitzgebel and Cushman's study also had a high number of participants, and they used reasonably strict criteria for ethical expertise (= MA or PhD in philosophy, with ethics as an area of competence or specialization).
In a follow-up study, 
Schwitzgebel and Cushman [2015]
 replicated their earlier finding about order effects and found that professional philosophers were equally affected by 
Tversky and Kahneman's [1981]
 'Asian disease' framing (see our own experiment below).
Moreover, neither forced reflection, nor self-reported expertise, nor familiarity with the relevant cases made a difference to philosophers' susceptibility to the tested effects. 
Tobia, Buckwalter, and Stich [2013]
 found that professional philosophers and lay people exhibit an equally large actor-observer bias concerning two well-known ethical cases, including a trolley case of the switch-type (see below). Actor-observer bias is the tendency to judge cases differently from a first-person and a third-person perspective. However, in a follow-up study by 
Tobia, Chapman, and Stich [2013]
, there was no main effect of actorobserver bias. Instead, they found an interaction of this factor with a cleanliness manipulation, operationalized by the scent of Lysol, which is associated with cleanliness.
Both of these effects should be taken with a grain of salt, though. First, although the actorobserver effects in 
Tobia, Buckwalter, and Stich [2013]
 were large, they were just below the conventional .05-threshold for statistical significance, and they also failed to replicate in 
Tobia, Chapman, and Stich [2013]
, as well as in our own experiment (see below). Second, the alleged surprising effects of subtle priming, as claimed for the scent of Lysol, have largely been discredited by the replication crisis of the last decade (see, for example, Open Science


Collaboration [2015]).
A study by 
Löhr [2019]
 tested various hypotheses about Nozick's experience machine scenario with professional philosophers and laypeople. Even though professional philosophers were more consistent in their overall responses, 29% still gave inconsistent answers in a within-subject presentation of three variations of Nozick's scenario.
A recent study by 
Wiegmann, Horvath, and Meyer [2020]
 used a standard trolley dilemma and a six-option version of the same case, to test order effects and the influence of irrelevant additional options on moral judgements in laypeople and expert moral philosophers (= participants with a PhD or MA in philosophy, with ethics as an area of competence or specialization). Expert ethicists were no more resistant to order effects and irrelevant options than laypeople. Descriptively speaking, they were even more susceptible to these effects than laypeople (while also being more consistent in their responses).
Finally, let us briefly consider some findings on intuitive philosophical expertise outside of ethics. 
Hitchcock and Knobe [2009]
 found that the intuitions of philosophical experts about actual (or token) causation were affected by norm violations to the same extent as those of laypeople. However, it is somewhat controversial whether this is really a philosophically irrelevant factor. 
Schulz, Cokely, and Feltz [2011]
 found that the facet warmth of the personality trait extraversion predicts compatibilist intuitions about free will in both philosophical experts and laypeople (see also 
Feltz and Cokely [2019]
).
In a study performed with language experts from subfields of philosophy and linguistics, 
Machery [2012]
 found that experts have no clear advantage over laypeople.
Moreover, the various expert subgroups disagreed with each other in their intuitive judgements about reference.


Horvath and Wiegmann [2016] compared expert epistemologists' and laypeople's
intuitive judgements about knowledge cases and found significant expert-lay differences in a number of cases. However, these differences were all quantitative rather than qualitative (that is, laypeople agreed significantly more strongly with the tested knowledge-claims than experts, but the general tendency was the same). More strikingly, expert epistemologists sometimes disagreed with the 'textbook consensus' in epistemology, for example, by judging fake-barn-type cases to be instances of knowledge (as do laypeople).
In a recent study, Schindler and Saint-Germier [Unpublished Manuscript] compared intuitive judgements and the relevant interpretative abilities of professional philosophers and laypeople concerning standard thought experiments from theoretical philosophy. Overall, they found that philosophers have an advantage over laypeople vis-à-vis the relevant 'textbook consensus' in only three out of six cases. 
3
 The upshot of the reviewed studies is that philosophical experts at best enjoy a mild advantage over laypeople in a few of the tested cases. The empirical data thus do not support the expertise defence as a convincing reply to the experimental restrictionist challenge.
Moreover, the prospect of a general, unqualified expertise defence 'from the philosophical armchair' seems near hopeless at this point, because the cases where philosophical experts may have a genuine advantage over laypeople are few and far between, and cannot be predicted in advance of empirical investigation.
However, it would be premature to conclude that the expertise defence has been empirically refuted. First, the number of investigated biases in the moral domain (= 5) is still fairly small. 
4
 Second, given that professional philosophers are difficult to recruit and surprising findings are much easier to publish, researchers may have primarily studied biases that they expected 'to work' with expert participants. The current literature may therefore paint an overly negative picture of (moral) philosophers' relevant expertise. To broaden and 'debias' this research, our own study investigates as many biases as all the previous studies combined (= 5), which we have, for the most part, chosen independently of specific expectations concerning expert participants (see below for details). We will now present the results of this large and comprehensive online experiment performed with expert moral philosophers and laypeople.


Experiment
The preregistration of our experiment can be found here:
https://osf.io/t5kpa/?view_only=aca56e761a9e4e6f9b9ee7f0197594d4


Participants
Our analysis includes the data of 454 participants. Their mean age was 36 years. 53%
identified as male and 45% as female, while 2% selected other or prefer not to say. 227 were expert participants (mean age 37 years, 76% male, 21% female, and about 3% other or prefer not to say), and equally many, 227, were lay participants (mean age 35 years, 39% male, 69% female, and 1% other or prefer not to say).
Expert participants were recruited through a call for participation with a link to the online experiment, which was distributed on an electronic mailing list for philosophers (PHILOS-L: https://www.liverpool.ac.uk/philosophy/philos-l), a blog specialized in ethics (PEA Soup: http://peasoup.us), and two social media platforms (Facebook and Twitter). To qualify as experts, participants had to indicate having a PhD (59%) or an MA (41%) in philosophy, with moral philosophy or ethics as one of their areas of specialization (51%) or competence (49%). We excluded the data of participants who did not complete the survey, or took less than 2 minutes to do so, or failed to answer both attention checks correctly. 227 out of 1033 participants met these criteria, which were not mentioned in the call for participation or during the survey. 5
Lay participants were recruited on Prolific Academics, a database based in the UK (compare 
Palan and Schitter [2018]
). Each participant received compensation of £0.40. To ensure that lay participants differed strongly from expert participants in their level of philosophical expertise, we only included the data of participants who had either no prior experience with philosophy, or only some experience in school or university (without a degree in philosophy), and who were not current students of philosophy. We also excluded the data of participants who did not complete the survey, or took less than 2 minutes to do so, or failed to answer both attention checks correctly. 6 227 out of 336 participants met these criteria, which were not mentioned in the call for participation or during the survey. 7


Design and Materials
The experiment was conducted online on Unipark (https://www.unipark.com/en/surveysoftware/). Participants were first presented with general instructions that familiarized them with the question mode, asked them to read the case descriptions carefully, and appealed to them to take the task seriously. Participants were then randomly assigned to one of two framing direction conditions (Positive or Negative), and presented with five moral scenarios that we used to implement five different framing effects (Focus, Prospect, Accounting, Perspective, and Decoy). The five scenarios were framed in a way expected to either increase A pilot study with lay participants suggested that the framing direction manipulation works in the expected direction, with effects ranging from small to large across vignettes.
One might worry that small or even non-significant effects in laypeople are not useful for testing the expertise defence, because experts can hardly outperform laypeople here by being less biased than the latter. This worry is misplaced, however. First, pilot studies provide only rough estimates of effect sizes, and thus predict only roughly what will happen in the main study. Second, there is still room for experts to outperform laypeople in individual scenarios, and also averaged across all scenarios. Moreover, experts are sometimes even more biased than laypeople (see, for example, 
Chi [2006]
; 
Wiegmann et al. [2020]
). Third, and most importantly, selecting only scenarios that yield strong biases in laypeople stacks the deck in favour of the experts, for it makes it relatively easy for them to outperform laypeople in the experimental setting, even though they might not really be better on average. To illustrate, consider a teacher who wants to compare the performance of two students A and B, and does so by first testing A on a set of questions, and then asking B only those questions that A got wrong. This flawed procedure would make it very easy for B to outperform A, because B only needs to get a few of the questions right that A got wrong, while at the same time it is completely screened off how B would perform on the questions that A got right. Therefore, we did not dismiss any scenario simply because the pilot study indicated only a small effect, and we selected most of the original scenarios independently of expectations concerning philosophical experts (with the exception of Prospect and Perspective; see below).
Here is the exact wording of our five scenarios, with the relevant manipulations in square brackets (with bold font indicating the Positive condition, for which higher ratings were expected):
Focus (question-focus on good vs. bad consequences; 
Petrinovich and O'Neill [1996])
 Carl is standing on the pier and observes a shark swimming toward five swimmers. There is only one possibility to avoid the death of the five swimmers:
Carl could make loud noises, and thereby divert the shark into his direction.
However, there is a fisherman swimming on the path between Carl and the shark.
Diverting the shark would therefore save the five swimmers but kill the fisherman.
How much do you disagree or agree with the following claim:
Carl should make loud noises, which will result in [the five swimmers being saved / the fisherman being killed].
This manipulation of the question-focus in terms of good or bad consequences is based on 
Petrinovich and O'Neill [1996]
, who originally used the trolley paradigm to demonstrate its effect. In our adapted version, the trolley/train is replaced by a shark in order to avoid interferences with our second trolley-style scenario (see below). Originally, this manipulation resulted in a large ( 2 = .45) and robust effect (39 out of 40 paired cases received significantly lower agreement ratings for the kill-wording). Moreover, the applied framing is clearly morally irrelevant, for the potential action and its consequences are exactly identical.


Prospect (prospect framed in positive vs. negative terms; Tversky and Kahneman [1981])
A country is preparing for the outbreak of an unusual disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows:
If Program A is adopted, [200 people will be saved / 400 people will die].
If Program B is adopted, there is a one-third probability that [600 people will be saved / nobody will die] and a two-thirds probability that [no people will be saved / 600 people will die].
How much do you disagree or agree with the following claim:
Program A should be adopted. This vignette tests a seminal effect known as the 'Asian Disease Problem', introduced by Tversky and 
Kahneman [1981]
, which is one of a variety of effects that show that identical prospects are evaluated differently when framed in terms of losses versus gains. The original scenario is very similar to the one we used-only the original test question ('Which of the two programs would you prefer?') was modified to highlight the moral dimension of the scenario. The effect found in the original study was large-Program A was favoured by 72% of the participants when framed in terms of saving, as compared to 22% when framed in terms of dying-and it was also found to be highly robust (see, for example, 
Ruggeri et al. [2019]
, who replicated effects of this kind in nineteen countries). Since the two framings are identical in all morally relevant aspects, an effect of this kind would clearly indicate biased moral judgements. In fact, the 'Asian Disease Problem' has already been tested among professional philosophers (with only slightly different vignettes), and they were not found to be immune to this effect 
(Schwitzgebel and Cushman [2015]
). A replication with our ethical version would thus provide converging evidence that even professional philosophers (in our case: moral philosophers) are susceptible to this seminal effect.
Accounting (mental accounting; 
Thaler [1985]
; 
Tversky and Kahneman [1981])
 Sarah has decided to go to a charity event [where admission will be $20 per ticket / and already bought a ticket for $20]. All of those $20 will be spent on improving the living conditions in some of the world's poorest countries, but only if the ticket is signed by the ticket holder and handed over to a representative of the charity organization during the event. As Sarah enters the venue where the charity event takes place, she discovers that she has [lost a $20 note / lost her ticket] on the way to the venue. Frustrated with her loss, Sarah decides against spending $20 on [a / another] ticket.
How much do you disagree or agree with the following claim: Sarah should be blamed for not spending $20 on [a / another] ticket.


[Attention check, on next page:]
What did Sarah lose on her way to the venue? Her ticket/Her mobile phone/A $20 note This vignette is a moral adaptation of another seminal finding by 
Tversky and Kahneman [1981]
, and 
Thaler [1985]
. The key idea is that we have different mental accounts for different kinds of costs, which can lead to different decisions in financially identical situations. In the original version, participants are asked to imagine that they had decided to see a play whose admission is $10 per ticket. In one condition, they were told that they had bought a ticket only to discover that they had lost it. In another condition, they had not bought a ticket, but instead lost a $10 bill on their way to the theatre. When asked whether they would still pay $10 for a ticket, almost all participants (88%, 
Tversky and Kahneman [1981]
) answered 'Yes' in the condition where they lost a $10 bill, in contrast to only about half of them (46%) in the condition where they lost the original ticket. We adapted this paradigm to the moral domain by stipulating that the money for the ticket goes to a charity devoted to fighting extreme poverty. The original findings suggest lower blame ratings in the condition where the ticket was lost-under the assumption that people tend to blame other people less if they themselves would have behaved similarly. Without making any questionable additional assumptions-for example, that losing a ticket is more frustrating than losing a $10 bill and that more frustrated people deserve less blame-it is hard to see how these two versions could differ in morally relevant aspects.
Perspective (actor vs. observer perspective; 
Tobia, Buckwalter, et al. [2013]
; 
Tobia, Chapman, et al. [2013])
 [Anne is / You are] a technician in a company producing chemicals and responsible for the safety of employees. One day, [she observes / you observe] on [her / your] monitor that poisonous gas has been released into the ventilation system and is about to contaminate a room with three researchers, who will die if they are exposed to the gas. Because there is not enough time to warn the three researchers, there is only one possibility to avoid their death: [Anne is / You are] in control of the ventilation system and could close the ventilation shaft leading to the room with the three researchers, who would be saved by this measure.
However, as a result of closing the ventilation shaft, the poisonous gas would be released into another room where one researcher is working. Since there is no way to block the ventilation shaft to this other room and also not enough time for a warning, the one researcher working there would die from being exposed to the gas.
How much do you disagree or agree with the following claim:
[Anne / You] should close the ventilation shaft. This vignette tests the finding by 
Tobia, Buckwalter, and Stich [2013]
 that professional philosophers are equally susceptible to actor-observer bias in moral scenarios as laypeople. Actor-observer bias trades on the contrast between judging decisions from the first-person perspective of the person who makes the decision (the actorperspective), and a more neutral third-person perspective (the observer-perspective).
One reason for including this alleged bias was to clarify earlier findings by 
colleagues [2013, 2013]
, which are somewhat mixed (see above). One puzzling aspect of their results is that the actor-observer manipulation affected professional philosophers and laypeople in opposite directions. For instance, in a switch-type trolley dilemma 
(Tobia, Buckwalter, et al. [2013]
; experiment 2), the observer framing increased permissibility ratings in laypeople (with respect to redirecting the trolley), but it decreased permissibility ratings in professional philosophers. Since we are consistently re-phrasing the test question in terms of whether a certain decision should be made (in contrast to previous studies), it was not antecedently clear how our manipulation would influence participants' ratings. Thus, we conducted a pilot study that indicated that laypeople's agreement ratings should be higher in the observer condition. We also made the conservative assumption that the direction of the effect, if any, would be the same for experts and laypeople. An actor-observer effect would clearly indicate a bias in our scenario, because it seems ceteris paribus morally irrelevant who makes the decision here.


Decoy (decoy effect; Huber et al. [1982])
On the test ground of a modern railroad property, an unmanned speed-train that normally can be remote-controlled is out of control due to a technical defect.
This speed-train is heading towards five railroad workers that are maintaining the tracks (see figure below). Since these workers are wearing a new type of hearing protection, they would not notice the speed-train on time, and hence would be run over by it and lose their lives in the accident. Peter, an employee of the rail track control center, recognizes the upcoming accident. The speed-train would collide with the one worker and be stopped before it reaches the five workers. The one worker would lose his life due to the collision.
How much do you disagree or agree with the following claim:
Peter should choose Option 2, that is, he should push the button that will open the trap door in the left bridge and cause the one worker to fall on the tracks.


[Attention check (next page):]
How many bridges were displayed in the figure on the previous page? 1/2/3 This vignette tests the 'decoy effect', one of the best-known human violations of rational choice (also known as the 'attraction effect' or 'asymmetric dominance effect'; 
Huber et al. [1982]
; 
Huber and Puto [1983]
; see 
Huber et al. [2014]
, for an overview; see 
Frederick et al. [2014]
, for boundary conditions). This effect consists of adding an inferior option to a choiceset which increases the choice-share of the option that it most closely resembles. In our moral adaptation, the additional option that results in the death of two people should thus increase the ratings for the otherwise identical option where only one person dies.
The response format we used was the same for all five scenarios: a 7-point Likert-item ranging from 'strongly disagree' (1) to 'strongly agree' (7).


Results
Data available online at: https://osf.io/y5x6b/?view_only=1d233da8938c414da95cb1288884ea76 Our results are summarized in 
Figure 1
, 
Table 1, and Table 2
. We will first analyse the overall effect of framing direction and its interaction with level of expertise, and then consider each framing effect separately. from 1 ('strongly disagree') to 7 ('strongly agree').


Global Analyses
We applied a mixed ANOVA with framing direction (Positive vs. Negative) and level of expertise (Expert vs. Lay) as between-subjects factors, and framing effect as within-subject factor. All results are summarized in 
Table 1
; we will now discuss the most relevant ones.
The framing direction manipulation (Positive vs. Negative) affected participants' responses in the expected direction, with mean ratings in the Positive condition (M=4.49, SE=0.07) being significantly higher than in the Negative condition (M=4.00, SE=0.07), F(1, 450) = 25.68, p < .001,  2 = .054. The interaction of level of expertise and framing direction was not significant, F(1, 450) = 2.56, p = .111,  2 = .0056, indicating that the overall effect of framing direction did not differ significantly between moral philosophers and laypeople. 9
The interaction of framing effect and framing direction was significant, indicating that the five framing effects differed in how strongly they affected participants' responses, F(4, 1800) = 6.02, p < .001,  2 = .013.
Lastly, the interaction of framing effect, level of expertise, and framing direction was not significant (albeit almost), F(4, 1800) = .22, p = .064,  2 = .005, indicating that the pattern of effects caused by the framing direction manipulation in the five scenarios was roughly the same for lay and expert participants. However, this still leaves open whether individual framing effects affected moral philosophers and laypeople differently (see below for further analysis). Error 1800
Limiting the analysis to moral philosophers (Expert), a repeated-measure ANOVA with framing direction (Positive vs. Negative) as between-subjects factor and framing effect as within-subject factor indicated that, across all scenarios, the framing direction manipulation affected the agreement ratings of experts in the expected direction. Mean ratings in the Positive condition (M=4.38, SE=0.11) were significantly higher (on average by 0.33 points) than in the Negative condition (M=4.05, SE=0.11), F(1, 225) = 4.95, p < .027,  2 = .0215.
Limiting the analysis to laypeople (Lay), the analogous ANOVA led to similar results. Mean ratings in the Positive condition (M=4.59, SE=0.09) were significantly higher (on average by 0.64 points) than in the Negative condition (M=3.95, SE=0.08), F(1, 225) = 28.34, p < .001,
 2 = .
112.
To conclude, our framing direction manipulation affected both expert moral philosophers and laypeople equally, with no significant difference between these two groups. 10 Descriptively, however, the effect size of framing direction was only small-tomedium for experts, but medium-to-large for laypeople. 11 
Table 2
 displays the effect of framing direction (Positive vs. Negative) and level of expertise (Expert vs. Lay) for each of the five framing effects. We chose (and preregistered:


Analyses at the Level of Individual Framing Effects
https://osf.io/t5kpa/?view_only=aca56e761a9e4e6f9b9ee7f0197594d4) this as our primary level of analysis for the following reason: the five framings influence participants' responses differently, even if some of them look superficially similar. For instance, both question-focus and prospect-framing manipulate whether the word 'killing' or 'saving' is used, but the underlying psychological mechanism is still different. The manipulation of question-focus merely highlights the negative/positive aspect of the available action, while prospect-framing makes people prefer risky/safe choices if a prospect is framed negatively/positively. Therefore, the influence of the five effects might differ as well, 
12
 and we wanted to find out how each individual framing affects our moral intuitions. 
13
 Some of the framings might also influence expert and lay participants differently, which can only be discovered by analysing each framing condition separately. 14 Given our preregistered significance criterion (p < .05, two-sided), lay responses were significantly influenced by two of the five framing effects (Focus and Prospect), while expert responses were only significantly affected by one framing effect (Prospect). Applying a less strict significance criterion (p < .05, one-sided) would render two additional framing effects (Accounting and Decoy) significant for both moral philosophers and laypeople, and so experts would be affected by morally irrelevant factors in three out of five cases, and laypeople in four out of five cases.
Concerning expert-lay differences at the level of individual framing effects, moral philosophers were thus significantly less influenced by two framing effects (Focus and Prospect), while there was no significant expert-lay difference concerning the other three effects. 
Table 2
. Number of participants, means, 95% confidence interval, and standard deviation for all combinations of framing direction, framing effect and level of expertise. The columns for p-values and effect sizes (one-way ANOVA) concern the framing direction manipulation (Positive vs. Negative) in the respective group of moral philosophers (Expert) or laypeople (Lay), for each of the five framing effects (Focus, Prospect, Accounting, Perspective, Decoy). P-values and effect sizes in the 'Expert vs. Lay' column concern the comparison of moral philosophers and laypeople in relation to the framing direction manipulation in the respective framing condition, that is, the interaction of level of expertise and framing direction for the framing effect at issue. Reported p-values are not adjusted (see footnote 13). .006* .017


Framing Effect


Discussion
We tested five well-known cognitive biases in our experiment, such as 'Asian disease' framing and the decoy effect, and we also placed special emphasis on their replicability. The only exception is actor-observer framing, which we included on the basis of previous results with professional philosophers 
[Tobia, Buckwalter, et al. 2013;
Tobia, Chapman, et al. 2013]
.
Our own results are based on a much higher number of participants, and they strongly suggest that actor-observer framing in moral scenarios is not a robust effect (and is perhaps even a non-effect) for both philosophical experts and laypeople, which is in line with another failed replication of actor-observer framing (reported in 
Cova et al. [2018]
).
Since many of the tested biases are also well-known in ethics, it is remarkable that moral philosophers were still significantly affected by these biases taken together, that is, over all five scenarios. Even at the level of individual scenarios, moral philosophers were significantly affected by Tversky and Kahneman's 'Asian disease' framing, which is one of the most famous psychological findings. Therefore, bias was neither eliminated by expertise in ethics, nor by the widespread familiarity of the tested effects. Adding to many previous results (see section 3), our findings thus cast further doubt on the expertise defence against the challenge from experimental restrictionism.
However, our results are also more mixed and complicated than those of previous studies. For example, expert moral philosophers-unlike laypeople-were not significantly affected by a simple framing in terms of people killed versus people saved in our Focus scenario. And while expert ethicists were significantly influenced by our 'Asian disease' framing in the Prospect case, they were still significantly less affected than laypeople (see above). Our results therefore indicate that expert ethicists have a genuine advantage over laypeople with respect to some well-known biases.
So, is our study good news for proponents of the expertise defence? That depends on what their ambition is. If they aim for a general 'armchair' defence of appeals to intuitions about cases in ethics, then our mixed findings are not exactly good news for them. For, whether moral philosophers are more immune to bias in a given case can neither be settled from one's philosophical armchair, nor by some very general argument in favour of moral philosophers' expertise. Instead, we can only tell whether moral philosophers are less affected by certain biases once we have carried out sufficient experimental research. Very general armchair versions of the expertise defence are thus undermined by our mixed results to the same extent that they were by the more clear-cut previous findings (compare section 3).
However, if (moral) philosophers are open to pursuing a more empirical and piecemeal version of the expertise defence, then our findings may provide some reasons for optimism.
For example, the fact that expert ethicists don't fall for a simple saving/killing framing in our Focus case might be a reason to trust expert intuitions more when it comes to trolley scenarios of the switch-variety. One key issue for such a piecemeal empirical approach to the expertise defence would be whether the relevant findings can be generalized to other (similar) cases or (related) biases. Absent further experimental data, it might be unclear, for example, whether moral philosophers are equally immune to a saving/killing framing in trolley scenarios of the push-type. Therefore, the ambitions of an empirical expertise defence may have to be very modest indeed, and thus are bound to disappoint most actual proponents of the expertise defence in (moral) philosophy.


Conclusion
We first considered the experimental restrictionist challenge to intuitions about cases, with a special focus on moral philosophy, and then introduced the expertise defence as the most popular reply. The expertise defence makes the empirically testable assumption that the case intuitions of expert philosophers are significantly less influenced by philosophically irrelevant factors than those of laypeople. The upshot of our discussion of relevant findings from experimental metaphilosophy was twofold: first, extant findings largely tell against the expertise defence, and second, the number of published studies and investigated biases is still fairly small. To advance the debate about the expertise defence in moral philosophy, we thus tested five well-known biases of judgement and decision-making among expert ethicists and laypeople. Averaged across all biases and scenarios, the intuitive judgements of both experts and laypeople were clearly susceptible to bias. However, moral philosophers were also less biased in two of the five cases (Focus and Prospect), although we found no significant expertlay differences in the remaining three cases.
In comparison to previous findings (for example 
Cushman [2012, 2015]
; 
Wiegmann et al. [2020]
), our results appear to be relatively good news for the expertise defence, because they suggest that moral philosophers are less influenced by some morally irrelevant factors, such as a simple saving/killing framing. On the other hand, our study does not support the very general armchair versions of the expertise defence that one often finds in metaphilosophy, which try to reassure (moral) philosophers that they need not worry about the influence of philosophically irrelevant factors. At best, however, we need not worry about just a few cases and a few human biases-and even that modest hypothesis can only be upheld on the basis of sufficient empirical research. 
15
 
(in the Positive condition) or decrease agreement with the presented moral claims (in the Negative condition). This resulted in a 2*2*5 mixed design, with framing direction (Positive vs. Negative) and level of expertise (Expert vs. Lay) as between-subjects factors, and framing effect (Focus, Prospect, Accounting, Perspective, and Decoy) as within-subject factor. The order of presentation was fixed, as presented below. 8 Two attention checks concerning the Accounting and Decoy scenario were included (see below).


[
Positive condition (three options):] Peter can choose between exactly three options: Option 1: Peter could do nothing. The five workers would be run over by the speed-train and lose their lives in the accident. Option 2: Peter could push a button that would open a trap door installed in the right bridge and cause the two workers on top of the right bridge to fall on the tracks. The speed-train would collide with the two workers and be stopped before it reaches the five workers. The two workers would lose their lives due to the collision. Option 3: Peter could push a button that would open a trap door installed in the left bridge and cause the one worker on top of the left bridge to fall on the tracks. The speed-train would collide with the one worker and be stopped before it reaches the five workers. The one worker would lose his life due to the collision. How much do you disagree or agree with the following claim: Peter should choose Option 3, that is, he should push the button that will open the trap door in the left bridge and cause the one worker to fall on the tracks. [Negative condition (two options):] Peter can choose between exactly two options: Option 1: Peter could do nothing. The five workers would be run over by the speed-train and lose their lives in the accident. Option 2: Peter could push a button that would open a trap door installed in the left bridge and cause the one worker on top of the left bridge to fall on the tracks.


Figure 1 .
1
Participants' agreement ratings as a function of framing effect, level of expertise, and framing direction. Error bars represent 95% confidence intervals. Response options range


Table 1 .
1
Results of mixed ANOVA with level of expertise (Expert vs. Lay) and framing direction (Positive vs. Negative) as between-subjects factors, and framing effect (Focus, Prospect, Accounting, Perspective, Decoy) as within-subject factor.
Effect


For a survey of empirical studies of intuitive expertise more generally, see
Kahneman and Klein [2009]
.


Further studies that bear on the expertise defence less directly are
Beebe and Monaghan [2018]
,
Carter et al. [2016]
,
Carter et al. [2019]
, and
Sytsma and Machery [2010]
.


These are order effects Cushman 2012, 2015;
Wiegmann et al. 2020]
, 'Asian disease' framing
[Schwitzgebel and Cushman 2015]
, actor-observer bias
[Löhr 2019;
Tobia, Buckwalter, et al. 2013;
Tobia, Chapman, et al. 2013]
, cleanliness priming
[Tobia, Chapman, et al. 2013]
, and irrelevant additional options
[Wiegmann et al. 2020]
.


The main reasons for this high exclusion rate were not having a PhD or MA in philosophy (639 participants), and not having moral philosophy/ethics as an area of specialization or competence (563 participants). 6 12% of expert and 19% of lay participants failed to answer both attention checks correctly.7  In line with our preregistration, lay participants were recruited until we reached the number of valid expert participants at the end of May 2019.


This order of presentation was chosen to minimize potential order effects. For instance, it has been shown that presenting a 'push-type' dilemma can strongly influence the evaluation of subsequent scenarios. This is why we presented Decoy, which includes a push-type option, as the final scenario. Moreover, the two structurally similar scenarios in which a threat can be redirected by the agent (Focus and Perspective) were not presented one right after the other, but rather with two scenarios in between (Prospect and Accounting).


A linear mixed model analysis with participant and framing effect as random effect led to the same results-as expected given the specifics of our design(balanced, no missing values, etc.). This equivalence also holds for the following analyses.


Given that the gender distribution differed strongly between expert and lay participants, we also tested the interaction of gender and framing direction, which was not significant, p = .76 (i.e. the framing direction affected both genders equally). 11 The conventions for reported effect sizes are as follows: 0.01 = small, 0.06 = medium, 0.14 = large.


This expectation was confirmed by the significant interaction of framing direction and framing effect.13  The distinctness of the five framing effects is also why p-values inTable 2 are not adjusted for multiple comparisons.14 This possibility obtains irrespective of the fact that the overall interaction of framing direction, framing effect, and level of expertise was not significant (p = .064).


We would like to thank John Horden, Steffen Koch, Michael Vollmer, and several anonymous reviewers for very helpful comments on previous versions of this paper. We would also like to thank our audiences at EuroCogSci, Ruhr University Bochum, September 2019, at the Experimental Philosophy Conference Bern,








Funding


Joachim Horvath and Alex Wiegmann's work on this paper was supported by an Emmy
Noether grant of the German Research Foundation (DFG), project number 391304769.
 










Philosophical Expertise, in A Companion to Experimental Philosophy




J
Alexander




J. Sytsma and W. Buckwalter






Wiley Blackwell




Malden, MA












Accentuate the Negative




J
Alexander






R
Mallon






J
M
Weinberg








Review of Philosophy and Psychology




1


2
















Epistemic Closure in Folk Epistemology




J
R
Beebe






J
Monaghan








Oxford Studies in Experimental Philosophy


J. Knobe, T. Lombrozo, and S




















Oxford
Nichols






Oxford University Press


















H
Cappelen








Philosophy Without Intuitions






Oxford University Press












Not Knowing a Cat is a Cat: Analyticity and Knowledge Ascriptions




J
A
Carter






M
Peterson






B
Van Bezooijen








Review of Philosophy and Psychology




7


2
















Knowledge-how, Understanding-why and Epistemic Luck: An Experimental Study




J
A
Carter






D
Pritchard






J
Shepherd








Review of Philosophy and Psychology




10
















Two Approaches to the Study of Experts' Characteristics, in The Cambridge Handbook of Expertise and Expert Performance




M
Chi




K.A. Ericsson, N. Charness, P. Feltovich, and R. Hoffman






Cambridge University Press




Cambridge












Last but not least, many thanks to Nick Byrd, Daniel Dennett, and Peter Singer for distributing our call for participation on Twitter










University of Bern ; University of Salzburg






and at the Tagung für Praktische Philosophie, Panel Gedankenexperimente in der praktischen Philosophie








Estimating the Reproducibility of Experimental Philosophy




F
Cova






B
Strickland






A
Abatista




10.1007/s13164-018-0400-9>








Review of Philosophy and Psychology


















M
Deutsch




The Myth of the Intuitive: Experimental Philosophy and Philosophical Method


Cambridge, MA




The MIT Press














Extraversion and Compatibilist Intuitions: A Ten-year Retrospective and Meta-analyses




A
Feltz






E
Cokely








Philosophical Psychology




32
















The Problem of Abortion and the Doctrine of Double Effect




P
Foot








Oxford Review




5
















The Limits of Attraction




S
Frederick






L
Lee






E
Baskin








Journal of Marketing Research




51
















Relativism and the Foundations of Philosophy




S
Hales








The MIT Press


Cambridge, MA












Cause and Norm




C
Hitchcock






J
Knobe








The Journal of Philosophy




106
















What Is Wrong with Moral Testimony?




R
Hopkins








Philosophy and Phenomenological Research




74
















How (Not) to React to Experimental Philosophy




J
Horvath








Philosophical Psychology




23
















Unpublished Manuscript. Mischaracterization Reconsidered




J
Horvath














Experimental Philosophy and the Method of Cases, Philosophy Compass




J
Horvath






S
Koch




10.1111/phc3.12716>


















Intuitive Expertise and Intuitions about Knowledge




J
Horvath






A
Wiegmann








Philosophical Studies




173
















Adding Asymmetrically Dominated Alternatives: Violations of Regularity and the Similarity Hypothesis




J
Huber






J
W
Payne






C
Puto








Journal of Consumer Research




9


1
















Let's be Honest about the Attraction Effect




J
Huber






J
W
Payne






C
Puto








Journal of Marketing Research




51
















Market Boundaries and Product Choice: Illustrating Attraction and Substitution Effects




J
Huber






C
Puto








Journal of Consumer Research




10


1
















Second-Hand Moral Knowledge




K
Jones








The Journal of Philosophy




96


2
















Moral Expertise, Analyse & Kritik




K
Jones






F
Schroeter








34














Conditions for Intuitive Expertise: A Failure to Disagree




D
Kahneman






G
Klein








American Psychologist




64
















A Defense of the Very Idea of Moral Deference Pessimism




M
Lewis








Philosophical Studies




177
















Putting the Trolley in Order: Experimental Philosophy and the Loop Case




S
M
Liao






A
Wiegmann






J
Alexander






G
Vong








Philosophical Psychology




25
















The Experience Machine and the Expertise Defense




G
Löhr








Philosophical Psychology




32


2
















The Epistemology of Thought Experiments: First Person versus Third Person Approaches, Midwest Studies in Philosophy




K
Ludwig








31














Expertise and Intuitions About Reference




E
Machery








Theoria




27


















E
Machery




Philosophy Within Its Proper Bounds


Oxford




Oxford University Press
















E
Machery






R
Mallon






S
Nichols






S
Stich








Semantics, Cross-Cultural Style






92














Philosophical Expertise, Philosophy Compass




J
Nado








9














Moral Responsibility and Determinism: The Cognitive Science of Folk Intuitions




S
Nichols






J
Knobe








41




Noûs












10.1126/science.aac4716>


349/6251








Estimating the Reproducibility of Psychological Science
















Prolific.ac-A Subject Pool for Online Experiments




S
Palan






C
Schitter








Journal of Behavioral and Experimental Finance




17
















Influence of Wording and Framing Effects on Moral Intuitions




L
Petrinovich






P
O'neill








Ethology and Sociobiology




17
















Not Lost in Translation: Successfully Replicating Prospect Theory in 19 Countries [Preprint], Open Science Framework




K
Ruggeri






S
Alí






M
L
Berge




10.31219/osf.io/2nyd6>






















S
Schindler






P
Saint-Germier








Unpublished Manuscript. Philosophical Expertise Put to the Test








Persistent Bias in Expert Judgments About Free Will and Moral Responsibility: A Test of the Expertise Defense




E
Schulz






E
Cokely






A
Feltz








Consciousness and Cognition




20


















E
Schwitzgebel






F
Cushman




Moral Reasoning? Order Effects on Moral Judgment in Professional Philosophers and Non-Philosophers, Mind & Language






27














Philosophers' Biased Judgments Persist Despite Training, Expertise and Reflection




E
Schwitzgebel






F
Cushman








Cognition




141
















Two Conceptions of Subjective Experience




J
Sytsma






E
Machery








Philosophical Studies




151


2
















Mental Accounting and Consumer Choice




R
Thaler








Marketing Science




4
















A Defense of Abortion




J
J
Thomson








Philosophy & Public Affairs




1


1
















The Trolley Problem




J
J
Thomson








The Yale Law Journal




94
















Moral Intuitions: Are Philosophers Experts?




K
Tobia






W
Buckwalter






S
Stich








Philosophical Psychology




26
















Cleanliness is Next to Morality, Even for Philosophers




K
Tobia






G
Chapman






S
Stich








Journal of Consciousness Studies




20


11
















The Framing of Decisions and the Psychology of Choice




A
Tversky






D
Kahneman








Science




211
















How to Challenge Intuitions Empirically Without Risking Skepticism, Midwest Studies in Philosophy




J
M
Weinberg








31














The Methodological Necessity of Experimental Philosophy, Discipline Filosofiche




J
M
Weinberg








15














Are Philosophers Expert Intuiters?




J
M
Weinberg






C
Gonnerman






C
Buckner






J
Alexander








Philosophical Psychology




23
















Intuitive Expertise and Irrelevant Options




A
Wiegmann






J
Horvath






K
Meyer








Oxford Studies in Experimental Philosophy




3
















Transfer Effects Between Moral Dilemmas: A Causal Model Theory, Cognition




A
Wiegmann






M
R
Waldmann








131














Philosophical Expertise and the Burden of Proof, Metaphilosophy




T
Williamson








42















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]