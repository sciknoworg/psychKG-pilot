You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



SIMULATION CHANGES CHOICE 3


General Audience Summary
People mentally project themselves into the imagined future, pre-living events that might or might not actually happen. Such future thinking comprises a good portion of people's everyday, or naturally-occurring, thoughts. Can mentally simulating imagined futures change the actual future, or do these simulations merely pass time until the actual future arrives? These studies were designed to test whether people who simulate an option are more likely to choose that option. First, we surveyed adults about their upcoming personal decisions. When we followed up one week later, participants were more likely to choose the option(s) they naturally simulated more. What if people were directed to imagine choosing a particular option, rather than letting simulation play out naturally? Would choice still favor the simulated option(s)? In our next studies, people imagined experiencing one option before choosing between two options. Simulation led people to choose the imagined option more than the unimagined one. This was the case for multiple decision types: adults' hypothetical personal decisions, college students' actual snack decisions, and adults' actual online video decisions. If simulation has the power to change the choices people make in the real world, policy makers and practitioners could direct people to simulate-and ultimately choose-"better" futures. Psychotherapists already use imagery-based methods with clients to help them access past memories and process current emotions; our studies suggest that imagining a possible future could be an effective technique for psychotherapists to help clients make decisions. One caveat is that imagining negative options could still lead people to choose those options. Practitioners and policy makers should be aware of how their own future simulations could polarize their decisions toward one option. It is still unclear whether simulating multiple options or imagining other people's futures affects decision-making, which is especially relevant for policymaking contexts.


SIMULATION CHANGES CHOICE 4
People face countless decisions each day, from the mundane to the meaningful: what to eat, where to vacation, whom to marry. These decisions can be complex, involving multiple options, each with multiple relevant features. Personal decisions do not always have a correct answer, their options cannot be compared side-by-side, and their resolutions have lasting implications for one's future. Thus, people spend significant time and energy playing out future options using a process called episodic simulation. We propose that these everyday, naturally-occurring, future-oriented simulations are not merely epiphenomenal; instead, they can drive decisions.


Thinking About the Future
Future thinking is pervasive. People think about the future once every two to four minutes 
(Gardner and Ascoli, 2015)
, reporting as many as one hundred future-oriented thoughts per day 
(D'Argembeau et al., 2011)
. At least 30% of spontaneous thoughts are future-oriented 
(Andrews-Hanna et al., 2010)
, about two times the prevalence of past-oriented spontaneous thoughts 
(Branch & Zickar, 2021;
Busby Grant & Walsh, 2016;
Jason, et al., 1989;
Smallwood & Schooler, 2015)
. Future thoughts focus on current concerns and serve important planning, goal-setting, and decision-making functions 
(Berntsen, 2019;
Cole & Berntsen, 2016;
Hallford & D'Argembeau, 2022;
Klinger, Barta, & Maxeiner, 1980)
. Approximately 18% of future thoughts are about decisions 
(D'Argembeau et al., 2011)
. These naturally occurring simulations could be a byproduct of the decision-making experience with no causal effect on behavior. Yet, they could also play an active role in shaping one's decisions. Can thinking about the future actually influence the future?
The process of episodic simulation involves constructing detailed mental scenes and imagining experiencing specific possible events 
(Schacter et al., , 2008
. People essentially pre-live an event they have not yet experienced by activating episodic details, recombined into novel future events 
Schacter, Benoit, & Szpunar, 2017)
. Simulating future events is therefore SIMULATION CHANGES CHOICE 5 remarkably similar to remembering past events; both require episodic activation and recombination 
(Addis, Wong, & Schacter, 2007;
Spreng, Mar, & Kim, 2009;
Yeshurun, Nguyen, & Hasson, 2021)
.
Mental imagery plays a central role in episodic simulation. Future thinking heavily implicates the brain's visuo-oculomotor system, yielding a predominantly visual mental representation that people experience as vividness 
(Conti & Irish, 2021)
. Spatial imagery helps to construct a rich, detailed, threedimensional setting for the simulated event, while object imagery contributes to the emotional intensity of the simulation 
(Aydin, 2018;
Byrne, Becker, & Burgess, 2009;
Wiebels et al., 2020)
. Repeated simulation of a future event allows for quicker reconstruction and results in increasingly detailed and elaborate representations 
(Wiebels et al., 2020)
. Notably, temporal orientation-the sense of when an event occurs-is not inherently part of the content of episodic simulations 
(Mahr, Greene, & Schacter, 2022
), suggesting that these representations focus more on the vividness of imagined experiences than on their temporal context. Episodic simulation can shape judgments, intentions, and behaviors. Simulating a future event increases the perceived plausibility of the simulated event 
(De Brigard et al., 2013;
). For instance, imagining being in a car accident is associated with stronger expectations that a car accident will occur 
(Gregory, Burroughs, & Ainslie, 1985)
. Imagining helping increases prosocial intentions and behavior 
(Gaesser & Fowler, 2020;
Gaesser et al., 2018;
Gaesser et al., 2019;
Gaesser & Schacter, 2014)
. Similarly, consumers who simulate using a product not only feel more favorably toward it but also are more likely to purchase the product, even weeks later 
(Gregory, Cialdini, & Carpenter, 1982;
Petrova & Cialdini, 2008)
. Simulating spending money reduces temporal discounting, helping people opt for larger, long-term rewards over smaller, more immediate ones 
(Ballance et al., 2022;
Benoit et al., 2011;
Bulley et al., 2019;
Bulley & Schacter, 2020)
. These findings suggest that future thoughts are likely not toothless, internal chatter; they might impact how people make decisions in their day-to-day lives.


SIMULATION CHANGES CHOICE 6


The Role of Simulation in Decision-Making
If humans were purely rational, there would be little need to imagine the future to make decisions; one could simply analyze the options on all relevant features, weigh the importance of each feature, then choose the optimal option. For example, how might one pick a new apartment?
Apartments have many attributes, including size, cost, and commute time. People instructed to approach apartment selection analytically sought information one attribute at a time, compared across all apartments, and accumulated roughly equal amounts of information about each apartment 
(McGill & Anand, 1989
). Yet, for many personal decisions, too many options exist to consider each fully, and multiple options can be "optimal" in qualitatively different ways 
(Johnson et al., 2022)
.
When left to their own devices, people make decisions that appear less-than-rational; they are risk-averse, weighing negative outcomes over positive ones, and myopic, weighing near outcomes over far ones 
(Kahneman & Tversky, 1984)
. When making decisions, people spontaneously use mental images-such as those generated during episodic simulation 
(Śmieja, Zaleskiewicz, Sobkow, & Traczyk, 2023)
. Such mental images serve as a proxy for information that people are unable to acquire directly 
(Blaisdell, 2019)
. By using simulation to gain information, however, people might inadvertently bias their choices.
When using mental imagery to make decisions, people are more likely to seek out information about a few select options before choosing one 
(McGill and Anand, 1989)
. When picking an apartment, imagery led people to think holistically, collecting all attributes for one apartment before moving on to the next. Gathering information in this way makes it easier to conjure an image of an apartment. This approach, however, led people to ignore some apartment options entirely. Why not create images for all apartments and then choose the best? The imagery approach may prioritize efficiency; once the mental image meets threshold, there is no need to look at another. For real-life decisions with non-finite sets of options and different information about each, efficiency is especially necessary.


SIMULATION CHANGES CHOICE 7
Naturalistic decision-making often elicits episodic simulation. According to the recognitionprimed decision model, people use simulation when they need to make efficient decisions and have prior experience 
(Klein, 1993
(Klein, , 1997
(Klein, , 2005
Klein & Crandall, 2018)
. Experts under constraints to decide quickly begin by activating actions they used in similar situations. If there is uncertainty about the first option, the decision-maker simulates possible outcomes, and if necessary, generates a second option.
Other work likewise suggests that decision-makers initially consider the best, most likely, or most accessible options from previous experience, then deliberate among them 
(Phillips et al., 2019)
. These theories both suggest that simulation directs people to think about options they are already likely to choose, increasing the efficiency of the decision-making process.
Query theory likewise posits that decision-makers start with the most viable option, but retrieving reasons from memory changes the choices people make 
(Johnson et al., 2007;
Weber & Johnson, 2011)
. The mere act of considering the first option leads people to stick with the status quo and inhibits accessibility of alternatives. A candidate mechanism for this inhibition of alternatives is retrieval-induced forgetting 
(Anderson et al., 1994;
Murayama et al., 2014)
. In list-learning tasks, retrieving an item from memory (e.g., "apple") increases its accessibility while decreasing the accessibility of categorically related items (e.g., "orange") relative to unrelated ones (e.g., "hammer"). In the decision-making context, the reasons for and against different options are related, so the act of recalling reasons in favor of one option makes it more difficult to think of reasons in favor of another option.
We propose that simulation, like retrieval, might actively shape decision-making: imagining an option should make it more likely to be chosen. Simulating an option might make it easier to continue simulating that option over harder-to-imagine alternatives. Indeed, retrieval-induced forgetting impacts personal memories, such that people find it harder to recall details of an experience if it is related to a recently recalled memory 
(Hauer & Wessel, 2006)
. Episodic simulation relies on similar neurocognitive SIMULATION CHANGES CHOICE 8 processes as episodic memory 
Schacter et al., 2008)
; thus, selective simulation of one option might make simulating other options more difficult.
Simulation makes the imagined future feel more plausible  and shapes choices in controlled scenarios 
(Petrova & Cialdini, 2008)
. Whereas prior research used scripted simulations 
(Gregory et al., 1982)
, our approach centers naturalistic, self-guided simulations applied to day-to-day decisions, demonstrating this effect in a more ecologically valid way.


Current Studies
Does naturalistic simulation change choice or is it just a byproduct of the choice people would otherwise make? Six studies tested whether thinking about one option over others changes the decisions people make. In each study, we examined how participant-generated simulation of a decision option influenced its likelihood of being chosen. Studies 1 and 2 measured the impact of simulation on participants' personal decisions. Studies 3 and 4 measured its impact on controlled decisions in the laboratory. We instructed participants to use the mental imagery component of simulation to imagine experiencing one of two options. In all studies, we hypothesized that participants would be more likely to choose the option they simulated over the option they did not.


Study 1: Thinking about Personal Decisions
Study 1 assessed the relation between simulation and decision-making in people's daily lives.
Participants reported an upcoming decision and the options they were considering. We collected naturalistic data across two weeks, measuring how much people thought about each option and how likely they would be to choose each option. We hypothesize that everyday simulation shapes decisionmaking, such that the more a person simulates an option, the more likely they will choose it later.


SIMULATION CHANGES CHOICE 9


Method


Participants
Participants (N = 170) were recruited to participate in a two-part weeklong study about decisions through the online recruitment platform TurkPrime, now CloudResearch. Based on exploratory findings from Study 2a, we set a target sample size of 155, which offers 80% power to detect a correlation of r = .22 between everyday simulation and likelihood to choose at a significance level of .05.
Participants (n = 5) were excluded based on the preregistered exclusion criterion of providing nonsense text responses to the decision or not completing the follow-up at Time 2 (n = 16), leaving a final sample size of 149 (age 18-72, M = 37.62; 72 female, 75 male, 2 non-binary; 79% White, 7% Asian, 6% Black or African American, 3% Hispanic or Latino, 5% Mixed race or Other).
Participants in this and all subsequent studies provided informed consent and were compensated in a manner approved by the Institutional Review Board of Princeton University. Preregistrations for this and all other studies can be found on OSF (https://osf.io/2mf74/?view_only=6b717f1e2b5742cda8336a9fd327d89d), with the exception of Study 2a.


Procedure
Participants completed two questionnaires about an upcoming decision and the options they were considering for the decision: an initial questionnaire (Time 1) and a follow-up one week later (Time 2). At both times, participants rated their likelihood of choosing each option and their everyday thinking and talking about each option. We assessed the extent to which these naturally-occurring simulations related to participants' likelihood of choosing each option.


Time 1.
The Decision. In the initial questionnaire, participants first reported a decision they anticipated making in more than one week's time. They provided a brief title for the decision, which we used to SIMULATION CHANGES CHOICE 10 remind them of the particular decision at later points in the study. As exploratory measures, participants reported the expected timing of the decision (with eight options ranging from "less than one week from now" to "more than 5 years from now"), the importance of the decision from 0 ("Not at all") to 10 ("Extremely") and the amount they had thought and talked about the decision over the past week from 0 ("Not at all") to 10 ("All the time"). Decision Options. After reporting on the decision overall, participants listed up to five options they were considering for their decision, giving each a brief title that was used to remind them of that option later on. They then completed the following ratings about each option. The options were presented in a random order for all rating scales.
Likelihood to Choose. Participants rated how likely they would be to choose each option if they were to make the decision that day. For each option, likelihood to choose was rated on a scale of 0 to 100 percent. These ratings were made independently, so the sum of a person's ratings for all their options would not necessarily sum to 100. This value was used to calculate our primary measure of interest: change in likelihood to choose from Time 1 to Time 2. Everyday Simulation. Next, participants reported how much they thought about (i.e., mentally simulated) and talked about (i.e., socially simulated) each option over the past week using two separate rating scales from 0 ("Not at all)" to 10 ("All the time"). The sum of a participant's mental and social simulation ratings was taken as the overall everyday simulation score for that option.
Option Valence. Participants rated the positive and negative valence of each option. Option valence was rated on separate scales for positive and negative valence from 0 ("Not at all") to 10 ("Extremely"). These were combined into an overall valence score for each option by reverse scoring the negative rating and summing the two (positive rating + (10 -negative rating)). We used this to test whether the effect of simulation depended on initial feelings toward the option-making negative SIMULATION CHANGES CHOICE 11 options less appealing over time and positive options more appealing)-or simply made all options more likely.


Time 2.
The Decision. At the beginning of the follow-up questionnaire, participants were prompted with the decision title they provided during the first part of the study. They re-rated this decision using all the same scales collected at Time 1, including the expected timing of the decision (with an additional option to indicate that they had already made the decision), the importance of the decision, and how much they had thought/talked about the decision over the past week. At Time 1, we specifically asked participants for decisions that were more than one week away, so that at Time 2 they would not yet have made the decision and would still be considering multiple options. Participants who had already made the decision at Time 2 were not included in the main analyses. For exploratory purposes they were asked to select the option they chose from a list of all the options they provided at Time 1 plus an "Other: specify____" option and rate how satisfied they were with the outcome of their decision from 0 ("Not at all") to 10 ("Extremely").
Decision Options. Participants were prompted with each of the option titles they provided on the initial questionnaire. Participants then completed the same ratings of each option as in Time 1, allowing us to compare ratings across time.
Likelihood to Choose. For each option, participants rated their likelihood of choosing each option if they were to make the decision that day. Our primary dependent variable was change in likelihood to choose from Time 1 to Time 2, computed as the difference between Time 1 and Time 2 ratings for each option.
Everyday Simulation. Participants rated how much they thought and talked about the decision over the past week, which was combined into an everyday simulation score by averaging these two items. Change in everyday simulation was computed as the difference between the Time 1 and Time 2 SIMULATION CHANGES CHOICE 12 simulation scores for each option. This was our primary predictor variable. We see parallel effects when running all analyses on each component of the combined score (see Supplement).
Option Valence. Participants rated the valence of each option. Positive and negative ratings were combined into an overall valence score by reverse scoring the negative rating and summing the two. Option valence at Time 2 was included as an exploratory outcome measure.


Results
These and all subsequent analyses were conducted in R version 4.2.3. For linear mixed-effects models, we used the lme4 package version 1.1-32 
(Bates, Mächler, Bolker, & Walker, 2015)
 and report the best-fitting random effects structure supported by the data, per recommended guidelines 
(Barr et al., 2013;
Matuschek et al., 2017;
Wright, 2017)
. We report all primary and preregistered analyses testing the overall effect of simulation on choice ratings and behavior in the Results section for each study. See Supplement for additional exploratory analyses of how the reported effects differ according to characteristics of the participants (e.g., age), decisions (e.g., importance), and simulations (e.g., vividness). Supplementary results for this and all subsequent studies are available at:
https://osf.io/2mf74/?view_only=6b717f1e2b5742cda8336a9fd327d89d.
The Supplement also contains more information about the content of the personal decisions reported in Studies 1 and 2. People reported making decisions on a wide range of issues, which could be broadly categorized into the following themes: "Travel", "Consumer", "Work", "Financial", "Health", "Relationships", "Food", "Household", "Moving", and "Miscellaneous". The most common words used in participants' decision text for Study 1 were: "new", "job", "buy", "car", and "vacation".


Everyday Simulation Predicts Changes in Choice Ratings
Our primary preregistered analysis tested whether people became more likely to choose options they thought and talked about more over the course of one week. We ran a linear mixed effects model testing whether increases in everyday simulation of one option over one week predicted increases in the SIMULATION CHANGES CHOICE 13 likelihood of choosing that option. Each participant reported on multiple options, so to account for the nested structure in our data we included a random intercept for participant. As expected, we found that  Note. Results from Study 1. Panel (a) shows the change in everyday simulation from Time 1 to Time 2 predicting change in likelihood to choose rating from Time 1 to Time 2 for each of the options provided by the participants. Panel (b) shows the initial likelihood of choosing the option at Time 1 predicting the degree of everyday simulation reported at Time 2. Confidence bands reflect 95% confidence intervals.
We next tested whether simulation predicts choice likelihood differently for options that people initially like vs. do not like. On the one hand, simulation might uniformly increase the likelihood to choose an option. On the other hand, simulation might only increase the likelihood to choose an option that a person already feels positively toward and decrease one's likelihood of choosing a more negative option. We conducted a second preregistered analysis using a linear mixed-effects model to test whether the interaction between an option's initial valence rating and the change in its everyday simulation score predicted the change in its likelihood-to-choose rating. Again, we included participant as a random intercept to account for the repeated measures in our data. There was a small, but significant interaction effect between initial valence and change in everyday simulation on change in likelihood to choose rating, b = 0.15 [0.00, 0.31], β = .08 [0.00, 0.16], t(508.54) = 1.98, p = .048, offering preliminary support that simulation might have a stronger effect on options people initially feel good about. That said, the direction of the effect remained the same regardless of the initial valence of the option. That is, people became more, not less, likely to choose options they simulated more, even for initially negative options.


Initial Choice Likelihood Predicts Subsequent Everyday Simulation
We were also interested in which options people naturally simulated over the course of the week, with the idea that choice likelihood and simulation might be mutually reinforcing. We hypothesized that over the course of the week people would engage in more everyday simulation for options that they were initially more likely to choose. Our next preregistered analysis tested this hypothesis using a linear mixed-effects model to assess the cross-time association between the likelihood of choosing an option at Time 1 and the amount of simulation the participant reported for that option at Time 2, with participant as a random intercept. As predicted, participants reported significantly more simulation at Time 2 for options that they were initially more likely to choose at Time 


SIMULATION CHANGES CHOICE 15


Discussion
These findings offer preliminary support for the hypothesis that simulation shapes decisionmaking. Everyday simulation might be part of a feedback loop whereby people naturally simulate options they are already likely to choose, and additional simulation further increases their likelihood of choosing simulated options. These findings, however, are correlational. Study 2 tests the possibility that simulation's role in decision-making is causal.


Studies 2a & 2b: Simulating Personal Decision Options
Simulating an option could increase its choice likelihood. However, it is also possible that simulation is epiphenomenal: people think about the option they ultimately choose regardless. Studies 2a and 2b tested the causal impact of simulation on decision-making. Participants directly simulated one of two options they were considering for a personal decision. We expected participants would be more likely to choose the simulated option. In Study 2a, we followed up with participants one week later.


Method


Participants
The samples for Studies 2a and 2b were recruited on Mechanical Turk via the TurkPrime (now CloudResearch) platform and were compensated for their participation. Participants who had participated in Study 2a were not eligible to participate in Study 2b.
Study 2a. Participants (N = 371) were recruited to participate in a two-part weeklong online study about decisions. We collected data from the first 20 participants before collecting the remainder of the sample in order to write our primary analysis scripts and test that the survey was working Mixed race or Other).


Procedure
In both Studies 2a and 2b, participants completed a questionnaire in which they were instructed to simulate the experience of having chosen one of two options they were considering about an upcoming decision. Participants rated their likelihood of choosing each options both before and after the simulation. We assessed the extent to which participants became more likely to choose the simulated option compared to the non-simulated option. Unless otherwise noted, each step of the procedure listed below applies to both Studies 2a and 2b, and the steps of the procedure are listed in the order they occurred. In Study 2a, we also followed up one week later with an additional questionnaire to see which option, if any, they ultimately chose in their daily life. The hypotheses and analyses for Study 2b were preregistered based on the exploratory results of Study 2a.


Pre-simulation.
The Decision. Participants were instructed to think of a decision they anticipated making within the next week that had at least two options they were considering. First, they provided a brief title for the upcoming decision and reported when they expected to make the decision (in "days from now") as well as how important the decision was for their life, from 0 ("Not at all important") to 10 ("Extremely important").
Decision Options. After reporting on the decision overall, participants provided brief titles for exactly two options they were considering for their upcoming decision. They then completed the following ratings about each option. The options were presented in a random order for all rating scales.
Likelihood to Choose. As a baseline measure of our primary variable of interest, participants rated how likely they would be to choose each option if they were to make the decision that day. For each option, likelihood to choose was rated on a scale of 0 to 100 percent. These ratings were made independently and on a separate page for each option. In addition to assessing the likelihood-to-choose ratings separately for each option, we also computed a polarization score for each participant by taking the absolute value of the difference between the likelihood-to-choose ratings for the two options.
Option Valence. Participants also rated how positively and negatively they felt about each option, on two separate scales from 0 ("Not at all") to 10 ("Extremely").


Simulation.
Option Simulation. After generating and rating the two options, participants simulated having already made their decision and choosing one option. They were randomly assigned to either simulate the first or second option they listed. The simulation instructions were as follows:  
Meyer, Hershfield, Waytz, Mildner, and Tamir (2019)
. Each item was rated on a Likert-type scale ranging from 1 ("Not at all") to 10 ("Extremely"), and an overall vividness score was computed as the mean rating (after reverse scoring) on the five items.
Now


Post-simulation.
Likelihood to Choose. After completing their simulation, participants again rated how likely they would be to choose each option if they were to make the decision that day. Again, the two options were presented in a random order and on separate pages. As in Study 1, our primary dependent variable was change in likelihood to choose from pre-to post-simulation, computed as the difference between preand post-simulation ratings for each option. We computed polarization as the absolute difference between the likelihood-to-choose ratings for the two options.
Option Valence. Lastly, participants re-rated the positive and negative valence of each option using the same two scales as the pre-simulation rating. These were combined into an overall valence score for each option by reverse scoring the negative rating and summing the two (positive rating + (10negative rating)).


One-Week Follow-up (Study 2a only).
The Decision. On a separate questionnaire administered one week after the initial questionnaire, participants were prompted with their decision title from the initial questionnaire and indicated whether or not they had already made the decision. Participants who had made the decision SIMULATION CHANGES CHOICE 19 (Deciders) were asked a different set of questions about their decision than those who had not made the decision (Non-deciders).
Decision Outcomes. For deciders, our outcome variable was which option they chose.
Participants who had already made the decision were asked which option they chose (from the two option titles they provided on the initial questionnaire plus an "Other: specify____" option). As exploratory measures, deciders also reported when they made the decision by selecting from a list of dates and rated how satisfied they were with the outcome of their decision on a scale from 0 ("Not at all satisfied") to 10 ("Extremely satisfied"). This information allowed us to explore whether simulation was more impactful for decisions made in the first few days following the initial survey compared to decisions made later in the week.
For non-deciders, our outcome variable was which option they would hypothetically choose in the future. First, non-deciders indicated whether or not they still intended to make the decision. Then, regardless of their intention, participants selected the option they would choose if they were to make the decision that day (from a list of their two option titles and an "Other, specify" option). This information allowed us to differentiate possible effects of simulation on non-deciders' hypothetical choices as compared to deciders' actual choices, and to explore counterfactual choices (i.e., hypothetical choice data for non-deciders who no longer intended to make the decision) from plausible future choices (i.e., hypothetical choice data for non-deciders who still intended to make the decision).
Decision Importance. Both deciders and non-deciders then rated how important the decision was for their life on a scale from 0 ("Not at all important") to 10 ("Extremely important"). using a single item ranging from 0 ("Not at all") to 10 ("All the time"). The options were presented in a random order for this and all subsequent ratings.
Option Valence. Lastly, participants rated the positive and negative valence of each option on two separate scales ranging from 0 ("Not at all") to 10 ("Extremely").


Results


Directed Simulation Polarizes Choice Ratings in Favor of the Simulated Option
In Study 2a, our primary analysis explored whether simulation increased participants' likelihoodto-choose ratings for the option they were randomly assigned to simulate. We used a linear mixedeffects model predicting the change in likelihood-to-choose ratings for each option from whether or not  
Figure 2a
).
To explore whether simulation enhanced the simulated option, inhibited the non-simulated option, or both, we followed up our primary analysis with two one-tailed, one-sample t-tests comparing the observed change in likelihood-to-choose ratings to zero, separately for each option. Simulation significantly increased likelihood-to-choose ratings for the simulated option, t(339) = 1.89, p = .030, d = .
10, and significantly decreased likelihood-to-choose ratings for the non-simulated option, t(339) = -2.95, p = .002, d = .16, consistent with an inhibition-based polarization effect. Based on these findings, we preregistered hypotheses and analyses for Study 2b.
Study 2b supported our primary hypothesis, replicating the finding that simulation increased participants' likelihood-to-choose ratings for the simulated option relative to the non-simulated option SIMULATION CHANGES CHOICE


21
(see 
Figure 2b
). Using the same mixed-model analysis as Study 2a, we found a greater change in likelihood-to-choose ratings for the simulated option (Msim = 1.22, SDsim = 18.10, 95% CI 
[-1.16, 3.62
 1.01, p = .156, d = .07, but it did significantly decrease the likelihood to choose the non-simulated option, t(222) = -1.91, p = .029, d = .13, again consistent with an inhibition-based account. These results offer evidence that episodic simulation leads to the polarization of decision options, such that the simulated option is more likely to be chosen relative to the non-simulated option. Note. Results from Study 2a (panel a) and 2b (panel b). Both panels show the change in likelihood-tochoose ratings from pre-to post-simulation for the simulated option (blue) compared to the nonsimulated option (gray). The dotted line represents zero change or no effect of simulation on the likelihood to choose a given option. The mean change in likelihood to choose is indicated by the black dot. Error bars represent 95% confidence intervals.
As in Study 1, we were also interested in whether the change in likelihood to choose an option from before to after the simulation depended on the initial valence of the option. For both Studies 2a and 2b, we conducted a preregistered analysis using a linear mixed-effects model to test whether the interaction between an option's initial valence rating and whether or not the option was simulated 


Everyday Simulation Predicts Actual and Hypothetical Choice
In Study 2a, we followed up with participants to assess whether option simulation-both our We tested how simulation impacted both actual decisions in deciders and hypothetical decisions in non-deciders. For these analyses, we included deciders (n = 222) and non-deciders (n = 36) who chose one of the two options they provided on the initial survey and not a new option. First, we tested whether deciders chose the simulated option more often than the non-simulated option. We used a chisquare goodness-of-fit test to determine whether the observed number of participants who chose the simulated option was higher than the expected number due to chance, that is, 50% of the participants in each analysis. Our one-time simulation manipulation did not affect deciders' actual choices, as reported one week later, χ 2 (1, N = 222) = 0.29, p = .59, Cohen's w = .04 [.00, .17]. We similarly tested whether non-deciders, even though they had not actually made the decision, would choose the simulated option more than the non-simulated option when faced with the hypothetical choice between the two options.
Again, our one-time simulation manipulation did not affect participants' hypothetical choice behavior one week later, χ 2 (1, N = 36) = 0.11, p = .74, Cohen's w = .06 
[.01, .39
]. In both cases, the proportion of participants who selected the option they simulated was around 47% (106 out of 222 for deciders; 17 out of 36 for non-deciders).
We did, however, find that everyday simulation predicted participants' choice behavior. Study 2a was also the basis of Study 1. We used the longitudinal data in Study 2a to explore whether everyday simulation predicted likelihood-to-choose ratings over the course of the week. First, we explored whether increases in everyday simulation from Time 1 to Time 2 predicted corresponding changes in choice ratings one week later. As in Study 1, we ran a linear mixed-effects model predicting changes in likelihood-to-choose ratings from changes in simulation ratings. Each participant reported on two options, so to account for the nested structure in the data, we included a random intercept for participant. As in Study 1, we found that simulation was significantly related to the likelihood of choosing, b = 4.04 [3.18, 4.89], β = .39 [ 0.30, 0.47], t(510.65) = 9.22, p < .001. Naturally simulating an option more over time went hand-in-hand with becoming more likely to choose that option, and vice versa; less simulated options became less likely to be chosen.
We further tested whether this everyday simulation predicted deciders' actual choice behavior.
Specifically, we conducted a mixed binomial logistic regression predicting whether or not an option was chosen from its simulation rating, with participant included as a random intercept to account for repeated measures. Indeed, people were more likely to choose options that they naturally simulated SIMULATION CHANGES CHOICE 24 more over the course of the week, z = 5.86, p < .001, odds ratio = 1.24 [1.15, 1.33]. For every one-unit increase in simulation, people were 24% more likely to choose that option as opposed to the alternative.


Discussion
Study 2 demonstrated that simulation increased self-reported likelihood of choosing the simulated option relative to the non-simulated option. Although this brief manipulation did not alter choices one week later, the degree to which participants naturally simulated an option in their everyday lives did predict choice. Simulation also polarized options, making the simulated option more likely and the non-simulated option less likely to be chosen. Polarization could expedite decision-making by differentiating options and increasing choice certainty.


Study 3: Simulating Snack Options in the Lab
Studies 1 and 2 focused on decisions participants faced in their lives. These naturalistic decisions reflected a variety of initial preferences, and choice behavior could not be reliably confirmed. Study 3 resolved these issues with a controlled lab study using two novel but equally preferable snack options.
After simulating one of the snacks, participants chose a snack to take home. We hypothesized they would be more likely to choose the simulated snack.


Method


Participants
Thirty-four Princeton University students aged 18-22, M = 19.38; 7 male, 26 female, 1 nonbinary; 41% Asian, 29% White, 6% Black or African American, 6% Hispanic or Latinx, 18% Mixed race or
Other participated for course credit between February and March 2020. A power analysis for the chisquare test on the binary decision outcome based on the results of Study 2a yielded a target sample size with a lower bound of 88 (to detect a medium-sized effect, w = 0.3) and an upper bound of 197 (to detect a small-to medium-sized effect, w = 0.2) at a significance level of .05 with 80% power. Our preregistered stopping rule was to end data collection when the sample size reached 197 or on the last day of the semester (as long as data had been collected from at least 88 participants by that time). In March 2020, data collection was stopped early due to COVID-19 restrictions. Even though we did not meet our target sample size, we proceeded with analyses given that in-person data collection constraints would not allow for further data collection.


Materials
Snacks. Ten commercially available snacks with unique combinations of flavors, such as "Spicy Cherry Almonds" and "Butterfinger Popcorn," were selected from a set of 25 such snacks, according to ratings from a separate norming sample (see OSF for details of the norming study and a list of the snacks used). Color photographs of the snacks, 150 pixels in width for portrait-orientation images or 150 pixels in height for landscape-orientation images, were used in all survey materials when referring to the snacks. All ten snacks were presented in the pre-screening survey, but for the in-lab survey, only two snacks were presented to each participant, selected according to the participant's individual prescreening responses. Individually sized packages (M = 3.65 ounces, SD = 1.18) of the snacks were used at the end of the study when participants chose which snack, if any, to take.


Procedure
Pre-screening. Before being invited to participate in the lab study, prospective participants completed an online pre-screening survey in which they first reported any known food allergies.
Students who reported food allergies were thanked, debriefed, and not invited to participate further.
Those respondents who did not report any food allergies were then presented with a photo and description for each of the ten snacks one at a time and in a random order. For each snack, they indicated how much they would like to eat that snack on a scale from 1 ("Definitely would not like to eat this") to 7 ("Definitely would like to eat this") as well as whether or not they had eaten that snack before. See Supplement for the questionnaire used for pre-screening.


SIMULATION CHANGES CHOICE 26
Snack Matching. Experimenters used participant's pre-screening preference ratings to select a personalized pair of snacks for them to choose between during the lab session. Each participant was assigned two snacks that they rated equally on the pre-screening but had not eaten before. If there was more than one potential pair of snacks for a given participant, the experimenter selected the pair that was rated closest to the midpoint of the scale on the question measuring how much they would like to eat the snack. If there were more than two snacks with the same pre-screening preference rating, two snacks were selected based on how many packages we had left in the study materials. This was done to balance the number of times a particular snack item was presented across participants in the study, where possible. Participants were emailed an invitation to participate in the lab study after the experimenters had assigned them a pair of snacks.
Lab Survey. All testing took place individually in a small lab room with a single computer. When the participant arrived, the experimenter first confirmed that the participant had no known food allergies and had not previously eaten either of the two snack options chosen for them. The experimenter then left the room while the participant completed the survey portion of the study in a standard web browser.
Option Presentation. At the beginning of the survey, participants saw images of their two assigned snacks and were told that they would have the opportunity to take one of the two snacks home with them at the end of the study. Each participant was assigned a unique pair of snacks. The presentation order of the two snack images was randomized to ensure that some snacks were not systematically more likely to appear on one side of the screen.
Simulation. On the next screen, participants were randomly shown one of their two snacks and instructed to simulate the experience of eating that snack. The simulation instructions were as follows: Vividness. On a separate page, participants rated the vividness of their simulation using the same five items from Study 2 
(Meyer et al., 2019)
, with the only difference being that each item was rated on a Likert-type scale ranging from 1 ("Not at all") to 7 ("Extremely"). Again, an overall vividness score was computed as the mean rating (after reverse scoring) on the five items. After the simulation phase, we measured our primary outcome measures.
"
Like-to-Eat Ratings. Participants rated how much they would like to eat each of the two snacks (presented in a random order and on separate pages). Snack preference was assessed on the same scale used in the pre-screening, ranging from 1 ("Definitely would not like to eat this") to 7 ("Definitely would like to eat this").
Snack Choice. Participants made a binary choice on the computer screen indicating which snack they would like to take at the end of the experiment. The snacks were presented in a random order.


Snack Ratings.
As exploratory measures, participants also rated how excited they were to eat the chosen snack and how confident they were in their decision on Likert-type scales ranging from 1
("Not at all") to 7 ("Extremely").
Study Completion. Finally, participants completed the demographic information and notified the experimenter that they had completed the study. The final screen also showed the snack they had chosen earlier in the study and informed them that they could take the selected snack. When the experimenter returned to the room, the participant was offered a choice of either or neither of the two actual snack packages to take home with them and was then debriefed.


SIMULATION CHANGES CHOICE 28


Results


Directed simulation affects snack choice but not preference
In our primary preregistered analysis, we tested whether simulation affected participants' choice behavior. We ran a chi-square goodness-of-fit test on the observed frequency of participants who chose each snack, either simulated or non-simulated, compared to the expected chance frequency of 50% of participants choosing each snack. Participants were significantly more likely to choose the simulated snack (23 out of 34, or ~67%), χ 2 (1, N = 34) = 4.24, p = .04, Cohen's w = .35 
[.04, .69]
 
(Figure 3
).
Consistent with our hypothesis, simulating a novel snack option made participants more likely to actually choose that snack to take with them.
In our secondary preregistered analysis, we tested whether simulation impacted how much participants thought they would like to eat each snack. Recall that participants were matched with two snacks they had rated equally on the pre-screening survey, so, by design, the initial difference in like-toeat ratings was exactly zero. Thus, any difference in post-simulation like-to-eat ratings could be attributed to the simulation manipulation. The observed preference (Msim -Mnon = .41, 95% CI [-.15,
.98]) for the simulated snack (Msim = 4.41, SDsim = 1.35) compared to the non-simulated snack (Mnon = 4.00, SDnon = 1.33) was not significant, t(33) = 1.49, p = 0.15, d = .25. 


Discussion
Study 3 demonstrated that simulation impacts choice behavior, not just self-reported intentions.
People are more likely to choose-and take-a simulated snack over a non-simulated snack. Simulation did not, however, change participants' relative desire to eat each snack. This null result is difficult to interpret, given that Study 3 was underpowered. It is possible though that simulation affects choice without affecting evaluations such as excitement or enjoyment. We explore this possibility in Study 4.


Studies 4a & 4b: Simulating Video Options Online
Study 3 showed that simulation impacts choices between two equally preferred options. Study 4 aimed to replicate these findings in a larger sample with a new scenario: watching videos. Participants SIMULATION CHANGES CHOICE 30 simulated one of two videos based on its title and screenshot-similar to how one might select a video on YouTube-then chose a video. We compared choice behavior in the simulation condition to a control condition to rule out mental imagery (Study 4a) and priming (Study 4b) as explanations for the effect.
Participants also watched the chosen video, allowing us to explore how simulation affects decision evaluations.


Method


Participants
For both Study 4a and 4b, we aimed for a target sample size of 290 participants, 145 in the simulation condition and 145 in the control condition. A power analysis based on the results of Study 3 yielded a target sample size of 145 in the simulation condition to achieve 90% power at a significance level of .05 for the primary chi-square test of the proportion of participants choosing the simulated option. We aimed to recruit an equal number of participants in the control condition as well in order to conduct exploratory analyses comparing the two conditions. Participants who participated in Study 4a
were not eligible to participate in Study 4b.


Study 4a.
A total of 285 participants (aged 18-80, M = 26.86; 174 male, 110 female, 1 nonbinary; 78% White, 10% Hispanic or Latinx, 3% Asian, 3% Black or African American, 6% Mixed race or Other) were recruited online via the Prolific platform. Because the assignment to condition occurred when participants started the survey in Qualtrics while the participant count was determined by Prolific when participants finished the survey, there was a slight asymmetry in sample size between conditions, with a final sample of 140 participants in the control condition and 145 in the simulation condition. the online YouTube channel Great Big Story, were used as the two decision options in these studies.
Each video was approximately two and half minutes long (2:34 for Bottle Messages, 2:28 for Info King).
Screenshots of the two videos including their titles and length were provided at the beginning of the study and were used as cues for participants' simulations and decisions. Based on ratings from separate norming studies, the two selected videos were closely matched on the following criteria: how much participants reported wanting to watch the video based on the screenshot provided, how easy it would be to imagine the video based on the screenshot provided, how much participants actually liked watching the video, and how emotionally intense participants rated the video (see Supplement).


Procedure
The procedures for Study 4a and 4b were almost identical with the exception of their control conditions and some exploratory measures. Unless otherwise noted, each step of the procedure listed below applies to both studies, and the steps of the procedure are listed in the order they occurred.
Audio Test. For both Study 4a and Study 4b, participants first completed an audio test to ensure that they were able to hear the video later in the study. This audio test was also used to screen out potential bots and ensure participants were paying attention. Participants who did not pass the audio check were ineligible to continue the study.
Option Presentation. Prior to simulation, participants were presented with screenshots of the two video options side-by-side (counterbalanced which was on which side). They were told that later in the study they would choose one of the videos and watch that video. Unlike in the previous studies, participants did not rate the video options prior to simulation, ensuring that the simulation task and post-simulation choices were not influenced by prior consideration of the options.


SIMULATION CHANGES CHOICE 32
Task Instructions. All participants were then instructed that they would complete an "imagination task" before making their video choice. In both studies, half of the participants were assigned to the simulation condition and the other half were assigned to the control condition. In both conditions, participants typed their response to their respective prompt into a blank text box and were free to move onto the next page whenever they were done typing. The amount of time spent on the task and the content of the text were recorded for all participants.
Simulation Condition. In both Study 4a and 4b, participants in the simulation condition were randomly presented with one of the two video screenshots and asked to think about and describe what it would be like to watch that video by typing into a text box. To ensure participants were simulating episodically rather than just thinking about the video, they were explicitly instructed to "include as much detail as possible, including what the video looks, sounds, and feels like." The simulation procedure was identical for both Study 4a and 4b, although the two studies had different procedures for their respective control conditions, as described below.
Control Conditions. In Study 4a, participants assigned to the control condition completed an imagery control. These participants were presented with an optical illusion and asked to describe their experience of seeing the illusion. This task has been used as a control task in previous simulation research because it requires participants to describe an imagery-based experience in words, without the additional components of self-projection and mental time travel involved in the process of episodic simulation 
(Meyer, Hershfield, Waytz, Mildner, & Tamir, 2019)
. To ensure the sensory nature of describing the illusion was as comparable as possible to the simulation condition, we further instructed participants to "include as much detail as possible, including what the image looks, sounds, and feels like."
In Study 4b, participants assigned to the control condition completed a description control task.
This task was designed to account for the possible choice-enhancing effect of additional exposure to one of the options. Participants in this condition described one of the screenshots used to represent the video options. Just like in the simulation condition, control participants were shown one of the two screenshots at random; however, instead of imagining the experience of watching the video, they were instructed to look carefully at the screenshot and describe only what was present in the image itself.
These instructions were designed to prevent unintended simulation, and participants were further asked to "include as much detail as possible, including the objects, colors, and shapes that you see in the image."
Vividness. Participants used the same vividness items from Study 1 
(Meyer et al., 2019)
 to rate the vividness of their experience on a scale from 1 ("Not at all") to 7 ("Extremely") during the "imagination task" in all conditions.
Video choice. As our primary outcome of interest, participants then decided which of the two videos to watch by selecting one of the two screenshots to indicate their choice. Again, the two screenshots were presented side-by-side, and the order of the screenshots was counterbalanced across participants. As a secondary decision measure, we also recorded the amount of time it took participants to make their decision.
Pre-watch Ratings. After making their decision, but prior to watching the video, participants rated how excited they were to watch the chosen video, from 1 ("Not at all") to 7 ("Extremely"), and how certain they were that they chose the better video, from 1 ("Not at all") to 7 ("Extremely"). These ratings were included to explore possible differences between participants whose expectations matched their enjoyment of the video and those whose expectations did not match.
Video Experience. Participants then watched their chosen video. The video was presented as a YouTube video embedded in the online questionnaire browser window. Although the video controls were accessible, participants were instructed to watch the video once and only once and to let the video play through without pausing. The page was set to only allow the participant to advance the screen after SIMULATION CHANGES CHOICE 34 the amount of time corresponding to the exact length of the video. We recorded the amount of time participants spent on the video watching page.
Post-watch Ratings. After watching the video, participants rated their enjoyment of the video from 1 ("Did not enjoy it at all") to 7 ("Extremely enjoyed it"), how certain they were that they chose the better video from 1 ("Not at all certain") to 7 ("Extremely certain"), and how much they regretted their choice from 1 ("Do not regret it at all") to 7 ("Extremely regret it"). We used these ratings to explore whether simulation affected people's actual experience of watching the video.


Rumination-Reflection Questionnaire (Study 4b).
In Study 4b, we also included an exploratory measure of individual differences in the way participants tend to think about themselves. Specifically, the Rumination-Reflection Questionnaire assesses the degree to which self-oriented thought is focused on threats and potential losses (i.e., rumination) or driven by curiosity and general interest in the self 
(i.e., reflection;
Trapnell & Campbell, 1999)
.
Interest in Non-chosen Video. Finally, as a way to assess the possible effect of simulation on evaluation of the non-simulated option, we asked participants how interested they were in watching the video they did not choose from 1 ("Not at all interested") to 7 ("Extremely interested").


Results


Simulation Affects Video Choice
To replicate the analysis from Study 3, our primary preregistered analysis for Study 4a tested whether simulation made people more likely to actually choose to watch the video they simulated. For participants in the simulation condition, we ran a chi-square goodness-of-fit test on the observed frequencies of people who chose either the simulated or the non-simulated video. We also conducted this analysis for the simulation condition in Study 4b for replication purposes. Replicating our finding from Study 3, participants in the simulation condition were significantly more likely to choose the simulated video than would be expected by chance, in  
(Figure 3)
.
In Study 4b, we also included a control condition in which participants described the screenshot representing one of the video options, rather than fully simulating the experience of watching the video.
This design allowed for a more rigorous test comparing the percent of participants who chose the video they simulated in the simulation condition to the percent of participants who chose the video whose screenshot they described in the control condition. This analysis was not possible for Study 4a because the visual illusion control condition did not correspond to one of the video options.
In our primary preregistered analysis for Study 4b, we conducted a two-way chi-square goodness of fit test on the frequencies of people choosing the video they simulated/described vs. the one they did not across the two conditions. Although people who merely described the screenshot chose that video at a numerically lower rate than those who simulated, the difference between these two percentages (62% for the simulated video vs. 55% for the described screenshot) was not significant, χ2 (1, N = 287) = 1.28, p = .26, Cohen's w = .07 
[.00, .18]
. Thus, it is unclear whether the effect of simulation goes beyond the effect of merely looking at an option in detail again.
Lastly, we explored whether participants in the control condition in Study 4b chose the video corresponding to the described screenshot at a higher-than-chance rate. Similar to the analysis reported above for the simulation condition in Studies 4a and 4b, we ran a chi-square goodness of fit test on the frequency of participants who chose the described vs. the non-described video. Participants in the describe screenshot control condition were not significantly more likely to choose the described video than would be expected by chance (82 out of 149, or 55%), χ2 (1, N = 149) = 1.51, p = .22, Cohen's w = .10 [.01, .26] 
(Figure 3)
. Thus, consistent with the idea that priming and perceptual processing alone are insufficient to sway choice, merely being re-exposed to an option was not enough to significantly influence choice.


SIMULATION CHANGES CHOICE 36


Simulation Increases Excitement for but not Enjoyment of the Chosen Video
We also explored whether simulation affected how people experienced their decisions relative to people who decided without simulating beforehand. It is possible that the act of simulation could lead people to be more excited about their choice and to enjoy the chosen video more, given the extra time spent imagining their future experience. Alternatively, simulation could lead to post-decision regret or less enjoyment of the chosen video, especially if the actual experience did not match their expectations.
First, we examined whether people who simulated a video were more excited about watching their chosen video compared to people who described a visual illusion (Study 4a) or a video screenshot (Study 4b). We conducted independent-samples t-tests comparing mean excitement ratings between the two conditions (simulation vs. control). In Study 4a, participants in the simulation condition (Msim We then asked whether participants who simulated a video enjoyed their chosen video more after watching it. We tested this using independent-samples t-tests to compare mean video enjoyment ratings between the simulation condition and the control condition for both studies. Despite their increased excitement, participants who simulated their future experience before deciding did not enjoy the video they chose more than participants who did not simulate, in both Study 4a, t(281.26) = 0.19, p = .85, d = .02, and Study 4b, t(276.76) = 0.74, p = .46, d = .09. There were no consistent differences between the simulation and control conditions on any of the other measures of decision or video experience, including certainty in decision (pre-or post-), post-decision regret, or interest in the nonchosen video after watching the chosen video (see Supplement). Together these findings suggest that simulation affects which option is chosen without changing one's perception or experience of the options.


Discussion
Studies 4a and 4b replicated Study 3: people chose to watch a video they simulated over one they did not. However, we found mixed evidence on whether simulation impacts choice beyond reexposure. Though simulating a video did shift choice levels beyond chance and describing one of the video screenshots did not, we found no significant difference between the simulation and description conditions. There are also limits to how simulation impacts decision evaluations: participants who simulated a video were more excited about their chosen video immediately after deciding but before watching it. These positive expectations did not translate into greater enjoyment of the video after watching, consistent with other errors in affective forecasting of decisions 
(Gilbert & Ebert, 2002)
.


General Discussion
Across six studies, we find consistent support for the hypothesis that simulating a possible future increases the likelihood of choosing that future. Simulation yielded small, but significant, shifts in people's hypothetical choices for real-life personal decisions and affected their actual choices in controlled scenarios. When considering options in everyday life, people naturally simulated ones they were initially most likely to choose, and simulated options became even more likely to be chosen. When deciding between two novel-but otherwise equally desired-snacks or videos, people chose the one they were directed to simulate. Together, these findings demonstrate the power of mere thought to impact decisions.


SIMULATION CHANGES CHOICE 38


The Simulation Feedback Loop
We found evidence that simulation is part of a feedback loop. The loop starts with people simulating options they already think are likely. In our naturalistic study (Study 1), participants naturally thought about options they were initially more likely to choose. This is consistent with prior findings that the options that come to mind first are the ones that have been effective before 
(Klein, 1993
(Klein, , 2005
Morris et al., 2021)
 or reflect the default 
(Johnson et al., 2007;
Phillips et al., 2019;
Weber & Johnson, 2011)
. Simulation is one tool people might use to deliberate among their most plausible options.
On the other side of the feedback loop, simulation makes options seem more likely. In Studies 1 and 2, participants thought they would be more likely to choose options they simulated for their personal decision, consistent with prior findings that repeated simulation increases an event's perceived plausibility . Here, changes in likelihood occurred after just one simulation.
Simulation also decreased people's likelihood of choosing the non-simulated option. If a simulated future is implausible, people may be unlikely to enter this feedback loop 
(Garcia Jimenez, Mazzoni, & D'Argembeau, 2023)
. For decisions with viable alternatives, however, simulation could be the tipping point that leads one option to be considered further and ultimately chosen.
Memory-based models of decision-making are consistent with this feedback loop. Query theory proposes that thinking about reasons increases their accessibility while inhibiting alternatives 
(Johnson et al., 2007;
Weber & Johnson, 2011)
. The reasons people mention initially when deliberating continue to be mentioned further as people get closer to the decision. Computational modeling likewise shows that memory is optimized to sample similar thoughts. As people sample "thoughts" from memory, evidence accumulates for the more often sampled option at a faster rate. Sampling then stops when there is sufficient evidence to make a decision 
(Zhao et al., 2022)
. We expect that simulation functions similarly by making simulated options more likely to be simulated again. Future research could test this SIMULATION CHANGES CHOICE 39 possibility using ecological momentary assessment to capture everyday simulation as it unfolds over the time leading up to a decision.
Feedback loops are consistent with work on perceptual attention and decision-making. For simple choices with all options visible, people initially direct their eyes toward the best uncertain options 
(Callaway, Rangel, & Griffiths, 2021)
. When looking at the stimulus, the brain extracts its features, retrieves the learned values associated with those features, and integrates those values to make a decision 
(Krajbich, Armel, & Rangel, 2010)
. The more one looks at the option, the more likely they are to accumulate evidence in its favor and, ultimately, to select it 
(Krajbich, Armel, & Rangel, 2010;
Isham & Geng, 2013)
. Indeed, experimentally guiding the eyes to linger on one option longer biases choice toward that option 
(Armel, Beaumel, & Rangel, 2008;
Tavares, Perona, & Rangel, 2017)
. This may help explain why our description condition in Study 4b did not differ significantly from our simulation condition. Analogously, future events become more vivid when simulated repeatedly 
(Wiebels et al., 2020)
, providing additional evidence to support a decision. Our work shows that considering an option in the "mind's eye" before deciding does increase its likelihood of being chosen.
Simulation could serve as a form of mental re-exposure that people naturally invoke to shape their choices. Previous research shows the mental imagery component of simulation is especially common in daily life 
(Conti & Irish, 2021)
. Our simulation instructions emphasizing conjuring mental imagery did not yield clear differences between simulation-based imagination and visual description of the option, suggesting that re-exposure via mental imagery could be one mechanism by which simulation impacts choice. It is still unclear from prior work and the current studies what role other components of simulation, such as temporal orientation, play in daily decision-making 
(Mahr, Greene, & Schacter, 2022)
. Future work could isolate the temporal component of simulation by asking participants to imagine their experience of the option in detail, including a clear beginning, middle, and end.


Limitations
Across six studies, we see consistent evidence that simulation affects decision-making but are limited in drawing strong conclusions in several ways. First, the effect of simulation on choice likelihood ratings for personal decisions was small and did not affect real-life choices beyond one week (Study 2a).
Previous research and Study 1 suggest that repeated simulation over time is more likely to influence real-life decisions than a one-time simulation manipulation (e.g., 
Wiebels et al., 2020)
. Future research with repeated interventions in applied settings could help address these gaps. Second, we are limited in making strong claims about the independent role of simulation beyond re-exposure to an option in impacting decision-making (Study 4b). Third, by controlling for initial preference in our lab studies, we could not test whether simulation can overcome initial biases toward one option that simulation naturally amplifies. Finally, our personal decision studies were limited in their ability to capture the extent to which everyday simulation was spontaneous vs. deliberate 
(Cole & Kvavilashvili, 2021)
. We look forward to future work elucidating the components of simulation that shape choices in everyday contexts.


Applying the Power of Simulation
How can people harness this power of simulation to improve real-world decisions? Clinicians already use simulation to help clients align choices with their goals and values. Psychotherapists use imagery-based methods to rescript memories 
(Arntz, 2012;
Holmes et al., 2007)
 and process emotions 
(Ji et al., 2016;
Lang, 1977)
. Our studies suggest that simulating specific futures could also help clients make decisions.
Directed simulation is not always helpful. Imagining committing acts of harm increases-rather than decreases-how likely one thinks they are to actually commit such acts 
(Morris et al., 2022)
.
Likewise, in our studies, both positive and negative simulated options became more likely to be chosen.
Could the perceived likelihood of choosing a simulated negative option actually translate into choice SIMULATION CHANGES CHOICE 41 behavior? Even if people do not act on imagined negative futures, the belief that they might do so could have negative effects on their mental health and well-being.
Could simulation also impact societal decisions over longer time frames? Prioritizing short-term futures at the expense of long-term goals could contribute to continued engagement in unsustainable behaviors 
(Kunreuther & Weber, 2014)
. Simulation interventions aimed to motivate behavior change by imagining catastrophic future climate impacts could backfire by making them seem more plausible and harder to avoid. A more effective strategy might be to simulate sustainable short-term behaviors. Policy makers should be aware of the potential impact of naturally-occurring simulation on longer-term societal decisions 
(Constantino & Weber, 2021;
Johnson et al., 2022)
.
We find reliable evidence that imagining the future does not just reflect our choices, it changes them. Simulation-induced decision change in the absence of detailed scripts or guidelines adds to existing literature on the impact of episodic simulation. Not only can simulation bring fictional stories to life 
(Tamir et al., 2016)
, help us see others' perspectives 
(Vollberg et al., 2021)
, and change how we view ourselves 
(Rubin-McGregor et al., 2022)
, it can help us decide which stories to read, who to spend time with, and which life paths to take.
everyday simulation was significantly related to the likelihood of choosing an option, b = 4.04 [3.18, 4.89], β = .39 [ 0.30, 0.47], t(510.65) = 9.22, p < .001 (Figure 1, panel a). People who simulated an option more over the course of the week increased their likelihood to choose that option, whereas people who simulated an option less over the course of the week decreased their likelihood to choose that option. The results were similar when looking at the thinking and talking components of everyday simulation separately (see Supplement).


Figure 1
1
Relationship between Everyday Simulation and Likelihood to Choose in Study 1


1, b = 0.03 [0.02, 0.03], β = .28 [0.21, 0.35], t(587.51) = 8.05, p < .001 (Figure 1, panel b).


Everyday Simulation .
.
Similar to Study 1, participants rated how much they engaged in everyday simulation about their decision and its options over the course of the week. For their decision title and each option title, they rated how much they thought and talked about it over the course of the week SIMULATION CHANGES CHOICE 20


Figure 2
2
Change in Likelihood to Choose from Pre-to Post-Simulation in Study 2


predicted the change in its likelihood-to-choose rating. To account for the repeated measures in our data, we included participant as a random intercept. The interaction between simulation and initial option valence was not significant in either study(Study 2a: b = 0.14[-0.35, 0.61], β = .01 [-0.02, 0.04], t(674) = 0.55, p = .58; Study 2b: b = -0.04[-0.71, 0.71], β = .00 [-0.04, 0.03], t(442) = -0.10, p = .92), demonstrating that the simulation manipulation had a similar effect on positive as well as negative options.


one-time simulation manipulation and their own everyday simulation-impacted their actual and hypothetical choices one week later. Of the initial sample of 340 participants who completed the initial questionnaire, 80% (N = 271) completed the follow-up at Time 2. Of the follow-up participants, 86% (N = 233) had already decided one week later, consistent with our instruction that they select a decision they anticipated making within the week. The remaining 14% (N = 38) had not made the decision at the time of the follow-up.


We are interested in understanding how people imagine the taste of new snacks. Please take a moment to think about what it would be like to try this snack." Participants then typed out how they SIMULATION CHANGES CHOICE 27 imagined their experience eating this snack, with instructions reminding them to "include as much detail as possible, including what the snack looks, tastes, and feels like as you eat it." The amount of time the participant spent on the simulation task was recorded.


Figure 3 Binary
3
Choice Outcomes in Studies 3 and 4Note. Results from Studies 3 and 4. Binary choice outcomes showing the percentage of participants who chose the simulated option (or the described option in the control condition of Study 4b) relative to the non-simulated option. Error bars represent 95% confidence intervals. Significance levels indicate the observed percentage was significantly different from 50%, *p < .05, ** p < .005, *** p < .001.


Study 4b .
4b
A total of 287 participants (aged 18-65, M = 26.78; 170 male, 114 female, 3 nonbinary; 78% White, 10% Hispanic or Latinx, 3% Asian, 3% Black or African American, 6% Mixed race or Other) were recruited online via Prolific. The final sample had 149 participants in the control condition and 138 in the simulation condition. Two videos, titled "1200 Messages in 1200 Bottles" (hereafter referred to as Bottle Messages) and "Late Night Drama with the King of Infomercials" (hereafter referred to as Info King) from


= 4.39, SDsim = 1.40) were more excited (Msim -Mcon = 0.45, 95% CI[0.11, 0.79]) about the upcoming video compared to those in the imagery control condition (Mcon = 3.94, SDcon = 1.52) , t(279.17) = 2.60, p < .01, d = .31. This finding replicated in Study 4b, t(275.52) = 2.99, p = .003, d = .35. That is, participants who simulated a video option (Msim = 4.43, SDsim = 1.43) were more excited about their chosen video (Msim -Mcon = 0.48, 95% CI [0.16, 0.80]) compared to those who described a video screenshot (Mcon = 3.95, SDcon = 1.29).


properly. Participants (n = 31) were excluded for providing nonsense text to the open-ended questions, leaving a final sample of 340 (age 20-81, M = 39.94; 147 female, 193 male; 75% White, 11% Black or African American, 6% Asian, 3% Hispanic or Latino, 4% Mixed race or Other). Study 2a was conducted SIMULATION CHANGES CHOICE 16 prior to the other studies and was not preregistered. We based the preregistered exclusion criteria and power analyses in the preregistrations for Study 1 and Study 2b on this sample. Study 2b was a preregistered replication of Study 2a. Using the effect size estimated from Study 2a, a power analysis yielded a target sample size of 230 to detect an effect of d = .185 at a significance level of .05 with 80% power. We a priori decided to stop data collection when we reached 250 participants (before exclusions) in order to achieve the target sample size. As a result of an error with the recruitment platform, only 249 of the 250 requested participants completed the survey. We
Study 2b. excluded participants (N = 26) who provided nonsense responses to the open-ended simulation item,
yielding a final sample of 223 participants (age 18-75, M = 34.62; 85 female, 136 male, 1 non-binary, 1
prefer not to say; 67% White, 20% Black or African-American, 6% Asian, 6% Hispanic or Latino, and 2%


we would like you to imagine that you have already made the decision about [personal decision text] and you chose the following option: [personal option text]. In the space below, describe your experience having chosen this option from your own point of view. Please include as much detail as possible.Participants typed their response to the simulation instructions in an open-ended text box and were free to move on to the next page whenever they finished their simulation. The amount of time that each participant spent on the simulation task was recorded.Vividness. On a separate page, participants rated the vividness of their simulation using a 5-item measure with three forward-scored items (e.g., "To what extent did you see what you imagined in your mind's eye?") and two reverse-scored items (e.g., "How difficult was it for you to describe with words what you imagined?"), adapted from
SIMULATION CHANGES CHOICE
18


]) compared to the non-simulated option (Mnon = -2.43, SDnon = 19.01, 95% CI[-4.94, 0.08]), b = 3.66 [0.21, 7.10], β = .20 [0.01, 0.38], t(444.00) = 2.08, p = .038. The follow-up one-tailed t-tests showed that simulation did not significantly increase likelihood-to-choose ratings for the simulated option, t(222) =


30.96, p < .001, Cohen's w = .46 [.30, .62], and Study 4b (86 out of 138, or 62%), χ2 = 8.38, p = .004, Cohen's w = .25[.08, .41]  
SIMULATION CHANGES CHOICE
35
145) =
both Study 4a (106 out of 145, or 73%), χ2 (1, N =














Remembering the past and imagining the future: common and distinct neural substrates during event construction and elaboration




D
R
Addis






A
T
Wong






D
L
Schacter




















10.1016/j.neuropsychologia.2006.10.016






Neuropsychologia




45


7














Remembering can cause forgetting: retrieval dynamics in long-term memory




M
C
Anderson






R
A
Bjork






E
L
Bjork










Journal of Experimental Psychology. Learning, Memory, and Cognition




20


5
















Functional-anatomic fractionation of the brain's default network




J
R
Andrews-Hanna






J
S
Reidler






J
Sepulcre






R
Poulin






R
L
Buckner




10.1016/j.neuron.2010.02.005






Neuron




65


4
















Biasing simple choices by manipulating relative visual attention




C
Armel






A
Beaumel






A
Rangel




10.1017/S1930297500000413






Judgment and Decision Making




3


5
















Imagery Rescripting as a Therapeutic Technique: Review of Clinical Trials, Basic Studies, and Research Agenda




A
Arntz




10.5127/jep.024211






Journal of Experimental Psychopathology




3


2
















The differential contributions of visual imagery constructs on autobiographical thinking




C
Aydin




10.1080/09658211.2017.1340483
















Random effects structure for confirmatory hypothesis testing: Keep it maximal




D
J
Barr






R
Levy






C
Scheepers






H
J
Tily




10.1016/j.jml.2012.11.001






Journal of Memory and Language




68
















Imagining emotional events benefits future-oriented decisions




B
C
Ballance






Y
J
Tuen






A
S
Petrucci






W
Orwig






O
K
Safi






C
R
Madan






D
J
Palombo




10.1177/17470218221086637






Quarterly Journal of Experimental Psychology




75


12






















SIMULATION CHANGES CHOICE




43












Fitting Linear Mixed-Effects Models Using lme4




D
Bates






M
Mächler






B
Bolker






S
Walker




10.18637/jss.v067.i01






Journal of Statistical Software




67
















A neural mechanism mediating the impact of episodic prospection on farsighted decisions




R
G
Benoit






S
J
Gilbert






P
W
Burgess




10.1523/JNEUROSCI.6559-10.2011






The Journal of Neuroscience: The Official Journal of the Society for Neuroscience




31


18
















Spontaneous future cognitions: an integrative review




D
Berntsen




10.1007/s00426-018-1127-z






Psychological Research




83


4
















Mental imagery in animals: Learning, memory, and decision-making in the face of missing information




A
P
Blaisdell




10.3758/s13420-019-00386-5






Learning & Behavior




47


3
















Mental time travel into the episodic future, episodic past, and episodic counterfactual past in everyday life




J
G
Branch






M
J
Zickar




10.1002/acp.3765






Applied Cognitive Psychology




35


1
















Cuing both positive and negative episodic foresight reduces delay discounting but does not affect risktaking




A
Bulley






B
Miloyan






G
V
Pepper






M
J
Gullo






J
D
Henry






T
Suddendorf




10.1177/1747021818819777






Quarterly Journal of Experimental Psychology




72


8
















Deliberating trade-offs with the future




A
Bulley






D
L
Schacter




10.1038/s41562-020-0834-9






Nature Human Behaviour




4
















Exploring the Use of Experience Sampling to Assess Episodic Thought




J
Busby Grant






E
Walsh




10.1002/acp.3215






Applied Cognitive Psychology




30


3
















Remembering the past and imagining the future: A neural model of spatial memory and imagery




P
Byrne






S
Becker






N
Burgess




10.1037/0033-295X.114.2.340






Psychological Review




114






















SIMULATION CHANGES CHOICE




44












Fixation patterns in simple choice reflect optimal information sampling




F
Callaway






A
Rangel






T
L
Griffiths




10.1371/journal.pcbi.1008863






PLoS Computational Biology




17


3


1008863














Do future thoughts reflect personal goals? Current concerns and mental time travel into the past and future




S
N
Cole






D
Berntsen




10.1080/17470218.2015.1044542






Quarterly Journal of Experimental Psychology




69


2
















Spontaneous and deliberate future thinking: A dual process account




S
Cole






L
Kvavilashvili








Psychological research




85


2
















Decision-making under the deep uncertainty of climate change: The psychological and political agency of narratives




S
M
Constantino






E
U
Weber




10.1016/j.copsyc.2021.11.001






Current Opinion in Psychology




42
















Harnessing visual imagery and oculomotor behavior to understand prospection




F
Conti






M
Irish








Trends in Cognitive Sciences




25
















Frequency, characteristics and functions of future-oriented thoughts in daily life




A
D'argembeau






O
Renaud






M
Van Der Linden




10.1002/acp.1647






Applied Cognitive Psychology




25


1
















Coming to grips with the past: effect of repeated simulation on the perceived plausibility of episodic counterfactual thoughts




F
De Brigard






K
K
Szpunar






D
L
Schacter




10.1177/0956797612468163






Psychological Science




24


7
















Episodic simulation of prosocial interaction: Investigating the roles of memory and imagination in facilitating a willingness to help others. Psychology of Consciousness: Theory




B
Gaesser






Z
Fowler




















Moral imagination: Facilitating prosocial decisionmaking through scene imagery and theory of mind




Brendan
Gaesser






K
Keeler






L
Young




10.1016/j.cognition.2017.11.004






Cognition




171
















Episodic simulation and episodic memory can increase intentions to help others




Brendan
Gaesser






D
L
Schacter




10.1073/pnas.1402461111






Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






111














Episodic simulation reduces intergroup bias in prosocial intentions and behavior




Brendan
Gaesser






Y
Shimura






M
Cikara




10.1037/pspi0000194






Journal of Personality and Social Psychology
















Repeated simulation increases belief in the future occurrence of uncertain events




Garcia
Jimenez






C
Mazzoni






G
Argembeau






A




10.3758/s13421-023-01414-6






Memory & Cognition
















The natural frequency of human prospective memory increases with age




R
S
Gardner






G
A
Ascoli




10.1037/a0038876






Psychology and Aging




30


2
















Decisions and revisions: The affective forecasting of changeable outcomes




D
T
Gilbert






J
E J
Ebert




10.1037/0022-3514.82.4.503






Journal of Personality and Social Psychology




82
















Self-relevant scenarios as mediators of likelihood estimates and compliance: Does imagining make it so




W
L
Gregory






R
B
Cialdini






K
M
Carpenter




10.1037/0022-3514.43.1.89






Journal of Personality and Social Psychology




43
















Self-relevant scenarios as an indirect means of attitude change




W
L
Gregory






W
J
Burroughs






F
M
Ainslie




10.1177/0146167285114009






Personality and Social Psychology Bulletin




11






















SIMULATION CHANGES CHOICE




46












Why We Imagine Our Future: Introducing the Functions of Future Thinking Scale (FoFTS)




D
J
Hallford






A
Argembeau




10.1007/s10862-021-09910-2






Journal of Psychopathology and Behavioral Assessment




44


2
















Retrieval-induced forgetting of autobiographical memory details




B
J A
Hauer






I
Wessel




10.1080/02699930500342464






Cognition and Emotion




20


3-4
















Imagery rescripting in cognitive behaviour therapy: images, treatment techniques and outcomes




E
A
Holmes






A
Arntz






M
R
Smucker




10.1016/j.jbtep.2007.10.007






Journal of Behavior Therapy and Experimental Psychiatry




38


4
















Looking time predicts choice but not aesthetic value




E
A
Isham






J
J
Geng




10.1371/journal.pone.0071698






PloS One




8


8


71698














Time orientation: Past, present, and future perceptions




L
A
Jason






J
Schade






L
Furo






A
Reichler






C
Brickman




10.2466/pr0.1989.64.3c.1199






Psychological Reports




64


3_suppl
















Emotional Mental Imagery as Simulation of Reality: Fear and Beyond-A Tribute to Peter Lang




J
L
Ji






S
B
Heyes






C
Macleod






E
A
Holmes




10.1016/j.beth.2015.11.004






Behavior Therapy




47


5
















Aspects of endowment: a query theory of value construction




E
J
Johnson






G
Häubl






A
Keinan




10.1037/0278-7393.33.3.461






Journal of Experimental Psychology. Learning, Memory, and Cognition




33


3
















Conviction Narrative Theory: A Theory of Choice Under Radical Uncertainty




S
G B
Johnson






A
Bilovich






D
Tuckett




10.1017/S0140525X22001157






The Behavioral and Brain Sciences


















Choices, values, and frames




D
Kahneman






A
Tversky




10.1037/0003-066X.39.4.341






The American Psychologist




39


4




















SIMULATION CHANGES CHOICE




47












A recognition-primed decision (RPD) model of rapid decision making. Decision Making in Action: Models and Methods




Klein




















The recognition-primed decision (RPD) model: Looking back, looking forward. Naturalistic Decision Making




Klein




















Recognition--primed decisions. Ergonomics: Major Writings




Klein




















The role of mental simulation in problem solving and decision making. In Local applications of the ecological approach to human-machine systems




G
Klein






B
W
Crandall






















10.1201/9780203748749-11/role-mental-simulation-problem-solving-decision-making-gary-klein-beth-crandall














Motivational correlates of thought content frequency and commitment




E
Klinger






S
G
Barta






M
E
Maxeiner




10.1037/h0077724






Journal of Personality and Social Psychology




39
















Visual fixations and the computation and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel




10.1038/nn.2635






Nature Neuroscience




13


10
















Aiding decision making to reduce the impacts of climate change




H
Kunreuther






E
U
Weber




10.1007/s10603-013-9251-z






Journal of Consumer Policy




37


3
















Imagery in therapy: an information processing analysis of fear




P
J
Lang




10.1016/S0005-7894(77)80157-3






Behavior Therapy




8


5






















SIMULATION CHANGES CHOICE




48












A long time ago in a galaxy far, far away: How temporal are episodic contents




J
B
Mahr






J
D
Greene






D
L
Schacter




10.1016/j.concog.2021.103224






Consciousness and Cognition






96


103224












Balancing Type I error and power in linear mixed models




H
Matuschek






R
Kliegl






S
Vasishth






H
Baayen






D
Bates




10.1016/j.jml.2017.01.001






Journal of Memory and Language




94
















Creative expertise is associated with transcending the here and now




M
L
Meyer






H
E
Hershfield






A
G
Waytz






J
N
Mildner






D
I
Tamir




10.1037/pspa0000148






Journal of Personality and Social Psychology




116


4
















Episodic simulation of harmful events: When imagined harm becomes morally justified. Cognition, 225, 105104




A
Morris






B
Gaesser






F
A
Cushman




















Generating Options and Choosing Between Them Depend on Distinct Forms of Value Representation




A
Morris






J
Phillips






K
Huang






F
Cushman




10.1177/09567976211005702






Psychological Science




32


11
















Forgetting as a consequence of retrieval: a meta-analytic review of retrieval-induced forgetting




K
Murayama






T
Miyatsu






D
Buchli






B
C
Storm




10.1037/a0037505






Psychological Bulletin




140


5
















Evoking the imagination as a strategy of influence




R
K
Petrova






R
B
Cialdini




C. P.


















P
M
Haugtvedt






Herr




Handbook of consumer psychology


& F. R. Kardes




















Taylor & Francis
Group






Lawrence Erlbaum Associates


















SIMULATION CHANGES CHOICE




49












How we know what not to think




J
Phillips






A
Morris






F
Cushman




10.1016/j.tics.2019.09.007






Trends in Cognitive Sciences




23


12
















Simulation induces durable, extensive changes to self-knowledge




J
Rubin-Mcgregor






Z
Zhao






D
I
Tamir




10.1016/j.jesp.2021.104229






Journal of Experimental Social Psychology




98


104229














On the constructive episodic simulation of past and future events. The Behavioral and Brain Sciences




D
L
Schacter






D
R
Addis




10.1017/S0140525X07002178






30














Remembering the past to imagine the future: the prospective brain




D
L
Schacter






D
R
Addis






R
L
Buckner




10.1038/nrn2213






Nature Reviews. Neuroscience




8


9
















Episodic simulation of future events: concepts, data, and applications




D
L
Schacter






D
R
Addis






R
L
Buckner




10.1196/annals.1440.001






Annals of the New York Academy of Sciences




1124
















Episodic Future Thinking: Mechanisms and Functions. Current Opinion in Behavioral Sciences




D
L
Schacter






R
G
Benoit






K
K
Szpunar




10.1016/j.cobeha.2017.06.002






17














The science of mind wandering: empirically navigating the stream of consciousness




J
Smallwood






J
W
Schooler




10.1146/annurev-psych-010814-015331






Annual Review of Psychology




66
















Imagining Risk Taking: The Valence of Mental Imagery Is Related to the Declared Willingness to Take Risky Actions




J
Śmieja






T
Zaleskiewicz






A
Sobkow






J
Traczyk




















The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: a quantitative meta-analysis




R
N
Spreng






R
A
Mar






A
S N
Kim




10.1162/jocn.2008.21029






Journal of Cognitive Neuroscience




21


3






















SIMULATION CHANGES CHOICE




50












Get real: effects of repeated simulation and emotion on the perceived plausibility of future experiences




K
K
Szpunar






D
L
Schacter




10.1037/a0028877






Journal of Experimental Psychology. General




142


2
















Reading fiction and reading minds: the role of simulation in the default network




D
I
Tamir






A
B
Bricker






D
Dodell-Feder






J
P
Mitchell




10.1093/scan/nsv114






Social Cognitive and Affective Neuroscience




11


2
















The Attentional Drift Diffusion Model of Simple Perceptual Decision-Making




G
Tavares






P
Perona






A
Rangel




10.3389/fnins.2017.00468






Frontiers in Neuroscience




11


468














Private self-consciousness and the five-factor model of personality: distinguishing rumination from reflection




P
D
Trapnell






J
D
Campbell




10.1037//0022-3514.76.2.284






Journal of Personality and Social Psychology




76


2
















Activating episodic simulation increases affective empathy




M
C
Vollberg






B
Gaesser






M
Cikara




10.1016/j.cognition.2020.104558






Cognition




209


104558














Query theory: Knowing what we want by arguing with ourselves. The Behavioral and Brain Sciences




E
U
Weber






E
J
Johnson




10.1017/s0140525x10002797






34














Relational processing demands and the role of spatial context in the construction of episodic simulations




K
Wiebels






D
R
Addis






D
Moreau






V
Van Mulukom






K
E
Onderdijk






R
P
Roberts




10.1037/xlm0000831






Journal of Experimental Psychology: Learning, Memory, & Cognition




46
















Some limits using random slope models to measure academic growth




D
B
Wright




10.3389/feduc.2017.00058






Frontiers in Education




2














The default mode network: where the idiosyncratic self meets the shared social world




Y
Yeshurun






M
Nguyen






U
Hasson




10.1038/s41583-020-00420-w






Nature Reviews. Neuroscience




22


3
















Process and content in decisions from memory




W
J
Zhao






R
Richie






S
Bhatia




10.1037/rev0000318






Psychological Review




129


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]