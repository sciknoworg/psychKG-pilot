You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1â€“3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Real-world decisions pose a difficult challenge: there are often so many potential options that we could not possibly call each of them to mind before deciding; yet, we also cannot choose an option that we do not first call to mind. Because of this, which options happen to come to mind has an enormous impact on our lives in momentous and mundane ways. When deciding what to have for dinner, for example, if you only ever consider making scrambled eggs, you may end up spending your whole life eating scrambled eggs. For many reasons, this might not be ideal.
In these kinds of decisions, there are obviously better and worse ways of calling options to mind. But we might also consider what comes to mind in contexts for which this is not so clearly the case. Try thinking of a zoo animal. What came to mind? And why is it that that zoo animal came to mind and not some other? Although prior work has pointed out that there are regularities across individuals in what comes to mind for these sorts of established categories 
(Battig & Montague, 1969;
De Dayne, Navarro, Perfors, Brysbaert, & Storms, 2019;
Mervis & Rosch, 1981)
, what remains unclear is why certain category members generally come to mind while others do not.
Here, we shed light on this question by taking the novel approach of connecting what has been discovered about which options come to mind during decision making with the question of what comes to mind within various categories. We pursue the idea that the process of generating options for decision-making tasks is closely related to the more general process of simply generating kinds of things: If you're trying to decide what kind of pet to get your child, you have to call to mind instances of the concept pet, and if you're trying to decide what to do for summer vacation, you have to call to mind members of the category 'vacations'. Thus, option generation during decision making may reflect domaingeneral mechanisms for calling to mind instances of a concept or members of a category. Accordingly, work on option generation in decision making stands to benefit from the more general study of how we call to mind members of a particular category, and vice-versa. Our approach will be to empirically demonstrate a domain-general framework for understanding what is likely to come to mind, for any arbitrary context or category.


Prior work on option generation in decision making
Existing research on what comes to mind during decision making has shown that people are remarkably skilled at generating candidate options. Over a range of decision making contexts, people can almost immediately generate a small set of generally good options from an effectively infinite option space 
(Johnson & Raab, 2003;
Klein, Wolf, Militello, & Zsambok, 1995;
Phillips, Morris, & Cushman, 2019)
. More specifically, the options that come to mind have been found to be historically valuable, likely, and semantically accessible 
(Bear, Bensinger, Jara-Ettinger, Knobe, & Cushman, 2020;
Morris, Phillips, Huang, & Cushman, 2021;
Zhang et al., 2021)
. 
Bear et al.
 find that people tend to call to mind generally valuable behaviors, even in the absence of a particular goal. For example, when being asked to simply name a number of hours of TV to watch in a day, participants' responses are predicted by both how likely the participant considers the behavior to be, and how ideal they consider it to be (2020). Morris et al. find that participants' judgements about the general value of an option predicts its likelihood of coming to mind whether or not it is not a good option for the particular decision making context at hand: even when people are specifically asked to think of options of low value, such as 'Think of a meal you'd least like to have for dinner,' they can't help but call to mind high value options (meals they really do like) (2021). The understanding of 'value' in this prior work is quite specific: relying on estimates of model-free cached values or perceptions of what would be prescriptively ideal 
(Phillips et al., 2019)
. This work illustrates the general observation that the options that come to mind are often those that have been historically or generally valuable, rather than being particularly good options for the specific context at hand. When deciding what to have for dinner, for example, tacos may have a low value in that specific context (you just had them yesterday), but may still be likely to come to mind because they generally have had a high value in the foods-to-have-for-dinner category.
While this prior work has made important progress in indicating that more generally valuable items within categories are more likely to come to mind, value can be ill-defined depending on the category in question (e.g., zoo animals). In other categories, what comes to mind seems not to be well described by what is valuable. When considering crimes, for example, what comes to mind? It is probably not the least bad crimes (e.g., underage drinking), which may, historically speaking, have had the highest general or model-free value; rather, the crimes that intuitively come to mind seem to have a particularly low value (e.g., murder). Instead of relying on notions of value to explain what comes to mind across categories, we propose that the role of value in determining what comes to mind when making decisions may instead illustrate a broader principle according to which particularly relevant features for the category in question help shape what comes to mind. Our basic idea, in brief, is that for the categories that were relevant in prior work (e.g., foods to eat), value just happens to be a particularly relevant feature; while for other categories (e.g., zoo animals) value is a less relevant feature and is unlikely to predict what comes to mind.


Prior work on categories, features, and typicality
Many theories of categories and concepts emphasize the role of certain features in defining or organizing the space of category members, where the extent to which something has particular features, or combinations of features, determines if it should be considered a member of a particular category (see 
Murphey 2002
, Chapter 2, for an overview). More specifically, category membership is often considered to be graded, where certain category members are considered 'better' or more 'typical' than others, though how category-relevant features map onto typicality is disputed in the literature 
(Janczura & Nelson, 1999;
Kellogg, 1981;
Malt & Smith, 1984;
Rosch & Lloyd, 1978)
. While past work has found that category members which are judged as more typical are also more likely to come to mind when generating instances from that category 
(Barsalou, 1985;
Hampton & Gardiner, 1983;
Janczura & Nelson, 1999;
Mervis, Catlin, & Rosch, 1976;
Rosch, Simpson, & Miller, 1976)
, little has been done to investigate this relationship in detail or to characterize what comes to mind within categories in its own right. Here, we seek to investigate what comes to mind by building on foundational ideas about feature-based descriptions of categories.
Whether by differentiating members of one category from members of another, or by differentiating between category members, representing category members in terms of certain features is useful for organizing conceptual knowledge. Importantly, for different categories, different features are more likely than others to be useful for organizing knowledge of that category's members. For some categories, such as dinner meals, relevant features are likely to include notions of general value (e.g., how much one likes that food); for other categories, such as zoo animals, such notions of value are unlikely to be relevant, while other features (e.g. how 'dangerous' or 'cute' a zoo animal is), are likely to be used. The idea pursued here is that for a particular category, certain category-relevant features guide what comes to mind in that category.
To expand on and test this idea, we begin by examining what comes to participants' minds within different ordinary categories, and then analyze unifying patterns in the kinds of features that predict what comes to mind in each category. We then seek to demonstrate, within each category, a correspondence between the features that predict what comes to mind and the features which more naturally coincide with people's representations of category members. By this general proposal, while the features that predict what comes to mind within each category will differ from each other, the most predictive features will consistently be ones that are especially central to people's representations of the category's members. While this interpretation of what comes to mind does not rely on notions of general value, it can explain previous findings that the options generated during decision making are generally valuable relative to the category of thing being called to mind. This fact may simply be a reflection of how decision-makers represent items in a category, with many relevant features likely being indicators of value and also determining what options are considered.


Experimental approach
We propose to make progress on understanding the factors that determine what comes to mind when thinking of members of a certain category. We consider 7 familiar categories: zoo animals, holidays, jobs, kitchen appliances, chain restaurants, sports, and vegetables. Within each category, we investigate whether differences between category members can be used to understand their likelihood of coming to mind. More specifically, we begin by asking participants to tell us the category members that come to mind (Study 1). We then introduce a novel experimental technique for constructing the space of relevant features used to represent the members of each category (Study 2), as well as for locating category members within the resulting feature space (Study 3). After empirically describing and locating category members within a category-specific feature space, we demonstrate that an item's position along particular dimensions of this space, representing the degree to which it is described by various features, predicts its likelihood of coming to mind. In Study 4, we investigate the features which predict what comes to mind in ad hoc categories and show that these features are not simply recapturing the role of typicality in determining what comes to mind. Having established a set of features for each category which vary in the extent to which they predict which category members come to mind, in Study 5 we find that for the most predictive features within a category, participants accidentally think of category members with these predictive features (e.g. large zoo animals) even when asked to think of category members with the opposite feature (e.g. small zoo animals). We thus provide evidence that in general, certain features automatically guide what comes to mind within a category, with limited context-specific shifts. Prior work showing that options that come to mind in decision making often are those that are generally valuable, rather than being particularly good options for the specific context at hand, might then be interpreted as demonstrating a specific instance of this phenomenon. We then show in Study 6 that the features which predict what comes to mind within a category are especially relevant to how we represent members of that category in general. Specifically, we find that for a given category, the more a feature dimension predicts what comes to mind, the more easily participants can report what category members are located at a particular location on that dimension. Under the hypothesis we argue for, the process of calling members of a category to mind might then be modeled as a search through feature space, weighted towards certain features that are relevant for that category. Finally, in Study 7, we test our framework in a decision making task and directly demonstrate its usefulness for understanding option generation during decision making.


Study 1: What comes to mind
In order to understand which factors determine what comes to mind in a particular category, we first investigated which category members are actually likely to come to mind. Participants recruited from MTurk (N = 123, M age = 38.0, SD age = 10.0, 62 females, 3 non-binary) were presented sequentially with each of 10 categories (zoo animals, holidays, jobs, kitchen appliances, chain restaurants, sports, vegetables, types of furniture, types of clothing, and breakfast foods) and asked to list 10 items in that category as they came to mind. Participants who failed to follow instructions on any trial, by repeatedly listing the same response or items that were not in the given category for that trial, were excluded from analysis (n = 20). Within each category, participants sometimes gave similar responses which were worded differently (for example, in the zoo animals category, different participants gave the responses 'otter,' 'otters,' and 'sea otter'). To accurately describe the frequency with which different items came to mind across participants in each category, we reconciled similar responses into a single response ('otter'). Because of difficulty in disambiguating similar responses for 3 categories (types of furniture, types of clothing, and breakfast foods), we excluded these categories from subsequent analyses. A general sense of what comes to mind across participants in each of the 7 remaining categories can be described in terms of the frequencies of the resulting responses. See 
Fig. 1
 for an illustration of the zoo animals that come to mind.
For inclusion in subsequent analyses which seek to characterize what comes to mind in each category, we selected all responses which had been given by at least 2 participants. In the zoo animals category, we also added to this list of responses zoo animals which appeared in the animal lists of 3 popular U.S. zoos, so that zoo animals that were not called to mind by any participants, but might otherwise be expected to be called to mind, would be included in our analyses (e.g. tarantula). Analogous procedures for the other categories did not result in the addition of items to the category list, as popularly recognized instances of the category were already largely present in participant responses. These category member lists of size 63 (zoo animals), 29 (holidays), 85 (jobs), 32 (kitchen appliances), 42 (chain restaurants), 37 (sports), and 40 (vegetables) are used in the remainder of our studies.  


A new method for empirically deriving category-specific representational spaces
We have proposed that which category members come to mind might be understood based on their location in participants' representational feature space for that category 1 . If we consider the features by which we represent things in a particular category, the likelihood of a category member coming to mind might vary systematically with the extent to which it is well described by particularly relevant features. To pursue this idea, we first must determine which features are used to represent members of each of our 7 categories, and then must determine how well each of these features describes each category member. We develop a new method for empirically deriving category-specific representational spaces and then locating category members within the resulting space.


Study 2: Constructing a category's feature space
To get an idea of what features people find relevant when describing members of each category, we recruited participants from MTurk (N = 147, M age = 36.9, SD age = 10.4, 73 females, 4 non-binary), randomly assigned them to make judgments about one category, and presented them with 10 sets of randomly paired members of that category derived from the prior experiment. For each pair, we asked them to tell us what made the two category members similar or different. For example, participants assigned to the zoo animals category 
Figure 2
 . Visualization of a subset of feature space for the zoo animals category. This space has only 3 dimensions: striking, large, and dangerous. Zoo animals are located along each dimension of feature space according to the average participant rating for how well a feature describes that zoo animal, and are colored according to the log probability of them coming to mind. An interactive version of this plot can be accessed at https:// dataverse.harvard.edu/file.xhtml?fileId=7280545&version=2.0 were told they would be comparing different zoo animals, and then for 10 trials were asked to list up to 4 similarities and 4 differences between two randomly paired zoo animals.
To illustrate, when comparing a jaguar and a hippo, one participant remarked that both can be dangerous, but jaguars are faster and hippos are larger. Features that were remarked upon by at least two participants within a category (e.g. dangerous) can be interpreted as potentially relevant for representing members of that category. Because our ultimate goal is to test the hypothesis that certain especially relevant features predict what comes to mind in a particular category, we want to be able to compare the predictiveness of these features to other features that are likely less relevant for conceptualizing the category. Accordingly, we also introduced features that could in principle be used to represent category members but are less likely to be considered relevant, e.g., 'has large feet relative to its body size' for the zoo animals category. From this set of features, we constructed a given category's feature space with each feature as a dimension in that space. The dimensionality of each category feature space is as follows: zoo animals: 30, holidays: 16, jobs: 16, kitchen appliances: 16, chain restaurants: 17, sports: 14, vegetables: 14. Within these n-dimensional feature spaces, we can think of a given category member's location as indicating how it is thought of in terms of these features relative to other category members.


Study 3: Locating category members in feature space
To determine the location of each category member in its category's feature space, we recruited additional participants from MTurk (N = 291, M age = 40.5, SD age = 12.1, 132 females, 2 non-binary) to judge how well each feature in a category's feature space described each category member. Participants were again assigned to one of the 7 categories and told they would be answering questions about things in that category. They were then presented with members from that category (from Study 1) and asked to rate how well a series of features (from Study 2) described the category member. For most features, participants rated how well statements of the general form 'This [category member] [has this feature]' described the category member on a scale from 1 ('not well') to 5 ('very well'), e.g., a participant may have been asked to rate how well the sentence "This zoo animal is dangerous" described a zebra. Certain categorical features, such as diet, were instead presented as a multiple choice question (described in more detail in the Supplementary Material). Each participant was assigned between 4 and 16 features, depending on the category, for which to give these ratings on each trial.
We took the average rating across participants for how well a feature described each category member as a point estimate of that member's location along that dimension in the category's feature space. Thus, an item's location within a category-specific feature space can be represented as a vector of ratings for each feature, or a point in the n-dimensional feature space. See 
Fig. 2
 for an illustration.


Predicting what comes to mind by location in feature space
We next asked whether the locations of category members along the different dimensions of feature space can help explain which category members come to mind. To do this, we simply calculated, for each dimension of feature space, the correlation between each category member's location along that dimension with the frequency with which that category member came to mind in the first study. A strong positive relationship indicates that the more a given feature applies to a given category member, the more likely that category member is to come to mind. In the case of either a strong positive or negative relationship, which category members come to mind can be predicted based on their location along a given feature dimension. For example, amongst zoo animals, the feature 'striking' is positively related to coming to mind, indicating that zoo animals that are considered more striking are more likely to come to mind, while the feature 'quiet' is negatively related to coming to mind, indicating that zoo animals that are considered less quiet are more likely to come to mind. This analysis revealed two key findings: (1) category member location along a number of category-specific feature dimensions was highly predictive of whether that category member would come to mind, and (2) there was a large amount of variance in the predictiveness of the different features (see 
Fig. 3
 for an illustration).
The correlations reported here do not take into account covariance between features. For example, it is intuitive that the largeness, strikingness, and dangerousness of zoo animals are related, and indeed in a factor analysis of the predictiveness of feature dimensions of zoo animal space, each of the three load highly on a single factor. However, this does not exclude the possibility that each of these features is independently central to people's representations of category members, and plays an independent role in guiding what comes 
Figure 3
 . For each dimension in zoo animal feature space, the absolute value of the correlation between each zoo animal's location along that dimension and that zoo animal's likelihood of coming to mind. Directionally negative correlations are indicated in blue. to mind. For readers who are interested in the relationships between the different feature dimensions and their predictivenss of what comes to mind, we include the factor analysis in the Supplementary Material. For our main analyses we continue with our purely datadriven approach of individually considering, for each feature as generated by participants, its relationship with representations of category members and their likelihoods of coming to mind.


Distinctness from typicality
Prior work on concepts and categories has found that people consider category membership to be graded, with some things being better or more typical members of a category than others, and that category members that first come to mind also tend to be judged as more typical of that category 
(Barsalou, 1985;
Hampton & Gardiner, 1983;
Janczura & Nelson, 1999;
Mervis et al., 1976;
Rosch et al., 1976)
.
Thus far we have been providing evidence for the proposal that there are certain features according to which we represent things in a particular category and which also guide what comes to mind in that category. While it is intuitive that features which are relevant to the way we represent things in a certain category also bear some relationship with the perceived typicality of things in that category, the nature of this relationship is disputed in the literature 
(Janczura & Nelson, 1999;
Kellogg, 1981;
Malt & Smith, 1984;
Rosch & Lloyd, 1978)
. While common features might plausibly contribute both to perceived typicality and what comes to mind, we next investigated whether our proposal for what comes to mind within a category and judgements about typicality are meaningfully distinct phenomena, warranting separate study.
Given this prior work, perceived typicality of category members might be expected to bear a relationship to many of the features which predict what comes to mind in highlyfamiliar categories (e.g., large zoo animals might tend to be considered some of the most typical). Thus, predictions about what comes to mind based on typicality judgements and based on the predictive features we have identified may be overlapping. To empirically test the separability of these two approaches, we consider two ad hoc categories: zoo animals you would take with you on a plane, and vegetables that you would use to paint your house. In these categories, we suspected that the features which predict what comes to mind largely would not be those which contribute to the perceived typicality of category members. Using these two new categories, we re-ran the previous series of three studies, first asking participants what comes to mind, then deriving the relevant features for these categories, then locating each category member in the resulting n-dimensional feature space, and finally considering the relationship between locations in feature space and coming to mind. Critically, we also collected judgments of the typicality of each category member to investigate how these features relate to what comes to mind. In accordance with past work, we asked about typicality in two ways: the extent to which category members are typical of the category 
(Hampton & Gardiner, 1983;
Janczura & Nelson, 1999;
Rosch et al., 1976)
, and the extent to which category members are good members of the category 
(Mervis et al., 1976)
.


Studies 4a-4c: Methods and Results
Except where noted, we employed the exact same methods used in Studies 1-3. We first recruited participants from Prolific (N = 299, M age = 37.0, SD age = 14.0, 147 females, 4 non-binary) to list 10 things as they came to mind in a category 2 . Once again, highly similar responses were re-coded into a single category, so that what comes to mind across participants in each of the ad hoc categories can be understood in terms of the frequencies of the resulting responses.
We again selected all responses for a given category which had been given by at least two participants for inclusion in the subsequent two studies. A second set of participants were then recruited from Prolific (N = 60, M age = 35.7, SD age = 14.4, 29 females, 2 nonbinary) and randomly assigned to compare category members within two of the categories in the prior study. For one of these two categories, we asked participants to list up to 4 similarities and differences between 5 sets of randomly paired category members. We then asked them to do the same for the second randomly chosen category. For each category, we selected all features that were remarked on by at least two participants to be the dimensions of that category's feature space. To this list of features, we also added features which we expected to be less relevant to the category, as well as typicality and goodness of category members. Finally, we located category members in these feature spaces by recruiting a third set of participants from Prolific (N = 337, M age = 37.2, SD age = 13.2, 169 females, 6 non-binary), introducing them to one of the categories from the prior study, and then  
Figure 4
 . For each dimension in category feature space, the absolute value of the correlation between each category member's location along that dimension and its likelihood of coming to mind. Directionally negative correlations are indicated in blue. Bars for "typical" and "good" are outlined in bold.
asking them to rate 8 category members (randomly selected from those generated in the first study) in terms of 15 features (randomly chosen from the feature lists produced from the second study, which include typicality and goodness). To illustrate, participants assigned to the category of 'zoo animals you would take with you on a plane' might be assigned to rate zoo animals according to various features including largeness, and would be asked to rate how well-described a particular zoo animal is by the feature statement "It is large." Feature statements for typicality and goodness were formed analogously; for the category of zoo animals you would take with you on a plane, these feature statements were "It is typical of zoo animals you would take with you on a plane," and "It is a good zoo animal to take with you on a plane," respectively.
As with the 7 original familiar categories used in the prior studies, we found that category members' locations along a number of category-specific feature dimensions were predictive of how likely those category members were to come to mind. There was again a large amount of variance in the predictiveness of the different features (see 
Fig. 4
). We also found that the likelihood of a category member coming to mind was not well explained by the extent to which it was judged as a "typical" or "good" category member. In the category of 'zoo animals you would take with you on a plane', both measures of typicality had a weak negative correlation with likelihood of coming to mind (r = âˆ’0.027, p = .795 and r = âˆ’0.006, p = .954 respectively), while in the category of 'vegetables that you would use to paint your house', both measures of typicality had a weak positive correlation with likelihood of coming to mind (r = 0.21, p = .139 and r = 0.084, p = .548 respectively). In fact, in both categories, a category member's likelihood of coming to mind was better predicted by its location along at least 10 other feature dimensions than by either typicality or quality 
(.16 < r < .30; .004 < p < .122
 in the category of 'zoo animals you would take with you on a plane', and .32 < r < .45; .007 < p < .0215 in the category of 'vegetables that you would use to paint your house').
In sum, we found that what comes to mind in these categories is not well explained by judgments about typicality or quality and is better explained by other category features. These results support the claim that what comes to mind within a category and judgements about typicality are distinct phenomena, and also encourage a feature-based approach for understanding what comes to mind within a category.


Intrusions in what comes to mind
In each of the categories we have analyzed here, the category members that come to mind can be understood based on their location along feature dimensions in categoryspecific representational space. Moreover, we have argued that this framework is likely quite domain general, and could help explain previous findings that valuable options tend to come to mind in decision making contexts 
(Johnson & Raab, 2003;
Klein et al., 1995;
Morris et al., 2021)
. On this view, an option's value may simply be one of multiple relevant features, or may simply be correlated with other relevant dimension(s) in the representational feature space used during decision making. Critically, prior work provided evidence that value plays an automatic, context-free role in guiding what comes to mind. In other words, this work demonstrated that participants did not seem to be able to prevent general value from causing options to come to mind, even when it would have been beneficial to do so. More specifically, 
Morris et al. (2021)
 found that when participants are asked to think of nonvaluable category members, such as the meal they would least like to have for dinner, they disproportionately report thinking of valuable options, or foods that they actually would like to have for dinner. Participants were more than 6 times more likely to experience these valuable "intrusions" than to experience non-valuable intrusions (accidentally thinking of meals they do not like when asked to think of the meal they would most like to have for dinner). Since our claim is that the role of value in guiding what comes to mind in such decision-making contexts is just one illustration of the more general role that any categoryrelevant feature might play, then we should expect to see the same pattern in intrusions for features that predict what comes to mind in other categories.


Study 5: Methods and Results
To test whether this is the case, we ran a study analogous to the one conducted by 
Morris et al. (2021)
 for the categories of zoo animals, holidays, and chain restaurants. In each of these categories, we identified the 5 feature dimensions which best predicted category members' likelihoods of coming to mind. In the zoo animals category, for example, these features were striking, large, dangerous, long-lived, and cool. Since each of these 5 features had a positive correlation with coming to mind, zoo animals which are welldescribed by these features can be considered to be located at the "predictive end" of that feature dimension. For example, an elephant is considered to be large, and is located at the predictive end of the 'large' feature dimension, while a tarantula is considered to be small, and is located at the non-predictive end of the 'large' feature dimension. Our hypothesis is that people will show a general tendency to have "intrusive" thoughts of category members at the predictive ends of feature dimensions, even when trying to think of category members at the opposite end of the dimension. Following Morris et al. 
2021
, we investigate this possibility by comparing the number of intrusions from the predictive ends of feature dimensions to the number of intrusions from the non-predictive ends of feature dimensions. In other words, 
Morris et al. (2021)
 found that valuable intrusions occurred more than non-valuable intrusions in the category of meals to make for dinner, and we expect to find a similar pattern for the 5 most predictive features for all 3 categories we investigate. Such a finding would strengthen our claim that the process of calling things to mind relies on domain-general mechanisms based on category-relevant features which, depending on the category at hand, need not include or approximate value.
Participants recruited from Prolific (N = 570, M age = 35.4, SD age = 16.4, 280 females, 10 non-binary) were randomly assigned to one of the 3 categories and one of the 5 different feature dimensions for that category and then asked to think of a category member located at either the predictive or non-predictive end of that feature dimension. For example, a participant assigned to the zoo animals category might be tasked with thinking of zoo animals at the non-predictive end of the "large" dimension, and would be asked to "name the smallest zoo animal." Another participant tasked with thinking of zoo animals at the predictive end of the same dimension would be asked to "name the largest zoo animal." After giving their response, participants were then asked to list all of the options they considered before responding, even if they immediately realized that they were not good options. Then, they were asked to rate the extent to which each of the options they considered had the desired feature. To illustrate, one participant who was asked to name the smallest zoo animal responded with "armadillo," and reported having additionally considered a giraffe, a deer, and a badger. This participant was then asked to rate how small they think each of these zoo animals are on a sliding scale from "not small" to "very small." Any consideration that a participant rated as being below the midpoint on this scale (i.e. closer to "not small" than "very small") was categorized as an intrusion.
This analysis approach revealed that for each of the 5 selected feature dimensions in the categories of zoo animals and chain restaurants, and 4 of the 5 feature dimension in the category of holidays, intrusions were more likely on average across participants when they were asked to think of category members at the non-predictive end of the feature dimension than when asked to think of category members at the predictive end of the 
Figure 5
 . For the predictive (left) and non-predictive end of each feature dimension, the average probability of a consideration being an intrusion, across participants assigned to think of a zoo animal at that end of the feature dimension. feature dimension. For the average probability of intrusions in each case, see 
Fig. 5
 for the zoo animals category, and Tab. 1 in the Supplementary Material for all categories.
To more quantitatively investigate this prediction, we can conceive of the predictive ends of our chosen feature dimensions as predictive locations in feature space, and non-predictive ends as non-predictive locations in feature space, defined with respect to a particular dimension. We can then conduct a generalized linear mixed effects regression over trial-level considerations across all categories to determine the effect of the predictiveness of a feature space location on the probability of a consideration being an intrusion when asked to name category members in that location. 3 This analysis revealed that the probability of an intrusion was strongly predicted by whether or not the end of the feature dimension being asked about was predictive of what came to mind in its respective category (p < .001, z = âˆ’5.140, OR = 0.168, 95% CI [.085, .332]). Specifically, the probability of a consideration being an intrusion was higher when participants were asked about the non-predictive ends of feature dimensions (p(intrusion)= 0.571), than when they were asked about the predictive ends (p(intrusion)= 0.246). These results support the claim that the previously established role of value in determining what comes to mind in decision-making contexts is a specific instance of a general phenomenon: certain category-relevant features guide what comes to mind within a category automatically, and thus in a way that is somewhat impervious to conscious control.


Determining relevant features and their relationship with what comes to mind
We have seen that different dimensions of category-specific representational space vary in how well they predict whether or not a given category member comes to mind, and that highly predictive features guide what comes to mind automatically. Moreover, many of the features that predict what comes to mind seem to be either orthogonal to or even inversely related to intuitive notions of value (e.g. 'dangerous' zoo animals). So, what makes some features more predictive than others? Given that across participants certain category members come to mind more than others (see 
Fig. 1
), we should expect that what comes to mind within a category is not determined arbitrarily, but rather by our experiences with category members and the way in which they are represented.
Given the pattern of data observed thus far, it remains possible that the features we found to predict what comes to mind within a category are not meaningfully involved in the way we represent and call to mind category members; they may, for example, merely be correlated with other factors which actually guide this process. However, it is also possible that these features predict what comes to mind for a more interesting reason, perhaps because they have been historically useful when thinking about or calling to mind category members. In this case, we would expect people's representations of category members to actually encode information about these specific features. To test this hypothesis, we next sought to analyze the relationship between a feature's predictiveness of what comes to mind in a category, and the extent to which that feature is encoded by participants' representations of category members.


Study 6: Which features are most relevant for representations of category members?
To understand which feature dimensions our representations of category members most strongly encode, we next designed an experiment to test how naturally people can think about category members in terms of different features. For each category, we selected a range of features from the previously constructed feature spaces which varied in their predictiveness of coming to mind, as determined in Study 3.
Participants were recruited from MTurk (N = 241, M age = 39.2, SD age = 12.4, 121 females, 0 non-binary) and randomly assigned to one of the 7 categories (zoo animals, holidays, jobs, kitchen appliances, chain restaurants, sports, and vegetables), and then asked to list, over 8 trials, members of that category that had a particular feature; the order of the features was randomized. On each trial, participants were asked to list as many category members that had that feature as possible in 30 seconds. For example, participants assigned to the zoo animals category were told that they would be asked to list zoo animals that fit certain descriptions. On one of the 8 trials, a participant may be repeatedly asked to 'list a zoo animal that has large feet relative to its body size' until 30 seconds had elapsed. 
Figure 6
 . Feature relevance of each dimension of zoo animal feature space, based on the ease with which participants listed zoo animals that have that feature, according to our ease of response metric.
For each trial, we can estimate the ease with which the participant was able to think about category members in terms of the given feature from a combination of (1) the number of responses given during the 30 second trial and (2) the speed of each response. To estimate this, we quantified the "ease of response" for a single trial by calculating the sum of the reciprocals of the amount of time it took the participant to generate each response. So for trial t in which n responses were given with respective response times rt 1 , rt 2 , ...rt n , the trial ease of response t eor = 1/rt 1 + 1/rt 2 + ... + 1/rt n . Trial ease of response for trials in which a participant was asked to give responses with a particular feature was averaged across participants to get the ease of response for that feature. Thus for each feature, the more responses participants tended to give, and the more quickly they tended to give these responses, the greater the ease of response to that feature. Ease of response values were then normalized by dividing each feature's ease of response by the maximum ease of response for a feature within the category. We take the ease of response to a feature to track the extent to which that feature is relevant to participants' encodings of category members, and so, from this point on, we will refer to the normalized ease of response to a feature simply as "feature relevance." Our approach for determining feature relevance revealed two key findings: (1) for each category, there were clearly relevant features, and (2) there was significant variation among features in terms of relevance (see 
Fig. 6 for an illustration)
.
A concern one might have with our measure of feature relevance is that ease of response will tend to be greater for features which happen to describe more category members, independent of their relevance to people's representations of those category members. For example, suppose that most zoo animals just happen to be mammals. Given that fact, if we asked one group of participants to list zoo animals that are mammals, they would likely be able to list a lot of mammals quickly even if they were just randomly generating zoo animals; moreover, they would likely not be able to list many amphibians. Accordingly, it 
Figure 7
 . Difference in the proportion of each response in the category of zoo animals between Study 1, in which participants were simply asked to name zoo animals, and Study 6, in which participants were specifically asked to name large zoo animals. Responses ordered and colored according to largeness ratings obtained in Study 3 (increasing left to right, dark to light). seems like our measure of feature relevance would conclude that "mammalness" is a relevant feature for zoo animals but "amphibianness" is not, simply because it just happens that more zoo animals are mammals than amphibians. While this may certainly be the case for some features, this is unlikely to fully explain which features were categorized as relevant for the different categories. Critically, many of the features we find to be most relevant for a category are those which are relatively uncommon. For example, while largeness is a highly relevant feature and one of the most predictive of the zoo animals that come to mind, the majority of zoo animals are unlikely to be considered large rather than small (consider all of the birds, insects, reptiles, and rodents at zoos). More importantly, we find that participants in this study responded with category members that are especially well-described by the given feature, relative to other category members, and even relative to those category members that are likely to come to mind in general. To illustrate: although large zoo animals tend to come to mind in general (see 
Fig. 3
), when participants were asked specifically to name large zoo animals, especially large zoo animals were even more likely to come to mind than they previously were. While a bear is generally considered to be a large animal, 'bear' made up a similar proportion of responses in the two studies, while the largest animals such as 'giraffe' or 'elephant' made up a greater proportion of the responses in this study (see 
Fig. 7
 for a more detailed look at differences in responses between the two studies). This suggests that participants who named large zoo animals in this study selectively called to mind category members at a particularly extreme location along this feature dimension, supporting the conclusion that it is indeed a relevant dimension for representing zoo animals.


The relationship between what comes to mind and feature relevance
If what comes to mind within a given category is a reflection of which category members exist in the relevant part of representational space, as we have proposed, then the features which better predict what comes to mind within a category should also be more relevant to participants' representations of category members.
To test whether this is the case, we calculated the correlation between a feature's predictiveness of coming to mind (see 
Fig. 3
) and that feature's relevance across all 7 categories. We found a highly significant positive relationship overall, r = 0.60, p < 0.001, and clear positive relationships in each of the 7 categories: zoo animals (r = 0.289), vegetables (r = 0.89), holidays (r = 0.74), jobs (r = 0.15), kitchen appliances (r = 0.46), chain restaurants (r = 0.87), and sports (r = 0.67). 4 See 
Fig. 8
 for the overall relationship across categories, and for an illustration in the case of zoo animals.
The consistent relationship observed across all 7 categories provides clear evidence for our proposed hypothesis. If features that predict what comes to mind in a given category are those that have been historically useful for representing or calling to mind category members, then we would expect that participants will have previously encoded category members along those dimensions. What we found is precisely that: the more predictive a given feature was, the more participants encoded category members along that dimension.


What comes to mind when making decisions
Previous work on decision making has found that generally valuable options tend to come to mind, even when they are not good options for the particular context at hand. We have sought to contextualize this finding within our more general theory, according to which certain category relevant features guide what comes to mind in a category across contexts. Still, we have not yet provided direct evidence that these phenomena ought to be united under a common framework. To address this question directly, we conducted a final study that tests the predictions made by our framework in a decision-making task. In this study, we ask participants to make a novel, open-ended decision in which the features that determine the best solution for the problem diverge somewhat from the features that typically predict what comes to mind. This allows us to more clearly observe the independent effect of decision making on what comes to mind. For simplicity, we asked participants to make a decision involving zoo animals, as we have already measured the features that predict which zoo animals are likely to come to mind generally, and thus can easily analyze the extent to which these features continue to predict what options come to mind in a novel decision-making task. 
4
 The variance in the strength of this relationship across the different categories might be explained by a number of factors. Because the number of data points in each individual category is relatively small (between 10 and 18) we should expect the correlation coefficient to be a noisy estimate of the relationship between feature relevance and feature predictiveness in a particular category. Weaker correlation coefficients might also result from noise in measurements of feature relevance and feature predictiveness themselves. For example, the relationship was weakest in the category of jobs, which is the category in which features varied the least in both their relevance and in their predictiveness of what comes to mind. To the extent that there is noise in the information captured by these metrics, magnified noise due to lower variance in each feature's role in guiding what comes to mind and relevance to representations of category members might explain why the relationship between these appears weaker in this category.  
Figure 8
 . Predictiveness of coming to mind is plotted against feature relevance for each feature in a) zoo animal feature space, and b) all category feature spaces


Study 7: Methods and results
Participants were recruited from Prolific (N = 100, M age = 35.6, SD age = 15.2, 48 females, 0 non-binary) and were told that they would be answering a question, and then reflecting on the process that lead them to their answer. All participants were asked to answer the following question:
Imagine you are taking a group of children to the zoo. However, the zoo is closing early and you only have time to see one animal. Which zoo animal do you take the children to see, given that you know they might be scared of the larger animals?
After answering, participants where then asked to list all the zoo animals they considered before making their decision, including the one they gave as their response, providing us with the "consideration set" employed in their decision making 
(Morris et al., 2021)
. Finally, as a simple sanity check, we also asked participants to report the features that they thought it was important to consider when deciding on a zoo animal, allowing us to make sure that these features differed from those that generally predict what comes to mind.
Two participants were excluded from analyses because they responded with multiple zoo animals rather than a single zoo animal. Analyzing the responses from the rest of the participants, we first checked to make sure that the features participants listed as important to consider were relevant to the specific decision-making context. Indeed, participants most frequently mentioned that it was important to consider animals that were not too large, not too dangerous, and cute. As intended, these features clearly differ from those that typically predict which zoo animals come to mind.
Accordingly, we next analyzed the options that come to mind in this novel decision making task and asked whether we find evidence that the previously identified general mechanism for calling zoo animals to mind plays a role in participants' decision making.
To do this, we want to ask whether the features that predicted which zoo animals come to mind generally play a similar role in shaping participants' consideration set during decision making (despite the fact that many of these features are unlikely to be useful for selecting a specific zoo animal in this task). To investigate this, we use the same analysis approach as in Study 3 by locating the zoo animals participants reported considering in feature space using the ratings we gathered in Study 3, and then determining the extent to which different features predict the frequency with which zoo animals were considered. 5 As can be seen in 
Fig. 9
, the features that predict what zoo animals were considered before participants made a decision are highly similar to those that predicted what zoo animals came to mind during instance generation in Study 1 (r = 0.95, p < 0.001). This suggests a similar mechanism is employed for calling zoo animals to mind in both kinds of tasks.
We next ask whether the features that predict which zoo animals are selected differ from the features that predict which zoo animals come to mind, demonstrating independence between the generation and selection mechanisms (c.f. 
Morris et al., 2021;
Zhang et al., 2021)
. To do this, we employ a similar analysis approach, locating the selected zoo animals in feature space and estimating each dimension's predictiveness for selection. Here, we find that the features that predict which zoo animals were selected (see 
Fig. 9
) differ substantially from those that predict which zoo animals participants considered before deciding (r = 0.14, p = 0.48), and also differ substantially from those that predict category instance generation in non-decision-making contexts (r = âˆ’0.13, p = 0.51). This result provides a clear illustration of the usefulness of the framework we have presented when applied directly to decision making. It also supports the idea that during decision making, the options that come to mind might be drawn from one generally useful representational space (which may or may not include notions of general value), while choosing an option from those that have been called to mind relies on some more specific, context-appropriate decision criteria 
(Morris et al., 2021;
Phillips et al., 2019)
.


General Discussion
Across a series of studies, we have tested a general framework for understanding what comes to mind within a category in terms of locations in representational space. In 7 familiar categories (zoo animals, holidays, jobs, kitchen appliances, chain restaurants, sports, and vegetables), we found that an item's location along certain dimensions of category-specific feature space predicts how likely it is to be called to mind. We also found that what comes to mind in a given category is biased towards these locations in feature space reliably and by default, even when participants were tasked with thinking of category members which are not in these locations. Further, we provided evidence that this approach can be extended to ad hoc categories (e.g., vegetables that you would use to paint your house), and that what comes to mind is not merely a reflection of the typicality or quality of category members. We then demonstrated that predictive feature dimensions are also particularly relevant to people's general way of representing members of those categories, with a given feature's predictiveness of coming to mind positively correlating with that feature's relevance  
Figure 9
 . a) For each dimension in zoo animal feature space, the absolute value of the correlation between each zoo animal's location along that dimension and that zoo animal's probability of being considered (left), or selected (right), in the decision making context presented in Study 7. In both panels, features are in order of decreasing magnitude of correlation with consideration probability. Directionally negative correlations indicated in blue. b) Correlation between feature predictiveness of which zoo animals came to mind during instance generation in Study 1, and feature predictiveness of which zoo animals were considered (left) or selected (right) in the decision making context presented in Study 7.
within a category. This finding suggests it can be fruitful to conceptualize the process of calling category members to mind as a search through the category's feature space, weighted towards certain relevant dimensions, or equivalently, as sampling from a relevance-based feature space.
The proposed framework-in which the category-members that come to mind can be understood by their location in relevance-based feature space-can also be usefully applied to previous work on what comes to mind during decision making. In Study 7, we find evidence that a similar mechanism underlies both instance generation from a category and option generation for decision making: specifically, the features which predict what comes to mind when simply generating instances of the category 'zoo animals' similarly predict what comes to mind when making a decision about zoo animals (r = 0.95 between the predictiveness of features in each context). While future work is needed to empirically verify that our framework indeed predicts what comes to mind in the specific paradigms used in prior decision making studies, it is certainly compatible with the finding that options generated during decision making tend to be generally valuable 
(Bear et al., 2020;
Johnson & Raab, 2003;
Klein et al., 1995;
Morris et al., 2021;
Phillips et al., 2019)
. In decision making tasks, the options that come to mind often belong to categories in which the features that are relevant for representing category members are predictive of subjective value (e.g., for the category of meals to make for dinner, many of the relevant dimensions for representing meals also track how much that meal is liked in general). Our proposal that what comes to mind is guided by relevant dimensions of a category's feature space can thus explain option generation in these contexts, while also generalizing to contexts in which general value, or features which approximate or contribute to it, does not play a role in guiding what comes to mind.


Relationship to prior work on categories and what comes to mind
We have sought to go beyond prior work on instance generation in established and novel categories 
(Barsalou, 1985;
Battig & Montague, 1969;
De Dayne et al., 2019;
Mervis & Rosch, 1981)
. In particular, we demonstrated a clear positive relationship between (i) the extent to which a feature is predictive of what comes to mind in a given category, and (ii) the extent to which people typically encode information about that feature for category members. One plausible explanation for this relationship is that in people's past experiences with a particular category, it has been useful to call to mind category members with certain features. For example, when thinking of a vegetable to serve with dinner, it might be most useful to consider nutritious vegetables which tend to be well-liked. When planning a trip to the zoo, it might be useful to call to mind large, striking animals that are exciting and cannot easily be seen elsewhere -this would explain why participants' mental representations of various zoo animals may include some sort of cached 'strikingness' metric. What comes to mind by default might then be usefully biased by these features which are historically relevant to our experiences with and representations of category members. This explanation fits well with the finding that value guides what comes to mind in many decision making contexts, as it is generally useful to consider good options before making a decision 
(Phillips et al., 2019)
.
It is important to note that not all category-relevant features are necessarily predictive of what comes to mind. For example, while the feature 'diurnal' was not predictive of what zoo animals came to mind, participants who were asked to name diurnal zoo animals could do so relatively easily. This fact is consistent with the hypothesis that certain features guide what comes to mind within a category because we have learned that it is useful to call category members with those features to mind. While we certainly expect such features to be encoded by our representations of category members, other features might also be worthwhile to encode for various other reasons. Thus, the process of calling category members to mind by sampling from relevant locations in representational space might rely on predictions about the usefulness of calling to mind category members with those features. While the feature 'diurnal' may be relevant to the way people represent zoo animals, it may not affect which zoo animals come to mind because it is not generally useful to use the dimension diurnal to call zoo animals to mind.
It might be tempting to confuse our notion of 'usefulness of calling to mind' with the representations of value that past work has used to describe the options that come to mind during decision making. An option's idealness 
(Bear et al., 2020)
, its model-free value 
(Phillips et al., 2019)
, or the extent to which it is liked 
(Morris et al., 2021)
, are examples of explicitly represented featural descriptions of a given option. While there are clearly many instances in which relying on these features will be useful for calling options to mind, there are also many clear cases in which value representations come apart from the usefulness of calling certain options to mind. Consider the wildlife that come to mind when planning for a camping trip. Bears, spiders, or snakes likely come to mind, and do so more than squirrels, rabbits, or birds. Despite this, it is the latter options (not the former) that are likely represented as having a higher value, according to the value metrics proposed in prior work. In such contexts, features other than general value determine the usefulness of calling certain options to mind. Quite generally then, it will be useful to differentiate between the role of specific featural representations (such as general value) in guiding what comes to mind, and the usefulness of calling to mind options with particular featural representations.
Our findings might also be contextualized in relation to theories of spreading activation, which frame information retrieval from memory as the spreading of activation through a network of information-encoding units, with the level of activation determining the rate and probability of recall 
(Anderson, 1983)
. As this general framework is quite flexible, the extent to which our framework is consistent with this approach depends on how the units and associations of these networks are defined. For example, if the network consisted merely of nodes representing category members and edges representing the semantic similarity between category members, the predictions of semantic spreading in this network would differ sharply from our predictions. To illustrate this point, consider the zoo animals that came to participants' minds in Study 1 
(Fig. 1)
. Each of the top 7 responses were given by over half of all participants, despite the fact that they are generally quite dissimilar from each other. Correspondingly, responses that actually were highly similar to the most commonly reported zoo animals were not mentioned by many participants (e.g., while 'monkey' came to mind for 63 participants, 'chimpanzee' only came to mind for 10). While this naive interpretation of spreading activation cannot explain our findings, the general framework of spreading activation could be used to more closely approximate the account we have offered. For example, one could build a network that is designed to encode the relationship between category labels (e.g., 'zoo animal') and category members 
('lion', 'turtle', 'zebra', etc.)
 and have the associations between units encode features weighted by their relevance for the category. Within such a network, one could then conceptualize the process of calling category members to mind as the spreading of activation from the category label to category members depending on their corresponding degree of association, and associations between category members might additionally aid in explaining which category members a particular individual calls to mind, as well as their order. While this way of implementing our findings is possible and broadly consistent with our approach, one advantage of our framework is that it retains information about the structure of the representational space for some category which is independent of the particular items located in that space. This might allow us to more flexibly and naturally explain how compositions of or changes to representational spaces determine changes in what comes to mind.


Typicality, ad hoc categories, and decision making
Understanding what comes to mind in terms of relevant features can also help explain why category members that are perceived to be more typical also tend to come to mind first 
(Barsalou, 1985;
Hampton & Gardiner, 1983;
Janczura & Nelson, 1999;
Mervis et al., 1976;
Rosch et al., 1976)
. Prior work has shown that typicality is meaningfully related to the way we represent category members in terms of certain features 
(Janczura & Nelson, 1999;
Kellogg, 1981;
Malt & Smith, 1984;
Rosch & Lloyd, 1978)
, and similar category-relevant features might often contribute to both phenomena. However, we have also provided evidence that they are distinct. In particular, we demonstrated that in two ad hoc categories, typicality judgements were not as strongly related to a category member's likelihood of coming to mind as were other relevant features, suggesting that there are important differences in the relationships the two phenomena bear to the way people represent category members in terms of certain features.
Although we have set out to understand what comes to mind within established categories in the absence of context-specific constraints, many of the instances in which people call items in a category to mind are in fact situated within a particular context. For example, when thinking of a vegetable to serve with dinner, perhaps you keep in mind that one of your guests hates broccoli, and another has soft teeth. This example illustrates how easily the lines between established categories (vegetables), decision-making contexts (what vegetable to serve with dinner), and ad hoc categories (vegetables to serve to broccoli-hating soft-toothed dinner guests) become blurred. An advantage of our framework is that it is flexible enough to account for what comes to mind without discriminating between these phenomena: in each, we might sample from representational spaces according to certain features which we have encoded as relevant to a particular context.
Of course, for many categories, we may not already have a well-formed representational space in which category members are encoded. For example, participants in Study 4 likely had never thought about what zoo animals they would take on a plane. Still, we found regularities in the feature-space locations of what came to mind, with certain features predicting a category member's likelihood of coming to mind. While most of these predictive features were those which predicted what came to mind in the broader category of zoo animals, there were also limited context-relevant shifts in the predictive features between these contexts. For example, cute and dangerous zoo animals increased and decreased respectively in their likelihood of coming to mind, with the zoo animals that came to mind in the ad hoc category being rated on average as less dangerous and more cute than those that came to mind in the broader category. Helpfully, our framework can also be extended to explain these differences. If what comes to mind is a product of a search through feature space, biased towards certain relevant features, this search might also be shifted towards features that are uniquely important in some particular context. This proposal fits well with the findings of 
Morris et al. (2021)
, who analyzed what participants called to mind when deciding on a meal to make in various contexts, such as after getting dental surgery. In this context, we might expect what comes to mind to be recalcitrantly biased towards features which are generally useful when thinking of meals (such as how much the participant likes that meal), but also to exhibit a flexible bias towards contextually appropriate dimensions of feature space. Indeed, Morris and colleagues found that what comes to mind in these contexts tends to be a mix of generally 'valuable' responses, and ones that conform to the context-specific constraints (e.g., not too chewy). When contextually appropriate features conflict with generally predictive features for the category at hand, such as when deciding on the worst meal to make for dinner or when naming the smallest zoo animal, we have seen that people cannot entirely avoid calling to mind category members with the generally predictive but contextually inappropriate feature. Similarly, although 'dangerousness' became less predictive of what came to mind in the ad hoc category of zoo animals to take with you on a plane than in the original category of zoo animals, more dangerous zoo animals were still more likely to come to mind, despite the fact that most participants would probably prefer to be on a plane with less dangerous zoo animals. Thus, while the features that guide what comes to mind are at least somewhat flexibly determined in contextualized or ad hoc categories, more work must be done to understand the nature and extent of this flexibility 
(Hamrick and Griffiths (2014)
 and 
Lieder, Griffiths, M. Huys, and Goodman (2018)
 offer relevant formalizations of cases in which specific aspects of the context at hand bias which options are considered during decision making).


Future directions
Future study on the question of what comes to mind might build off the work presented here in a number of ways. First, work might be done to understand how people's experiences with a particular category determine the features that guide what comes to mind within that category. We proposed that it may simply have been historically useful across various contexts to call to mind category members with those features. This theory might be tested by introducing people to a novel category and having them recall category members to complete various tasks for which certain features are variably useful. In such an experiment, we could then ask whether a feature's usefulness in these prior tasks affects what category members later come to mind. Relatedly, individual differences in people's experiences with pre-existing categories might determine relevant features (exemplified by 
Medin, Lynch, Coley, and Atran (1997)
 in tree experts), and be used to predict individual differences in what comes to mind. Finally, the empirical tools we've developed in this paper might also be applied more directly to decision making categories in which the options being called to mind are possible actions.


Conclusion
We have proposed that what comes to mind can be fruitfully understood as samples from relevance-based feature spaces, and offered the empirical and theoretical tools for constructing and locating items within such a feature space. Notably, our framework also offers the potential for a unified account of what comes to mind in established categories, ad hoc categories, and during decision making. We hope our proposal inspires future work that continues to build on, and improve, this general approach.        
Table 8
: For the predictive (bold) and non-predictive end of each feature dimension in each category, the average probability across participants assigned to think of a category member at that end of the feature dimension of a response being an intrusion.
Figure 1
1
. a) Distribution of the proportion of participants for which each zoo animal came to mind, from largest (left) to smallest. b) Most and least probable responses from this distribution.


Table 1 :
1
Zoo animals (67% of variance explained by all factors).
Factor
Factor
Factor
Factor
Factor
Factor
Factor
Factor
Factor
Comm-
0
1
2
3
4
5
6
7
8
unality
large
0.87
-0.14
-0.04
0.14
-0.12
0.02
0.01
0.03
-0.27
0.89
cute
-0.27
-0.16
0.88
0.11
-0.25
0.19
0.01
0.11
-0.05
1.0
dangerous 0.65
0.52
-0.19
0.16
0.15
-0.05
0.22
-0.05
0.01
0.84
diurnal
0.21
-0.61
0.15
-0.16
0.18
-0.09
-0.17
0.15
-0.25
0.62
diet,
-0.18
-0.17
0.04
-0.18
-0.07
-0.24
-0.21
0.1
0.48
0.44
omni-
vore
diet,
0.2
0.88
0.12
-0.03
0.09
-0.08
-0.1
-0.01
-0.18
0.89
carni-
vore
type,
0.19
-0.02
0.13
0.76
-0.49
0.21
0.19
-0.03
-0.1
0.96
mammal
type,
0.0
-0.01
-0.07
0.02
0.02
-0.97
-0.1
0.07
-0.01
0.97
fish
type,
-0.15
-0.05
0.1
-0.97 -0.13
0.05
0.08
-0.01
0.01
1.0
bird
type,
0.05
0.11
-0.15
-0.02
0.86
0.12
-0.27
0.06
0.07
0.88
reptile
type,
-0.01
-0.06
0.19
0.07
0.09
0.1
-0.56
0.09
0.06
0.39
amphib-
ian
desert
-0.21
-0.01
-0.5
0.1
0.16
0.19
0.15
-0.1
-0.06
0.4
lifespan
0.83
-0.02
0.17
0.12
-0.05
0.02
-0.19
-0.08
-0.09
0.79
cool
0.39
0.29
0.7
-0.1
-0.0
0.09
-0.02
-0.11
0.05
0.76
normal
-0.13
-0.17
0.02
0.05
-0.22
-0.06
-0.0
0.71
-0.04
0.61
striking
0.67
0.46
0.32
-0.18
-0.02
-0.02
0.1
-0.19
-0.05
0.84
think
-0.01
0.01
0.02
-0.02
0.1
-0.03
-0.08
0.77
0.08
0.62
forest
-0.25
0.17
0.04
0.2
0.06
0.16
0.38
0.13
0.73
0.86
tropics
-0.1
-0.08
-0.05
-0.14
0.38
0.01
-0.05
-0.21
0.55
0.53
arctic
-0.16
0.24
0.22
-0.1
-0.16
-0.23
-0.22
0.23
-0.18
0.35
land
-0.17
-0.12
-0.12
0.08
0.01
0.59
0.68
-0.07
0.05
0.87
large
0.05
-0.15
0.24
0.0
-0.0
0.24
0.39
-0.12
0.02
0.31
feet
quiet
-0.15
0.03
-0.2
0.33
0.29
-0.23
0.1
-0.01
0.07
0.33
has good
0.14
0.22
0.18
-0.04 -0.53
0.17
-0.1
0.33
0.02
0.53
hearing
has long
-0.04
0.26
0.06
0.19
-0.17
0.16
0.44
0.15
0.14
0.4
hair
sleeps
-0.03
-0.04
-0.07
-0.24
0.15
-0.23
0.01
-0.14
-0.29
0.25
very
little
proport-
0.14
0.080 0.078 0.076 0.070 0.070 0.064 0.058 0.055
ional
factor
variance


Table 2 :
2
Chain restaurants (67% of variance explained by all factors).
Factor 0 Factor 1 Factor 2 Factor 3 Communality
likes
0.69
0.09
-0.2
-0.23
0.58
popular
0.96
0.12
0.03
0.15
0.96
think
0.76
0.14
-0.03
0.0
0.59
high energy
0.22
0.9
-0.03
0.02
0.86
dangerous
0.2
0.43
0.71
0.16
0.76
strenuous
0.19
0.96
0.01
-0.02
0.95
spectators
0.83
0.21
0.27
0.17
0.83
competitive
0.58
0.43
0.17
0.23
0.61
agility
0.21
0.79
-0.0
-0.47
0.88
expensive
0.05
-0.14
0.72
0.27
0.61
space
0.23
-0.02
0.28
0.36
0.27
been
0.37
0.08
0.03
-0.01
0.14
around
learn
0.16
0.01
-0.84
0.29
0.82
flexibility
0.14
0.69
0.1
-0.7
1.0
proportional
0.24
0.24
0.14
0.084
factor
variance


Table 3 :
3
Sports (70% of variance explained by all factors).
Factor 0 Factor 1 Factor 2 Factor 3 Communality
likes
0.82
-0.0
0.38
0.1
0.82
popular
0.95
-0.07
0.02
0.14
0.93
think
0.88
0.17
0.2
-0.07
0.84
colorful
0.3
0.13
0.18
0.66
0.58
dishes
0.9
-0.14
0.02
0.13
0.85
available
0.71
-0.18
0.05
0.11
0.55
healthy
0.26
-0.4
-0.19
0.12
0.28
fragrant
-0.16
-0.09
0.2
0.49
0.31
warm
0.42
0.05
0.06
0.04
0.19
sweet
0.24
0.31
0.07
0.72
0.67
large
0.21
-0.1
0.74
0.33
0.72
crunchy
0.06
-0.56
0.05
-0.06
0.32
heavy
0.25
0.35
0.87
0.24
1.0
calories
0.16
0.95
0.12
0.24
1.0
proportional
0.30
0.12
0.12
0.011
factor
variance


Table 4 :
4
Vegetables (65% of variance explained by all factors).
Factor 0 Factor 1 Factor 2 Factor 3 Factor 4 Communality
likes
0.91
0.05
-0.03
-0.0
-0.05
0.84
expensive
0.11
0.91
0.15
-0.06
0.15
0.89
think
0.79
0.4
-0.1
0.03
0.05
0.79
large
0.39
0.88
-0.08
0.16
-0.01
0.96
requires
-0.12
0.22
0.44
0.46
0.01
0.47
electricity
gets hot
-0.02
0.07
-0.21
0.91
0.33
1.0
specialized
-0.49
-0.05
-0.11
-0.11
0.0
0.27
common
0.95
0.05
-0.02
-0.07
-0.01
0.92
dangerous
-0.1
0.03
0.49
0.23
0.83
1.0
essential
0.92
0.23
-0.09
-0.22
0.1
0.97
loud
-0.01
0.01
0.85
-0.14
0.03
0.74
heavy
0.11
0.87
0.04
0.13
0.1
0.8
plain sight
0.71
0.36
0.0
0.15
-0.24
0.71
often
0.94
0.15
0.04
-0.11
-0.14
0.95
easy
0.66
-0.12
-0.25
-0.18
-0.15
0.57
metallic
-0.1
0.28
-0.25
0.16
0.54
0.46
proportional
0.34
0.18
0.087
0.083
0.077
factor
variance


Table 5 :
5
Kitchen appliances (77% of variance explained by all factors).
Factor 0 Factor 1 Factor 2 Factor 3 Communality
likes
0.77
-0.09
0.22
0.17
0.68
people
-0.01
-0.54
0.23
-0.05
0.35
oriented
pays well
0.72
0.1
0.23
-0.13
0.59
been
-0.06
0.13
0.25
0.34
0.19
around
desirable
0.95
-0.06
0.22
0.07
0.95
common
-0.34
-0.28
-0.15
0.49
0.45
think
0.58
0.01
0.08
0.04
0.35
important
0.23
0.24
0.13
0.46
0.34
creativity
0.29
-0.16
0.62
-0.06
0.5
skills
0.36
0.33
0.73
0.17
0.79
physical
-0.21
0.65
0.1
0.08
0.48
dangerous
-0.13
0.7
0.07
-0.05
0.51
detail
0.38
-0.0
0.68
0.35
0.72
oriented
glamorous
0.75
-0.1
0.27
-0.38
0.78
male
0.18
0.64
0.12
0.14
0.47
dominated
difficult
0.29
0.56
0.56
0.01
0.71
proportional
0.22
0.14
0.13
0.059
factor
variance


Table 6 :
6
Jobs (55% of variance explained by all factors).
Factor 0 Factor 1 Factor 2 Factor 3 Communality
likes
0.65
0.43
0.02
0.32
0.71
religious
0.19
-0.13
0.93
-0.26
0.98
think
0.43
0.43
0.08
0.32
0.48
political
0.12
-0.4
-0.52
-0.11
0.45
around
0.2
0.29
0.71
0.33
0.73
family
0.6
0.38
0.42
-0.08
0.69
oriented
partying
-0.01
0.93
0.09
0.08
0.88
time off
0.54
0.08
0.07
0.06
0.31
romantic
0.03
0.21
0.13
0.36
0.19
traditions
0.21
0.59
0.68
-0.01
0.86
food
0.25
0.65
0.63
0.04
0.89
widely
0.59
0.33
0.32
0.66
1.0
celebrated
reflective
0.81
-0.12
0.08
-0.07
0.69
joyous
0.42
0.75
0.33
0.08
0.86
meaningful
0.91
0.09
0.1
-0.04
0.86
early
-0.06
-0.11
-0.16
0.48
0.27
proportional
0.22
0.20
0.18
0.076
factor
variance


Table 7 :
7
Holidays (68% of variance explained by all factors).
Study 5
Category
Feature
Probability of Intrusion
large
0.091
small
0.21
dangerous
0.15
harmless
0.41
zoo animals
striking
0.18
unremarkable
0.54
long-lived
0.22
short-lived
0.56
cool
0.083
boring
0.62
time off
0.50
little time off
0.51
widely celebrated
0.22
few celebrate
0.78
holidays
likes
0.13
doesn't like
0.59
romantic
0.38
unromantic
0.53
often think of
0.60
rarely think of
0.54
popular
0.13
unpopular
0.70
many locations
0.067
few locations
0.71
chain restaurants
ordinary
0.13
unique
0.57
cheap
0.30
expensive
0.45
bright logo
0.36
dull logo
0.52


McRae, Cree, Seidenberg, and Mcnorgan (2005)
 and
Buchanan, Valentine, and Maxwell (2019)
 offer related ideas on how to describe and compare category members in terms of certain category-relevant features, and De Dayne et al.(2019)and
Rips, Shoben, and Smith (1973)
 give alternate approaches to empirically describe how categories and category members are organized in conceptual space.


In the first two studies, we initially collected data on what comes to mind for six different ad hoc categories-3 having to do with zoo animals and 3 having to do with vegetables. However, to make completing and reporting this series of studies more feasible, we arbitrarily chose only one from each group to use in the full set of studies and analyses.


The model included fixed effects for whether or not the feature space location was predictive, as well as the category in question, and random intercepts for individual participants (who listed multiple considerations) with random slopes to account for variable effects of predictiveness of a feature space location depending on the feature dimension with respect to which it is defined.


When calculating the correlation between feature ratings and frequency of either consideration or response for each zoo animal, we included all zoo animals in the category member list as described in section 2. There were 6 zoo animals given as considerations by at least 2 and at most 4 participants, as well as 1 response given by 2 participants, that were not included in this list. These were excluded from analysis.








Acknowledgements
We are very grateful to members of Dartmouth's PhilLab for their helpful feedback, audiences at the Cognitive Science Society and the Society for Philosophy and Psychology for comments, and the editor and three reviewers for their helpful suggestions.






Supplementary Material
All materials for the paper are openly available both on github (https://github .com/PhilLaboratory/WhatComesToMind/) as well as on the Open Science Framework (https://doi.org/10.7910/DVN/ISZQG3/).


Study 3
Locating category members in feature space. We asked participants how well different features described category members. Most of these judgements were given as a rating between 1 and 5 as to how well a feature statement of the form 'This [category member] [has this feature]' described a category member, as described in the main text. In the zoo animals category, certain features were asked about in a slightly different way to make the task more natural. Participants were asked to choose from options when describing an animal's diet (herbivore/omnivore/carnivore), type (mammal/reptile/amphibian/bird/fish/invertebrate), and sleeping patterns (nocturnal/ diurnal), with responses numerically coded as a rating of 1 for the selected option (i.e. herbivore) and ratings of 0 for the unselected options (i.e. omnivore and carnivore). For features describing an animal's habitat (lives in the desert/forest/tropics/arctic/land/water) participants were asked to give a yes/no response (coded as 1 or 0). For judgements about a zoo animal's lifespan, participants were asked to choose from long/medium/short, with responses coded as 2, 1, and 0.
Analyzing feature predictiveness of what comes to mind. The extent to which category members have certain features co-vary, and these features do not always account for independent variance in the likelihood of category members coming to mind. Here we report, for each category, results from a principal component factor analysis over category member locations along each feature dimension. In the zoo animals category, 4 features are excluded from analysis. Three 
('nocturnal', 'lives in water', 'diet, herbivore')
 are excluded because they have extremely high correlations with another feature ('diurnal', 'lives on land', and 'diet, carnivore' respectively). One ('type, invertebrate') is excluded because it has zero variance across category members. The analyses are conducted with varimax rotation, and the number of factors reported for each category is determined by the number of factors with eigen values > 1. Factor loadings and communalities are reported in the tables below.
 










A spreading activation theory of memory




J
R
Anderson




10.1016/S0022-5371








Journal of Verbal Learning and Verbal Behavior




22


3
















Ideals, central tendency, and frequency of instantiation as determinants of graded structure in categories




L
W
Barsalou








Journal of experimental psychology: learning, memory, and cognition




11


4


629














Category norms of verbal items in 56 categories a replication and extension of the connecticut category norms




W
Battig






W
Montague








Journal of Experimental Psychology




80
















What comes to mind?




A
Bear






S
Bensinger






J
Jara-Ettinger






J
Knobe






F
Cushman








Cognition




194














English semantic feature production norms: An extended database of 4436 concepts




E
Buchanan






K
Valentine






N
Maxwell








Behavioral Research Methods




51


4
















The "small world of words" english word association norms for over 12,000 cue words




S
De Dayne






D
Navarro






A
Perfors






M
Brysbaert






G
Storms








Behavioral Research Methods




51
















Measures of internal category structure: A correlational analysis of normative data




J
Hampton






M
Gardiner








British Journal of Psychology




74
















What to simulate? inferring the right direction for mental rotation




J
B
Hamrick






T
L
Griffiths








Proceedings of the 36th annual meeting of the cognitive science society


the 36th annual meeting of the cognitive science society












The Cognitive Science Society








Concept accessibility as the determinant of typicality judgments




G
Janczura






D
Nelson








American Journal of Psychology




112


1
















Take the first: Option-generation and resulting choices. Organizational behavior and human decision processes




J
G
Johnson






M
Raab








91
















R
Kellogg




Feature frequency in concept learning: What is counted? Memory and Cognition






9














Characteristics of skilled option generation in chess. Organizational behavior and human decision processes




G
Klein






S
Wolf






L
Militello






C
Zsambok








62














The anchoring bias reflects rational use of cognitive resources




F
Lieder






T
L
Griffiths






M
Huys






Q
J
Goodman






N
D




10.3758/s13423-017-1286-8








Psychonomic Bulletin & Review




25


1
















Correlated properties in natural categories




B
Malt






E
Smith








Journal of Verbal Learning and Verbal Behavior




23


2
















Semantic feature production norms for a large set of living and nonliving things




K
Mcrae






G
Cree






M
Seidenberg






C
Mcnorgan








Behavior Research Methods




37
















Categorization and reasoning among tree experts: Do all roads lead to rome?




D
Medin






E
Lynch






J
Coley






S
Atran








Cognitive Psychology




32
















Relationships among goodness-of-example, category norms, and word frequency




C
Mervis






J
Catlin






E
Rosch








Bulletin of the Psychonomic Society




7
















Categorization of natural objects




C
Mervis






E
Rosch








Annual Review of Psychology




32
















Generating options and choosing between them depend on distinct forms of value representation




A
Morris






J
Phillips






K
Huang






F
Cushman








Psychological Science




32


11
















Typicality and the Classical View of Categories




G
Murphey




10.7551/mitpress/1602.003.0002


doi: 10.7551/ mitpress/1602.003.0002








The MIT Press












How we know what not to think




J
Phillips






A
Morris






F
Cushman








Trends in Cognitive Sciences




23


12
















Semantic distance and the verification of semantic relations




L
Rips






E
Shoben






E
Smith








Journal of Verbal Learning and Verbal Behavior




12


1
















Cognition and categorization. Lawrence Elbaum Associates




E
Rosch






B
Lloyd






E
Rosch






C
Simpson






S
Miller








Journal of Experimental Psychology: Human Perception and Performance




2


4










Structural bases of typicality effects








Retrievalconstrained valuation: Toward prediction of open-ended decisions




Z
Zhang






S
Wang






M
Good






S
Hristova






A
S
Kayser






M
Hsu








Proceedings of the National Academy of Sciences




20


118















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]