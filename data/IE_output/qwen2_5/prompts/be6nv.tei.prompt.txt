You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



What are the origins of reward?
The concept of reward is a cornerstone across behavioral science, cognitive neuroscience, and artificial intelligence. Rewards serve as powerful incentives and essential teaching signals that guide learning in both biological and artificial systems: from the tasty morsel that motivates a mouse in a maze, to monetary incentives that reinforce human behavior to the points that train algorithms to master chess. The mechanisms of learning from rewards have been extensively studied, particularly in the field of reinforcement learning 
(Botvinick et al., 2019;
Dayan and Balleine, 2002;
Dayan and Niv, 2008;
Schultz, 2015;
Schultz et al., 1997;
Sutton and Barto, 1998)
.
Here, a significant body of research has focused on the role of the neurotransmitter dopamine as a "common currency" for processing rewards and the dopamine system as the primary locus for the reinforcement of a behavior in the brain 
(Collins and Frank, 2014;
Dayan and Balleine, 2002;
Lerner et al., 2021;
Schoenbaum et al., 2013;
Schultz, 2016;
Schultz et al., 1997)
; Box 1).
However, a critical question remains unanswered: Where does the reward signal come from that drives that reinforcement?
Traditionally, rewards have been thought to be signaled by the immediate outcomes of actions, like the amount of juice given to an animal or the points awarded to a human in an experiment.
In this view rewards are static, quantifiable external entities. This is at odds with what we know about biological agents: First, it neglects the complexity and dynamic nature of biological systems, where no singular sensory pathway is dedicated to reward detection 
(Hayden and Niv, 2021;
. Instead, reward must be inferred based on contextdependent and internally generated signals 
(Bavard and Palminteri, 2023;
Kobayashi et al., 2010;
Padoa-Schioppa, 2009)
. Second, whether an outcome is rewarding and the degree to which it is rewarding -the reward function -depends on an agent's goals. Designing specific reward functions for different goals in artificial agents is a non-trivial problem 
(Silver et al., 2021;
Singh et al., 2010
Singh et al., , 2009
Zheng et al., 2020
), but we know that biological agents routinely set their own goals. Therefore, reward cannot be inherent to the stimulus but must be computed within the organism (de 
Araujo et al., 2020
Araujo et al., , 2008
Han et al., 2018;
Holman, 1969;
Sclafani, 2004;
Tellez et al., 2013b)
.
Indeed, in what follows, we consider findings from studies of ingestive behavior clearly demonstrating that the critical reinforcing signals from food and water are not linked directly to consumption (reviewed in (de 
Araujo et al., 2020)
). Instead, they originate from delayed post-oral primary reward signals generated during digestion and absorption, which are necessary and sufficient for reinforcing behavior (Part 1, see Glossary). These interoceptive primary rewards are accompanied by a cascade of earlier signals, referred to as secondary and proxy rewards, whose main role is not to sustain reinforcement but to facilitate learning and prospective control (Part 2). Furthermore, there is increasing evidence that both the internal states and goals of an organism contribute to the generation and modulation of primary reward signals (Part 3).
Together, these findings shift our understanding of rewards from immediate sensory gratification to a state-dependent evaluation of an action's impact on vital physiological processes. That is, the true value of food and water lies in an organism's ability to transform these goods into vital resources for survival-nutrients, energy, hydration, or the support of reproductive functionswhen needed. In the last part of this paper, we sketch how the reinforcement learning framework might be revised to recognize the subjective and dynamic nature of biological rewards (Part 4).


Primary reward signals represent essential physiological variables
Where do reward signals for food or water come from? During digestion, the energy required to support cellular functions is released from foods. This is a fundamental physiological process supporting life that requires no learning. However, since organisms must procure energy in order to sustain life, there is a clear adaptive advantage for the evolution of a reinforcing mechanism to couple nutrient digestion with behavior. As nutrient digestion arrives with a significant delay from consumption, it was initially thought that reinforcement from food involves hormone release, which retroactively "stamps-in" reward 
(Messier and White, 1984)
. However, while hormones can be powerful regulators of reward sensitivity 
(Fulton et al., 2000;
Schulz et al., 2023)
 and internal states 
(Liebling et al., 1975;
Smith and Gibbs, 1985)
, hormones are not themselves reinforcing (with the notable exception of cholecycstokinin (CCK), detailed below). That is, there is no evidence that animals will work to self-administer feeding and satiety hormones (e.g., ghrelin, insulin, leptin). Rather, hormones primarily produce an inhibitory effect on behavior (e.g., satiety and meal termination), with the exception of ghrelin, which stimulates hunger and feeding 
(Kojima and Kangawa, 2002;
Malik et al., 2008)
 and can act as a negative reinforcer to condition avoidance 
(Schéle et al., 2017)
. So, if not from hormones, where does the reinforcement come from? To answer this question, it is useful to start with the case of sugar.


The case of sugar
When a mouse licks a spout to obtain a sugar solution, dopamine levels in the striatum rise.
However, seminal work over the last decade has shown that neither licking nor dopamine release is sustained if a non-nutritive sweetener (e.g. sucralose) is used instead of sugar (e.g. sucrose or 6 glucose) 
(Beeler et al., 2012;
de Araujo et al., 2008;
Tan et al., 2020;
Tellez et al., 2013b)
. That sugar reinforcement is not tied to sweetness can also be seen in sweet taste "blind" mice, where sugar can still condition preferences and cause dopamine release (de 
Araujo et al., 2008;
Tan et al., 2020)
. Put simply, sweet taste and other oral sensations are neither necessary nor sufficient to sustain glucose-related dopamine release and appetitive responding. Instead, and in keeping with the utility of glucose as a cellular fuel, sugar reinforcement is generated when glucose is oxidized to produce adenosine triphosphate (ATP), which is the fundamental energy source of life. The result is that any potential glucose source is as reinforcing as it is a useful source of energy. Evidence to support this contention comes from a study investigating the effects of feeding on dopamine release 
(Tellez et al., 2013b)
. When mice ingest glucose, extracellular dopamine levels in the striatum increase; however, when the anti-metabolic agent, 2 deoxyglucose (2-DG), is simultaneously administered, dopamine efflux is blocked and licking for glucose declines as if it is less reinforcing. Since 2-DG prevents the cells from using glucose to generate ATP, this result implies that a reinforcing signal is generated when cells use energy for fuel 
(Tellez et al., 2013b)
. Parallel findings are observed in human fMRI studies where responses in the striatum to calorie predictive flavor cues reflect the metabolic impact of prior consumption of those flavors with a sugar (i.e., increases in plasma glucose and dietary induced thermogenesis, DIT) (de 
Araujo et al., 2013;
Veldhuizen et al., 2017)
. Currently, the identity of this reinforcing signal and sensor remains unknown. However, there is evidence that a sensor exists in the hepatoportal vein 
(Zhang et al., 2018)
, a blood vessel transporting nutrients from the gastrointestinal tract to the liver, which generates neural signals that are carried via the vagus nerve to brain dopamine circuits 
(Figure 1)
. Direct infusion of metabolizable sugar here increases dopamine levels in the striatum and conditions flavor preference, but not the infusion of nonmetabolizable sugar, revealing the key role of the hepatoportal vein as an energy sensing mechanism driving reinforcement. Additionally, there is evidence for a sugar sensing pathway from the upper intestine 
(Han et al., 2018;
Kaelberer et al., 2018;
Tan et al., 2020)
 . Whether this is redundant or carries a distinct function is unknown.


The case of fat
Sugar is not the only signal that can lead to sustained reinforcement. Dietary fat is sensed by a distinct group of cells in the upper intestine, which generate a signal that is conveyed by the vagus nerve to central dopamine circuits 
(Han et al., 2018;
Kaelberer et al., 2018;
McDougle et al., 2024)
 
(Figure 1
). Animals will work to optogenetically stimulate this pathway, reflecting gutderived reward 
(Han et al., 2018)
. Additionally, gut administration of CCK, which is ususally contingent upon nutrient sensing, also activates this pathway to cause dopamine release. Like glucose, intragastric infusion of lipids results in dopamine efflux in the dorsal striatum and this effect can be blocked with bilateral vagotomy 
(Tellez et al., 2013a)
. There is also evidence that the sugar and fat pathways not only arise from distinct mechanisms, but also project to discrete populations of fat-sensitive or sugar-sensitive neurons in the nodose ganglion, hindbrain and midbrain, such that there are parallel but segregated reinforcing signal to the brain dopamine circuits 
(McDougle et al., 2024)
. Interestingly, concurrent activation of both pathways (i.e., by consuming foods with fat and carbohydrate), appears to potentiate reinforcement in humans 
(DiFeliceantonio et al., 2018)
 and in mice 
(McDougle et al., 2024)
 so that calorie for calorie, foods with both fat and carbohydrate are more reinforcing (and release more dopamine) than those with fat or carbohydrate alone. This example highlights the importance of signals generated by the organism rather than characteristics inherent to the food (e.g., calories) as the key drivers of reinforcement. In summary, multiple mechanisms are tied to the sensing of energy and nutrients that generate post-oral reinforcement in response to dietary fat and sugar, the two main energy sources fueling life.


8


The case of water
As with sugar and fat, the primary reinforcing signal from water consumption appears to be rooted in post-oral feedback after water consumption 
(Grove et al., 2022)
 
(Figure 1
). Grove and colleagues conducted an elegant series of experiments and discovered that water-deprived animals show robust dopamine responses in the VTA time-locked to licking water, followed by two secondary, sustained post-ingestion activations in the striatum when water enters the gastro-intestinal track and is absorbed into the bloodstream. Strikingly, but similar to effects observed with feeding described above, the secondary dopamine response to rehydration is not strictly tied to the act of drinking: The same response is observed when water is directly infused into the stomach, bypassing oral consumption. Conversely, this dopamine activation is notably absent when the water is substituted with a dehydrating hypertonic solution. This points to a sophisticated post-oral feedback system sensitive to changes in systemic osmolality. Thus, while sugar and fat consumption are rewarding because they supply the body with energy, water consumption seems to be rewarding because it leads to (the detection of) systemic rehydration.
In summary, a picture emerges where the reinforcing effects of foods and fluids are driven by distinct subliminal post-oral primary reward signals. These interoceptive reward signals reflect key physiological resources essential for sustaining life (e.g., energy, nutrients, or hydration), such as the metabolism of glucose into ATP, detection of lipids in the upper gut, and systemic osmolality changes. These events are directly signaled to the brain's dopamine system, allowing the organism to optimize decision making towards actions and objects key to survival. While the exact afferent pathway for carbohydrates is still subject of investigation, there is evidence that glucose oxidation after sugar consumption is sensed in the portal vein 
(Zhang et al., 2018)
 and transmitted through vagus nerve and the nodose ganglion to the midbrain dopamine system (de 
Araujo et al., 2020;
Tellez et al., 2016)
. Fats (lipids): Fat is detected in the upper intestine, where it activates peroxisome proliferator-activated receptors (PPAR-α). This activation sends reinforcing signals via the vagus nerve to the nodose ganglion and hindbrain, which in turn increases dopamine release through the substantia nigra 
(Han et al., 2018;
McDougle et al., 2024)
. Although the pathways for fat and sugar appear similar, they are parallel and activate distinct sub-populations (McDougle 2024). There is also evidence that sugar is sensed in the upper intestine, leading to vagal signals 
(Kaelberer et al., 2018;
Tan et al., 2020)
. Whether this pathway is redundant or distinct in function from the hepatoportal sensor is unknown. Water: The pathway for water is still partially unknown. However systemic rehydration is likely detected from changes in blood osmolality and projected to dopamine neurons in the ventral tegmental area (VTA) via GABAergic projections from the lateral hypothalamus tracking fluid balance 
(Grove et al., 2022)
. While these pathways have primarily been studied in rodents, it is believed that similar mechanisms exist in humans.


10


Box 1: Reinforcement learning and the Dopamine System
Reinforcement learning (RL) models have been remarkably successful at describing how organisms learn from rewards 
(Sutton and Barto, 1998)
. At the heart of this approach is an agent that interacts with its environment via actions ( ! ). Those actions result in changes in the environment (changes in state ! ) and in outcomes that affect the agent (rewards ! ) ( 
Figure 3B)
. RL aims to solve the problem of learning an action policy -picking an action given states and previous outcomes -that maximizes the cumulative long-term expected reward for the agent.
Since agents don't necessarily know which actions lead to the best long-term outcomes, they need to learn the optimal policy at any given moment in time t. One way to find the optimal policy is via temporal-difference learning (TD) where the agent iteratively evaluates and updates its policy based on the differences between the actual observed rewards ! and the expected values -the sum of expected future rewards -by learning from reward prediction errors (RPE) ! :
! = ! + ! ( !"# ) − ! ( ! ) !"# ( ! ) = ! ( ! ) + ! ,
where is the amount of value update or the learning rate. One of the big revelations of the past decades was the discovery that phasic activity in midbrain dopamine neurons seems to reflect TD-like RPEs between the received reward and the expected time and magnitude of reward that are directly associated with the reinforcement of behavior 
(Fiorillo et al., 2008;
Keiflin et al., 2019;
Maes et al., 2020;
Niv and Schoenbaum, 2008;
Schultz, 2016;
Schultz et al., 1997;
Sharpe et al., 2017
; Watabe-Uchida et al., 2017) (see 
Figure 2
).
The distinction between reward and value is critical in this algorithmic context. Reward refers to the valenced outcome of an action, that reinforces behavior. In contrast, value represents the summed expectation of future rewards, integrating past experiences and the potential long-term benefits or costs of an action. In other words, value is inherently future-oriented, subjective, model-and experience-dependent, whereas reward serves as a 'ground-truth' correction signal and is thus linked more closely to the current time point and treated as an objective 'external'
feedback.
Note that this definition of reward is at odds with an agent capable of generating their own goals. This is because goals in RL are implicit in the reward function. While the agent learns a policy that optimizes the long-term expected reward, what is eliciting those rewards will determine the long-term goals of an agent. With externally generated rewards R, the agent will only ever have one goal: maximizing reward. Any other goal will be implicit in the reward function and not under the agent's control. Thus, agents capable of pursuing their own goals need internally generated reward functions.


The role of secondary and proxy rewards


Proxy rewards solve the credit assignment problem
A critical aspect of primary reward signals discussed above is that they arrive with a delay: The benefits of eating or drinking unfold over minutes to hours, as digestion, absorption, and rehydration are slow. Despite this delay, primary rewards still reinforce cues and behaviors that occurred during or even prior to consumption (de 
Araujo et al., 2008;
Holman, 1969;
Sclafani, 2004)
. This temporal gap between action (consumption) and outcome (reward signal) poses a 'credit assignment' problem, in which the organism must link the value of a delayed outcome (i.e., the primary reward signal) to the act of consumption that led to it 
(Dayan, 2022;
Sutton and Barto, 1998)
.
Biological agents navigate this challenge by leveraging sensory signals that provide an early prediction of the expected physiological consequences of their actions. Specifically, food and water consumption are accompanied by a cascade of early signals including both pre-oral sensors (e.g., vision and olfaction) and intra-oral oral sensors (e.g., taste, flavor, and texture) that offer a rough estimate of future hydration levels and energy availability, by signaling the potential presence and value of nutrients or toxins (de 
Araujo, 2011;
Grove et al., 2022;
 2016; Zimmerman and Knight, 2020).
These early pre-oral and intra-oral signals have been associated with phasic dopamine activity in both humans 
(Thanarajah et al., 2019;
Van Galen et al., 2023)
 and animals 
(Grove et al., 2022;
Han et al., 2018;
McDougle et al., 2024;
Tan et al., 2020;
Tellez et al., 2013a)
 
(Figure 2A
). Yet, while the response to earlier pre-oral cues, such as a bell or a visual signal, requires learning (secondary rewards), oral signals, in particular taste, produce immediate and innate subjective experiences of liking/disliking (Box 2).
The immediate dopamine responses following consumption initially led to the belief that intraoral signals were the primary reinforcers driving conditioned responses to earlier cues indicating food arrival in classical conditioning scenarios 
(Figure 2A)
. However, while oral signals do seem to play a privileged role during the reinforcement of food or water intake (Box 2), they should be reconceptualized as intermediate proxy rewards, because they do not sustain reinforcement nor dopaminergic activity on their own without the primary delayed reinforcement signal ( 
Figure   2B
). A prime example of this is flavor-nutrient conditioning (FNC). Rodents readily develop preferences for flavors associated with post-oral energy signals (e.g., glucose oxidation) over those with pleasant taste sensations but no nutritional value (e.g., non-nutritive sweeteners) 
(Holman, 1969;
Sclafani, 2004;
Sclafani and Glendinning, 2003)
. Blocking the generation of postoral signals by eliminating ATP production or severing the vagus nerve in these scenarios blocks central dopamine release and FNC 
(Tan et al., 2020;
Tellez et al., 2013b)
. Similarly, animals that lack the ability to sense sweet taste nevertheless form preferences for fluids containing sugar based upon the generation of a post-oral reward signal (de 
Araujo et al., 2008;
Tellez et al., 2013b)
. Thus oral sensory pleasure is neither necessary nor sufficient to sustain reinforcement.
So what is the role of proxy rewards? 
Dayan (2022)
 proposed that the function of these innate affective responses might be to provide an 'early affective draft' of the long-term expected value of consumed goods to help bridge the delay between actions and outcomes and solve the credit assignment problem 
(Dayan, 2022)
. For example, a proxy reward signal linked to sweet taste will initialize the value of consuming the food item, which will speed up learning the association of the action with the later burst of energy when glucose is metabolized into energy. This idea of using intermediate proxy reward signals to speed up learning the value of actions with delayed consequences is known as ‚shaping' in both animal learning 
(Skinner, 1975)
 and models of Reinforcement Learning 
(Ng et al., 1999;
Randløv and Alstrøm, 1998
 
(Zheng et al., 2020)
, with implications for both biological and artificial intelligence, such as designing artificial agents that navigate environments with sparse or delayed rewards 
(Devidze et al., 2022;
Ng et al., 1999;
Randløv and Alstrøm, 1998)
. 


Box 2: The matter of taste
Oral signals include gustatory, retronasal, olfactory and oral somatosensory inputs. Each is transduced by distinct receptors but integrated in the brain to produce a unitary perception of flavor 
(Small, 2012)
. Oral sensations play a privileged role in facilitating credit assignment since they pair the action (consumption) with a proxy of the expected delayed outcome experienced subjectively as liking or disliking 
(Dayan, 2022)
. It is also important to appreciate that taste and flavor perceptions play distinct roles in guiding intake.
Taste perceptions (sweet, sour, salty, bitter, and savory) serve as indicators of potential nutritional values or harmful consequences of ingested substances. However, contrary to intuition, taste plays a rather limited role in identifying foods and flavors. Rather, this depends on retronasal olfaction 
(Mozell et al., 1969)
, which occurs when volatiles from the mouth reach the olfactory receptors in the nasal cavity and then evoke quality-specific codes in the primary olfactory cortex 
(Gottfried et al., 2006)
. Consequently, we can perceive the sense of strawberry both as an aroma in the world and as a flavor in our mouths. However, we can only know how sweet that strawberry is by putting it in our mouths.
Affective responses to taste are stable: They are observed in newborns of many species 
(Steiner, 1973)
, indicating that they are either innate or learned in utero. In contrast, flavor preferences are largely learned 
(Sclafani, 2004)
. This points to an important distinction for their respective roles in reinforcement learning: Flavor perception enables organisms to learn new associations between nutritional outcomes with specific foods allowing the development of preferences or aversions based on experiences like malaise (i.e., conditioned flavor avoidance), pleasure or the receipt of energy (conditioned flavor preference). Hence a negative experience with a sweet food, such as food poisoning, might lead to avoidance of that specific food, rather than all sources of energy from foods with sugar 
(Small, 2012)
. By contrast, taste identifies the presence and quantity of potential nutrients or toxins without requiring learning. This is advantageous because it would be perilous to have to learn that bitter should be rejected and sweet accepted. 


Distinct striatal architectures for primary and proxy rewards
Emerging evidence suggests that oral proxy rewards and post-oral primary reward signals engage distinct neural pathways within the dopamine system. Specifically, early oral reward signals predominantly activate the ventral striatum (VS), in particular the nucleus accumbens (NAcc) 
(Grove et al., 2022;
Tellez et al., 2016)
. In contrast, late post-oral signals primarily recruit the dorsal striatum (DS) 
(Grove et al., 2022;
Tellez et al., 2016)
.
This anatomical distinction between early and late signals in relation to the VS and DS likely maps onto discrete functional roles 
(Averbeck and Murray, 2020)
. The VS is known for its involvement in reward anticipation and value learning and is associated with the hedonic aspects of food consumption, or "liking" 
(Morales and Berridge, 2020)
. This aligns with the idea that early cues act as intermediate, proxy rewards that expedite value-based learning and help bridge the gap until the final action-reinforcing signal arrives 
(Dayan, 2022)
. In contrast, the DS is linked to action learning and motivation-related signals, or "wanting", consistent with the notion that late primary reward signals serve as direct reinforcers of behavior. This view is further supported by early research showing that restoring dopamine signaling in the DS, but not the VS, was sufficient to rescue feeding behavior and prevent starvation in dopamine-deficient mice 
(Szczypka et al., 2001
). Human PET studies further corroborate this distinction, showing that dopamine release during oral stimulation occurs in the VS (along with the insula and hypothalamus), while postmeal tonic dopamine responses are observed in the DS (and basolateral amygdala) 
(Small et al., 2003;
Thanarajah et al., 2019)
.


Beyond credit assignment: Early signals drive prospective control
Beyond facilitating action-outcome learning, early predictive pre-and intraoral signals play an important role enabling organisms to forecast potential future bodily states and act prospectively 
(Livneh et al., 2020)
. For example, predictive cues can help an organism discern when to stop drinking or eating based on the expected effects on hydration and energy levels, without waiting for delayed post-ingestive feedback.
Evidence for prospective control can be seen in an increase of insulin release and a suppression of AgRP 'hunger' neurons in response to food-predicting cues, which leads to an increased metabolism of the ingested food and a direct modulation of food consumption 
(Betley et al., 2015;
Chen et al., 2015;
Sternson, 2013)
. Interestingly, prospective control can influence the final reward signal itself. For example, higher insulin levels impact the conversion of glucose into energy, thereby affecting the post-oral reward derived from glucose oxidation. Accordingly,
Veldhuizen and colleagues demonstrated that dietary-induced thermogenesis (DIT) following carbohydrate consumption is modulated by the sweetness and conditioned liking of the consumed beverage 
(Veldhuizen et al., 2017)
.
Furthermore, early predictive cues significantly boost motivation and change perception. This is evident in cue-potentiated feeding, which can occur even in the absence of hunger 
(Petrovich et al., 2002;
Weingarten, 1983)
, and in the stimulation of cravings through mental simulation, such as imagining the taste of food 
(Perszyk et al., 2021)
. In humans, the response to food cues has been identified as a significant predictor of cue-potentiated feeding and long-term weight gain 
(Perszyk et al., 2021)
. Moreover, expectations about future satiety prior to consumption significantly impact subjective reports of fullness even hours later 
(Brunstrom et al., 2011)
 .
Thus, while primary reward signals reflect essential physiological variables (i.e., the energy extractable from food) this energy availability is subsequently influenced by anticipatory and preparatory actions (i.e., metabolic changes in the body). This highlights a closed loop between the anticipation of reward, preparatory actions that are informed by this anticipation (allostasis), and the feedback (post-oral) reward, which then in turn improves future predictions.


The state dependency of primary reward
The previous sections review the evidence that primary reward signals for food and water rewards are internally generated and driven by specific bodily events, such as nutrient detection 
(Figure 1
). Yet, how valuable an outcome is to an individual not only depends on its nutritive value but also on a person's needs, desires, goals, and context. For instance, a burger will be more valuable to a hungry than a sated person (internal state/need), but less valuable if a more attractive alternative is also available (context), or if the person is on a diet (goals), or extremely thirsty (competing need). Consequently, one might wonder if each of these contexts elicits a different primary post-oral reward signal or if the primary reward signal is constant, but subsequently ‚contextualized' by the organism's internal state and goals.
Although extensive research exists on the state-dependency of early pre-and intra-oral signals (e.g., how hunger and thirst influence the dopamine responses to food cues) (i.e. 
(Abizaid et al., 2006;
Averbeck and Murray, 2020;
Cabanac, 1971;
Cone et al., 2014;
Fulton, 2010;
Fulton et al., 2000;
Saper et al., 2002)
), precisely how internal states impact primary post-oral reinforcing signals is currently unknown (but see 
(Grove et al., 2022;
Han et al., 2018)
). This gap in knowledge is primarily due to the relatively recent discovery of these signals. The presently available data support at least two kinds of interactions between internal states and primary reward signals:
'state-generated' reward signals, where reinforcing signals directly reflect a beneficial change in current internal state, and 'state-modulated' signals, where reinforcing signals are modulated in their amplitude by anticipated future internal state ( 
Figure 3B)
.


State-generated primary reward signals
Fluid consumption is an prime example where primary reward signals directly reflect the detection of a change in an internal state ( 
Figure 3B)
. Here, a subset of VTA neurons has been identified that responds to changes in systemic osmolarity and is both necessary and sufficient for reinforcing fluid consumption 
(Grove et al., 2022)
. Crucially, this dopamine response is driven by GABAergic neurons in the lateral hypothalamus (LH), which track fluid balance, in line with earlier research implicating the hypothalamic pathway in reinforcement and motivational salience 
(Allen et al., 2017;
Fulton, 2010;
Fulton et al., 2000;
Nieh et al., 2016)
. Importantly, this indicates that the primary reward associated with water consumption is triggered by the detection of an actual beneficial change in current systemic hydration (fluid balance), not by a desired or anticipated change in state as it is represented by thirst-promoting neurons in the subfornical organ (SFO) (see Box 3). Importantly, while thirst does not seem to be the underlying cause of primary reward signals associated with rehydration, it does modulate the reward upon the consumption of water, consistent with a gating of reward signals by need state 
(Cone et al., 2014;
Fulton et al., 2000;
Harris et al., 2000;
Sclafani, 2004)
 and reminiscient of how physiological states gate sensory signals related to food 
(Livneh et al., 2017)
.


20


Box 3: The role of hunger and thirst in drive reduction
The idea that behavior is reinforced to the extent that it brings an organism's internal states closer to their optimal or desired value goes back to Hull's drive reduction theory of motivation 
(Hull, 1943)
. According to this theory, deviations of critical internal variables -such as energy levels, temperature, fluid balance -from their desired values (referred to as 'set points' or 'set ranges' which support the organism's functioning) create drives. These drives are need states that motivate the organism to seek out resources like food or shelter. According to this theory, an outcome is rewarding and an action reinforced to the extent that it changes internal states of that organism to successfully reduce this homeostatic drive.
Thus, drive neurons must represent need states and be linked to the motivation to reduce drive 
(Andermann and Lowell, 2017;
Augustine et al., 2018;
Gizowski and Bourque, 2017;
Lowell, 2019;
Sternson and Eiselt, 2017;
Zimmerman et al., 2016)
. For example, hunger-promoting AgRP neurons and thirst-promoting SFO in the hypothalamus fulfill these criteria 
(Aponte et al., 2011;
Betley et al., 2015;
Chen et al., 2015;
Krashes et al., 2011;
Reed et al., 2022)
. Interestingly, neither stimulation of 'thirst' nor 'hunger' neurons drives midbrain dopamine activity directly 
(Grove et al., 2022)
, but instead they modulate the dopamine response to primary rewards 
(Abizaid et al., 2006;
Fulton, 2010;
Fulton et al., 2000;
Krashes et al., 2011)
.
This discrepancy may be explained by a recent shift in the understanding of what is represented by thirst and hunger neuron activity 
(Betley et al., 2015;
Chen et al., 2015;
Reed et al., 2022;
Zimmerman et al., 2016)
. Instead of responding to actual caloric or fluid deficits, thirst and hunger neurons are increasingly believed to encode expected future states 
(Reed et al., 2022)
. For example, their activity is rapidly inhibited upon the presentation of predictive food-or waterpredicting cues, even prior to the actual detection of a state change 
(Betley et al., 2015;
Chen et al., 2015;
Mandelblat-Cerf et al., 2015;
Zimmerman et al., 2016)
. These cue-elicited responses are shaped by variables such as food and water availability, palatability and caloric content, suggesting that these hunger and thirst neurons motivate behavior in an anticipatory fashion, consistent with an allostatic (rather than a homeostatic) model 
(Schulkin and Sterling, 2019)
.
The anticipatory nature of their responses may explaining why a change in hunger or thirst neuron activity may not be a suitable source of post-oral reward signals: instead, a separate, 'groundtruth' account of actual change in energy or fluid balance is required -which serves both as a primary reward signal and as corrective feedback to update predictions about expected future states from hunger or thirst neurons 
(Reichenbach et al., 2022;
Su et al., 2017)
.


State-modulation of primary reward signals
Primary reward signals for food seem to be fundamentally different from those associated with water, in that they seem to reflect 'absolute' direct signals caused by a concrete physiological event (i.e., glucose oxidation; see The case of sugar; 
Figure 1
), rather than a beneficial change in internal state 
(Sclafani, 2004)
. This notion is supported by findings that sugar is rewarding (and reinforcing) beyond satiation 
(Chen et al., 2015)
. For instance, artificially inducing satiation (via optical stimulation of the left nodose ganglion) did not affect striatal DA activity nor reinforce behavior. Instead, the reinforcement depended on the pathway linking the detection of nutrients with the VTA (via the right nodose ganglion) 
(Han et al., 2018)
. Importantly, as with thirstpromoting neurons for water reward, stimulation of hunger-promoting AgRP neurons potentiated the activation of VTA dopamine neurons by a primary food reward 
(Alhadeff et al., 2019;
Fulton, 2010;
Grove et al., 2022;
Reichenbach et al., 2022)
. Such modulation of reward responses is also achieved by receptors on dopamine neurons themselves for hormones sensitive to internal state, such as ghrelin and leptin for hunger 
(Abizaid et al., 2006;
Fulton et al., 2000)
, suggesting a potential mechanism for how internal need states (e.g., hunger) modulate, but do not cause, primary reward signals for food ( 
Figure 3B)
.


Does storage explain different architectures for different resources?
The recent discovery of post-oral reward signals reveals an exciting opportunity to investigate their relationship with an organism's internal states and goals. Notable differences are emerging between reward signals for different kinds of resources: Primary reward signals for water rewards are closely tied to beneficial changes in internal state (rehydration), whereas food rewards might originate from more absolute sources related to energy availability, while both are modulated by anticipatory state changes (e.g., thirst and hunger).
One potential explanation for these distinct architectures may be biological storage capacities:
While the surplus energy from food can be stored long-term as fat, which can subsequently be used when energy demands rise, water storage is more limited and the set range of adaptive osmolarity levels is much tighter. This fundamental distinction should influence the neural circuitry that regulates the reinforcement of behaviors acquiring these resources. Specifically, non-storable resources, such as water and temperature, should be prioritized when needed and used proportionate to their restoring effect 
(Burnett et al., 2016;
Gaziano et al., 2022;
Petzold et al., 2023)
. In contrast, storable resources, like food, can be pursued even in the absence of immediate need. This indicates that while food consumption is crucial when hungry, it remains rewarding even after satiation-until the point of physical discomfort or detrimental health effects due to excessive intake as in the case of overeating. Ideally, the neural architecture for such resources would feature a stable reward signal with enhancements during deficits, moderated by long-term negative feedback mechanisms (e.g., stomach fullness, body weight sensors) to prevent overaccumulation, as examplified in body weight sensors that regulate body fat mass 
(Bake et al., 2021;
Jansson et al., 2018)
.
Similar mechanisms might apply to secondary reinforcers used to obtain primary rewards that also have the capacity of storage, such as money. Although money cannot be consumed, and there is no specific sensory channel or metabolic signal for processing money in the body, it serves as a powerful reinforcer for humans -almost as potent as food or water rewards 
(Kim et al., 2011;
Oren et al., 2022;
Valentin and O'Doherty, 2009;
Yee et al., 2021)
. If the capacity for storage determines the cognitive architecture for state-dependent reinforcement, it would suggest that monetary rewards could engage the same neural architecture for food, but not water, rewards (see Outstanding Questions).
In sum, having multiple architectures for implementing state dependency of primary reward signals provides flexibility for adaptive behavior in the face of multiple, potentially competing, physiological needs. Importantly, considering a variety of biological mechanisms by which reward functions are influenced by internal states can provide insight into the neural basis of goaldependent valuation of motivational incentives 
(Botvinick and Braver, 2015;
Dickinson and Balleine, 1994)
.


Revising the reinforcement learning framework
Despite the success of the formal framework of reinforcement learning, one of its core concepts, the very definition of reward, remains surprisingly paradoxical : reward is treated as an external, objective and stable quantity ( 
Figure 3A, Box 1)
. This externally generated information serves as an ultimate 'ground-truth' correction signal upon which the agent can update their subjective beliefs about the value of states and actions. This is at odds with recent experimental work that highlights the presence of internally-generated and state-dependent primary reward signals and invites us to revisit the very definition of reward within the biological RL framework. In what follows, we describe how the classical RL framework could be extended to incorporate this knowledge into a revised RL framework, in which reward arises within the organism rather than from its environment, and also is a function of an agent's internal states and goals 
(Figure 3C & D)
. . These can be incorporated into the RL framework by conceptualizing the body as a specific environment, providing sensory inputs about internal (bodily) states (Sbod) which can be affected both by external actions (aenv, e.g., picking an apple to eat) as 
R mod = drive modulated primary reward r prim d S t S t S t S t+1 S t+2 D exp prim 1 d 2 S t+1 r ⨯ = R S t r ⨯ = R ⨯ B C D A
well as internal actions (abod, e.g., regulating insulin levels). Sensory signals from the body (obod) are noisy and ambiguous, leading the agent to form subjective beliefs about internal states (S bod subj) based on observations and prior beliefs. In this version, only certain types of rewards (primary rewards, R prim ) are generated internally, while others can still be received from the environment (R ext ) as in panel A. However, this view does include state-or goal-dependent reward functions. D Revised RL framework: In this updated model, all reward signals are internally generated. There is no valenced signal from the environment -instead, valence is generated within the agent in response to (neutral) incoming sensory observations. The agent uses observations to infer the state of the external and internal (bodily) state and update their expectations. Reward signals are generated in two ways: First, subjective state estimates are 


Primary reward signals originate in the body
In a revised RL framework, primary reward signals are not externally generated, and they do not track a single quantity of interest (e.g., calories). Instead, they originate in the body -the milieu intérieur 
(Gross, 1998)
 
(Figure 3C)
. This reflects the fact that the agent's ultimate goal -survival -is realized within the body and that the success of acquiring energy, hydration, or protecting the body from harm can only be evaluated by monitoring the signals the agent receives from that body. Importantly, nutrient-specific rewards are signaled via parallel but distinct gut-brain circuits 
(Figure 1)
 
(McDougle et al., 2024)
, and can combine supra-additively to shape the value of food items 
(DiFeliceantonio et al., 2018;
McDougle et al., 2024;
Perszyk et al., 2021)
. Modular RL architectures with multiple independent (resource-specific) reward signals have already been examined in computational work and outperform monolithic solutions in which different resources are combined into a single scalar reward signal 
(Dulberg et al., 2022;
Keramati and Gutkin, 2014;
Van Seijen et al., 2017)
. This paradigm shift away from a scalar reward signal resonates with a wealth of research on the heterogeneity of DA responses, and has resulted in several RL theory updates in which scalar reward prediction errors (RPEs) are replaced by multidimensional RPEs 
(Bogacz, 2020;
Dabney et al., 2020;
Gardner et al., 2018;
Lee et al., 2024)
.
Incorporating the body as part of the agent's environment highlights that internal bodily states, similar to environmental states, are not directly observable by the agent. Instead, these states must be inferred based on noisy observations from visceral sensors and combined with prior beliefs 
(Figure 3B)
, a process known as interoception 
(Craig, 2002;
Khalsa et al., 2018;
Petzschner et al., 2022
Petzschner et al., , 2021
. Interoception underpins effective body regulation 
(Petzschner et al., 2021
(Petzschner et al., , 2017
 and has been suggested to form the basis for emotional valence 
(Barrett, 2017;
Seth, 2013)
. Importantly, information on current bodily state is combined with cues from the environment and learned associations (a predictive model) to provide an estimate of future internal state in the service of prospective control 
(Petzschner et al., 2021;
Reed et al., 2022;
Schulkin and Sterling, 2019;
Stephan et al., 2016)
. In the following, we discuss how such subjective estimates of current and predicted future internal bodily states form the basis of an internally generated, state-dependent reward function.


Reward is state-dependent
That a pellet of sugar is more rewarding to a hungry animal than to a sated one is intuitive, but formalizing the state dependency of reward signal is nontrivial. If rewards are received from the environment 
(Figure 3A)
, this environment would have to contain information about the agent's internal state in order to emit the correct signal. However, if primary reward signals are instead generated within the body 
(Figure 3C)
 
(Grove et al., 2022;
Han et al., 2018)
. In other words, In our revised RL framework, all reward signals are generated within the agent and tightly linked with subjective, internal states ( 
Figure 3D)
. The literature reviewed above supports two putative mechanisms for such a link in the context of primary rewards. First, state-modulated rewards describe how the internal state of the agent (e.g., hunger) gates or modulates the impact of an 'absolute' reward signal on the agent's evaluation (e.g., the reinforcing strength of a burger will be boosted in states of food deprivation). Here, the relevant internal state is represented as a drive, or deviation of a agent's current state from a goal or set-point, and contains a prediction of future metabolic state ( 
Figure 3B)
. This form of reward modulation is consistent with the purported interactions between separate 'valuation systems' in the brain, supposedly concerned with tracking rewards via 'homeostatic systems' (concerned with metabolism) or 'cognitive control systems' (concerned with fulfilling goal-directed behaviours) 
(Plassmann et al., 2022
) 
(Plassmann et al., 2022)
.
In contrast, the second mechanism, which we refer to as state-generated rewards, emphasizes an even tighter coupling between the value of primary rewards and their effects on the internal state of organism 
(Hull, 1943;
Keramati and Gutkin, 2014)
 
(Figure 3B; Box 3)
. Here, the reward signal directly reflects a beneficial change in internal state congruent with an organism's goals.
In other words, consumption of a food or drink is rewarding to the extent that it brings the organism closer to its determined goal (e.g., a drink is as rewarding as the rehydration that it causes). Modern formulations of this idea incorporate prospective control ( acting to avoid future drives) 
(Hulme et al., 2019;
Keramati and Gutkin, 2014;
Petzschner et al., 2021
Petzschner et al., , 2017
Stephan et al., 2016)
, or replacing the 'landscape of (physiological) needs' with an emotional or affective landscape 
(Shenhav, 2024)
.


Goal-dependent rewards
Primary rewards are defined by the physiological benefits they offer to the organism. The fundamental goals implied by primary reward functions of biological agents are those of survival and reproduction. However, these global goals translate into more specific subgoals and actions of attaining certain resources and avoiding certain dangers depending on the specific agent and its environment 
(Ho et al., 2022;
Wise et al., 2023)
. Understanding the architectures that allow agents to update their reward functions based on changing internal and external circumstances is the basis for understanding more complex and flexible behavior of intelligent agents, who routinely set their own goals and experience reward upon achieving them 
(Botvinick et al., 2019;
Frömer et al., 2019;
Molinaro and Collins, 2023)
. But how are these reward functions transformed to achieve cognitive goals that are more abstract of temporally delayed? One possibility is that the cognitive mechanisms underlying goal-directed behavior beyond primary rewards have evolved by hijacking the existing cognitive architectures for state-dependent primary reinforcement. In particular, the idea of drive reduction has been translated from the physiological into the cognitive domain with the idea of 'cognitive set-points' . In a remarkable parallel to physiological drive reduction, value signals during the pursuit of more abstract cognitive goals can be understood as resulting from the comparison between a current state, the desired (goal) state, and the degree to which an action reduces the distance between the two . Others have speculated that internal goals play a key role in modulating an organism's motivation to pursue them 
(Barto, 2013;
O'Reilly, 2020;
Swieten et al., 2021)
. Nevertheless, these frameworks contain a common theme, suggesting that if agents generate reward signals based on internal state changes, they are capable of goal-dependent valuation.


Concluding Remarks and Future Perspectives
In this paper, we have reviewed research on ingestive behavior to uncover the nature and origins of biological reward functions. Traditionally, rewards have been associated with the immediate outcomes of actions, such as the sensory pleasure of consumption-like the sweet taste of biting into a juicy apple. However, it is now established that the critical reinforcing signals from food and water are not linked directly to consumption. Instead, they arise from delayed post-oral primary reward signals generated during digestion and absorption, tracking vital resources for survival, such as nutrients, energy, and hydration.
We have also examined how these primary reward signals are connected to secondary reinforcers and oral proxy signals, such as cues and appetitive responses to taste, and how they are influenced by an organism's internal states and goals. Here, we propose a revised reinforcement learning framework that shifts the focus from immediate sensory gratification of food and fluids to a more nuanced, internally-generated, state-dependent reward system. This perspective not only deepens our understanding of how fundamental biological needs shape behavior, but also opens new avenues for exploring the interplay between primary and secondary rewards in human cognition, as well as investigating how cognitive goals shape the reward function. Future research should aim to further elucidate the neural architectures that underpin these reward processes, and how these architectures might relate to more abstract cognition, e.g., the pursuit of goals or symbolic reinforcers (see Outstanding Questions).


Outstanding Questions
• Here we have discussed two reward sensing mechanisms and pathways for fat and sugar. Are there other pathways for these macronutrients and other macro-and micronutrients?
• What are the underlying primary reward signals associated with other physiologically relevant processes, such as sex, temperature regulation, and oxidation?
• How do these interoceptive reward signals become integrated with brain circuits supporting decision making?
• To what extent do interoceptive reward mechanisms generalize to intrinsic rewards related to curiosity, goal achievement, or novelty?
• Does the ability to store energy from food provide organisms with the capacity to reinforce behavior beyond internal states? Could that provide additional insights into why overeating is common, but overdrinking is rare, as well as mechanisms of addiction more generally?
• Do storable secondary reinforcers (e.g. money) share neural architectures with energyrelated rewards, but not with un-storable rewards like those linked to water intake?
• How do other interoceptive signals, such as the processing of cardiac and breathingrelated information, interact with reward systems?
• How are the different dopamine signals for delayed internal and immediate external reinforcing signals integrated, e.g. within the dorsal and ventral striatum?
• Can proxy rewards (shaping signals) be learned? How does the delayed primary reward signal update early (predictive) reward responses upon consumption?
• How does cognition shape the biological reward function?


Highlights
• The reinforcing effects of food and fluids are driven by post-oral interoceptive primary reward signals, which reflect key physiological resources essential for sustaining life, such as energy, nutrients, and hydration.
• Primary rewards are accompanied by a cascade of earlier signals-secondary and proxy rewards-that facilitate learning and prospective control rather than sustaining reinforcement.
• Primary reward signals are dependent on internal states and goals.
• The traditional reinforcement learning framework needs to be revised to incorporate internally generated, state-dependent rewards.


Glossary
Cue-potentiated feeding: The stimulation of food consumption by cues that have become associated with food.


Dietary induced thermogenesis (DIT):
The increase in energy expenditure above basal levels observed following nutrient consumption. It reflects the energy use associated with absorbing the nutrient, which is thought to be primarily determined by the energy content of the food.
Interoception: The overall process of how the nervous system (central and autonomic) senses,
interprets and integrates signals originating from within the body, providing a moment-bymoment mapping of the internal landscape of the body across conscious and nonconscious levels.
Primary Reward: A reward signal capable of directly reinforcing behavior by activating the brain's dopamine system without dependence on another underlying reward signals or prior learning (unconditioned stimulus, US).
Proxy Reward: A signal that generates immediate subjective experiences of liking or disliking, offering an 'early affective draft' of the expected long-term value of an outcome. Proxy rewards help in assigning credit between actions and their delayed outcomes. Similar to secondary rewards, they cannot sustain reinforcement without the presence of a primary reward.
Secondary Reward: A learned reward signal that is reinforcing because it predicts the occurrence of a primary reward (conditioned stimulus, CS). It cannot sustain reinforcement on its own without the presence of a primary reward.
Figure 1 :
1
Distinct Afferent Pathways for Primary Reward Signals through which carbohydrates, fats, and water activate the midbrain dopamine system to promote reinforcement. Carbohydrates (sugar):


Figure 2 :
2
Expanded View of Conditioning Including Post-Oral Primary Reward Signals. (A) In the classic view, the receipt of a primary reward (consumption of food or juice) triggers a phasic activation of midbrain dopamine neurons in response to the unconditioned stimulus (US) (red peak). When reward delivery is consistently preceded by a cue, such as a sound or visual signal (conditioned stimulus, CS), phasic dopamine response gradually shifts across trials from the moment of consumption to the earlier occurrence of the predictive cue, now considered a secondary reward (green peaks). (B) Updated View of Classical Conditioning: Recent research suggests that the critical reinforcing signals from food or water are not primarily linked to oral sensory signals during consumption. Instead, primary reward signals are associated with post-oral processes that occur during digestion and absorption (red peak). In this model, the immediate responses to oral signals act as proxy rewards (yellow), providing an early 'affective draft' of the hedonic value and delayed outcome of the consumed food. These proxy rewards are distinct from pre-oral cues (secondary rewards), which, through conditioning, become associated with and predictive of the primary rewards. It remains an open question whether post-oral primary reward signals diminish over time as earlier signals increasingly predict their occurrence, as depicted by the lighter shading of the red peak.


Thus, taste and accompanying subjective experience (e.g., sweetness and liking) are critical for initial decisions about accepting or rejecting a food. Both taste and flavor are able to evoke subjective affective experiences to enable fast direct associations between actions (consumption) and outcomes, prior to the generation of post-oral rewarding signals. Oral sensations and their accompanying subjective experiences (liking/disliking) thus occupy an intermediary position as proxy rewards between conditioned reinforcers that are associated with incentive motivation or "wanting" (Morales and Berridge, 2020) and primary reward signals that are subliminal and delayed (Figure 2B).


Figure A revised reinforcement
learning framework for state-and goal-dependent internal rewards. A Traditional RL: Agents interact with an external environment by performing actions that may change the state of the environment (St), they use observations (sensory signals from the environment) and their priors expectations to form beliefs about the current state of the environment (Ssubj). Additionally, agents receive scalar valenced signals from the environment, 'rewards,' which inform them about the desirability of a state or the outcome of an action. These reward signals are then used to update the agents' subjective estimates of 'value,' which represent the expected cumulative future rewards (not shown, but see Box 1). B Different forms of state-dependent, internally generated reward signals. Left, state-generated reward signals. Right, state-modulated reward signals. C Adding the body to traditional RL: Recently discovered primary reward signals, originating in the agent's body (see Section Primary reward signals represent essential physiological variables)


compared to internal goals. If an outcome brings the agent's subjective state estimate closer their current goal (smaller distance D), it is perceived as rewarding (R int ). In this view, 'values' are expected future distances to goals, and 'rewards' are actual changes in current distance. Second, primary reward signals are elicited by specific physiological events, and subsequently modulated by subjective estimates of internal state. Definitions: S -state, R/r -reward, o -observation, a -action, D/d -distance, subjsubjective estimate, env -environment, bod -body, prim -primary, ext -external, mod -modulated, exp -expected


interoceptive (subjective) estimates of internal state, rather than actual physiological changes, are responsible for the state-dependency of reinforcement. Secondly, it remains elusive how non-bodily, psychological internal states (e.g., cognitive goals) could influence these internallygenerated reward signals. Clarification of the relationship between the reward signal R and the organism's internal (bodily and psychological) subjective state Ssubj could inform the mechanisms supporting flexible, goal-directed behavior.


). While the affective responses to different tastes appear relatively stable and innate (Box 2), it remains an unknown whether and how the agent can also learn useful shaping signals (proxy rewards) from experience. That is, to what extent do late reinforcing signals enable the agent to adjust and refine proxy reward responses? This is an area of ongoing theoretical research


, this problem goes away and reward signals can be a function of (changes in) current bodily state. Still, there are two reasons why adding the body to
the agent's environment is not sufficient to account for state-dependent rewards. First, evidence
reviewed in the Section The state dependency of primary reward suggests that it is not the
underlying state of the body itself that influences post-oral reinforcing signals for sugar, fat and
water rewards, but instead central representation and expectations of the state of the body. This
is evidenced by GABAergic LH neurons tracking systemic hydration status, and SFO neurons
and hypothalamic AgRP neurons coding internal thirst and hunger drives (Box 3). Stimulating
these regions was sufficient to modulate DA reward signals and behaviour, equivalent to the
effects of natural dehydration or hunger




















Ghrelin modulates the activity and synaptic input organization of midbrain dopamine neurons while promoting appetite




A
Abizaid






Z-W
Liu






Z
B
Andrews






M
Shanabrough






E
Borok






J
D
Elsworth






R
H
Roth






M
W
Sleeman






M
R
Picciotto






M
H
Tschöp






X-B
Gao






T
L
Horvath




















10.1172/JCI29867






J Clin Invest




116














Natural and Drug Rewards Engage Distinct Pathways that Converge on Coordinated Hypothalamic and Reward Circuits




A
L
Alhadeff






N
Goldstein






O
Park






M
L
Klima






A
Vargas






J
N
Betley




10.1016/j.neuron.2019.05.050






Neuron




103
















Thirst-associated preoptic neurons encode an aversive motivational drive




W
E
Allen






L
A
Denardo






M
Z
Chen






C
D
Liu






K
M
Loh






L
E
Fenno






C
Ramakrishnan






K
Deisseroth






L
Luo




10.1126/science.aan6747






Science




357
















Toward a Wiring Diagram Understanding of Appetite Control




M
L
Andermann






B
B
Lowell




10.1016/j.neuron.2017.06.014






Neuron




95
















AGRP neurons are sufficient to orchestrate feeding behavior rapidly and without training




Y
Aponte






D
Atasoy






S
M
Sternson




10.1038/nn.2739






Nat Neurosci




14




















V
Augustine






S
K
Gokce






S
Lee






B
Wang






T
J
Davidson






F
Reimann






F
Gribble






K
Deisseroth






34


Lois












Hierarchical neural architecture underlying thirst regulation




C
Oka






Y




10.1038/nature25488






Nature




555
















Hypothalamic Interactions with Large-Scale Neural Circuits Underlying Reinforcement Learning and Motivated Behavior




B
B
Averbeck






E
A
Murray




10.1016/j.tins.2020.06.006






Trends Neurosci




43
















The gravitostat protects diet-induced obese rats against fat accumulation and weight gain




T
Bake






F
Peris-Sampedro






Z
Wáczek






C
Ohlsson






V
Pálsdóttir






J
Jansson






S
L
Dickson




10.1111/jne.12997






J Neuroendocrinology




33


12997














The theory of constructed emotion: an active inference account of interoception and categorization




L
F
Barrett




10.1093/scan/nsw154






Social cognitive and affective neuroscience




12
















Intrinsic Motivation and Reinforcement Learning




A
G
Barto




10.1007/978-3-642-32375-1_2






Intrinsically Motivated Learning in Natural and Artificial Systems


Baldassarre G, Mirolli M


Berlin, Heidelberg; Berlin Heidelberg




Springer
















The functional form of value normalization in human reinforcement learning




S
Bavard






Palminteri
S
2023




10.7554/eLife.83891




12


83891












Taste uncoupled from nutrition fails to sustain the reinforcing properties of food




J
A
Beeler






J
E
Mccutcheon






Zfh
Cao






M
Murakami






Alexander
E
Roitman






M
F
Zhuang






X




10.1111/j.1460-9568.2012.08167.x






Eur J of Neuroscience




36
















Neurons for hunger and thirst transmit a negative-valence teaching signal




J
N
Betley






S
Xu






Zfh
Cao






R
Gong






C
J
Magnus






Y
Yu






S
M
Sternson




10.1038/nature14416






Nature




521
















Dopamine role in learning and action inference




R
Bogacz












eLife 46








Motivation and Cognitive Control: From Behavior to Neural Mechanism




M
Botvinick






T
Braver




10.1146/annurev-psych-010814-015044






Annu Rev Psychol




66
















Reinforcement Learning, Fast and Slow




M
Botvinick






S
Ritter






J
X
Wang






Z
Kurth-Nelson






C
Blundell






D
Hassabis




10.1016/j.tics.2019.02.006






Trends in Cognitive Sciences




23
















Expected satiety" changes hunger and fullness in the inter-meal interval




J
M
Brunstrom






S
Brown






E
C
Hinton






P
J
Rogers






S
H
Fay




10.1016/j.appet.2011.01.002






Appetite




56
















Hunger-Driven Motivational State Competition




C
J
Burnett






C
Li






E
Webber






E
Tsaousidou






S
Y
Xue






J
C
Brüning






M
J
Krashes




10.1016/j.neuron.2016.08.032






Neuron




92
















Physiological Role of Pleasure: A stimulus can feel pleasant or unpleasant depending upon its usefulness as determined by internal signals




M
Cabanac




10.1126/science.173.4002.1103






Science




173
















Sensory Detection of Food Rapidly Modulates Arcuate Feeding Circuits




Y
Chen






Y-C
Lin






T-W
Kuo






Z
A
Knight




10.1016/j.cell.2015.01.033






Cell




160
















Opponent actor learning (OpAL): Modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive




Age
Collins






M
J
Frank




10.1037/a0037015






Psychological Review




121
















Ghrelin Acts as an Interface between Physiological State and Phasic Dopamine Signaling




J
J
Cone






J
E
Mccutcheon






M
F
Roitman




10.1523/JNEUROSCI.4404-13.2014






J Neurosci




34
















How do you feel? Interoception: the sense of the physiological condition of the body




A
D
Craig




10.1038/nrn894






Nature Reviews Neuroscience




3
















A distributional code for value in dopamine-based reinforcement learning




W
Dabney






Z
Kurth-Nelson






N
Uchida






C
K
Starkweather






D
Hassabis






R
Munos






M
Botvinick




10.1038/s41586-019-1924-6






Nature




577
















Liking" as an early and editable draft of long-run affective value




P
Dayan




10.1371/journal.pbio.3001476






PLoS Biol




20


3001476














Reward, Motivation, and Reinforcement Learning




P
Dayan






B
W
Balleine




10.1016/S0896-6273(02)00963-7






Neuron




36
















Reinforcement learning: the good, the bad and the ugly




P
Dayan






Y
Niv




10.1016/j.conb.2008.08.003






Current opinion in neurobiology




18
















Neurobiology of Sensation and Reward, Frontiers in Neuroscience




I
E
De Araujo




Gottfried JA






CRC Press


Boca Raton (FL; Taylor & Francis






Multiple Reward Layers in Food Reinforcement








Food reward in the absence of taste receptor signaling




I
E
De Araujo






A
J
Oliveira-Maia






T
D
Sotnikova






R
R
Gainetdinov






M
G
Caron






Mal
Nicolelis






S
A
Simon




10.1016/j.neuron.2008.01.032






Neuron




57
















Rethinking Food Reward




I
E
De Araujo






M
Schatzker






D
M
Small




10.1146/annurev-psych-122216-011643






Annu Rev Psychol




71
















Metabolic Regulation of Brain Response to Food Cues




I
E
De Araujo






T
Lin






M
G
Veldhuizen






D
M
Small




10.1016/j.cub.2013.04.001






Current Biology




23
















Exploration-Guided Reward Shaping for Reinforcement Learning under Sparse Rewards




R
Devidze






P
Kamalaruban






A
Singla








Advances in Neural Information Processing Systems




35
















Motivational control of goal-directed action




A
Dickinson






B
Balleine




10.3758/BF03199951






Animal Learning & Behavior




22
















Supra-Additive Effects of Combining Fat and Carbohydrate on Food Reward




A
G
Difeliceantonio






G
Coppin






L
Rigoux






Edwin
Thanarajah






S
Dagher






A
Tittgemeyer






M
Small






D
M




10.1016/j.cmet.2018.05.018






Cell Metabolism




28
















Modularity benefits reinforcement learning agents with competing homeostatic drives




Z
Dulberg






R
Dubey






I
M
Berwian






J
D
Cohen




10.48550/arXiv.2204.06608
















The temporal precision of reward prediction in dopamine neurons




C
D
Fiorillo






W
T
Newsome






W
Schultz




10.1038/nn.2159






Nature Neuroscience




11
















Goal congruency dominates reward value in accounting for behavioral and neural correlates of value-based decision-making




R
Frömer






Dean
Wolf






C
K
Shenhav






A




10.1038/s41467-019-12931-x






Nat Commun




10


4926














Appetite and reward




S
Fulton




10.1016/j.yfrne.2009.10.003






Frontiers in Neuroendocrinology




31
















Modulation of Brain Reward Circuitry by Leptin




S
Fulton






B
Woodside






P
Shizgal




10.1126/science.287.5450.125






Science




287
















Rethinking dopamine as generalized prediction error 285




Mph
Gardner






G
Schoenbaum






S
J
Gershman






















I
Gaziano






S
Corneliussen






N
Biglari






R
Neuhaus






L
Shen






T
Sotelo-Hitschfeld






P
Klemm






L
Steuernagel






De
Solis






A
J
Chen






W
Wunderlich






F
T
Kloppenburg






P
Brüning






J
C


















Dopamine-inhibited POMCDrd2+ neurons in the ARC acutely regulate feeding and body temperature


10.1172/jci.insight.162753






JCI Insight




7


162753












The neural basis of homeostatic and anticipatory thirst




C
Gizowski






C
W
Bourque




10.1038/nrneph.2017.149






Nature Reviews Nephrology




14
















Dissociable Codes of Odor Quality and Odorant Structure in Human Piriform Cortex




J
A
Gottfried






J
S
Winston






R
J
Dolan




10.1016/j.neuron.2006.01.007






Neuron




49
















Claude Bernard and the Constancy of the Internal Environment




C
G
Gross




10.1177/107385849800400520






Neuroscientist




4
















Dopamine subsystems that track internal states




Jcr
Grove






L
A
Gray






La
Santa
Medina






N
Sivakumar






N
Ahn






J
S
Corpuz






T
V
Berke






J
D
Kreitzer






A
C
Knight






Z
A




10.1038/s41586-022-04954-0






Nature




















W
Han






L
A
Tellez






M
H
Perkins






I
O
Perez






T
Qu






J
Ferreira






T
L
Ferreira






D
Quinn






Z-W
Liu






X-B
Gao






M
M
Kaelberer






D
V
Bohórquez






S
J
Shammah-Lagnado






G
De Lartigue






I
E
De Araujo




10.1016/j.cell.2018.08.049






A Neural Circuit for Gut-Induced Reward. Cell




175
















Motivational state regulates the content of learned flavor preferences




J
A
Harris






M
C
Gorissen






G
K
Bailey






R
F
Westbrook




10.1037/0097-7403.26.1.15






Journal of Experimental Psychology: Animal Behavior Processes




26
















The case against economic values in the orbitofrontal cortex (or anywhere else in the brain)




B
Y
Hayden






Y
Niv




10.1037/bne0000448






Behavioral Neuroscience




135
















People construct simplified mental representations to plan




M
K
Ho






D
Abel






C
G
Correa






M
L
Littman






J
D
Cohen






T
L
Griffiths




10.1038/s41586-022-04743-9






Nature




606
















Intragastric reinforcement effect




G
L
Holman




10.1037/h0028233






Journal of Comparative and Physiological Psychology




69
















Principles of behavior: an introduction to behavior theory, Principles of behavior: an introduction to behavior theory




C
L
Hull








Appleton-Century


Oxford, England












Neurocomputational theories of homeostatic control




O
J
Hulme






T
Morville






B
Gutkin




10.1016/j.plrev.2019.07.005






Physics of Life Reviews




31
















Body weight homeostat that regulates fat mass independently of leptin in rats and mice




J-O
Jansson






V
Palsdottir






D
A
Hägg






E
Schéle






S
L
Dickson






F
Anesten






T
Bake






M
Montelius






J
Bellman






M
E
Johansson






R
D
Cone






D
J
Drucker






J
Wu






B
Aleksic






A
E
Törnqvist






K
Sjögren






J-Å
Gustafsson






S
H
Windahl






C
Ohlsson




10.1073/pnas.1715687114






Proc Natl Acad Sci




115
















A Network for Computing Value Equilibrium in the




K
Juechems






J
Balaguer






Herce
Castañón






S
Ruz






M
O'reilly






J
X
Summerfield






C




10.1016/j.neuron.2018.12.029






Human Medial Prefrontal Cortex. Neuron




101
















Where Does Value Come From?




K
Juechems






C
Summerfield




10.1016/j.tics.2019.07.012






Trends in Cognitive Sciences




23
















A gut-brain neural circuit for nutrient sensory transduction




M
M
Kaelberer






K
L
Buchanan






M
E
Klein






B
B
Barth






M
M
Montoya






X
Shen






D
V
Bohórquez




10.1126/science.aat5236






Science




361


5236














Ventral Tegmental Dopamine Neurons Participate in Reward Identity Predictions




R
Keiflin






H
J
Pribut






N
B
Shah






P
H
Janak




10.1016/j.cub.2018.11.050






Current Biology




29














Homeostatic reinforcement learning for integrating reward collection and physiological stability




M
Keramati






B
Gutkin




10.7554/elife.04811






3














Interoception and Mental Health: A Roadmap




S
S
Khalsa






R
Adolphs






O
G
Cameron






H
D
Critchley






P
W
Davenport






J
S
Feinstein






J
D
Feusner






S
N
Garfinkel






R
D
Lane






W
E
Mehling






A
E
Meuret






C
B
Nemeroff






S
Oppenheimer






F
H
Petzschner






O
Pollatos






J
L
Rhudy






L
P
Schramm






W
K
Simmons






M
B
Stein






K
E
Stephan






O
Van Den Bergh






I
Van Diest






Von
Leupoldt






A
Paulus






M
P
Ainley






V






Al
Zoubi






O
Aupperle






R
Avery






J
Baxter






L
Benke






C
Berner






L
Bodurka






J
Breese






E
Brown






T
Burrows






K
Cha






Y-H
Clausen






A
Cosgrove






K
Deville






D
Duncan






L
Duquette






P
Ekhtiari






H
Fine






T
Ford






B






Garcia
Cordero






I
Gleghorn






D
Guereca






Y
Harrison






N
A
Hassanpour






M
Hechler






T
Heller






A
Hellman






N
Herbert






B
Jarrahi






B
Kerr






K
Kirlic






N
Klabunde






M
Kraynak






T
Kriegsman






M
Kroll






J
Kuplicki






R
Lapidus






R
Le






T
Hagen






K
L
Mayeli






A
Morris






A
Naqvi






N
Oldroyd






K
Pané-Farré






C
Phillips






R
Poppa






T
Potter






W
Puhl






M
Safron






A
Sala






M
Savitz






J
Saxon






H
Schoenhals






W
Stanwell-Smith






C
Teed






A
Terasawa






Y
Thompson






K
Toups






M
Umeda






S
Upshaw






V
Victor






T
Wierenga






C
Wohlrab






C
Yeh






H
Yoris






A
Zeidan






F
Zotev






V
Zucker






N




10.1016/j.bpsc.2017.12.004








Biological Psychiatry: Cognitive Neuroscience and Neuroimaging




3
















Overlapping Responses for the Expectation of Juice and Money Rewards in Human Ventromedial Prefrontal Cortex




H
Kim






S
Shimojo






J
P
O'doherty




10.1093/cercor/bhq145






Cerebral Cortex




21
















Adaptation of Reward Sensitivity in Orbitofrontal Neurons




S
Kobayashi






O
Pinto De Carvalho






W
Schultz




10.1523/JNEUROSCI.4009-09.2010






J Neurosci




30
















Ghrelin, an orexigenic signaling molecule from the gastrointestinal tract




M
Kojima






K
Kangawa




10.1016/s1471-4892(02)00220-5






Curr Opin Pharmacol




2
















Rapid, reversible activation of AgRP neurons drives feeding behavior in mice




M
J
Krashes






S
Koda






C
Ye






S
C
Rogan






A
C
Adams






D
S
Cusher






E
Maratos-Flier






B
L
Roth






B
B
Lowell




















10.1172/JCI46229






J Clin Invest




121














A feature-specific prediction error model explains dopaminergic heterogeneity




R
S
Lee






Y
Sagiv






B
Engelhard






I
B
Witten






N
D
Daw




10.1038/s41593-024-01689-1






Nat Neurosci
















Dopamine, Updated: Reward Prediction Error and Beyond




T
N
Lerner






A
L
Holloway






J
L
Seiler




10.1016/j.conb.2020.10.012






Current Opinion in Neurobiology




67














Intestinal satiety in rats




D
S
Liebling






J
D
Eisner






J
Gibbs






G
P
Smith




10.1037/h0077163






J Comp Physiol Psychol




89
















Homeostatic circuits selectively gate food cue responses in insular cortex




Y
Livneh






R
N
Ramesh






C
R
Burgess






K
M
Levandowski






J
C
Madara






H
Fenselau






G
J
Goldey






V
E
Diaz






N
Jikomes






J
M
Resch






B
B
Lowell






M
L
Andermann




10.1038/nature22375






Nature




546
















Estimation of Current and Future Physiological States in Insular Cortex




Y
Livneh






A
U
Sugden






J
C
Madara






R
A
Essner






V
I
Flores






L
A
Sugden






J
M
Resch






B
B
Lowell






M
L
Andermann




10.1016/j.neuron.2019.12.027






Neuron




105
















New Neuroscience of Homeostasis and Drives for Food, Water, and Salt




B
B
Lowell




10.1056/NEJMra1812053






N Engl J Med




380
















Causal evidence supporting the proposal that dopamine transients function as temporal difference prediction errors




Ejp
Maes






M
J
Sharpe






A
A
Usypchuk






M
Lozzi






C
Y
Chang






Mph
Gardner






G
Schoenbaum






M
D
Iordanova




10.1038/s41593-019-0574-1






Nat Neurosci




23
















Ghrelin modulates brain activity in areas that control appetitive behavior




S
Malik






F
Mcglone






D
Bedrossian






A
Dagher




10.1016/j.cmet.2008.03.007






Cell Metab




7
















Arcuate hypothalamic AgRP and putative POMC neurons show opposite changes in spiking across multiple timescales




Y
Mandelblat-Cerf






R
N
Ramesh






C
R
Burgess






P
Patella






Z
Yang






B
B
Lowell






M
L
Andermann




10.7554/eLife.07122






4


7122












Separate gut-brain circuits for fat and sugar reinforcement combine to promote overeating




M
Mcdougle






A
De Araujo






A
Singh






M
Yang






I
Braga






V
Paille






R
Mendez-Hernandez






M
Vergara






L
N
Woodie






A
Gour






A
Sharma




10.1016/j.cmet.2023.12.014






Cell Metab




23
















Contingent and non-contingent actions of sucrose and saccharin reinforcers: effects on taste preference and memory




C
Messier






N
M
White




10.1016/0031-9384(84)90129-x






Physiol Behav




32
















A goal-centric outlook on learning




G
Molinaro






Age
Collins




10.1016/j.tics.2023.08.011






Trends in Cognitive Sciences




27
















Liking' and 'wanting' in eating and food reward: Brain mechanisms and clinical implications




I
Morales






K
C
Berridge




10.1016/j.physbeh.2020.113152






Physiology & Behavior




227


113152














Nasal Chemoreception in Flavor Identification




M
M
Mozell






B
P
Smith






P
E
Smith






R
L
Sullivan
Jr






P
Swender




10.1001/archotol.1969.00770030369020






Archives of Otolaryngology




90


















A
Y
Ng






D
Harada






S
J
Russell




Policy Invariance Under Reward Transformations: Theory and Application to Reward ShapingProceedings of the Sixteenth International Conference on Machine Learning, ICML '99


San Francisco, CA, USA




Morgan Kaufmann Publishers Inc
















Inhibitory Input from the Lateral Hypothalamus to the Ventral Tegmental Area Disinhibits Dopamine Neurons and Promotes Behavioral Activation




E
H
Nieh






C
M
Vander Weele






G
A
Matthews






K
N
Presbrey






R
Wichmann






C
A
Leppla






E
M
Izadmehr






K
M
Tye




10.1016/j.neuron.2016.04.035






Neuron




90
















Dialogues on prediction errors




Y
Niv






G
Schoenbaum




10.1016/j.tics.2008.03.006






Trends in Cognitive Sciences




12
















Unraveling the Mysteries of Motivation




R
C
O'reilly




10.1016/j.tics.2020.03.001






Trends in Cognitive Sciences




24
















Neural encoding of food and monetary reward delivery




S
Oren






M
Tittgemeyer






L
Rigoux






M
Schlamann






T
Schonberg






B
Kuzmanovic




10.1016/j.neuroimage.2022.119335






NeuroImage




257


119335














Range-Adapting Representation of Economic Value in the Orbitofrontal Cortex




C
Padoa-Schioppa




10.1523/JNEUROSCI.3751-09.2009






J Neurosci




29
















Fat and Carbohydrate Interact to Potentiate Food Reward in Healthy Weight but Not in Overweight or Obesity




E
E
Perszyk






Z
Hutelin






J
Trinh






A
Kanyamibwa






S
Fromm






X
S
Davis






K
M
Wall






K
D
Flack






A
G
Difeliceantonio






D
M
Small




10.3390/nu13041203






Nutrients




13


1203














Amygdalo-Hypothalamic Circuit Allows Learned Cues to Override Satiety and Promote Eating




G
D
Petrovich






B
Setlow






P
C
Holland






M
Gallagher




10.1523/JNEUROSCI.22-19-08748.2002






J Neurosci




22
















Complementary lateral hypothalamic populations resist hunger pressure to balance nutritional and social needs




A
Petzold






H
E
Van Den Munkhof






R
Figge-Schlensok






T
Korotkova




10.1016/j.cmet.2023.02.008






Cell Metabolism S155041312300044X




















F
Petzschner






H
Critchley






C
Tallon-Baudry




10.4249/scholarpedia.55569






2022. Interoception. Scholarpedia




17


55569












Computational Models of Interoception and Body Regulation




F
H
Petzschner






S
N
Garfinkel






M
P
Paulus






C
Koch






S
S
Khalsa




10.1016/j.tins.2020.09.012






Trends in Neurosciences




44
















Computational Psychosomatics and Computational Psychiatry: Toward a Joint Framework for Differential Diagnosis




F
H
Petzschner






Lae
Weber






T
Gard






K
E
Stephan




10.1016/j.biopsych.2017.05.012






Biological Psychiatry




82
















How we decide what to eat: Toward an interdisciplinary model of gut-brain interactions




H
Plassmann






D
S
Schelski






M-C
Simon






L
Koban




10.1002/wcs.1562






WIREs Cognitive Science




13


1562














Learning to Drive a Bicycle using Reinforcement Learning and Shaping




J
Randløv






P
Alstrøm


















Appetite to learn: An allostatic role for AgRP neurons in the maintenance of energy balance




F
Reed






S
H
Lockie






A
Reichenbach






C
J
Foldi






Z
B
Andrews




10.1016/j.coemr.2022.100337






Current Opinion in Endocrine and Metabolic Research




24


100337














Metabolic sensing in AgRP neurons integrates homeostatic state with dopamine signalling in the striatum




A
Reichenbach






R
E
Clarke






R
Stark






S
H
Lockie






M
Mequinion






H
Dempsey






S
Rawlinson






F
Reed






T
Sepehrizadeh






M
Deveer






A
C
Munder






J
Nunez-Iglesias






D
Spanswick






R
Mynatt






A
V
Kravitz






C
V
Dayas






R
Brown






Z
B
Andrews




10.7554/eLife.72668






11


72668












The Need to Feed




C
B
Saper






T
C
Chou






J
K
Elmquist




10.1016/S0896-6273(02)00969-8






Neuron




36
















Central administration of ghrelin induces conditioned avoidance in rodents




E
Schéle






C
Cook






Le
May






M
Bake






T
Luckman






S
M
Dickson






S
L




10.1016/j.euroneuro.2017.05.001






European Neuropsychopharmacology




27
















Dopamine signals mimic reward prediction errors




G
Schoenbaum






G
R
Esber






M
D
Iordanova




10.1038/nn.3448






Nature neuroscience




16
















Allostasis: A Brain-Centered, Predictive Mode of Physiological Regulation




J
Schulkin






P
Sterling




10.1016/j.tins.2019.07.010






Trends in Neurosciences




42
















Dopamine reward prediction-error signalling: a two-component response




W
Schultz




10.1038/nrn.2015.26






Nat Rev Neurosci




17
















Neuronal Reward and Decision Signals: From Theories to Data




W
Schultz




10.1152/physrev.00023.2014






Physiological Reviews




95
















A neural substrate of prediction and reward




W
Schultz






P
Dayan






P
R
Montague




10.1126/science.275.5306.1593






Science




275
















How gut hormones shape reward: A systematic review of the role of ghrelin and GLP-1 in human fMRI




C
Schulz






C
Vezzani






N
B
Kroemer




10.1016/j.physbeh.2023.114111






Physiol Behav




263


114111














Oral and postoral determinants of food reward




A
Sclafani




10.1016/j.physbeh.2004.04.031






Physiology & Behavior




81
















Flavor preferences conditioned in C57BL/6 mice by intragastric carbohydrate self-infusion




A
Sclafani






J
Glendinning




10.1016/S0031-9384(03






Physiology & Behavior




79
















Interoceptive inference, emotion, and the embodied self




A
K
Seth




10.1016/j.tics.2013.09.007






Trends in Cognitive Sciences




17
















Lateral Hypothalamic GABAergic Neurons Encode Reward Predictions that Are Relayed to the Ventral Tegmental Area to Regulate Learning




M
J
Sharpe






N
J
Marchant






L
R
Whitaker






C
T
Richie






Y
J
Zhang






E
J
Campbell






P
P
Koivula






J
C
Necarsulmer






C
Mejias-Aponte






M
Morales






J
Pickel






J
C
Smith






Y
Niv






Y
Shaham






B
K
Harvey






G
Schoenbaum




10.1016/j.cub.2017.06.024






Current Biology




27
















The affective gradient hypothesis: An affect-centered account of motivated behavior




A
Shenhav




10.31234/osf.io/68yta




















D
Silver






S
Singh






D
Precup






R
S
Sutton




10.1016/j.artint.2021.103535






Reward is enough. Artificial Intelligence




299


103535














Intrinsically motivated reinforcement learning: an evolutionary perspective




S
Singh






R
Lewis






A
Barto






J
Sorg




10.1109/TAMD.2010.2051031






IEEE Transactions on Autonomous Mental Development




2
















Where Do Rewards Come From?




S
Singh






R
L
Lewis






A
G
Barto


















THE SHAPING OF PHYLOGENIC BEHAVIOR




B
F
Skinner




10.1901/jeab.1975.24-117






J Exper Analysis Behavior




24
















Flavor is in the brain




D
M
Small




10.1016/j.physbeh.2012.04.011






Physiology & Behavior




107
















Feeding-induced dopamine release in dorsal striatum correlates with meal pleasantness ratings in healthy human volunteers




D
M
Small






M
Jones-Gotman






A
Dagher




10.1016/S1053-8119(03)00253-2






NeuroImage




19
















The Satiety Effect of Cholecystokinin Recent Progress and Current Problemsa




G
P
Smith






J
Gibbs




10.1111/j.1749-6632.1985.tb29936.x






Annals of the New York Academy of Sciences




448
















The gustofacial response: observation on normal and anencephalic newborn infants




J
E
Steiner








Symp Oral Sens Percept


















Allostatic Self-efficacy: A Metacognitive Theory of Dyshomeostasis-Induced Fatigue and Depression




K
E
Stephan






Z
M
Manjaly






C
D
Mathys






Lae
Weber






S
Paliwal






T
Gard






M
Tittgemeyer






S
M
Fleming






H
Haker






A
K
Seth






F
H
Petzschner








Frontiers in Human Neuroscience




10














Hypothalamic Survival Circuits: Blueprints for Purposive Behaviors




S
M
Sternson




10.1016/j.neuron.2013.02.018






Neuron




77
















Three Pillars for the Neural Control of Appetite




S
M
Sternson






A-K
Eiselt




10.1146/annurev-physiol-021115-104948






Annu Rev Physiol




79
















Nutritive, Post-ingestive Signals Are the Primary Regulators of




Z
Su






A
L
Alhadeff






J
N
Betley




10.1016/j.celrep.2017.11.036






AgRP Neuron Activity. Cell Reports




21
















Reinforcement learning: An introduction




R
S
Sutton






A
G
Barto








MIT Press


Cambridge, MA












Hunger improves reinforcement-driven but not planned action




Swieten Mmh Van






R
Bogacz






S
G
Manohar




10.1101/2021.03.24.436435
















Dopamine production in the caudate putamen restores feeding in dopamine-deficient mice




M
S
Szczypka






K
Kwok






M
D
Brot






B
T
Marck






A
M
Matsumoto






B
A
Donahue






R
D
Palmiter




10.1016/s0896-6273(01)00319-1






Neuron




30
















The gut-brain axis mediates sugar preference




H-E
Tan






A
C
Sisti






H
Jin






M
Vignovich






M
Villavicencio






K
S
Tsang






Y
Goffer






C
S
Zuker




10.1038/s41586-020-2199-7






Nature




580




















L
A
Tellez






W
Han






X
Zhang






T
L
Ferreira






I
O
Perez






S
J
Shammah-Lagnado






de






van den Pol AN








Separate circuitries encode the hedonic and nutritional values of sugar




I
E
Araujo




10.1038/nn.4224






Nat Neurosci




19




















L
A
Tellez






S
Medina






W
Han






J
G
Ferreira






P
Licona-Limón






X
Ren






T
T
Lam






G
J
Schwartz






de












A gut lipid messenger links excess dietary fat to dopamine deficiency




I
E
Araujo




10.1126/science.1239275






Science




341
















Glucose utilization rates regulate intake levels of artificial sweeteners




L
A
Tellez






X
Ren






W
Han






S
Medina






J
G
Ferreira






C
W
Yeckel






I
E
De Araujo




10.1113/jphysiol.2013.263103






J Physiol




591
















Food Intake Recruits Orosensory and Post-ingestive Dopaminergic Circuits to Affect Eating Desire in Humans




S
E
Thanarajah






H
Backes






A
G
Difeliceantonio






K
Albus






A
L
Cremer






R
Hanssen






R
N
Lippert






O
A
Cornely






D
M
Small






J
C
Brüning






M
Tittgemeyer




10.1016/j.cmet.2018.12.006






Cell Metabolism




29
















Overlapping Prediction Errors in Dorsal Striatum During Instrumental Learning With Juice and Money Reward in the Human Brain




V
V
Valentin






J
P
O'doherty




10.1152/jn.91195.2008






Journal of Neurophysiology




102
















Brain responses to nutrients are severely impaired and not reversed by weight loss in humans with obesity: a randomized crossover study




K
A
Van Galen






A
Schrantee






Ter
Horst






K
W






La
Fleur






S
E
Booij






J
Constable






R
T
Schwartz






G
J
Dileone






R
J
Serlie






M
J




10.1038/s42255-023-00816-9






Nat Metab
















Hybrid Reward Architecture for Reinforcement LearningAdvances in Neural Information Processing Systems




H
Van Seijen






M
Fatemi






J
Romoff






R
Laroche






T
Barnes






J
Tsang








Curran Associates, Inc












Integration of Sweet Taste and Metabolism Determines Carbohydrate Reward




M
G
Veldhuizen






R
K
Babbs






B
Patel






W
Fobbs






N
B
Kroemer






E
Garcia






M
R
Yeomans






D
M
Small




10.1016/j.cub.2017.07.018






Current Biology




27
















Neural Circuitry of Reward Prediction Error




M
Watabe-Uchida






N
Eshel






N
Uchida




10.1146/annurev-neuro-072116-031109






Annu Rev Neurosci




40
















Conditioned Cues Elicit Feeding in Sated Rats: A Role for Learning in Meal Initiation




H
P
Weingarten




10.1126/science.6836286






Science




220
















Interactive cognitive maps support flexible behavior under threat




T
Wise






C
J
Charpentier






P
Dayan






D
Mobbs




10.1016/j.celrep.2023.113008






Cell Reports




42


113008














Dorsal Anterior Cingulate Cortex Encodes the Integrated Incentive Motivational Value of Cognitive Task Performance




D
M
Yee






J
L
Crawford






B
Lamichhane






T
S
Braver




10.1523/JNEUROSCI.2550-20.2021






J Neurosci




41
















Sugar Metabolism Regulates Flavor Preferences and Portal Glucose Sensing




L
Zhang






W
Han






C
Lin






F
Li






I
E
De Araujo




10.3389/fnint.2018.00057






Front Integr Neurosci




12


57














What Can Learned Intrinsic Rewards Capture?




Z
Zheng






J
Oh






M
Hessel






Z
Xu






M
Kroiss






H
V
Hasselt






D
Silver






S
Singh








Proceedings of the 37th International Conference on Machine Learning. Presented at the International Conference on Machine Learning. PMLR


the 37th International Conference on Machine Learning. Presented at the International Conference on Machine Learning. PMLR


















Layers of signals that regulate appetite




C
A
Zimmerman






Z
A
Knight




10.1016/j.conb.2020.03.007






Current Opinion in Neurobiology




64










Systems Neuroscience








Thirst neurons anticipate the homeostatic consequences of eating and drinking




C
A
Zimmerman






Y-C
Lin






D
E
Leib






L
Guo






E
L
Huey






G
E
Daly






Y
Chen






Z
A
Knight




10.1038/nature18950






Nature




537

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]