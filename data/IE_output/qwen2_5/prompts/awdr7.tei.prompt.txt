You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Does Utility Bias Mental Simulations of Risky Events? Introduction
Imagine participating in a raffle where the total number of slips and the number of winning slips are known. How do you perceive your chances of winning? The subjective representations about probabilities play a crucial role in how we understand and navigate uncertainty. Current research suggests that humans do not directly represent or calculate probabilities 
(Kahneman & Tversky, 1973)
. Instead, this process is more likely implemented through a sampling mechanism 
(Sanborn & Chater, 2016)
. Models based on this sampling framework (e.g., 
Costello & Watts, 2014;
Zhu et al., 2020
) approximate normative reasoning under ideal conditions when sufficient cognitive resources are available 1 . These models have successfully accounted for several observed phenomena in probability judgments, including conservatism in judgment and the fallacies in the conjunction and disjunction probabilities 
(Costello & Watts, 2014
, 2017
Erev et al., 1994)
.
Despite advances in the sampling processes theories, little empirical research has explicitly investigated how people draw samples from risky events with outcomes that differ in utility. For instance, consider a gamble with a 50/50 chance of winning £5 or nothing-while the two outcomes share equal probabilities, their utilities differ significantly. This raises an important question: do explicit utilities influence the probabilities with which outcomes are mentally sampled, and if so, in what ways do they shape this sampling process?
Allowing for two possible directions of bias (undersampling or oversampling) in two differing domains (gains and losses), we can outline four biased hypotheses and one unbiased neutrality hypothesis, as illustrated in 
Figure 1
. If the aim of a sampling process is to form accurate beliefs, and if individuals trust the probabilities they are provided, then utilities should ideally have no influence on what comes to mind. This idea is referred to as the Neutrality hypothesis. However, there is currently remarkably little empirical evidence to support it.


Figure 1
Hypotheses of the sampling process considering the influence of domains (gains and losses) and potential biases, with citations of empirical studies that can be explained by the certain biased sampling process.
Instead, it has been found that prior beliefs about outcome distributions can influence probability judgments. 
Yu and Lagnado (2012)
 demonstrated that experimentally induced priors can shape probability judgments. In the absence of such experimentally induced priors, judgments may rely on the prior beliefs derived from environmental statistics. For instance, larger gains, such as national lotteries, are generally less common than smaller gains. Under these conditions, a Centralisation bias might emerge.
Supporting this, 
Pleskac and Hertwig (2014)
 and 
Hoffart et al. (2019)
 found that, under uncertainty, people tend to assign lower probability to higher reward, believing that larger rewards were less likely than smaller ones. While not empirically tested in these studies, 
Pleskac and Hertwig (2014)
 argued that people would, in line with the notion of a fair bet, think that larger losses would be less likely than smaller losses.
Alternatively, a resource-rational perspective shifts focus from using external information to refine uncertain probabilities to improving decision-making when only a limited number of outcomes can be sampled. 
Lieder, Griffiths, and Hsu (2018)
 argued that in such cases, preferential sampling of outcomes with the greatest absolute utility difference from the mean outcome can improve the quality of the decision. For example, in Russian Roulette, decision-making improves if the decision maker prioritises sampling the fatal outcome, ensuring this possibility is not overlooked. Empirical evidence supports the idea that extreme outcomes, both extreme gains and extreme losses, are recalled first and at rates higher than their objective probabilities 
(Ludvig et al., 2014;
Madan et al., 2014
Madan et al., , 2021
. However, this pattern has not been studied for the descriptive gambles investigated in our study. We refer to this tendency as the Polarisation hypothesis.
There is also modest empirical evidence supporting the Pessimism hypothesis. This evidence comes from a probability judgment task in Experiment 2 of de Molière and Harris's study 
(2016)
, where participants estimated the probability of three risky events that shared the same objective probability but differed in their outcomes: gaining money, losing money, or a neutral condition with no monetary consequences. Their findings showed that, compared to the neutral condition, probability estimates were higher in the loss-money scenario and lower in the gain-money scenario (shown in their 
Figure 2
). One possible explanation for this tendency is the concept of defensive pessimism 
(Norem & Cantor, 1986)
, where individuals lower their expectations to prepare for and mitigate potential disappointment in an uncertain future.
Finally, the Optimism hypothesis has the strongest empirical support, primarily from studies using the "Marks paradigm" 
(Marks, 1951)
. In this task, participants were presented with a deck of cards containing both blank and marked cards. The proportion of marked cards varied between 10% and 90%, and participants were informed of the exact proportion before the experiment. They were then asked to draw a card at random and predict whether it would be marked or blank. The marked card could take on one of three meanings depending on the scenario: winning a point (desirable condition), losing a point (undesirable condition), or being meaningless (neutral condition). Participants were more likely to predict a marked card in the desirable condition and less likely in the undesirable condition compared to the neutral scenario 
(Irwin, 1953;
Marks, 1951
; see also 
Krizan and
 Windschitl, 2007 for a review). While this task uses prediction rather than probability estimates as the measure-and studies have shown that likelihood judgments do not reliably exhibit Optimism (e.g., 
Park et al., 2022)
-it may also be limited to cases where probabilities are equal 
(Krizan & Windschitl, 2007)
. Unlike other hypotheses, Optimism lacks a clear normative justification but could be explained by the idea that individuals derive utility from the outcomes they imagine.
In general, the literature on sampling biases is inconsistent, with different researchers employing various measures that produce divergent results. For instance, predictions tend to exhibit optimism, while probability judgments are often neutral or vary in direction. Critically, past work has generally not considered the time course of these biases: While these are often characterised as static effects, recent work on sequential sampling models has proposed potential temporal dynamics in mental processes, meaning early responses may systematically differ from later ones 
(Lieder, Griffiths, M. Huys, & Goodman, 2018;
Zhu et al., 2024)
. This particularly applies to the first value considered: research on anchoring effects 
(Tversky & Kahneman, 1974)
 has suggested the starting point of the sampling process may be influenced by especially salient external values 
(Lieder, Griffiths, M. Huys, & Goodman, 2018;
Spicer et al., 2022)
 and so may be particularly prone to utility biases. Furthermore, individual differences have received limited attention. Most studies focus on testing broad hypotheses using group means 
(Park et al., 2022
 is an exception as they investigated the proportion of the biased individuals), which can obscure variability among participants. For instance, while many individuals may exhibit Neutrality, the group mean might appear biased due to a small subset of participants better aligned with another hypothesis.
To address these gaps in the past works, we adapted a paradigm that calls for repeated mental simulation, the random generation task 
(Baddeley, 1966)
. In contrast to the Marks paradigm in which participants are asked for a single prediction of a lottery, in random generation, participants are asked to repeatedly mentally simulate the outcomes of a lottery in time with a metronome, for example by imagining drawing a slip of paper with a numerical value from a hat, reporting the numerical value, replacing the slip of paper, shuffling, and repeating the process. Random generation was originally used to study working memory 
(Baddeley, 1998)
 and the concept of randomness of people 
(Nickerson, 2002)
, and recently it has been adapted to explore the mental sampling process itself, such as stereotypes 
(Falben et al., 2024)
, and events with equal and unequal probabilities 
(Castillo et al., 2024;
Leon-Villagra et al., 2022)
.
We investigated the biases depicted in 
Figure 1
 across four experiments using the random generation paradigm, comparing its results to probability judgments (Experiments 1 and 2) and predictions (Experiments 3 and 4). To enhance the reliability of our findings, we collected extensive data from each participant, enabling us to more accurately determine which hypothesis their responses aligned with. Specifically, we asked participants to imagine playing a gamble repeatedly, and then say out loud or write down the outcome they imagined. Critically, we manipulated the meaning of these values such that in one condition, participants were told they would represent winning points, in another losing points or that they were just numbers (i.e., not associated with winning or losing).
The first two experiments employed this design but used different probability distributions. Experiment 1 involved a uniform distribution, represented by drawing slips of paper from a bag, whereas Experiment 2 employed a binomial distribution, illustrated by counting the number of heads after simultaneously tossing ten coins. Experiments 3 and 4 aimed to test the generalizability of the findings from the first two experiments.
Specifically, in Experiment 3, we used a drawing-card scenario based on the Marks paradigm to evaluate whether our findings in Experiment 1 and 2 were due to the phrasing of instructions, the number of possible outcomes, or the number of mental simulations participants were asked to perform. Similarly, we conducted Experiment 4 in the laboratory with more salient monetary incentives to test the boundary conditions of the findings.


Experiment 1
In Experiment 1, we employed the random generation paradigm to investigate how participants mentally simulate a gamble with equally probable outcomes. The experiment included three domains: gains, losses, and a neutral control condition. Our primary objectives were: (1) to assess whether the generated histograms align with participants' probability judgments, (2) to determine whether changes in the domains influence the generated results, and (3) to investigate whether the initial number generated is different from the latter ones.


Method


Participants
A total of 30 participants (8 women, 22 men; age: M = 22.0 years, SD = 3.6) took part in the study. All participants were recruited via the University of Warwick participant pool (https://warwick.sona-systems.com/). Participants were reimbursed with Amazon vouchers (a show-up fee of £3 and a random bonus). The bonus ranged from 0p to 20p, and the expected value of the bonus is 10p. Ethical approval was given by the Humanities and Social Sciences Research Ethics Committee (HSSREC) at the University of Warwick.


Design and Materials
The experiment employed a within-subject design, incorporating three variants of a random generation task through three distinct domains: gain, loss, and control. All the participants began with the control domain, and the order of the subsequent gain and loss domains was counterbalanced across subjects.
In each domain, participants were presented with a set of 11 slips of paper of identical size representing the numbers 0 to 10. Domains differed in the value of these numbers: In the gain domain, slips were labeled as "winning [x] points"; in the loss domain, slips were labeled as "losing [x] points", where "x" represents each of the numbers 0 to 10; in the control domain, slips were only labeled with their respective number.
Participants were asked to imagine "drawing a slip out from a bag, saying the number or the outcome on it out loud, putting it back, shuffling, then repeating the process", following the instructions in 
Baddeley (1966)
. To help participants understand the instructions, the experimenter visually illustrated the process without revealing the slip contents. Importantly, in the gain and loss domains, participants were asked to articulate the full phrase "winning" or "losing [x] points" during every response to ensure they did not forget the domain.


Procedure
The experiment was conducted online using Microsoft Teams, which was also used to record participants' audio. The experiment began with an explanation of the random generation task, including a visual demonstration of the drawing process using physical slips by the experimenter.
The main procedure is shown in 
Figure 2
. The experiment contained three blocks, one for each of the three domains. Each block began by showing a photograph of the set of slips from that domain. Participants were then asked to generate draws from that set as spoken responses for four minutes. To maintain a consistent response pace, participants
were asked to open a web page, with a purple dot flashing at the center of the screen, 37 beats per minute. Participants were asked to generate a number every time the dot appeared. They produced responses slightly faster than requested, producing an average sequence length of 155.71 numbers (SD = 27.82).


Figure 2
An illustration of the procedure of Experiments 1 and 2. The figure with a person uttering outcomes is an example for the gain domain. C=control; G=gain; L=loss; bpm=beats per minute.
At the end of each block, participants received a questionnaire with two questions:
first, a forced-choice question, whether all the numbers were equally likely; and second, the probabilities of each number as a percentage without requiring that they sum to 100. After the questionnaire, in the gain and loss domains, the experimenter drew a slip from a bag in front of the participants. The outcome on the slip was not revealed until the end of the experiment and either added or subtracted from the point total. This total was then converted into a cash bonus, with each point equaling one penny 2 . This approach aimed to encode outcomes as either losses or gains while keeping them independent from the random generation tasks. The experiment took about 40 minutes to complete.


Results
Two participants were excluded due to generating at least one sequence that was shorter than 80% of the required length (i.e., fewer than 118 numbers). The results reported below are for the final sample of 28 participants.
When analysing and reporting the data, each generated response was converted into its absolute value, meaning "5" in the control domain, "winning 5 points" in the gain domain, and "losing 5 points" in the loss domain were all transcribed as 5 (and all termed "number" below).


Analysis Outline
The analysis was carried out in four stages. First, we examined the responses of the participants to the forced choice question of whether all numbers were equally likely, as a check on their understanding of the probability distribution. Second, we measured the similarity between the distributions of the probability judgment and the random generation tasks to explore potential alignment between these methods. In the third stage, we focused on the random generation results and conducted a group-level analysis to investigate the effects of domains and starting points on the generated numbers via a Bayesian ANOVA.
Since the analysis revealed a significant effect of the domains, we further examined their influence on the mean responses in both the random generation and probability judgment tasks.
Finally, we conducted an individual-level analysis. This began with examining the effects of domains and starting points for each participant using Bayesian ANOVA to identify subgroups of participants who were or were not influenced by the domains. To confirm the existence of a group uninfluenced by the domains, we applied the same group-level Bayesian ANOVA to their data. We then qualitatively visualised the direction of participants' biases by comparing the mean of the generated numbers in the gain and loss domains with those in the control domain. Lastly, we evaluated each participant's distribution by comparing it to the neutral distribution (the distribution of the random generation results in the control domain), and the importance distributions defined in the Utility-Weighted sampling 
(UWS, Lieder, Griffiths, & Hsu, 2018)
 model, where the Polarisation hypothesis is one of its special cases.


Responses to the Forced Choice Question
For the forced choice question, the majority of participants selected "equal" across the three domains: 78.57% in the control domain (22 out of 28, 95% CI = [59.05%, 91.70%]), 67.86% in the gain domain (19 out of 28, 95% CI = [47.65%, 84.12%]), and 82.14% in the loss domain (23 out of 28, 95% CI = [63.11%, 93.94%]). Detailed counts are presented in 
Table 1
.
Furthermore, we conducted a comparison of the proportion of "equal" responses in the gain and loss domains relative to the control domain. Using McNemar's test with continuity correction, we were unable to reject the null hypothesis, which states participants report the same pattern of probability based on our manipulation of gain or loss domain. Specifically, the test results were χ 2 (1, N = 28) = 1.33, p = .5 for the control-gain comparison and χ 2 (1, N = 28) = 1, p = 1 for the control-loss comparison, after a Holm-Bonferroni correction. 


Comparing Distributions of Probability Estimates and Random Generation
In this analysis, we wanted to address whether the generated histograms align with participants' probability judgments. 
Figure 3
 illustrates the distribution of (normalised) probability judgments and random generation proportions across numbers for each domain.
To obtain these two types of distributions, we normalised the probability judgments and the histogram of the random generation for each participant and calculated the mean value for each number across the participants. Comparisons with the uniform distribution via one-sample t tests, as shown in 
Figure 3
, revealed tendencies to under-generate 0 in the loss domain, under-generate 0 and 1 in the gain domain, and over-generate 3 in the loss domain.
Furthermore, we observed high similarity between the probability judgment and random generation distributions, quantified by the overlapping index 
(Pastore & Calcagnì, 2019;
Weitzman, 1970)
 measuring the percentage of these distributions covering the same area; overlapping indices were calculated individually for each subject, and the mean coefficient for each domain is presented in 
Figure 3
.
At the individual level, we analysed the correlation of the mean values and of the variance between the random generation and probability judgment in each domain. The results, summarised in 
Table 2
, include Pearson's correlation coefficients and the corresponding p-values after applying Holm-Bonferroni correction. These analyses did not indicate any significant correlations between the two tasks. 


Group-level Analysis of Random Generation
If utilities influence the sampling process, we would expect the means of the generated numbers to differ across the domains. Similarly, if there is a time course of biases, the initial number in each domain (the starting point) should be distinct from the subsequent numbers. To test these two hypotheses, we conducted a within-subject Bayesian ANOVA 3 with the default prior scales and calculated the inclusion Bayes factor (BF) using R packages BayesFactor (version 0.9.12-4.5; 
Morey et al., 2023)
 and bayestestR 
(version 0.13.2;
Makowski et al., 2019)
.


Figure 3
The comparison between the normalised probability judgment and the distributions of random generation in control, gain and loss domains of Experiment 1. The dashed lines indicate the theoretical distribution, i.e., uniform distribution; the black error bars represent the 95% confidence interval; the stars mark the numbers or the outcomes whose densities are significantly different from the uniform distribution after a Holm-Bonferroni correction at the significance level of 0.05 ; the percentages are the values of the overlapping index between the probability judgment and the distribution of random generation.
Specifically, we considered the domains, the starting points (whether the number is the first one or not) and their interaction as the fixed effects in the Bayesian ANOVA. We also accounted for the random effect of the subjects. The BF were 1.27 × 10 15 , 4.92 × 10 6 and 1/2.17 for the domains, starting point and their interaction respectively. As indicated in the results of the Bayesian ANOVA, participants exhibited a starting point bias. 
Figure   4
 shows that participants typically began with a relatively small value, and all subsequent numbers were distributed more evenly.
Given the significant effect of domains observed earlier, we conducted an additional Bayesian ANOVA to examine the effects of domains and task type (random generation vs. probability judgment) on the mean responses. The BF from this Bayesian ANOVA provided anecdotal evidence against differences in the means across the domains (BF =


Figure 4
The histograms of the starting points and all the subsequent numbers in Experiment 1.
1/1.11) or between the tasks (BF = 1/1.15). Despite this, we found substantial evidence supporting an interaction effect (BF = 3.87). We believe that the low BF for the domain effect due to using means instead of raw numbers, which reduces individual variance and obscures domain influences. These results will be later discussed in the Discussion subsection.


Individual Differences in Random Generation
The BF for both the domains and the starting point variables indicated decisive evidence that these factors had significant effects. However, we wanted to further investigate how the specific domains influenced the numbers individually.
A Bayesian ANOVA was applied to each participant's data. 
Table A1
 shows the distribution of the individual BF. We found that 78.57% of the participants (22 out of 28, 95% CI = [59.05%, 91.70%]) had a BF value below 1/3. To confirm that these 22 participants were not influenced by the domains, and that this was not a consequence of a small effect size and little data being interpreted as evidence for the null 
(Sanborn & Hills, 2014)
, we repeated the group-level Bayesian ANOVA using only their data. This time, we found that the BF of the domains dropped to 1/46.99 and the BF of the interaction was 1/81.82. However, the BF of the starting point was 8.46 × 10 5 , still indicating decisive evidence supporting the starting point bias.
In addition, to investigate and visualise the direction of participants' biases (or lack thereof), we calculated the mean values of each domain for each participant, and then subtracted the mean value of the control domain from the mean values of the gain and the loss domains. independent samples were drawn from the neutral distribution to match the average sequence length in Experiment 1. This process was repeated three times, simulating the Neutrality hypothesis by maintaining a consistent distribution across all three domains.
We then calculated the mean value difference between the simulated gain and simulated control domains, and between simulated loss and simulated control domains.
Following the central limit theorem, the joint distribution of the two types of mean value differences followed a bi-variate normal distribution, of which the mean value and the covariance matrix can be estimated from the simulation results. The 95% confidence region of this distribution is shown as an ellipse in 
Figure 5
. We found that 82.14% of the participants (23 out of 28, 95% CI = [63.11%, 93.94%]), including all 22 participants whose individual BF of the domains were below 1/3, had points that fell within the ellipse. This indicates that more than half of the participants were unaffected by the change in domains.
Among the remaining participants, there were three in the Optimism region, one in the Polarisation region and one in the Centralisation region.


Figure 5
The 
q ∝ p(o)|∆u(o) − ∆u|,
(1)
where o is an outcome of a gamble, p(o) is the probability of that outcome, u(o) is the utility of that outcome, ∆u(o) is the incremental gain compared with another option, and ∆u is the average utility of the outcomes in the previous similar decisions, acting like prior information. However, there was only one option in our experiment, so ∆u(0) = u(o).
Thus, the approximate importance distribution in equation 1 simplifies tõ
q ∝ p(o)|u(o) − u|.
(2)
Lieder, Griffiths, and Hsu (2018) defined the utility of an outcome o as
u(o) = o k o k max − o k min + ε
(3)
where k was set to k = 1, o max and o min were the largest and the smallest outcome in the given choice, and ε ∼ N (0, σ) reflects neural noise.
Since the importance distribution predicts the sampling distribution, we focused on comparing each participant's empirical histogram in the gain and loss domains with both the neutral distribution and the importance distributions, rather than analysing mean values. Assuming independence among the sampled numbers, we used a multinomial likelihood function to identify the best-fitting distribution-based hypothesis for each participant across both domains.
In our analysis, we assumed the pre-weighted distribution p(o) in equation 2 to be either the uniform or the neutral distribution. We considered k = 1 and k = 0.5, covering the range of the utility exponent empirically identified in previous studies (e.g., 
Glöckner & Pachur, 2012)
. When there is no prior expectation (u = 0), the UWS predicts the Polarisation hypothesis. But we also tested another version of UWS, when u = u(o),
representing an expectation to win or lose the average amount of money in the given gamble. An estimate of σ ε = 0.1703, as determined by 
Lieder, Griffiths, and Hsu (2018)
, was applied consistently across all the specified UWS models.
Since the utility function contains noise and the importance distribution is influenced by utilities, we ran a simulation 20,000 times to estimate the importance distribution. In each simulation, random noise was added to each outcome's utility, and the resulting importance distribution was computed. We then calculated the mean "importance probability" for each outcome across all simulation results. However, we identified one optimistic participant who was classified under the UWS model with k = 1, u = u(o), a model that does not predict an optimistic trend. This discrepancy occurred because the empirical distributions overestimated "0" in the loss domain and "5" in the gain domain, whereas the importance distribution predicted an overestimation of both "0" and "5" across domains. As a result, the importance distribution produced a higher overall likelihood than other hypotheses. These findings suggest that, for most of the participants, the utilities of the outcomes did not influence the sampling process as predicted by the UWS models.


Discussion
First, we compared the histograms of responses between the probability judgment and random generation tasks. While there was considerable overlap between the two, the correlations of their means or variances were not statistically significant, and we found substantial evidence supporting an interaction between domains and tasks. These results


Figure 6
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 1. The lines represent the empirical distributions of each participant that was best fit by that hypothesis, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who were best fitted by the hypothesis.
suggest that people did not employ the same mental process in these tasks. This discrepancy could be attributed to the simplicity of the uniform distribution, which could allow participants to judge probabilities directly without relying on sampling. Next, we investigated the influence of utility on the random generation task. While we found an overall effect of the domains, further individual-level analysis revealed that the majority of the participants were unaffected by the utilities and drew samples from the same distribution, regardless of whether they were placed within the control, gain or loss domains. This was despite participants receiving payment based on the outcome of the random draw (though necessarily payment was not based on their responses), and prefacing each of their responses in which they imagined a win or a loss with "winning" and "losing".
Our random generation paradigm also allowed us to examine the time course of mental simulation, and we uncovered a starting point bias among participants: Individuals initially favour smaller numerical values than the subsequent numbers as they continued their sampling process.


Experiment 2
The results of Experiment 1 supported the Neutrality hypothesis for the majority of participants when the outcomes followed a uniform distribution. However, since most real-world lotteries have unequal probabilities, Experiment 2 investigated a new scenario:
the number of heads after flipping 10 coins. This experiment aimed to investigate whether the Neutrality hypothesis and the starting point bias observed in Experiment 1 would persist under a binomial distribution. Additionally, it examined whether the generated histograms and probability judgments would align more closely as the underlying distributions increased in complexity compared to the uniform distribution.


Method


Participants
A total of 40 participants (31 women, 9 men; age: M = 23.0 years, SD = 3.7) took part in this experiment. All participants were recruited via the University of Warwick participant pool (https://warwick.sona-systems.com/). They were reimbursed with Amazon vouchers (a show-up fee of £3 and a random bonus). The bonus was either £0 or £1, depending on the gambles at the end of the experiment. The average payment was £3.50. Ethical approval was given by the Humanities and Social Sciences Research Ethics Committee (HSSREC) at the University of Warwick.


Design, Materials and Procedure
The design and procedure were identical to Experiment 1 ( 
Figure 2
), with the following exceptions: participants were asked to have both the microphone and the camera on, and their video and voice were recorded. This was only for ensuring that participants remained fully attentive during the experiment.
The materials also changed. Participants were presented with ten coins in a transparent box. They were asked to imagine shaking the box, observing the number of heads, and responding with that number. In the winning and losing scenarios, the number of heads represented the number of points that was won or lost, while in the control scenario, the number of heads had no meaning.
The order of the domains was counterbalanced as we did in Experiment 1, and the participants were still asked to follow a flashing dot with a pace of 37 times per minute. In Experiment 2, participants produced a speed close to the theoretical one-an average length of 148.26 numbers (SD = 6.19) after 4 minutes.
At the end of each domain, participants received the same two questions from Experiment 1. In the gain and loss domains, before advancing to the next block, the experimenter shook the box in front of the participants, counted the number of heads, and converted it into points (one head equals one point) that the participants won or lost (see Footnote 2). But at the end of the control domain, the experimenter did not play this gamble. Before the experiment ended, the experimenter calculated the total points (denoted as T). Then the participants were given a T/20 chance to win a £1 bonus or otherwise only received the show-up fee. The experiment took about 40 minutes to complete.


Results
Three participants were excluded due to generating at least one sequence that was shorter than 80% of the required length (i.e., fewer than 118 numbers); one participant was excluded due to having more than three values outside of the range of 0 and 10. The results reported below are for the final sample of 36 participants. Since Experiment 2 measured the same variables as Experiment 1, the analysis outline remained identical.


Responses to the Forced Choice Question
As in Experiment 1, we initially examined participants' responses to the forced-choice question asking whether all outcomes are equally likely.  
Table 3
 provides more detailed counts.
Furthermore, we conducted a comparison of the proportion of "unequal" responses in the gain and loss domains relative to the control domain. Using McNemar's test with continuity correction, we are still unable to reject the null hypothesis, which states that participants report the same pattern of probability based on our manipulation of gain or loss domain. Specifically, the test results were χ 2 (1, N = 36) = 0, p = 1.0 for the control-gain comparison and χ 2 (1, N = 36) = 0, p = 1.0 for the control-loss comparison, after a Holm-Bonferroni correction.  
Figure 7
 depicts the probability judgment and the distribution of random generation for each domain compared with the binomial distribution using one-sample t tests. The stars mark the numbers whose densities are significantly different from the binomial distribution at the significance level of 0.05 after a Holm-Bonferroni correction. Notably, both the probability judgments and the distributions of random generation exhibited a significant departure from the expected binomial distribution, reflecting a "flattened" shape consistent with prior research showing that participants produce sampling distributions that are flatter than the true probabilities 
(Peterson et al., 1968;
Teigen, 1974)
.
The overlapping index was also employed to examine the similarity between these two distributions: Their values were all equal to or higher than 75%, indicating a high level of similarity between the explicit probability judgments and random generation relative frequencies.


Figure 7
The comparison between the normalised probability judgment and the distributions of random generation in control, gain and loss domains of Experiment 2. The dashed lines indicate the theoretical distribution, i.e., binomial distribution; the black error bars represent the 95% confidence interval; the stars mark the numbers whose densities are significantly different from the binomial distribution after a Holm-Bonferroni correction at the significance level of 0.05; the percentages are the values of the overlapping index between the probability judgment and the distribution of random generation.
At the individual level, we analysed the correlation of the mean values and of the variance between the random generation and probability judgment, shown in 
Table 4
. We found that the correlations of the mean values were significant in all three domains, and the correlation of the variance was also significant in the loss domain, meaning participants' random generations and probability judgments are strongly related.
The consistency between these tasks indicates that individuals likely rely on mental simulations when making explicit probability estimates. This alignment reinforces the idea that random generation can provide valuable insights into how people intuitively evaluate probabilities. 


Group-level Analysis of Random Generation
A within-subjects Bayesian ANOVA was employed to examine whether there were effects of domain and starting point in the generated numbers. The method and the variables were all the same as in Experiment 1.
The BF of the domains was 1.32 × 10 11 , indicating decisive evidence for the fixed effects. In contrast, the BF of the starting points was only 1/1.09, indicating anecdotal evidence at best against a fixed effect. Additionally, the BF of 1/3.28 for the interaction indicated that the data provided substantial evidence against an interaction effect between these factors.
We propose that the absence of the starting point bias observed in previous experiments is due to participants' tendency to begin with the most probable outcome when the distribution is non-uniform. The binomial distribution, in particular, is a special case where the most probable outcome coincides with the mean value. 
Figure 8
 illustrates the histograms of the starting points compared to all subsequent numbers. Examining the


Figure 8
The histograms of the starting points and all the subsequent numbers in Experiment 2.
proportions of the number 5 as a starting point versus subsequent numbers across domains, a Cochran-Mantel-Haenszel Chi-Squared test revealed a significant interaction (χ 2 (1) = 11.71, p < .001). Post hoc tests for each domain showed that the number 5 had a significantly higher proportion at the starting points than among the subsequent numbers in the gain domain (χ 2 (1) = 7.26, p = .01; BF = 6.50). However, no significant differences were found in the control domain (χ 2 (1) = 1.09, p = .15; BF = 1/2.72) or the loss domain (χ 2 (1) = 3.02, p = .08; BF = 1/1.01). All the post hoc p-values were Holm-Bonferroni corrected.
We also investigated the influence of the domains on the mean responses in both the random generation and probability judgment tasks. Similar to the results in Experiment 1, the BF from the Bayesian ANOVA provided anecdotal evidence against differences in the means across the domains (BF = 1/1.45) or between the tasks (BF = 1/2.97). And in contrast to the results of Experiment 1, we found substantial evidence against an interaction effect (BF = 1/13.70), further supporting the idea of consistency between these tasks.


Individual Differences in Random Generation
We next explored the individual differences in the effect of the domains. We repeated the same Bayesian ANOVA for each individual as we did in Experiment 1, and To visualise the influence of the utilities, we employed the same Monte Carlo method as in Experiment 1 with the exception that 146 independent samples were drawn from the distributions to match the average sequence length in Experiment 2.
The results, illustrated in 
Figure 9
, reveal that 72.22% of the participants (26 out of 36, 95% CI = [54.81%, 85.80%]) fell within the ellipse, while five participants were in the Centralisation region, two in the Polarisation region, and three in the Optimism region.
We also noticed that one participant with a BF of the domains below 1/3 fell outside the confidence ellipse. This anomaly occurred because the participant's personal neutral distribution deviated from the neutral distribution used to estimate the confidence ellipse. Despite this deviation, the participant remained unaffected by the domain conditions, aligning with the Neutrality hypothesis.
We used the same distribution-based likelihood comparison to assess how well the Neutrality hypothesis and the UWS models fit the empirical distributions. The same simulation method was used to calculate the importance distributions except that the pre-weighted distribution p(o) was the binomial distribution in Experiment 2. 
Figure 10
 presents the overlap between the empirical distributions and their best-fitted hypothetical distributions ( 
Figure B2
 displays the same figure but assuming that the pre-weighted  


Discussion
Comparing the histograms of responses between the probability judgment and random generation tasks, we observed high overlapping indices as well as a significant positive correlation in their mean values. We also found substantial evidence against the interaction between domains and tasks. These findings suggest that when the distribution becomes more complex, participants are more likely to rely on the sampling process to inform their probability judgments.
Even when using outcomes with unequal probabilities, our results continue to demonstrate that for most individuals the domains do not exert a significant influence on sampling patterns. Probabilities did influence the sampling proportions, with the higher probability head counts being more often randomly generated. Moreover, our observations align with prior research 
(Peterson et al., 1968;
Teigen, 1974)
, reflecting a flattened sampling distribution. These findings bolster the Neutrality hypothesis, depicted in 
Figure  1
, which suggests that people's sampling tendencies are primarily influenced by objective probabilities, unaffected by domain variations.
It is important to note that we did not observe the starting point bias identified in the previous experiment, where participants tended to begin with smaller numbers.
Instead, Experiment 2 revealed a different form of starting point bias: when the risky event followed a non-uniform distribution, participants were more likely to start sampling from the most probable outcome, with the strongest evidence for this in the gain domain.


Experiment 3
Experiments 1 and 2 demonstrated how considering individual difference is important as it showed that the majority of participants supported the Neutrality hypothesis under the random generation paradigm. In contrast, prior research using a similar approach, the Marks paradigm, found evidence in favour of the Optimism hypothesis 
(Irwin, 1953;
Marks, 1951)
. Such a difference raises the question of whether the Optimism observed in the Marks paradigm masks a predominance of Neutrality participants, or whether people are more optimistic in the Marks paradigm due to the fundamental methodological differences. This was addressed in Experiment 3.
First, we compared random generation with the Marks paradigm by using the same card-drawing scenario as the Marks paradigm. The key difference was in the instructions:
participants were asked to imagine drawing a card in the random generation task and to predict which card would be drawn in the Marks paradigm. outcomes. The support for the Neutrality hypothesis could have been influenced by this factor, as fewer and more distinctive outcomes might lead to bias. To investigate this, Experiment 3 compared gambles with two outcomes to those with six outcomes.
In summary, Experiment 3 built on the domain manipulations in Experiments 1 and 2 while introducing three additional independent variables for comparison with the Marks paradigm: task instruction (random generation or prediction), repetition (one-off task or a task repeated 10 times), and number of outcomes (two or six). The primary objectives of Experiment 3 were to investigate:
1. Whether participants' responses would be influenced by the gain, loss, and control domains; 2. Whether different task instructions (random generation vs. prediction) would affect participants' responses;
3. Whether responses in the one-off task would be different from the overall responses in the repeated task;
4. Whether participants were more likely to show the influence of domains with fewer outcomes;
5. Whether the numbers generated in the one-off condition were similar to the starting points in the repeated condition; and 6. Whether the starting point bias observed in Experiment 1 would replicate. 


Method


Participants


Design, Materials and Procedure
Experiment 3 employed a within-subject design with 24 different conditions (3 domains × 2 tasks × 2 levels of repetition × 2 levels of number of outcomes). To maintain task consistency, participants either began with prediction tasks followed by random generation tasks or started with random generation tasks followed by prediction tasks.
Within each task, a Latin square design was used to balance the order of the 12 conditions (3 domains × 2 levels of repetition × 2 levels of number of outcomes). This approach created 24 possible condition orders, and we ensured that the number of participants assigned to each order was as balanced as possible, with the difference in sample size across orders kept to no more than one.
Participants were shown a figure of six cards. In the two-outcome condition, three cards were labeled "0" and three were labeled "5" in the control domain; three were labeled "+0" and three "+5" in the gain domain; and three were labeled "−0" and three "−5" in the loss domain. In the six-outcome condition, the cards were labeled with numbers ranging from "0" to "5" in the control domain, "+0" to "+5" in the gain domain, and "−0"
to "−5" in the loss domain.
The experimental program was developed using PsychoPy3 (version 2023.2.3; Peirce et al., 2019) and conducted online. 
Figure 11
 illustrates the procedure for a condition in Experiment 3. At the start of each condition, participants were introduced to the gamble,
where the cards would be shuffled, and a random card drawn with replacement. In the random generation task, participants were instructed to imagine drawing a card, while in the prediction task, participants were asked to predict the value on a randomly drawn card.
The full text of the instructions for each condition is included in Appendix C.
After the instruction screen, participants had 30 seconds to enter their imagined or predicted value in a text box and click the "Next" button to continue. To ensure participants maintained awareness of the domain, they had to include the symbols "+" and "−" with each input in the gain and loss domains to proceed. If no input was provided within 30 seconds, the program advanced automatically. Once participants submitted their responses, the program executed the gamble, displayed an animation of shuffling and drawing cards, and saved the results without revealing them to the participants. Both tasks ended with a comprehension check question: "Which task have you been asked to do?" with two options provided: "imagine drawing cards" and "predict cards to be drawn".


Figure 11
The procedure of a condition for Experiment 3.
As in Experiments 1 and 2, the values in the gain and loss domains represented winning and losing points, respectively. Each participant started with an initial score of 220 points. Any points gained or lost during the experiment were added to the initial score, with the total points disclosed at the end of the experiment. The experiment lasted approximately 30 minutes.


Results
Three criteria were used for data exclusion, and participants meeting any of these were excluded: First, participants with more than 13 invalid inputs (10% out of the 132 inputs in total) across the experiment 4 were excluded (n = 3); Second, participants who failed both comprehension checks regarding the task instructions were excluded (n = 4);
Third, we excluded participants whose random sequences were extremely predictable in any of the four repeated-control conditions (prediction vs. random generation and two-vs. six-outcome; n = 52) 5 . We established this by using a measure from chaos theory, "determinism" (DET), which measures how much of a given sequence is repeated elsewhere 
(Marwan et al., 2007;
Weber and Camerer, 1987
; see Appendix D), and which has previously been used as an exclusion criterion in random generation studies 
(Castillo et al., 2024)
. To avoid domain effects, we applied this measure only to sequences in the control condition, setting the exclusion threshold to 90%. In total, data from 56 participants were excluded. The results reported below are for the final sample of 98 participants.


Analysis Outline
The analysis was conducted at both the group and individual levels. At the group level, we examined the distribution of the response numbers in two ways. First, we compared the averaged histograms of the response numbers in the two-and six-outcome conditions with the theoretical uniform distribution. Second, we compared the mean values of each of the 24 conditions with the theoretical mean of 2.5. To address Objectives 1-4 from the introduction of Experiment 3 and investigate the effects of the independent variables-task instruction, number of outcomes, number of repetitions, and domains-as well as their interactions, we performed a Bayesian ANOVA. For Question 5, we compared the response numbers in the one-off condition with the starting points in the repeated condition. To answer Question 6, we compared the starting point with all the subsequent numbers within the repeated condition. Both of these analyses were carried out using Bayesian ANOVA.
In the individual-level analysis, we focused on the independent variables that showed significant effects in the group-level analysis, analysing their influence at the individual level using Bayesian ANOVAs. Since the two-outcome and six-outcome gambles differ in their outcome variances, the numbers generated in these two conditions could also exhibit different variances, potentially affecting the ANOVA results. To address this, we divided the data into two subsets based on the number of outcomes and conducted 


Group-level Analysis
Firstly, we illustrated how the numbers were distributed in the two-and six-outcome conditions, as shown in 
Figure 12
. For each participant, we calculated the frequency of each number across the domains and number-of-outcome levels. We then averaged these frequencies across participants and compared the mean frequencies with the theoretical values (1/2 for the two-outcome condition and 1/6 for the six-outcome condition) using one-sample t tests.
All six histograms deviated from the uniform distributions, revealing an optimistic bias: in the gain domain, smaller numbers were less frequent, while larger numbers occurred more often; in the loss domain, this pattern was reversed. To further investigate the distribution of each condition, we calculated the mean value for each condition, as


Figure 12
The distribution of numbers in the control, gain, and loss domains under the two-and six-outcome conditions in Experiment 3. The dashed lines indicate the theoretical distributions, i.e., uniform distributions; the error bars represent the 95% confidence interval; the stars mark the numbers whose frequencies are significantly different from the uniform distribution after a Holm-Bonferroni correction at the significance level of 0.05.
shown in 
Figure 13
. These mean values were compared with the theoretical unbiased mean of 2.5 using one-sample t tests and applied the Holm-Bonferroni correction to the p-values at a significance level of 0.05. Conditions with mean values significantly different from 2.5 are marked.
To assess the effects of each variable on the response numbers, we used a Bayesian ANOVA considering all the four variables and their interactions. The corresponding BFs are presented in 
Table 5
. The BFs for repetition, domain, and their interaction provided decisive evidence supporting the fixed effects. In contrast, the BF for task indicated decisive evidence against any effect, while the BF for the number of outcomes offered substantial evidence for the absence of an effect.
Next, we examined the influence of repetition as a factor in the experimental design.
To do this, we divided the data into three parts, as illustrated in 
Figure 14
: the numbers


Figure 13
The mean value of each condition in Experiment 3. The dashed line marks the position of the theoretical mean value of 2.5, and the stars mark the conditions of which the mean values are significantly different from 2.5 after a Holm-Bonferroni correction at the significance level of 0.05. For the labels of the conditions, GEN=random generation task, PRE=prediction task, TWO=two-outcome gamble, SIX=six-outcome gamble, REP=repeated, ONE=one-off, CTRL=control, GAIN=gain, LOSS=loss.
from the one-off condition, the first number in the repeated condition, and all subsequent numbers in the repeated condition. We began by comparing the two "initial" values-those from the one-off condition and the first number in the repeated condition (comparing the green [dark gray] and red [medium gray] bars in 
Figure 14)
. Following this, we investigated  
Figure 14)
. 
Table 6
 shows the results of the first part of the analysis using the Bayesian ANOVA considering different domains and number of outcomes. We found decisive evidence supporting the fixed effects of repetition and domain, indicating that participants were influenced by the domains and tended to produce higher numbers across all the domains when aware that they could only play the gamble once.
To investigate the starting point bias, we performed another Bayesian ANOVA to analyse the influence of the number of outcomes, domain, starting points, and their interactions in the repeated condition. The BF are presented in 
Table 7
.
We found decisive evidence supporting the fixed effects of the domains, starting 


Figure 14
The mean values of the numbers in the one-off condition and the first and subsequent numbers in the repeated condition across the domains and the number of outcomes in Experiment 3. The dashed line marks the position of the theoretical mean value of 2.5.
points, and their interaction. 
Figure 15
 illustrates the trace plots across different domains and numbers of outcomes. Notably, participants tended to start with an optimistically biased value but gradually converged towards the theoretical mean of 2.5 in Experiment 3. 


Figure 15
The mean values of the ten numbers across participants in each domain and number of outcomes in Experiment 3. The error bars reflect the 95% confidence interval on the mean values. The horizontal lines mark the location of the theoretical mean value, which is 2.5.


Individual-level Analysis
An individual-level analysis was carried out to evaluate whether the "significant" BF in 
Table 5
 was representative of all participants. We repeated the individual Bayesian ANOVA and BF as in the above experiments, but considered the variables of the domains, repetition, and their interaction. 


90.37%]).
Then, we separated the data into two subsets based on the number of outcomes to evaluate the consistency of the domain effect. Specifically, for each participant and each level of the number of outcomes, we analysed the influence of the domains using the Bayesian ANOVA and the BF. The BF for the two-and six-outcome conditions were found to be significantly and positively correlated (Pearson correlation coefficient after Box-Cox transformation: r(96) = .54, p < .001). To avoid the correlation being artificially caused by individual points falling in the corner, participants were categorised based on their individual BFs, using a comparison threshold of 1/3. The contingency table for this categorisation is presented in 
Table 8
. The results of the Fisher's exact test also indicated a significant correlation (p < .001). As shown in 
Table 8
, there were 63.26% of the participants (62 out of 98; 95% CI = [52.93%, 72.78%]) with BFs lower than 1/3 at both the two-and six-outcome conditions.
To confirm this group of participants were not influenced by the domains, we duplicated all the group-level analyses on only these 62 participants.
Full results are provided in Appendix E. 
Table E1
 shows that the BF of the domains decreased from 1.65 × 10 27 to 1/19.48; the BF of the repetition decreased from 251.44 to 1/40.16; and the BF of their interaction decreased from 1.36 × 10 3 to 1/21.71.
These results suggest that we have identified a group of participants who were not influenced by any of these variables. However, we replicated the difference between the number in the one-off condition and the first number in the repeated condition, as observed in the group-level analysis 
(Table E2
 and 
Figure E1
). 
Figure 16
 visualises the individual biases. We employed the same Monte Carlo method to estimate the 95% confidence ellipse, except that the neutral distributions for the two-and six-outcome conditions are the empirical histograms of the numbers in the control domain in Experiment 3, and 22 independent samples were drawn for each iteration of the simulation. We found that 86.73% of the participants (85 out of 98, 95% CI = [78.38%, 92.74%]) had points that fell within the ellipses of the Neutrality hypothesis at each level of the numbers of outcomes.


Figure 16
The We next moved on to the distribution-based likelihood comparison that involves both the two-and six-outcome conditions. The same simulation method was used to calculate the importance distributions of the UWS models except that the pre-weighted distribution p(o) was the two-and six-outcomes uniform distributions, respectively. For each participant, the likelihood of each hypothesis was evaluated and summed across the four empirical distributions (gain vs. loss and two vs. six outcomes). As shown in 
Figure   17
 ( 
Figure B3 displays the same figure but assuming
  in Experiment 1. Specifically, the importance distribution failed to account for the asymmetry in the empirical distribution but still produced the highest overall likelihood, leading to the discrepancy.


Discussion
In Experiment 3, we varied the task instruction, the number of outcomes, the repetition of the tasks, and the domains. At the group level, we found that people were not influenced by the the task instruction but were influenced by the number of repetitions and the domains. Our analysis also revealed that people tended to produce higher values in the one-off conditions than their first number in the repeated condition. Within the repeated condition, a starting point bias was observed, which was utility-dependent: Participants tended to start with a high value in the gain domain and a low value in both the control and loss domains.
Further individual-level analysis showed that some effects were driven by a minority of participants, while others were not. Notably, more than half of the participants were not influenced by repetition, domains, or their interactions, and the effect (or non-effect) of domains was consistent across different levels of the number of outcomes. When we focused on participants who were not influenced by domains at both number-of-outcome conditions, we replicated only one effect observed in the group-level analysis: participants were more extreme in the one-off condition than in the first item of the repeated condition.


Figure 17 The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 3. The lines represent the empirical distributions of each participant, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who was best fitted by the hypothesis.
In the distribution-based comparison, the Neutrality hypothesis emerged as the dominant hypothesis compared to the UWS models. Approximately 84% (82/98) of the participants were best fitted by the Neutrality hypothesis, suggesting that their sampling process was not influenced by changes in the domains.


Experiment 4
A potential issue for the previous experiments was that participants received only minimal or no monetary incentives from the gambles. Since we wanted to investigate whether the utility of an outcome biases participants' perception of its associated probability, it is possible that the previous support for the Neutrality hypothesis was due to the low magnitude of the incentives. With smaller incentives, participants might not have been sufficiently motivated for their perceptions to reflect any bias.
Second, participants in similar prediction tasks are often incentivised based on their accuracy (e.g., 
Budescu & Bruderman, 1995;
Crandall et al., 1955)
 or receive feedback, such as being shown the actual results after making their predictions (e.g., 
Park et al., 2022)
. In our study, however, the bonus had to remain independent of participants' responses. To address this, we provided feedback on their accuracy after each condition, a feature not included in Experiment 3. This adjustment aimed to make the task more comparable to other prediction tasks in the literature.
With Experiment 4, we explored whether the results found in Experiment 3 are robust after we increase the magnitude of the incentive and the distinction between the random generation and the prediction tasks. The design, hypotheses, and analysis method of the study were pre-registered on Open Science Framework (https://osf.io/sbeq9).


Method


Participants
We recruited 48 participants (25 women, 23 men; age: M =24.8 years, SD=3.0) via the University of Warwick subject pool (https://warwick.sona-systems.com/). For the half-an-hour experiment, they received a substantial payment involving a show-up fee of £5 plus a random bonus ranging between £0 and £20. The average payment was £15.
Ethical approval was given by the Humanities and Social Sciences Research Ethics Committee (HSSREC) at the University of Warwick.


Design, Materials and Procedure
The experiment was the same as Experiment 3, with a few exceptions. The 24 condition orders were counterbalanced, with two participants assigned to each order. This experiment was conducted in person, with participants using laboratory computers via the Pavlovia platform (https://pavlovia.org/). Additionally, card values now represented monetary values rather than points, indicated by adding a pound sign (£) in front of the numbers for the gain and loss domain. This change aimed to make the concept of utility more concrete and to allow incentivization with larger monetary incentives compared to Experiments 1 and 2.
Similar to Experiment 3, the program played the gambles after each condition and saved the results. At the end of the experiment, one result from each type of gamble (gains vs. loss and two vs. six outcomes) was randomly selected and summed to determine the bonus. Since all outcomes were based on chance, the actual bonus depended on the randomly selected results. As we used the same gambles in Experiment 3, the worst possible result was losing £10. The participants were initially given a cash note of £10, which was put in front of them throughout the experiment and could gain or lose from depending on the results of the gambles.
The experimental program was also modified in a few ways. In the prediction task, participants received feedback on their accuracy and the theoretical accuracy after each condition, whereas no feedback was provided in the random generation task. The second change involved adding a comprehension check after presenting the information sheet. This check asked whether the bonus amount depended on participants' responses or was unrelated: Participants who answered incorrectly had to reread the information sheet and attempt the question again. Notably, performance on this comprehension check was not part of the exclusion criteria.


Results
As we preregistered, we excluded participants who had more than 13 invalid inputs (n = 1) or failed both comprehension checks (n = 3). We found 31 participants with a DET measure higher than 90%. However, excluding these participants would have removed the majority of the sample, leaving insufficient data for meaningful analysis. To address this, we deviated from the preregistered criterion, retaining a final sample of 44 participants. For transparency, we report analyses using the originally planned exclusion criteria (resulting in a sample size of 15 participants) in Appendix F. These results are largely consistent with those obtained using the sample of 44 participants. Since Experiment 4 measured the same variables as Experiment 3, the analysis outline remained identical and followed the pre-registered analysis plan 6 .


Group-level Analysis
First we compared the averaged histogram of the numbers in each domain and each level of the number of outcomes with the theoretical uniform distributions. As shown in 
Figure 18
, we observed the same optimistic pattern that we found in Experiment 3. In terms of mean values in each of the 24 conditions, we compared them with 2.5 using one-sample t tests and marked the ones significantly different from 2.5 at the level of 0.05 after a Holm-Bonferroni correction. As shown in 
Figure 19
, all mean values in the gain domain were higher than 2.5, while those in the loss domain were lower, also reflecting an optimistic bias in participants' responses.
A Bayesian ANOVA was used to analyse the influence of the independent variables and their interactions, and 
Table 9
 presents the corresponding BFs. Being different from the results in Experiment 3, the BF for repetition provided strong evidence against an effect. In contrast, the BF for the task, the domains, and their interaction decisively


Figure 18
The distribution of numbers in the control, gain, and loss domains under the two-and six-outcome conditions in Experiment 4. The dashed lines indicate the theoretical distributions, i.e., uniform distributions; the black error bars represent the 95% confidence interval; the stars mark the numbers whose frequencies are significantly different from the uniform distribution after a Holm-Bonferroni correction at the significance level of 0.05.
supported the presence of an influence. As shown in 
Figure 19
, the interaction suggests that the mean values for the prediction tasks tended to be more accurate than those for the random generation tasks in both the gain and loss domains.
When comparing the numbers from the one-off condition with the first number of the repeated condition, we replicated the effects of repetition and domains observed in Experiment 3. As shown in 
Table 10
 and 
Figure 20
, participants continued to be optimistic and produced higher values in the one-off conditions than in the first number of the repeated conditions.
Next, we investigated the starting point bias in the repeated condition. As shown in 
Table 11
 and 
Figure 21
, we found decisive evidence for the starting point bias.
Furthermore, we found substantial evidence suggesting that this bias is independent from utility.


Figure 19
The mean value of each condition in Experiment 4. The dashed line marks the position of the theoretical mean value of 2.5, and the stars mark the conditions of which the mean values are significantly different from 2.5 after a Holm-Bonferroni correction at the significance level of 0.05. For the labels of the conditions, GEN=random generation task, PRE=prediction task, TWO=two-outcome gamble, SIX=six-outcome gamble, REP=repeated, ONE=one-off, CTRL=control, GAIN=gain, LOSS=loss.


Individual-level Analysis
After increasing the distinction between the random generation and prediction tasks-specifically by providing accuracy feedback in the prediction tasks but not in the random generation tasks-we found decisive evidence supporting the effect of the task, the  domain and their interaction. Next, we examined whether these effects characterized the majority of our participants.


Figure 20
The comparison between the number in the one-off condition and the first number in the repeated condition across the domains and the number of outcomes in Experiment 4.


Table 11
The inclusion Bayes factors for the repeated condition in Experiment 4. for the task, and 61.36% (27 out of 44, 95% CI = [45.50%, 75.64%]) for their interaction.


Variables


Figure 21
The mean values of the ten numbers across different domains and numbers of outcomes in Experiment 4. The error bars reflect the 95% confidence interval on the mean values. The horizontal lines mark the location of the theoretical mean value, which is 2.5.
Next, we analysed the consistency of the domain's influence across different numbers of outcomes. The BFs for the two-and six-outcome conditions were found to be significantly and positively correlated (Pearson correlation coefficient after Box-Cox transformation: r(38) = .78, p < .001) 7 . To further analyse this, participants were categorised based on their individual BFs, using a comparison threshold of 1/3. The contingency table for this categorisation is presented in 
Table 12
. The results of the Fisher's exact test also indicated a significant correlation (p = .003). We temporarily dropped four participants from the individual BF analysis, as there was no variance in their produced numbers, leading to void values in their Bayesian ANOVA and the corresponding BFs. They were involved in the visualisation and the distribution-based evaluation.
had both BFs less than 1/3. To verify this subgroup of participants were not influenced by the domains, we duplicated all the group-level analysis on these nine participants.
Full results are provided in Appendix E. We found that these nine participants were not influenced by the domains (domain BF=1/530.44; 
Table E4
); we also replicated the influence of the repetition on the initial value (repetition BF=7.53; 
Table E5
) and the utility-independent starting point bias (starting points BF = 3.10 × 10 3 , and domain × starting points BF = 1/407.70; 
Table E6
), as observed in the group-level analysis.
We further visualised the individual biases using the same Monte Carlo method as in Experiment 3. As shown in 
Figure 22
, at the two-outcome level, 47.72% of the We then evaluated the likelihood of the neutral distribution and the importance distribution for each participant. As shown in 
Figure 23
 ( 
Figure B4
 displays the same figure but assuming that the pre-weighted distribution p(o) in the UWS models is the neutral distribution in Experiment 4), we found 45.45% of the participants (20 out of 44, 95% CI = [30.39%, 61.15%]) who were best fitted by the Neutrality hypothesis. Additionally, 10 and 14 participants were classified under the UWS models with k = 1, u = u(0) and k = 0.5, u = u(0), respectively. However, we observed the same pattern as in Experiments 1 and 3: Optimistic participants were assigned to U-shaped importance distributions that failed to capture their optimistic tendencies but still yielded the highest overall likelihood.


Discussion
In Experiment 4, we increased the incentive and made it more salient by giving participants a cash endowment. We also made the distinction between the random


Figure 22
The scatter plot showing the relationship between the empirical M gain − M control and the empirical M loss − M control at the individual level in Experiment 4. The ellipses represent the 95% confidence regions of the Neutrality hypothesis. The dots with lighter color indicate participants with individual BF of the domains below 1/3 at the specific outcome level.
generation task and the prediction task more pronounced after providing the accuracy feedback. At the group level, we found very strong evidence that people were influenced by the task instruction and the domains, but not by the number of outcomes or repetition.
Our analysis also revealed an influence of the repetition on the initial values and the starting point bias. However, unlike in Experiment 3, we found moderate evidence supporting a utility-independent starting point bias in Experiment 4.
Further individual-level analysis showed that more than half of the participants were not influenced by the tasks, while fewer than half were not affected by the domains.
The effect of the domains was consistent across both two-outcome and six-outcome gambles. It shows that more people were biased by the utilities when they held the endowment and the incentive was more salient.
In the quantitative analysis of the mean values, we found that the number of participants falling within the Neutrality hypothesis ellipses and the Optimism region was


Figure 23
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 4. The lines represent the empirical distributions of each participants, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who was best fitted by the hypothesis.
nearly equal for both the two-outcome and six-outcome conditions. In the distribution-wise comparison between the Neutrality hypothesis and the UWS models, we found that the Neutrality hypothesis was not dominant, with only 20 participants best fitted by the Neutrality hypothesis.
As reported in Appendix F, the results remained broadly consistent when applying the pre-registered exclusion criteria. The main difference was the observation of anecdotal evidence against the influence of repetition when comparing the numbers from the one-off condition with the initial numbers in the repeated condition 
(Table F2
). However, we attribute this finding to the small sample size.


General Discussion
In this article, we investigated the impact of the utility of outcomes on mental simulations in various gambles with descriptive probabilities. According to our results, the group-level analysis across all four experiments indicated an influence of utility. However, individual-level analyses revealed notable differences. In the first three experiments, the majority of participants produced mental simulations that were unbiased by utilities, aligning with the Neutrality hypothesis. In contrast, Experiment 4 showed a shift: fewer than half of the participants remained unbiased, while most of the biased participants exhibited an Optimism bias. We attribute this difference to the engagement of the participants. Experiment 4 was conducted in person and involved participants holding an endowment during the task. This setup made the rewards more tangible and salient compared to Experiments 1-3. As a result, participants exhibited more optimistic behaviour in response to the task.
Quantitatively, we compared the Neutrality hypothesis with four different versions of the importance distributions defined in the UWS models, two of which provide a quantitative description of the Polarisation hypothesis. Our finding revealed that the Neutrality hypothesis emerged as the winning model across all experiments-although it was not as dominant in Experiment 4 as it had been in the first three experiments.
However, we also observed that some optimistic individuals were classified under the U-shaped importance distribution in Experiments 1, 3, and 4. This classification occurred because the distribution failed to account for the asymmetry in overestimation between the gain and loss domains, highlighting the requirement of the quantitative distributions for other hypotheses.
The analysis of starting point biases and their interaction with domains revealed variability across experiments. For uniformly distributed risky events (Experiments 1, 3, and 4), we found decisive evidence of a starting point effect on the values, aligning with empirical findings on the anchoring effect 
(Lieder, Griffiths, M. Huys, & Goodman, 2018)
.
Regarding the interaction with domains, Experiment 3 provided strong evidence for an interaction, while Experiments 1 and 4 showed anecdotal or substantial evidence against such an effect. However, further analysis of Experiment 3, focusing exclusively on participants who were uninfluenced by the domains, revealed only anecdotal evidence supporting a utility-dependent starting point bias (the BF of domain × starting points is 1.64 in 
Table E3
). In summary, when outcomes are equally likely, utility-sensitive participants tend to start with an optimistic value, while utility-insensitive participants tend to start with smaller values.
In contrast, for non-uniform distributions (Experiment 2), there was no evidence of a starting point effect on the values. Instead, participants tended to start sampling from the most probable outcome in the gain domain, with no significant effects observed in the control or loss domains. These findings suggest that while the starting point bias is robust across many contexts, its interaction with domain-specific factors is less consistent and requires further exploration.
In Experiments 3 and 4, we compared the starting points in the repeated condition with the numbers provided in the one-off condition. In both experiments, participants exhibited a utility-independent tendency to respond with more extreme numbers in the one-off condition compared to the starting points of the repeated condition. These findings indicate that the response in the one-off condition should not be treated as equivalent to the starting point of a sequence. This unexpected effect shows similarity to the observations by 
Li (2003)
 in a study on risky choices, where participants were more likely to use a heuristic of comparing extreme outcomes in the one-off condition but shifted towards maximising expected value in the repeated condition. We propose that participants in our experiments also adopted different strategies depending on the context:
Participants might rely on heuristics or intuition in the one-off condition, whereas in the repeated condition, they may anticipate the need to balance predictions over time, leading
to a more rational approach.


Random Generation, Probability Judgment and Prediction Are Related
We compared the results of probability judgment and random generation tasks in Experiments 1 and 2, as well as the results of prediction and random generation tasks in Experiments 3 and 4. These comparisons reveal important relationships among these tasks, providing insight into how individuals use mental simulations to approximate probabilities.
First, the findings from Experiments 1 and 2 suggest that people rely on mental simulation when making probability judgments, particularly in more complex scenarios, such as those involving binomial distributions (Experiment 2). In simpler contexts, participants may bypass simulation and instead estimate probabilities directly using descriptive statistics or common knowledge. Second, the results of Experiments 3 and 4
indicate that the prediction tasks produced outcomes similar to the random generation tasks, especially in the absence of accuracy feedback. This convergence between the two tasks supports the notion that predictions are also guided by a mental simulation process.
These findings highlight a fundamental cognitive mechanism underlying all three tasks: the use of mental simulation to estimate probabilities across distributions (as in probability judgment), and commit to forecasts (as in prediction). Together, these results suggest that probability judgment and prediction tasks tap into a shared cognitive process, providing converging evidence for the simulation heuristic 
(Kahneman & Tversky, 1982
) as a key process for navigating risk and uncertainty.
This idea offers a potential explanation for some of the findings in prediction and probability judgments, particularly related to the desirability bias (referred to as the Optimism hypothesis in our study). For instance, 
Park et al. (2022)
 reported that predictions show a much stronger desirability bias, which they attributed to the influence of non-normative factors, such as hunches. We propose an alternative explanation: The prediction may be based on fewer samples than the likelihood judgments (as also suggested by 
Sundh et al., 2023)
, leading to a stronger Optimism effect observed in predictions compared to likelihood judgments.
In addition, as reviewed by 
Krizan and Windschitl (2007)
, the effect of the desirability bias is strongest when the two outcomes of a gamble have equal probabilities (50/50), but is weaker when the probabilities are unequal. Although our study did not explicitly test the interaction between probability and utility in the one-off condition, the influence of probabilities on the repeated mental simulations that we found in Experiment 2 suggests that participants prioritised probability over utility. We speculate that this tendency extends to the one-off condition, reflecting a cognitive heuristic that favours probability more than utility.


Individual Differences Should be Considered
Our study highlights the importance of considering individual differences in psychological research. Across the four experiments, the BF of the domains at the group level consistently provided decisive evidence supporting the effect of the domains. However, further individual-level analysis revealed that this effect in Experiments 1, 2, and 3 was driven by a small subset of participants, while the majority of participants remained uninfluenced by the domain manipulations. These findings demonstrate that group-level results can mask meaningful variability at the individual level.
As 
Frankot et al. (2024)
 noted, group-level analyses often obscure the presence of subgroups and individual patterns of behaviour. Our findings align with this view, underscoring the limitations of relying solely on aggregate data to draw conclusions. Even sophisticated statistical approaches, such as the mixed-effects models used in our group-level analysis, may fail to fully account for the diversity of individual responses. This is particularly important in tasks involving risk and probability, where individual cognitive process can vary widely based on factors such as the use of cognitive heuristics (e.g., 
Shaham et al., 1992)
, cognitive abilities (e.g., 
Peters et al., 2006)
 or personality (e.g., 
Huang et al., 2024)
.


Theoretical and Practical Implications
Our findings have theoretical implications for sampling-based models of probability judgment (e.g., 
Zhu et al., 2022
Zhu et al., , 2024
, which assume people generate samples from an internal distribution of possible outcomes. Furthermore, they align with models of risky choice (e.g., 
Busemeyer & Diederich, 2002;
Busemeyer & Townsend, 1993;
Lieder, Griffiths, & Hsu, 2018;
Roe et al., 2001)
, which describe decision-making as a process of comparing outcomes weighted by their probabilities. Our results highlight the necessity of incorporating individual differences into these models, particularly regarding two possible tendencies: while some individuals may remain unaffected by outcome utilities, adhering strictly to probability-driven sampling, others exhibit an optimistic bias, over-representing favorable outcomes. Accounting for these tendencies in theoretical frameworks could improve predictions of real-world decision-making and reveal the cognitive and motivational factors underlying variability in probabilistic reasoning.
The current findings also have practical implications for fostering rationality in probability judgment. Our observation of the starting point bias reveals that individuals often begin simulations with a skewed initial estimate. However, given sufficient time to simulate outcomes, participants tend to converge toward the rational mean value. This suggests that judgment strategies could be improved by interventions that encourage extended deliberation or structured simulation exercises, particularly in contexts where quick judgments may lead to systematic biases.


Conclusion
In conclusion, utility's influence reveals important heterogeneity in mental simulation processes. While group-level analysis provided decisive evidence supporting the effect of the domains in gain, loss and control conditions, individual-level analysis revealed a non-negligible subgroup of participants who remained uninfluenced by the domains.
Furthermore, we observed that as incentives increased, a greater proportion of participants exhibited the influence of the domains. Additionally, a starting point bias was evident, with participants favouring smaller or more probable outcomes as the initial responses.
Based on these findings, we recommend that both empirical studies and theoretical models in this field account for starting point bias and individual differences in the influence of utility on simulation processes, particularly in relation to the Neutrality (remaining unbiased) and Optimism hypotheses (over-sampling the better gains and under-sampling the worse losses in a gamble).


Constraints on Generality
This study examined how utility influences the perception of probability in a sample of university students in England. Our tasks required participants to understand fundamental concepts such as probability, random generation, and prediction, which rely on basic numeracy skills. Research indicates that numeracy skills vary with educational exposure, age, and cultural background 
(Klaczynski et al., 2019;
Peters et al., 2010)
.
Consequently, the proportion of biased versus unbiased individuals observed in our study may not generalise to all age, educational levels or cultural contexts. However, our individual-level analyses provide a useful framework for exploring these individual differences across diverse educational backgrounds and cultures.
Furthermore, our study focused exclusively on how participants simulate gambles based on descriptive information. Since prior research has shown that people behave differently when making decisions from description versus experience 
(Hertwig & Erev, 2009)
, it is reasonable to infer that simulation processes may also differ when based on experiential information. Several studies have explored how utility influences experience or memory. For example, the extreme gains and losses are often overestimated during the memory encoding process 
(Madan et al., 2021)
, though these studies did not examine the time course of these effects. On the other hand, 
Szollosi et al. (2023)
 asked participants to generate sequences of outcomes a gamble might provide if the experiment continued.
However, they did not evaluate the probabilities of different outcomes within those sequences. Applying the random generation paradigm to gambles based on experience could therefore provide valuable insights into the interaction between memory and utility over time.


Table A1
The Distribution of the Individual Bayes Factors for the Domains in Experiment 1.
Bayes Factors Counts (Percentages)
(1/100, 1/30] 3 (10.71%) (1/30, 1/10] 16 (57.14%) (1/10, 1/3] 3 (10.71%) (1/3, 1] 1 (3.57%) 
(10,
30]
 1 (3.57%) (100, +∞) 4 (14.29%) 22 (50.00%) 6 (13.64%) 6 (13.64%)


Figure B2
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 2 when p(o) in the Utility-Weighted Sampling (Equation 2) was the neutral distribution. The lines represent the empirical distributions of each participants, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who was best fitted by the hypothesis.  results in winning 5 points.


Six-Outcome-Loss:
Each card is printed with the outcomes -0 to -5. The outcome displayed on the card will determine the number of points you earn. For example, drawing the card with "-0" results in losing 0 points, while drawing the card with "-5" results in losing 5 points.


Second Paragraph
Prediction-one-off : In the next page, you will be asked to write down which card will be drawn if the game is played once.


Prediction-repeated:
In the next few pages, you will be repeatedly asked to write down which card will be drawn if the game is played ten times repeatedly: replacing the last drawn card and shuffling between each draw.
Random generation-one-off : In the next page, you will be asked to write down the drawn card you imagined if the game is played once.


Random generation-repeated:
In the next few pages, you will be repeatedly asked to write down the drawn card you imagined if the game is played ten times repeatedly: replacing the last drawn card and shuffling between each draw.
One-off-control: After you complete the task, the program will play the game once for real. Please be aware that your answer will not influence the result.


Third Paragraph
One-off-control: After you complete the task, the program will play the game once for real. Please be aware that your answer will not influence the result.
One-off-gain: After you complete the task, the program will play the game once for real, and the result will be added to the points you win. Please be aware that your answer will not influence the result.
One-off-loss: After you complete the task, the program will play the game once for real, and the result will be added to the points you lose. Please be aware that your answer will not influence the result.
Repeated-control: After you complete the task, the program will play the game ten times for real. Please be aware that your answer will not influence the results.
Repeated-gain: After you complete the task, the program will play the game ten times for real, and the results will be added to the points you win. Please be aware that your answer will not influence the results.
Repeated-loss: After you complete the task, the program will play the game ten times for real, and the results will be added to the points you lose. Please be aware that your answer will not influence the results.


Figure D1
The recurrence plot for an example sequence {4, 2, 1, 5, 4, 3, 2, 5, 4, 1}.


Figure D2
The histogram of the determinism in Experiment 3 (A) and Experiment 4 (B). The dashed lines mark the position of 0.9. For the labels of the legend, GEN=random generation task, PRE=prediction task, TWO=two-outcome gamble, SIX=six-outcome gamble, REP=repeated, CTRL=control. 


Table E2
Inclusion Bayes factors comparing the numbers from the one-off condition with the first number in the repeated condition in Experiment 3, based on the 62 participants with BFs less than 1/3 at both the two-and six-outcome conditions. 


Variables


Table E3
Inclusion Bayes factors for the repeated condition in Experiment 3, considering the 62 participants whose BFs were less than 1/3 at both the two-and six-outcome conditions.


Variables
Inclusion 


Figure E1
The mean values of the numbers in the one-off condition and the first and subsequent numbers in the repeated condition across the domains and the number of outcomes in Experiment 3., only considering the 62 participants whose BFs were less than1/3 at both the two-and six-outcome conditions.


Table E4
Inclusion Bayes factors for Experiment 4, focusing on the nine participants whose BFs were less than 1/3 at both the two-and six-outcome conditions. 


Variables
domain × task 1 3.73×10 4 domain × repetition 1 3.60×10 3 domain × repetition × task 1 8.80×10 6 domain × number of outcomes 1 2.34×10 4 domain × number of outcomes × task 1 4.27×10 8 domain × number of outcomes × repetition 1 4.13×10 6
domain × number of outcomes × repetition × task 1 1.08×10 13


Table E5
Inclusion Bayes factors comparing the numbers from the one-off condition with the first number in the repeated condition in Experiment 4, based on the nine participants with BFs less than 1/3 at both the two-and six-outcome conditions. 


Variables


Table E6
Inclusion Bayes factors for the repeated condition in Experiment 4, considering the nine participants whose BFs were less than 1/3 at both the two-and six-outcome conditions.


Variables
Inclusion 


Figure E2
The mean values of the numbers in the one-off condition and the first and subsequent numbers in the repeated condition across the domains and the number of outcomes in Experiment 4, only considering the nine participants whose BFs were less than 1/3 at both the two-and six-outcome conditions.


Analysis of Experiment 4 Following the Pre-Registration
In this section, we present the analysis of Experiment 4 following the originally-planned exclusion criteria. The results below are for the final sample of 15 participants. The analysis plan remained identical to Experiments 3 and 4.


Group-level Analysis
First we compared the averaged histogram of the numbers in each domain and each level of the number of outcomes with the theoretical uniform distributions. As shown in 
Figure F1
, we observed the same optimistic pattern that we found in Experiment 3 and 4.
Next, we examined the mean values for each of the 24 conditions, comparing them with the theoretical mean of 2.5. Conditions with mean values significantly different from 2.5 were identified after applying a Holm-Bonferroni correction. As illustrated in 
Figure 19
, the domain effects were consistent: mean values in the gain domain were higher than 2.5, while those in the loss domain were lower than 2.5.
A Bayesian ANOVA was used to analyse the influence of the independent variables and their interactions, and 
Table F1
 presents the corresponding BF.
In Experiment 4, the BF for repetition provided very strong evidence against an effect. In contrast, the BF for the domains decisively supported the presence of an influence. The BF for the tasks and the interaction between domain and task were much smaller when sample size was 44. But they still provide substantial and very strong evidence supporting the main effects.
When comparing the numbers from the one-off condition with the first number of the repeated condition, we did not replicated the effects of repetition observed in Experiment 3 and 4. Although 
Figure F3
 shows that participants seemed to produce higher values in the one-off conditions than in the first number of the repeated conditions, but the BF for repetition in 
Table F2
 provided anecdotal evidence against this effect.
Next, we investigated the starting point bias in the repeated condition. As shown in


Figure F1
The distribution of numbers in the control, gain, and loss domains under the two-and six-outcome conditions in Experiment 4 (N = 15). The dashed lines indicate the theoretical distributions, i.e., uniform distributions; the black error bars represent the 95% confidence interval; the stars mark the numbers whose frequencies are significantly different from the uniform distribution after a Holm-Bonferroni correction at the significance level of 0.05. 
Table F3
 and 
Figure F4
, however, we found only anecdotal evidence for the starting point bias.


Individual-level Analysis
As shown in 
Table F1
, we found decisive evidence supporting the effect of domains, substantial evidence supporting the effect of tasks, and very strong evidence for their interaction. Next, we examined whether these effects characterized the majority of our participants.
We applied similar individual-level Bayesian ANOVAs, considering only these three variables. 
Table F4
 shows the distribution of the BFs. We found that 33.33% (5 out of 15, 95% CI = [11.82%, 61.62%]), 73.33% (11 out of 15, 95% CI = [44.90%, 92.21%]) and 66.67% (10 out of 15, 95% CI = [38.38%, 88.18%]) of the participants had BF lower than 1/3 for the domains, task, and their interaction, respectively.


Table F1
The inclusion Bayes factors considering all the participants for Experiment 4 (N = 15).


Variables
Inclusion domain × number of outcomes × repetition × task 1 1.60×10 9


Table F2
The inclusion Bayes factors for comparing the number from the one-off condition with the first number in the repeated condition in Experiment 4 (N = 15).


Variables
Inclusion based on their individual BFs, using a comparison threshold of 1/3. The contingency table for this categorisation is presented in 
Table F5
. However, the results of the Fisher's exact


Figure F3
The comparison between the number in the one-off condition and the first number in the repeated condition across the domains and the number of outcomes in Experiment 4 (N = 15).


Table F3
The inclusion Bayes factors for the repeated condition in Experiment 4 (N = 15).


Variables
Inclusion test did not reject the null hypothesis (p = .24). We believed this is because of the small sample size.
Only 20.00% of the participants (3 out of 15, 95% CI = [4.33%, 48.09%]) had both BFs less than 1/3. To verify this group of participants were not influenced by the domains,


Figure F4
The mean values of the ten numbers across different domains and numbers of outcomes in Experiment 4 (N = 15). The error bars reflect the 95% confidence interval on the mean values. The horizontal lines mark the location of the theoretical mean value, which is 2.5.


Table F4
The Distribution of the Individual Bayes Factors for the 
Domains,
Tasks and Their Interaction in Experiment 4 (N = 15)
.
Bayes Factors Domain (Percentages) Tasks (Percentages) Interaction (Percentages) (0, 1/100] 0 0 2 (13.33%) (1/100, 1/30] 0 0 3 (20.00%) (1/30, 1/10] 3 (20.00%) 0 2 (13.33%) (1/10, 1/3] 2 (13.33%) 11 (73.33%) 3 (20.00%) (1/3, 1] 0 1 (6.67%) 2 (13.33%) (1, 3] 2 (13.33%) 1 (6.67%) 1 (6.67%) (3, 10] 2 (13.33%) 1 (6.67%) 0 (10, 30] 0 0 1 (6/67%) (100, +∞] 6 (40.00%) 1 (6.67%) 1 (6.67%)
Note: The BF intervals refer to 
Jeffreys (1961)
 and 
Wetzels et al. (2011)
, and those with no participants were omitted.
we duplicated all the group-level Bayesian ANOVA analysis on these participants. 
Table   F6
 shows the overall Bayesian ANOVA results; 
Table F7
 shows the results of the comparison of the initial number between the one-off and repeated conditions; 
Table F8
 shows the analysis of the starting point bias.
According to these BF values, these three participants were not influenced by the domains; we also found substantial evidence against the influence of the repetition on the Six-outcome level BF < 1/3 BF ≥ 1/3 Two-outcome level BF < 1/3 3 3 BF ≥ 1/3 1 8 initial value and the starting point bias, as observed in the group-level analysis. 
Figure F5
 shows the comparison of the mean values of the numbers in the one-off condition and the first and subsequent numbers in the repeated condition across the domains and the number of outcomes for the three participants.


Table F6
Inclusion Bayes factors for Experiment 4 (N = 15), focusing on the three participants whose BFs were less than 1/3 at both the two-and six-outcome conditions. 


Variables


Table F7
Inclusion Bayes factors comparing the numbers from the one-off condition with the first number in the repeated condition in Experiment 4 (N = 15), based on the three participants with BFs less than 1/3 at both the two-and six-outcome conditions. 


Variables


Table F8
Inclusion Bayes factors for the repeated condition in Experiment 4 (N = 15), considering the three participants whose BFs were less than 1/3 at both the two-and six-outcome conditions.


Variables
Inclusion We further visualised the individual biases and evaluated the Neutrality hypothesis and the UWS models using the same Monte Carlo method. As shown in 
Figure F6,
  .41%]) of the participants' points fell within the ellipses of the Neutrality hypothesis for the two-outcome and six-outcome conditions, respectively. We also found that 26.67% (4 out of 15, 95% CI = [7.79%, 55.10%]) and 46.67% (7 out of 15, 95% CI = [21.27%,


Figure F5
The mean values of the numbers in the one-off condition and the first and subsequent numbers in the repeated condition across the domains and the number of outcomes in Experiment 4 (N = 15), only considering the three participants whose BFs were less than 1/3 at both the two-and six-outcome conditions.
73.41%]) of the participants fell within the Optimism region.
We then compared the empirical distributions with the hypothetical ones individually. As shown in 
Figure F7
, we found 53.33% of the participants (8 out of 15, 95% CI = [26.59%, 78.73%]) participants who were best fitted by the Neutrality hypothesis.


Figure F6
The scatter plot showing the relationship between the empirical M gain−control and the empirical M loss−control at individual level in Experiment 4 (N = 15). The ellipses represent the 95% confidence regions of the Neutrality hypothesis. The dots with lighter color indicate participants with individual BF of the domains below 1/3 at the specific outcome level.
Figure 5 shows the relationship between the empirical M gain − M control and M loss − M control at the individual level. The Neutrality hypothesis suggests that people draw samples from the neutral distribution, the distribution of the random generation results in the control domain averaged across the participants (represented by the distribution of Random generation in the left panel of Figure 3), across all domains. To show the plausible range of outcomes from this hypothesis, we conducted a Monte Carlo simulation, drawing samples from the neutral distribution. The simulation was run 20,000 times, and in each iteration, 156


Figure 6
6
presents the overlap between the empirical distributions and their best-fitted hypothetical distributions (Figure B1 displays the same figure but assuming that the pre-weighted distribution p(o) in the UWS models is the neutral distribution in Experiment 1). Our analysis revealed that the Neutrality hypothesis outperformed the UWS models for 89.29% of the participants (25 out of 28, 95% CI = [71.77%, 97.73%]).


Figure 9
9
The scatter plot showing the relationship between the empirical M gain − M control and M loss − M control at individual level in Experiment 2. The ellipse represents the 95% confidence region of the Neutrality hypothesis. And the dots with lighter color represent the participants with individual BF of the domains lower than 1/3. distribution p(o) in the UWS models is the neutral distribution in Experiment 2). In Experiment 2, the Neutrality hypothesis was still the best model with 77.78% of the participants (28 out of 36, 95% CI = [60.85%, 89.88%]).


Figure 10
10
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 2. The lines represent the empirical distributions of each participant, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who were best fitted by the hypothesis. UWS = Utility-weighted Sampling.


Another methodological difference is the level of repetition: the Marks paradigm requires participants to give only a single response, whereas the random generation paradigm involves repeated responses. Experiment 3 addressed this difference by manipulating the level of repetition. The third difference is the number of possible outcomes. While the Marks paradigm normally uses dichotomous outcomes, Experiment 1 and 2 included scenarios up to 11


Figure B3
B3
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 3 when p(o) in the Utility-Weighted Sampling (Equation 2) was the neutral distribution. The lines represent the empirical distributions of each participants, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who was best fitted by the hypothesis.


Figure B4
B4
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 4 when p(o) in the Utility-Weighted Sampling (Equation 2) was the neutral distribution. The lines represent the empirical distributions of each participants, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who was best fitted by the hypothesis.


Table 1
1
The Counts of Participant Responses to the Forced-choice Question Whether All the Numbers Were Equally Likely across Three Domains of Experiment 1.
Loss
Control
Gain
Equal Unequal
Equal
Equal Unequal
19 2
0 1
Unequal
Equal Unequal
0 2
0 4


Table 2 The
2
Domain Cor. of Mean (p-value) Cor. of Variance (p-value)
Control
.00057 (1.00)
.13 (1.00)
Gain
-.0055 (1.00)
.16 (1.00)
Loss
-.048 (1.00)
.059 (.77)
Note: The abbreviation "Cor." represents the Pearson's correlation coefficient. The
p-values have been adjusted via Holm-Bonferroni correction.
Correlation of the Mean Value and of the Variance between the Random Generation and Probability Judgment in Experiment 1.


The majority of participants selected the correct answer, "unequal", across the three domains: 69.44% in the control domain (25 out of 36, 95% CI = [51.89%, 83.65%]), 72.22% in the gain domain (26 out of 36, 95% CI = [54.81%, 85.80%]), and 69.44% in the loss domain (25 out of 36, 95% CI = [51.89%, 83.65%]).


Table 3 The
3
Loss
Control
Gain
Equal Unequal
Equal
Equal Unequal
7 1
0 3
Unequal
Equal Unequal
2 1
1 21
Counts of Participant Responses to the Forced-choice Question of Whether All the Numbers Were Equally Likely across Three Domains of Experiment 2.Comparing Distributions of Probability Estimates and Random Generation


Table 4
4
The Correlation of the Mean Value and of the Variance between the Random Generation and Probability Judgment in Experiment 2.
Domain Cor. of Mean (p-value) Cor. of Variance (p-value)
Control
.473 (<.001)
.101 (.56)
Gain
.921 (<.001)
.340 (.084)
Loss
.672 (<.001)
.549 (<.001)
Note: The abbreviation "Cor." represents the Pearson's correlation coefficient. The p-values have been adjusted via Holm-Bonferroni correction.


Table A2
A2
shows the histogram of the individual BF. In Experiment 2, we found 69.44% of participants (25 out of 36, 95% CI = [51.89%, 83.65%]) whose BF fell below 1/3. To confirm that these 25 participants were not influenced by the domain, we repeated the group-level Bayesian ANOVA using only their data. The results were similar to Experiment 1: the BF for the domains dropped to 1/762.91 and the BF for the interaction was 1/1109.92. However, the BF of the starting point was 1.86, still indicating anecdotal evidence supporting the fixed effect.


A total of 154 participants (132 women, 20 men, 2 other; age: M = 18.7 years, SD = 0.8) were recruited via the University of Warwick's subject pool and received course
credit without any monetary incentive for their participation. Ethical approval was given by the Humanities and Social Sciences Research Ethics Committee (HSSREC) at the University of Warwick.


Bayesian ANOVAs for each participant's numbers, focusing solely on the effect of the domains and analysing each subset separately. As a result, each participant had two BFs for domain effects: one for the two-outcome condition and one for the six-outcome condition. If the influence of domains is consistent across conditions, these two BFs should be correlated. To test this, we calculated their Pearson correlation. In addition, we used a threshold of 1/3 as the criterion and created a contingency table categorising participants
as influenced or not influenced by the domains for both the two-outcome and six-outcome gambles. A Fisher's exact test was then conducted to evaluate the consistency of domain influence across the two gambles. To confirm that we had identified a subgroup of participants who remained uninfluenced in both gambles, we applied a group-level Bayesian ANOVA to their data, considering all variables. To qualitatively and quantitatively assess the biases of each participant, we used the same methods as in Experiments 1 and 2. This involved comparing the mean values across the gain, loss, and control domains and evaluating individual distributions under the Neutrality and Polarisation hypotheses.


Table 5
5
The inclusion Bayes factors of all the participants for Experiment 3.
Variables


Table 6
6
The inclusion Bayes factors for comparing the number from the one-off condition with the first number in the repeated condition in Experiment 3.
Variables
Inclusion Bayes factor
repetition
312.65
number of outcomes
1 1.49
number of outcomes × repetition
1 3.42
domain
4.62 × 10 26 4.62 × 10 26 4.62 × 10 26
domain × repetition
1 4.09
domain × number of outcomes
1 1.99
domain × number of outcomes × repetition
1 340.60


Table 7
7
The inclusion Bayes factors for the repeated condition in Experiment 3.
Variables


Table A3
A3
shows the distribution of the BF of each variable. The results indicate that the majority of participants were unaffected by the variables: 76.53% for the domains (75 out of 98, CI = [66.89%, 84.50%]), 70.41% for the repetition (69 out of 98, 95% CI = [60.34%, 79.21%]), and 83.67% for their interaction (82 out of 98, 95% CI = [74.84%,


Table 8
8
Contingency table Showing the Number of Participants Categorized by Their Individual Bayes Factors of the Domains at Both the Two-outcome and Six-outcome Conditions in Experiment 3.
Six-outcome level
BF < 1/3 BF ≥ 1/3


scatter plot showing the relationship between the empirical M gain − M control and M loss − M control at the individual level in Experiment 3. The ellipse represents the 95% confidence regions of the Neutrality hypothesis. The dots with lighter color indicate participants with individual BF of the domains below 1/3 at the specific outcome level.


Table 9
9
The inclusion Bayes factors of all the participants for Experiment 4.
Variables


Table 10
10
The inclusion Bayes factors for comparing the number from the one-off condition with the first number in the repeated condition in Experiment 4.
Variables
Inclusion Bayes factor
repetition
191.60 191.60 191.60
number of outcomes
1 30.51
number of outcomes × repetition
1 27.42
domain
5.26 × 10 54 5.26 × 10 54 5.26 × 10 54
domain × repetition
1 3.39
domain × number of outcomes
1 61.02
domain × number of outcomes × repetition
1 2.78×10 3


We applied similar individual-level Bayesian ANOVAs, considering only these three variables.Table A4shows the distribution of the BF of each variable. Specifically, we found that 31.82% of participants (14 out of 44, 95% CI = [18.61%, 47.58%]) had BF values lower than 1/3 for the domains, 65.91% (29 out of 44, 95% CI = [50.08%, 79.51%])
Inclusion Bayes factors
number of outcomes
1 76.50
domain
6.49 × 10 174 6.49 × 10 174 6.49 × 10 174
domain × number of outcomes
1 726.34
starting points
5.45 × 10 7 5.45 × 10 7 5.45 × 10 7
number of outcomes × starting points
1 111.93
domain × starting points
1 8.69
domain × number of outcomes × starting points
1 7.26×10 5


Table 12
12
Contingency table Showing the Number of Participants Categorized by Their Individual BF of the Domains at Both the Two-outcome and Six-outcome Conditions in Experiment 4.
Six-outcome level
BF < 1/3 BF ≥ 1/3


Table A2 The
A2
Distribution of the Individual Bayes Factors for the Domains in Experiment 2.
Table A3
The Distribution of the Individual Bayes Factors for the Domains, Repetition and Their
Interaction in Experiment 3.
Bayes Factors Domain (Percentages) Repetition (Percentages) Interaction (Percentages)
(1/100, 1/30]
0
0
28 (28.57%)
(1/30, 1/10]
47 (47.96%)
0
36 (36.73%)
(1/10, 1/3]
28 (28.57%)
69 (70.41%)
18 (18.37%)
(1/3, 1]
7 (7.14%)
25 (25.51%)
11 (11.22%)
(1, 3]
2 (2.04%)
2 (2.04%)
3 (3.06%)
(3, 10]
3 (3.06%)
2 (2.04%)
2 (2.04%)
(30, 100]
3 (3.06%)
0
0
(100, +∞]
8 (8.16%)
0
0
Bayes Factors Counts (Percentages)
(1/100, 1/30]
6 (16.67%)
(1/30, 1/10] (1/10, 1/3] (1/3, 1] The Distribution of the Individual Bayes Factors for the Domains, Tasks and Their 13 (36.11%) Table A4 6 (16.67%) 3 (8.33%) (3, 10] 1 (2.78%) Interaction in Experiment 4.
(100, +∞) Bayes Factors Domain (Percentages) Tasks (Percentages) Interaction (Percentages) 7 (19.44%)
(0, 1/100]
0
0
5 (11.36%)
(1/100, 1/30]
0
0
7 (15.91%)
(1/30, 1/10]
9 (20.45%)
0
6 (13.64%)
(1/10, 1/3]
5 (11.36%)
29 (65.91%)
9 (20.45%)
(1/3, 1]
2 (4.55%)
5 (11.36%)
5 (11.36%)
(1, 3]
3 (6.82%)
3 (6.82%)
3 (6.82%)
(3, 10]
3 (6.82%)
1 (2.27%)
2 (4.55%)
(100, +∞]


Table E1
E1
Inclusion Bayes factors for Experiment 3, focusing on the 62 participants whose BFs were less than 1/3 at both the two-and six-outcome Conditions.
Variables
Inclusion Bayes factors
task
1 300.18
repetition
1 40.16
repetition × task
1 3.65×10 3
number of outcomes
1 119.63
number of outcomes × task
1 2.13×10 4
number of outcomes × repetition
1 1.56×10 3
number of outcomes × repetition × task
1 2.94×10 7
domain
1 19.48
domain × task
1 3.60×10 4
domain × repetition
1 21.71
domain × repetition × task
1 1.06×10 7
domain × number of outcomes
1 1.48×10 4
domain × number of outcomes × task
1 7.48×10 10
domain × number of outcomes × repetition
1 6.07×10 6
domain × number of outcomes × repetition × task
1 5.84×10 17


Table F5
F5
Contingency table Showing the Number of Participants Categorized by Their Individual BF of the Domains at Both the Two-outcome and Six-outcome conditions in Experiment 4 (N = 15).


domain × number of outcomes × repetition × task
Inclusion Bayes factors
task
1 59.96
repetition
1 23.92
repetition × task
1 85.60
number of outcomes
1 62.51
number of outcomes × task
1 426.29
number of outcomes × repetition
1 111.79
number of outcomes × repetition × task
1 6361.25
domain
1 233.72
domain × task
1 2.23×10 3
domain × repetition
1 895.45
domain × repetition × task
1 1.06×10 5
domain × number of outcomes
1 4.63×10 3
domain × number of outcomes × task
1 3.31×10 7
domain × number of outcomes × repetition
1 3.87×10 5
1
4.69×10 9


53.33% (8 out of 15, 95% CI = [26.59%, 78.73%]) and 46.67% (7 out of 15, 95% CI = [21.27%, 73


The concept of "sufficient cognitive resources" varies across models. For the Bayesian Sampler
(Zhu et al., 2020)
, it refers to a sufficiently large sample size. In the probability theory plus noise model
(Costello & Watts, 2014)
, it means a high number of samples with minimal recall noise.


The concept of converting points to money, and the minimum and maximum win, were explained to the participants at the beginning of the experiment. However, the actual conversion was not revealed until the experiment was over. In the loss domain, participants were endowed with 10 points before the gamble so they would not truly lose points.


In the analysis across all four experiments, we applied all the Bayesian ANOVA directly to the response numbers and included random effects to account for variation across participants. Instances where Bayesian ANOVA was applied to the mean values are explicitly noted in the text.


Invalid inputs were defined as those that were not possible (e.g., number "6") or were missing responses.


One participant was dropped from the DET analysis because this participant only generate one number in one of the repeated conditions.


In the individual-level analysis of Experiment 4, however, we deviated from the pre-registered analysis plan for addressing the concern that the correlation of the BF for the two-and six-outcome conditions might be "artificially caused by individual points falling in the corner." The pre-registered method was insufficient to resolve this issue. Instead, we used the Fisher's exact test as applied in Experiment 3.








Appendix A Tables for the Distributions of Individual Bayes Factors
This appendix shows the distributions of the individual Bayes Factors from Experiment 1 to Experiment 4. The intervals refer to 
Jeffreys (1961)
 and 
Wetzels et al. (2011)
, and those with no participants were omitted.


Appendix B Alternative Importance Distribution in Utility-Weighted Sampling
In the analysis across all four experiments, we used the importance distribution defined by the UWS models to represent the Polarisation hypothesis and compared it to the Neutrality hypothesis. As specified in Equation 2, the importance distribution depends on the definition of p(o). To evaluate the robustness of this comparison, we re-analysed the data by assuming p(o) to be the neutral distribution in each experiment, while keeping all other parameters of the UWS models consistent with the previous comparisons.
As shown in 
Figures B1, B2
, B3, and B4, respectively, the Neutrality hypothesis remained the dominant hypothesis in Experiments 1, 2, and 3, while in Experiment 4, the Neutrality hypothesis was supported by only half of the participants. These findings were consistent with the results obtained when p(o) was defined as the descriptive probabilities.


Figure B1
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 1 when p(o) in the Utility-Weighted Sampling (Equation 2) was the neutral distribution. The lines represent the empirical distributions of each participants, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who was best fitted by the hypothesis.


Appendix C Instructions for Experiment 3 and 4
The instruction for each condition in Experiment 3 and 4 consisted of three paragraphs, each of which was from the following subsections according to the combination of the dependent variables. For instance, the instruction for the two-outcome-control-prediction-one-off condition is as follows:
Three cards have the number 0, and the other three have the number 5. The number displayed on the card has no relation to the points.
In the next page, you will be asked to write down which card will be drawn if the game is played once.
After you complete the task, the program will play the game once for real. Please be aware that your answer will not influence the result.


First Paragraph
Two-outcome-control: Three cards have the number 0, and the other three have the number 5. The number displayed on the card has no relation to the points.


Two-outcome-gain:
Three cards have outcome +0, and the other three have outcome +5. The outcome displayed on the card will determine the number of points you earn. For example, drawing the card with "+0" results in winning 0 points, while drawing the card with "+5" results in winning 5 points.


Two-outcome-loss:
Three cards have outcome -0, and the other three have outcome -5. The outcome displayed on the card will determine the number of points you earn. For example, drawing the card with "-0" results in losing 0 points, while drawing the card with "-5" results in losing 5 points.


Six-outcome-control:
Each card is printed with the numbers 0 to 5. The number displayed on the card has no relation to the points.


Six-Outcome-Gain:
Each card is printed with the outcomes +0 to +5. The outcome displayed on the card will determine the number of points you earn. For example, drawing the card with "+0" results in winning 0 points, while drawing the card with "+5" Appendix D


Determinism
In this section, we explain the definition of the determinism (DET) and the reason for setting 90% as one of our exclusion criteria. This measure was developed by 
Marks (1951)
 and 
Weber and Camerer (1987)
 to analyse recurrence in a sequence. The measure is based on the recurrence plot, which shows whether the element x i in a sequence is the same as x j . 
Figure D1
 shows an example of the recurrence plot for the sequence {4, 2, 1, 5, 4, 3, 2, 5, 4, 1}.
DET measures the percentage of the dots on the plot that fall on diagonal lines with length equal to or larger than 2:
where l is the length of a diagonal, and C(l) is the count of the diagonal with length l. For example, in 
Figure D1
, there are eight diagonals of length 1 (single dots), two diagonals of length 2, and the one diagonal of length 10 (the main diagonal). The DET for the example sequence is: DET = 2 × 2 + 1 × 10 8 × 1 + 2 × 2 + 1 × 10 = 63.63%. 


Appendix E The Analysis of the Uninfluenced Participants
In this section, we presents the analysis for the subgroup of the participants who were identified as uninfluenced by the utilities in individual-level analysis in Experiment 3 and 4.
The analysis plan followed the one for the group level: We performed a Bayesian ANOVA to investigate the effects of the all the independent variables and their interactions. Then, we tested whether the numbers generated in the one-off condition were equivalent to the starting points in the repeated condition and whether the starting point bias of values would replicate. Both tests were carried out using Bayesian ANOVA. 
Table E1
 shows the overall Bayesian ANOVA results; 
Table E2
 shows the results of the comparison of the initial number between the one-off and repeated condition; 
Table E3
 shows the analysis of the starting point bias. 
Figure E1
 shows the comparison of the mean values of the numbers in the one-off condition and the first and subsequent numbers in the repeated condition across the domains and the number of outcomes. 
Table E4
 shows the overall Bayesian ANOVA results; 
Table E5
 shows the results of the comparison of the initial number between the one-off and repeated conditions; 
Table   E6
 shows the analysis of the starting point bias. 
Figure E2
 shows the comparison of the mean values of the numbers in the one-off condition and the first and subsequent numbers in the repeated condition across the domains and the number of outcomes.


Experiment 3


Experiment 4


Appendix F


Figure F2
The mean value of each condition in Experiment 4 (N = 15). The dashed line marks the position of the theoretical mean value of 2.5, and the stars mark the conditions of which the mean values are significantly different from 2.5 after a Holm-Bonferroni correction at the significance level of 0.05. For the labels of the conditions, GEN=random generation task, PRE=prediction task, TWO=two-outcome gamble, SIX=six-outcome gamble, REP=repeated, ONE=one-off, CTRL=control, GAIN=gain, LOSS=loss.
Next, we analysed the consistency of the domain's influence across different numbers of outcomes. The BFs for the two-and six-outcome conditions were found to be significantly and positively correlated (Pearson correlation coefficient after Box-Cox transformation: r = .80, p < .001). To further analyse this, participants were categorised


Figure F7
The comparison between the empirical and hypothetical distributions in the gain and loss domains in Experiment 4. The lines represent the empirical distributions of each participants, and the bar plots show the distributions of each hypothesis. The value of N represents the number of the participants who was best fitted by the hypothesis.
 










The capacity for generating information by randomization




A
D
Baddeley








Quarterly Journal of Experimental Psychology




18


2


















10.1080/14640746608400019














Random generation and the executive control of working memory




A
D
Baddeley




10.1080/713755788








The Quarterly Journal of Experimental Psychology Section A




51


4
















The relationship between the illusion of control and the desirability bias




D
V
Budescu






M
Bruderman








Journal of Behavioral Decision Making




8


2


















10.1002/bdm.3960080204














Survey of decision field theory




J
R
Busemeyer






A
Diederich




10.1016/S0165-4896(02)00016-1








Mathematical Social Sciences




43


3
















Decision field theory: A dynamic-cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend




10.1037/0033-295X.100.3.432








Psychological Review




100


3
















Explaining the flaws in human random generation as local sampling with momentum




L
Castillo






P
León-Villagrá






N
Chater






A
Sanborn




10.1371/journal.pcbi.1011739








PLOS Computational Biology




20


1














Surprisingly rational: Probability theory plus noise explains biases in judgment




F
Costello






P
Watts








Psychological Review




121


3


















10.1037/a0037010














People's conditional probability judgments follow probability theory (plus noise)




F
Costello






P
Watts








Cognitive Psychology




89


















10.1016/j.cogpsych.2016.06.006














Explaining High Conjunction Fallacy Rates: The Probability Theory Plus Noise Account




F
Costello






P
Watts








Journal of Behavioral Decision Making
















Expectancy Statements and Decision Times as Functions of Objective Probabilities and Reinforcement Values




V
J
Crandall






D
Solomon






R
Kellaway








Journal of Personality




2


24














Conceptual and direct replications fail to support the stake-likelihood hypothesis as an explanation for the interdependence of utility and likelihood judgments




L
De Molière






A
J L
Harris




10.1037/xge0000124








Journal of Experimental Psychology: General




145


4
















Simultaneous over-and underconfidence: The role of error in judgment processes




I
Erev






T
S
Wallsten






D
V
Budescu








Psychological review




101


3


519














Randomly generating stereotypes: Can we understand implicit attitudes with random generation?




J
Falben






L
Castillo






P
Leon Villagra






N
Chater






A
N
Sanborn










Proceedings of the Annual Meeting of the Cognitive Science Society


the Annual Meeting of the Cognitive Science Society






46












Understanding individual subject differences through large behavioral datasets: Analytical and Statistical considerations




M
A
Frankot






M
E
Young






C
Vonder Haar








Perspectives on Behavior Science




47


1


















10.1007/s40614-023-00388-9














Cognitive models of risky choice: Parameter stability and predictive accuracy of prospect theory




A
Glöckner






T
Pachur








Cognition




123


1


















10.1016/j.cognition.2011.12.002














The description-experience gap in risky choice




R
Hertwig






I
Erev




10.1016/j.tics.2009.09.004








Trends in Cognitive Sciences




13


12
















How environmental regularities affect people's information search in probability judgments from experience




J
C
Hoffart






J
Rieskamp






G
Dutilh




10.1037/xlm0000572








Journal of Experimental Psychology: Learning, Memory, and Cognition




45


2
















Impulsivity is a stable, measurable, and predictive psychological trait




Y
Huang






S
Luan






B
Wu






Y
Li






J
Wu






W
Chen






R
Hertwig




10.1073/pnas.2321758121








Proceedings of the National Academy of Sciences




121


24














Stated expectations as functions of probability and desirability of outcomes




F
W
Irwin








Journal of Personality




21


















10.1111/j.1467-6494.1953.tb01775.x














The Theory of Probability




H
Jeffreys








Oxford University Press












On the psychology of prediction




D
Kahneman






A
Tversky




10.1037/h0034747








Psychological Review




80


4
















The simulation heuristic




D
Kahneman






A
Tversky








Judgment under Uncertainty: Heuristics and Biases


D. Kahneman, P. Slovic, & A. Tversky




Cambridge University Press


















10.1017/CBO9780511809477.015














Age, numeracy, and cultural differences in Chinese and American adolescents' performance on the ratio bias task




P
A
Klaczynski






E
A
Amsel






W
S
Felmban




10.1016/j.jecp.2019.104669








Journal of Experimental Child Psychology




188














The influence of outcome desirability on optimism




Z
Krizan






P
D
Windschitl




10.1037/0033-2909.133.1.95








Psychological Bulletin




133


1
















Eliciting human beliefs using random generation




P
Leon-Villagra






L
Castillo






N
Chater






A
Sanborn








Proceedings of the Annual Meeting of the Cognitive Science Society


the Annual Meeting of the Cognitive Science Society






44












The role of Expected Value illustrated in decision-making under risk: Single-play vs multiple-play




S
Li








Journal of Risk Research




6


2


















10.1080/1366987032000078893














Overrepresentation of extreme events in decision making reflects rational use of cognitive resources




F
Lieder






T
L
Griffiths






M
Hsu




10.1037/rev0000074








Psychological Review




125


1
















Empirical evidence for resource-rational anchoring and adjustment




F
Lieder






T
L
Griffiths






M
Huys






Q
J
Goodman






N
D




10.3758/s13423-017-1288-6








Psychonomic Bulletin & Review




25


2
















Extreme outcomes sway risky decisions from experience: Risky decisions and extreme outcomes




E
A
Ludvig






C
R
Madan






M
L
Spetch




10.1002/bdm.1792








Journal of Behavioral Decision Making




27


2
















Remembering the best and worst of times: Memories for extreme outcomes bias risky decisions




C
R
Madan






E
A
Ludvig






M
L
Spetch




10.3758/s13423-013-0542-9








Psychonomic Bulletin & Review




21


3
















Encoding context determines risky choice




C
R
Madan






M
L
Spetch






F
M D S
Machado






A
Mason






E
A
Ludvig








Psychological Science




32


5


















10.1177/0956797620977516














bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework




D
Makowski






M
Ben-Shachar






D
Lüdecke




10.21105/joss.01541








Journal of Open Source Software




4


40


1541














The effect of probability, desirability, and "privilege" on the stated expectations of children




R
W
Marks








Journal of Personality




19


3


















10.1111/j.1467-6494.1951.tb01107.x














Recurrence plots for the analysis of complex systems




N
Marwan






M
Carmenromano






M
Thiel






J
Kurths








Physics Reports




438


5-6


















10.1016/j.physrep.2006.11.001














BayesFactor: Computation of Bayes Factors for Common Designs




R
D
Morey






J
N
Rouder






T
Jamil






S
Urbanek






K
Forner






A
Ly












Version 0.9.12-4.5








The production and perception of randomness




R
S
Nickerson




10.1037/0033-295X.109.2.330








Psychological Review




109


2
















Anticipatory and post hoc cushioning strategies: Optimism and defensive pessimism in "risky" situations




J
K
Norem






N
Cantor




10.1007/BF01173471








Cognitive Therapy an"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]