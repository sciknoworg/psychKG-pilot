You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



INTRODUCTION
When first introduced to different choice alternatives, agents are usually uncertain about which alternative may deliver better reward outcomes. This uncertainty can be reduced through individual learning, where agents repeatedly select the alternatives and experience their outcomes. Alternatively, agents can learn by observing the outcomes of others' choices. A drawback of observational learning is that it typically prevents agents from the immediate reward that would follow their own choices. However, observing still offers some advantages that sometimes make it the preferred way to learn in social animals. First, observation spares agents the initial trial-and-error process of sampling alternatives. This is particularly beneficial when some options may result in adverse outcomes, making observation a safer strategy 
(Chamley, 2003;
Coolen et al., 2003;
Dewar, 2004;
Kendal et al., 2004;
Webster & Laland, 2008;
Galef, 2009;
Laland, 2004)
. Second, observing skilled or experienced peers can accelerate learning, as these individuals are more likely to display choices of the best alternatives 
(Rendell et al., 2010)
.
In humans, uncertainty-driven learning appears to involve metacognitive representations. Studies using explicit confidence reports have linked exploration via individual choices to low confidence in the value of available alternatives 
(Boldt et al., 2019)
. Confidence reports on value-based choices reflect the difference in estimated value among alternatives 
(De Martino et al., 2013;
Lebreton et al., 2015)
, but are also affected by a series of contextual and egocentric biases 
(Lebreton et al., 2019;
Chambon et al., 2020;
Ting et al., 2020;
Salem-Garcia et al., 2023)
. However, most research on the factors influencing confidence has focused on situations where humans learn through their own choices, leaving a gap in understanding how confidence may be differently shaped when humans can also learn through observation.
Effects of observational learning on confidence could be situational, a reflection of the contexts where agents observe more or less. As mentioned earlier, observation is often favored to avoid negative outcomes, but the presence of such negative outcomes has separately been found to affect metacognition too. Indeed, in human studies of non-social reinforcement learning, participants have reported lower confidence in their decisions in contexts involving reward loss, compared to contexts where reward outcomes are positive, even when the quality of choices in both situations is similar 
(Lebreton et al., 2019;
Ting et al., 2020;
Salem-Garcia et al., 2023)
. Thus, we expect that the presence of losses should simultaneously produce more frequent observational learning and lower confidence in value-based choices.
Beyond loss-related effects, confidence during observational learning may also be influenced by choice agency, which significantly shapes cognitive computation and subjective experience 
(Haggard, 2009;
Haggard & Chambon, 2012)
. Research has shown that individuals exhibit greater confidence in decisions linked to their own actions, both for perceptual 
(Charles et al., 2020)
 and value-based 
(Chambon et al., 2020)
 tasks, possibly through self-reinforcement mechanisms 
(Zajkowski & Zhang, 2021;
Ptasczynski et al., 2022)
. Since increased observation typically implies fewer own choices, we should expect people to be less confident in the value of the alternatives when obtaining information about them through observed choices.
While both loss-and agency-related factors may contribute to reduced confidence in contexts of heightened observational learning, no studies have simultaneously examined their simultaneous effects. To address this, we designed a series of two-armed bandit experiments. Participants chose between two alternatives with rewards drawn from independent Gaussian distributions with different means but identical variance. Learning about the value of these alternatives occurred either through individual choices or by observing another agent. To compare the effects of contexts with frequent and rare observation, in our initial experiment participants freely chose whether to learn by making their own decisions or by observation, while contextual factors (presence of losses and observee expertise) were manipulated to encourage varying levels of observation. To dissociate between the origin of differences we found in confidence, in follow-up experiments the mode of learning (observation or personal choice) was imposed. Across experiments, participants repeatedly judged which alternative delivered higher average reward, and rated their confidence in that judgment. Interestingly, this confidence was lower in situations with losses, as well as when participants made less choices (observed more), despite their choice and judgement accuracy being as good or better. Our findings reveal two distinct pathways through which observational learning contexts reduce confidence in value-based choices: the influence of losses and the absence of agentic control.


EXPERIMENT 1
Our first experiment served as an initial step in exploring the relationship between learning mode and confidence. We designed a series of contexts in where individuals would freely engage in individual and observational learning to a different extent, and examined whether this impacted confidence in the value of the alternatives. Rather than imposing a specific learning mode, participants decided whether to learn through their own choices (choice trials) or by observing another agent (observation trials) ( 
Figure 1a
). In choice trials, participants selected between two color-coded decks of cards and received points drawn from the reward distribution associated with the chosen deck. In observation trials, participants (observers) watched another agent (the observee) select a deck and observed the reward derived from the choice, though this reward did not contribute to their final earnings. Each participant completed 32 blocks, with each block consisting of 12 trials. To create varying contexts with differing levels of individual and observational learning, we manipulated two variables across blocks. First, whether general reward given by the alternatives was high or low, with alternatives in low reward blocks being more likely to deliver negative reward. Second, observee experience: at the start of each block, we told participants that the observee had already completed either 0 (inexperienced) or 10 (experienced) choices between the current alternatives. Participants were told the observee was always the same individual, whose choices had been recorded in a previous session. However, the observee was actually a simulated agent employing a value-learning strategy, progressively favoring the deck with the highest estimated value (see Methods). After four randomly selected trials per block, participants were prompted to report their confidence, as a percentage, that a given deck had the higher mean payoff in the current block ( 
Figure 1A
). The left side outlines the sequence of a trial. First, participants decided whether to choose or observe. In observation trials participants saw another agent's choice between two decks, and were given feedback on the reward delivered by that choice, without that reward affecting their final payoff. In choice trials participants picked one of the two decks and saw their choice's reward, which contributed towards their final payoff. Four times per block, at the end of a trial participants had to use a confidence scale to simultaneously judge which of the two decks delivered higher average reward and give their confidence on that judgment. Boxes on the right summarize the variables manipulated across blocks. !" , #" represent the means of high and low value decks, respectively, while !" , #" represent their standard deviations B. Proportion of trials where participants decided to observe, per condition. C. Same as B, but across trials. D. Proportion of high value deck choices per condition, only taking into account choice trials. E. Deck judgment accuracy per condition, defined as the proportion of confidence judgments where participants gave their rating within the half of the scale corresponding to the high value deck, thus identifying such deck as that giving higher reward on that block. F. Absolute confidence,  A from 50 to 100, per condition. For B, D, E and F, small dots connected with lines depict individual participants, with the density of their distribution being represented by the violins. Big dots with error bars depict across-participant averages with their respective standard error of the mean. For C, error bars depict standard error of the mean, with their point of intersection with the lines denoting across-participant averages. Note that this summary data is for visualization purposes only, as our statistical analyses rely on LMMs using trial-to-trial data.


Methods


Participants
We recruited 50 human participants using Prolific (www.prolific.com). Age and gender were not recorded, but we used Prolific's feature to ensure a balanced sample with respect to gender. Remuneration ranged between £10 and £14, depending on the final accumulated points. 7 participants were excluded after a t-test indicated that their deck choice performance (choices of the high value deck) was non-significantly greater than chance. All analyses in the results section are based on the 43 remaining participants.


Apparatus and stimuli
The experiment was coded on JavaScript using jsPsych (De Leeuw, 2015), version 6.1.0. It was presented online on the participants' internet browser. Experiment presentation and data collection were made through Cognition (www.cognition.run).


Procedure


Structure of a trial
Participants completed 32 blocks, each consisting of 12 trials. Each trial required drawing a card from either a blue or pink deck. At the start of the trial, participants chose between making the decision themselves (choice trial) or observing another agent, referred to as the observee, making the choice (observation trial). To make this selection, the screen displayed the options "CHOOSE" and "OBSERVE" in boxes on opposite sides of the screen, with the sides counterbalanced across participants. Participants clicked on the box corresponding to their preferred type of trial using the mouse. Subsequently, a blue and a pink card appeared side by side, face-down. In choice trials, participants selected the left or right card by pressing the "S" or "D" key on their keyboard. In observation trials, participants pressed the spacebar to see the observee's choice. The chosen card was outlined in white for 500 ms and then revealed a reward number, positive or negative, on a green or red background, respectively. This reward was either added to or subtracted from the participant's cumulative score. The unchosen card remained face-down, preventing feedback on foregone choices. Participants could take as much time as needed to click a "NEXT" button to proceed to the next trial. Within each block, rewards for the two decks were drawn from Gaussian distributions, with one deck consistently having a higher mean reward (high value deck) than the other (low value deck).


Reward and observee experience conditions
The experiment implemented a 2x2 factorial design, with each block assigned to a condition resulting from the crossing of two variables: reward and observee experience. The reward variable referred to the overall level of reward within a block, which was either high or low, although the high value deck consistently offered higher average reward than the low value deck. In high reward blocks, the mean rewards for the high and low value decks were 30 and 20 points, respectively, while in low reward blocks, the mean rewards were 5 and -5 points. For both decks and across both reward conditions, rewards were sampled from a Gaussian distribution with a standard deviation of 15 points. To ensure no extreme values appeared, any reward sampled outside three standard deviations from the mean was resampled. The reward manipulation was designed to increase the frequency of losses (negative rewards) in the low reward condition, which was expected to encourage participants to observe more frequently.
The second variable, observee experience, referred to the number of trials the observee had completed before participants began a block. In the experienced observee condition, that number of trials was 10. Consequently, if participants chose to observe on their trial 1, they would see the observee's trial 11. In the inexperienced observee condition, both participant and observee started the block simultaneously. To prevent participants from gaining access to their future potential outcomes in experienced observee trials, reward samples within a block were distinct for the participant and the observee. The observee experience manipulation was intended to increase observation rates in the experienced observee condition.
Participants were informed of the reward condition (high or low) and the observee experience condition (experienced or inexperienced) at the start of each block. Throughout the block, the reward level and the trial numbers for both the participant and the observee were displayed on the screen. At the end of each block, participants were shown the total number of points they had earned.
Two additional elements were counterbalanced across blocks. First, the color of the decks (blue or pink) associated with the high and low value decks was alternated. Second, the side of the screen (left or right) on which each deck appeared was varied. The experiment consisted of 32 blocks, resulting from including two blocks for each combination of color mapping, screen side mapping, reward condition, and observee experience condition.


Confidence ratings
Confidence ratings were collected four times per block, following either observation or choice trials. Participants were presented with the prompt: "How confident are YOU that, on the current block, one deck gives on average more points than the other?" A horizontal scale appeared below the prompt, consisting of a bar divided into two halves, one blue and the other pink. The colors of the scale corresponded to the block's color-side mapping, with the intensity of the colors decreasing from bright at the extremes to white at the center. When participants hovering their mouse cursor over the scale, an integer appeared, ranging from 50 at the center, representing total uncertainty regarding which deck provided a higher average reward, to 100 at either extreme, indicating complete confidence in the corresponding deck. Participants were required to position the cursor on the half of the scale representing the deck they believed offered greater average reward and to click at the point that reflected their level of confidence. To capture confidence ratings at different points within a block, these ratings were distributed across four trial bins: 1-3, 4-6, 7-9, and 10-12. Each rating occurred after a trial number within one of these bins, and across blocks, each trial number was sampled approximately evenly. This one-click rating, then, gave information on the correctness of the deck judgment and on absolute confidence in the judgment. Importantly, confidence ratings were designed to assess participants' belief about which deck provided the higher average reward overall, rather than their confidence in having chosen the best deck on the preceding trial. This was so because we expected participants to make some choices to maximize immediate reward (exploitation), but also some to gather information about the value of an alternative (exploration), so a deck could be chosen even if not believed to be that with the biggest payoff.


Defining observee choices
Participants were told they would have the opportunity to observe the choices of a human participant that had previously completed some choice-only blocks. The identity of this observee was not disclosed, but participants assigned them an avatar and name. This observee was actually a simulated agent whose choice behavior captured basic traits thought to be shared by humans. The first of these traits was value learning. The value for the high value deck h on trial t was simply the averaged reward r experienced after choosing that deck across the trials so far on that block:
!,# = 1 % # # #$% (1)
The same was applied to define value for the low value deck l. For simplicity, and to avoid assumptions, no prior value was assigned to any deck at the start of the block. The second trait we gave to our simulated agent was early exploration of both decks, transitioning to exploitation, with more choices of the deck associated with the highest value as trials went by. This was achieved with a softmax choice function, which determined the probability of choosing the high value deck on trial t:
( !,# * = & !,# ' & !,# ' + & $,# '
(2)
The temperature parameter τ captures the stochasticity of choices. We made τ = 10, which in simulations of the experiment's context led to around 70% choices of the high value deck around trial 10. This ensured that, in the experienced observee condition, participants could usually start observing significantly more choices of the high value deck. Since no prior value was assigned for each deck, in early trials observees chose based on a coin flip (0.5 probability of choosing either deck) until both decks had been chosen at least once, and choices could already be made based on experienced reward.


Payoff
Participants were informed that their remuneration for completing the experiment would consist of a base payment of £8, provided their data demonstrated meaningful engagement with the task and choices consistent with learning. In addition to the base payment, participants could earn a variable bonus, bringing the total possible payoff up to £14. The calculation of such bonus, not disclosed to participants, was based on the number of points accumulated during the task. Specifically, the bonus was scaled according to a benchmark derived from the expected performance of a hypothetical high-performer who chose the higher-value deck on 75% of choice trials, with an overall preference for the optimal strategy 75% of the time. From this benchmark, the performance of a hypothetical participant that chose randomly both between observation and choice trials and between blue and pink decks. The resulting value served as the denominator in a formula that scaled the bonus. The numerator was the difference between the maximum planned payoff (£14) and the minimum (£10). This scaling factor was then multiplied by the participant's accumulated points, yielding a final bonus amount between £10 and £14, rounded up to the nearest pound. While confidence ratings were not directly tied to monetary rewards, participants were explicitly informed that their data would undergo scrutiny. Specifically, systematic or random use of the confidence scale-such as repeatedly selecting the same value or side without apparent consideration-would result in forfeiture of payment. This lack of economic incentivization is unlikely to have influenced our confidence results, as prior research has shown similar confidence ratings regardless of whether they are monetarily enforced 
(Lebreton et al., 2019)
.


Instructions and practice blocks
Before the main part of the experiment participants read the instructions, where they were familiarized with different aspects: the procedure of a trial, the fact that they would only keep the reward they earned in choice trials, how to give confidence ratings, the different conditions a block could belong to, the fact that within a block a deck always gave higher average reward than the other, and the payoff scheme. Participants were also encouraged to accumulate as many points as possible.
After the instructions, participants completed four practice blocks of 12 trials each. On the two first blocks participants simply saw the observee choosing. This helped participants familiarize themselves with the observee's choice dynamics, mainly exploration of both decks leading to more choices of the high value deck. The last two practice blocks were like those in the main part of the experiment. Within each pair of practice blocks participants were presented once each of the two reward conditions, in random order. On the first pair of blocks, participants always observed from the observee's first trial, and on the second pair they observed an experienced observee and an inexperienced observee once, in random order.


Behavioral Models
The primary aim of our behavioral analyses was to assess the impact of experimental manipulations on several dependent variables. Due to the hierarchical structure of the data and unbalanced factor levels (e.g., differing numbers of observation trials across conditions), we employed Linear Mixed Models (LMMs), building separate models for each dependent variable. First, to verify whether our design produced conditions with varying levels of observation, we examined whether participants chose to observe or make their own choices on each trial. Next, we assessed how these conditions influenced three dependent variables. First, in trials where participants made their own choice, whether the high value deck was selected. Second, deck judgment accuracy: that is, whether a confidence rating had been given within the half of the scale corresponding to the high value deck, meaning the participant was more confident in that deck giving more reward, and thus correctly identifying it as the best alternative. When using this variable, we excluded trials with a rating of 50, that manifested no preference for either deck. Finally, our main variable interest, absolute confidence, indexed by the 50-to-100 reported integer, irrespective of the half of the scale the rating had been given within.
For each dependent variable, we aimed at a full model including fixed effects for the factorial design variables, which in our first experiment were reward level (high vs. low) and observee experience (experienced vs. inexperienced), along with their interaction. Trial number, centered around the sample mean, was included as a numeric fixed effect to control for withinblock learning. Random effects included participant ID (random intercept) and the factorial design variables (random slopes, additive without interactions). If convergence issues arose, we simplified the models by first removing the interaction between fixed effects, treating them additively. Persistent issues were addressed by running separate models for each predictor, excluding the non-tested variable from both fixed and random effects.
The statistics we report are based on running an ANOVA on the LMM. When predicting a binary dependent variable (observation choices, high value deck choices and deck judgment accuracy) we fitted a logistic regression by using the mixed function of the afex package 
(Singmann et al., 2023)
. In the main text we report the given χ 2 statistic with its associated pvalues, calculated via Likelihood Ratio Test. The single value between brackets corresponds to the degrees of freedom of the model. When predicting (continuous) absolute confidence we used the anova function within the lmer function of the lme4 R package 
(Bates et al., 2015)
. We report the F statistic, degrees of freedom and p-values, calculated through Satterthwaite's method implemented in the lmerTest package 
(Kuznetsova et al., 2017)
. Non-significant effects are only accompanied by their p-value.
Below are the final specifications of the models referred to in the Results section of Experiment 1. Our first two models try to predict decisions to observe on every trial. Following the approach described above, and encountering convergence problems with both the full model and the first simplification, we ran two separate models, where the main predictors were reward condition (M1.1.1.) and observee experience condition (M1.1.2.):
M1.1.1.: observation_chosen ~ reward_condition + trial_number + (reward_condition | participant_id) M1.1.2.: observation_chosen ~ observee_experience_condition + trial_number + (observee_experience_condition | participant_id)
We then ran three full models predicting choices of the high value deck (M 1.3.), deck judgment accuracy (M 1.4.) and absolute confidence (M1.5.): 


Results
We started by modelling the frequency of observation as a function of reward magnitude (Model M1.1, see Methods) and observee experience (Model M1.2), while also controlling for trial number. In its respective model, we found a significant main effect of reward (χ 2 (6), 35.16, p < .001, 
Figure 1B)
, with low reward blocks leading to more observation decisions, most likely explained by participants observing to protect themselves from potential losses. While in the other model there was no significant main effect of observee experience (p = .17), we found that participants observed significantly more in the experienced observee blocks when reward was high (χ 2 (6), 10.17, p = .001). We also found effects of trial number, with participants observing less as trials went by (reward model: χ 2 (6), 1315.91, p < .001; observee experience model: χ 2 (6), 1055.47, p < .001), showing that, congruent with learning, participants were more likely to engage in choice trials the more outcomes they had experienced ( 
Figure 1C
). Overall, manipulating each of our two variables created conditions with different levels of observation, although the reward manipulation was much more successful.
Next, we analyzed the effects of the predictors derived from our experimental manipulations on choice and confidence measures (models M1.2, M1.3, M1.4). Choices of the high value deck (that is, that with higher generative mean) were significantly more frequent in the low reward condition (χ 2 (11), 10.40, p < .001; 
Figure 1D
). We found no significant influence of neither observee experience (p = .28) nor the interaction between the two factors (p = .24). Importantly, because trial number had been controlled for, the reward effect was not simply due to higher initial observation making choice trials in low reward blocks typically belong to later stages within a block, where due to learning more choices of the high value deck should be expected (see also Supplementary Material 1). Consistently with choices, deck judgment accuracy (whether confidence for the better deck was over or under 50%) was marginally higher in the low reward condition (χ 2 (11), 3.52, p = .06; 
Figure 1E
), but not affected by observee experience (p = .17) nor their interaction (p = .46). If confidence tracked the better performance participants had in low reward blocks, such confidence should be higher in that condition. However, absolute confidence (the absolute value of confidence ratings, ranging from 50 to 100; 
Fig 1F)
 went in the opposite direction, being significantly higher in the high reward condition 
(F(1, 42)
, 55.95, p < .001; 
Figure 1F
). This variable was also not affected by observee experience (p = .91) or the interaction term (p = .76). All three choice and confidence measures were also positively associated with trial number (high value deck choices: χ 2 (11), 249.97, p < .001; deck judgment accuracy: χ 2 (11), 83.50, p < .001; absolute confidence: F(1, 5375.44), 622.07, p < .001), indicating that participants performed better and became more confident as they acquired more information.


Discussion
In Experiment 1 we found that low reward blocks, where participants observed more, were related to lower confidence in knowing the best alternative, despite choosing such alternative more often, and identifying it with higher accuracy. Why would such a discrepancy occur? One possibility is that lower reward and / or frequent losses made participants less confident in their judgments. This is consistent with studies documenting valence biases in value-based learning 
(Lebreton et al., 2019;
Ting et al., 2020;
Salem-Garcia et al., 2023)
, so we will call this the valence hypothesis. Interestingly, valence could also be responsible for the better choices and deck judgment accuracy in low reward blocks, in line with the loss attention literature 
(Yechiam & Hochman, 2013a
, 2013b
, that identifies more attentiveness, and consequently better performance, in situations of likely losses. Besides valence, another explanation for the difference between conditions is that participants felt more confident in high reward blocks because they made more choices of their own, independently of whether that led to more accurate beliefs or not (agency hypothesis).


EXPERIMENT 2
Since in our first experiment more observation was always tied to lower reward, the behavioral results could not disentangle between the effects of reward valence and agency. In order to arbitrate between these hypotheses, we designed a second experiment where general level of reward and frequency of observation were dissociated by design. The main innovation of Experiment 2 was that participants could not decide whether to choose or observe 
(Figure 2A
).
In what we called observation + choice blocks, we randomly interleaved observation and choice trials, with roughly half of the trials belonging to each type (see Methods). In only choice blocks, all trials were choice trials. As in Experiment 1, across blocks we also manipulated the general level of reward, giving rise to high reward and low reward blocks. However, given the limited success of the manipulation, we did not vary the experience of the observee: within a block, participants and observee always had the same trials of experience (akin to the unexperienced observee condition). With this new task design, finding lower confidence for low reward than for high reward blocks but no difference in confidence between agency conditions would lend support for the valence hypothesis. Alternatively, lower confidence for observation + choice than for only choice blocks but no difference between reward conditions would offer evidence for the agency hypothesis. Finally, should we find lower confidence for both low reward and choice only blocks, this would simultaneously support valence and agency hypotheses ( 
Figure 2B
).  


Procedure
Experiment 2 differed from Experiment 1 in some key aspects. Most notably, participants did not decide between observation and choice on each trial. Instead, observation trials displayed a screen prompting participants to press the spacebar to reveal the observee's choice, while choice trials required participants to press the S or D keys to make their own selection. The trial type was indicated by text at the top of the screen ('OBSERVATION' or 'CHOICE'), and the prompts for key presses were distinct for each trial type. Additionally, observation trials included an avatar representing the observee. The rest of the trial structure, including feedback for the chosen option and the frequency and method of confidence ratings, remained as in Experiment 1. Observee choices were simulated using the same algorithm.
Another difference in Experiment 2 was the across-block 2×2 factorial design. As in Experiment 1, reward (high vs. low reward blocks) was manipulated. However, the observee experience variable was replaced with a manipulation of choice agency. In only choice blocks, participants made all their choices. In observation + choice blocks, participants observed the observee's choice in about half of the trials, while choosing themselves in the rest. The exact number of observation trials within a block was either 5, 6 or 7 (in 25%, 50% and 25% of the blocks, respectively). This slight variation was implemented so participants could not know for sure the number of observation trials within a block. This way we prevented that, towards the end of a block, participants stopped paying attention if no more choice trials were left, which could affect confidence ratings. The position of observation trials along observation and choice blocks was randomized, and so was the number of observation trials across blocks.
Participants completed 32 blocks of 12 trials each, with the block structure determined by variable counterbalancing, similarly as in Experiment 1. To address potential bias caused by differences in own choices between block types, the payoff calculation was adjusted. Participants received a fixed £8 plus a bonus of up to £4 (minimum £10 total). Instead of summing all rewards derived from their own choices, as in Experiment 1, the bonus was based on reward from three randomly sampled own choices from each block. This ensured participants were not biased towards paying more attention to only choice blocks.
The instructions and practice blocks followed a similar format to Experiment 1, incorporating the modifications for Experiment 2. Notably, these adjustments reflected the absence of observation or choice decisions and the replacement of the observee experience manipulation with the choice agency manipulation.


Behavioral Models
We used a very similar LMM approach as in our previous experiment. However, due to the new factorial design, the observee experience condition predictor was here replaced by the choice agency condition. The variables we tried to predict were the same as those from Experiment 1's last set of analyses: high value deck choices, deck judgment accuracy and absolute confidence. This gave rise to three main models: In some follow-up analyses described in the results section, two variations of M2.2 where reward condition is neither part of the fixed nor of the random effects were also ran. In one, only trials from the high reward condition were included, and in the other only trials from the low reward condition.


Results
We fitted three mixed-effects models to predict choice accuracy (M2.1), deck judgment accuracy (M2.2) and absolute confidence (M2.3). Each dependent variable was predicted by the level of reward, the level of choice agency (whether that block featured observation and choice trials or only choice trials), the interaction between the two previous predictors and trial number (for exact model specification see Methods). Choices of the high value deck ( 
Figure  2C
) were marginally, although non-significantly, more frequent in the low reward condition (χ 2 (11), 3.51, p = .06), while not being affected by agency (p = .382) nor the interaction (p = .834). Deck judgment accuracy ( 
Figure 2D
) was significantly affected by both factors: participants were more likely to identify the high value deck in low reward (χ 2 (11), 13.56, p < .001) and in choice-only blocks (χ 2 (11), 4.84, p = .03). The interaction between these variables was also significant (χ 2 (11), 4.04, p = .04). Comparing simple effects of agency at each level of reward separately indicated the effect remaining significant only in low reward (χ 2 (6), 5.21, p= .02), but not in high reward (p= .29) blocks. Absolute confidence ( 
Figure 2E
) was significantly predicted by both reward 
(F(1, 41.95)
, 56.91, p < .001) and choice agency (F(1, 42.21), 16.67, p < .001), as well as their interaction (F(1, 5384.03), 4.35, p = .04): reported confidence was higher in low reward than in high reward blocks, and in only choice blocks than in observation + choice blocks, but the agency-based difference was more pronounced for high reward blocks. Finally, similar to Experiment 1, all three measures were significantly influenced by trial number: participants increasingly chose the high value deck (χ 2 (11), 278.44, p < .001), indicated the high value deck gave more reward (χ 2 (11), 83.68, p < .001) and reported higher confidence in those ratings (F(1, 5376.82), 888.74, p < .001).


Discussion
Our results provide evidence for both tested hypotheses. Reduced absolute confidence in low reward blocks (where losses were more frequent) despite better, or at least not worse, performance supports the valence hypothesis. Higher absolute confidence in only choice blocks supports the agency hypothesis. Thus, Experiment 2 allowed us to identify independent and coexisting influences of valence and agency on confidence.
It could be argued that the higher absolute confidence observed in only choice blocks is simply a byproduct of better deck judgment accuracy in these blocks. However, this explanation is inconsistent with the data. In high reward blocks, the effect of agency on deck judgment accuracy disappeared, yet the effect on absolute confidence not only persisted but became more pronounced. This suggests a direct causal influence of agency on confidence.
Consistent with Experiment 1, low reward blocks were associated with more frequent choices of the high value deck and more accurate deck judgments. Since agency was not confounded with reward in Experiment 2, these findings strengthen the case for a reward-specific effect on choices, potentially related to loss attention. Regarding agency, only choice blocks were associated with more accurate deck judgments, but this effect was limited to low reward blocks. This could reflect enhanced reward processing, better exploration or just a bigger difference in sampled value between decks.
The observed agency effects on confidence could be attributed to factors related to making more choices. For instance, participants may integrate information from their own choices with greater confidence, or the act of choosing itself may boost confidence. Alternatively, the difference in confidence between agency conditions might not stem from the choices per se, but from information accessed via those choices. In observation trials, the observed choice did not always align with the choice the participant would have made, potentially reducing confidence-particularly when the participant would have chosen the alternative deck.


EXPERIMENT 3
In order to further disambiguate whether higher confidence in the only choice condition was driven by choice agency or rather by information access, we designed a full information variant of the task, where both chosen and unchosen reward values were revealed during outcome feedback ( 
Figure 3A)
. The only other difference from Experiment 2 was increasing payoff variability: standard deviations of both decks were raised from 15 to 20. This change was introduced in order to counteract the decrease in overall task difficulty derived from receiving twice as much outcome information per trial. With this new full information design, participants would not experience the situation of not accessing their desired information. A reward effect (lower confidence for low reward blocks) being present again may support the information access hypothesis ( 
Figure 3B
). Still finding lower confidence for observation + choice than for only choice blocks would support the choice agency hypothesis, suggesting our previous agency effect had indeed a component related to choices.  


Procedure
Experiment 3 primarily differed from Experiment 2 in that, after both own and observed choices, reward feedback was provided for both the chosen and non-chosen deck cards. Both cards were revealed, displaying their numeric reward values (in points) and colored green or red according to the positive or negative valence of the feedback. To help participants identify their chosen option more clearly, the corresponding card was outlined in white. As in the previous experiments, only the reward for the chosen option in choice trials was eligible for contribution toward the final payoff.
Providing full reward information would presumably facilitate a more accurate and faster estimation of each deck's value, which could lead to more frequent choices of the high value deck and higher deck judgment accuracy. To mitigate potential ceiling effects in these variables, the task difficulty was increased by raising the standard deviation of the Gaussian distribution used to generate rewards for the decks. The standard deviation was increased from 15 (used previously) to 20.
Minor adjustments were made to the instructions and practice blocks to align them with the full information manipulation. All other elements of the experiment remained as in Experiment 2, including the basic trial structure, across-block manipulated variables, confidence ratings, randomization and counterbalancing, the number of blocks and trials, and the payoff scheme.


Behavioral Models
The full feedback design in Experiment 3 led to slight modifications in the dependent and independent variables used in our LMMs. In Experiments 1 and 2, the high value deck was used as a reference for analyzing deck choices and deck judgment accuracy, even when this deck could occasionally have lower experienced payoffs due to sampling variability. This approach allowed for defining an a priori best deck, even if one of the options had not yet been sampled. However, the full feedback design alleviates this issue, as both deck values can be estimated from the first choice onward. This also renders exploration unnecessary, as the deck with the highest experienced payoff should always be chosen. Consequently, instead of using choices of the high value deck as a dependent variable, we examined choices of what we call the "best deck so far". To compute this, we excluded the first trial of each block, where choices could not yet be informed by that block's reward history. Similarly, deck judgment accuracy was calculated by determining whether participants' judgments aligned with the half of the scale corresponding to the best deck so far. Our third dependent variable, absolute confidence, remained unchanged, as it is unsigned. In terms of predictors, in addition to reward condition, agency condition, and trial number, the fixed effects in our models included the difference in mean reward between the best deck so far and the other deck. This variable allowed us to assess whether differences in choices and confidence across conditions extended beyond variations in reward balance between decks. Like trial number, this predictor was mean-centered.
The specifications of our models can be found below. Note that when predicting deck judgment accuracy, convergence issues prevented us from running a full model, and even a first simplified model without interactions, so we ran two different models, one with reward condition as predictor (M3. 


Results
Following the previous approach, we built mixed-effects models predicting choices (M3.1), deck judgment accuracy (M3.2.1 and M3.2.2) and absolute confidence (M3.3). Importantly, as explained before, the full information design made us redefine the choice and judgment accuracy measures to be conditioned on the best deck so far, instead of best a priori (high value) deck.
Choices of the best deck so far ( 
Figure 3C
) were unaffected by reward (p = .31), agency (p = .28), or their interaction (p = .40). Deck judgment accuracy ( 
Figure 3D
) exhibited a nonsignificant trend towards higher values in the choice-only condition (χ 2 (7), 3.69, p < .06), but was unaffected by reward (p = .64). Most interestingly for our hypotheses, absolute confidence ( 
Figure 3E
) was positively associated with both reward (F(1,45.13), 74.84, p < .001) and agency (F(1, 44.93), 6.72, p = .01), but not their interaction (p = .20). Trial number positively predicted choice accuracy (χ 2 (12), 4.82, p = .03) and absolute confidence (F(1, 5764.08), 644.95, p < .001), but not deck judgment accuracy (reward model: p = .28; agency model: p = .27). Finally, our newly incorporated predictor had a significant effect on all three measures: as the difference in average reward between best and worst decks so far increased, best deck choices (χ 2 (12), 821.87, p < .001), deck judgment accuracy (reward model: χ 2 (7), 519.44, p < .001; agency model: χ 2 (7), 522.31, p < .001) and absolute confidence (F(1, 5828.64), 1315.80, p < .001) increased.


Discussion
Experiment 3 demonstrates that the agency effect observed previously remains significant even when information access is controlled by providing full reward feedback for both alternatives on each trial. While we cannot entirely rule out the possibility that the agency effect in earlier experiments was partly attributable to observation trials preventing participants from accessing desired information, our findings establish that the agency effect persists in the absence of this information access limitation.
We also found that full feedback eliminated differences in performance between high and low reward conditions. This could be attributed to ceiling effects in choices and deck judgment accuracy, despite our efforts to increase task difficulty. 
Figures 3C and 3D
 illustrate that some participants approached or reached maximum performance under certain conditions, which may have obscured any previously observed differences in accuracy. Nonetheless, our results suggest that choice agency independently influences absolute confidence beyond its effect on choices.
Finally, although non-significant, we observed a trend suggesting that participants identified the best deck more accurately in only choice blocks. Given the full feedback design, this effect cannot be attributed to better exploration during choice trials. Instead, it may reflect improved encoding of reward values in trials where participants made their own choices, again potentially driven by increased attention during these trials.


GENERAL DISCUSSION
Experiencing the outcomes of chosen alternatives should enhance confidence in knowing which of these alternatives is associated with better reward. However, here we found such confidence to be lower in situations where learning occurred primarily through observing another agent's choices rather than through one's own. In Experiment 1, we showed that observational learning increased in contexts with frequent losses, but the losses increasing observation also reduced confidence compared to contexts with no losses and less observation. To dig deeper into whether reduced confidence had been produced by losses or by more observation, we ran Experiment 2, where we independently manipulated reward and choice agency. There, both factors demonstrated to influence confidence. Experiment 3 confirmed these effects even when full feedback was provided for both chosen and nonchosen alternatives. Together, our findings highlight two factors common in situations with frequent observational learning that negatively impact confidence: the presence of losses, which often increase observation, and a reduced number of self-made choices.
The negative effect of losses on confidence aligns with prior research showing that losses lower confidence while gains increase it, in both perceptual 
(Giardini et al., 2008;
Lebreton et al., 2018;
Hoven et al., 2022)
 and reinforcement learning 
(Lebreton et al., 2019;
Ting et al., 2020)
 decision making. In the latter domain, a recent computational model 
(Salem-Garcia et al., 2023)
 relates such effects to outcome context-dependency during value learning. According to this account, confidence would be biased by experienced outcomes being reframed relative to the reward expected in a context, which would be lower in situations where alternatives deliver negative rather than positive rewards. Compared to these previous studies, our low reward conditions show that reduced confidence can also appear in contexts where different alternatives give average rewards of opposite valence (positive vs negative). This kind of situations, common in real life, capture what could motivate a transition from initial, loss-avoiding observation into reward-seeking choices.
The second effect we identified was agency-based: even in situations with no losses, confidence was lower when participants observed more than when they made all their choices. This difference could be underlied by different factors. Confidence may have tracked the better attention 
(Truong et al., 2017)
, information processing 
(Falbén et al., 2020)
 or memory retrieval (Ben Yehuda, 2019) that has been found for self-related stimuli and outcomes obtained by our own actions. And although our data did not reflect enhanced processing through better choices in only choice conditions, the analyses reported in Supplementary Material 2 seem to hint at different processing, with agency determining the weight outcome information had on confidence. Specifically, in Experiment 3 we saw confidence to be most affected by reward information coming from chosen decks, as opposed to non-chosen decks in choice trials and any deck in observation trials. The fact that this was only significant in high reward conditions, though, suggests an interaction between agency and reward. Agency could also have affected confidence via enhanced affective states and motivation, as people feel more/less confident when these states are positive/negative 
(Jönsson et al., 2005;
Ifcher & Zarghamee, 2014;
Koellinger & Treffers, 2015;
Culot et al., 2021)
. Moreover, affect 
(Kaiser et al., 2021;
Leotti et al., 2010)
 and motivation 
(Eitam et al., 2013;
Karsh & Eitam, 2015)
 grow positively with the feeling of agency, with motivation in particular increasing when agency gives the possibility to influence the environment. In our study, agency could also be linked to motivation through more opportunities to win reward in only choice conditions, as the rewards picked for final payoff came only from choice trials. Another possible affective driver is the need to feel good about one's own choices. Accordingly, increased confidence after making a choice could be a way to reinforce self-consistency, similarly as it happens with post-choice valuation 
(Brehm, 1956;
Sharot et al., 2010;
Egan et al., 2010;
Fujiwara et al., 2013)
. A related choice-induced factor could be confirmation bias, believed to sometimes be behind overconfidence 
(Salem-Garcia et al., 2023)
, and which is only present for information derived from one's own choices 
(Chambon et al., 2020)
. However, note that confirmation bias has also been shown to be caused by high confidence (Rollwage et al., 2020) rather than to cause it, providing evidence for reversed causality. Whatever the origin of our agency effect is, there are some accounts that cannot fully explain it. First, some could attribute lower confidence to participants, while observing, not always accessing the outcome information corresponding to the choice they would have made. However, the agency effect surviving in Experiment 3, where outcome feedback was given for both alternatives, rules that out as the sole explanation. Second, since increased confidence has been found for voluntary motor actions as opposed to passive motor actions 
(Charles et al., 2020)
, or for motor actions as opposed to no actions 
(Filevich et al., 2020)
, one could think the agency effect can be reduced to a motor effect. Unlike in those studies, though, our tasks required participants to still make an action, in form of a key press, to reveal the observee's choice. The fact that despite matched actions between observation and choice trials we still found more own choices being followed by greater confidence suggests that our agency effect is not simply of motor origin.
When attempting to foster observation in Experiment 1, featuring experienced observees was far less successful than introducing the presence of losses. Participants likely prioritized obtaining immediate rewards over the potential benefits of learning from a more experienced agent. Including more trials per block or featuring more than two choice options may have made initial observation of experienced observees look like a better investment. Leveraging observee experience could have involved straightforward choice imitation, or more sophisticated processes that involve inferring the observee's goals and mental states, what may end up shaping the observer's values 
(Burke et al., 2010;
Najar et al., 2020;
Charpentier et al., 2020)
. However, that would probably require understanding the observee's strategy and/or choice quality. Participants may not have had enough exposure to the observee's choices to do that, despite the initial training session featuring two full blocks of observation.
Our experimental manipulations influenced not only absolute confidence but also deck choices and judgment accuracy. Compared to high reward blocks, low reward blocks led to more frequent choices of the high value deck (Experiments 1 and 2) and greater deck judgment accuracy (Experiment 1), while ceiling effects may have masked similar outcomes in Experiment 3. Previous studies suggest that enhanced on-task attention in the presence of losses might drive better decision-making in such contexts 
(Yechiam & Hochman, 2013a
, 2013b
. Whatever the cause may be, it is remarkable that, despite improved performance in loss-heavy conditions, participants still reported lower confidence. Beyond reward effects, manipulating the presence of observation trials also impacted deck judgment accuracy, though not deck choices. In Experiments 2 and 3, deck judgment accuracy tended to be higher for only choice blocks. While these effects were modest, they align with studies finding enhanced attention 
(Truong et al., 2017)
 and information processing 
(Falbén et al., 2020)
 for self-related stimuli, and where obtaining an outcome by performing an action helps remembering that outcome (Ben Yehuda, 2019).
In Experiment 1, we showed that observation increased in the presence of losses and decreased as participants learned which alternatives yielded better outcomes. However, lossavoidance and learning are likely not the only factors influencing the balance between observing and choosing. Section 3 of the supplementary material reveals that, within low reward blocks, decisions to observe (compared to choosing) were associated with smaller differences in experienced rewards between decks and lower confidence in the preceding trial. Value difference between alternatives (De 
Martino et al., 2013;
Lebreton et al., 2015)
 and confidence 
(Boldt et al., 2019)
 have been previously identified as determinants of value-based decisions. However, since value-based confidence seems to be estimated from value differences 
(De Martino et al., 2013)
, their effects are likely interdependent, making it unclear if confidence separately drives observation decisions. In any case, both variables being predictors only in low reward blocks suggests that participants used observation mainly as a strategy when they were uncertain of which deck could penalize them if chosen.
Confidence was often dissociated from deck choices and deck choice accuracy within participants across conditions, but our results section did not relate these three variables across participants. Our analyses in section 4 of the supplementary material show that participants making more high-value deck choices also tended to have better deck judgment accuracy. However, neither better choices nor greater judgment accuracy correlated positively with absolute confidence; in fact, there was sometimes a negative trend. This suggests that the typical positive relationship between confidence and performance was disrupted here by biases. Since losses had the largest impact on confidence in our within-participant analyses, we computed a measure of loss-derived confidence bias, defined as a greater positive difference in confidence between high and low reward blocks. Across participants, those with stronger loss-derived confidence bias tended to report higher overall confidence but showed lower deck judgment accuracy. This implies that while loss-driven bias determined overall confidence ratings, participants with better insight into the best deck experienced less bias.
Although the findings summarized in the previous paragraph highlight biases in confidence, they do not speak of overconfidence as traditionally defined-confidence exceeding objective performance. Prior evidence 
(Lebreton et al., 2019;
Ting et al., 2020;
Salem-Garcia et al., 2023)
 suggests that individuals in contexts involving personal choices and positive rewards often display overconfidence. Losses and non-owned actions would then reduce this overconfidence, thus ameliorating the bias. Another possibility is that losses and less choices do not reduce but exacerbate bias, yet in the opposite direction: making people underconfident. Surprisingly, the analyses reported in Supplementary Material 5 seem to support this last hypothesis. Moreover, in Experiment 3 underconfidence was the norm across all conditions. The reason why our data departs from the often-found baseline overconfidence, though, is still to be determined.
While our results contributed to identifying different factors that may lead to reduced confidence while learning through observation, they also formulate some questions that warrant further investigation. A natural extension of this research would be to develop a computational model that explains the mechanisms by which reward valence and agency influence confidence. This could build on existing frameworks, such as the reinforcement learning model developed by 
Salem-Garcia et al. (2023)
. Another promising avenue would be to revisit our unsuccessful attempt to manipulate observation by varying observee experience. We could examine how providing more explicit information on observee characteristics, such as skill level or strategy, affects observers-not only in terms of engaging in observation, but also in changing their own confidence in the alternatives' value. As a final idea, the study of metacognitive representations could further advanced by incorporating tasks where observers assess both their own confidence and that of the observees. This would allow us to examine whether different information or biases shape confidence estimates about oneself and others.
Figure 1 .
1
Experiment 1, design and results. A. Task design.


M1.2.: high_value_deck_chosen ~ reward_condition * observee_experience_condition + trial_number + ((reward_condition + observee_experience_condition) | participant_id) M1.3.: deck_judgment_accuracy ~ reward_condition * observee_experience_condition + trial_number + ((reward_condition + observee_experience_condition) | participant_id) M1.4.: absolute_confidence ~ reward_condition * observee_experience_condition + trial_number + ((reward_condition + observee_experience_condition) | participant_id)


Figure 2 .
2
Experiment 2, design and results. A. Task design.


M2. 1
1
: high_value_deck_chosen ~ reward_condition * choice_agency_condition + trial_number + ((reward_condition + choice_agency_condition) | participant_id) M2.2: deck_judgment_accuracy ~ reward_condition * choice_agency_condition + trial_number + ((reward_condition + choice_agency_condition) | participant_id) M2.3: absolute_confidence ~ reward_condition * choice_agency_condition + trial_number + ((reward_condition + choice_agency_condition) | participant_id)


Figure 3 .
3
Experiment 3, design and results. A. Task design. The left side outlines the sequence of a trial, which followed the structure of Experiment 2, except for reward feedback being always shown for the chosen and non-chosen deck, with the chosen deck being outlined.














Imitation-theory and experimental evidence




J
Apesteguia






S
Huck






J
Oechssler








Journal of Economic Theory




136


1
















Fitting linear mixed-effects models Usinglme4




D
Bates






M
Mächler






B
Bolker






S
Walker




10.18637/jss.v067.i01








Journal of Statistical Software




67


1














Agency and confidence: On the function of metacognition in action (Doctoral dissertation




M
Ben Yehuda












University of Oxford












Confidence modulates exploration and exploitation in value-based learning




A
Boldt






C
Blundell






B
Martino








Neuroscience of consciousness




2019


1


4














Postdecision changes in the desirability of alternatives




J
W
Brehm








The Journal of Abnormal and Social Psychology




52


3


384














Neural mechanisms of observational learning




C
J
Burke






P
N
Tobler






M
Baddeley






W
Schultz








Proceedings of the National Academy of Sciences




107


32
















Information about action outcomes differentially affects learning from self-determined versus imposed choices




V
Chambon






H
Théro






M
Vidal






H
Vandendriessche






P
Haggard






S
Palminteri








Nature Human Behaviour




4


10
















Rational herds: Economic models of social learning




C
Chamley








Cambridge University Press












Evidence for metacognitive bias in perception of voluntary action




L
Charles






C
Chardin






P
Haggard








Cognition




104041














A neuro-computational account of arbitration between choice imitation and goal emulation during human observational learning




C
J
Charpentier






K
Iigaya






J
P
Doherty








Neuron




106


4
















Species difference in adaptive use of public information in sticklebacks




I
Coolen






Y
V
Bergen






R
L
Day






K
N
Laland








Proceedings of the Royal Society of London. Series B: Biological Sciences


the Royal Society of London. Series B: Biological Sciences






270














The influence of sad mood induction on task performance and metacognition




C
Culot






C
Fantini-Hauwel






W
Gevers








Quarterly Journal of Experimental Psychology




74


9


















J
R
De Leeuw




jsPsych: A JavaScript library for creating behavioral experiments in a Web browser. Behavior research methods






47














Confidence in value-based choice




De
Martino






B
Fleming






S
M
Garrett






N
Dolan






R
J








Nature neuroscience




16


1
















Social and asocial cues about new food: Cue reliability influences intake in rats




G
Dewar








Animal Learning & Behavior




32


1
















Motivation from control




B
Eitam






P
M
Kennedy






E
Higgins








Experimental brain research




229
















Choice-induced preferences in the absence of choice: Evidence from a blind two choice paradigm with young children and capuchin monkeys




L
C
Egan






P
Bloom






L
R
Santos








Journal of Experimental Social Psychology




46


1
















Self-relevance enhances evidence gathering during decision-making




J
K
Falbén






M
Golubickis






S
Tamulaitis






S
Caughey






D
Tsamadi






L
M
Persson






S
L
Svensson






A
Sahraie






C
N
Macrae








Acta Psychologica




209


103122














Response-related signals increase confidence but not metacognitive performance




E
Filevich






C
Koß






N
Faivre








Eneuro




7


3














Value of freedom to choose encoded by the human brain




J
Fujiwara






N
Usui






S
Q
Park






T
Williams






T
Iijima






M
Taira






.
.
Tobler






P
N








Journal of neurophysiology




110


8
















Strategies for social learning: testing predictions from formal theory




B
G
Galef








Advances in the Study of Behavior






39














Sense of agency




P
Haggard






V
Chambon








Current biology




22


10
















The experience of agency: Feelings, judgments, and responsibility




P
Haggard






M
Tsakiris








Current Directions in Psychological Science




18


4
















Motivational signals disrupt metacognitive signals in the human ventromedial prefrontal cortex




M
Hoven






G
Brunner






N
S
De Boer






A
E
Goudriaan






D
Denys






R
J
Van Holst






.
.
Lebreton






M








Communications Biology




5


1


244














Affect and overconfidence: A laboratory investigation




J
Ifcher






H
Zarghamee








Psychology, and Economics




7


3


125








Journal of Neuroscience








Odor emotionality affects the confidence in odor naming. Chemical senses




F
U
Jönsson






H
Olsson






M
J
Olsson








30














The interplay between affective processing and sense of agency during action regulation: a review




J
Kaiser






M
Buciuman






S
Gigl






A
Gentsch






S
Schütz-Bosbach








Frontiers in Psychology




12


716220














The role of conformity in foraging when personal and social information conflict




R
L
Kendal






I
Coolen






K
N
Laland








Behavioral Ecology




15


2
















Motivation from Control. The sense of agency




N
Karsh






B
Eitam




















Joy leads to overconfidence, and a simple countermeasure




P
Koellinger






T
Treffers








PloS one




10


12


143263














lmerTest package: tests in linear mixed effects models




A
Kuznetsova






P
B
Brockhoff






R
H
Christensen








Journal of statistical software




82
















Social learning strategies




K
N
Laland








Animal Learning & Behavior




32


1
















Automatic integration of confidence in the brain valuation signal




M
Lebreton






R
Abitbol






J
Daunizeau






M
Pessiglione








Nature neuroscience




18


8
















Contextual influence on confidence judgments in human reinforcement learning




M
Lebreton






K
Bacily






S
Palminteri






J
B
Engelmann








PLoS computational biology




15


4


1006973














Born to choose: The origins and value of the need for control




L
A
Leotti






S
S
Iyengar






K
N
Ochsner








Trends in cognitive sciences




14


10
















The actions of others act as a pseudo-reward to drive imitation in the context of social reinforcement learning




A
Najar






E
Bonnet






B
Bahrami






S
Palminteri








PLoS biology




18


12


3001028














The value of confidence: Confidence prediction errors drive value-based learning in the absence of external feedback




L
E
Ptasczynski






I
Steinecker






P
Sterzer






M
Guggenmos








PLOS Computational Biology




18


10


1010580


















L
Rendell






R
Boyd






D
Cownden






M
Enquist






K
Eriksson






M
W
Feldman














Why copy others? Insights from the social learning strategies tournament




K
N
Laland








Science




328


5975
















Linking confidence biases to reinforcement-learning processes




N
Salem-Garcia






S
Palminteri






M
Lebreton








Psychological Review




130


4


1017














Demonstrator skill modulates observational aversive learning




I
Selbing






B
Lindström






A
Olsson








Cognition




133


1
















Do decisions shape preference? Evidence from blind choice




T
Sharot






C
M
Velasquez






R
J
Dolan








Psychological science




21


9
















_afex: Analysis of Factorial Experiments




H
Singmann






B
Bolker






J
Westfall






F
Aust






M
Ben-Shachar














R package version 1.3-0








Robust valence-induced biases on motor response and confidence in human reinforcement learning




C.-C
Ting






S
Palminteri






J
B
Engelmann






M
Lebreton








Cognitive, Affective, & Behavioral Neuroscience
















I saw mine first: A prior-entry effect for newly acquired ownership




G
Truong






K
H
Roberts






R
M
Todd








Journal of Experimental Psychology: Human Perception and Performance




43


1
















Social learning strategies and predation risk: minnows copy only when using private information would be costly




M
M
Webster






K
N
Laland








Proceedings of the Royal Society B: Biological Sciences




275
















Losses as modulators of attention: review and analysis of the unique effects of losses over gains




E
Yechiam






G
Hochman








Psychological bulletin




139


2


497














Loss-aversion or loss-attention: The impact of losses on cognitive performance




E
Yechiam






G
Hochman








Cognitive Psychology




66


2
















Within and Cross-Domain Effects of Choice-Induced Bias




W
Zajkowski






J
Zhang



















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]