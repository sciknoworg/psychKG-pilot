You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
In a complex world with endless possibilities to choose from, the questions of which and how much information to search for is pivotal for making efficient decisions. Seemingly, humans master this challenge by limiting their information search in an adaptive manner, thereby finding a suitable tradeoff between the desire to make well-informed decisions and the need to limit invested effort. Here, we present a hierarchical Bayesian cognitive model of adaptive information search for decisions between options that are characterized by multiple attributes. The model predicts the order in which people distribute their attention, when they terminate their search and valuation processes, and the choice they make. It accounts for many empirical findings reported in previous work as well as for a series of search dynamics and choice patterns that we tested in a newly designed and preregistered eye-tracking experiment.


Strategies of Integration, Integration of Strategies
In multi-attribute choice, such as choosing between different smartphones based on their attributes (e.g., price, brand, screen size, battery capacity), the underlying problem that people face is to integrate multiple pieces of information to identify and select an option that meets their goals best. Traditionally, it has been proposed that humans employ a variety of strategies to make such judgements and decisions in an adaptive manner 
(Gigerenzer et al., 1999;
Payne et al., 1988)
. These strategies range from exhaustive (or compensatory) strategies that integrate all attributes or cues and weight them by their importance or validity, often referred to as a weighted additive strategy (WADD), to frugal (or non-compensatory) strategies that focus on the most important and valid information, often referred to as a lexicographic or take-the-best heuristic (TTB). When selecting a strategy, the adaptive decision maker is assumed to take the characteristics of the environment into account, for instance, by considering the dispersion and redundancy of information 
(Payne et al., 1988;
Todd & Gigerenzer, 2007)
 or by learning about a strategy's adaptiveness through reinforcement 
(Gluth et al., 2014;
Rieskamp & Otto, 2006)
.
However, the need to assume qualitatively different strategies for multi-attribute decisions has been questioned 
(Newell, 2005)
. Specifically, it has been argued that strategies such as WADD and TTB could be re-conceptualized as extreme cases of a single choice architecture that is based on the principle of evidence accumulation (M. D. 
Lee & Cummins, 2004)
. Models of evidence accumulation, also known as Sequential Sampling Models (SSM), assume the decision maker to sample information over time and to make a choice as soon as sufficient evidence has been accumulated and a decision threshold is crossed 
(Forstmann et al., 2016)
. SSM have been applied in various fields, including recognition memory, perceptual decision making, value-based decisions, decisions under risk, and decision neuroscience 
(Busemeyer & Townsend, 1993;
Clithero, 2018;
Gold & Shadlen, 2007;
Heekeren et al., 2008;
Ratcliff, 1978;
Ratcliff & Rouder, 1998)
. Notably, research on decisions with multiple attributes and multiple (i.e., more than two) options has also inspired the development of several variants of SSM. These models have partly been developed to explain how the context, that is the presence of specific options, change the evaluations of other options 
(Busemeyer et al., 2019
; see also "General Discussion"). According to the SSM framework, it has been proposed that people increase their decision threshold to make more accurate choices by accumulating more evidence leading to slower decisions, which mimics WADD-like behavior. Alternatively people lower their decision threshold to make faster but possibly less accurate decisions, thereby mimicking TTB-like decisions (M. D. 
Lee & Cummins, 2004;
Newell, 2005;
van Ravenzwaaij et al., 2014)
. Recently, it has been argued that a resource-rational analysis that takes the cost of sampling information into account 
(Krueger et al., 2024)
 can explain how different strategies to search for and integrate multiple pieces of information emerge.


Attention, Search, and Valuation
How we distribute our attention across different options, attributes, and cues, and how this allocation of attention may influence our decisions and inferences has been studied intensively over the last decades. By now, there is ample evidence for a complex, dynamic, and bi-directional interplay of attention and decision making. One prominent line of research focusses on the influence of attention on behavior, finding that options that receive more attention 1 during a decision process are more likely to be chosen. This notion is supported by a wealth of eye-tracking data across various choice domains, including value-based, perceptual, risky, and social decisions 
(Fiedler & Glöckner, 2012;
Gluth et al., 2018;
Krajbich et al., 2010;
Krajbich, 2019;
Pärnamets et al., 2015;
Shimojo et al., 2003;
Tavares et al., 2017;
Ting & Gluth, 2024)
. Importantly, the positive association of choice probability and gaze time still holds, even if participants are asked to select the option they do not prefer 
(Kovach et al., 2014;
Sepulveda et al., 2020)
. This finding suggests that the congruency between accumulated evidence and the current task goal modulates any putative influence of attention on choice (De 
Martino & Cortese, 2023;
Frömer & Shenhav, 2022)
.
A second branch of research investigates how attention is allocated when making judgments and decisions 2 . It has been emphasized that attention is critical to sample information by orienting the decision maker towards relevant attributes and cues as well as towards likely choice candidates 
(Glaholt & Reingold, 2011;
Gluth et al., 2020;
Orquin & Mueller Loose, 2013;
Russo & Leclerc, 1994;
Ting & Gluth, 2024;
Yarbus, 1967)
. First of all, people attend to (more) relevant information earlier on and more often, and they may ignore a substantial amount of (less relevant) information for the sake of responding fast and efficiently 
1
 Note that we refer to a very specific form of attention, that is, overt visual attention, which is usually measured with eye tracking and quantified by the amount of time a stimulus is fixated (i.e., gaze time). A related method is mouse tracking that allows identifying which information is sampled and for how long 
(Payne et al., 1993;
Willemsen & Johnson, 2011)
. For a critical discussion of this narrow definition of attention, see 
Mormann and Russo (2021)
. 
2
 In the following, we will not distinguish between judgements (or inferences), in which a state of the world is inferred (e.g., weather prediction), and preferential choices, in which a person seeks to select an option that is most consistent with their preferences (e.g., snack choice). In principle, making judgements based on a set of cues with different predictive validities and making decisions based on a set of attributes with different weights can be distinguished, as only judgements can be said to be objectively correct or incorrect. However, the problem of integrating information to give a (discrete) response is essentially the same across judgements and decisions, and we thus consider the relevant literature of both. Thus, our theory applies to multi-cue judgements just as it applies to multi-attribute decisions. 
(Jovancevic-Misic & Hayhoe, 2009;
Krueger et al., 2024;
Meißner et al., 2016;
Reutskaja et al., 2011;
Rieskamp & Hoffrage, 2008;
X. Yang & Krajbich, 2023;
Yarbus, 1967)
. Furthermore, people are more likely to sample more information from an option (instead of switching to another alternative), if the initially sampled information suggests it to be a good choice candidate 
(Jekel et al., 2018)
. First reported for multi-cue inferences, this Attraction Search Effect (ASE) has also been found in multi-attribute decisions 
(Kaanders et al., 2021;
Scharf et al., 2019;
H. Wang et al., 2022)
, and it is even observed in search behavior of non-human primates 
(Hunt et al., 2018)
. Another critical feature of search order is the distinction of optionwise vs. attribute-wise search, that is, the extent to which transitions are made between different attributes within a single option vs. within a single attribute across different options 
(Payne, 1976
). In the traditional view of adaptive strategy selection (see previous section), these two search patterns are thought to reflect different choice strategies, with option-wise search being associated with more holistic and compensatory strategies such as WADD, and attribute-wise search being linked to more dimensional and non-compensatory strategies such as TTB 
(Payne et al., 1988;
Russo & Dosher, 1983)
. Consistently, a recent study found a strong negative correlation between the Payne Index 
(Payne, 1976)
, which quantifies the amount of option-wise relative to attribute-wise search, and the difference of attribute weights (X. 
Yang & Krajbich, 2023)
. In other words, participants who mostly focused on one attribute (relative to another) exhibited a more attribute-wise search, whereas participants who weighted attributes more equally searched in a more option-wise manner. An open question is whether variability in search patterns could also be captured within a single decision architecture, rather than necessitating the assumption of distinct strategies.


Modeling the Interplay of Attention and Choice
The empirical work on the different roles of attention in decision making has been accompanied by the development of both descriptive and normative models of this interplay.
The attentional Drift Diffusion Model (aDDM) extends the DDM 
(Ratcliff, 1978)
, the predominant SSM in cognitive science and decision neuroscience, by implementing an influence of attention on evidence accumulation 
(Krajbich et al., 2010;
Krajbich & Rangel, 2011)
. Specifically, the aDDM assumes that choice options that are not attended at a given time exert a reduced influence on the accumulation of evidence. In the (standard) case of choosing the most preferred option, the model is thus able to account for the positive correlation of an option's gaze time and its choice probability. Originally, the aDDM has been developed and tested for simple value-based choice settings, such as choosing between different food options.
Here, the model assumes that each choice option is represented by a single, integrated subjective value that needs to be sampled 
(Levy & Glimcher, 2012;
Polanía et al., 2019)
. More recently, however, the aDDM has been extended to multi-attribute decision problems 
(Fisher, 2021;
X. Yang & Krajbich, 2023)
. The central extension is the assumption of an additional parameter that models the reduced influence of unattended attributes (over and above the reduced influence of unattended options). The extension proposed by 
Yang and Krajbich (2022)
 further allows different attributes to impact evidence accumulation with different strengths (i.e., attribute weights).
Importantly, the aDDM focusses on the influence of attention on preference formation, but it does not explicitly predict how the decision maker allocates attention to the different attributes or options. An exemption is the extended aDDM proposed by 
Gluth et al. (2020)
, according to which the probability to fixate an option is a function of the accumulated evidence for that option relative to the accumulated evidence for the alternatives (see also J.-S. 
Wang et al., 2024)
. This added feature leads to a Gaze Cascade Effect 
(Shimojo et al., 2003)
, that is, a reciprocal excitation of attention and preference, and it allows the extended aDDM to account for the finding that over the time of making a decision, participants narrow down their search on the most likely choice candidates and come to disregard very unattractive options 
(Gluth et al., 2020)
. Relatedly, the iCodes model 
(Jekel et al., 2018)
 has been developed as an extension of the Parallel Constraint Satisfaction model, a neural network model for probabilistic inferences that assumes spreading activation as its core mechanism 
(Glöckner et al., 2014)
, to accommodate the ASE. The model assumes that the probability to sample an option's cue is a function of the cue's activation in the network. And because a cue's activation is positively affected by activation of other cues of the same option, the model predicts the ASE (i.e., the increased probability to keep sampling from promising choice candidates).
In addition to these descriptive accounts, there are several normative theories of how attention should be allocated when making decisions. Based on the assumptions that humans have limited cognitive capacities and that sampling information is costly 
(Lieder & Griffiths, 2020;
Simon, 1955;
Sims, 2003)
, the general rationale is that humans should allocate attention in an efficient manner to make well-informed decisions while at the same time limiting their invested resources 
(Callaway et al., 2021;
Jang et al., 2021;
Krueger et al., 2024;
Sepulveda et al., 2020)
. For example, Callaway et al. (2021) assume a Bayesian updating process, according to which the rational agent allocates attention to options for sampling from their underlying value distributions and updating the corresponding belief distributions. Because sampling is costly, the optimal policy is to maximize the probability of identifying (and choosing) the option with the highest value while taking sampling costs into account. Among other predictions, the model can reproduce the positive correlation of gaze time and choice probability that has inspired the development of the aDDM 3 . This is because a rational agent will cease sampling from options that are unlikely to be selected in light of some initially taken samples. An alternative, slightly more descriptive model that also assumes a Bayesian belief updating process accounts for the gaze-choice correlation by assuming that people are averse to uncertainty and thus prefer options that they have sampled more 
(Li & Ma, 2021)
. While most of these (quasi-)normative accounts model comparatively simple decisions that are based on single (integrated) value representations 
(Callaway et al., 2021;
Jang et al., 2021;
Sepulveda et al., 2020)
, 
Krueger et al. (2024)
 have developed a resource-rational model for multi-attribute, risky decision problems (see also 
Callaway et al., 2023)
. Interestingly, their analysis suggests that search patterns akin to the strategies WADD and TTB can be part of the resource-rational model's repertoire. Additionally, the resource-rational model sometimes behaves very similar to the satisficing heuristic 
(Simon, 1955)
, according to which options are chosen if their attributes meet some (absolute) cutoff criterion.
Notably, the core challenge for these normative models is to specify the value of allocating attention in future steps to determine whether and where to look next. Unless the choice problem is very simple and restricted 
(Gittins, 1979;
Weitzman, 1979)
, complete solutions of this allocation problem are often intractable, and simplified assumptions need to be made. And even if these approximations may be sufficient to derive predictions that are reasonably close to the complete solution, it appears problematic to assume that humans can perform these (complete or approximate) solutions within the few seconds in which they make many of their decisions (moreover, performing these computations would itself be cognitively very costly and thus possibly not resource-rational). Consequently, simpler variants of Bayesian belief updating models have been proposed to predict information search. One variant for binary decisions assumes that search is guided by the relative uncertainty of one option relative to the other, formalized as the ratio of the standard deviations of the options' posterior value distributions 
(Song et al., 2019)
. Another theory, the Directed Cognition model by 
Gabaix et al. (2006)
, proposes a myopic search rule, according to which people think only one step ahead to determine whether to choose or to continue sampling information and, if continuing, where to allocate attention next (see also 
Busemeyer & Rapoport, 1988)
. In a multi-attribute choice task with mouse tracking, the Directed Cognition model predicted the amount of sampling reasonably well 
(Gabaix et al., 2006)
, though it appears to make less accurate predictions than the optimal search model in problems with very limited state spaces such as simple planning scenarios 
(Callaway et al., 2022)
. Notably, the proposal that people plan their search (only) one step ahead has been followed up in extensions and variations of the Directed Cognition model in consumer and marketing research 
(Ursu et al., 2022;
L. Yang et al., 2015;
 for an overview, see 
Wedel et al., 2023)
.
Taken together, various models have been proposed to describe the role of attention in decision making and inferences, but they are either limited in their scope and address only a subset of the rich empirical findings (e.g., the aDDM focuses on the influence of attention on preference formation), or their underlying assumptions are problematic considering the humans' limited cognitive capacities (i.e., rational models of attention allocation). In the following, we will formalize a descriptive process model of information search in multiattribute, multi-alternative choice that accounts for the discussed empirical findings while maintaining a plausible level of computational complexity.


Model Specification
Our theory of Multi-Attribute Search and Choice (MASC) implements a hierarchical Bayesian framework with multiple layers to characterize belief distributions about attribute values that in turn form the building blocks of the belief distributions about option values. The first core assumption of our model is that the decision maker needs to pay attention to an option's attribute to learn about the attribute's value. Following a Bayesian idea, when looking at an attribute, the decision maker essentially draws a sample from the true (but hidden) attribute value with some error and generates a posterior belief about this value 
(Gabaix et al., 2006;
Krueger et al., 2024;
Ursu et al., 2022;
L. Yang et al., 2015)
. Assuming for simplicity that prior and posterior belief distributions are normally distributed, the attribute values are updated as follows:
, , = , , −1 × , , −1 + , , 2 , , , (1a) , , = , , −1 + 1 2 , (1b)
where , , and , , refer to the mean and precision of the belief in attribute j of option i after f samples, respectively, represents the standard deviation of the sampling process, and si,j,f refers to the currently sampled attribute value, which is drawn from a normal distribution with its mean being the true attribute value and its standard deviation being . Before sampling, the prior mean belief , , =0 is 0 (i.e., unbiased), and the prior precision , , =0 is equal to the true attribute precision in the environment 4 . Updating an attribute's belief allows the agent to also update their (normally distributed) belief about the options i's overall value:
, = ∑ , , × =1 , (2a) , 2 = ∑ 2 , , =1 ,
(2b)
where , and , 2 refer to the mean and variance of the value belief of option i after f samples, m is the number of attributes, and is the weight of attribute j, reflecting its relative importance.
The second assumption of our model is that the decision maker chooses an option whenever that option's value is believed to be sufficiently higher than all other options' values.
Technically, this can be implemented by testing whether the overlap of the highest (i.e., i = best) minus all other posterior value distributions is equal or lower than some threshold :
ℎ , : Φ (0, , − , , √ , 2 + , 2 ) ≤ , ≠ ,
(3)
where Φ(0, , ) refers to the value of the CDF of the normal distribution at 0 with mean M and standard deviation SD. The subscript f of the threshold indicates that the threshold might increase over time to ensure that decisions are made at some point, even if there is not much evidence for any option. This is similar to the concept of collapsing bounds in SSM 
(Cisek et al., 2009;
Fudenberg et al., 2018;
Gluth et al., 2012;
Tajima et al., 2016)
, but in case of MASC, the threshold increases rather than collapses to elicit decisions at larger overlaps of the value distributions. Notably, this decision rule effectively implements a relative threshold termination rule, that is, the value of the best option relative to the alternatives (rather than an absolute criterion) is critical for terminating the decision 
(Mullett & Stewart, 2016;
Teodorescu & Usher, 2013
).
The third critical assumption of our model is that the decision maker allocates attention and transitions across pieces of information in an efficient yet not optimal way. More specifically, we assume a myopic search rule, according to which the agent plans only one fixation or sample ahead 
(Busemeyer & Rapoport, 1988;
Gabaix et al., 2006;
Ursu et al., 2022;
L. Yang et al., 2015)
. For each attribute j of each option i, the agent considers how likely sampling from j will lead to i being chosen in the next step:
, , +1 = ∫ ( ℎ + 1 | , , +1 = ) × ( , , +1 = ) +∞ −∞ .
(4)
In essence, Equation 4 states that , , +1 (i.e., the myopic search score of looking next at attribute j of option i) depends on whether sampling the value x from attribute j will result in the choice of i, and on how likely it is that x is sampled (for all possible values of x). In Appendix A, we derive a closed-form solution for this score. After normalization, the myopic search score is then used to determine the next sample probabilistically via the softmax rule:
, , +1 = , , +1 ∑ ∑ , , +1 =1 =1 ,
(5a)
( , , +1 ) = exp ( * , , +1 ) ∑ ∑ exp ( * , , +1 ) =1 =1 ,
(5b)
where nMSi,j is the normalized myopic search score, and  is a free parameter that models the extent to which the search rule governs sampling compared to random sampling behavior (in which case  = 0). Note that the normalization ensures that the influence of the search rule is similar for early and late samples (the probability to elicit a choice with one more fixation is much higher at late compared to early samples; without normalization, search patterns would thus become much more deterministic towards the end of a decision, or in other words, search patterns would be almost random and thus unpredictable at the beginning of a decision).
As simulations further below will demonstrate, this allocation rule is efficient, as it predicts that attributes with higher weights and higher uncertainty are more likely to be sampled, because they can be expected to increase the precision of the value distributions to greater extent (i.e., they are more informative). At the same time, the search rule implies a (not necessarily optimal) preference for sampling the currently most promising choice candidates, because updating them provides the best chance to terminate the decision in the next step. This value-dependency of sampling is consistent with the rich empirical literature on the positive association of attention and choice 
(Krajbich, 2019;
Weilbächer et al., 2021)
 and of dynamic interactions between valuation and attention 
(Gluth et al., 2020;
Jekel et al., 2018;
Sepulveda et al., 2020;
Shimojo et al., 2003)
. 
Figure 1
 illustrates the mechanics of MASC for a specific multi-attribute decision problem at a specific step within the search and choice process.
At a minimum, the model has three free parameters, the variance of the sampling process 2 , the choice threshold , and the search rule's sensitivity parameter . As stated above, it is plausible to assume that the threshold changes (increases) over time to avoid sampling excessively long in case of difficult decisions. For instance, one could assume a linear dependency of the threshold on the sampling number, = =0 + Δ × , in which case  becomes another free parameter (one can also fix the initial threshold =0 and only use Δ as a free parameter, as we do further below). In case of m attributes, there are also m -1 attribute weights to be specified (as we fix the sum of all weights to 1) 5 . Moreover, different attributes might differ in terms of noise, in which case attribute-specific values of the variance parameter 2 could be assumed (e.g., numeric vs. pictorial information; cf. 
Frederick et al., 2014 and
Spektor et al., 2021)
.


Figure 1
Illustration of the Theory of Multi-Attribute Search and Choice 
(MASC)
 Note. MASC is illustrated with a specific example at an early stage of a decision between n = 2 options (smartphones) characterized by m = 3 attributes (display size, battery, memory). Attribute and option values are represented as belief distributions. Attributes can have different weights (i.e., relative importance). The first fixation of the agent is on the second attribute of the first option (battery), which has a high weight. The sample from this fixation suggests a comparatively low attribute value, and the corresponding belief distributions of attribute and option values are updated accordingly. A choice at this point is unlikely, as the posterior value distributions still overlap too much (i.e., the grey-shaded area is too small). Thus, a new fixation is generated. The n-by-m fixation probability matrix Ft+1 is governed by the expectation of which sample from an attribute-option pair may provide decisive evidence. Notably, the model predicts that the agent is more likely to switch to the other option (which currently has higher value), and especially to its battery attribute (which has the highest importance weight). A refixation to the same attribute-option pair is unlikely because the decision maker is more likely to sample yet unseen attributes to reduce uncertainty.
In a nutshell, MASC assumes that people form beliefs about the subjective value of available choice options. These beliefs are updated by sampling information from the different options' attributes, following a myopic search rule that leads to an efficient but not optimal search process. Once the accumulated information provides sufficient confidence that one option is preferable to all others, a decision is made. With these assumptions, MASC shares many assumptions with various extant models in the literature. In brief, the adoption of a Bayesian approach that assumes values to be represented as belief distributions is shared with normative models 
(Jang et al., 2021;
Sims, 2003)
, including the resource-rational analysis approach 
(Callaway et al., 2022;
Krueger et al., 2024)
. The use of a myopic search rule is reminiscent of the Directed Cognition model 
(Gabaix et al., 2006)
 and related models in economics and marketing 
(Ursu et al., 2022;
L. Yang et al., 2015)
. Critically, the combination of those elements (and the termination rule) is unique to our theory, as is the exact specification of the myopic search rule. Furthermore, MASC clearly goes beyond previous accounts that use process-tracing data such as eye movements to inform behavioral model predictions but do not predict the search process itself 
(Glickman et al., 2019;
Gluth et al., 2018;
Molter et al., 2022;
Thomas et al., 2019;
X. Yang & Krajbich, 2023)
. The General Discussion provides a more detailed comparison of MASC with existing accounts and how the models handle the interaction between attention and decision making.


Model Simulations and Experiment
Our proposed computational framework can account for the various interactions between attention and decision making that were outlined in the Introduction, including the positive correlation of attention allocated to an option and its choice probability 
(Gluth et al., 2020;
Krajbich, 2019)
, the positive correlation of an option's value and the attention devoted to it 
(Fiedler & Glöckner, 2012;
Gluth et al., 2020;
Jekel et al., 2018)
, the positive correlation of attention allocated to an attribute and the attribute's weight 
(Rieskamp & Hoffrage, 2008;
X. Yang & Krajbich, 2023)
, and the positive correlation of the dispersion of different attribute weights and the tendency to search in an attribute-wise manner 
(Payne et al., 1988;
X. Yang & Krajbich, 2023)
. To demonstrate the theory's explanatory capacity, we sought to develop an experimental paradigm that allows to establish all these effects, which have only been reported in separate studies so far, and to compare the empirical findings with simulations of the model.
The rationale for designing a novel eye-tracking experiment is based on the recognition thatat least, in its current form -MASC focusses on modeling top-down attention, as it specifies how information search is determined by the desire to make fast and efficient decisions. The theory does not account for the various stimulus-driven and bottom-up drivers of attention, such as position, salience, and size, which are known to have a sizable influence on eye movements 
(Orquin et al., 2021)
, although future extension of the theory are conceivable (see "General Discussion"). Therefore, we sought to develop a new multi-attribute choice task, in which effects of salience and size as well as systematic position effects can be minimized as much as possible.


Method
Preregistration. Prior to data collection, the study was preregistered on the Open Science Framework (OSF) (https://osf.io/xh3tb), using the OSF Preregistration template. We preregistered seven hypotheses regarding behavioral and eye-movement results that MASC predicts:
Choice consistency (H1): The larger the (subjective) value difference between two options, the more consistently the higher-rated option is preferred.


Number of fixations (H2):
The larger the value difference between two options, the fewer fixations are required to decide.


Attention and choice (H3):
There is a positive correlation of the number of fixations on an option and its choice probability.


Value and attention (H4):
There is a positive correlation of value difference and probability of fixation.
Attraction Search Effect (ASE) (H5): If the first-sampled attribute value of an option is better than average, the probability to sample from the same option again is increased.
Weights and attention (H6): More important attributes are more likely to be sampled, especially at the beginning of the decision process.
Weights and Payne Index (H7): There is a negative correlation of the dispersion of attribute weights and the Payne Index, reflecting a more attribute-wise (as compared to optionwise) search pattern 
(Payne, 1976)
.
Preregistration also included exclusion criteria (i.e., incomplete datasets, poor eyetracking quality, too many too fast decisions, decision not predictable above chance by ratings)
as well as a power analysis that was based on simulating MASC (cf. Gluth & Jarecki, 2019).
To inform the power analysis, a pilot study with 20 participants was conducted, and the model parameters were estimated to align MASC's predictions to the pilot data as closely as possible.
Then, the model was simulated with varying number of participants (by resampling from the pilot data and parameter values) to determine how many participants are required to achieve a joint probability of 80% that all seven hypotheses are confirmed. This analysis resulted in a required sample size of 75.
Participants. Following the power analysis, we tested 82 participants, of which 19 did not pass at least one of the preregistered exclusion criteria, resulting in a final sample of n = 63 participants whose data were analyzed (42 female, age: 18-39 years, M = 24.3, SD = 5.1; demographic data of 2 participants not recorded). Of the 19 excluded participants, 12 were excluded because their smartphone decisions could not be predicted by the respective ratings, 5 were excluded because their hotel decisions could not be predicted by the respective ratings, and 2 were excluded due to poor quality eye tracking data. Convenience sampling was used, as participants were recruited via the online recruiting system of the Department of Psychology at the University of Hamburg as well as an online portal that is mostly used by students (of different subjects) from different universities across Hamburg. Participants were required to be at least 18 years old, speak the study language (German), not take drugs, not suffer current physical, psychological, or neurological disorders, and to have never received a diagnosis of schizophrenia or bipolar disorder. Participants gave written informed consent, and the study was approved by the Local Ethics Committee of the Department of Psychology at the University of Hamburg (# 2022_046).
Stimuli and apparatus. Participants were asked to rate and decide between two sets of options: smartphones and hotels. Smartphones were characterized by the three attributes display size, battery capacity, and memory storage. Hotels were characterized by the three attributes distance to beach, room size, and number of stars. To create realistic option sets and to incentivize the task, we identified 30 smartphones and hotels in a restricted price range (between 190 and 450 EUR) that were available online at the time of testing and extracted the relevant attributes. A two-night stay in a double bedroom was used to determine the price of the hotel (and was also used as incentive; see "Procedure" below). Beyond the three attribute values, participants received no further information about the options, such as the smartphones' brand or the hotels' exact locations (they were only described as being in Northern Germany).
Eye movements were recorded using an EyeLink 1000 Plus eye tracker from SR Research (desktop mount) at a sampling rate of 1 kHz. A chin rest was used to stabilize the head. A 24-inch screen with a resolution of 1920 x 1080 pixels and a sampling rate of 144 Hz was positioned at a distance of 92 cm from the chin rest, with the eye tracker in-between. Button presses were made on a mechanical keyboard with <1ms latency. For stimulus presentation, we used the standalone version of PsychoPy3 (version v2022.2.1), which is based on Python. The study was conducted in a darkened room with dimmed artificial light.


Figure 2
Multi-Attribute Rating and Choice Tasks Note. A) Rating task. Participants rated how much they like each option (smartphones, hotels) based on three attributes on a continuous scale from 0 to 10. The position of the attributes changed from trial to trial. B) Choice task. In each trial, participants decided between a blue and a green option. The position of the attributes was slightly shifted from trial to trial as indicated by the dotted lines that indicate the previous positions of three attributes on the next trial (the dotted lines were not displayed in the experiment).
Procedure. After giving informed consent, participants were first informed about the type of options, their attributes, the symbols that would represent the attributes during the tasks, and the range of each attribute. Next, participants were instructed on and asked to perform the rating task. In each trial, they were shown the three attribute symbols (in black) of the smartphone or hotel with the specific attribute values written as (white) text on top of the respective symbol ( 
Figure 2A
). They rated how much they liked the option on a continuous scale from 1 to 10, using the mouse to click on the desired position of the rating scale. After a mouse click on the rating scale, the respective rating was displayed numerically, and the participate was asked to either confirm (by pressing Space) or to change their rating (by pressing Esc). Importantly, the symbols' positions on the screen were not fixed but varied randomly from trial to trial to avoid (attention-induced) systematic position effects (e.g., search patterns in reading direction would favor attributes located in the upper left part of the screen). Ratings of smartphones and hotels were intermixed randomly, and all items were rated twice (in two blocks). Eye movements were not recorded during the rating task. Participants were informed that they took part in a lottery across all participants of the study, from which two participants received a reward (either a smartphone or a hotel stay), one of them from the rating task. In case they were selected as receiving the rating task's reward, two of their ratings were randomly drawn and they received the higher-rated option.
After completion of the rating task, a custom-built algorithm (implemented in Python) was applied to the rating data to create three sets of easy, medium, and difficult trials (40 trials
x 3 difficulty levels x 2 choice sets = 240 trials in total) by selected options according to their rating difference (the average over the two ratings per item was used). Choice sets with a fully dominant option that was better than the alternative option with respect to all three attributes were excluded. Participants were instructed on the decision-making task, and the eye tracker was calibrated using a 9-point calibration layout. By default, the right eye was calibrated. If the calibration of the right eye did not work, the left eye was tried instead. In every trial, a total of six symbols with attribute value information written in (white) text on top of the symbols were presented ( 
Figure 2B
). The three symbols for one option were colored green 
(RGB values: 37,
86,
24)
, the three symbols for the other option were colored blue (RGB values: 0, 67, 164).
Luminance was kept constant across green and blue. At the center of the screen, a white fixation cross was presented on top of two semi-circles that had the same color as the options. The semicircles indicated which button to press to choose either the left or the right option (Q for left, P for right option). A trial started with the six attribute symbols changing to their new location (see below), but being presented without text for 1 s. Then, the text for attribute values appeared for 10 s during which participants were asked to make their decision. Fixation cross and semicircles were always visible in the screen center. Importantly, the symbols' positions on the screen were not fixed but changed slightly from trial to trial to avoid systematic position effects (e.g., effects of reading direction, different attribute-vs. option-wise distances). These trialwise position shifts were determined prior to running the experiment by generating 10 million potential attribute trajectories (adhering to minimum distances between attributes and the fixation cross) with random initial locations for each attribute and then selecting 400 trajectories with the smallest average standard deviation for all between-attribute mean distances (across trials). For each participant, four of these 400 trajectories were then drawn (without replacement) and used for the two blocks of each choice type (smartphones, hotels). Each block consisted of 60 trials. After each block, participants were given a short break, and the eye tracker was recalibrated. The order of choice types (either two blocks of smartphones first, or two blocks of hotels first) was counterbalanced across participants. Participants were informed that the second reward of the lottery was taken from this decision-making task, and in case they were selected, one of the trials was drawn randomly and they received the chosen option.
Upon completion of the decision-making task, participants were asked to fill out a demographic questionnaire (assessing birthday, gender, native language, handedness, educational attainment, and income) and the German versions of the 18-item revised Obsessive-Compulsive Inventory questionnaire (OCI-R) 
(Foa et al., 2002)
 and the 27-item Intolerance of Uncertainty scale (IUS) 
(Buhr & Dugas, 2002)
. All questionnaires were administered via the online tool LimeSurvey. The experiment lasted for about 1.5h.


Statistical analyses.
A frequentist statistical approach was used to test the various hypotheses on choice, RT, and eye-movement effects outlined above (see "Preregistration").
Unless stated otherwise, data was aggregated within participants (e.g., means, regression coefficients) and subjected to conventional inferential statistics (e.g., t-test, ANOVA, Pearson correlation) on the group level, assuming an alpha-level of 5% and using one-sided tests whenever applicable.
Model simulation. Our central goal of simulating MASC is to show that the model can predict the series of seven effects on the interplay of search and decision-making dynamics outlined above (see "Preregistration") in the context of a single study, in which these effects are also observed empirically. Hence, our focus lies on a qualitative test of the model's prediction of the observed data, rather than on a strictly quantitative comparison. Furthermore, there is no closed-form solution for estimating parameters of MASC (mainly because the actual sample drawn from the attribute value distribution when sampling an attribute remains unknown). Therefore, we settled on the following compromise between simulating MASC without any reference to the actual data on the one extreme end and performing a complete parameter estimation on the other extreme end. First, we estimated individual attribute weights of the three smartphone and hotel attributes by performing linear regressions of the rating task data (i.e., regressing the ratings of options onto the standardized attribute values). The resulting regression coefficients were normalized to sum up to 1 and then used as attribute weights. In case of a negative regression coefficient, the coefficient and the corresponding attribute's values were multiplied by -1 before normalization. This was done to enforce positive attribute weights, which is necessary for implementing MASC (see Appendix A), while still accounting for the fact that the attribute exerted a negative influence on choice probability.
Next, we performed a grid search and simulated MASC to find a suitable parameter set for each participant and each choice set, using the participant's attribute weights as fixed parameters, fixing the initial choice threshold =0 to .01, and searching over the three parameters i.) standard deviation of sampling , ii.) increase (per fixation) of choice threshold Δ, and iii.) sensitivity of search rule . For each parameter, we tried out 31 different, equidistant values ( : from 0.001 to 3.001; Δ: from .01 to .09; : from 0 to 10). Following Callaway et al. 
2021
 The parameter set with the highest average score on these summary statistics was then used to simulate the data of the participant. Without doubt, a more principled parameter estimation approach would be desirable and will be addressed in future developments of MASC. However, a simple parameter recovery analysis suggests that the currently adopted procedure yields acceptable results (Appendix B).


Results
In the following, we will present the results of our experiment along with the respective predictions of MASC, going through the seven preregistered hypotheses. Statistical tests, parameter estimation, and comparison of data and model are performed separately for the two choice sets of smartphones and hotels. Because predictions of MASC will differ slightly from one simulation to the next, we used the model and estimated parameters to simulate 1000 virtual experiments, each of them including the same number of participants and trials as in the actual experiment, and report how many of these simulated experiments resulted in a significant effect.  
Figure 3A
, left column). MASC is able to reproduce these effects (Smartphone: 96% of the virtual experiments that were simulated with MASC resulted in significant effects with respect to all three pairwise comparisons; Hotel: 100% simulated effects significant) ( 
Figure 3B
, left column). The model does so because a difficult decision is characterized by at least one option being almost as good as the best option. Consequently, an incomplete search of attributes might result in the former option appearing more attractive than the latter. Notably, the model predicts slightly more consistent choices than observed in the data (see also section "Discussion" below).


Choice consistency (H1) and number of fixations (H2
As a measure of decision time, we analyzed the number of fixations as a function of difficulty. In line with H2, we found that participants made fewer fixations in easy compared to medium trials (Smartphone: t(62) = -5.63; p < .001; d = -0.71; Hotel: t(62) = -9.17; p < .001; . The predictions of MASC were consistent with this increase (Smartphone: 99% simulated effects significant, Hotel: 100% simulated effects significant) ( 
Figure 3B
, right column). Mechanistically, MASC predicts the increase in fixations with choice difficulty because of the larger overlap of the value belief distributions in difficult trials, so that the decision maker should sample more information to identify the best option.


Figure 3
Choice Consistency and Number of Fixations Note. Data (A) and model predictions (B) of choice consistency (first columns, black) and number of fixations (second columns, blue) as a function of the difficulty level for the smartphone (upper row) and hotel (lower row) choice sets. In line with the data, MASC predicts consistency to decrease and fixations to increase for more difficult decisions. MASC predicts the number of fixations very accurately, whereas it predicts a too-high choice consistency (see Discussion for potential reasons for this discrepancy). In all figures, error bars in the data plots and thin lines in the model plots represent 95% confidence intervals, and thin lines in the data plots show individual data.


Attention and choice (H3).
As discussed above, multiple eye-tracking studies have established a robust positive association of dwell time and choice. People are more likely to choose items they have looked at longer 
(Krajbich, 2019)
. We tested this prediction by a logistic regression, predicting the choice of option 1 over option 2 (defined arbitrarily) as a function of the proportion of fixations on option 1, while controlling for the value difference between the two. Supporting H3, this analysis revealed a strong association of dwell time and choice in both datasets (Smartphone: t(62) = 13.55; p < .001; d = 1.71; Hotel: t(62) = 13.34; p < .001; d = 1.68) ( 
Figure 4A
). Our theory predicts the same effect with remarkably similar strength (Smartphone: 98.8% simulated effects significant; Hotel: 99.7% simulated effects significant) ( 
Figure 4B
). Notably, MASC does not need to assume a causal influence of attention on valuation 
(Krajbich et al., 2010
), although we do not rule out that such an influence may exist.
In contrast to resource-rational search models 
(Callaway et al., 2021;
Jang et al., 2021)
, MASC predicts the effect in the (current) case of decisions between two alternatives without requiring any additional assumptions such as biased priors. Appendix C shows that the model also predicts a positive association of dwell time and choice in the case of multi-alternative decisions, in line with empirical work 
(Gluth et al., 2020;
Krajbich & Rangel, 2011)
. MASC predicts the effect in both two-and multi-alternative choices because of its myopic search rule, according to which options are inspected further if they appear attractive after some initial samples (see also section "Comparing Search Rules" below).


Figure 4
Attention and Choice
Note. (A) The more time participants fixated an option, the more likely they chose it. (B) MASC captures this effect well.
Value and fixations (H4) and the ASE (H5). Although some earlier studies have reported only little evidence for an influence of an option's subjective value on the probability to look at it 
(Krajbich et al., 2010;
Krajbich & Rangel, 2011;
Reutskaja et al., 2011)
, the majority of studies and more recent work suggest a comparatively robust positive association 
(Fiedler & Glöckner, 2012;
Gluth et al., 2020;
Kovach et al., 2014;
Sepulveda et al., 2020)
.
Furthermore, several of these studies found the association of value and fixation probability to increase over the time course of a decision. Stated differently, people look at high-value options more often, and this tendency strengthens during the choice process. We tested these effects in our data sets by regressing the probability to fixate option 1 onto the (within-trial) fixation number, the value difference of option 1 vs. option 2, and the interaction term of these two predictor variables. In line with H4, participants looked more often at the better compared to  
Figure   5A
; left column). Owing to its myopic search rule, which drives search toward attractive choice candidates, MASC reproduces this increasing tendency to focus on the better option (Smartphone: 99.2% simulated effects significant, Hotel: 95.3% of simulated effects significant) ( 
Figure 5B
; left column). Interestingly, both the data and the model suggest the correlation of value difference and fixation probability to remain moderately positive (i.e., between 0 and .3) and decline again in case of very late fixations (12 or later).
Like the dependency of search on value difference, the ASE refers to the dependency of the second sample on the value of the first sample 
(Jekel et al., 2018)
. More precisely, people are more likely to keep sampling from the same option, if the first sample yielded positive information. Confirming H5, we observed a significant ASE in the Smartphone dataset (t(62) = 3.01; p = .002; d = 0.38) and the Hotel dataset (t(62) = 2.59; p = .006; d = 0.33) ( 
Figure 5A
; right column). MASC predicts the ASE (100% simulated effects significant for both datasets) ( 
Figure 5B
; right column).


Figure 5
Value and attention, and the Attraction Search Effect (ASE)
Note. (A) Correlation of value difference and fixation probability (left column) and the ASE (right column). (B) MASC captures the fact that participants fixated the higher-valued option more often after a few fixations. Similarly, it captures the ASE, that is, the tendency to keep sampling an option at the second fixation if the first fixated attribute had a positive (i.e., aboveaverage) value.


Attribute weights and attention (H6).
A fast and efficient search is characterized by first looking at more important or diagnostic information and only moving on to other sources if the first samples do not provide conclusive evidence. For example, the TTB heuristic epitomizes this principle 
(Gigerenzer et al., 1999;
Rieskamp & Hoffrage, 2008)
. Accordingly, we hypothesized (H6) that participants will fixate the most important attribute more often at early stages of the emerging decision, but that this tendency will decrease as the decision goes on. Formally, this was tested by regressing the fixation of the attribute with the highest weight (as specified by the separate rating task) onto the fixation number. Consistent with the preregistered hypothesis, the intercept coefficient of this logistic regression was significantly higher than ln(1/2) 7 , indicating that participants fixated the most important attribute more often than the chance level of 1/3 (Smartphone: t 
62
 
Figure 6A
). Our theory predicted a very similar development of fixations on attributes of different weights (100% simulated effects significant for both datasets) ( 
Figure 6B
). Once again, the critical feature of MASC to explain this effect is the myopic search rule (in combination with the choice rule). At the beginning of a decision, sampling attributes with high weights provide the best chance to identify good options, as such samples are most likely to yield strong updates of value beliefs.
After sampling those attributes a few times, however, their distributions are sharpened so much that taking more samples from the same attribute is unlikely to change any beliefs and switching to the remaining attributes becomes necessary. 
7
 The chance level value of the intercept in a logistic regression with m attributes is equal to ln 1 1− 1 , which reduces to ln(1/2) in case of m = 3.


Figure 6
Attribute Weights and Fixations Note. Development of fixations over the time course of decisions as a function of attribute weights in the data (A) and model (B). As predicted by MASC, the initial tendency to look at more important attributes decreases over time. Notably, the model also predicts a difference between the medium-and lowest-weight attributes, which is seen in the Hotel data but not in the Smartphone data.
Attribute weights and Payne Index (H7). Finally, we predicted to replicate previous work (X. Yang & Krajbich, 2023) on interindividual differences reflecting the relationship of attribute weights and search patterns. People with more extreme attribute weights search in a more attribute-wise manner, resulting in a lower Payne Index 
(Payne, 1976
). Thus, we tested for a negative correlation of the difference between the highest and medium weights and the individual Payne Indices. Confirming H7, there was a significantly negative correlation in the Hotel dataset (r(61) = -.28; p = .013), but contrary to H7, there was no correlation in the Smartphone dataset (r(61) = 0.01; p = .529) ( 
Figure 7A
). MASC predicts a weak but significant negative correlation for both datasets (Smartphone: 99.9% simulated effects significant; Hotel:
100% simulated effects significant) ( 
Figure 7B)
. Mechanistically, the model predicts this relationship between attribute weights and transition patterns by means of its myopic search rule, which captures the intuition that sampling a very dominant attribute (across all options) is likely to provide decisive evidence.


Figure 7
Attribute Weights and Payne Index Note. Correlation of attribute dispersion (quantified by the difference between the highest and medium attribute weight) and Payne Index in the data (left column) and model (right column). MASC predicts a negative correlation which is seen in the Hotel dataset but is not significant in the Smartphone dataset.


Discussion
Based on existing literature as well as simulations of MASC, we developed and tested seven hypotheses on the consistency and speed of multi-attribute decisions as well as the interplay of eye movements and decisions. In one of two conditions (i.e., Hotels), all hypotheses were confirmed, in the other condition (i.e. Smartphones), five of seven hypotheses were confirmed, with the remaining two tests trending in the expected direction. The predictions of MASC matched most of the empirical results very closely. Importantly, these patterns are not hard-coded into MASC but are an emergent property of a small number of core principles, most notably the efficient but not strictly optimal myopic search rule. Thus, the positive association of attention and choice (H3, 
Figure 4
), the positive association of value and attention together with the ASE (H4 and H5, 
Figure 5
), and the tendency to sample more important attributes first (H6, 
Figure 6
) all emerge from this principle. Also, the negative correlation of the dispersion of attribute weights and the Payne Index (H7, 
Figure 7
) results from the model's prediction that decision makers who give the most important attribute a particularly high weight will try to decide by sampling only this attribute, which again emerges from MASC's search rule.
A notable difference between data and model is the higher choice consistency of the latter 
(Figure 3)
. We see several potential reasons for this discrepancy. First, we used the coefficients from the linear regression of the rating task as weights in the model, thereby assuming people to use the same (noiseless) attribute weights in the decision-making task. It is conceivable, however, that those weights might differ between the two tasks at least to some extent, similar to the differential weighting of probabilities and amounts in bidding and choosing from risky gambles 
(Lichtenstein & Slovic, 1971)
. Also, weights might not remain completely stable during the decision-making task but vary from trial to trial or drift in a specific direction. Furthermore, sampled information must be maintained in working memory and could be subject to forgetting. If participants need to re-fixate options to refresh their working memory, then their actual belief updating will be less precise than assumed by MASC, which in its current form does not model working memory or forgetting processes. In future work, it could be interesting to implement forgetting in the model, for instance, by assuming the precision of attribute values (and consequently also option values) to decay over time.


The Search Process in Multi-Attribute Choice and its Rationale
How people search for information and how they devote their attention to the different attributes and options is critical to understand decision making. Previous models have suggested a variety of solutions to this problem, which range from circumventing it by using process-tracing data such as eye movements to inform model predictions (X. 
Yang & Krajbich, 2023)
 to proposing that people search for information with (resource-)rational optimality 
(Krueger et al., 2024;
Sims, 2003)
. As discussed earlier, MASC assumes a myopic search rule, according to which the agent plans only one sample ahead, asking for each attribute j of each option i, how likely sampling j will lead to i being chosen. The myopic element makes MASC's search rule akin to that of the Directed Cognition model 
(Gabaix et al., 2006)
 and related models 
(Ursu et al., 2022;
L. Yang et al., 2015)
. Critically, however, MASC's rule is more frugal as it does not take the choice of other options into account when considering sampling from option i.
In the following, we seek to stress the relevance of MASC's search rule in two ways.
First, we compare it to several conceivable alternatives and demonstrate that these alternative search rules fail to capture the seven hypotheses tested above and thus the full spectrum of interactive patterns between attention and decision making that have been observed in the current as well as in many previous studies. Second, we illustrate the efficiency of the search rule by linking it to the concept of reward rate 
(Bogacz et al., 2006;
Gold & Shadlen, 2002)
.


Comparing Search Rules
We compare MASC's myopic search rule with seven simpler alternatives that determine transitions by specific features (e.g., option values) or not at all (i.e., random search), as well as with one more complex search rule that assumes the agent to not only consider choosing i when sampling this option i next (as done by MASC) but also choosing any other option. In the following, we briefly describe these alternative search rules (formal specifications are provided in Appendix D):
Random search with refixations (RAND I): This baseline search rule assumes that all attributes are equally likely to be sampled next (including the currently sampled attribute).
Notably, this rule demonstrates how the predictions of MASC change when the search sensitivity parameter  is set to 0 and thus effectively switched off.


Random search without refixations (RAND II): This search rule is the same as RAND I,
with the exception that the currently sampled attribute cannot be sampled directly again. Note that this rule has been implemented in early simulations of the aDDM for (simple value-based) binary decisions 
(Krajbich et al., 2010)
, where it was assumed that people switch back and forth between the two choice options.
Accumulated option values (OPTVAL): This search rule assumes that the probability to sample an attribute is a function of the current mean of the value distribution of the option to which the attribute belongs. This rule has been proposed in our extension of the aDDM to capture the increasingly positive association of option value and fixation probability as decisions emerge over time 
(Gluth et al., 2020)
. Notably, the rule implies that all attributes of a given option have the same probability of being sampled, as it considers only the option level but not the attribute level.
Accumulated attribute values (ATTVAL): Instead of option values, it is conceivable that attention is attracted towards attributes with higher values. Thus, this search rule assumes the sampling probability to depend on the current mean of each attribute value distribution.


Uncertainty of option values (OPTUNC)
: From a Bayesian perspective, the goal of sampling information is to reduce uncertainty about option values to identify the best option.
Thus, it seems plausible that option uncertainty may drive search (D. G. 
Lee, 2023;
Song et al., 2019)
 . Like OPTVAL, this rule implies that all attributes of a given option have the same probability of being sampled.


Uncertainty of attribute values (ATTUNC): Instead of uncertainty about option values, this
rule considers uncertainty about attribute values as the driver of search (reducing attribute uncertainty will necessarily reduce option uncertainty as well).
Attribute weights (ATTWEIGHT): Search could also be driven by attribute weights, such that more important attributes are more likely to be fixated, because sampling more important information can be expected to lead to stronger belief updates of option value distributions.
Note that this rule implies that the same attributes across all options have the same probability of being sampled.
More complex myopic search rule (MYOPIC II): This search rule is similar to MASC's search rule as specified in Equation 4. However, whereas MASC assumes the sampling probability for attribute j of option i to depend solely on the expectation to choose option i, the search rule MYOPIC II assumes the sampling probability to depend on the expectation to choose any option after one more sample. Although this rule does not implement the completely Bayes-optimal search process, as it looks only one step ahead, it could be considered being closer to optimality. In fact, it implements the rational strategy within the bound of being myopic and is thus very similar to the search rule of the Directed Cognition model 
(Gabaix et al., 2006
; see also 
Callaway et al., 2023)
.
Importantly, we only adjusted the search rule but did not change the rest of MASC's architecture and used the same parameter estimation scheme as for MASC (see above). Thereto, the ranges of tested parameter values for the alternative search rules were selected carefully so that most of the participants' estimated parameters would lie in-between the extreme (i.e., the minimum and maximum) values of the grid search. To evaluate the different search rules' predictions, each model variant was again simulated 1'000 times to assess how often each rule predicts the seven preregistered behavioral and eye-tracking effects. 
Table 1 summarizes these
 results.


Table 1
Qualitative Predictions of Search Rules Note. The first and second entries per cell refer to the Smartphone and Hotel datasets, respectively. For the data, "+" indicates that a given effect was significant, and "-" indicates that no significant effect was observed. For the search rules, "+" indicates that a given effect is predicted in more than 95% of the simulations, "(+)" 50-95%, "(-)" 5-49.9%, and "-" less than 5% of all simulations. H1-H7 refer to the seven preregistered hypotheses (see main text). a The ATTWEIGHT rule does predict that more attention is given to the more important attribute (in fact, this is the defining feature of the rule), but it fails to predict the decrease of this effect for later fixations (see 
Figure 6
).
All search rules allow predicting the two purely behavioral effects (H1, H2), that is, the reduction of choice consistency and the increase of fixations as decisions become more difficult. Contrary to our proposed search rule, however, most alternatives struggle with capturing effects H3 to H7. The best rule among these alternatives appears to be OPTVAL, which has been proposed as an extension of the aDDM 
(Gluth et al., 2020)
 and assumes that search is driven by the (accumulated) value of options, allowing it to capture the positive association of allocated attention and choice probability (H3) and the value-dependent effects (H4 and H5). Yet, this rule takes only option values into account and neglects the attribute level. Consequently, it neither predicts the influence of attribute weights on search (H6) nor the negative correlation between weight dispersion and the Payne Index (H7). Despite its conceptual similarity to MASC's search rule, the more complex MYOPIC II search rule fails to predict most attentional effects, including the positive association of attention and choice probability. This is consistent with previous work suggesting that (more) optimal search rules do not predict this effect in binary decisions unless additional assumptions (e.g., biased priors) are included 
(Callaway et al., 2021;
Jang et al., 2021)
. Taken together, the comparison illustrates that the proposed myopic search rule of MASC is necessary to allow the model capturing the full spectrum of search and choice patterns seen in previous work and our own data.


Search Sensitivity and Reward Rate
In addition to showing that the suggested myopic search rule accurately predicts the empirical effects, it is important to know whether using the rule allows decision makers to choose more efficiently. To answer this question, we simulated the model across a range of parameter sets to ascertain how each parameter relates to the number of fixations, choice consistency and in turn, reward rate. For simplicity, we define reward rate as the ratio of choice consistency (as a value-based analogue to accuracy) and number of fixations (as a proxy of decision speed), that is, the number of consistent decisions per fixation. We omit features such as non-decision time or the length of intertrial intervals 
(Bogacz et al., 2006;
Gold & Shadlen, 2002)
, which are irrelevant in the current context.
Using the same range of parameter values as in the grid search, we sampled 10 equidistant values for each parameter, resulting in a total of 1'000 parameter sets. Each set was used to simulate the model with 200 trials. Attribute weights were sampled from a beta distribution with α = 0.75 and β = 0.75, then normalized to 1, while corresponding attribute values were sampled from a standard normal distribution. If the attribute values for a trial resulted in one option being superior with respect to all attributes, then the values were resampled (i.e., we excluded "no-brainer" trials similar to our experiment; see above). To assess the contribution of each parameter, we used a general linear model to regress the three measures of choice consistency, number of fixations, and reward rate onto the parameter values. 
Figure 8
 depicts how the sampling noise, threshold increase and search sensitivity parameters are related to these measures. Note. Relationship between MASC parameters and different behavioral outcome measures. Higher levels of sampling noise lead to lower reward rates, while higher values of threshold change and the search sensitivity parameter lead to higher reward rates (note that if  = 0, search is random).
Firstly, sampling noise is negatively related to choice consistency (β = -0.084, t 
996
 


Differences in Allocation of Attention and Attribute Weights
Observers first sample important attributes before shifting attention to others, suggesting that weights are predictive of the amount of attention an attribute receives 
(Krueger et al., 2024;
Rieskamp & Hoffrage, 2008)
. A direct connection between attention and weights has also been implemented in some decision-making models such as Decision Field Theory 
(Busemeyer & Townsend, 1993;
Roe et al., 2001
). However, some recent binary, two-attribute choice tasks have observed a disproportionate relationship between weights and attention, finding that the highest weighted attribute accounts for ~95% of dwell time, considerably more than would be predicted when assuming that attention is a linear function of the difference in weights 
(March & Gluth, 2024;
X. Yang et al., 2024)
. One explanation for this finding is that some attributes may be less efficiently processed than others, requiring repeated sampling before value beliefs are sufficiently updated and other attributes can be considered. We performed a simulation, in which we examined the predictions of MASC for two-attribute decisions. The results show that MASC can indeed predict a disproportionately high allocation of attention to the higher-weighted attribute when assuming that the attributes are noisy (and therefore less efficiently processed), as indicated by high sampling noise parameter values. 
Figure 9A
 shows the development of fixations over time to the more important attribute when weight difference = 0.5, similar to the studies mentioned above. When sampling noise is high, MASC repeatedly samples from the most important attribute before shifting attention to the other, with this shift occurring later with higher levels of noise. Consequently, the model predicts that a disproportionally large amount (~90%) of attention is allocated to the more important attribute, despite the difference in weights being only 0.5 ( 
Figure 9B
).


Figure 9
Attribute Weights and Attention with Varying Sampling Noise Note. (A) Development of fixations to the higher weighted attribute over time with a fixed weight difference of 0.5. MASC predicts that higher sampling noise leads to prolonged sampling of the higher weighted attribute early on before attention switches to the other attribute. (B) shows the predicted difference in attention as a function of weight difference for varying levels of sampling noise.


Decision Making Under Time Pressure
Past research has argued that people resort to non-compensatory search strategies to reduce the processing demands of information search under increased time pressure 
(Krueger et al., 2024;
Payne et al., 1988)
. This strategy shift is indicated by attending mostly to important attributes, showing greater variability in the proportion of gaze time spent on each attribute, and by making a higher proportion of attribute-wise compared to option-wise transitions (i.e., a lower Payne Index) as time pressure increases 
(Payne et al., 1988;
Krueger et al., 2024;
Rieskamp & Hoffrage, 2008)
. Here, we simulate time pressure by systematically increasing MASC's threshold parameter θ (in the range of .001-02), while keeping all other aspects of the model constant. Note that since the threshold parameter determines the accepted overlap between posterior option distributions before a choice is made, higher threshold values represent more liberal decision thresholds and lead to faster decisions. Repeating this simulation for varying levels of search sensitivity α demonstrates that MASC's myopic search rule can predict the above-mentioned effects that have been interpreted as a shift to non-compensatory search strategies ( 
Figure 10
). 


Response Time and The Number of Options
Information theory suggests that entropy increases logarithmically with the number of alternatives in a choice task. In turn, Hick's Law states that there should be a logarithmic relationship between the number of alternatives and response times, which early research had confirmed empirically 
(Hick, 1952;
Hyman, 1953)
. Although MASC does not predict fixation duration or response time per se, MASC is able to replicate this logarithmic relationship when using the number of fixations as a proxy for decision speed 
(Figure 11
).


Figure 11


Relationship between Number of Fixations and Number of Options
Note. Constant terms a and b were calculated by regressing the predicted number of fixations onto log2(N-1). Here, we simulate single attribute decisions with threshold increase Δ = .01, search sensitivity α = 5 and sampling noise 2 = 1, although MASC consistently predicts this logarithmic relationship across a range of parameter sets.


Overall Value and Response Time
It is well established that reaction times decrease as the value difference between options grows 
(Brus et al., 2021;
Busemeyer & Townsend, 1993;
Gluth et al., 2015
), yet a growing body of literature has begun to consider the role of overall value of all choice alternatives together. This research shows that higher overall values of the choice set leads to faster decisions in both simple value-based and perceptual choices 
(Pirrone et al., 2022;
Polanía et al., 2014;
Sepulveda et al., 2020;
Shevlin et al., 2022;
Ting & Gluth, 2023)
. To illustrate how MASC predicts this relationship, we analyzed the effect of overall value on the predicted number of fixations while controlling for value difference in a general linear model.
We expected that MASC should predict this effect, but also that the relationship should be stronger when observers adopt a less cautious decision threshold. This is because in a set of high value options, sampling one option is likely to provide a large (positive) update of the posterior belief distribution and increase the likelihood of choosing this option, in particular under a lenient threshold. In line with our expectation, MASC predicts both the general reduction of sampling with high overall value and the amplification of this effect under lenient decision thresholds.
We sampled 100 parameter sets and simulated 200 trials. Because overall value effects have mostly been reported in "simple" perceptual or value-based decisions, we simulated single-attribute choices with N = 5 options 8 . Since decisions are relatively fast when N is small, we chose N = 5 to elicit longer decisions in order to better illustrate the relationship between overall value and number of fixations. As expected, there was a significant negative effect of overall value on predicted number of fixations ( ̅ = -0.778, t(99) = -18.578, p < .001). Repeating the simulations with varying threshold parameter shows that the effect increases for less cautious decisions 
(Figure 12
).


Figure 12
Overall Value and Predicted Number of Fixations Note. Predicted number of fixations as a function of overall value (controlled for value difference). Gray points show 200 trials for one simulated participant and the green lines show the predicted number of fixations when value difference is fixed.


General Discussion
Multi-Attribute Search and Choice (MASC) is a cognitive model that describes the process of choosing between two or more options which are characterized by multiple attributes. MASC focusses on modeling the interplay of attention and preference formation, aiming to provide a comprehensive account of a series of empirical findings that have been established in many process-tracing studies and replicated in our own experiment. The theory takes inspirations from the SSM framework of decision making 
(Busemeyer et al., 2019;
Forstmann et al., 2016;
Gold & Shadlen, 2007;
X. Yang & Krajbich, 2023)
 but embeds the idea of sampling and accumulating evidence into a Bayesian architecture to describe how beliefs about attribute and option values shape the dynamics of allocating attention and ultimately committing to a particular choice 
(Callaway et al., 2021;
Gabaix et al., 2006;
Jang et al., 2021)
.
This allows MASC to make predictions about where the decision maker looks next, based on considering which next sample is most likely to reveal decisive evidence.


The Elements of MASC
The three core features of MASC are the belief distributions of attribute and option values, the myopic search rule that determines how likely attributes and options are sampled next, and the termination rule that implements a relative criterion of when to stop sampling and choose. These features are associated with the three parameters of sampling noise, search sensitivity, and threshold (and change of threshold over time), respectively.
The presence of noise in sampling attributes implies a gradual updating of attribute value beliefs and can explain different search patterns of attributes that are (re-)presented differently.
Interestingly, our simulations of MASC suggest a larger divergence of the relative importance of attributes (i.e., their weights) and the amount of attention they receive, if these attributes are noisy 
(Figure 9
). This is in line with recent work on dietary and consumer decisions, showing a strong imbalance of allocated attention in decisions with comparatively vague attributes such as the tastiness of food options or the attractiveness of clothing articles. The concreteness of attribute information has also been identified as a critical modulator of the effectiveness of decoy options in multi-alternative decision problems 
(Frederick et al., 2014;
Spektor et al., 2021)
. Although MASC is currently not designed to account for such context effects (as discussed in the section "Current Limitations and Future Directions" below), further developments of the theory could help to better understand the intricate boundary conditions of context effects (see also 
Trueblood et al., 2022
, for another attention-based account of this elusiveness).
With respect to our own experiment, it is noteworthy that the estimated parameters suggest a moderate amount of sampling noise, even though attribute information was provided numerically (group mean ±SD of , Smartphone: 1.20 ±0.23; Hotel: 0.80 ±0.19). In line with this, participants sampled attributes more often than once, making about two fixations per attribute value per trial on average. Again, working memory capacity and forgetting could be one reason for these re-fixations. An alternative view, however, is to understand the perception and evaluation of numbers as a (noisy) Bayesian inference process 
(Barretto-García et al., 2023)
. Under this premise, it is plausible that people sample even very discrete numeric values multiple times to increase the precision of their posterior beliefs 9 . Notably, this view contrasts with some other recently proposed search models 
(Callaway et al., 2023;
Krueger et al., 2024)
, which assume that sampling a numeric attribute value just once shrinks the corresponding belief distribution to a point estimate, or in other words, increases the precision to infinity. These models should have difficulties accounting for re-fixations of previously attended attributes (or re-opening of boxes in mouse-lab experiments).
The second core element of MASC is its search rule. The decision maker is assumed to pursue the goal of reaching conclusive evidence quickly and thus to sample information that is expected to meet this goal. Following this premise, we implement a rule that quantifies the expected probability of choosing option i when taking one more sample from attribute j of the same option. Importantly, the dependency of search on the three features importance (i.e., attribute weights), uncertainty, and value is an emergent property of this search rule, as sampling more important and less certain attributes as well as better choice candidates is more likely to yield decisive evidence. Thus, MASC's search rule is pivotal to explain the various patterns of search and attention-choice interactions presented above 
(Figure 4-7
; 
Table 1
).
Notably, the proposal of a search rule that plans (only) one step ahead is not new, but has been implemented in prior models of (multi-attribute) decision making 
(Busemeyer & Rapoport, 1988;
Callaway et al., 2023;
Gabaix et al., 2006;
Ursu et al., 2022;
L. Yang et al., 2015)
. In contrast to MASC, however, all these previous search rules assume that search remains (boundedly) rational within the limited horizon of planning one step ahead: The decision maker is assumed to compute the expected utility of taking one more sample before deciding (minus a cost for sampling) and compares it to the expected utility of deciding immediately. Critically, this includes the consideration of choosing any other option (k, l, …)
after sampling an attribute of option i, which is not part of MASC's search rule but implemented in the alternative rule MYOPIC II (see above and Appendix D). As shown in 
Table 1
, this rule fails to capture most of the attentional patterns in the current experiment as well as in previous experiments with binary choice problems. For example, the rule does not predict that the more promising choice option is more likely to be looked at, which allows capturing both the positive association of attention and choice 
(Krajbich, 2019)
 and the ASE 
(Jekel et al., 2018)
. This is becausewhen considering choosing both options (as assumed by MYOPIC II)sampling the less promising choice option is expected to yield the same amount of information as sampling the more promising choice option, ceteris paribus. Some models overcome this limitation by assuming a bias in the prior belief distribution towards lower values 
(Callaway et al., 2021;
Jang et al., 2021)
. However, this assumption itself seems problematic in the current and many previous studies, in which participants were familiarized with the range of options via instructions and (often multiple rounds of) preference ratings before the choice task (e.g., 
Brus et al., 2021;
Gluth et al., 2020;
March & Gluth, 2024;
Ting & Gluth, 2023;
Weilbächer et al., 2021)
. Therefore, we would argue that the search rule of MASC does not only provide a better account of the empirical data on attention-choice interactions but is also computationally less demanding, as it only considers whether sampling an option may result in choosing that option (but not in choosing the others).
MASC's third and last core element is the relative stopping rule for terminating the search process and committing to a particular choice option. Technically, this is implemented by testing how much the currently best option's value distribution overlaps with those of all other options. A decision is made if all overlaps are smaller than some threshold . In other words, the currently best option needs to set itself apart from all other options clearly enough to be chosen, which is essentially a relative stopping rule 
(Teodorescu & Usher, 2013)
. Alternatively, MASC could use (instead or in addition) an absolute criterion, according to which an option's value distribution must surpass an absolute threshold to elicit a choice, akin to the satisficing heuristic 
(Callaway et al., 2022;
Reutskaja et al., 2011;
Simon, 1955;
Stüttgen et al., 2012)
.
Interestingly, when replacing the relative by an absolute stopping rule, MASC still captures the core effects of attention-choice interactions in our study (Appendix E), which demonstrates the robustness of the theory with respect to the decision criterion. However, the absolute stopping rule makes the very extreme prediction that the chosen option is always sampled last, because only sampled options are updated and can thus cross the threshold (cf. 
Mullett & Stewart, 2016)
.
Although many eye-tracking studies do report that people tend to fixate the chosen option last 
(Krajbich et al., 2010;
Ting & Gluth, 2023;
Weilbächer et al., 2021)
, this association is far from being deterministic. Taken our current experiment as an example, the last fixation was made on the chosen option in 63% (±7%) of the trials. Remarkably, this pattern is captured very well by MASC with a relative stopping rule, which predicts the chosen option to be fixated last in 59% (±7%) of trials 10 .


Relationship to Extant Theories of Attention and Choice
As discussed in the previous section, MASC exhibits many similarities with Bayesian updating models for multi-attribute choice problems that have been developed in economics and marketing 
(Gabaix et al., 2006;
Ursu et al., 2022;
L. Yang et al., 2015)
, but it critically differs in terms of the specifics of the search rule 11 . Other theories of how attention and choice interact have been proposed in cognitive psychology and neuroeconomics (see also Introduction). The aDDM 
(Krajbich et al., 2010;
Krajbich & Rangel, 2011;
X. Yang & Krajbich, 2023)
 and the related Gaze-weighted Linear Accumulator Model (GLAM; Thomas et al., 2019) assume people to accumulate evidence for available choice options, with a reduced accumulation rate for non-fixated options. These models capture many behavioral and eyetracking patterns, including the positive association of attention and choice and the tendency to choose the last-fixated option. However, aDDM and GLAM either assume a random search process (similar to the search rules RAND I and RAND II that we tested above), or the empirical eye-tracking data is used to inform the model 
(Cavanagh et al., 2014)
. Thus, both approaches remain agnostic about the drivers of search, limiting the insights that can be gained from applying these models. An exception to this is the extended aDDM proposed by 
Gluth et al. (2020)
, according to which the probability of fixating an option is a function of the option's accumulated evidence. This assumption is akin to the search rule OPTVAL that we tested above, which captured most of the eye-movement patterns 
(Table 1
). Yet, the model lacks an attribute level and thus cannot explain how attribute weights are related to search dynamics ( 
Figure 6
) or search patterns (i.e., Payne Index; 
Figure 7
). Replacing the assumption that search is driven by option values by a dependency on attribute values (i.e., ATTVAL) did not solve the problem, as this search rule accounted for even fewer data patterns ( 
Table 1
).
The iCodes model 
(Jekel et al., 2018)
 is a neural network model and has been proposed to accommodate the ASE in multi-cue probabilistic inferences. To do so, the model assumes that cues with higher activations in the network are more likely to be sampled, and that cue activations spread to neighboring cues of the same option. In line with MASC but in contrast to the Bayesian updating models with fully-rational or myopic-rational search 
(Callaway et al., 2022;
Gabaix et al., 2006;
Jang et al., 2021)
, iCodes predicts the ASE in binary choice problems.
sampling costs as a free parameter. A decision is made as soon as the expected utility gain of taking another sample does not compensate these costs anymore.
As far as we can see, however, iCodes lacks a component to take uncertainty into account and should have difficulties predicting that people are more likely to search for yet unseen (or rarely sampled) cues and attributes. Future work could test the two theories against each other more rigorously and formally.
Notable similarities with MASC (and related theories of multi-attribute decision making) can be found in two models that have recently been developed in categorization research 
(Braunlich & Love, 2022;
Weichart et al., 2022)
. Both of them model how people determine the next sample when looking for stimulus dimensions that may allow a successful categorization. The Sampling Emergent Attention model by 
Braunlich and Love (2022)
 assumes people to take all possible future samples into account when determining the next sample, thereby implementing a fully-rational but computationally highly demanding search rule that is akin to those used in the resource-rational analysis approach 
(Callaway et al., 2021;
Krueger et al., 2024)
. In contrast, the extended Adaptive Attention Representation Model by 
Weichart et al. (2022)
 computes the expected change (i.e., gradient) of evidence for the currently favored categorization label to drive the search towards dimensions that are currently expected to provide the largest amount of information. This rule resembles a myopic search rule that takes only the next sample into account. And similar to MASC and iCodes, this rule promotes a confirmation bias 
(Nickerson, 1998;
Talluri et al., 2018;
J.-S. Wang et al., 2024)
, meaning that the agent is assumed to search for information that confirms the currently favored categorization.
Recently, 
Trueblood et al. (2022)
 have put forward a modeling framework that describes how preference formation processes may depend on the distribution of attention in multiattribute, multi-alternative decision problems. The framework assumes that the decision maker compares two options with respect to one attribute at every time point and updates their preferences for the options depending on this relative attribute-wise comparison. A transition matrix determines whether attention is shifted to another pair of options and to another attribute.
By assuming that this transition matrix depends on the similarity of options and their spatial arrangement, 
Trueblood et al. (2022)
 are not only able to predict several context effects in decisions with multiple attributes and options 
(Busemeyer et al., 2019)
, but they can also account for the malleability of these effects to the way options and attributes are presented 
(Cataldo & Cohen, 2018;
Gluth et al., 2018;
Spektor et al., 2018
Spektor et al., , 2021
. In contrast to MASC and some of the other theories discussed above, however, the transition matrix is assumed to be static within trials, so that previous samples do not change the ongoing search process.
Furthermore, the eye-tracking results in the current study (with a positive Payne Index indicating predominantly option-wise search 12 ) together with previous work 
(Glöckner & Herbold, 2011;
Noguchi & Stewart, 2014;
Reeck et al., 2017)
 are inconsistent with the assumption of a purely attribute-wise comparison mechanism. Still, the notion of attribute-wise comparisons points toward a potential future extension of MASC that may enable it to account for context effects as well (see also next section).


Current Limitations and Future Directions
As noted several times already, the current version of MASC does not account for context effects in decisions with multiple attributes and multiple alternatives. Context effects refer to the phenomenon that the relative preference between two options can depend on the presence and the specifics of a third option 
(Busemeyer et al., 2019;
, which violates fundamental assumptions of standard economic decision theory 
(Luce, 1959;
Savage, 1954)
. In particular, the attraction, compromise, and similarity effects have been suggested as the core set of context effects, and many multi-attribute choice models (mostly SSMs) have been developed to account for them (for a review of the effects and models, see 
Busemeyer et al., 2019)
. Furthermore, most of these models include some form of attention mechanisms to explain context effects, and the order and amount of allocated attention has been proposed to be a major determinant of the presence, absence, and reversal of context effects in different choice environments 
(Spektor et al., 2021;
Trueblood, 2022;
Trueblood et al., 2022)
.
Given our many contributions to this line of research (e.g., 
Berkowitsch et al., 2014;
Gluth et al., 2017
Gluth et al., , 2018
Spektor et al., 2019)
, one of our central goals for future developments of MASC will be to allow it explaining context effects.
Another extension of MASC could be to integrate bottom-up drivers of attention when determining which information is sampled next. We purposefully developed a top-down and goal-directed theory of attention allocation, specifying how people try to search for decisive information to make efficient decisions. Yet, it is know that visual factors such as the position, salience, and size of information strongly influence eye movements 
(Orquin et al., 2021)
, and some previous multi-attribute choice models take some of these factors into account 
(Trueblood et al., 2022;
L. Yang et al., 2015)
. In the present work, we circumvented these aspects as much as possible to focus on top-down attention by designing an experiment with isoluminant stimuli that change their position from trial to trial, so that the impact of salience and position is minimized.
Along with the inclusion of visual factors into MASC, the model could also be extended to allow predicting the duration of fixations. Currently, MASC specifies whether and where to look next, but not for how long. A simple approach would be to draw fixation durations from a sensible distribution function such as the log-normal distribution 
(Krajbich et al., 2010)
. This would allow the model to predict response times in addition to the number of fixations, but it would not provide new mechanistic insights into what drives fixation durations. Alternatively, one could partition a fixation into smaller events, effectively assuming that multiple samples are taken during a single fixation until sufficient information about the currently fixated stimulus has been gathered and making a saccade to a new piece of information is deemed more beneficial 
(Callaway et al., 2021;
Jang et al., 2021;
Song et al., 2019;
Tatler et al., 2017)
. In this case, a testable prediction of MASC would be that noisy attributes such as food stimuli are not only fixated more often but also longer as compared to easily discernable attributes such as nutrition labels, because both strategies (i.e., fixating more often and fixating longer) can reduce noise.
Given that several models of multi-attribute choice and multi-dimensional categorization assume some form of forward-looking mechanism to determine the next sample but disagree in terms of the exact planning horizon and algorithm 
(Braunlich & Love, 2022;
Callaway et al., 2021;
Gabaix et al., 2006;
Jang et al., 2021;
Ursu et al., 2022;
Weichart et al., 2022;
L. Yang et al., 2015)
, it will be critical for future research to provide (further) empirical evidence for this forward-looking mechanism as well as to specify it in more detail. Note that we are not bound to a strictly myopic search rule that plans only one step ahead. Instead, it is conceivable that planning depth might differ as a function of the choice problem and response mode. While a very limited planning horizon and thus a myopic search rule seems plausible in the current case of rapid eye movements (< 1s) and comparatively fast decisions (< 10s), more elaborate goal-directed decisions in strategic games and different response modalities such as mouse-lab, which make search decisions more explicit, could foster a longer planning horizon 
(Callaway et al., 2022)
. Moreover, gaining expertise in a specific field of decision making could be related to planning depth, leading to search and choice behavior that approximates optimality 
(Van Opheusden et al., 2023)
.


Conclusion
Humans master complex choice problems by searching for relevant information in adaptive and efficient ways, but their behavior does not always adhere to predictions of strict optimality or rationality. Our theory of Multi-Attribute Search and Choice (MASC) offers an account of this highly efficient yet sub-optimal search and choice behavior, thereby capturing a series of empirical patterns of interactions between attention and decision making that has been established in the literature and reproduced in the current study. At the core of MASC lies a myopic search rule, according to which people anticipate which next sample is most likely to yield decisive evidence. Consistent with rationality principles 
(Jang et al., 2021)
, important drivers of search such as attribute weights, uncertainty, and accumulated value arise as emergent properties from this rule. But at the same time, MASC predicts a tendency to search for confirmatory evidence 
(Talluri et al., 2018)
, thus offering a cognitive mechanism to explain the Gaze Cascade Effect 
(Shimojo et al., 2003)
 and the Attraction Search Effect 
(Jekel et al., 2018)
. Future developments of MASC will be necessary to extend the scope of the theory, for instance to predict context effects and fixation durations. In this regard, we are sympathetic with other recent approaches in the field 
(Trueblood et al., 2022)
 and see our theory as a starting point for building a general framework to jointly model search and choice processes in complex decision environments.


Code and data availability statement
Model code and data are publicly available on GitHub (https://github.com/jordandeakin/MASC), and the OSF project website (https://osf.io/h3zkw/)
includes the preregistration protocol (https://osf.io/xh3tb).  
Figure B2
 shows the true and averaged recovered parameters for each dataset. Note that since we used a grid search for parameter estimation, we jittered the true parameters for illustration purposes to ensure that the points did not overlap. The data in 
Figure B2
 indicate that when the true generating parameter is high, the search sensitivity parameter tends to be overestimated, resulting in less accurate recovery. Although MASC captures the main qualitative trends in the data, the model overpredicts the efficiency of the search process when being simulated with the best parameters (i.e., underestimation of number of fixations and overestimation of choice consistency; see 
Figure 3
). Since the model operates on simulated data in the recovery process, this overprediction of search efficiency is likely responsible for the overprediction of the recovered search sensitivity parameter. In future implementations of MASC, we will use a more fine-grained parameter estimation process which will attenuate this issue and improve recovery.


Figure B2
Correlations of True and Recovered Parameters Note. The upper row refers to the Smartphone dataset, the lower row to the Hotel dataset. The grey area shows the range of fitted lines across the 100 recovery simulations, while the dark grey line shows x = y (perfect recovery).


Figure C1
MASC Simulations for n = 4
Note. Simulations are shown for the Hotel dataset. H1-H7 refer to the seven preregistered hypotheses that are also tested for n = 2 in the main text (see Results and 
Figures 3-7)
. The dashed lines that indicate chance level were adjusted to the case of n = 4. Note that the model predicts lower choice consistency and more fixations than in binary decisions, which is plausible. Also, the probability to sample again from the same option at the second fixation (see H4 & H5, right panel) and the Payne Index (H7) are lower. Again, this is plausible, because if the number of options increases from 2 to 4, while the number of attributes remains at 3, the number of possible within-attribute transition increases from 1 to 3, while the within-option transitions remain at 2, and the chance-level Payne Index decreases from 1/3 to -1/5 (cf. 
Böckenholt & Hynan, 1994)
.
Uncertainty of option values (OPTUNC): This search rule assumes that option uncertainty drives search. We quantify option uncertainty by the variance of option values, again using a softmax function:
( , , +1 ) = ( * , 2 ) ∑ ( * , 2 ) =1 (D5)
Uncertainty of attribute values (ATTUNC): This search rule assumes that attribute uncertainty drives search. We quantify attribute uncertainty by the variance of attribute values , ,
, ,
, again using a softmax function:
( , , +1 ) = ( * , , 2 ) ∑ ∑ ( * , , 2 ) =1 =1 (D6)
Attribute weights (ATTWEIGHT): This search rule assumes that more important attributes are more likely to be attended to. Once more, we use the softmax rule to link attribute weights to sampling:
( , , +1 ) = ( * ) ∑ ( * ) =1 (D7)
More complex myopic search rule (MYOPIC II): This search rule is similar to MASC's search rule as specified in Equation 4. However, whereas MASC assumes the sampling probability for attribute j of option i to depend solely on the expectation to choose option i, the search rule MYOPIC II assumes the sampling probability to also depend on the expectation to choose any other option (k, l, …) after one more sample. Therefore, the calculation of the myopic search score is more complex as compared to Equation 4 (a more detailed derivation of the search score is provided below):
, , + = ∑ ∫ ( ℎ + 1 | , , +1 = ) * ( , , +1 = ) +∞ −∞ =1 (D8)


Derivation of the extended myopic search rule (MYOPIC II)
As stated above, the MYOPIC II search rule considers the probability of choosing any option (i, k, l, …) when determining the next sample. Therefore, we must take the possibility into account that observing a particularly "bad" (i.e., low-value / negative) sample next could lead to choosing one of these other options. As for the derivation of MYOPIC I (see Appendix A), we simplify this approach by first assuming that there is only one other option (k) and generalize to non-binary decision problems towards the end. In the case of a binary decision, we need to ask what the mean of the value distribution at the next sample, , +1 * , must (at most) be to elicit the choice of k. This leads to Equations D9a-c that differ slightly from A1a-c:
+1 = Φ (0, , − , +1 , √ , +1 2 + , 2 ) ,
(D9a)
, − , +1 = −Φ −1 ( +1 , 0, √ , +1 2 + , 2 ) ,
, +1 * = , + Φ −1 ( +1 , 0, √ , +1 2 + , 2 ) ,
Essentially, D9c differs from A1c only by the sign between the first and the second term on the right side, which changes from minus to plus. Note that the term Φ −1 (… ) will always be negative (as long as +1 < .5, which is always true), so that , +1 * will always be smaller than , +1 , which is plausible as we are looking for a low option value of i that may lead to choosing k.
The resulting option value , +1 * then replaces , +1 in Equation A2c to specify how "bad" the next sample , , +1 * must be to elicit a choice of k. Again, the probability of observing this sample is computed as in Equation A3a, and again, it is straightforward to generalize to more than two choice options now, by taking the highest "bad" sample that is required to elicit a choice (here, the intuition is that we only need to compute the probability of sampling the highest "bad" value, which is still sufficiently low to elicit any choice of k, l, …, because sampling even "worse" values will do so as well). Altogether, the myopic search score of MYOPIC II is calculated as:
, , +1 = Φ ( , , , ) .
Furthermore, equation A3a rather than A3b is used to specify the myopic search score, because option i is not compared to all other options anymore (and instead to an absolute criterion), so that taking the maximum required sample is not necessary anymore.
As stated in the main text, absolute threshold models usually make the extreme prediction that the chosen option must have been fixated last, because only this option gets updated and can thus surpass the absolute criterion (cf. 
Mullett & Stewart, 2016)
. In case of a time-variant threshold as in our case, however, this is not strictly the case anymore, because an option that does not surpass a (stricter) criterion at fixation f might surpass a (more lenient)
criterion at fixation f + 1, even if its value distribution has not been updated. This can lead to cases in which more than one option surpasses the threshold at the same time. In such cases, we assume that the decision maker chooses one of these options randomly. After parameter estimation (using the same methods as reported in the main text), we found that MASC with an absolute threshold predicts the last-fixated option to be chosen in 71% (±6%) of trials across both datasets, which is substantially higher than the actual data (63%; ±6%). Given that MASC with a relative threshold predicts 59% of choices of the last-fixated option, one might speculate that participants used a relative threshold most of the time but sometimes switched to an absolute threshold. However, more systematic tests and additional experiments would be required to substantiate this speculation.
As for MASC with the relative stopping rule, we then performed 1'000 simulations of MASC with the absolute stopping rule for the binary choice set to test how often the model predicts a given effect (i.e., Hypothesis 1 to 7, see main text) to be significant. 
Figure E1
 shows the results of one of these simulations. For brevity, we only depict results of the Hotel dataset in 
Figure E1
, but report the predicted frequency of significant effects for both: H1: Smartphone: 96.8% significant simulations; Hotel: 100% significant simulations H2: Smartphone: 97.1% significant simulations; Hotel: 15.9% significant simulations H3: Smartphone: 99.9% significant simulations; Hotel: 100% significant simulations


Figure E1
Simulations of MASC with absolute stopping rule (n = 2)
Note. Simulations are shown for the Hotel dataset. H1-H7 refer to the seven preregistered hypotheses that are also tested for MASC with a relative stopping rule. Notably, most qualitative patterns are captured by this variant of MASC as well, although some effects are predicted to be stronger than the empirical results would suggest (e.g., H3, H4). On the other hand, the relationship between difficulty and the number of fixations (H2) is weaker than observed in the empirical data with only 15.9% of simulations with the Hotel dataset producing significant effects. This stems from the model predicting relatively small increases in the number of fixations when transitioning from medium to hard trials, compared to from easy to medium trials. Additionally, while the decrease of attention on the most important attribute over time (part of H6) is predicted to be comparatively weak, the effect remains significant across all simulations with both datasets; see text above.
, goodness of fit was then approximated by a set of summary statistics: the proportion of correctly predicted choices, the difference of model-predicted and observed number of fixations per trial (normalized by the participant's highest number of fixations), and the difference of modelpredicted and observed relative proportion of fixations on each attribute of each option per trial.


d = -1.16), in easy compared to hard trials (Smartphone: t(62) = -7.53; p < .001; d = -0.95; Hotel: t(62) = -11.58; p < .001; d = -1.46), and in medium compared to hard trials (Smartphone: t(62) = -3.29; p = .001; d = -0.41; Hotel: t(62) = -5.89; p < .001; d = -0.74) (Figure 3A, right column)


the worse option as indicated by a significantly positive effect of value difference (Smartphone: t(62) = 14.73; p < .001; d = 1.86; Hotel: t(62) = 13.11; p < .001; d = 1.65). This tendency increased over time, as indicated by a significantly positive interaction effect in both datasets (Smartphone: t(62) = 3.30; p < .001; d = 0.42; Hotel: t(62) = 4.59; p < .001; d = 0.58) (


= 8.92; p < .001; d = 1.12; Hotel: t(62) = 7.28; p < .001; d = 0.92), and the coefficient of fixation number was significantly negative, implying that fixations on the most important attribute decreased over time (Smartphone: t(62) = -6.45; p < .001; d = -0.81; Hotel: t(62) = -4.96; p < .001; d = -0.62) (


Figure 8 MASC
8
Parameters and Reward Rate


Figure 10 Simulating
10
Time Pressure with Varying Levels of Search Sensitivity Note. (A) Payne Index as a function of time pressure (i.e., threshold parameter) and search sensitivity; at high levels of search sensitivity, a negative relationship between the Payne Index and time pressure emerges. Variability in the proportion of fixations spent on each attribute (B) and option (C) increases with time pressure. (D) The proportion of attention directed to the most important attribute increases with time pressure.


Based on the ratings of options that participants provided prior to the decision-making task, three sets of binary choice options were created that differed in terms of rating difference and thus choice difficulty (i.e., easy, medium, hard) 6 . As expected (H1), choice consistency varied as a function of difficulty, with participant choosing the better option (defined as a weighted sum of attribute values) more often in easy compared to medium trials (Smartphone: t(62) = 8.11; p < .001; d = 1.02; Hotel:
t(62) = 9.32; p < .001; d = 1.17), in easy compared to hard trials (Smartphone: t(62) = 9.06; p
< .001; d = 1.14; Hotel: t(62) = 16.02; p < .001; d = 2.02), and in medium compared to hard
trials (Smartphone: t(62) = 3.48; p < .001; d = 0.44; Hotel: t(62) = 7.98; p < .001; d = 1.01)
(
).


Accounting for Search Patterns in Previous Research This
section demonstrates how MASC can account for further qualitative decision-making effects observed in the literature and beyond the scope of the experimental paradigm presented here. Specifically, we demonstrate by simulations how the model captures disproportionate relationships between attention and weight, changes in search patterns under time pressure, and the dependency of decision speed on the number and overall value of options. Attribute weights and values for each simulation were sampled using the same method described in the previous section (see Search Sensitivity and Reward Rate) unless stated otherwise.
=
-56.331, p < .001), positively related to the number of fixations (β = 2.345, t(996) = 23.727, p
< .001) and negatively related to reward rate (β = -0.047, t(996) = -43.109, p < .001). Higher
levels of sampling noise lead to less precise updates of posterior beliefs at each fixation. In
turn, choices become less consistent, and more fixations are needed to choose an option,
resulting in decreasing reward rates. Second, larger increases in threshold lead to reduced
choice consistency (β = -1.464, t(996) = -26.225, p < .001) and fewer number of fixations (β =
-139.099, t(996) = -37.536, p < .001). Because the decrease in choice consistency is
outweighed by the reduced number of fixations, larger threshold increases ultimately result in
a higher reward rate (β = 1.077, t(996) = 26.403, p < .001). Finally, and most critically,
increases in the search sensitivity parameter are positively associated with choice consistency
(β = 0.004, t(996) = 8.096, p < .001) and negatively associated with the number of fixations (β
= -0.120, t(996) = -4.058, p < .001), leading to higher reward rates for higher search
sensitivity values (β = 0.003, t(996) = 9.094, p < .001). Thus, the search rule can be
considered being efficient as it positively associated with reward rate by increasing choice
consistency while decreasing the amount of search.


National Science Foundation / Schweizerischer Nationalfonds (SNF; grant no. 100019E_214099 / 1) to S. Gluth and J. Rieskamp, respectively. S. Gluth also acknowledges support by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program (grant agreement no. 948545). The authors thank Arjen Alink for programming the experimental task, Maryam Tohidi-Moghaddam for valuable discussions, Amir Hossein Hadian Rasanan for helpful comments on an earlier version of the manuscript, and Jan Hausfeld for the suggestion to test our theory's predictions of overall value effects.


In the case of binary decisions, however, the model by
Callaway et al. (2021)
 and the (very similar) model by
Jang et al. (2021)
 need to assume that the prior belief distribution is biased towards lower values (i.e., lower than those present in the actual choice set) to predict this correlation of allocated attention and choice probability.


This assumption should be plausible when people are familiar with the attributes they consider, or when participants are informed about the range of attribute values at the beginning of an experiment. In other cases, the assumption might be violated, and , , =0 could be treated as a free parameter. The same applies to , , =0 , which could be a free parameter to model optimistic or pessimistic expectations (cf. Callaway et al., 2021).


Attribute weights could also be taken from regression analyses of the same or a related task. In our experiment, for example, we asked participants to rate each option prior to making decisions and derived attribute weights from the linear regression coefficients of the rating task (see "Model Simulation and Experiment").


For a better comparison of data and model predictions, choice consistency was not defined by the raw ratings of options but on inferring the subjective value of options via linear regression analysis (note that the regression coefficients of this analysis were also used to define the attribute weights in the model).


This allows us demonstrating that MASC can also be applied to "simple" decisions without multiple attributes such as choosing which cloud of dots contain more dots
(Sepulveda et al., 2020)
 or which snack food is preferred
(Gluth et al., 2020;
Krajbich et al., 2010)
, by simply collapsing the model's attribute and option levels into a single "integrated value" level.


After all, the task is not only to perceive a number but to evaluate it in the context of the range and distribution of possible numbers in the entire set of options. For instance, the decision maker does not only need to perceive that a smartphone has 64 GB memory but also to evaluate how competitive this number is on the current "market".


When implementing a time-variant threshold (similar to decreasing bounds in SSM), MASC with an absolute threshold can predict that the last-fixated option is not always chosen. However, the model still predicts it to be chosen too often (~75% of trials; for details, see Appendix E). 11 MASC also uses a different termination rule. It is based on comparing the overlap of value distributions with some threshold, which is a free parameter in the model. In contrast, the economic models assume some form of


In the current study, the Payne Index is expected to be positive, as there are more attributes than options, so that more within-option than within-attribute transitions can be made (2 vs. 1)
(Böckenholt & Hynan, 1994)
. Nevertheless, the empirical Payne Index in our study is significantly higher than the chance-level Payne Index of 1/3 (Smartphone: M = .39, SD = .15, t(64) = 3.21, p = .002, d = 0.40; Hotel: M = .38, SD = .16, t(64) = 2.55, p = .013, d = 0.32), indicating a preference for option-wise search. Similarly, the SM Index
(Böckenholt & Hynan, 1994)
, which directly accounts for the dependency of transitions on the number of alternatives and attributes, is significantly positive (Smartphone: M = 0.72, SD = 0.62, t(64) = 9.39, p < .001, d = 1.16; Hotel: M = 0.67, SD = 0.64, t(64) = 8.67, p < .001, d = 1.08), again suggesting option-wise search to dominate in our datasets.


Which option the "strongest competitor" is, does not only depend on the options' means but also their variances. In case of three options, for example, the option with the (currently) lowest mean might still be a stronger competitor to the best option than the option with the second-highest mean, if the lowest option has a much higher variance. Therefore, it is not sufficient to just compare option i with the alternative that has the highest mean value. Instead, applying Equation A2c reveals what the strongest competitor is.








Acknowledgements
This work was supported by a collaborative research grant, funded by the German Research Foundation / Deutsche Forschungsgemeinschaft (DFG; grant no. GL 984/1-1) and the Swiss






Appendix A


Derivation of the Myopic Search Rule
Equation 4 in the main text provides only a high-level intuition for computing the myopic search score , , +1 . In the following, we derive a closed-form solution for this score in detail. To simplify things, we will work with the special case of n = 2 options (i vs. k) for most of the time, as the generalization to more than two options is straightforward and will become evident towards the end of the solution.
First, recall that Equation 3 specifies the choice (or termination) rule of MASC and states that option i is chosen as soon as its value belief distribution is sufficiently higher than the corresponding distribution of the competing option k, which is quantified by comparing the distribution overlap with the threshold parameter . When looking one sample ahead (and considering sampling attribute j of option i), the relevant question to ask is what the updated value distribution of option i would need to be to make the distribution overlap lower than +1
and thus to elicit the choice of i. Recall that the value belief distribution depends on the mean and variance , and , 2 , which are updated according to Equation 2a and 2b, respectively.
While updating the mean depends on the actual (and currently unknown) sample, the change in variance is independent of the sample and can be directly computed based on Equation 2b (and 1b, on which 2b is built). Therefore, the question reduces to asking what the mean of the value distribution at the next sample, , +1 , must (at least) be to elicit the choice of i. We get this value by inverting Equation 3 and solving for , +1 :
where Φ −1 ( , , ) refers to the value of the inverse CDF of the normal distribution with mean M and standard deviation SD at probability p.
Knowing the minimum option value , +1 that is required to elicit a choice, the next step is to derive the value of the attribute sample , , +1 that results in this option value. To do so, we work backwards from the option level to the attribute level. First, we isolate the contribution of the considered attribute j in specifying the option value according to Equation 2a:
Next, we plug Equation 1a, which gives us the updated attribute mean , , +1 , into Equation A2a and solve for , , +1 :
Note that this equality only holds if all weights are positive (i.e., > 0 for all i), because a negative but very small (e.g., -10 -10 ) in the denominator at the beginning of the bracket will lead to a high negative value of , , +1 , which would suggest that virtually any future sample is expected to elicit a choice. In our own study, we thus multiplied negative regression coefficients and their corresponding attribute values of the Smartphone or Hotel data by -1 to enforce positive weights (see main text), and we recommend adopting this approach in future applications of MASC.
Knowing the minimum sample value , , +1 that is required to elicit a choice, the last step is to compute the probability that such a value (or higher) will be sampled. This probability simply depends on attribute j's current mean , , and precision , , :
)
. 
A3a
When n > 2, a choice is only made if an option is believed to be sufficiently better than all other options. In this case, one can compute , , +1 via Equations A1c and A2c for all pairwise comparisons of option i against option k, …, n and then take the highest sample among these comparisons. The intuition is that if a sample is sufficiently high to make option i better than its strongest competitor, it must also be sufficiently better than all other competitors 13 . Thus, Equation A3a generalizes to:
)
. 
A3b
To summarize, Equation A1c is used to compute the minimum required option values, which are then plugged into Equation A2c to compute the minimum required samples, which are then plugged into Equation A3b to compute the myopic search score of sampling attribute j of option i next. This must be done for all attributes and options before proceeding with Equation 5a.


Appendix B Parameter Recovery Analysis
A simple parameter recovery analysis was performed by taking the estimated parameter values of the 63 participants, simulating their decisions again, and then reestimating the parameters of MASC using the procedures described in the main text. We simulated the parameter recovery study 100 times for each dataset to assess variability in the correlation between the true and the recovered parameters. 
Figure B1
 shows the distributions of these correlation coefficients for each parameter for both datasets. The sampling noise and threshold increase parameters were recovered very well, the recovery results of the search sensitivity parameter were still acceptable for our current purposes (all correlations were significant at p < .001).


Figure B1
Variability in the Correlation of True and Recovered Parameters
Note. The upper row refers to the Smartphone dataset, the lower row to the Hotel dataset and represents the mean correlation across all 100 simulations.


Appendix C Predictions of MASC for Multi-Alternative Decisions
In the main text, we compare the predictions of MASC with data from a choice task with n = 2 options and m = 3 attributes. Here we show that the qualitative predictions the model makes also hold for cases of decisions with more than two options. Specifically, we created sets of n = 4 options (and m = 3 attributes) by using all trials of all participants from our eye-tracking experiment and adding two more options to each trial by sampling randomly from all options in the hotel and smartphone sets (which in total included 30 options each).
Note that for decisions with n > 2 options, we define difficulty as the difference between the best and next best option as determined by the value ratings and weights. As for the binary choice set, we then performed 1'000 simulations of MASC for the 4-alternative choice set to test how often the model predicts a given effect (i.e., Hypothesis 1 to 7, see main text) to be significant. Notably, we thus used the same parameter values as for the binary choice set, demonstrating that MASC makes reasonable predictions for choice sets of different sizes with the same set of parameters. 
Figure C1
 shows the results of one of these simulations. For brevity, we only depict results of the Hotel dataset in 
Figure C1
, but report the predicted frequency of significant effects for both: H1: Smartphone: 100% significant simulations; Hotel: 100% significant simulations H2: Smartphone: 88.5% significant simulations; Hotel: 100% significant simulations H3: Smartphone: 100% significant simulations; Hotel: 100% significant simulations H4: Smartphone: 95.4% significant simulations; Hotel: 94.9% significant simulations H5: Smartphone: 100% significant simulations; Hotel: 98.9% significant simulations H6: Smartphone: 100% significant simulations; Hotel: 100% significant simulations H7: Smartphone: 100% significant simulations; Hotel: 100% significant simulations Appendix D


Specification of Alternative Search Rules
In the following, we formally specify the eight alternative search rules which we tested against the proposed myopic search rule of MASC.
Random search with refixations (RAND I): This search rule assumes that all attributes are equally likely to be sampled next (including the currently sampled attribute). Formally, in case of n options and m attributes, the sampling probability is:
Random search without refixations (RAND II): This search rule is the same as RAND I, with the exception that the currently sampled attribute cannot be sampled directly again. For the remaining attributes, the sample probability becomes:
Accumulated option values (OPTVAL): This search rule assumes that the probability to sample an attribute is a function of the current mean of the value distribution of the option to which the attribute belongs. A softmax rule is used to link option values and sampling probability:
Accumulated attribute values (ATTVAL): This search rule assumes that assumes the sampling probability to depend on the current mean of each attribute value distribution, again using a softmax rule as linking function:


MASC Variant with Absolute Decision Threshold
As discussed in the main text, MASC uses a relative decision threshold as termination rule by comparing the overlap of the value distribution of the best option with all other options to some threshold. Here, we tested a variant of MASC that implements an absolute threshold.
More specifically, we assumed that the decision maker terminates the decision when the value distribution of an option exceeds some threshold abs,1,f with some probability abs,2, or in other words, 1 -abs,2 percent of the value distribution of option i must be larger than abs,1 to elicit the choice of i. To make the model as comparable as possible to the MASC variant with a relative threshold (for which we fixed the initial threshold =0 to .01 but treated the threshold increase Δ as a free parameter; see main text), we fixed abs,2 to .01 and the initial abs,1,f=0 to 0 but allowed abs,1,f to decrease over time and used this threshold decrease abs as a free parameter (using 31 different, equidistant values from 0 to .27 for the grid search). To give an example, if abs = .18, the decision maker checks whether 99% of the value distribution of any option is larger than 0 after the first fixation, but after the second fixation, the decision maker checks whether 99% of the value distribution of any option is larger than -.18, thus becoming more lenient in accepting an option over time.
We used MASC's myopic search rule to determine the next fixation. However, the rule needs to be adjusted to the absolute threshold variant, because the anticipation of which next sample is most likely to elicit a decision depends on the termination rule. Technically, the adjustment affects the specification of the option value , +1 that would be required after one more sample to elicit a choice of option i. Thus, equation A1c was changed to:
,1, +1 − Φ −1 ( ,2 , 0, , +1 ) (E1)
 










Individual risk attitudes arise from noise in neurocognitive magnitude representations




M
Barretto-García






G
De Hollander






M
Grueschow






R
Polanía






M
Woodford






C
C
Ruff




10.1038/s41562-023-01643-4








Nature Human Behaviour




7


9
















Rigorously testing multialternative decision field theory against random utility models




N
A J
Berkowitsch






B
Scheibehenne






J
Rieskamp




10.1037/a0035159








Journal of Experimental Psychology. General




143


3
















Caveats on a process-tracing measure and a remedy




U
Böckenholt






L
S
Hynan




10.1002/bdm.3960070203








Journal of Behavioral Decision Making




7


2
















The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks




R
Bogacz






E
Brown






J
Moehlis






P
Holmes






J
D
Cohen




10.1037/0033-295X.113.4.700








Psychological Review




113


4
















Bidirectional influences of information sampling and concept learning




K
Braunlich






B
C
Love




10.1037/rev0000287








Psychological Review




129


2
















Sources of confidence in value-based choice




J
Brus






H
Aebersold






M
Grueschow






R
Polania




10.1038/s41467-021-27618-5








Nature Communications




12


1














The intolerance of uncertainty scale: Psychometric properties of the English version




K
Buhr






M
J
Dugas




10.1016/S0005-7967(01)00092-4








Behaviour Research and Therapy




40


8
















Cognitive and neural bases of multi-attribute, multi-alternative, value-based decisions




J
R
Busemeyer






S
Gluth






J
Rieskamp






B
M
Turner




10.1016/j.tics.2018.12.003








Trends in Cognitive Sciences




23


3
















Psychological models of deferred decision making




J
R
Busemeyer






A
Rapoport




10.1016/0022-2496(88








Journal of Mathematical Psychology




32


2
















Decision field theory: A dynamic-cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend








Psychological Review




100


3
















Optimal nudging for cognitively bounded agents: A framework for modeling, predicting, and controlling the effects of choice architectures




F
Callaway






M
Hardy






T
L
Griffiths




10.1037/rev0000445








Psychological Review
















Fixation patterns in simple choice reflect optimal information sampling




F
Callaway






A
Rangel






T
L
Griffiths




10.1371/journal.pcbi.1008863








PLOS Computational Biology




17


3














Rational use of cognitive resources in human planning




F
Callaway






B
Van Opheusden






S
Gul






P
Das






P
M
Krueger






T
L
Griffiths






F
Lieder




10.1038/s41562-022-01332-8








Nature Human Behaviour




6


8
















Reversing the similarity effect: The effect of presentation format




A
M
Cataldo






A
L
Cohen




10.1016/j.cognition.2018.02.003








Cognition




175
















Eye tracking and pupillometry are indicators of dissociable latent decision processes




J
F
Cavanagh






T
V
Wiecki






A
Kochar






M
J
Frank




10.1037/a0035813








Journal of Experimental Psychology: General




143


4
















Decisions in changing conditions: The urgency-gating model




P
Cisek






G
A
Puskas






S
El-Murr




10.1523/JNEUROSCI.1844-09.2009








Journal of Neuroscience




29


37
















Improving out-of-sample predictions using response times and a model of the decision process




J
A
Clithero




10.1016/j.jebo.2018.02.007








Journal of Economic Behavior & Organization




148
















Goals, usefulness and abstraction in value-based choice




De
Martino






B
Cortese






A




10.1016/j.tics.2022.11.001








Trends in Cognitive Sciences




27


1
















The dynamics of decision making in risky choice: An eye-tracking analysis




S
Fiedler






A
Glöckner




10.3389/fpsyg.2012.00335








Frontiers in Psychology
















A multiattribute attentional drift diffusion model




G
Fisher




10.1016/j.obhdp.2021.04.004








Organizational Behavior and Human Decision Processes




165
















The Obsessive-Compulsive Inventory: Development and validation of a short version




E
B
Foa


"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]