You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



People commonly encounter probabilistic outcomes in their daily lives. Decisions about one's finances, health, and occupation all entail accepting and managing risks. While psychologists have long been interested in how people approach such risks, little research has explored how people think about and value improving the chances that a risk produces a positive outcome. This is puzzling, as many risky decisions are improvement decisions (e.g., a student deciding whether to expend additional time studying to improve the chances that they pass an exam). The current research finds that people make these improvement decisions by considering how they would feel if they were to obtain a bad outcome. This leads to suboptimal lay and expert decisionmaking in a variety of consequential contexts (e.g., medicine and finance).
Many decisions involve choosing whether or not to invest money, time, or effort to improve the chances of obtaining a positive outcome. Executives determine how much budget to allocate to sales-boosting campaigns, students decide how many hours to spend studying to improve their chances of passing an exam, and intelligence analysts evaluate costly initiatives designed to reduce the likelihood of terrorist attacks. Because money, time, and effort are limited, such improvement decisions are consequential: Investing resources in one improvement often means neglecting others.
While these improvement decisions are common, little research investigates how people make them. Of course, a large literature in psychology and economics examines how people think about and value risky prospects (e.g., people's valuation of a 30% chance of a reward; see 
Mata et al., 2018)
. In turn, it seems straightforward to assume that valuations of an improvement (e.g., going from a 30% to 40% chance of a reward) are roughly equivalent to the difference in the valuations of two individual prospects (e.g., the difference between the valuation of a 30% chance of a reward and the valuation of a 40% chance; see 
Wu & Gonzalez, 1996)
. However, a recent paper 
(Lewis & Simmons, 2020)
 shows that people often prefer improving their chances of success when those chances are already high. The authors argue that this is because people weigh the expected final outcome in addition to the improvement itself (prospective outcome bias).
This manuscript proposes a new psychology of how people make improvement decisions.
The literature on regret informs our expectations (e.g., 
Loomes & Sugden, 1982;
Zeelenberg, 1999)
. Regret arises when people compare a realized outcome to a superior counterfactual alternative that they could have obtained had they acted differently 
(Bleichrodt & Wakker, 2015;
Loomes & Sugden, 1982)
. Because experiencing regret is aversive, people work to minimize the regret they anticipate feeling for their actions 
(Zeelenberg, 1999)
. While regret is typically studied when people choose between options, regret might also emerge when people consider whether to improve their chances of success. For example, someone might ask "if I forego studying tonight, will I regret that decision when it turns out I didn't pass my exam?". The more they anticipate regretting not studying, the more they would value spending the night studying.
An improvement decision should be evaluated based on how much it increases one's chances of success. However, we believe that people's anticipation of regret is biased, leading them to diverge from this evaluation. 
Figure 1
 illustrates our proposed logic.


Figure 1


Bad Outcomes Eliminated by the Same Improvement with Different Initial Chances of Success
Regret is based on how much one could have done to prevent a bad outcome from occurring 
(Zeelenberg & Pieters, 2007)
. So, in cases where people consider making an improvement to their chances of success, they are assumed to consider the regret they might feel for foregoing an improvement when that improvement would have mattered (i.e. when it prevents a loss). In 
Figure 1
, panel A and B are schematic representations of two example situations in which a decision-maker can improve their chances of a good outcome by 10 percentage points (p.p.). In panel A, someone can improve their chances of success from 80% to 90%. In panel B, someone can improve their chances of success from 10% to 20%. In both cases, the actual improvement is 10 p.p.; therefore, the two improvements should be considered to have equal value if decision-makers are considering each improvement's effect across all outcomes.
Here, we build on existing literature, and argue that instead of evaluating these improvements in relation to the total set of outcomes (i.e., across all outcomes), people evaluate these improvements purely by the proportion of bad outcomes eliminated. 
Figure 1
 displays how the improvement in panel A prevents 50% of the bad outcomes; in panel B, the improvement only prevents 12% of the bad outcomes. If people consider how much an improvement matters purely among the set of bad outcomes rather than all outcomes (e.g., 
Baumeister & Vohs, 2001
), they will drastically overestimate regret for situations in which they already have a high chance of success relative to those where they have a lower initial chance of success. Essentially, we propose that people evaluating improvements attend to the wrong denominator, and only evaluate improvements in relation to bad outcomes, rather than in relation to all outcomes. This prediction deviates from existing theories of risky decision making (see 
Table 1
).  
(Kahneman & Tversky, 1979)
 People evaluate probabilities subjectively resembling an inverse s-shape Slight increase in valuations of improvements with very low and very high initial probabilities


Table 1


Implied Predictions of Valuations of Improvements by Relevant Theories
A very flat u-shape Regret Theory 
(Loomes & Sugden, 1982)
 People evaluate probabilities subjectively, and in addition value outcomes by how they compare to alternative outcomes Similar to prospect theory, but an overall higher value A very flat u-shape with a slightly higher intercept than Prospect Theory Risk as uncertaintyaversion 
(Rothschild & Stiglitz, 1978)
 People are not averse to risk, just uncertainty/variance Low initial probabilityimprovements increase variance, high initial probability increases decrease variance A linearly increasing slope


Prospective
Outcome Bias 
(Lewis & Simmons, 2020)
 People evaluate the improvements as well as the final outcome
Valuation of improvements is a weighted function of improvement and final outcome A linearly increasing slope with a higher intercept than Risk as uncertainty-aversion


Conditional Regret
People evaluate improvements by focusing on the relative reduction in bad outcomes


Valuation of improvements represent the proportion of negative outcomes eliminated
A convex function that is much steeper at higher probabilities * This column describes the shape of the valuations implied by this theory for a set improvement (e.g. a 10 p.p. increase in winning chances) across the full range of possible initial probabilities of success from >0% to <100%. The convex function implied by Conditional Regret theory is illustrated in 
Figure 2
. A more detailed discussion of these theories can be found in the Supplementary Materials, Section 4.
If people's valuations of improvements are indeed biased by considering primarily the relative reduction in bad outcomes (rather than overall impact), several predictions logically follow. First, the same improvements (e.g., 10 p.p. improvements) will be valued considerably more when they reduce a greater proportion of bad outcomes. Therefore, we hypothesize that a convex pattern of valuations of improvements will emerge across the range of initial probabilities (see 
Figure 2
). Importantly, this convex pattern-and our suggestion that people focus on the proportion of bad outcomes improvements eliminate-can be empirically distinguished from predictions implied by existing models (see 
Table 1
). Second, because we believe these biased valuations emerge from the regret one anticipates experiencing upon obtaining a bad outcome, we expect them to behave differently than typical decision biases. Specifically, many decision-making biases arise from people employing mental shortcuts or heuristics (i.e., System 1 processing, see 
Evans & Stanovich, 2013
). Consequently, increasing deliberation 
(Kahneman & Frederick, 2002)
 or motivation 
(Petty et al., 1981)
 typically attenuates or even eliminates these biases, reducing their effect in weightier decisions (e.g., 
Chaiken, 1980)
. Regret, on the other hand, is an emotion in which one blames oneself for obtaining an inferior outcome. The more important the outcome, the more self-blame people feel 
(Zeelenberg & Pieters, 2007)
. Therefore, interventions that typically reduce decision biases-such as increasing outcomes' importance-may actually increase the bias we document.
Finally, if people indeed overvalue improvements in situations with higher initial chances of success, it implies that people will invest resources suboptimally, preferring to increase their chance of success slightly in situations where they were already likely to succeed (e.g., improving a 90% chance of a reward to 95%) rather than more dramatically increasing their chances of success for less likely outcomes (e.g., improving a 10% chance to 20%).
Eleven studies investigate how people value improvements. We first report a pilot study confirming that participants approach improvements differently than static risks. Studies 1a-1g test if participants' valuations of improvements follow the hypothesized convex pattern 
Figure 2
 depicts. Studies 2a-2b explore anticipated regret's role as the process underlying these valuations. Finally, Study 3 examines how lay and expert decision-makers make suboptimal choices when deciding between improvements.


Open Practices Statement
The Supplementary Materials detail additional analyses and exploratory measures. All studies-except the Pilot Study and Study 1a-were preregistered. All data, materials, preregistrations, and analysis scripts are available at:
https://osf.io/acvrn/?view_only=139ea21a8fc14dbbbca9248246286945. Since we did not know the expected effect-size ex-ante and cared about precision in our estimates, we typically preregistered collecting approximately 100 participants per cell for within-subject estimates, and 400 per cell for between-subject comparisons.


Pilot Study
First, we report a pilot study testing if people treat improvements differently than static risky outcomes.


Method
Participants and design. 227 Americans (Mage = 38.5, 45% female, 43% male, 11% did not respond) were recruited from Amazon Mechanical Turk in exchange for payment. We intentionally used very strict exclusion criteria for this pilot study to ensure that we would not inadvertently interpret participant misunderstanding as a meaningful effect. If inattentive participants misunderstood an improvement from 20% to 30% chance of winning to $10 as "a 30% chance of winning $10" we would document a positive, linear, slope that would not actually represent the valuation of improvements but merely reflect participants misunderstanding the question. Specifically, participants had to answer a total of eight questions correctly; in total, 130 participants failed to do so. Analyzing results without these exclusions does not change the pattern of results or their statistical significance.
The design was fully within-subjects. Each participant completed two sets of trials. In one set, participants completed 12 trials where they indicated their willingness-to-pay to enter $10 lotteries (enter condition) as well as an attention check trial asking their willingness-to-pay to enter a lottery with a zero percent chance of winning. In another set, participants completed 11 trials where they indicated their willingness-to-pay to change their chances of winning $10 lotteries (change condition), as well as three attention check trials asking willingness-to-pay for a zero percentage point change. The probabilities of these trials were yoked together so that for each change trial, there were two enter trials, one of which asked willingness-to-pay to enter a lottery at the initial probability in the change trial, and the second of which asked willingness-to-pay to enter a lottery at the higher probability which participants could improve their chances to in the change trial. For example, in one of the change trials, participants were asked their willingness-to-pay to change their chances of winning a $10 lottery from 10% to 20%. In the enter trials, the same participants also indicated their willingness-to-pay to enter two separate lotteries -one with a 10% chance to win $10 and one with a 20% chance to win $10. If there is nothing special about improvement decisions and they are treated the same as static risks, then we would expect participants' valuations of changing their chances from 10% to 20% to be roughly equivalent to the difference in their valuations of entering lotteries with 10% and 20% chances of winning.


Results
Figure 3 makes clear how improvements are treated very differently than (mathematically equivalent) static risky prospects. The flat green line reveals that participants' implied valuation of each improvement was roughly similar across all initial probabilities. That is, the gap between participants' valuations of two individual risks did not change across the full spectrum of initial probabilities. However, the convex pattern of the purple line in 
Figure 3
 suggests that valuations of improvements appear to follow our model's predictions, such that valuations increase more and more as the initial probability of winning goes up. Next, we turn to studies designed to test for this convex pattern more thoroughly. Note. Participants' mean willingness-to-pay for explicit (purple line) and implied (green line) improvements in the Pilot Study. Error bars are +/-1 SE.


Studies 1a-g
Studies 1a-g all involved participants indicating their valuations of improvements, using a variety of stimuli, methods, and measures for generalizability. We predicted that regardless of the elicitation method, number of trials, or probabilities sampled, a convex pattern of improvement valuations would emerge.


Method
Participants and design. In total, we conducted seven different studies, Studies 1a-1g.
Participants in Studies 1a-c, 1e, and 1g were Americans recruited on Amazon Mechanical Turk (AMT; employing the Cloud Research approved sample). Participants in Study 1d and 1f were undergraduate students at a large American public university. All studies consisted of a series of trials in which participants indicated their valuation of an improvement (e.g. "How much are you willing to pay to change a 50% chance of winning $10 to a 60% chance of winning $10").
Between studies, we varied different features of the design (see 
Table 2
). Depending on the study, participants completed between 16 and 43 trials. In each trial, participants had an initial probability of winning $5 or $10 (the specific amount varied across studies). Participants indicated how much they were willing to pay (or, in Study 1g, how many captchas they were willing to solve) to increase their chance of winning by ten percentage points (p.p). Some studies asked about a limited set of initial probabilities (e.g., initial probabilities from 10% to 90%, in 10 p.p. increments), while others were more expansive (asking about 32 improvements, with many non-round initial probabilities). Outcomes of some studies were hypothetical, while others were fully incentive-compatible (via the BDM procedure, 
Becker et al., 1964)
. Unlike the other studies, Study 1c also measured valuations of 5 p.p. increases. Results for these trials are reported in the Supplementary Materials; these trials followed a similar convex pattern as the 10 p.p. increases. Participant demographic information for each of these studies is in the Supplementary Materials, along with information on Supplemental Study 2. This study replicated the design of Studies 1a-g, but with a much larger winning outcome (gaining $1,000), and a bad outcome which was a loss (losing $5). It found results similar to Studies 1a-g. We were concerned that participants might misunderstand the study instructions and give their valuation of the final lottery after the improvement was applied, as opposed to the improvement itself. To prevent this misunderstanding, we used extremely strict (preregistered) exclusion criteria. In all of Studies 1a-1g, participants completed two attention check trials where the improvement gave no benefit (i.e., it was zero p.p.). Participants who failed this check were excluded. Each study also included comprehension questions which asked participants to display an understanding of the consequences of their choices; participants who answered these questions incorrectly were also excluded. Analyses including all respondents-which are consistent with what we report in the main text-can be found in the Supplementary Materials.


Results
Figure 4 presents participants' mean willingness-to-pay for 10 percentage point improvements. The initial probability of winning each lottery is plotted on the x-axis. For example, the values at 60% represent participants' mean willingness-to-pay to increase their chances of winning $10 from 60% to 70%. As hypothesized, when changes in chances begin to reduce the proportion of bad outcomes more dramatically, participants' valuations of such chances rapidly increase. To test our hypothesis more formally, we compared a model which contained a predictor for the relative reduction in bad outcomes (which we term the conditional regret model) against models that follow from alternative theories (see 
Table 1
). Specifically, we used mixed effects linear regressions with random intercepts by participant, and regressed willingness-to-pay onto the absolute size of the improvement. The conditional regret model added an additional predictor for the relative reduction in bad outcomes from the change, the prospective outcome bias model instead added an additional predictor for the final chances of winning after the change, and the model for regret theory and other alternate models had no additional predictors. In all of 1a-1g, the conditional regret model best fit the data (see 
Table 2
).
Of course, these model comparisons only tell us which model was best in predicting the valuations of the improvement decisions we studied. We are not arguing that Prospect Theory, or any of the other candidate theories are inappropriate for predicting risky decision-making outside of improvement decisions. Full information on robustness checks-as well as additional model comparisons-can be found in the Supplementary Materials.
Moreover, the convex pattern depicted in 
Figure 4
 is particularly notable when one considers that Studies 1a-1g all have a fully within-subjects design. Specifically, many participants displayed very different valuations of the same (10 p.p.) improvements. For example, in Study 1d, all trials improved participants' chances of winning $5 by 10 p.p. (i.e., an expected value of $0.50). However, participants behaved risk-averse below initial probabilities of 60% (e.g., participants were willing to pay an average of $0.24 (SE = .04) to change a 10% chance of winning $5 to a 20% chance), and risk-seeking above initial probabilities of 60% (e.g., those same participants were willing to pay an average of $0.71 (SE = .06) to change an 80% chance of winning $5 to a 90% chance). In other words, the same participants-within the same context and using the same measures-displayed both an affinity for and an aversion to identical risky improvements. however conflict with the notion that risk-preferences are only based on individual differences (e.g., 
Cohen & Einav, 2007)
 or solely the result of an interaction between the decision context and individual differences 
(Frey et al, 2017
, L'Haridon, O. & Viedier, 2019
. and found that people indeed follow this predicted convex pattern. However, we have not directly tested the hypothesized conditional regret-based process which creates this pattern.
Studies 2a and 2b were employed as tests of this underlying mechanism.


Study 2a
Study 2a's framing manipulation tests our theory's assumption that people naturally focus on the relative proportion of bad outcomes eliminated by an improvement.


Method
Participants and design. 2,421 Americans (Mage = 33.0, 49% female, 49% male, 1% did not respond) were recruited from Prolific Academic in exchange for payment. 91 Participants who failed a preregistered attention check were excluded from analyses. Participants were randomly assigned to one of six between-subjects conditions in a 2(initial probability: 20% or 80%) X 3(frame: neutral, proportional increase, proportional decrease) full-factorial design. In the 20% [80%] initial probability condition, participants read that they had a 20% [80%] chance of winning $10.00 and that they had the opportunity to increase their chances of winning by 10 percentage points (see 
Figure 5
 for a stylized depiction of the instructions). In all conditions, participants used a $0 to $3.00 slider to indicate their willingness-to-pay to increase their winning chances.
Between-subjects, we also varied what aspect of the improvement was emphasized to participants. In the neutral frame condition participants were presented with the improvement depicted solely in terms of percentage points. If people naturally focus on bad outcomes when considering improvements, a framing manipulation which draws attention to bad outcomes should minimally affect valuations of improvements relative to this neutral frame. To test this, in the proportional decrease frame condition, participants read that a 10 percentage point improvement would decrease their chances of losing by 1/2 (in the 80% condition) or 1/8 (in the 20% condition). In contrast, a framing manipulation which draws attention to good outcomes should attenuate-or even reverse-the bias we have documented thus far. Thus, in the proportional increase frame condition, participants read that a 10 percentage point improvement would increase their chances of winning by 1/8 (in the 80% condition) or 1/2 (in the 20% condition).


Figure 5
Information Presented by Condition, Study 2a


Results
We submitted participants' willingness-to-pay to a 2(initial probability: 20% or 80%) X 3(frame: neutral, proportional increase, proportional decrease) ANOVA. This revealed a main effect of initial probability, F(1, 2324) = 20.05, p < .001, η 2 = .009. In other words, participants valued changing an 80% chance of winning $10 to a 90% chance more than they valued changing a 20% chance of winning $10 to a 30% chance. However, as 
Figure 6
 reveals, this pattern varied across the three framing conditions. A significant Initial Probability X Frame interaction confirmed this, F(2, 2324) = 4.34, p = .013, η 2 = .004.
In the neutral condition, participants were willing to pay more to change an 80% chance of winning $10 to a 90% chance (M = $0.90, SD = $0.75) than to change a 20% chance of winning $10 to a 30% chance (M = $0.74, SD = $0.66), t(804) = 3.17, p = .002, d = 0.22, 95% CI [0.08, 0.36]). This pattern also appeared in the proportional decrease condition. When improvements were framed in terms of the relative reduction in losing outcomes, participants valued changing the 80% chance to a 90% chance (M = $1.01, SD = $0.79) more than they valued changing the 20% chance to a 20% chance (M = $0.78, SD = $0.69, t(762) = 4.15, p <
.001, d = 0.30, 95% CI [0.16, 0.44]). Crucially, there was no significant interaction between the neutral and proportional decrease conditions, F(1, 1566) = 0.80, p = .371, η 2 = .001.
However, as the rightmost bars in 
Figure 6
 reveal, the proportional increase frame produced a different pattern of results. In this condition, there was no difference in valuations between the 20% (M = $0.86, SD = $0.69) and 80% initial probability gambles (M = $0.87, SD = $0.67, t(748) = 0.28, p = .780 d = 0.02, 95% CI 
[-0.12, 0.16]
). This attenuation was confirmed by a significant interaction between the neutral and proportional increase conditions, F(1, 1562) = 4.21, p = .040, η 2 = .003. Unsurprisingly, there was also a significant interaction effect between the proportional increase and proportional decrease conditions, F(1, 1520) = 8.26, p = .004, η 2 = .005.
In sum, while a manipulation which prompted participants to consider the relative reduction in bad outcomes did not significantly alter the effect of initial probability on valuations of improvements, a parallel manipulation which instead prompted participants to consider good outcomes eliminated this effect. This pattern is consistent with people naturally evaluating improvements by focusing on the relative reduction in bad outcomes. 


Study 2b
Study 2b serves as another test of process. Regret is an emotion people experience when they believe their outcomes would have been better had they acted differently. Thus, decisions that are more important or more consequential typically result in greater regret. If regret underlies the bias in improvement decisions we document, making a decision's outcomes more impactful should amplify these effects -a prediction unique to a regret-based phenomenon.
Alternatively, if the biases we document are due to System 1 processing, making outcomes more impactful should instead attenuate the effect through increased motivation and/or deliberation (e.g., 
Chaiken, 1980)
.


Method
Participants and design. Participants were 1,607 Americans (Mage = 38.2, 52% female, 47% male, 1% non-binary) recruited from Amazon Mechanical Turk. We excluded 19
participants who failed a preregistered attention check. All participants were randomly assigned to one of four between-subjects conditions in a 2(initial probability: 60% or 10%) X 2(consequences: mild or severe) full-factorial design.
Participants began by reading that they had the opportunity to purchase a pill which would reduce their risk of getting a seasonal cold (a negative potential outcome, unlike the previous studies). Our first manipulation varied participants' initial probability of catching the cold. In the 60% [10%] initial probability condition, participants read that they had a 60% 
[10%]
 chance of catching the cold, and that if they purchased and consumed the pill, they would instead have a 50% [1%] chance of getting the cold.
A second manipulation varied the consequences of catching the cold. The cold's symptoms were described to participants as being either mild (and lasting one week) or severe (and lasting three weeks). After reading about the cold, the likelihood of catching it, and the pill (see 
Figure 7
 for a stylized depiction of the instructions), participants provided their willingnessto-pay for the pill. Willingness-to-pay was elicited on a slider scale ranging from $0.00 to $100.00. Participants also completed a series of exploratory measures which asked how much regret they would anticipate experiencing if they did not purchase the pill and did catch the cold.
We discuss these measures in complete detail in the Supplementary Materials. Information Presented by Condition, Study 2b


Results
We submitted participants' willingness-to-pay for the pill to a 2(initial probability: 60% chance or 10% chance) X 2(consequences: severe or mild) ANOVA. This revealed an expected main effect of Consequences, F(1, 1584) = 57.51, p < .001, η 2 = .035, indicating that participants' willingness-to-pay was higher when the cold carried more severe symptoms.
Furthermore, there was a main effect of Initial Probability, F(1, 1584) = 82.89, p < .001, η 2 = .050; participants valued the pill more when it eliminated a larger proportion of bad outcomes.
Crucially, these two main effects were qualified by the predicted Consequences X Initial Probability interaction, F(1, 1584) = 12.88, p < .001, η 2 = .008 (see 
Figure 8)
. When the cold's symptoms were mild, participants were willing to pay more for the pill when it reduced their chances of getting sick from 10% to 1% (M = $14.60, SD = $16.45) than they were when it reduced their chances of getting sick from 60% to 50% (M = $9.71, SD = $14.29), t 
794
 Study 2b found that increasing the severity of a bad outcome increased the extent to which participants were sensitive to the relative reduction in bad outcomes. In addition, exploratory analyses-detailed in the Supplementary Materials-highlight how Study 2b's measures of anticipated regret followed a similar interaction pattern as the willingness-to-pay measures in 
Figure 8
. Taken together, these patterns are consistent with our suggestion that participants value improvements by considering the extent to which they would regret realizing a bad outcome.
In sum, Studies 1a-2b found that people value improvements more when they are tethered to higher probabilities than lower probabilities. This fact implies that people may choose objectively inferior improvements over better alternatives. In Study 3 we test for these potential effects on choice.


Figure 8
Mean WTP for a Pill to Reduce Chances of Catching a Cold Note. Points show mean willingness-to-pay for a pill which would decrease participants' chances of catching a cold in Study 2b. Violin plot outlines illustrate estimated probability density, i.e. the width at each point reflects the proportion of the data there. Error bars are +/-1 SE.


Study 3
The convex function of valuations implies that decision-makers may prefer smaller improvements to high initial probability outcomes over more substantial improvements to low probability outcomes. Study 3 tests for such suboptimal choices. In addition, Study 3 examines how experts and non-experts choose between improvements inside and outside their domain of expertise. Typically, expertise is thought to improve decision-making 
(Kahneman & Klein, 2009)
; experts are assumed to be more motivated and deliberative than laypeople 
(Ericsson et al., 1993)
. However, since the bias we document is unlike typical System 1 biases, it is possible that the additional experience of experts may not alleviate this bias. Expertise could even exacerbate it, if, for example, experts view decisions in their domain as more consequential and thus feel the regret underlying this bias more acutely, paralleling Study 2b.


Method
Procedure and design. Study 3 consisted of three waves. In each wave, we recruited a separate sample of participants. We recruited 198 medical professionals (e.g., nurses/doctors; Mage = 40.8, 78% female, 21% male, 1% non-binary), 198 gig workers (e.g., Uber/Doordash drivers; Mage = 33.6, 42% female, 55% male, 3% non-binary), and 301 lay participants (Mage = 35.1, 47% female, 50% male, 3% non-binary). The medical professionals and gig workers were recruited by Qualtrics Panels, and the lay participants were Americans recruited through Prolific Academic, all in exchange for payment. We excluded 192 participants who failed preregistered comprehension checks (113 medical professionals, 30 gig workers, and 49 lay participants).
Across all three waves of data collection, all participants made choices in seven different domains (see 
Table 3
); in each domain, participants completed four choice trials. The order in which participants saw the domains was randomized, and within each domain, the order of the four trials was randomized. This feature of the design allowed us to directly compare experts'
and non-experts' choices in a given domain.
Each trial presented participants with two options. Both options had some initial probability of success, and participants had to choose which option to improve. Within each domain, there was one control trial, and three different experimental trials. 
Figure 9
 gives a stylized depiction of the information shown to participants in each condition. Spending time studying for one of two upcoming exams


Finance
Receiving additional tickets for one of two different raffles
In the control trials, one option always corresponded with a higher absolute and relative improvement. For example, a control trial in the medical domain presented participants with two patients, both of whom initially had a 10% chance of survival. Participants had to select which patient they would prioritize treating. If they selected the first patient, that patient's chances of survival would improve from 10% to 20%; if they selected the second patient, that patient's chances of survival would improve from 10% to 19% (see Branch A of 
Figure 9
; order in which options were listed was counterbalanced between participants). In this way, all of the control trials presented participants with a clearly superior improvement -going from 10% to 20% is both a larger absolute increase in chances than the alternative (10 percentage points vs. nine percentage points) and leads to a larger relative reduction in bad outcomes (11% eliminated vs.
10% eliminated). Thus, the control trials serve as a benchmark. We expected the vast majority of participants to prefer the superior improvement to the inferior alternative.
The experimental trials had a slightly different structure. Just as with the control trials, participants saw two options and had to choose which option to improve. However, unlike the control trials, one option in the experimental trials always corresponded with a larger absolute increase in chances, while the other option led to a larger relative reduction in bad outcomes (see Branch B of 
Figure 9
). This design allows us to test if participants' sensitivity to the relative reduction in bad outcomes might lead to suboptimal choices. If medical decisions are made with an eye towards maximizing the number of lives saved, improving a patient's chances of survival from 10% to 20% is-all else equal-a more optimal decision than improving a patient's chances of survival from 80% to 89% (a 10 percentage point vs. nine percentage point improvement). Yet, we expected that many participants in these experimental trials would choose the smaller improvements-e.g., 80% to 89%-which correspond with a greater relative reduction in bad outcomes (11% of bad outcomes eliminated vs. 45% of bad outcomes eliminated).
There were three types of experimental trials. The three types of trial varied whether the smaller improvement was either nine percentage points, seven percentage points, or five percentage point (see Branches B-D of 
Figure 9
). This feature allowed us to test if participants would prefer improvements that led to larger relative reductions in bad outcomes even when these improvements were vastly inferior.


Figure 9
Information Presented to Participants by 
Condition,
Study 3
 At the end of the survey, all participants completed two comprehension check questions asking them to correctly identify the consequences of their choices, as well as several professional and demographic questions (see the Supplementary Materials for complete details).


Results
Results for all participants across the entire range of domains and trials are shown in 
Figure 10
. For the control trials, there was a clear (and unsurprising) pattern; participants overwhelmingly preferred the superior improvements. That is, only ~5% of participants preferred the smaller improvements to the larger ones (see purple bars in 
Figure 10
). However, in the experimental trials, participants frequently made suboptimal choices: 56% of participants chose the smaller improvement in the nine p.p. trials (yellow bars in 
Figure 10
). To more formally test this, we conducted a linear mixed-effects model predicting choice of the smaller improvement from the trial (either the control or the nine p.p. experimental trial) with random intercepts by participant. This model revealed that participants were significantly more likely to choose the lower absolute value option in the nine p.p. condition relative to the control condition ( = .52, t(6,564) = 60.00, p < .001, d = 1.35, 95% CI [1.30, 1.40]), an effect which remained robust with alternate specifications (see the 
Supplementary Materials
).
An examination of the green and yellow bars in 
Figure 10
 showcases how participants made suboptimal choices across the five, seven, and nine p.p. trials at a (roughly) similar frequency. In the seven p.p. trials, 52% of participants chose the suboptimal improvement, while in the five p.p. trials, 49% did. In other words, approximately half the time, participants preferred improvements that were twice as small, but led to a greater relative reduction in bad outcomes.
For example, 45% of medical professionals chose a treatment which would improve a patient's chances of survival by five percentage points over a treatment which would improve a patient's chances of survival by 10 percentage points. The fact that so many professionals were willing to choose an option which was only half as impactful as the alternative is a testament to how aversive anticipated regret can be.


Figure 10
Choice of the Smaller Improvement Option in Study by 
Sample, Scenario, and Trial Condition
 Note. Error bars represent standard errors of proportions. We next explore the effects of expertise on improvement decisions. Here, we conducted two analyses. The first compared gig workers' choices within the gig work trials against lay participant and medical professionals' choices within those same trials (see 
Figure 11A
), and the second compared medical professionals' choices within the medical trials against lay participant and gig workers' choices within those trials (see 
Figure 11B
).
For gig workers, we found no evidence that expertise led to better or worse decisionmaking (i.e., 76% of gig workers chose the smaller improvement in the nine p.p. condition, as compared to 78% for medical professionals and 77% for lay participants),  = -.01, t(503) = 0.316, p = .752, d = 0.03, 95% CI 
[-0.16, 0.21]
. However, in the medical sample, we actually found that medical professionals were more likely to make suboptimal choices (48% choosing smaller improvement in the nine p.p. condition vs. 32% for gig workers and 31% for lay BIASES IN IMPROVEMENT DECISIONS participants),  = .17, t(503) = 3.09, p = .002, d = 0.37, 95% CI [0.13, 0.60], an effect which held even with a variety of robustness checks (see the Supplemental Materials).
This increase might have occurred for a variety of reasons. Experts might see decisions within their field as being highly important, and thus be more likely to anticipate feeling regret when making such decisions (as implied by Study 2b). Moreover, the experience of regret is purely dichotomous; once outcomes are realized, experts either experience regret or do not.
Experts-with months, years, or a lifetime of making decisions in a specific domain-might be most quick to recall situations in which their initial chances of success were high, they did not improve those chances, and they subsequently realized a bad outcome and blamed themselves for it. This biased recall might lead improvements attached to initially high probabilities to be particularly attractive. Independent of each of these interpretations of our results, our data suggest that expertise alone may not be sufficient to attenuate the biased valuation of improvements.


General Discussion
Many decisions require people to consider investing scarce resources to improve the likelihood of a good outcome. However, little prior research examines how these improvement decisions are made. Eleven studies demonstrate that people appear to make these decisions by focusing on the relative reduction in bad outcomes. Consistent with our theorizing, participants' valuations of improvements followed a convex pattern. This pattern appeared with a range of probabilities and payoffs, with investments of effort or money, and in both hypothetical and incentive-compatible settings. Our final study found that participants' sensitivity to the relative reduction in bad outcomes led to suboptimal choices in high-stakes domains. 1
Moreover, we found that the phenomenology of these improvement decisions could be characterized by the (biased) anticipation of regret. Mathematical models of regret-which, critically, do not assume that people primarily focus on bad outcomes-are commonly used to predict behavior and explain various decision-making anomalies (e.g., 
Loomes & Sugden, 1982)
.
Supplementary Material Section 3 sketches out how these models can be updated to better capture how decision-makers value improvements. And, Supplementary Materials Section 5 discusses how our logic may operate when people choose which of multiple prospects to enter.
Of course, the methodology we employed may not perfectly resemble improvement decisions that people naturalistically face. For example, people typically don't know their precise chances of passing an exam, or exactly how much studying increases those chances. However, the empirical benefit of using precise probabilities is that researchers can know the exact information decision makers might use in their judgments, and thus do not have to infer, for example, what probability a "decent chance" represents for individual participants. That said, to directly test how this bias might function with less explicit probabilities, we conducted Supplemental Study 4. This study's design mimicked Study 3, but utilized naturalistic language (e.g., "unlikely" replaced "20%", and "very likely" replaced "80%"). We replicate the pattern of suboptimal choices in Study 3.
Our studies test cases with two possible outcomes. How might people anticipate regret when more than two outcomes are possible? For example, how would a Formula One driver consider taking a risk-like delaying a crucial pit stop-to increase their chances of earning a top-three finish? While this question is non-trivial to test, we can speculate about how regret might operate here. First, research finds people often simplify information to make it easier to process 
(Fisher & Keil, 2018;
Kahneman & Tversky, 1979;
Smith & Medin, 1981)
. So, people may dichotomize continuous outcomes, although how they do this might depend on the individual and situation. In the above example, many drivers might reframe an action as either increasing their chances of winning or not winning. However, for a middling driver, earning a top-three finish might feel like winning; for an elite driver, perhaps only coming in first might suffice. Second, when people evaluate multiple outcomes at once (e.g., the chance of winning, of a top-three finish, or of not finishing altogether), we suggest that people will predominantly focus on avoiding the worst outcome (see 
Ito et al., 1998;
Baumeister et al., 2001
). Therefore, a driver might be expected to focus more on the relative improvement in their chances of finishing the race at all more than the relative improvement in their chances of getting fourth place.
Finally, there are interesting similarities between the behavior documented herein and conceptually different behaviors found in the literature. The convex pattern we find-where valuations increase as initial probabilities increase-might also be found in other phenomena involving probabilities or proportions. For example, the goal gradient effect 
(Kivetz et al., 2006;
Hull 1932;
Heath, Larrick & Wu, 1999)
 finds that as people and animals get closer to a goal, effort increases. Theories of curiosity (e.g., Loewenstein 1994) argue that curiosity increases as closeness to complete information increases. In each of these cases, improvements or progress may be judged relative to some naturally occurring reference point, whether that reference point be the total elimination of bad outcomes, goal achievement, or complete information (see 
Loewenstein, 1994)
. As people progress towards a reference point, the same amount of progress eliminates a larger proportion of the remaining distance, making it feel more valuable and motivating. This would result in a convex pattern across a range of situations with naturally occurring reference points, and could perhaps explain a variety of phenomena in psychology.
Figure 2 Proportional
2
Reductions in Bad Outcomes for Ten Percentage Point ImprovementsNote. Illustrates the proportion of bad outcomes eliminated by a 10 percentage point improvement as initial probability of success increases.


Figure 3 WTP
3
for Ten Percentage Point Increase in Chances of Winning $10


Figure 4
4
Mean WTP for a Ten Percentage Point Improvement in Chance to WinNote. Participants' mean willingness-to-pay for a 10 percentage point improvement by initial probability (Studies 1a-1f), and participants' mean willingness-to-work (i.e., solve Captchas) for a 10 percentage point improvement by initial probability (Study 1g). Error bars are +/-1 SE of the mean.If, as we hypothesize, people naturally focus on bad outcomes, and anticipate how much regret they would feel if they decided to forgo an improvement, they should exhibit a convex pattern of valuations of improvements. Studies 1a-1g utilized an array of methods and measures


Figure
Mean WTP to Improve Chances by Ten Percentage PointsNote. Points show participants' mean willingness-to-pay to change their chances of winning a given lottery by 10 percentage points in Study 2a. Violin plot outlines illustrate estimated probability density, i.e. the width at each point reflects the proportion of the data there. Error bars are +/-1 SE.


Figure 7
7
Figure 7


Figure 11
11
Choice of the Smaller Improvement in Gig and Medical Domains by SampleNote. Choices of the suboptimal option giving the smaller improvement in the gig domain for all three samples (A, left) and in the medical domain for all three samples(B, right). Error bars represent standard error of proportions.


Table 2
2
Design and features of Studies 1a-1g. The conditional regret and classic regret theory models were compared using a Chi-square test, which was possible because the two models are nested. A significant Chi-square test means that the conditional regret model fits the data significantly better than the classic regret theory model. Because the conditional regret and prospective outcome bias models were not nested, they could not be compared with a Chi-square test. Instead, a comparison based on AIC was used. Here, >.99 means that there is a more than 99% probability that the conditional regret model is correct given the comparison model and underlying data. Additional details are given in the Supplementary Materials.
vs. Prospective
N (Before
vs. Classic Regret Theory
Outcome Bias
Study
Exclusions)
Prize
# Trials
Sample
Description
Model*
Model**
1a
109 (109)
$10
16
AMT
Finds convex pattern of valuations
 2 (1) = 395.91, p < .001
>.99
1b
101 (127)
$10
43
AMT
Measured 5 p.p. and 10 p.p. improvements
 2 (1) = 903.11, p < .001
>.99
1c
87 (131)
$10
22
AMT
Includes more trials with higher initial probabilities
 2 (1) = 617.71, p < .001
>.99
Fully incentive
1d †
96 (98)
$5
20
Students
compatible through in-
 2 (1) = 48.93, p < .001
>.99
person BDM procedure
1e †
203 (408)
$5
25
AMT
Larger sample size and incentive compatible
 2 (1) = 2,246.80, p < .001
>.99
1f †
109 (161)
$5
32
Students
Expanded set of trials
 2 (1) = 620.24, p < .001
>.99
Participants indicate
1g †
117 (214)
$5
25
AMT
willingness to work for
 2 (1) = 1,181.80, p < .001
>.99
improvements
† Incentive compatible study
*
**


While scholars have questioned the notion that risk attitudes are a stable individual difference based on work showing different risk-attitudes within individuals across domains (e.g., a risky investor who is unwilling to go bungee jumping, Blais & Weber 2006; but see also Frey et al. 2017), as far as we are aware this is the first study showing the exact same individual behaving both risk-seeking and risk-averse within the exact same decision context (arguably with the exception of Frederick et al. 2018). Of course, this does not mean there are no individual differences in risk-attitudes in general or in our studies (see the additional analysis of Study 1e in the Supplementary Materials for an analysis of individual heterogeneity), it does


Table 3
3
Domains and Choice Scenarios Presented to Participants, Study 3
Domain
Choice scenario
Medicine
Giving a treatment to one of two critically ill patients
Gig economy
Focusing on meeting one of two bonus goals
Public health
Distributing a vaccine for one of two different diseases
Business
Allocating budget to one of two different projects
Law
Doing additional preparation for one of two upcoming court cases
Education


Further, Supplementary Study 3 tests an intervention which reduces these suboptimal choices by moving the focus in decisions from individual outcomes to average expected outcomes.














Bad is stronger than good




R
F
Baumeister






E
Bratslavsky






C
Finkenauer






K
D
Vohs








Review of General Psychology




5


4
















Measuring utility by a single-response sequential method




G
M
Becker






M
H
Degroot






J
Marschak








Behavioral Science




9


3


















10.1002/bs.3830090304














Regret in Decision Making under Uncertainty




D
E
Bell




10.1287/opre.30.5.961








Operations Research




30


5
















A Domain-Specific Risk-Taking (DOSPERT) scale for adult populations




A.-R
Blais






E
U
Weber








Judgment and Decision Making




1


1


















10.1017/S1930297500000334














Regret Theory: A Bold Alternative to the Alternatives




H
Bleichrodt






P
P
Wakker




10.1111/ecoj.12200








The Economic Journal




125


583
















Heuristic versus systematic information processing and the use of source versus message cues in persuasion




S
Chaiken








Journal of Personality and Social Psychology




39


5


752














Consistency and heterogeneity of individual behavior under uncertainty




S
Choi






R
Fisman






D
Gale






S
Kariv








American Economic Review




97


5
















Estimating risk preferences from deductible choice




A
Cohen






L
Einav








American Economic Review




97


3
















The role of deliberate practice in the acquisition of expert performance




K
A
Ericsson






R
T
Krampe






C
Tesch-Römer








Psychological Review




100


3


















10.1037/0033-295X.100.3.363




















BIASES IN IMPROVEMENT DECISIONS












The binary bias: A systematic distortion in the integration of information




M
Fisher






F
C
Keil








Psychological Science




29


11
















Valuing bets and hedges: Implications for the construct of risk preference




S
Frederick






A
Levis






S
Malliaris






A
Meyer








Judgment and Decision Making




13


6
















Risk preference shares the psychometric structure of major psychological traits




R
Frey






A
Pedroni






R
Mata






J
Rieskamp






R
Hertwig




10.1126/sciadv.1701381








Science Advances




3


10














Relations among emotion, appraisal, and emotional action readiness




N
H
Frijda






P
Kuipers






E
Ter Schure




10.1037/0022-3514.57.2.212








Journal of Personality and Social Psychology




57


2
















Goals as reference points




C
Heath






R
P
Larrick






G
Wu








Cognitive Psychology




38


1
















Negative information weighs more heavily on the brain: the negativity bias in evaluative categorizations




T
A
Ito






J
T
Larsen






N
K
Smith






J
T
Cacioppo








Journal of Personality and Social Psychology




75


4


887














Representativeness Revisited: Attribute Substitution in Intuitive Judgment




D
Kahneman






S
Frederick








Heuristics and Biases


T. Gilovich, D. Griffin, & D. Kahneman




Cambridge University Press










1st ed.










10.1017/CBO9780511808098.004














Conditions for intuitive expertise: A failure to disagree




D
Kahneman






G
Klein




10.1037/a0016755








American Psychologist




64


6
















Prospective outcome bias: Incurring (unnecessary) costs to achieve outcomes that are already likely




J
Lewis






J
P
Simmons




10.1037/xge0000686








Journal of Experimental Psychology: General




149


5
















All over the map: Heterogeneity of risk preferences across individuals, contexts, and countries




O
L'haridon






F
M
Viedier




10.3982/qe898








Quantitative Economics




10


1
















Regret Theory: An Alternative Theory of Rational Choice Under Uncertainty




G
Loomes






R
Sugden




10.2307/2232669








The Economic Journal




92


368


805














Risk Preference: A View from Psychology




R
Mata






R
Frey






D
Richter






J
Schupp






R
Hertwig








Journal of Economic Perspectives




32


2


















10.1257/jep.32.2.155














Personal involvement as a determinant of argument-based persuasion




R
E
Petty






J
T
Cacioppo






R
Goldman




10.1037/0022-3514.41.5.847








Journal of Personality and Social Psychology




41


5
















Increasing risk: I. A definition




M
Rothschild






J
E
Stiglitz








Uncertainty in Economics




Academic Press
















Categories and concepts




E
E
Smith






D
L
Medin








Harvard University Press












Theory of games and economic behavior




Von
Neumann






J
Morgenstern






O








Theory of Games and Economic Behavior




Princeton University Press














Curvature of the Probability Weighting Function




G
Wu






R
Gonzalez




10.1287/mnsc.42.12.1676








Management Science




42


12
















Anticipated regret, expected feedback and behavioral decision making




M
Zeelenberg








BIASES IN IMPROVEMENT DECISIONS Journal of Behavioral Decision Making




12


2


















10.1002/(SICI)1099-0771


2<93::AID-BDM311>3.0.CO;2-S








12












A Theory of Regret Regulation 1.0




M
Zeelenberg






R
Pieters




10.1207/s15327663jcp1701_3








Journal of Consumer Psychology




17


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]