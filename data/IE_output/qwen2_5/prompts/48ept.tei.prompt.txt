You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1â€“3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Bidirectional Influences of Information-Sampling and Concept Learning


Introduction
At its heart, category learning involves extracting key patterns that capture the essence of our experiences, and allow us to make accurate inferences about the external world. Two fundamental challenges for psychological research are to understand how this knowledge is acquired, and once acquired, how it can be flexibly used to guide successful interactions with the external world. Although successful categorization models differ in how categories are represented in memory (e.g., as flexible clusters, exemplars, or prototypes; 
Love, Medin, & Gureckis, 2004;
Nosofsky, 1986;
Smith & Minda, 1998)
, they tend to sidestep the question of how sensory information is encoded, but assume that the representations considered during deliberation are available to the decision-maker, and can be modulated by selective attention based on their behavioural relevance 
(Figure 1
.A).
Attention plays a key role in allowing these models to capture the flexibility by which humans are able to organize stimuli into categories .
These attentional weights provide key information about how different sources of information are organized during decision-making.
Leading contemporary categorization models, therefore, tend to treat category decisions as "single-step" decision problems; in which agents make decisions about the final choice, but not about what information to sample. While it is plausible that decision-makers encode all relevant stimulus information from the low-dimensional stimuli typically considered in the laboratory, 1 in high-dimensional environments, encoding all available sensory information is inefficient, and can impair learning. This reflects a fundamental computational constraint (known as the curse of dimensionality), which affects both machine-learning algorithms 
(Hastie, Tibshirani, & Friedman, 2009;
Li et al., 2017
) and human decision-makers (e.g., 
Bulgarella & Archer, 1962;
Edgell et al., 1996;
Pishkin, Bourne, & Fishkin, 1974;
Vong et al., 2018)
.
To be able to interact efficiently in high-dimensional environments, humans actively-sample information from sources expected to provide behaviourally relevant information (e.g., 
Cook, Goodman, & Schulz, 2011;
Markant & Gureckis, 2014;
Markant, Settles, & Gureckis, 2015;
Nelson & Cottrell, 2007;
Yang, Lengyel, & Wolpert, 2016)
. This is apparent, not only for decisions involving the collection of discrete samples of information across extended periods of time, 2 but are reflected in subtle patterns of eye-movements during decisions of relatively short duration (i.e., less than~3 sec.; 
Blair, Watson, Walshe, & Maj, 2009;
Rehder & Hoffman, 2005a)
. This partially reflects fundamental constraints of extrafoveal visual acuity, which drive decision-makers to integrate sensory information through a series of saccades to different locations. As expectations about ones environment can change based on the values of incoming sensory information, approaches that treat categorization decisions as single-step problems tend to ignore attentional effects that can occur within individual trials 
(Blair et al., 2009;
Gottlieb, 2018;
Gottlieb & Oudeyer, 2018)
.
Through experience, decision-makers learn to selectively-attend to behaviourally-relevant stimulus features 
(Shepard et al., 1961)
. When observations are drawn randomly (as in typical laboratory experiments), participants tend to gain equivalent experience with all possible stimulus configurations. When participants are free to select the stimuli from which they learn, however, they tend to selectively sample information to test specific hypotheses (this is known as hypothesis-dependent learning bias; 
Markant & Gureckis, 2014)
. This can facilitate learning when the generated-hypotheses closely resemble the true structure of the environment, but can otherwise impair learning.
Humans often show a bias for testing simple hypotheses, for example, and this can impede learning (and/or lead to the development of inaccurate beliefs) when the true structure of the world is complicated.
Here, we develop a computational model, Sampling Emergent Attention (SEA), designed to reflect this effect. The model actively selects information as a function of its goals and its current beliefs, and learns to selectively sample information sources expected to provide behaviourally-relevant information. 
3
 Leading contemporary models of categorization (e.g., 
Kruschke, 1992;
Love et al., 2004;
Nosofsky, 1986)
, in contrast, tend to sidestep the question of how information is initially sampled. Rather than investigating how decision-makers choose what information sources should be sampled, these models emphasize questions related to how stimulus information is organized. A particular focus of these models is to understand how, through selective attention, stimulus representations are contorted such that representations of behaviourally-relevant stimulus dimensions are accentuated (or "stretched"), and representations of irrelevant dimensions are ignored (or "compressed"). We therefore describe these models as treating categorization decisions as single-step decision problems 
(Figure 1
.A), as decisions are made about the final choice, but sequential intra-trial active sampling behaviour 
(Figure 1
.B) is not considered.
SEA consists of two interacting components; each of which can be considered normatively optimal in its own right. The first component reflects the decision maker's beliefs and expectations about the environment, the second estimates the value of different information states. Interactions between the two components allow the model to select samples that maximize expected utility. Whereas contemporary categorization models often include attentional parameters that contort stimulus representations along 
3
 Throughout the paper, we use the terms "information sources", "features", and "dimensions" interchangeably. "Information source" has a more general connotation than stimulus "dimension" or "feature," which are terms commonly used in the categorization literature. "Dimension" tends to emphasizes a geometric connotation, while "feature" does not. Although we focus on binary-valued features, the approach can also be applied to other representational formats supporting the expression of uncertainty as probability.
perceptually-separable stimulus dimensions 
(Figure 1
.A; 
Garner, 1976
), the proposed model re-conceptualizes attention as the gain in utility from sampling particular information sources. Despite this fundamental difference, SEA predicts classic behavioural effects associated with selective attention 
(Nosofsky, Gluck, Palmeri, McKinley, & Glauthier, 1994;
Shepard et al., 1961)
. Its active sampling behaviour additionally closely resembles patterns of human eye movements (e.g., 
Blair et al., 2009;
Rehder & Hoffman, 2005a
). 5 Finally, like human learners, SEA can also develop inaccurate beliefs about the world when it fails to balance demands for exploration and exploitation 
(Rich & Gureckis, 2018
 
Figure 1
 . Two Views of Attention. A) Contemporary categorization models tend to sidestep questions related to how decision-makers sample information from the world. Instead, their emphasis is on how multidimensional stimulus representations are are contorted by selective attention (e.g., 
Kruschke, 1992;
Love et al., 2004;
Nosofsky, 1986)
. In the example on the left, three stimulus dimensions (Size, Color and Shape) are equally attended. On the right, "Size" is given greater attentional weight than "Shape" or "Color". B) Active sampling requires decisions, not only about the appropriate final choice, but also about what samples should be selected. In the category structure depicted at left 
(Blair et al., 2009)
, the optimal sampling strategy is to first sample dimension 1, and then, depending on its value, sample either D2 or D3 (grey rectangles denote informative samples). This temporally-ordered sequence is illustrated at right. It is never necessary to sample all three dimension if D1 is sampled first.


Optimal Experiment Design and Human Information Sampling
Several groups have used the principles of optimal experimental design (OED; 
Fedorov, 1972
Fedorov, , 2010
MacKay, 1992)
 to investigate whether humans strategically sample information to test specific hypotheses. For cognitively-limited human decision-makers, the calculations underlying OED can be computationally-prohibitive. However, these studies indicate that, despite being susceptible to perceptual 
(Itti, Koch, & Niebur, n.d.;
Yamada & Cottrell, 1995;
Zhang, Tong, Marks, Shan, & Cottrell, 2008)
 and decisional 
(Klayman, 1995
) biases, we are often able to select information samples that resolve uncertainty about specific hypotheses. This effect is apparent both during the performance of traditional categorization tasks 
(Markant & Gureckis, 2014;
Markant et al., 2015)
, and during naturalistic behaviour. Preschool children, for instance, spontaneously conduct experiments to test specific causal hypotheses about the objects they are playing with 
(Cook et al., 2011)
. Hypothesis-dependent sampling strategies have also been identified through study of human eye-movements. During categorization, for instance, we tend to selectively fixate on stimulus locations that resolve uncertainty about the potential category label 
(Nelson & Cottrell, 2007;
Yang et al., 2016)
. During visual search, we similarly tend to fixate on locations expected to maximize information about the target location 
(Najemnik & Geisler, 2005
).
To select useful information sources to sample, a decision maker must be able to simulate future events. This capacity for preposterior analysis, 6 involves predicting the probability and utility of future states. When diagnosing a patient, for instance, doctors must have sufficient knowledge of human pathology to identify plausible diagnoses. They must also be able to use this knowledge to select medical tests that efficiently differentiate between the most probable diagnoses. To reflect that some some results can be more informative than others, 7 full preposterior analysis aggregates information about both the probability and usefulness of each expected result. In practice, this forward-search process can be computationally prohibitive for large problems, necessitating an approximation to the full preposterior search performed by SEA. 
Figure 2
 . Bidirectional Influences of Information Sampling and Learning. In this example, a decision-maker has learned to categorize stimuli, which vary according to three dimensions (one that is highly informative, one that is moderately informative, and one that is irrelevant), into two categories (denoted by blue crosses and red circles) by actively sampling information from the external world (110 stimuli, randomly-drawn from this imaginary world, are illustrated at the right). Their knowledge of the world (depicted as two probability distributions at left), reflects the samples that have been observed. In this example, the decision-maker has learned that the highly-important dimension predicts the category label, but has not learned that the moderately-important dimension mediates this relationship. As a result, this learner would be unable to classify all stimuli accurately. Characteristics of the external world (e.g., costs associated with sampling each dimension, or costs associated with incorrect choices), as well as characteristics of the learner (e.g., some learners might show a stronger bias for simple hypotheses) influence what is ultimately learned.


What is a Useful Question?
A number of different sampling norms have been used to define the usefulness of sampling a particular dimension (see 
Nelson, 2005)
. Disinterested sampling norms seek to maximize decision accuracy. One way to define the usefulness of a particular medical test, for instance, would be the degree to which it is expected to improve the probability of making a correct diagnosis. 8 In contrast, situation-specific sampling norms maximize reward rather than accuracy, and may be preferable when payoffs are asymmetric (i.e., when the maximization of accuracy differs from the maximization of reward; 
Meder & Nelson, 2012)
. For example, incorrectly diagnosing a malignant tumor as benign can be more costly than incorrectly diagnosing a benign tumor as malignant.
Utility-sensitive decision-makers should also consider the costs associated with sampling each information source. Invasive medical tests (e.g., a biopsy), for example, can be more informative than non-invasive tests (e.g., an X-ray). As a result, doctors must determine whether the benefits of a particular test are outweighed by its cost. A purely exploitative decision-maker should stop deliberating and commit to a choice when the gain in value from a particular test is outweighed by its cost. An exploratory decision-maker, however, might be willing to tolerate a small cost in order to learn about the environment.
Agents must, therefore, carefully balance demands for exploration and exploitation when learning about a domain, or risk developing inaccurate beliefs (as illustrated in 
Figure 2
).
Although medical decisions are often extended in time, we face the same challenges when making rapid decisions (i.e., deciding what information should be sampled), even about which eye movements to make, as evaluated in category learning experiments.


Self-Termination & Branching
As its beliefs are updated after observing each sample, SEA can display branching and self-termination. Branching involves changes in sampling strategy based on the values of the incoming information. Self-termination occurs when decision-makers decide to commit to a choice, rather than selecting additional samples.
Such decisions about when to commit to a choice are a fundamental component of many temporally-extended decisions 
(Figure 1
.B). Decision-makers may fail to capitalize on transient opportunities for reward (or accrue excessive costs associated with deliberation) if they wait too long before committing to a choice. If they respond too quickly, they may fail to collect enough evidence to support a desirable level of accuracy.
We propose that the depth of forward search, which varies from myopic search to full preposterior inference 
(Figure 1
.B), can be adjusted based on contextual demands on response timing. As clusters are activated based on the observed features (Equation (3)), and the cluster representations predict the appropriate final choice (e.g., the category label), as more information is accumulated/sampled, inferences about the correct response become more accurate (assuming that clusters reflect relevant aspects of the environment).
Several models have been proposed to address the question of self-termination.
"Integrate-to-bound" models, such as the Sequential Probability Ratio Test 
(SPRT;
Wald & Wolfowitz, 1948)
 and the Drift Diffusion Model (DDM; 
Ratcliff, 1978)
, for example, operate by collecting evidence for competing hypotheses over time (in the form of a log-likelihood ratio), and committing to a choice when the strength of the cumulative evidence exceeds a pre-defined threshold. In typical implementations of these models, the threshold remains stationary during deliberation, and is chosen to balance the trade-off between accuracy and deliberation cost. Unlike SEA, however, these models act as passive observers, as they do not select the samples from which they learn.
In contrast, SEA selects samples sources of information through consideration of its beliefs about the environment, and updates these beliefs following the observation of each sample. Incidentally, the calculations involved in this procedure provide a principled way to define the termination criterion. While a purely exploitative decision-maker should commit to a choice when the gain in utility for each sample is outweighed by its cost, an exploratory decision-maker may be willing to bear some sampling cost in order to learn about the environment. Whereas the DDM and SPRT define the termination criterion to balance demands for accuracy with missed opporunity costs, in SEA the termination criterion is calculated with regards to expected information gain, and a heuristic that strives to balance the trade-off between exploration and exploitation. 9
Because SEA strives to sample the most informative information source at each step, Additionally, the EGCM-RT will consider all stimulus features instead of than self-terminating.
successive


The Proposed Model
Here, we introduce a novel model of categorization, SEA, which is designed to treat decision-making as an active sampling problem (in which decisions are made, not only about the final choice ( 
Figure 1.A
 
(Knox et al., 2012)
, this mechanism can be seen as a heuristic linking the concept-learning and utility-sensitive sampling components.
Although category learning with feedback is typically treated as a supervised learning task, the present work recasts it as a problem in which the agent learns to traverse a series of probabilistic states (i.e., information samples) while minimizing sampling costs and maximizing reward (similar to reinforcement learning; 
Kaelbling, Littman, & Moore, 1996;
Sutton, 1990)
. While SEA will initially sample uniformly across dimensions, it will gradually learn to sample selectively from dimensions expected to provide useful information. The resulting representational structure is efficient, in that it minimizes both the amount of information encoded across experiences, and the amount of information considered during individual decisions.
In SEA, effects of selective sampling emerge with learning, and so sampling strategies change as the model learns about the environment. These bidirectional interactions between information sampling and concept-learning result in high-density representations along dimensions SEA believes are useful, and low-density representations along dimensions SEA deems irrelevant (reflecting the relative sampling frequency of these dimensions). This is analogous to the effects illustrated in 
Figure 1
.A, which are captured by single step categorization models, which sidestep the information sampling stage of decision-making, and selectively weight dimensions through attentional processes (e.g., 
Kruschke, 1992;
Love et al., 2004;
Nosofsky, 1986)
. In both frameworks, behaviourally-relevant stimulus dimensions have greater influence on the final choice than do irrelevant dimensions.
Active sampling can lead to a self-enforcing pattern of belief updating, where beliefs about the world influence the information that is sampled from it, and this information is used to update beliefs. This can have important consequences on learning efficiency. When decision-makers are free to select the stimuli from which to learn, they often learn more efficiently than when stimuli are presented in a predetermined order 
(Castro et al., 2009;
Gureckis & Markant, 2009;
Markant & Gureckis, 2010
, 2014
Markant et al., 2015)
. This effect, however, depends on the structure of the problem being learned 
(Enkvist, Newell, Juslin, & Olsson, 2006;
Markant & Gureckis, 2010
, 2014
. Bidirectional interactions between information sampling and learning can also determine what concepts are ultimately learned. One example is the blocking effect 
(Kamin, 1969)
, wherein after learning that a particular dimension is informative, a decision-maker will tend to exploit this knowledge rather than continue to explore other information sources. To avoid these kinds of "knowledge traps" 
(Rich & Gureckis, 2018)
, decision-makers must successfully balance demands for exploration and exploitation 
(Kaelbling et al., 1996;
Sutton & Barto, 1998)
.


Model Overview
In this section, we present SEA, and its potential variations. SEA's information-value component determines which (if any) features should be sampled. Its learning component provides the information-value component with the probabilities required to determine the sampling policy, and is updated based on the information sampled. Below, we specify these components, outline their interactions, and consider model variants that incorporate mechanisms that reflect the constraints of human decision-makers. what information sources should be sampled When the cost of sampling an information source exceeds the gain in utility, a purely exploitative decision-maker should commit to a final choice. B) To decide whether to stop deliberating, or to sample an additional stimulus dimension, SEA performs preposterior inference. In the illustrated example, two of the four features used by Rehder and Hoffman (2005a) (i.e., the head and tail of an abstract bird stimulus) have been observed, and all possible future sequences of samples are simulated. In typical categorization tasks, participants strive to maximize the accuracy of the final choice (as in 
Table 1
), and the cost of sampling each dimension is equivalent. For other kinds of decisions (e.g., those involving medical diagnoses), outcomes associated with the final choice can be associated with asymmetric values (e.g., the cost of a false negative is often greater than the cost of a false positive). Similarly, different tests can impose different costs (e.g., an MRI is more expensive than a blood test). Our beliefs about costs, values, and the probabilities of future events influence what information is sampled, and therefore what is ultimately learned. Ellipse: A decision-maker using a myopic planning process would consider the possible results of only a single sample into the future, and then make the best possible response. Full preposterior inference is generally more accurate, as it also considers the potential results of subsequent samples.


Concept-Learning Component
The concept learning component we use is closely related to 
Anderson's (1991b;
1990)
 Rational Model of Categorization (RMC), although any generative probabilistic model would also likely be appropriate. The RMC incrementally learns to sort stimuli into appropriate clusters, and can make near-optimal use of past information during learning and prediction. Here, we provide an overview of the RMC. Additional details can be found in the original papers 
(Anderson, 1991b;
Anderson & Matessa, 1990
).
The RMC is a flexible clustering model, which learns to parcelate representational space into clusters based on its experience with the normative characteristics of the task environment. Formally, the probability that any unobserved stimulus dimension, F i , will take a particular value, j, can be inferred by weighting the prediction of each cluster,
P (F i = j|k)
, by the probability of the cluster given the observed features, P (k|F O ):
P (F i = j|F O ) = k P (F i = j|k)P (k|F O ).
(1)
Where P (F i = j|k) is calculated using Equation 
2
, and P (k|F O ) is estimated using
Equation 
3
. By this notation (which we will use throughout the paper) the subscript, o, For each dimension, discrete feature values are assumed to be distributed according to a Dirichlet density characterized by dimension-value parameters Î± j , and dimension-wide parameters, Î± 0 (where Î± 0 = j Î± j ). The Dirichlet distribution allows the data to determine the number of clusters (as in SUSTAIN; 
Love et al., 2004)
, and allows for a potentially infinite number of clusters. However, between one and three clusters per category is typical. These desirable characteristics of the Dirichlet distribution have led to it being used in many categorization models (e.g., 
Anderson, 1991a;
Griffiths, Canini, Sanborn, & Navarro, 2007)
.
Across learning, SEA tracks the number of items in cluster k with the same value, j, on feature i in C ij . The posterior is also Dirichlet-distributed, and the probability that a feature will take a particular value within a cluster is:
P (F i = j|k) = Î± j + C ij Î± o + j C ij .
(2)
As C ij becomes populated through experience, it exerts stronger influence on P (F i = j|k)
relative to the prior. The prior parameters (the Î±'s) play an important role during early learning, as they allow SEA to appropriately estimate its uncertainty when few samples have been observed. After a single trial, for example, it would be erroneous to infer that all future objects will display the observed values.
Bayes' theorem can be used to calculate the last term in Equation 
1
, P (k|F O ). This term represents the probability (or activation) of each cluster given the observed features:
P (k|F O ) = P (F O |k)P (k) k P (F O |k)P (k) ,
(3)
where P (F O |k) is calculated using Equation 
2
, and P (k) represents the prior probability that any stimulus will be assigned to cluster k. The prior probability that a stimulus will be assigned to cluster k:
P (k) = cn k (1 âˆ’ c) + cn ,
(4)
where c denotes the coupling probability (a parameter that determines the probability that two objects come from the same category), and n k is the number of items already assigned to cluster k, and n is the total number of stimuli observed. The prior probability that a stimulus will be assigned to a novel cluster is:
P (0) = (1 âˆ’ c) (1 âˆ’ c) + cn ,
(5)
As no clusters have yet been created on the first trial, the model will start with a single cluster with each feature initialized with a uniform probability of occurring (as in equation 
5
). With greater experience, the model will incrementally learn a single partition of stimuli into clusters. With the parameters set as in the simulations described below, the model tends to sample all features. While the fully normative solution would be to consider all possible partitions of stimuli into clusters 
(Anderson, 1991a)
, this approach is intractable for all but the simplest problems. 12 The incremental approach may also be more psychologically valid 
(Love et al., 2004)
.


Combining Concept-Learning with a Utility-Sensitive Sampling Norm
When facing a choice with an uncertain outcome, the expected utility of a particular action, a, can be calculated by weighting the utility of each resulting state by its probability. In a category learning experiment, for example, one category label may be more probable than the other, but yield lesser reward. The action-utility function shown in 
Table 1
 corresponds to a contingency table in which two states (or categories), s p and s q , are mutually exclusive and exhaustive (i.e., P (s p âˆª s q ) = P (s p ) + P (s q ) = 1), and the decision maker must choose the appropriate action (a p or a q ; in a categorization experiment, this corresponds to the category label). The table could also be expanded to include more than two possible actions and states. 
a p a q s p 100 0 s q 0 100
For the action-utility function shown in 
Table 1
, the expected utility, E(U ) of action a p can be calculated as follows:
E(U (a p )) = U (a p |s p )P (s p ) + U (a p |s q )P (s q ).
(6)
For example, if P (s p ) = 0.7, and P (s q ) = 0.3, the expected utility of choosing a p would be 70 and that of a q would be 30. In this case, the utility-maximizing action would be to choose a p . As mentioned, payoffs can also be asymmetric. For instance, if the lower-left entry in 
Table 1
 was -1000, there would be a high penalty associated with a p when state s q holds, and the optimal choice would switch to a q . As in 
Anderson's (1991b;
1990)
 Rational Model of Categorization, the category label is treated like any other cluster feature; and equation (1) can be used to calculate the probability of each label, given the observed values. The value of action, a, given the observed features, F O , can be estimated by summing over states, s, and subtracting the costs associated with sampling each observed feature,
L o : 13 E(U (a|F O )) = s U (a|s)P (s|F O ) âˆ’ oâˆˆO L o ,
(7)
where P (s|F O ) is provided by Equation 
1
, and U (a|s) was introduced in Equation (6).
Before learning about the environment, a uniform prior (resulting from equations (4) and
(5)) drives probabilistic sampling of each stimulus feature.
The estimated utility of the current state, F O , can be estimated by maximizing over possible actions:
E(U (F O )) = argmax aâˆˆActions (E(U (a|F O ))).
(8)
As discussed, real-world decisions often require decision-makers to decide what information should be sampled. This is important, as the information that is sampled can influence the final choice. The results of a blood test, for instance, can influence a doctor's decision about whether to suggest chemotherapy for a patient. To estimate the utility of a test that reveals the value of an unknown feature (e.g., "cancer antigen present" vs. "cancer antigen absent"), we consider how much the results of the test would improve the utility of the current state (where the current state is defined by the vector of observed features, F O ). The expected utility of the state after sampling unobserved feature i, can be estimated by summing across its possible values, j:
E(U (F O , F i )) = jâˆˆF i E(U (F O , j))P (F i = j),
(9)
where E(U (F O , j)) denotes the expected utility of the state if value j (of unobserved feature F i ) was included in the vector of observed features. Equation (9) demonstrates how the expected utility of the state can be calculated for a single feature. As each feature can have multiple values (2 in the simulations described below), the model explores each branch for each feature. During myopic decisions, the model considers only a single step into the future. Preposterior analysis (which is implemented in SEA as a "depth-first" search process), involves imagining each branch several steps into the future. The computational demands of preposterior analysis, therefore, are high, even for the relatively low-dimensional decision problems commonly considered in the categorization literature.
Equation 
9
is used to calculate the gain in utility (cf. 
Nelson, 2005;
Nelson et al., 2010)
 from sampling unobserved feature i:  
(Busemeyer & Rapoport, 1998)
, which require multiple samples to be drawn from a single noisy stimulus feature 
(Edwards, 1965;
Rapoport & Burkheimer, 1971)
. Although such tasks similarly require participants to decide, at each time-step, whether to consider additional information or commit to a final choice, the problems considered here requires the integration of information across multiple stimulus features. This poses an additional challenge, as decision-makers must know which features provide useful information with regards to their goal. Efficient information sampling, therefore, requires knowledge about a problem's domain. In our model, the concept learning component provides this kind of information (i.e., knowledge of the problem's underlying structure) to the information-utility component (which then identifies the most informative samples).
G(F i ) = E(U (F O , F i )) âˆ’ E(U (F O )).
(10)


Balancing Demands for Exploration and Exploitation
Precisely determining the optimal balance of exploration and exploitation is intractable for most tasks and is only possible for special cases 
(Kaelbling, 1993;
Kaelbling et al., 1996;
Simsek & Barto, 2006)
. In order to derive the optimal solution, one would need to make several assumptions. It would be necessary, for instance, to estimate the number of trials left in the study (as the negative consequences of choosing a sub-optimal strategy increases with the number of trials on which it is applied). It would also be necessary to estimate the how rewarding the environment is (as optimal inference requires normalizing estimates based on environmental characteristics). It would also be necessary to estimate the probabilities of different category structures, which represents uncertainty about the appropriate categorization strategy (alternatively, one could restrict the possible forms of the environment, as in 
Stankiewicz, Legge, Mansfield, & Schlicht, 2006)
. Finally, it would also be necessary to consider the probability of any of these factors changing over time 
(cf. Brown & Steyvers, 2009;
Gittins & Jones, 1979;
Steyvers, Lee, & Wagenmakers, 2009)
.
Fortunately, a number of heuristic methods exist 
(Kaelbling, 1993;
Kearns & Singh, 2002;
Moore & Atkeson, 1993;
Schmidhuber, 1991;
Sutton, 1990)
. We combine two of these heuristic methods: stochastic choice via a softmax choice rule, and exploration bonuses for under-explored options 
(Kaelbling, 1993)
. The exploration bonus, E, could take many forms. In Kalman filter models, this term often takes the form of an uncertainty bonus that reflects the standard deviation of the choice's utility 
(Daw, O'Doherty, Dayan, Seymour, & Dolan, 2006)
. In the current model, E is calculated for each feature separately:
E i = max(U ) âˆ’ E(U (F O )) (1 + n i ) Ï• ,
(11)
where max(U ) denotes the maximum utility possible irrespective of sampling costs.
(E(U (F O )) will always be less than or equal to max(U )). n i denotes the number of previous observations of feature i, and Ï• denotes a fixed parameter modulating the influence of n i on E i . In the case that F O supports perfect prediction, the comparison of E(U (F O )) (i.e., the expected utility, including the costs of sampling each feature given the observed features) to max(U ) encourages the model to explore when sampling F O is costly.
Combining the exploration bonus with a softmax choice rule, the probability of sampling feature m is:
P (F m ) = e Î²(G(Fm)+Em) n e Î²(G(Fn)+En) ,
(12)
where Î² denotes a non-negative temperature parameter that modulates the stochasticity of the decision process (i.e., "how often is the feature with highest expected profit chosen?").
When E m = 0, and G(F m ) â‰¤ 0, the model stops deliberating and commits to a final choice.


Summary
SEA interleaves concept learning and information sampling, such that they mutually influence one another. Information sampling is akin to a dynamic planning process in which SEA's concept learning component (i.e., the Rational model) serves as an internal model of the environment. For instance, the Rational model may might learn that red objects tend to be heavy 90% of the time. Using this acquired knowledge, after observing that an object is red, the Rational Model (Equation (1)) would then be able to update its expectation that the object is heavy to 90%. Before learning this relationship between color and weight, the Rational model would rely on an uninformative prior (50% of objects are heavy, 50% of objects are light) to guide its predictions.
Calculating these probabilities of unobserved features (e.g., weight) is critical for planning which feature to sample next. The expected utility of a possible state is calculated by combining the probabilities of these states with their utilities (Equation 
1
 
8
. The expected utility of sampling this particular feature can be calculated by combining these expected utilities across feature values (equation 
9
). The gain in utility from sampling the feature can then be calculated using equation 
10
. The exploration bonus for this feature could then be calculated using equation 
11
. After performing these calculations for each feature, the probability of sampling each feature would then be calculated using equation 
(12
 The process would then be repeated with the value of feature "1" set to 1 (i.e., F O = [1,?,?]). When the depth of the forward search is limited to two steps, the algorithm would commit to sampling a feature after simulating the sampling of two features. 14 For a three-feature categorization problem, SEA would simulate the sampling of all three features before sampling the first. After sampling one feature, SEA would simulate sampling both remaining features. After calculating the information gain and exploration bonus for each feature, SEA would then decide what feature to sample using the Softmax choice rule (equation 
12
). Importantly, SEA does not learn anything during simulation.
The concept learning component is updated only after the final choice is made, and this learning changes behaviour on future trials only.
While the myopic decision algorithm requires minimal computational demands, it lacks the sophisticated behaviour that forward search enables (i.e., strategic self-termination and branching). When SEA employs a myopic strategy, it tends to sample more dimensions, and to be less accurate (in terms of its categorization decisions), than when preposterior analysis is employed. These limitations of the myopic algorithm are illustrated in the simulation of experiment performed by 
Blair et al. (2009)
 (see "Strategic Attention within Individual Trials").


Simulations
The proposed model treats decisions as a temporally-extended procedure involving sequentially sampling information from the environment, and then committing to a final  
Blair et al. (2009)
. We then simulate an experiment using the 5/4 category structure 
(Medin & Schaffer, 1978)
, and demonstrate that purportedly sub-optimal patterns of attention (inferred from both eye-tracking and behavioural choice data) may reflect averaging individual stimuli associated with distinct scan paths. Finally, we demonstrate that the mnemonic representations resulting from SEA's active sampling procedure predict human recognition and categorization behaviour during the rule-plus exception task 
(Davis et al., 2012a
(Davis et al., , 2012c
Love & Gureckis, 2007;
Palmeri & Nosofsky, 1995;
Sakamoto & Love, 2004)
.
Rather than fitting the model to each data set, we adopted a conservative approach, and used the same fixed parameters for all simulations (to avoid over-fitting). We therefore do not focus on parameter-specific effects in each simulation, but instead consider broader qualitative effects associated with the model architecture.
One-hundred utility units were awarded for correct answers, and no points were awarded for incorrect answers. The exploration parameter, Ï•, was set to 0 (such that the exploration bonus for each feature, E i was driven purely by potential gain in utility), the decision parameter, Î² was set to 1, and the cost of sampling each feature, L i , was set to 10.
For the conceptual learning component, the parameters were set to their default parameters 
(Anderson, 1991b)
; the coupling parameter, c, was set to 0.3, the Î± j parameter for each label was set to 0.01, and the Î± j parameter for each value of the other features was set to 1. 15


Benefits of Selective Sampling
Many real-world learning problems involve identifying a sparse signal hidden within a noisy high-dimensional space (similar to finding a needle in a haystack In both simulations, the stimuli were composed of 99 random binary features (generated through a process similar to coin flipping), and a single binary feature that perfectly correlated with the category label. During each of the 100 repetitions of each simulation, SEA was trained over 100 blocks of ten trials. As full preposterior inference (exhaustive forward search through the 100-dimensional space) imposes high computational demands, SEA was set to use a myopic strategy in which forward search was limited to one step ahead. In our first simulation 
(Figure 4
.A & 4.B), the cost associated with sampling each feature limited SEA's sampling behaviour to 5 or fewer features per trial.
Nevertheless, SEA quickly found the signal feature, and learned to ignore the others.
In the second simulation, instead of performing active sampling, SEA sampled every feature on every trial 
(Figure 4
.C). The comparison between the two models demonstrates how selective sampling based on expected utility can improve learning. Real world environments typically impose some cost for information sampling (e.g., time, effort, or value will be created. Low values of the Î± 0 parameter for the category label, for instance, would mean that distinct clusters with the same label would be unlikely.
monetary), and the number of features considered during deliberation is a function of these costs. Therefore, learning efficiency can be impaired when a models inductive bias (or prior) is inappropriately matched to the environment. Specifically, when estimated costs are too low, a decision-maker may sample too many-features. When decision costs are too high, the decision-maker may fail to efficiently explore the domain, and develop inaccurate beliefs as a result. A strongly cost-sensitive decision-maker, for example, may identify a single weakly-informative stimulus feature, and subsequently fail to identify more-reliable decision strategies (i.e., using a different stimulus feature, or considering a set of features).


A) B) C)
Active Sampling All Dimensions Sampled Active Sampling 
Figure 4
 . Classification accuracy increased quickly, such that after 40 training blocks, the model was typically able to categorize > 97% of the stimuli correctly. The number of features sampled (A) negatively covaried with the slope of the learning curve (B). This reflects the models ability to efficiently explore unsampled features (i.e., by considering the number of times each feature has been observed; Equation (11)), and capitalize on the single reliable feature in the simulation environment. The selective sampling model learned more quickly than a comparable model in which all stimulus features were always sampled (C).


Shepard et al. (1961)
For decades, the six problems developed by 
Shepard et al. (1961)
 have been a benchmark for testing formal categorization theories. In Shepard's six problems, stimuli consisting of three binary features, are used to define six different category problems ( 
Figure 5
). The type I problem is a one-dimensional task in which a single dimension is relevant and the other dimensions can be ignored. The type II problem is a two-dimensional rule-based task requiring the learner to employ a disjunctive exclusive-or (XOR) rule. In the type III, IV and V problems, all dimensions are informative, and for each category, all but one member can be categorized according to the same strategy, while the remainder must be categorized using a different strategy. These three problems also differ in interesting ways; the type III problem, for instance, can be solved using two dimensions, and the type IV problem is characterized by a linearly-separable prototype structure. Finally, in the type VI problem, all three dimensions are relevant, and participants must essentially memorize the individual stimuli.


I IV
V VI II III 
Figure 5
 . Geometric Depiction of the Six Problem Types 
(Shepard et al., 1961)
. Members of each category are denoted by white and black spheres. In the Type I problem, a single dimension is relevant. In the type II problem, two dimensions are relevant, and decisions makers must employ a logical XOR rule. In the type III, IV, and V problems, all dimensions are informative, but the categorization structures differ in interesting ways. In the type VI problem, all stimulus dimensions must be considered.
A typical finding, which has been both replicated 
(Nosofsky et al., 1994)
 and extended 
(Feldman, 2000;
Love, 2002;
Nosofsky & Palmeri, 1996)
, is that the initial difficulty of each task (as measured by the proportion of choice errors) closely reflects the number of dimensions that must be considered 
(Medin & Schaffer, 1978;
Nosofsky, 1984;
Shepard et al., 1961)
. Therefore, the tasks tend to increase in initial difficulty from type I to II, from II to {III, IV, V} 16 , and from {III, IV, V} to VI ( 
Figure 6
). In support of this idea, several formal categorization models, which include selective attention, are able to closely predict this behavioural effect 
(Nosofsky et al., 1994)
, while Bayesian models (like 
Anderson's Rational model;
Anderson, 1991b)
 tend to underestimate differences between the problems during early learning 
(Nosofsky et al., 1994)
.
We simulated the experiment performed by 
Rehder and Hoffman (2005a)
, who used eye-tracking to investigate whether the differences in behavioural accuracy between rules might reflect differences in information sampling. Their important finding was that, following learning, eye-movements closely reflected the behavioural relevance of each dimension ( 
Figure 6.A)
. These results provide compelling support for the idea that differences in attentional strategies underlie observed differences in behavioural accuracy between rules. The results also indicate that attention operates, not only at later decisional stages, but can influence information sampling behaviour.
We performed 1,000 simulations of this experiment using full preposterior forward search. Each simulation involved 28 learning blocks. In each block, each stimulus was presented in random order. Although we simulated all problems, our goal was to compare our findings to those of Rehder and Hoffman (2005a), so we report only results associated with problems I, II, IV and VI.
The model predicted the correct ordering of six problem difficulties. Perhaps more interestingly, the model learned to selectively sample behaviourally relevant stimulus dimensions across learning blocks ( 
Figure 6.B)
. Although the model used the same parameters for this simulation as for all others, this sampling behaviour resembled that of human decision-makers ( 
Figure 6.A)
. 17 One interesting difference, however, is that while humans tended to sample from all three dimensions during performance of the type IV problem, the model sampled an average of 2.5 dimensions. This reflects the prototype structure of this problem, which allowed SEA to strategically self-terminate on roughly half of the trials. The results of 
Rehder and Hoffman (2005a)
 imply that only a small percentage of high-performing participants may have self-terminated in this stimulus-specific way. While it is potentially interesting that the model identified this efficient sampling strategy, the propensity for self-termination will correlate with information cost. 
18
 In the next section, we apply SEA to a study whose design is ideal for evaluating whether people self-terminate and branch in a stimulus-specific way.


A) B)
Figure 6 . Human and model accuracy and sampling behaviour for the six problems described by 
Shepard et al. (1961)
. A) Left: Human categorization accuracy by learning block. Right: Model Accuracy by learning block. Mirroring behaviour of the Rational model 
(Anderson, 1991b)
, learning of the type IV was attenuated during later blocks relative to other problem types. For discussion of this effect, please see the original text. B) Left: In an eye-tracking study, 
Rehder and Hoffman (2005a)
 found that human participants learned to selectively fixate on behaviourally relevant stimulus dimensions across blocks. Horizontal axis: learning block. Right: Like human decision-makers, the model learned to selectively sample from behaviourally-relevant stimulus dimensions. Vertical-axis: number of dimensions sampled. Horizontal-axis: learning block.


Strategic Attention within Individual Trials
The results from the simulations of the 
Shepard et al. (1961)
 and 
Rehder and Hoffman (2005a)
 experiments demonstrate that the model is capable of mirroring the human tendency to strategically sample behaviourally-relevant information based on learned category structure. This type of feature-based attention is important for improving the efficiency with which decisions can be made. In many contexts, however, decision makers can further reduce the amount of information sampled by considering stimulus-specific factors.
For instance, in the category structure shown in 
Table 2
 (and in 
Figure 1
.B) , the indicator dimension (D1), by itself, is not predictive of category membership, but determines which of the two remaining dimensions should be sampled. When D1=1, for instance, the decision maker should sample D2 next, but when D1=2, only D3 is informative. Thus, 100% accuracy can be achieved by first sampling the indicator dimension, and then strategically sampling only one of the remaining dimensions. 19


Table 2
Category structure used by 
Blair et al. (2009)
 
& D3)
. The optimal strategy was to first sample dimension 1 (D1), and then sample either D2 or D3 depending on its value (i.e., if D1 = 0, the optimal strategy would be to sample D2, otherwise, one should sample D3). See also 
Figure 1
.B. 
A  1  1  1  A  1  1  2  B  1  2  1  B  1  2  2  C  2  1  1  C  2  2  1
 19 Interestingly, this category structure is closely related to the type III category structure of 
Shepard et al. (1961)
.


Category D1 D2 D3
Category D1 D2 D3 D 2 1 2 D 2
Participants in Blair et al's study learned to perform the task through trial-and-error, until either reaching a learning criterion of 24 correct consecutive trials or until a maximum of 200 total trials. Participants then performed an additional 72 (transfer) trials of the same stimuli without feedback. Data from participants (42%) who did not reach the accuracy criterion were excluded from the primary analyses. The findings indicated that participants were able to employ stimulus-specific attention during information sampling.
Participants tended to selectively sample dimensions 2 and 3 depending on the value of dimension 1, and therefore spent more time fixating on dimensions 1 and 2 for stimuli belonging to category A or B, and more time fixating on dimensions 1 and 3 for those belonging to category C or D.
To isolate behavioural effects reflecting the depth of the forward search process, we simulated this experiment using two model variants. The standard SEA model included stimulus specific attention and exhaustive preposterior search, while the myopic model considered only one step into the future. As each dimension is equally predictive in isolation, the myopic model was no more likely to sampling the indicator dimension than a non-indicator dimension. The myopic model, therefore, should sample the indicator dimension first on roughly one third of trials. In these trials, it could then select the appropriate non-indicator dimension to sample. However, if a non-indicator dimension was sampled first, the model should then randomly sample either the indicator dimension (and then self-terminate) or the other non-indicator dimension (and then sample the remaining dimension). As a result, when using a myopic strategy, the model should tend to sample a greater number of stimulus features than when preposterior analysis is used.
After reaching the learning criterion, the standard model correctly classified 93.3% of the remaining 72 transfer items. Mirroring human sampling behaviour, the standard model tended to sample all stimulus dimensions early in learning, but then tended to sample only 2 dimensions per trial: first D1, and then either D2 or D3. (The features sampled were optimal on 98.6% of trials). After reaching the learning criterion, the myopic model correctly classified 67.9% of the remaining 72 items. Like the standard model, the myopic model tended to sample all dimensions during early learning, and sample fewer dimensions later in learning. However, demonstrating the benefits of planning during information sampling, the myopic model tended to sample more dimensions than the standard model after learning (M = 2.33 instead of M = 2).


Modeling Eye-Movements in the "5/4" Categorization Task
The previous results from 
Blair et al. (2009)
 were inconsistent with a standard view of selective attention, but were compatible with SEA's sampling account which can lead to different sampling patterns for different stimuli. One possibility is that classic studies consistent with selective attention accounts in part reflect the averaging of different sampling patterns for different stimuli. In this section, we consider this possibility by revisiting 
Medin and Schaffer (1978)
 "5/4" categorization structure (shown in 
Table 3
), which was originally used to differentiate prototype-and exemplar-model accounts of category representation.
During a training phase, participants typically learn to categorize the first nine stimuli (A1-A5 and B1-B4) through trial and error. In a subsequent transfer phase, the participants also categorize the seven transfer items (T1-T7). The task is somewhat ill-defined, in that no single feature perfectly predicts the category label. Instead, the categories have a prototype structure (category A: [0,0,0,0]; category B: [1,1,1,1]), and the features differ in terms of how reliable they are with regards to prediction of the correct response. As shown in 
Table 3
, the "High1" and "High2" features each correctly predict the category label for seven of the nine training items, the "Med." feature predicts the correct category label for six out of the nine training items, and the last feature ("Low") predicts only five of the training items correctly.
Viewed through the lens of categorization models that include feature-wide attention parameters, an optimal decision-maker should place no-weight on the least-informative 716 feature. Exemplar models (e.g., 
Nosofsky, 1986)
, but not prototype models 
(Minda & 717 Smith, 2002;
Nosofsky, 1987)
, indicate that human participants tend to assign substantial 718 weight to this feature. This seemingly sub-optimal pattern of attentional weighting has 719 been interpreted as evidence favoring the prototype account of category representation 
Table 3
 The classic "5/4" Category Structure introduced by 
Medin and Schaffer (1978)
. Participants trained on the first nine stimuli (A1-A5 and B1-B4), and then, during a transfer phase, also categorized the remaining seven stimuli (T1-T7).
Stimulus High1 High2 Med. Low 
A1  2  2  1  2  A2  2  2  1  1  A3  2  2  2  1  A4  2  1  2  2  A5  1  2  2  2  B1  2  1  1  2  B2  1  2  1  2  B3  1  1  2  1  B4  1  1  1  1  T1  2  1  2  1  T2  2  1  1  1  T3  2  2  2  2  T4  1  2  1  1  T5  1  1  2  2  T6  1  2  2  1  T7  1  1  1  2
 To independently assess the attention devoted to each feature, 
Rehder and Hoffman (2005b)
 used eye-tracking to measure fixations to each feature across training. Visual features were randomly assigned to each category feature (i.e., the features depicted in Each transfer block consisted of a single presentation of each stimulus in random order, and no feedback was presented. Matching the predictions of exemplar theory, a key finding was that the majority of participants actually do display this seemingly sub-optimal attentional pattern.
In SEA optimality is defined with respect to the maximization of expected utility.
From this perspective, an active-sampling learner should seek to optimize scan paths for individual stimuli (i.e., minimizing sampling costs and maximizing reward). One possibility is that the attentional pattern observed by 
Rehder and Hoffman (2005b)
, might reflect an average across different optimal scan paths for individual stimuli.
To investigate this possibility, we simulated this experiment 1,000 times. Although the same parameters were used for all simulations, SEA's choice behaviour closely resembled that of human decision makers (Pearson r = 0.98; 
Figure 7
; 
Rehder & Hoffman, 2005b
). SEA's sampling behaviour also resembled human eye-movement data. Human decision-makers were more likely to sample the highly informative features (M (High1) = 80%, M (High2) = 80%) than the moderately informative feature (M = 75%), and were more likely to sample the moderately-informative feature than the least informative feature (M = 60%). SEA displayed the same ordering of feature fixation probabilities (High1 = 83%, High2 = 83%, Med. = 66%, Low = 17%).
These results provide a new vantage point on optimality for this task. From the perspective of models that have feature-wide attention, it is sub-optimal to place any weight (i.e., sample) the least informative feature in the 5/4 problem. However, according to SEA, featureal relevancy is contingent on what information has previously been sampled. According to SEA, depending on the stimulus and scan path, the so-called least informative feature can be highly informative. In those cases, SEA will sample this feature to maximize utility. SEA's strategic sampling leads it to sample 2.42 features on average for the 5/4 problem whereas a feature-wide attention model would need to consider 3.0 features on every trial. In light of this result, one conclusion is to exercise caution in characterizing attentional allocation as sub-optimal when stimulus-specific scan paths can increase sampling efficiency. 
Figure 7
 . Choice data (probability of choosing category "A" for each stimulus) for the model (solid line), and for human participants (dashed line; 
Rehder & Hoffman, 2005b)
.
A 1 A 2 A 3 A 4 A 5 B 1 B 2 B 3 B 4 T 1 T 2 T 3 T 4 T 5 T 6 T 7 0.0 0.2 0.4 0.6 0.8 1.0 Model Behavior Choice P(A) Stimulus


Rule-Plus Exception
In the previous simulations, we focused on eye tracking studies as they provide an independent estimate of attention (assuming a typically strong coupling between eye-movements and attention holds; e.g., 
Deubel & Schneider, 1996)
. However, we intend our theory and model to not only accurately predict human sampling behaviour, but to additionally account for effects thought to reflect the resulting mnemonic structure. To illustrate how our model performs subsequent recognition memory, we applied SEA to an experiment using the rule-plus exception category structure 
(Table 4)
. In this structure, most stimuli can be accurately sorted into categories according to a simple rule, but the remaining exception items must be recognized, and categorized according to a different strategy. Behaviour on this task reveals interesting differences in how rule-following and exception items are encoded. 
Table 4
 Rule-plus exception category structure 
(Davis et al., 2012c)
. Participants in this study learned to categorize based on the first eight stimuli (Item Type: "Train"). By attending only to the first feature ("D1"), participants would be able to categorize three of the four stimuli within each category. 2007; 
Palmeri & Nosofsky, 1995;
Sakamoto & Love, 2004)
. This is thought to reflect 774 stronger encoding of the rule-irrelevant features for the exception items. Differences in categorization and recognition accuracy between the rule-following and exception items, therefore, suggest differences in the organization of conceptual knowledge. As single-system categorization models (e.g., 
Nosofsky, 1986)
 have difficulty accounting for this effect, dual process frameworks (involving separate representational systems for rule-following and exception items) have been proposed (e.g., 
Nosofsky et al., 1994)
. We predicted that due to its minimization of sampling cost, SEA would develop incomplete representations of rule-following items (i.e., ignoring rule-irrelevant features). We also predicted that SEA would sample more features for exception items (as these need to be differentiated from rule-following items, and then sorted according to a different strategy).
In SEA, recognition strength is modeled (by the concept-learning component) as the likelihood of the observed stimuli, given the learned clusters:
Recognition Strength = k P (F O |k)P (k),
(13)
where P (k) denotes the prior probability of existing clusters (Equation 
4
 
Figure 8
 . A) Human Behaviour: Recognition ("Rec.") and categorization ("Cat.") accuracy for rule-following ("Rule") vs. exception ("Ex.") stimuli 
(Davis et al., 2012b)
. While categorization accuracy was greater for rule-following items, recognition accuracy was greater for exception items. Error bars reflect 95% confidence intervals. B) Model Behaviour. Mirroring human behaviour, the model displayed greater categorization accuracy for rule-following items than for exception items, but greater recognition strength (Equation (13)) for the exception items than the rule-following items. (Note differences in the vertical-axis scale for categorization accuracy and recognition strength.) C) Model Categorization Behaviour: Categorization accuracy for rule and exception items for the standard and yoked ("Y") models. Mirroring human behaviour, both models displayed better categorization accuracy for rule-following items than for the exception items. Accuracy for the yoked model was lower than that of the standard-model. Model-type and stimulus-type interacted such that the yoked model displayed a greater difference in accuracy between rule-following and exception stimuli than the standard model. D) Model Sampling Behaviour. While the standard model sampled a greater number of features for exception items than for rule-following items, the yoked model did not.
The model results conformed to the pattern of human results, as rule-following items had an accuracy advantage during learning, and a disadvantage during subsequent recognition test 
(Figure 8
). As illustrated by the black bars in 
Figure 8
.D, our model sampled fewer features (M = 2.45) for rule-following items than for exception items (M = 3.17) during learning, reflecting a learned strategy of sampling until the presence or absence of an exception item could be determined.
To better understand the consequences of this learned sampling strategy, we simulated a yoked model that inherited the scan-paths from a simulation of our standard model. This removes the possibility of hypothesis-dependent sampling, as the concept-learning and active-sampling components were decoupled. 
20
 Compared to our regular model, the yoked model's performance was particularly impaired on the exception items. The yoked model made disproportionately more errors to the exception items during learning (see 
Figure 8
.C) and was worse than our standard model in recognizing these items. This finding illustrates the importance of strategic sampling in this task. In particular, the categorization task necessitated greater sampling of information about exception items, leading to a more complete representation of these items in memory.


General Discussion
SEA describes how people strategically sample information while learning and making decisions. It consists of a Bayesian learning component, which models beliefs about the world, and an information-utility component that conducts a goal-directed forward search on these beliefs. Interactions between the two components allow the model to actively learn about the external world by sequentially sampling from information sources expected to provide useful information. In SEA, usefulness reflects both a drive to maximize gain in utility (exploitation of existing knowledge), and a drive to maximize knowledge of the external world (exploration). As a consequence of active sampling, SEA's knowledge of the world reflects the utility function it strives to optimize 
(Table 1 provides
 an example of a utility function that would maximize decision accuracy). SEA differs from single-step categorization models that sidestep questions related to active sampling, and contort representations of encoded dimensions based on their behavioural relevance (e.g., 
Kruschke, 1992;
Love et al., 2004;
Nosofsky, 1986
). SEA's active sampling behaviour, however, leads to the development of dense representations along dimensions expected to be behaviourally-relevant, and sparse representations along dimensions expected to be irrelevant. As a result, SEA provides a compelling account for many aspects of human categorization behaviour. One example is that SEA can develop and maintain beliefs that systematically deviate from reality ( 
Figure 2
). This is interesting, as each component can be considered normative in its own right.
As our goal was to offer a general theory of how attentional-like behaviour could emerge from sequentially sampling information according to its expected utility 
(TrommershÃ¤user, Landy, & Maloney, 2006)
, SEA was not tuned to any of the individual tasks. The default parameters form 
Anderson's (1991)
 rational model were used throughout. Similarly for each simulation, an arbitrary cost of 10 utility units was imposed for sampling each stimulus feature. Although it was not tuned to particular datasets or tasks, SEA was able to capture a wide range of category learning findings. For example, in addition to capturing the basic difficulty ordering of the six problem types described by 
Shepard et al. (1961)
 
(Kruschke, 1992;
Nosofsky et al., 1994)
.
SEA can additionally address sampling phenomena that are outside the scope of existing models with attentional mechanisms. Rather than initially-encoding all information used to form the decision, and then contorting these encoded representations based on their behavioural relevance, SEA's information-utility component selects relevant information through a dynamic forward search process. This allows the model to allocate attention flexibly within individual trials (as in 
Blair et al., 2009)
. This ability is unavailable to models in which attention operates at the level of individual features, but not at the level of individual stimuli. Moreover, as indicator features (such as those in the category structure considered by 
Blair et al. (2009)
, which indicate the next appropriate feature to sample) can be considered as contextual cues signaling appropriate decisional strategies, SEA's active sampling procedure naturally accounts for effects associated with context-gated knowledge partitioning 
(Lewandowsky, Roberts, & Yang, 2006;
Little & Lewandowsky, 2009;
Yang & Lewandowsky, 2003)
.
This capacity to flexibly sample from information sources expected to provide useful information supports an alternative interpretation of findings associated with the classic 5/4 category structure 
(Medin & Schaffer, 1978;
Rehder & Hoffman, 2005b)
. In our simulations, SEA sampled stimulus features at an overall rate consistent with the best-fit attention weights from the GCM exemplar model. However, these overall sampling proportions arose in SEA from averaging heterogeneous sampling patterns across the individual stimuli. One possibility is that heterogeneous sampling behaviour might also explain why these weights arose for the GCM. By characterizing each category decision as the culmination of an active sampling process, SEA offers a rich account of the micro-structure of each trial that can be tested experimentally. In cases such as the 5/4 studies, this dis-aggregation offers novel insights into classic categorization tasks and alternative accounts of the behavioural results.
Although we have focused on eye-tracking studies, we intend SEA to apply to other kinds of behaviour. Even in cases in which all stimulus features fall within the same spatial location, its selective sampling processes should still be operable. To illustrate this point, we applied SEA to a rule-plus-exception category learning problem in which most items followed a simple rule, and the remaining exception items had to be categorized according to a different strategy 
(Davis et al., 2012a
(Davis et al., , 2012c
. Like human decision-makers, SEA made more errors on exception items during learning while also showing enhanced recognition for these items following learning. This reflects increased representational density for the rule-following items relative to the exception items; as SEA tended to sample more stimulus features for exception items (sampling each stimulus until it could be determined whether it was an exception).
We also aimed to show how behaviours beyond the scope of classic models of selective attention could be explained in terms of strategic sampling. That SEA could capture the qualitative data patterns in these studies, and in cases offer novel interpretations and predictions, is a strength of this work. In this contribution, we did not stress comparison to alternative models, though we did note where classic selective attention models and myopic versions of SEA that do not perform full-look-ahead search would fail. In the future, finer-grained model comparisons and fits to data, including to individual participants, can assist in evaluating alternative strategic sampling models.
By considering information gathering to be an integral component of category learning, the current approach recasts categorization as a dynamic decision making problem. This is similar to a model-based reinforcement-learning approaches, in which the learning agent incrementally builds a model of the external world, while at the same time using the model to adjust its policy (i.e., guide the agent's choices; 
Sutton, 1990
Sutton, , 1991
. In these kinds of dynamic decision making tasks, optimal performance requires a delicate balance between exploration (which provides the highest returns according to current estimates of utility) and exploitation (which help the agent to discover options with potentially greater utility; 
Kaelbling et al., 1996;
Sutton & Barto, 1998)
.
Although it places less emphasis on managing the exploration/exploitation trade-off, the model most similar to SEA is likely that developed by 
Nelson and Cottrell (2007)
. This model combines a Bayesian concept-learning component (which was designed for the six problem types described by 
Shepard et al., 1961)
, with an active sampling procedure driven by the expected information gain of each stimulus feature 
(Nelson, 2005)
. In conjunction with a fixed cost for sampling each feature, the sampling procedure encouraged the model to selectively sample task-relevant stimulus features; mirroring previously-observed patterns of human eye-movements 
(Rehder & Hoffman, 2005a
 
(Ng & Jordan, 2002)
. In brief, generative and discriminative models characterize the task of the learner differently. Generative models attempt to learn an internal model of each class (i.e., category). In contrast, discriminative models attempt to find a boundary that separates classes. Generative models are typically Bayesian in form, whereas discriminative models include decision trees, SVMs, regression approaches, and some (but not all) connectionist models. In generative models, the learning task is to estimate the joint probabilities between all variables. These models assume that a hidden or latent variable (e.g., a category label)
generates the observed features. In contrast, discriminative models perform a conditional estimation. For example, logistic regression only estimates the probability of a class (i.e., category) as a function of the predictive features. In this sense, discriminative models are more focused by the task, whereas generative models address a broader estimation problem, though models of all types have an inductive bias to make learning tractable.
SEA displays characteristics of both generative and discriminative models. SEA is a generative model in that it builds an internal model of the world that can be sampled from.
On the other hand, its internal model is heavily biased by the discriminative pressures of the tasks it performs, which results from its utility-driven sampling. Therefore, rather than attempting to build an unbiased model of the world, SEA samples information that it expects will be useful for performance of the task. While learning to classify items as members of one of two contrasting categories, for example, SEA will naturally focus on information that discriminates the two categories. SEA is therefore a generative model whose internal model of the world is shaped by its goals. This is also the defining characteristic of the SUSTAIN clustering model 
(Love, 2005)
. In effect, SEA follows SUSTAIN's basic principles, but updates and places these principles within a Bayesian framework. This allows SEA to handle uncertainty, display strategic sampling behaviour, and model changes in tasks and goals via changes of its utility function.
These characteristics allow SEA to capture behaviours not typically associated with Bayesian models. One such behaviour is blocking 
(Kamin, 1969)
, in which knowledge of an informative stimulus feature can interfere with the learning of another. For example, consider a trial-by-trial category learning task in which the shape feature is predictive of category membership, and all other stimulus features are irrelevant. During early trials, SEA predicts that all features will be sampled occasionally, consistent with findings of a uniform prior in repeated resource allocation games 
(Benartzi & Thaler, 2001;
Langholtz, Ball, Sopchak, & Auble, 1997)
. However, assuming some cost to sampling information (e.g., a desire to minimize cognitive effort), eventually, only shape information will be sampled and other stimulus features will be ignored. Thus, if another feature that was previously behaviourally-irrelevant becomes informative, SEA would be unlikely to learn this new relationship.
The simulations reported here involved classification learning in which the learner aims to predict the category label from the features. In this induction task, all the features are known and the category label is inferred. However, other induction tasks are possible, such as inference learning, in which the learner knows the category label and one of the features is inferred instead (e.g., This is a fish. Does it have scales?). Although inference and classification learning are informationally equivalent (after feedback is provided, inference and classification learning provide the same information to the learner), but strongly influence what human decision-makers ultimately learn 
(Chin-Parker & Ross, 2002;
Rehder, Colner, & Hoffman, 2009;
Sakamoto & Love, 2010;
Yamauchi, Love, & Markman, 2002;
Yamauchi & Markman, 1998)
. In classification learning, people tend to learn information that discriminates between the two categories. In inference learning, however, people tend to learn more about the internal structure of each category.
When its utility function is adjusted to reflect each task, SEA's behaviour is consistent with these results. For classification learning, SEA's utility function should emphasize predicting the category label. In inference learning, SEA's utility function should emphasize predicting whatever feature is absent on the current trial. In effect, the task demands should shape SEA's utility function, which will in turn shape SEA's internal model; consistent with the psychological theory of how human memory is shaped by these tasks 
(Markman & Ross, 2003)
. Related manipulations that alter the presentation order of features and label 
(Ramscar, Yarlett, Dye, Denny, & Thorpe, 2010)
 or the isolation of categories 
(Goldstone, 1996)
 could also be accommodated in a principled way by tailoring SEA's utility function.


Future Directions
One line of future work is improving SEA's basic components. For example, SEA's learning component relies on 
Anderson's (1991b;
1990)
 Rational Model of Categorization.
Virtually any other concept learning model could be used that can perform forward planning by estimating the probabilities of unobserved features. Basic improvements could also be made to SEA's information-utility component. SEA's information-utility component performs an exhaustive forward search; evaluating the full breadth and depth of the decision-tree defined by the stimulus attributes. As the number of possible branches increases exponentially with the number of features considered, this exhaustive approach is prohibitively expensive for all but the simplest problems.
We did consider a myopic version of SEA that lowered search costs (in terms of computation) and performed well in some environments 
(Figure 4)
. On occasions, people may also engage in simple myopic search strategies (e.g., 
Busemeyer & Rapoport, 1998)
.
However, our results also highlight more sophisticated search strategies. One possibility would be to allow the model itself to appropriate depth of the forward search 
(Snider, Lee, Poizner, & Gepshtein, 2015)
. For the problems considered here, searching only two steps ahead would have been sufficient to support human-like behaviour. A model starting with a shallow search and then progressing deeper until reaching a performance plateau could be a viable model for human information sampling. More sophisticated search procedures, of course, could also improve computational efficiency, and/or better capture human characteristics. For example, Google DeepMind's AlphaGo, which defeated a champion human Go player, relies on Monte Carlo tree search to selectively explore the most promising parts of the search space 
(Silver et al., 2016)
. People may similarly rely on memory to retrieve the most effective search strategies used in the past 
(Logan, 1988)
.
In addition to considering the search strategy, where the primary concerns are computational complexity and pruning of the search space, consideration of alternative evaluation strategies, such as a "confirmatory" or "positive" testing strategies 
(Klayman, 1995)
, would also be fruitful. In a sense, SEA already explains people's tendency to engage in confirmatory behaviour in terms of using a biased internal model for forward planning.
Therefore, SEA can be considered an alternative account of how confirmatory behaviour can arise. Rather than solely reflecting a faulty reasoning process, confirmatory behaviour may reflect a biased internal model. In other words, a decision-maker could try to reduce uncertainty through preposterior inference, but fail to make accurate predictions as a result of inaccurate beliefs. SEA's capacity for this behaviour makes it susceptible to phenomena like blocking. Our hope is that it will advance our understanding of broader phenomena, such as echo chambers or filter bubbles, in which personalized information searches and social media use can lead to under-exposure to alternative viewpoints, resulting in inaccurate, or incomplete, worldviews 
(Pariser, 2011)
.
Incorporating alternative search and evaluation strategies may increase SEA's quantitative fit to human data, as could incorporating additional noise sources into SEA's evaluation and decision processes. Across the simulations considered here, SEA's behaviour could be characterized as somewhat idealized in comparison to human participants. In this contribution, we prioritized illustrating basic principles and performance patterns over quantitative fit. Future efforts may emphasize quantitative fit and measurement of individual differences in learning and information sampling strategies.
SEA also suggests fruitful research avenues to explore in psychology and neuroscience.
Traditional models of selective attention (e.g., 
Kruschke, 1992;
Love et al., 2004;
Nosofsky, 1986
) have been useful at both the behavioural and neural levels of analysis 
(Braunlich & Love, 2018;
Mack, Preston, & Love, 2013)
. While these models provide a principled way to investigate how information is organized during decision-making, they tend to sidestep questions related to active sampling processes which unfold across time during deliberation. SEA, however, posits that more sophisticated sampling processes unfold across time during deliberation. This opens a number of avenues for future investigation. For example, SEA
proposes that an optimal decision-maker should consider the gain in utility from each feature (G(F i ), Equation (8)). This variable can be subdivided into three sub-components:
the expected cost of sampling a feature, the gain in utility of sampling the feature without consideration of its cost, and the expected reliability (i.e., expected inverse variance) of each feature. SEA also provides an estimate of the expected reduction in uncertainty about the appropriate final choice from sampling each feature. In addition to the issues outlined above regarding search strategies, each of these variables may be of interest to scientists interested in examining intra-trial attentional effects. The code for all simulations is available online (https://github.com/lovelabUCL/SEA).


Conclusions
Current models of categorization provide a compelling account for how information is organized to support advantageous decision-making 
(Figure 1.A)
. Although these models provide important insights into decision-making strategy, they sidestep sequential and contingent information sampling processes that can occur within individual trials ( 
Figure   1
.B), and which are necessitated by the computational demands of interacting with the high-dimensional real world. As illustrated in 
Figure 4
.C, encoding all available sensory information in high-dimensional environments is computationally inefficient (at least at high resolution; 
Goffaux et al., 2010)
. Accordingly, decision-makers appear to draw on their existing knowledge to selectively sample information from sources expected to provide behaviourally-relevant information 
(Blair et al., 2009;
Najemnik & Geisler, 2005;
Nelson & Cottrell, 2007;
Yang et al., 2016)
. Active-sampling learners therefore can develop beliefs about the world that systematically deviate from reality 
(Figure 2
), particularly when competing demands for exploration and exploitation are not balanced appropriately.
Sampling Emergent Attention (SEA) describes these bidirectional effects on the development of conceptual knowledge. Although it is largely formulated at the computational level 
(Marr, 1982)
, it makes predictions about how behaviour should unfold both within and across trials, and should be useful in understanding and predicting human behaviour. SEA should serve as a useful guide for understanding attentional effects, learning, and decision phenomena underlying the development of biased representations of the external world. Such effects are not only common in the laboratory, but are of fundamental importance for understanding how capacity-limited decision-makers interact with the high-dimensional external world.


Nomenclature
a Action Î± j Dirichlet prior for particular value on particular stimulus feature Î± 0 Dirichlet prior for a stimulus feature (Î± 0 = j Î± j )
c Coupling probability 
C
Figure . A )
A
Active learning requires decisions, not only about the final choice, but about


denotes the index of the observed features of a given stimulus, and i denotes the index of the unobserved feature under consideration. For instance, given a stimulus (including both observed and unobserved dimensions) defined as vector F = [2, 1, 1, 2], if the second feature was under consideration and the third and fourth features were known, then i would be 2, O would be[3,4], and F O would be[?, ?, 1, 2].


). The choice of what feature to sample would then be made stochastically using the softmax choice rule (equation(12)).Conceptually, preposterior analysis is an extension of the myopic algorithm that involves simulation of multiple unobserved features. As in the previous example, the model might begin a trial by calculating the expected utility of the first feature (feature "1") being "0" (i.e., F O = [0,?,?]). Holding this imaginary feature-value constant, SEA would then simulate the expected utility if other features were subsequently sampled. For instance, to simulate sampling feature "2", SEA would consider the expected utility of states F O = [0,0,?] and F O = [0,1,?], using equation(8). It would then abstract over these possible values using equation (9). It would then calculate the gain in utility and the exploration bonus associated with sampling this feature using equations (10) and (11).


). Our estimate of recognition strength therefore reflects the degree to which a stimulus activates the existing clusters. This variable comprises the denominator in equation (1) and so plays an important role in normalizing estimates of P (k|F O ).


ij Number of times value j has been observed on feature i in a particular cluster G Gain in utility F Features (or "Dimensions", or "Information sources") j Feature value k Cluster number L o Sampling cost associated with feature o n k Number of items assigned to cluster k U Utility


).
A)
Shape
Shape
Size
Color
Size
Color
B)
D1?
D2? D3?
D3? D2?
C
D3?
D2? D1?
D1? D2?
D2?
D1? D3?
D3? D1?


term gain. 10 To encourage exploration of under-sampled information sources, SEA can include exploration bonuses for under-sampled information sources. As the partially observable Markov decision process (POMDP) can only be solved for relatively simple problems
net long-
), but also about what information to sample; Figure
1.B). It combines two normatively-motivated components. The first is a concept-learning
component that reflects the decision maker's knowledge of the world. The second is a
utility-sensitive sampling component that calculates the expected utility of particular
states. The two components interact to perform preposterior analysis. These interactions
allow the model to selectively sample from information sources that are expected to be
useful for differentiating a set of active hypotheses.
Strategically-sampling learners, such as SEA, can easily learn representations that
deviate from reality (Figure 2; Rich & Gureckis, 2018). This can happen when the learner
fails to balance competing demands for exploration and exploitation. For instance, when a
number of costly experiences with a stochastic variable are encountered early in training, a
cost-sensitive decision-maker may choose to avoid it; and never learn that it actually yields


Table 1 A
1
hypothetical action-utility function reflecting the utility for two actions: a p and a q . For this particular function, maximizing utility is equivalent to maximizing accuracy. Correct responses are rewarded with 100 utility units, and incorrect responses are awarded 0 units.


SEA proposes that this expected increase in utility from sampling F i is the key variable to consider when deciding what feature to sample, or whether to stop sampling and commit to a final choice. When G(F i ) for all features is less than, or equal to zero, a cost-sensitive decision-maker should stop sampling and commit to a final choice. When (F i ) for at least one feature is greater than zero, an exploitative strategy would be to sample the feature with the greatest gain.Importantly, costs are often dependent across features. The cost of a blood test, for instance, can be substantially less if other blood tests have already been ordered. A normative strategy therefore requires the consideration of all possible sequences of tests to account for these potential dependencies. As the computational demands of this approach increase exponentially with the number of features considered, it can only be justified when decisions involve a low number of stimulus features (as is common in psychology experiments), or when there is sufficient time available for deliberation and the stakes arehigh.An alternative would be to select tests myopically, selecting the next test without consideration of those following it. Such selection strategies are guaranteed to be optimal only if the next test happens to be the last. Interestingly, previous work has indicated that
human behaviour is often myopic during sequential sampling (or deferred decision) tasks


In deciding which feature to sample, SEA plans ahead for the maximal number of steps, like an adult might when playing a simple game such as tic-tac-toe. In the simulations, we compared SEA to , we describe SEA's behaviour in a two-class categorization problem involving stimuli with three binary stimulus features. We assume that the model has already been trained.Myopic decision-making involves simulating the sampling of single unobserved features. Before sampling any stimulus features F O is[?,?,?]. To determine what feature to sample first, the model simulates the effects of sampling each. For instance, The model might calculate the expected utility of the possible states after sampling the first feature
). Importantly, the utility-sensitive sampling component does not learn utilities of various states. Instead, SEA is initialized with a utility table (as in Table 1), and with the costs imposed by sampling each information source. The conjunction of the concept-learning and utility-sensitive sampling components allows the model to perform active sampling. Equation (8) is used to calculate the expected utility of states (i.e., specific stimulus feature configurations), abstracting beyond specific actions (or choices). Equation (9) is used to calculated the expected utility associated with sampling an unseen feature, abstracting beyond its possible values. This helps the model to determine if, after sampling a single feature, whether it should sample another feature. To make this determination, SEA considers information gain (equation (10)) and the exploration bonus for each unsampled stimulus feature (equation (11)) and combines them using a softmax choice rule (equation (12)). Myopic Decision-Making vs. Preposterior Analysis.variants that are myopic in that they only consider the next step or move. To clarify how the equations interact to support myopic decision-making and Preposterior analysis(i.e., F O = [0,?,?] or [1,?,?]) using equation


choice. As reviewed above, these sequential decisions about what features are goal-relevant can influence patterns of eye movements during short-duration decisions (i.e., less than~3 sec.), which are common in the categorization literature. Whereas successful contemporary theories of categorization tend to rely on attentional parameters that weight stimulus features according to their behavioural relevance, the proposed model can select relevant information through active sampling.To compare SEA's behaviour to human decision-makers and other computational models, we simulate several experiments. In the first, we demonstrate the utility of SEA's active sampling approach in high-dimensional environments. In the second, we investigate its choice behaviour in the classic six problems introduced by
Shepard et al. (1961)
 (a well-known test for formal models of categorization). To compare SEA's sequential sampling behaviour to that of human decision-makers, we then simulate an eye-tracking experiment conducted by


Table 3 )
3
in a counterbalanced fashion (across participants) to account for effects associated with visual salience. Through trial-and-error, participants trained until either completing 21 training blocks in total, or completing two consecutive blocks without error. Each block involved a single presentation of each of the nine stimuli in random order. During the subsequent transfer phase, participants categorized all 16 stimuli in each of two blocks.


). SEA is additionally able to predict the correct ordering of problem difficulties (i.e., Type I < II < IV < VI), 21 a common touchstone for evaluating formal categorization models.Nelson and Cottrell's    work can be seen as a special case of SEA. First, SEA includes a flexible concept-learning component that is capable of learning a wide variety categorization problems. Second, it is flexible, in that it can maximize accuracy or expected utility. This is useful when the maximization of utility and accuracy represent distinct objective functions. Below, we discuss some possible elaborations of SEA after first considering some implications of this work.
Bayesian Discriminative Learning. One popular distinction in machine learning
is between discriminative and generative models


In the category-learning literature, stimuli with two-four features are common (e.g.,
Nosofsky, 1986;
Shepard et al., 1961)
, and stimuli with 16 features are considered to be high-dimensional (e.g.,
Vong, Hendrickson, Navarro, & Perfors, 2018)
.


For example, when making a diagnosis a doctor might initially conduct a blood-test, and then choose an additional test once the results are known.


In the model, non perceptually-separable dimensions are effectively treated as a single information source, as it is not possible to sample one without the other.5 However, as SEA considers only the expected utility of each stimulus feature with regards to the final choice, it is not influenced by factors such as perceptual salience, which are known to influence human eye-movements
(Rehder & Hoffman, 2005b)
. Perceptual salience could be included as an independent factor that increases the likelihood of sampling.


Raiffa (1961)
 describes terminal analysis as the selection of an appropriate action after an experiment has been performed, and preposterior analysis as the selection of appropriate experiments.


This particular example corresponds to the probability gain sampling norm, which provides a compelling account of human information search
(Nelson, 2005;
Nelson, McKenzie, Cottrell, & Sejnowski, 2010)
.


As this partially observable Markov decision process (POMDP) can only be solved for relatively simple problems
(Knox, Otto, Stone, & Love, 2012)
, non-heuristic approaches are often computationally intractable.


Development of inaccurate representations can also be driven by similarity between information sources. For instance, information sources that resemble others that impose high costs might be avoided. They can also result from learned selective attention (e.g., blocking;
Kruschke & Blair, 2000)
.


This process is similar to that of infinite mixture models
(Rasmussen, 2000)
 and Dirichlet-process mixture models
(Neal, 2000)
.12 Tractable approximations based on particle filters have been developed (e.g.,
Brown & Steyvers, 2009;
Daw & Courville, 2008;
Sanborn, Griffiths, & Navarro, 2006)
. Markov Chain Monte Carlo methods (MCMC;
Andrieu, de Freitas, Doucet, & Jordan, 2003)
 can also be used to sample the space of category partitions.


We assume costs associated with the final action are included in the utility table (e.g.Table 1). These costs are not learned by the model, but are specified to match characteristics of the stimulus. Although we do not manipulate cost here, different stimulus features could have different associated costs.


In this example, a depth-two search process would involve considering the expected utility of 18 stimulus configurations: [0,?,?], [1,?,?], [?,0,?], [?,1,?], [?,?,0], [?,?,1], [0,0,?], [0,1,?], [1,0,?], [1,1,?], [0,?,0], [0,?,1], [1,?,0], [1,?,1], [?,0,0], [?,0,1], [?,1,0], [?,1,1].


Like all other parameters, information costs were held constant across simulations.


(Minda & Smith, 2002)
.


Because the calculations of the concept-learning component are stochastic, and because the stimuli were randomized, the yoked model was unable to perform stimulus-specific sampling. When coupled, the probabilistic calculations of the concept-learning component guide active sampling.








 










Is human cognition adaptive? The Behavioral and Brain Sciences




J
R
Anderson




10.1017/S0140525X00070801




















The adaptive nature of human categorization




J
R
Anderson








Psychological Review




98
















A rational analysis of categorization




J
R
Anderson






M
Matessa








Proceedings of the Seventh International Conference (1990) on Machine Learning


the Seventh International Conference (1990) on Machine Learning


















An introduction to MCMC for machine learning




C
Andrieu






N
De Freitas






A
Doucet






M
Jordan








Machine Learning






50














Naive diversification strategies in defined contribution saving plans




S
Benartzi






R
H
Thaler








American Economic Review




91


1


















10.1257/aer.91.1.79














Extremely selective attention: Eye-tracking studies of the dynamic allocation of attention to stimulus features in categorization




M
R
Blair






M
R
Watson






R
C
Walshe






F
Maj




10.1037/a0016272








Journal of Experimental Psychology: Learning, Memory, and Cognition




35


5
















Occipitotemporal representations reflect individual differences in conceptual knowledge




K
Braunlich






B
C
Love




10.1037/xge0000501








Journal of Experimental Psychology: General
















Random sequences change detection particle filters gambler's fallacy




S
D
Brown






M
Steyvers








Cognitive Psychology




58
















Concept identification of auditory stimuli as a function of amount of relevant and irrelevant information




R
G
Bulgarella






E
J
Archer








Journal of Experimental Psychology




63


3
















Psychological models of deferred decision making




J
R
Busemeyer






A
Rapoport








Journal of Mathematical Psychology




32
















Human Active Learning




R
M
Castro






C
Kalish






R
Nowak






R
Qian






T
Rogers






X
Zhu








Advances in Neural Information Processing Systems


D. Koller, D. Schuurmans, Y. Bengio, & L. Bottou




Curran Associates, Inc




21














The effect of category learning on sensitivity to within-category correlations




S
Chin-Parker






B
H
Ross








Memory & Cognition




30


3
















Decisions in changing conditions: The urgency-gating model




P
Cisek






G
A
Puskas






S
El-Murr








Journal of Neuroscience




29


37


















10.1523/JNEUROSCI.1844-09.2009














Where science starts: Spontaneous experiments in preschoolers' exploratory play




C
Cook






N
D
Goodman






L
E
Schulz








Cognition




120


3


















10.1016/j.cognition.2011.03.003














Age-related declines in the fidelity of newly acquired category representations




T
Davis






B
C
Love






W
T
Maddox








Learning & Memory




19


8


















10.1101/lm.024919.111














Learning the exception to the rule: Model-based fMRI reveals specialized representations for surprising category members




T
Davis






B
C
Love






A
R
Preston




10.1093/cercor/bhr036








Cerebral Cortex




22


2
















Striatal and hippocampal entropy and recognition signals in category learning: Simultaneous processes revealed by model-based fMRI




T
Davis






B
C
Love






A
R
Preston




10.1037/a0027865








Journal of Experimental Psychology. Learning, Memory, and Cognition




38


4
















BIDIRECTIONAL INFLUENCES












The pigeon as particle filter




N
D
Daw






A
C
Courville








Advances in Neural Information Processing Systems


















Cortical substrates for exploratory decisions in humans




N
D
Daw






J
P
O'doherty






P
Dayan






B
Seymour






R
J
Dolan




10.1038/nature04766








Nature




7095
















Saccade target selection and object recognition: Evidence for a common attentional mechanism




H
Deubel






W
X
Schneider








Vision Research




36


12
















Irrelevant information in probabilistic categorization




S
E
Edgell






N
J
Castellan






R
M
Roe






J
M
Barnes






P
C
Ng






R
D
Bright






L
Ford








Journal of Experimental Psychology: Learning, Memory, and Cognition




22


6


















10.1037/0278-7393.22.6.1463














Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing




W
Edwards




10.1016/0022-2496(65)90007-6








Journal of Mathematical Psychology




2


2
















On the role of causal intervention in multiple-cue judgment: Positive and negative effects on learning




T
Enkvist






B
Newell






P
Juslin






H
Olsson








Learning




32


1










Memory








Theory of optimal experiments




V
Fedorov








Academic Press


New York, NY












Optimal experimental design




V
Fedorov




10.1002/wics.100








Wiley Interdisciplinary Reviews: Computational Statistics




2


5
















Minimization of Boolean complexity in human concept learning




J
Feldman




10.1038/35036586








Nature




6804
















Interaction of stimulus dimensions in concept and choice processes




W
R
Garner




10.1016/0010-0285(76)90006-2








Cognitive Psychology




8


1
















A dynamic allocation index for the discounted multiarmed bandit problem




J
C
Gittins






D
M
Jones








Biometrika




66


3
















From coarse to fine? Spatial and temporal dynamics of cortical face processing




V
Goffaux






J
Peters






J
Haubrechts






C
Schiltz






B
Jansma






R
Goebel








Cerebral Cortex




21


2
















Isolated and interrelated concepts




R
L
Goldstone








Memory & Cognition




24


5
















Understanding active sampling strategies: Empirical approaches and implications for attention and decision research




J
Gottlieb








Cortex




102


















10.1016/j.cortex.2017.08.019














Towards a neuroscience of active sampling and curiosity




J
Gottlieb






P.-Y
Oudeyer








Nature Reviews Neuroscience




1














Unifying rational models of categorization via the hierarchical Dirichlet process




T
L
Griffiths






K
R
Canini






A
N
Sanborn






D
J
Navarro










Proceedings of the 29th Annual Conference of the Cognitive Science Society


the 29th Annual Conference of the Cognitive Science Society
















Active learning strategies in a spatial concept learning game




T
M
Gureckis






D
B
Markant








Proceedings of the Annual Meeting of the Cognitive Science Society


the Annual Meeting of the Cognitive Science Society






31












The elements of statistical learning: Data mining, inference, and prediction (Second)




T
Hastie






R
Tibshirani






J
Friedman








Springer












A model of saliency-based visual attention for rapid scene analysis




L
Itti




n.d








C
Koch




n.d








E
Niebur




n.d






10.1109/34.730558








IEEE Transactions on Pattern Analysis and Machine Intelligence




20


11














Learning in embedded systems




L
P
Kaelbling








MIT Press. BIDIRECTIONAL INFLUENCES


Cambridge, Mass












Reinforcement learning: A survey




L
P
Kaelbling






M
L
Littman






A
W
Moore








Journal of Artificial Intelligence Research




4
















Selective association and conditioning




L
J
Kamin








Fundamental issues in associative learning


















Near-optimal reinforcement learning in polynomial time




M
Kearns






S
Singh




10.1023/A:1017984413808








Machine Learning






49














Varieties of confirmation bias




J
Klayman








Psychology of learning and motivation




Elsevier




32














The nature of belief-directed exploratory choice in human decision-making




W
B
Knox






A
R
Otto






P
Stone






B
C
Love








Frontiers in Psychology




2


398














ALCOVE: An exemplar-based connectionist model of category learning




J
K
Kruschke








Psychological Review




99


1
















Blocking and backward blocking involve learned inattention




J
K
Kruschke






N
J
Blair








Psychonomic Bulletin & Review




7


4


















10.3758/BF03213001














Information-accumulation theory of speeded categorization




K
Lamberts








Psychological Review


















Resource-allocation behavior in complex but commonplace tasks




H
J
Langholtz






C
Ball






B
Sopchak






J
Auble




10.1006/obhd.1997.2709








Organizational Behavior and Human Decision Processes




70


3
















Knowledge partitioning in categorization: Boundary conditions




S
Lewandowsky






L
Roberts






L.-X
Yang








Memory & Cognition




34


8
















Feature selection: A data perspective




J
Li






K
Cheng






S
Wang






F
Morstatter






R
P
Trevino






J
Tang






H
Liu








ACM Computing Surveys (CSUR)




50


6


94














Beyond nonutilization: irrelevant cues can gate learning in probabilistic categorization




D
R
Little






S
Lewandowsky








Journal of Experimental Psychology. Human Perception and Performance




2


















10.1037/0096-1523.35.2.530














Toward an instance theory of automatization




G
D
Logan








Psychological Review




95


4
















Comparing supervised and unsupervised category learning




B
C
Love








Psychonomic Bulletin & Review




9


4


















10.3758/BF03196342














Environment and goals jointly direct category acquisition




B
C
Love








Current Directions in Psychological Science




14


4
















Models in search of a brain




B
C
Love






T
M
Gureckis




10.3758/CABN.7.2.90








Cognitive, Affective & Behavioral Neuroscience




7


2
















SUSTAIN: A network model of category learning




B
C
Love






D
L
Medin






T
M
Gureckis








Psychological Review




111


2


















10.1037/0033-295X.111.2.309














Decoding the brain's algorithm for categorization from its neural implementation




M
L
Mack






A
R
Preston






B
C
Love








Current Biology




23


20


















10.1016/j.cub.2013.08.035














Information-based objective functions for active data selection




D
J
Mackay








Neural Computation




4


4
















Category learning through active sampling




D
B
Markant






T
M
Gureckis








Proceedings of the Annual Meeting of the Cognitive Science Society, 32. BIDIRECTIONAL INFLUENCES


the Annual Meeting of the Cognitive Science Society, 32. BIDIRECTIONAL INFLUENCES
















Is it better to select or to receive? Learning via active and passive hypothesis testing




D
B
Markant






T
M
Gureckis








Journal of Experimental Psychology: General




143


1


94














Self-directed learning favors local, rather than global, uncertainty




D
B
Markant






B
Settles






T
M
Gureckis








Cognitive Science




40


1


















10.1111/cogs.12220














Category use and category learning




A
B
Markman






B
H
Ross








Psychological Bulletin




129


4


592














Vision




D
Marr








W. H. Freeman and Co


San Francisco












Information search with situation-specific reward functions




B
Meder






J
D
Nelson








Judgment and Decision Making




7


2


119








Tallahassee








Context theory of classification learning




D
L
Medin






M
M
Schaffer








Psychological Review




85


3


207














The influence of stimulus properties on category construction




F
Milton






A
J
Wills








Journal of Experimental Psychology: Learning, Memory, and Cognition




30


2


407














Comparing prototype-based and exemplar-based accounts of category learning and attentional allocation




J
P
Minda






J
D
Smith








Journal of Experimental Psychology: Learning, Memory, and Cognition




28


2


















10.1037//0278-7393.28.2.275














Prioritized sweeping: Reinforcement learning with less data and less time




A
W
Moore






C
G
Atkeson








Machine Learning






13
















10.1007/BF00993104














Optimal eye movement strategies in visual search




J
Najemnik






W
S
Geisler








Nature




434
















Markov chain sampling methods for dirichlet process mixture models




R
M
Neal








Journal of Computational and Graphical Statistics




9


2


















10.2307/1390653














Finding useful questions: On bayesian diagnosticity, probability, impact, and information gain




J
D
Nelson








Psychological Review




112


4


















10.1037/0033-295X.112.4.979














A probabilistic model of eye movements in concept formation




J
D
Nelson






G
W
Cottrell








Neurocomputing




70


















10.1016/j.neucom.2006.02.026














Experience matters: Information acquisition optimizes probability gain




J
D
Nelson






C
R M
Mckenzie






G
W
Cottrell






T
J
Sejnowski




10.1177/0956797610372637








Psychological Science




21


7
















On discriminative vs. Generative classifiers: A comparison of logistic regression and naive bayes




A
Y
Ng






M
I
Jordan








Advances in neural information processing systems


















Dynamic excitatory and inhibitory gain modulation can produce flexible, robust and optimal decision-making




R
K
Niyogi






K
Wong-Lin




10.1371/journal.pcbi.1003099








PLoS Computational Biology




9


6














Choice, similarity and the context theory of classification




R
M
Nosofsky








Journal of Experimental Psychology. Learning, Memory, and Cognition




10


1


















10.1037/0278-7393.10.1.104














Attention, similarity, and the identification-categorization relationship




R
M
Nosofsky








Journal of Experimental Psychology: General




115


1
















Attention and learning processes in the identification and categorization of integral stimuli




R
M
Nosofsky




10.1037/0278-7393.13.1.87








Journal of Experimental Psychology: Learning, Memory, and Cognition




13


1
















BIDIRECTIONAL INFLUENCES
















R
M
Nosofsky






M
A
Gluck






T
J
Palmeri






S
C
Mckinley






P
Glauthier


















Comparing modes of rule-based classification learning: A replication and extension




Hovland
Shepard






Jenkins








Memory & Cognition




22


3
















Learning to classify integral-dimension stimuli




R
M
Nosofsky






T
J
Palmeri








Psychonomic Bulletin & Review




3


2


















10.3758/BF03212422














An exemplar-based random walk model of speeded classification




R
M
Nosofsky






T
J
Palmeri








Psychological Review


















Recognition memory for exceptions to the category rule




T
J
Palmeri






R
M
Nosofsky








Journal of Experimental Psychology: Learning, Memory, and Cognition




21


3


548
















E
Pariser




The filter bubble: What the internet is hiding from you


London




Viking/Penguin Press














Task structure variables affecting concept identification




V
Pishkin






L
E
Bourne






S
M
Fishkin




10.3758/BF03334267








Bulletin of the Psychonomic Society




4


5
















Applied statistical decision theory. Div. of Research, Graduate School of Business Administration




H
Raiffa












Harvard Univ












The effects of feature-label-order and their implications for symbolic learning




M
Ramscar






D
Yarlett






M
Dye






K
Denny






K
Thorpe








Cognitive Science




34


6
















Models for deferred decision making




A
Rapoport






G
J
Burkheimer








Journal of Mathematical Psychology




8


4


















10.1016/0022-2496(71)90005-8


















The infinite gaussian mixture model




C
E
Rasmussen








Advances in Neural Information Processing Systems


















A theory of memory retrieval




R
Ratcliff








Psychological Review




85


2
















Feature inference learning and eyetracking




B
Rehder






R
M
Colner






A
B
Hoffman








Journal of Memory and Language




60


3
















Eyetracking and selective attention in category learning




B
Rehder






A
B
Hoffman








Cognitive Psychology




51


1


















10.1016/j.cogpsych.2004.11.001














Thirty-something categorization results explained: Selective attention, eyetracking, and models of category learning




B
Rehder






A
B
Hoffman








Journal of Experimental Psychology: Learning, Memory, and Cognition




31


5


















10.1037/0278-7393.31.5.811














The limits of learning: Exploration, generalization, and the development of learning traps




A
Rich






T
Gureckis








PsyArXiv












Schematic influences on category learning and recognition memory




Y
Sakamoto






B
C
Love








Journal of Experimental Psychology: General




133


4
















Learning and retention through predictive inference and classification




Y
Sakamoto






B
C
Love








Journal of Experimental Psychology: Applied




16


4


361














A more rational model of categorization




A
N
Sanborn






T
L
Griffiths






D
J
Navarro








Proceedings of the Cognitive Science Society


the Cognitive Science Society






28












Curious model-building control systems




J
Schmidhuber








IEEE International Joint Conference on




IEEE
















Learning and memorization of classifications




R
N
Shepard






C
I
Hovland






H
M
Jenkins








Psychological Monographs: General and Applied




75


13


1


















D
Silver






A
Huang






C
J
Maddison






A
Guez






L
Sifre






G
Van Den Driessche














Mastering the game of go with deep neural networks and tree search






Nature




529


7587


484














An intrinsic reward mechanism for efficient exploration




O
Simsek






A
G
Barto








Proceedings of the 23rd international conference on Machine learning


the 23rd international conference on Machine learning




ACM
















Prototypes in the mist: The early epochs of category learning




J
D
Smith






J
P
Minda








Journal of Experimental Psychology: Learning, Memory, and Cognition




24


6


1411














Prospective optimization with limited resources




J
Snider






D
Lee






H
Poizner






S
Gepshtein




10.1371/journal.pcbi.1004501








PLOS Computational Biology




11


9














Trading speed and accuracy by coding time: A coupled-circuit cortical model




D
Standage






H
You






D.-H
Wang






M
C
Dorris




10.1371/journal.pcbi.1003021








PLoS Computational Biology




9


4
















Lost in virtual space: Studies in human and ideal spatial navigation




B
J
Stankiewicz






G
E
Legge






J
S
Mansfield






E
J
Schlicht








Journal of Experimental Psychology: Human Perception and Performance




32


3


688














A bayesian analysis of human decision-making on bandit problems




M
Steyvers






M
D
Lee






E.-J
Wagenmakers








Journal of Mathematical Psychology




53


3
















Integrated architectures for learning, planning, and reacting Based on approximating dynamic programming




R
S
Sutton








Machine Learning Proceedings


San Francisco (CA




Morgan Kaufmann


















10.1016/B978-1-55860-141-3.50030-4














Planning by incremental dynamic programming. Machine learning proceedings




R
S
Sutton








Elsevier














Reinforcement learning: An introduction




R
S
Sutton






A
G
Barto








MIT Press


Cambridge, Mass






1st ed.








Decision making by urgency gating: Theory and experimental support




D
Thura






J
Beauregard-Racine






C.-W
Fradet






P
Cisek




10.1152/jn.01071.2011








Journal of Neurophysiology




108


11
















Humans rapidly estimate expected gain in movement planning




J
TrommershÃ¤user






M
S
Landy






L
T
Maloney








Psychological Science




17


11
















Do additional features help or hurt category learning? The curse of dimensionality in human learners




W
K
Vong






A
Hendrickson






D
Navarro






A
Perfors








PsyArXiv
















Optimum character of the sequential probability ratio test




A
Wald






J
Wolfowitz










The Annals of Mathematical Statistics




19


3
















Combination or differentiation? Two theories of processing order in classification




A
J
Wills






A
B
Inkster






F
Milton








Cognitive Psychology




80
















A model of scan paths applied to face recognition




K
Yamada






G
W
Cottrell








Proceedings of the 17th Annual Conference of the Cognitive Science Society


the 17th Annual Conference of the Cognitive Science Society


















Learning nonlinearly separable categories by inference and classification




T
Yamauchi






B
C
Love






A
B
Markman








Journal of Experimental Psychology: Learning, Memory, and Cognition




28


3


585














Category learning by inference and classification




T
Yamauchi






A
B
Markman








Journal of Memory and Language




39


1
















Context-gated knowledge partitioning in categorization




L.-X
Yang






S
Lewandowsky








Journal of Experimental Psychology: Learning, Memory, and Cognition




29


4


663














Active sensing in the categorization of visual patterns




S
C
Yang






.-H
Lengyel






M
Wolpert






D
M




10.7554/eLife.12215


















SUN: A bayesian framework for saliency using natural statistics




L
Zhang






M
H
Tong






T
K
Marks






H
Shan






G
W
Cottrell




10.1167/8.7.32








Journal of Vision




8


7

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]