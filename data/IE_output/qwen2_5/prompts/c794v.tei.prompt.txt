You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Anti-social behaviour is a persistent aspect of SNS. The ubiquity of social media in daily life has seen issues such as trolling 
(Hannan, 2018)
, cyberbullying 
(Whittaker & Kowalski, 2015)
, and hate speech 
(Matamoros-Fernández & Farkas, 2021)
 become regular features of SNS use. In light of this, regulation of anti-social online behaviour at the state 
(Harmful Digital Communications Act, 2015;
Napoli, 2019)
 and global level 
(Saurwein & Spencer-Smith, 2020;
Thompson & Daubs, 2022)
 has quickly become a practical necessity.
As pressure on institutions to respond to online anti-sociality mounts, there is an ever-greater need to understand what drives this behaviour 
(Carmi, 2022;
Mondal et al., 2017
). Central to this area of work is understanding what differentiates how individuals receive and respond to social information in online versus offline contexts 
(Ploug, 2009)
. The interdisciplinary nature of this topic has resulted in a variety of theoretical, and methodological attempts to explain online anti-sociality. One explanation which has received intermittent attention within the literature is the assertion that there is a fundamental discrepancy between online and offline moral perception 
(Miller, 2016)
.
Although a range of theoretical arguments in support of this conjecture have been presented 
(Miller, 2016;
Ploug, 2009;
Silverstone, 2007)
, comparatively few studies have actually sought to quantify the extent of this supposed mismatch in online/offline moral perception. The present study sought to advance work in this space through the development and validation of a vignette-based approach to measuring online/offline discrepancies in moral judgement.


Literature review


Theoretical and indirect empirical support
Theoretical arguments in favour of an online/offline discrepancy in moral judgement are based around the idea that online environments tend to obstruct users' ability to accurately perceive, and relate to, one another 
(Miller, 2016)
. When this social perception is diminished, our ability to make moral judgements is affected 
(Ploug, 2009;
Silverstone, 2007)
. Underlying this line of reasoning is Levinas' phenomenological account of morality, wherein an individual's capacity for moral judgement is taken as proportionate to their capacity to perceive what Levinas referred to as 'the face of the Other' (R. 
Cohen, 2013;
Levinas, 1985)
. This theoretical assertion has direct implications for global social media platforms which disproportionately enable both communication with -and perception of -distant others. Arguably, an online user is more abstracted from the social 
(reputational, emotional, physical, societal)
 consequences of (their own/others') anti-social behaviour, and therefore their moral judgement of this behaviour is diminished.
Support for this claim is not limited to the theoretical, and the idea of an online/offline discrepancy in moral judgement is consistent with a number of empirically informed perspectives across social and moral psychology. Perhaps most notable among these is the social intuitionist model of moral cognition, in which moral decision-making is primarily driven by intuitive, affective, and automatic cognitive processes 
(Haidt, 2001)
. Importantly in the context of the present project, Haidt's social intuitionist model of morality highlights the importance of studying moral judgements as socially intuitive, interpersonal processes:
The social intuitionist model avoids the traditional focus on conscious private reasoning and draws attention to the role of moral intuitions, and of other people, in shaping moral judgements. 
(Haidt, 2001, p.820 [emphasis added])
 This conceptual centring of the interpersonal, socially intuitive nature of moral judgement is broadly consistent with Lévinas' construction of social perception as the foundation of all moral concern. Indeed, recent trends in moral psychology might be seen as the work of moral theorists like Lévinas coming full circle. Just as Lévinas argued for the central role of social intuition (i.e., perception of the Other) in his phenomenological account of morality (R. 
Cohen, 2013)
, the extent to which individuals are capable of perceiving one another has become a central concern across a range of moral psychological research which builds upon the social intuitionist perspective 
A. Young & Monroe, 2019)
.
Within the social intuitionist tradition, the Theory of Dyadic Morality 
(TDM)
 provides additional support to the idea of online platforms inhibiting moral judgement.
First theorised by 
Gray and Wegner (2012)
, TDM argues that all judgements of moral wrongness are proportional to an individual's capacity to perceive harm being done to an Other 
(Schein & Gray, 2018)
. In the context of TDM, harm is defined as "an intentional agent causing damage to a vulnerable patient" 
(Schein & Gray, 2018, pp. 32-33)
. TDM argues that all judgements of moral wrongness involve a moral observer making some reference to a cognitive template of prototypical harm. This cognitive template is dyadic in that it involves a dyad of two parties, an intentional agent (A) acting upon a moral patient (P). TDM proposes that the cognitive process behind making a wrongness judgement involves comparing a given action to this template of prototypical moral wrongness (A -> P). The more readily an observer perceives an intentional actor causing harm to a vulnerable patient, the more 'dyadic' the situation is deemed to be, and the more morally wrong they evaluate the action 
(Annus, 2021;
Schein & Gray, 2015;
Ze & Baopei, 2019)
. This is particularly relevant to understanding moral judgement in online environments in which the harm caused by anti-social behaviour is so often rendered abstract and diffuse by the medium 
(Pew Research Centre, 2021;
Saurwein & Spencer-Smith, 2020;
Ullmann & Tomalin, 2020;
R. Young et al., 2023)
.
Recent evidence on the effects of mediation on mind perception (the extent to which a moral observer is ale to perceive the minds of an intentional actor and a vulnerable moral patient 
(Gray & Wegner, 2012)
) adds additional weight to the idea that online environments inhibit moral judgement. In a series of five experiments, 
Will et al. (2021)
 demonstrated the extent to which increasingly abstracted images of real people diminished participants' mind perception. Across these studies, participants were asked to rate the realness, agency (ability to act), and experience (ability to feel), of portrait images of people's faces which were mediated to varying degrees (e.g., an unmediated, live person; a picture of a person; and a picture of a picture of a person).
Across all studies, the extent to which a person's image was mediated was negatively correlated with participant ratings of realness, agency, and experience. Taken alongside the link between social perception and moral judgement, this 'Medusa Effect' 1 , wherein mind perception is inhibited by pictorial abstraction, has direct implications for considering online/offline discrepancies in moral judgement. These findings suggest that even in non-anonymous SNS contexts, where offline identities are mediated through personal images 
(Liu et al., 2016;
Zheng et al., 2016)
, our ability to perceive the realness, and lived experiences of Other users is fundamentally inhibited.


Direct empirical evidence
As seen in the preceding section, a range of evidence provides indirect support for the existence of online/offline discrepancies in moral judgement. However, empirical work which has explicitly sought to quantify these discrepancies is less abundant. One of the earliest studies to make direct, empirical comparisons between online/offline moral judgement was undertaken by 
Poole (2007)
. In a quantitative study of 453 students, Poole had participants respond to 11 pairs of short vignettes involving an ostensibly morally objectionable online and offline behaviour (e.g., online -'You go to a website and find an essay about a topic you are assigned. You print the essay, write your name on it, and submit it for grading.'; offline -'In a box of your older brother's things, you find a paper that he wrote in school. You recopy it, add your name to the top, and submit it for grading.'). Participants were asked to report their propensity to carry out the behaviour and rate the perceived acceptability of the behaviour. Analysis revealed that participants consistently found the online behaviours more morally acceptable and were on average more likely to engage in the online, rather than the offline behaviours.
Poole's (2007) study represents early evidence of some discrepancies in moral judgement (in the form of moral acceptability) across digital and offline contexts, at least among student populations. However, not all vignettes developed by Poole involved moral scenarios taking place in entirely online social environments. Instead, many of the vignettes involved behaviours which were merely enabled by digital technology (e.g., 'You copy a paragraph from each of four different Internet sources into an essay that you write for class'; 'You make a copy of a friend's audio CD for your own use'). Whilst these scenarios do still entail digital technology creating a degree of moral distance between a user and the consequences of their actions, given the contemporary ubiquity of SNS, the present project looks to extend the general insight provided by 
Poole (2007)
 by considering moral judgement in the context of social media use.
A more nuanced exploration of online moral judgement amongst young people can be found in the work of 
Flores and James (2013)
. Informed by a developmental approach to moral psychology 
(Kohlberg, 1994;
Kohlberg & Hersh, 1977)
, the authors highlight the importance of young people observing and understanding the moral consequences of their actions as they grow into adults 
(Flores & James, 2013)
. Building on the work of media theorists such as 
Silverstone (2007)
, Flores and James argue that online spaces represent new social contexts in which this process of moral learning may be impeded. To explore this issue, the authors conducted qualitative interviews with 61 teens and young adults who frequently engaged in a range of online activities (e.g., SNS use, gaming, blogging). Interviews were primarily based around participants' general experiences of online life, and also explored perceptions of appropriate and inappropriate behaviour in various online contexts. From this qualitative data, the researchers identified three distinct 'ways of thinking' about morality/ethics in online contexts, each of which appeared to greater or lesser extents in participants responses.
In order of most prevalent to least prevalent, these ways of thinking were individualistic thinking (focusing on consequences for oneself), moral thinking (considering known others), and ethical thinking (considering unknown others).
The fact that concern for unknown others was the least prevalent 'way of thinking' about online moral consequences is particularly significant in the context of large, socially noisy, SNS use, and speaks to the mismatch between a user's communicative capacity and ethical concern for the distant Other in online environments. These findings are however limited in that the qualitative data were not solely focused on social media use. Although SNS use was the most reported online behaviour amongst participants, the significance and prevalence of Flores and James (2013) 'ways of thinking' are somewhat muddied by the inclusion of non-SNS contexts in the study (e.g., participants interviewed about gaming or blogging).
Furthermore, 
Flores and James's (2013)
 work was limited by a lack of explicit comparison between online and offline moral perception. Without any comparison between online and offline 'ways of thinking' about moral consequences, their study provides little insight into the extent to which online environments themselves contribute to these moral judgements. While concern for oneself may be more prevalent than concern for others within online environments, without any direct comparison between online/offline contexts there is no reason to believe this finding is any different from participant's 'ways of thinking' about moral consequences in equivalent offline scenarios. Building upon the likes of 
Flores and James' (2013)
 work, future work in this space could benefit by narrowing its focus to moral perception in the context of social media use, and seeking to quantify and compare moral judgement across both online and offline contexts.
An example of more recent work which did make direct comparisons between online and offline moral perception is Crockett's (2017) paper on moral outrage in the digital age. Here, Crockett reanalysed data collected in a prior study by 
Hofmann et al. (2014)
. In the original study, 1,252 volunteers received periodic smartphone prompts over a three-day period asking them to complete short surveys regarding their moral experiences and observations. From this data, 
Crockett (2017)
 found that participants were more likely to learn about immoral acts from online, rather than offline sources.
Furthermore, participants experienced more moral outrage in response to learning about immoral acts online, compared to learning about immoral acts offline. Based on these findings, Crockett proposed a number of compelling hypotheses regarding the nature of morally provocative stimuli online, the extent to which social media platforms contribute to the prevalence of moral outrage, and whether the frequency and severity of online moral outrage exacerbates moral outrage expression (e.g., propensity to gossip, shame, or punish an immoral actor).
At first glance, Crockett's findings that people tend to be more morally outraged online may appear to stand at odds with the hypothesis that moral judgement is inhibited in online contexts. However, a few important differences between Crockett's work and research into online/offline moral judgement framework are worth considering. The first is the distinction between the moral evaluation of a (potentially offline) immoral action via an online platform (e.g., seeing a news headline whilst browsing social media about a politician being verbally assaulted), and the moral evaluation of an immoral action which itself takes place in an online context (e.g., a politician being verbally assaulted in a social media post). Without distinguishing between these two moral stimuli, 
Crockett's (2017)
 findings that moral outrage is more prevalent and severe online provide limited insight into the different types of moral stimuli which may be encountered online, and the extent to which online platforms contribute to discrepancies in online/offline moral outrage. By focusing on potential discrepancies in the moral judgement of online versus offline actions, rather than offline actions which are subsequently shared in online environment, the present project looks to extend upon current knowledge in this space.
Arguably the most significant empirical insight to date into online/offline discrepancies in moral judgement comes from 
Puryear and Vandello (2019)
. The authors sought to compare moral judgement and outrage in response to inflammatory comments made in online and offline contexts. 
Puryear and Vandello's (2019)
 work built on the hypothesis that online contexts often inhibit a user's social perception.
Drawing on the Theory of Dyadic Morality 
(Schein & Gray, 2018)
, the authors also theorised that this diminished social perception ultimately impedes perceptions of harm and moral judgement. Across four separate studies, the authors tested this hypothesis by having participants respond to pairs of vignettes involving a hypothetical actor making an offensive/inappropriate comment in an online/offline social setting.
Participants responded to vignettes using a range of self-report measures including moral outrage, moral wrongness, and perceived harm. Across the four studies, participants were less outraged, perceived less harm, and had a lower propensity to punish the immoral actor in online contexts. Although significant online/offline discrepancies were not found across all variables, overall results generally supported the hypothesised online/offline discrepancy in responses to morally objectionable behaviour, with the authors attributing these findings to the reduced salience of victims in online contexts, and online cultural norms.
In contrast to Crockett (2017), the vignette-based approaches used by 
Poole (2007)
 and 
Puryear and Vandello (2019)
 are notable in their ability to more closely control the stimuli which give rise to moral judgements of online behaviour. However, in the case of both 
Poole (2007)
 and 
Puryear and Vandello (2017)
, relatively little transparency is offered into the development and validation of these pairs of online/offline vignettes. This is a potentially significant shortcoming of studies whose empirical findings are so reliant on the extent to which details of the online/offline vignettes are comparable in the minds of participants. The present study therefore sought to build on the work of 
Poole (2007)
 and 
Puryear and Vandello (2017)
 through the transparent development and validation of a range of online/offline vignettes for use in future studies. The idea behind this transparent vignette development process is to improve the validity of future insight into online/offline discrepancies in moral judgement. The vignettes developed in this process are intended to serve as a baseline for future work in this area, and ideally will be equally useful for both quantitative and qualitative approaches to the topic.


Methodology


The need for online/offline equivalence
Designing hypothetical scenarios containing clear, realistic, and ecologicallyvalid moral behaviours is an important aspect of all vignette-based approaches to moral cognition research 
(Kahane, 2015;
Knutson et al., 2010;
Kruepke et al., 2018)
. Given this project's focus on comparing moral judgement across two different social contexts (online vs offline), a primary concern was also developing online/offline variants of a given scenario which would be as closely equivalent as possible in the minds of participants. By making this equivalence within pairs of on/offline vignettes a priority, this study sought to reduce the likelihood that any discrepancies identified between on/offline variants in subsequent studies would be the result of confounding factors (i.e., without first establishing vignette equivalence, observed differences in moral wrongness may be due to the on/offline scenarios not being comparable in the minds of participants). Because of this, the primary focus of this study was on comparing online/offline variants of a relatively large pool of potential vignettes, from which a smaller selection of vignette pairs could be selected for use in subsequent studies.
Through a review of prior vignette-based studies of moral judgement, a range of socio-contextual variables were identified as salient considerations in vignette design.
Testing how well pairs of online/offline vignettes compared to each other on each of these indicator variables was therefore deemed an appropriate benchmark for checking the equivalence of vignette pairs. These variables included: imageability -the extent to which participants were able to understand the behaviour described in the vignette 
(Clifford et al., 2015)
, emotional response -the strength of participants emotional response to the vignettes 
(Clifford et al., 2015)
, number of people affectedthe perceived social significance of the behaviour in the vignette 
(Scheall & Crutchfield, 2021)
, social harm -the perceived extent of social consequences of the vignette 
(Sabo & Giner-Sorolla, 2017)
, and moral wrongness -the extent to which participants felt an action was right or wrong 
(Laham et al., 2009)
. The goal of the pilot study was therefore to find a selection of on/offline vignette pairs which participants identified as closely equivalent on these variables.
Given the focus on establishing equivalence between online and offline variants of each scenario, a within-participants approach was chosen for the pilot study (i.e., each participant would respond to both online and offline versions of a given scenario).
Structuring the pilot in this way meant that the pilot results created a baseline of how individual participants compared on/offline vignettes. This set up an opportunity for subsequent studies using a between-participants approach (i.e., each participant responding to either the online or offline version of a vignette, but not both) could be contrasted with the present project's within-participant results.


Designing vignettes
Developing a battery of original vignettes involved considering a wide range of everyday scenarios in which a regular user might observe morally objectionable or harmful behaviour taking place on SNS. Inspiration for these scenarios was drawn from current affairs stories surrounding social media use 
(Ewe, 2023;
Lorenz, 2018;
K. Phillips, 2021
) along with informal conversations with colleagues and regular social media users. The ubiquitous nature of social media meant there was an ample amount of potentially useful scenarios. However, selection of online social scenarios/behaviours was ultimately limited to those which had clear offline parallels. A total of 24 unique vignettes (12 on/offline pairs) were designed for the pilot study, and a compendium of all pilot vignettes can be found in Appendix A.
Each individual vignette was comprised of a hypothetical scenario in which a moral actor is confronted with a moral decision 2 . In all pilot scenarios, the moral actor chooses an ostensibly immoral course of action. Care was taken to make sure online/offline vignette pairs remained consistent in terms of internal structure, length, and use of keywords, all of which have been previously identified as important aspects of effective vignette design 
(Bradbury-Jones et al., 2014;
Clifford et al., 2015)
. As is considered best practice in contemporary studies of computer-mediated communication 
(Carr, 2020)
, the online vignettes sought to keep their focus on the SNS enabled mediation of a morally objectionable behaviour, rather than the type of technology/device being used by the hypothetical actor.


Accounting for latent socio-contextual variables in vignette design
Despite being often overlooked in classical vignette-based studies of morality 
(Schein, 2020)
, social context is a crucial aspect of moral cognition. When designing the vignettes, a number of latent socio-contextual factors (beyond the aforementioned imageability, emotional response, number of people affected, social harm, and moral wrongness variables) were identified as important aspects of establishing on/offline equivalence. Vignette pairs were therefore designed to keep key features of the hypothetical social contexts as closely comparable as possible (e.g., social and reputational consequences of the immoral action, volition of the moral actor, ambient social noise, etc.). In most cases, the abstract, subjective nature of these additional factors made them difficult to directly observe (e.g., there is no easy way of having participants report on the perceived degree of social noise in a hypothetical scenario).
These additional socio-contextual factors were therefore treated as latent variables within the pilot study and keeping these latent variables as equivalent as possible across on/offline pairs required a good deal of care.
It is important to note here that the aim of this project was not to demonstrate that some online/offline social contexts and behaviours are exactly comparable. On the contrary, the hypothesis guiding this research is that online/offline contexts are fundamentally distinct social arenas, and that this distinction gives rise to discrepancies in moral perception. However, in order to use a vignette-based approach to test this hypothesis it was crucial to control for as many potentially confounding variables as possible when designing the vignette pairs. The validity of any vignettebased approach to exploring discrepancies in moral judgement is predicated on a rigorous attempt to establish equivalence between online and offline vignettes. This section provides an overview of some of the more salient latent socio-contextual factors identified, and how they were taken into account through vignette development.
The perceived social consequences of an action are a key determinant in discerning moral wrongness 
(Malle, 2021)
, and are closely related to (but not always as easy to measure as) perceived social harm 
(Dungan et al., 2017;
Sabo & Giner-Sorolla, 2017
). Because of this, vignette design played an important role in keeping a number of indeterminate social consequences of actions as closely comparable as possible across on/offline vignette pairs. One of the ways vignettes were designed to control for variability in on/offline social consequences was by keeping details on the ultimate consequences, or efficacy, of an actor's behaviour comparably ambiguous across vignette pairs. Having a degree of ambiguity in vignettes is important as it allows participants to define and respond to the scenario in their own terms 
(Barter & Renold, 1999;
Wilks, 2004)
. However, it was important to maintain this degree of ambiguity across both online/offline variants.
An example of this design consideration can be seen in the Charity Donation The agency or volition of a moral actor is closely related to moral judgements 
(Harris et al., 2012;
Malle, 2021;
Schein & Gray, 2018)
. When designing vignettes, it was therefore important that both the autonomy and volition of moral actors in the minds of participants was controlled as much as possible across online/offline contexts. This largely involved making each actor's motivation to act -and their propensity and/or capacity to engage in the given action -comparable across online/offline contexts. One of the ways this was achieved was by keeping the hypothetical behaviours at the centre of the vignettes relatively brief and spontaneous. An example of this can be seen in the Sexist Comment vignette. In the offline version of this scenario, an actor (Taylor) yells out a brief derogatory comment ("Nice ass!") at a female acquaintance whilst drinking with his friends. In the online variant, Taylor makes the exact same brief comment for the entertainment of his friends, except this time the comment is posted under a photo of the female acquaintance online. In both instances, it can be assumed Taylor is motivated at some level by a desire to impress or entertain his male friends. While there is an obvious discrepancy in the physical action/energy required to yell out a sexist comment, and posting a sexist comment online, the brevity and spontaneity of these two actions, and by extension any resulting moral judgements, was deemed likely to be functionally comparable in the minds of participants.
vignette (Appendix A),
Much of the traditional research into moral judgement has been informed by participant responses to well-used, but ultimately unrealistic hypothetical vignettes (e.g. the trolley problem - 
Foot (1967)
; the Footbridge dilemma -Thomson (1985; Schein, 2020)). Such approaches have more recently been called into question given the often highly abstract and unrealistic nature of such vignettes, and the implications this has for the generalisability of findings 
(Gold et al., 2014;
Schein, 2020)
. Given this concern within the literature, it was important that the content of pilot study vignettes was based on realistic social situations. Although the closely related imageability variable was directly assessed in this study (i.e., the extent to which a participant is able to imagine the content of a vignette), ensuring that scenarios were not only imaginable, but realistic, was a key consideration in designing vignettes. Since the inception of the project, regular social media use was intended to be part of the screening criteria for eligible participants. This meant that designing realistic vignettes benefitted from an assumed baseline level of participant understanding surrounding day-to-day behaviour online.
As arguably the least realistic of the vignettes developed for use in the pilot study, the Bridge Jumper vignettes provide a useful example of efforts to keep perceived realism symmetrical across on/offline vignette design. In the offline variant, an actor (Kate) is walking down a busy pedestrian bridge when she comes across a man threatening to jump to his death. In the online variant of this scenario, Kate is browsing a busy social media feed when she comes across a man livestreaming himself threatening to jump from a bridge. Encountering the situation outlined in the Bridge Jumper scenario is, fortunately, not an everyday occurrence in either online or offline contexts. Neither, however, is it outside the realm of possibility. Suicide by jumping often involves large public structures such as bridges and buildings and, consequentially, usually at least one incidental witness to the act 
(O'Donnell & Farmer, 1995;
Ooi et al., 2020)
. Incidental witnesses of suicide on social media have also become increasingly common over recent years (J. 
Phillips & Mann, 2019)
. Furthermore, in both online (J. 
Phillips & Mann, 2019)
 and offline 
(Mann, 1981)
 occurrences of suicide, public jeering or encouraging of the victim to go through with the act is worryingly commonplace. For all vignettes, and particularly the Bridge Jumper vignettes, it was unlikely that respondents would be drawing on first-hand experience of the exact details described in each scenario. However, none of the scenarios outlined in the vignettes were deemed so outlandish to be beyond the realms of possibility in the minds of participants.


Methods


Participant recruitment
The demographic questions and vignettes were compiled into an online questionnaire hosted on Qualtrics. 203 Mechanical Turk (MTurk) participants were recruited using the intermediary Cloud Research platform. Using Cloud Research allowed for tighter control of the recruitment process and decreased the likelihood of recruiting low-quality participants such as bots 
(Litman, 2020
 Participants were also required to be regular social media users. As the most widely used social media platform 
(Statista, 2023)
, self-reported time spent on Facebook was used as a proxy for general familiarity with SNS features and functionality ('How much time do you feel you spend on Facebook?' Anchors: 1 -I have never used Facebook, 7 -I use Facebook every day). Participants who reported never using Facebook were automatically excluded from the study.


Materials and procedure
Twelve pairs of hypothetical online/offline vignettes were used in the pilot study.
Each unique vignette averaged 6 short sentences, which meant participants needed to read approximately 1 paragraph of text to familiarise themselves with the content of a given scenario. A small stock image was also chosen to accompany each vignette, providing a visual aid to help participants interpret each scenario. Participants were then asked to use 7point Likert-type scales to make a series of morally relevant observations regarding the hypothetical behaviour contained in each vignette.
Participants were assigned to one of three scenario groups. Participants in each scenario group responded to four of the twelve possible online/offline vignette pairs (8 unique vignettes per participant). Dividing participants into these three scenario groups helped keep time to complete, participant engagement, and funding costs at an appropriate level. A breakdown of which vignettes were included in each scenario group can be found in Appendix A. Distribution of the 203 participants was slightly uneven with 66 participants in scenario group 1, 68 participants in scenario group 2, and 69 participants in scenario group 3. Presentation of the vignettes was randomised within each of the scenario groups to limit participants being primed by the first vignette in an online/offline pair before responding to the second vignette.
After reading each vignette, participants were then asked to respond to the vignette's content using five Likert-style scales. Details and rationale behind each of these measures are provided below in the order they were presented to participants:
Imageability. Participants used a 7-point scale to report how easy it was to clearly imagine the details of each vignette (anchors; 1 -Very difficult -7 -Very easy). Vignettebased studies rely on participants evaluating fictional scenarios, and as a result must come to terms with some degree of hypotheticality. This variable was therefore included as a means of comparing the clarity and realism of the hypothetical online/offline vignettes.
Vignettes with high imageability scores suggested that any subsequent findings regarding moral judgements would be more reliable. The better a participant is able to imagine the content of a vignette, the more theoretically valid their moral judgements. A 5-point measure of imageability was used effectively in a prior study by 
Clifford et al. (2015)
 which focused on developing and validating similar moral vignettes. This was expanded to a 7point scale to improve sensitivity of the measure and keep the resulting data consistent with the other measures included in the pilot study.
Emotional response. Participants used a 7-point scale to report the strength of their emotional response to each vignette (anchors; 1 -No emotional response -7 -Very strong emotional response). Emotional response is an important factor contributing to moral judgements 
(Dorado et al., 2023)
. Emotional response was expected to correlate with moral judgements, and it was therefore important that online/offline variants provoked similar degrees of emotional response amongst participants. A 5-point measure of emotional response was used by 
Clifford et al. (2015)
 in validating a large set of moral vignettes. As with imageability, this measure was expanded to a 7-point measure in the pilot study to increase sensitivity and keep data consistent across measures.
Size of effect. Participants were asked to estimate how many people they thought were negatively affected by the moral actor's behaviour in an open-text box. Number of people affected by a behaviour is a salient consideration in moral judgement 
(Conway & Gawronski, 2013;
Foot, 1967)
. This variable was particularly important given the ambiguous, and often unknowable, social impact of immoral actions in both online and offline public contexts. No upper limit was placed on responses to this variable. This was done with the intention of remaining responsive to a broad range of perceived social impact, from interpersonal effects through to macrosocial, societal effects of the moral actor's behaviour.
Social harm. Participants used a 7-point scale to report perceived social harm of the hypothetical actor's behaviour (anchors; 1 -Not at all harmful -7 -Extremely harmful).
Perceived harm is considered a consistent (and, according to some theorists, the singular would remain largely consistent across vignettes, allowing for this variable to be reliably compared across online/offline conditions. Although single-item measures of general 'social harm' were not apparent within the literature, the wording of this item was kept consistent with prior studies of perceived harm 
(Ames & Fiske, 2013)
.
Moral wrongness. Participants used a 7-point scale to report perceived moral wrongness of the hypothetical actor's behaviour (anchors; 1 -Not at all wrong -7 -Extremely wrong). This item was adapted from other similar measures of moral wrongness 
(Schnall et al., 2008;
Wheatley & Haidt, 2005)
. Although all other variables were deemed strong indicators of moral wrongness, measuring this variable directly at an early stage helped establish a within-participant baseline against which findings from subsequent between participant results could be compared.


Results


Demographic variables
Measures of central tendency remained relatively consistent across online/offline vignette pairs, and significant (p < .05) positive on/offline correlations were identified amongst almost all dependent variables. This was an early indication that efforts to design closely comparable on/offline vignettes were largely successful.  
Figure 2 below
). Based on this, it was deemed reasonable that all participants were at least familiar enough with the Facebook platform to recognise and conceptualise the hypothetical online scenarios contained in the questionnaire.


Exploratory network modelling
Network models were estimated and analysed using the qgraph 
(Epskamp et al., 2012
) and igraph 
(Csardi & Nepusz, 2006)
  heavier edges indicating larger coefficients. Bonferroni corrections 
(Weisstein, 2004)
 were applied when estimating the models to counteract the potential for erroneous inferences when making multiple simultaneous comparisons 
(Benjamini, 2010)
. In generating the visual plots, a force-embedded algorithm 
(Fruchterman & Reingold, 1991)
, was used to better demonstrate clusters of highly interconnected variables.
Larger copies of each of the network models are available in Appendix B and an annotated copy of the R script used to estimate and analyse the network models is also available via GitHub and includes details on all relevant parameters 3 .
One of the strengths of network models is their ability to quickly communicate patterns of dependency within multivariate data 
(Borsboom et al., 2021)
. As each of the network models were relatively small, the broad properties of the models were relatively easy to discern by simply plotting the estimated models. One of the clearest and most promising visual characteristics of the models was the consistently close clustering of online/offline vignette pairs (i.e., on/offline nodes of the same colour). In most cases, significant and unmediated positive correlations were identified between on/offline vignette pairs within each of the five dependent variables. This was a good indicator that early attempts to design vignettes with high on/offline equivalence had been largely successful. In some cases, positive relationships between on/offline responses for dependent variables were not direct and appeared to be mediated by other variables (e.g., 
Figure 3
 -Drunk Ex on/offline imageability). Although a potential point of speculation in future studies of this nature, ultimately these mediating relationships between on/offline vignettes were relatively few and far between. In terms of determining which vignettes would be most useful in subsequent studies, vignettes in which on/offline nodes appeared consistently closely clustered together within each dependent variable showed early promise.


Figure 1
Correlation Network model for Scenario Group 1
Note. Coloured nodes represent participant responses to a given vignette, and green edges between nodes represent significant (p < .001) positive correlations. Node colour is used to indicate different vignettes within the Scenario Group. The length/width of green edges scales with the size of the correlation coefficient (r) between two nodes. Text inside nodes indicates the following: on/off = online/offline version of the vignette, img = imageability, er = emotional response, soe = size of effect, sh = social harm, and mw = moral wrongness. Note that the placement of nodes along the x/y-axes of this plot is arbitrary.
Along with the visual characteristics of the plotted models, centrality indices and clustering coefficients were used to investigate the statistical structure of the models. Variables (nodes) tended to be tightly clustered (clustering coefficients for SG1 = 0.63, SG2 = 0.52, SG3 = 0.57), with relatively short average path lengths between nodes (average path lengths for SG1 = 2.15, SG2 = 2.48, SG3 = 2.10). As a result, all models were found to have what 
Watts and Strogatz (1998)
 have referred to as 'small-world' properties (small world indices (S) 4 for SG1 M = 4.08, SD = 0.7; SG2 M = 3.4, SD = 0.5; SG3 M = 6.05 SD = 1.5). These 'small-world' clusters of dependent variables tended to form three distinct clusters within each model. The largest clusters across the three models were comprised of emotional response (er), social harm (sh), and moral wrongness (mw) variables. This suggested that responses to these measures were all highly correlated with one another both within and between on/offline vignette pairs (this pattern is most obvious in 
Figure 3
, where the er/sh/mw cluster is completely independent of other clusters in the model). As emotional response to vignettes increased amongst participants, so too did perceptions of social harm and moral wrongness. The interrelation of perceived social harm 
(Usoof-Thowfeek et al., 2011)
, and emotional response 
(Prinz, 2006)
, with moral wrongness is consistent with theoretical perspectives on moral judgement, and the clustering of nodes in these models provided early evidence that this relationship remained largely consistent across comparable online and offline contexts. This result re-emphasised the importance of vignettes which remained closely equivalent on these metrics across on/offline conditions.


Figure 2
Correlation network model for Scenario Group 2
Note. Coloured nodes represent participant responses to a given vignette, and green edges between nodes represent significant (p < .001) positive correlations. Node colour is used to indicate different vignettes within the Scenario Group. The length/width of green edges reflects the size of the correlation coefficient (r) between two nodes. Text inside nodes indicates the following: on/off = online/offline version of the vignette, img = imageability, er = emotional response, soe = size of effect, sh = social harm, and mw = moral wrongness. Note that the placement of nodes along the x/y-axes of the model is arbitrary.
Although the models revealed close interrelation between emotional response, social harm, and moral wrongness, across all models imageability (img) and size of effect (soe) nodes tended to form two smaller, more independent clusters. Imageability nodes, in particular, formed uniformly dense clusters and these clusters were not significantly linked with other nodes in the models (see 
Figure 4
 as an example). This suggests that the imageability of vignettes did not significantly correlate with emotional response, social harm, moral wrongness, or size of effect variables. This result was initially surprising, but did not negate the importance of testing for imageability when piloting vignettes. The value of using readily imaginable scenarios in vignette based studies of moral perception is generally regarded as self-evident 
(Clifford et al., 2015;
Kahane, 2015)
, and this assertion is not undermined by a lack of direct correlation between imageability and the other dependent variables in this study. The primary concern with regards to measuring imageability in the pilot was ensuring vignettes had a reasonably high degree of imageability to limit interference with moral judgement. The separate clustering of the imageability nodes in the network models, coupled with the significant positive skew of all imageability scores, suggested an upper ceiling of vignette imageability had been achieved (i.e., all vignettes were readily imaginable enough to not confound moral judgements).
Across each of the network models, size of effect (soe) nodes were generally isolated from both er/sh/mw and img clusters. Size of effect was included as a measure in the pilot study as it was expected to be directly correlated with variables such as perceived social harm and moral wrongness (i.e., the more people are negatively affected by a behaviour, the more likely a participant is to rate the behaviour as socially harmful and/or morally wrong). The isolation of the size of effect nodes across the network models was not consistent with this hypothesis. The most immediate explanation of this pattern was a discrepancy in how the size of effect variable was assessed compared to other dependent variables in the study. Because participants responded to size of effect questions using an open-ended text box, the range of size of effect scores varied considerably compared to other dependent variables. However, after normalising all responses in each scenario group and re-estimating the network models, no change to the isolation of size of effect clusters was identified. This indicated that the lack of significant correlation between size of effect variables could not be explained by discrepancy in range of responses.


Figure 3
Correlation network model for Scenario Group 3
Note. Coloured nodes represent participant responses to a given vignette, and green edges between nodes represent significant (p < .001) positive correlations. Node colour is used to indicate different vignettes within the Scenario Group. The length/width of green edges reflects the size of the correlation coefficient (r) between two nodes. Text inside nodes indicates the following: on/off = online/offline version of the vignette, img = imageability, er = emotional response, soe = size of effect, sh = social harm, and mw = moral wrongness. Note that the placement of nodes along the x/y-axes of the model is arbitrary.
Another potential explanation of the isolated size of effect nodes was between participant differences in interpretation of the size of effect question. Although the wording of both vignettes and size of effect questions were designed to be as deliberate as possible, ultimately discrepancies in how people construe size of negative affect may explain a lack of consistent correlation between size of effect scores and dependent variables such as social harm. Consistent with this explanation is the occurrence of a small number of completely unconnected on/offline pairs of size of effect nodes within the network models (i.e., 
Figure 4
 -Anti-Vax Offline SOE; 
Figure 5
 -Drunk Ex Offline SOE). The fact that these nodes were not significantly linked with any other nodes in their respective networks indicated a lack of consistency in how participants conceptualised the size of effect of the hypothetical behaviours in these vignettes. The existence of a completely isolated individual node was therefore an early indicator that the corresponding vignette may not be an optimal choice for use in subsequent studies.


Dependent variable analyses
While network modelling and descriptive comparisons were a good initial indicator of on/offline equivalence within vignette pairs, inferential hypothesis tests were used to verify whether any observed differences between online/offline variables could be considered statistically significant. Given the nature of the vignettes and scales used, data on dependent variables was not anticipated to be normally distributed. This expectation was verified using a combination of density plots and Shapiro-Wilk's tests 
(Shapiro & Wilk, 1965)
. The Wilcoxon signed-rank test was therefore used as a non-parametric alternative to the t-test 
(Wilcoxon, 1945)
. As this study was focused on establishing equivalence between online/offline conditions, no preliminary predictions were made about the direction of any on/offline variance, and as such, all
Wilcoxon tests used a two-tailed approach. 


Imageability
Imageability scores were significantly positively skewed across all vignettes, suggesting that all scenarios were designed well enough for participants to conceptualise/understand the content of the hypothetical scenarios, and, presumably,  
Table 2
 below.
Although individual vignettes having good imageability is important 
(Schein, 2020;
Bostyn et al., 2018)
, for the purposes of the present study it was just as -if not more -important that the online/offline variants of a scenario had comparable imageability. The utility of an online/offline vignette depended on participants being able to readily conceptualise a vignette in order to effectively appreciate it's consequences, and if one version of a vignette was more easily imaginable, this may have implications for comparing moral judgements between on/offline versions.
Fortunately, relatively low variation across imageability means suggested that this wasn't likely to be a major issue in subsequent studies. Regardless, correlation tables were created to check for significant Pearson correlations between on/offline imageability scores for each scenario group. All imageability scores were found to be significantly positively correlated with one another within each scenario group, and significant positive correlations were found between all online/offline vignette pairs.
This suggested attempts to design vignettes which were comparably imaginable in the minds of participants were successful. The most strongly correlated online/offline pair were the Charity Donation vignettes, r(64) = 0.92, p < .001. The least strongly correlated online/offline pair were the Drunk Ex vignettes, r(67) = 0.38, p = .001.
Paired difference tests were used to check for statistically significant differences between online/offline imageability scores. Vignette pairs which were found to have a statistically insignificant difference between on/offline imageability scores were identified as good potential candidates for use in subsequent phases of the project.  
-0.62, .06]
). This further indicated that where significant on/offline discrepancies in imageability were found, the actual extent of these discrepancies were small.  


Emotional response


Size of effect
Perceived size of effect of the online/offline behaviours was assessed using the following scale: How many people do you think were negatively affected by 
[Actor]
 
Table 4
 below. Given the open-ended assessment of this variable, the range of effect sizes was larger than the other dependent variables (Cohen's d mean = .29, min. = .01, max = .57). This result suggested a lack of uniformity in participant perceptions of the vignettes' publicity. One participant's idea of how many people might witness a disorderly public act is likely quite different to the next participant. The size of effect results therefore highlighted the importance of vignettes which provide clarity and detail on social context. At this point in the analysis, vignette pairs with statistically significant size of effect W values, and a Cohen's d value >.40 were deemed insufficiently equivalent to be carried through to subsequent studies (i.e., Bridge Jumper, Explicit Comment, F the Police, Anti-Vax). This tolerance threshold was based on 
Cohen's (1988)
 tentative benchmarks for gauging effect sizes, wherein d = .50 suggests a medium effect size.
On/Offline pairs which were found to have Cohen's d values between 0.20-0.40 were still deemed reasonably viable candidates for subsequent studies, provided they performed well on other on/offline equivalence metrics and could potentially be tweaked to improve clarity on how many people were affected in the on/offline conditions.


Social harm
Perceived social harm was assessed using the following scale: How socially harmful was 
[Actor]
's behaviour in this scenario? (1 -Not at all harmful -7 -Extremely harmful). Social harm scores were considerably positively skewed. This is consistent with the morally contentious, and often inherently socially harmful nature of the behaviours included in the pilot vignettes. A full range of scores was identified in response to all vignettes except for the online/offline Drunk Ex scenarios, the lowest response for both of which was 2 (i.e., no participant thought that the behaviour in these scenarios was not at all harmful). The vignettes deemed the most socially harmful were the Bridge Jumper (online M = 6.06, SD = 1.48; offline M = 6.06, SD = 1.48),
and Drug Dealer (online M = 5.31, SD = 1.71; offline M = 5.20, SD = 1.80) pairs, and these were the only vignettes with mean social harm scores > 5.0. The Charity Donation vignettes were rated as the least socially harmful scenarios (online M = 3.33, SD = 1.75, offline M = 2.97, SD = 1.58). An overview of all key social harm results for each vignette pair can be found in 
Table 5
 below.  
-0.14, 0.54]
). This indicated that where significant on/offline discrepancies in perceived social harm were found, the actual extent of these discrepancies tended to be small. 


Moral wrongness
Moral wrongness was assessed using the following scale: How morally wrong was 
[Actor]
's behaviour in this scenario? (1 Not at all wrong -7 Extremely wrong). As with social harm, significant positive skew was found across moral wrongness scores, reflecting the inherently morally objectionable nature of the hypothetical actors' behaviour. Perhaps unsurprisingly, the online (M = 6.43, SD = 1.02), and offline (M = 6.43, SD = 1.09) Bridge Jumper vignettes had the highest mean moral wrongness scores and were the only mean scores in the > 6.0 range. Most mean moral wrongness scores remained in the 4.0 range, with an average standard deviation of 1.70. The least morally wrong vignette was online Fake News (M = 4.04, SD = 1.72). An overview of all key moral wrongness results for each vignette pair can be found in 
Table 6
 below.
All online/offline variants were significantly (p < .05) positively correlated with one another, and overall moral wrongness was the most consistently highly correlated variable between vignette pairs. The most strongly correlated online/offline pair was the 'Fuck the Police' vignettes (r(68) = 0.91, p < .001). The least strongly correlated pair were the Unfounded Accusation vignettes (r(68) = 0.71, p < .001).
Significant differences in moral wrongness scores between online/offline variants were consistent with the hypothesis informing the PhD research question.
However 


Discussion


Performance of dependent variables
Despite extensive efforts to pre-emptively validate vignettes within studies of general moral psychology 
(Clifford et al., 2015)
, reporting of the vignette design and validation process in prior vignette-based studies of online/offline moral judgement has been comparatively limited 
(Poole, 2007;
Puryear & Vandello, 2019)
. While this by no means invalidates the findings of these prior studies, it does suggest that existing insight into online/offline discrepancies in moral judgement is based upon relatively opaque processes for determining on/offline vignette equivalence. This study
represented an effort to amend this. By keeping the vignette design and development process transparent, this project sought to provide a foundation for future studies to continue improving the efficacy of vignette-based approaches to this topic.
Although most on/offline vignette pairs performed strongly across most metrics (i.e., significant on/offline correlation, statistically insignificant on/offline median discrepancies, relatively small on/offline effect size), no vignette pair was found to have flawless on/offline equivalence across all dependent variables. This result speaks to the inherent socio-contextual disparities in online and offline behaviours. As discussed in the methodology section, this study did not intend to argue that online/offline contexts are morally indistinguishable from one another. Instead, the objective was to identify hypothetical scenarios which were closely equivalent enough in the minds of participants to provide a basis for examining on/offline discrepancies in moral judgement. This was achieved, and a handful of vignette pairs were deemed sufficiently equivalent to warrant being carried through into subsequent studies.
Imageability. Grounding scenarios in everyday activities was an important aspect of keeping imageability consistent across on/offline contexts. Implicit comparisons were drawn between browsing social media and overhearing a conversation in a public space, and these experiences were framed as occurring during an actor's lunchbreak (e.g., Fake News vignettes). An explicit image shared publicly online was contrasted with wearing the same image on a t-shirt in public, and both of these actions were presented in terms of the immediate reputational consequences for close family members (e.g., Explicit Content vignettes). Using these broadly relatable experiences as cognitive touchstones reflected an effort to keep the actors, actions, and consequences in vignette pairs comparably imaginable in the minds of participants, despite the inherent spatiotemporal and contextual discrepancies between the online and offline contexts.
Pilot results suggested that these efforts were successful. Across all individual vignettes mean imageability remained high, and standard deviations remained low. This indicated that not only were attempts to design readily imaginable vignettes successful, but there was also relatively little variation in vignette imageability between participants. Given the self-evident value of readily imaginable vignettes in studies of moral judgement 
(Clifford et al., 2015;
Kahane, 2015)
, results of the network analysis suggested that the imageability of individual vignettes was sufficiently high to avoid covarying with other variables.
Online and offline imageability scores were significantly (p < .001) positively correlated with one another across all but one vignette pair (Drunk Ex vignette). This result was consistent with the theory behind designing equally imaginable vignettes, as the details of the Drunk Ex vignette pair were arguably the most sparsely comparable of all scenarios used in the pilot. In the online variant, an actor [Tom] is drinking at a bar and feels jealousy/anger when he sees a picture on social media of his ex-girlfriend with another man. He responds to the post with an angry comment. In the offline variant the actor's ex-girlfriend actually arrives at the bar in person with another man and Tom makes a similar comment. Mean imageability for these vignettes was not the lowest of all the vignettes, suggesting that the scenario in each vignette taken individually was at least plausible. However, the lack of significant correlation suggested that there was no direct relationship between imageability scores across on/offline variants. Based on this, the Drunk Ex vignettes were deemed insufficiently equivalent in terms of imageability and were therefore excluded from the pool of vignettes to be used in subsequent studies.
Emotional response. The idea that emotional response is closely linked to moral judgement is consistent with theoretical perspectives across contemporary moral 
(Maibom, 2010)
 and media 
(Raney, 2011)
 psychology. Generally speaking, the greater the emotional response to a morally objectionable behaviour, the more acute an individual's moral judgement of the scenario is likely to be (L. 
Young & Koenigs, 2007)
.
This relationship between variables was borne out by the pilot data, wherein significant positive correlations were identified between emotional response and moral wrongness/social harm across all vignettes. Participants were asked to rate their own (not Chloe's) emotional response to the behaviour in the scenario. The relatively low on/offline equivalence for this variable suggested that there was a statistically significant, albeit small, discrepancy in how emotionally confronting these two vignettes were for participants. Participants tended to find the online variant of this scenario slightly less emotionally confronting. Previous studies have explored the emotional desensitisation of users to depictions of physical violence on social media platforms 
(Li et al., 2017;
Miles-Novelo & Anderson, 2020)
, and digital media's capacity to dull otherwise emotionally confronting material is widely discussed within the literature 
(Bushman & Anderson, 2009;
Smith et al., 2003)
. However, this result suggests that this desensitisation effect may in some cases extend to participants' third-person evaluation of a hypothetical actor's exposure to violent content. Although a potential point of speculation for future work, the extent of the on/offline discrepancy in emotional response to this pair of scenarios was relatively minor, and not deemed significant enough at this stage of the analysis to automatically exclude the vignettes from being carried through to subsequent studies.


Size of effect.
The size of effect variable was included as a means of quantifying participant perceptions of how many people would be negatively affected by the behaviour in each vignette. The severity of a moral judgement tends to scale with the amount of people negatively impacted by an action 
(Jaffe & Pasternak, 2006)
, and it was therefore important that online/offline vignette pairs were at least reasonably equivalent on this metric. This was made difficult by the inherent variability and ambiguity surrounding how many people might ultimately witness an online behaviour such as posting a comment or sharing an image 
(Anandhan et al., 2018;
Bessi, 2017)
.
Another methodological challenge was the potential for within-participant differences in how a behaviour's 'negative affect' was construed in online/offline contexts. For example, a given participant may have interpreted online negative affect in terms of how often a behaviour was shared or recommended to other users, while interpreting offline negative affect in terms of how many people were actually present as the scenario unfolded. Given this, and with the benefit of hindsight, the open-ended nature of the size of effect question was perhaps too crude a way of having participants quantify the amount of people affected in each vignette.
Although this did not invalidate the data collected in response to this question, it did mean that the threshold for excluding vignettes which performed poorly on the size of effect variable was less strict than for other variables. Vignettes which did not have a significant on/offline size of effect correlation were excluded at this stage, as were vignettes with Cohen's d values approaching the .50/medium effect benchmark (e.g., estimates for the online variants were between 3-4 times higher than their offline counterparts, suggesting that participants perceived these online behaviours as being visible to a far larger audience. Furthermore, standard deviations >200 for each of these online vignettes indicated that these estimates of online visibility varied considerably between participants.
There was one vignette pair which performed particularly poorly on the size of effect measure despite the behaviour in the offline variant not taking place in a highly visible or exceptionally socially noisy public context. The Anti-Vax vignettes involved an actor (Casey) in a group of young mums harshly dismissing another mother's concerns about whether to vaccinate their child. In the online variant this interaction takes place in the comments section of a social media support group, while the offline variant played out in a face-to-face support group. Results found considerable, statistically significant variation in on/offline size of effect scores, with the estimated amount of people negatively affected by Casey's online behaviour typically being far larger than in the online condition. Although the size of the support group/incidental witnesses in the online/offline versions of these vignettes were intended to be roughly the same, responses to the online variant suggested that participants conceptualised an 'active social media support group' as being a far more publicly visible social setting, leading to more people being negatively affected by Casey's online behaviour. This disparity highlights the between-user variability in the perceived publicity of online contexts and emphasises the value of specificity in developing comparable online/offline vignettes.
Social harm. Given the close relationship between perceived harm and moral judgement 
(Gray & Wegner, 2012;
Ze & Baopei, 2019)
, this variable was assessed in the pilot study to check that online/offline scenarios were reasonably equivalent in terms of the perceived societal harm caused. The actual definition of 'social harm' in this
question was left open to participants' interpretation, and it was assumed that different participants would interpret and quantify social harm differently. However, the withinparticipants design of the pilot study (where each participant responded to both online and offline variants of a given vignette) meant that the focus of analysis was not on between-participant disparities in how social harm was construed, but rather on whether individual participants' personal conception of social harm differed across on/offline vignette variants. This decision was based on the expectation that how an individual participant defined social harm would remain stable regardless of on/offline context (i.e., while participant #1 and participant #2 might differ in how much social harm was caused in the Drug Dealer scenario, it was assumed that how each participant defined social harm would not differ significantly between on/offline variants).
Despite the on/offline disparities identified in response to the size of effect variable, most vignette pairs performed well on the social harm equivalence checks.
Where on/offline social harm discrepancies were significant, the actual extent of this discrepancy was found to be small (e.g., F the Police d = 0.20, Mean Joke = 0.20). This result suggested that while participants may perceive a greater number of people being negatively affected by an online behaviour, the actual extent or severity of the societal harm caused tended to be closely comparable in on/offline contexts for the majority of on/offline vignette pairs. Surprisingly, some vignettes which were excluded based on their performance on the aforementioned size of effect variable performed exceptionally well in terms of on/offline social harm equivalence. Relatively large, statistically significant on/offline differences were found in size of effect 5 responses to the Bridge Jumper 
(
 Bridge Jumper, the 'Anti-Vax' vignettes were not regarded by participants as exceptionally socially harmful 7 . Despite this, participants generally reported far more people being negatively affected by Chloe's behaviour in the online condition, but also felt there was essentially no difference in the degree of social harm caused by Chloe's behaviour in the on/offline conditions. One partial explanation of this result is the potentially confounding effect of the politically sensitive nature of the Anti-Vax vignette.
The pilot study was run in July 2021, when much of the world (including the USA, where pilot participants were located) was in the midst of responding to the COVID-19 pandemic. During this time, vaccine misinformation in online environments was a particularly salient political issue. Although the design of the Anti-Vax vignettes kept the actor's (Casey's) stance on whether children should be vaccinated ambiguous, a 
5
 Participant estimates of number of people negatively affected in each scenario. 
6
 Outside of the aforementioned retrospective scepticism of the size of effect measure's efficacy.
7 On Anti-Vax social harm M(SD) = 4.51(1.69). Off Anti-Vax social harm M(SD) = 4.51(1.40). Average M(SD) for all On vignettes = 4.53(1.68), and all offline vignettes 4.48(1.65).
heightened sensitivity to pro-/anti-vaccine discourse among participants may have acted as a confounding factor.
The nature of designing vignettes containing morally objectionable actions requires anticipating participants' moral sensibilities to a certain extent. The actors in the vignettes need to be seen to be breaking some moral norms, and there will always be some variation in participant sensitivity to these norms. However, these results highlight the importance of designing hypothetical scenarios which are neither too severe in their affect, nor too closely centred on hot button socio-political issues. Partly based on the incongruence between size of effect and social harm results, the Bridge Jumper and 'Anti-Vax' vignettes were deemed unsuitable in their current form for use in subsequent studies.
Moral wrongness. As one of the most commonly assessed classes of moral judgement 
(Malle, 2021)
, discrepancies in on/offline moral wrongness were selected early on as a focus of the thesis as a whole. Moral wrongness was therefore included in the pilot study for two reasons. The first, was to get an initial general idea of how vignettes might perform on this measure in subsequent studies. Pilot vignette pairs which had significant on/offline discrepancies in moral wrongness, but which performed well on other equivalence metrics would have been particularly apt for inclusion in subsequent studies. However, the consistent significant correlations between moral wrongness, social harm and emotional response scores, and the fact that only minor on/offline discrepancies were found across social harm and emotional response variables, meant that on/offline discrepancies in moral wrongness scores were similarly low. Significant on/offline moral wrongness discrepancies were found for only two vignette pairs, both of which had already been flagged for exclusion based on prior results (Explicit Content and Unfounded Accusation).
The second reason for the inclusion of this variable in the pilot was to establish a within-participant baseline of moral wrongness for the vignettes. Although vignettes were presented to pilot participants in a random order to reduce the likelihood of priming effects, all pilot participants did ultimately read and respond to both the online and offline version of each vignette. In Study 2, however, the intention was to have participants respond to either the online or offline variant of each vignette, but not both.
By establishing that individual participants perceptions of moral wrongness did not differ widely between on/offline contexts, the pilot allowed for subsequent studies to check whether a shift to a between-participants approach had any effect on this result.
The fact that mostly insignificant differences were found in on/offline responses to this variable was an early indicator that moral judgement might not differ as much in online contexts as initially theorised. The project's theoretical framework was informed by the likes of 
Miller (2016)
, and 
Silverstone (2007)
 who have suggested that online environments may fundamentally alter users ability to relate to others, and, in turn, their moral judgement. While these arguments are well-established within the theoretical literature, insight into the actual extent or consistency of on/offline disparities in moral judgement is relatively limited. Across most of the pilot vignettes, disparities in on/offline moral wrongness scores tended to be both small and insignificant. This result affirmed the within-participant moral equivalence of the vignette pairs, however highlighted the value of exploring a broader range of betweenparticipant moral judgements in subsequent studies including the perceived moral character of on/offline actors, participant's propensity to punish an actors' behaviour, and whether there was any correlation between participant's own experiences of online disinhibition.
By establishing a baseline of small and/or insignificant on/offline discrepancies in moral wrongness, these results also allowed for subsequent studies to experiment with varying key features of the vignettes. One idea was to introduce variants of the pilot vignettes which involved the same actor presented with the same moral decision but choosing to behave in a morally admirable way. Doing this would allow subsequent studies to expand upon the pilot findings by exploring whether the moral valence of on/offline behaviours had any effect on perceived moral wrongness. The few preexisting vignette-based studies of on/offline moral judgement have been primarily built around vignettes involving ostensibly bad actors 
(Poole, 2007;
Puryear & Vandello, 2019)
, and varying the moral valence in this way offered the potential to further explore the antecedents of online/offline moral perception.


Selection of vignettes for use in subsequent studies
Based on the results discussed above, selecting which vignette pairs to use in the rest of the project involved excluding vignettes which performed poorly across numerous dependent variables. This included the Bridge 
Jumper, Public Fight, Explicit
 Content, Fuck the Police, Anti-Vax, and Drunk Ex vignettes. One of the clearest trends amongst these exclusions was the removal of vignettes which took place in socially noisy settings with high public visibility. Poor on/offline equivalence in size of effect responses was the main driver of exclusions, pointing to the efficacy of vignettes which included some specificity in the number of incidental witnesses to a behaviour.
In some cases, excluded vignettes still had potential to provide useful insight given a little more tweaking and subsequent validation of the scenarios. For example,
the Anti-Vax vignettes performed well on all but the size of effect equivalence check, suggesting that adding more specific details on exactly how many people saw or were affected by Chloe's behaviour may have made this vignette pair a good fit.
Charity Donation, Fake News, Mean Joke, Drug Dealer, and Sexist Comment vignettes were ultimately decided on as the best options for use in subsequent studies.
In addition to performing well in quantitative analyses, the moral valence of the actor/outcomes in these scenarios had clear potential to be tweaked in subsequent studies whilst still keeping the on/offline variants closely comparable. By slightly changing the moral valence of the vignettes (e.g., having Alex choose to behave more morally by making a small donation in the Charity Donation vignette), future studies provide the opportunity to test the limits of the equivalence in moral wrongness established in the present project. Furthermore, all five vignettes were expected to prove useful in qualitatively exploring the nature of on/offline discrepancies. The selected vignettes represented a diverse and reasonably realistic/relatable range of scenarios for the average social media user, allowing for any qualitative studies to explore the nuances and differences in on/offline moral perceptions across a diverse range of social situations.
wherein a hypothetical actor (Alex) is presented with the opportunity to donate to a local charity. In both the online and offline variants of this scenario, the purpose of the donation request remains the same (families struggling due to the COVID-19 pandemic). However, no details are provided to the participant regarding what the actual social impact or efficacy of Alex's decision would have been had he decided to donate. Although the physical nature of Alex's action differs across online/offline contexts, the nature and extent of any social consequences arising from Alex's decision remain ambiguous in the online/offline variants and are left for the participant to discern. Designing the pilot study vignettes in this way helped ensure that any moral judgements arising from the social consequences of on/offline vignettes would be theoretically equivalent.The reputation of a moral actor provides a more specific example of a social consequence which was accounted for in the vignette design stage. Reputational consequences play an important role in moral judgement and behaviour
(Ellemers et al., 2019;
Haviv & Leman, 2002)
. Although perceptions of social reputation may differ depending on social context (i.e., online and/or offline contexts), impact of a given action on the actor's social reputation was alluded to in the vignettes by highlighting specific social relationships where appropriate, but leaving the actual extent of damage to the actor's social reputation equally ambiguous across online/offline variants. For example, in the Explicit Content vignette, an actor (Jackson) publicly associates himself with an explicit pornographic image. In the online variant, Jackson posts the image as his display picture on social media, while in the offline variant Jackson wears a t-shirt depicting the same image. Any action which involves a public, morally controversial, behaviour has very broad and potentially indiscernible implications for the actor's social reputation. However, in both variants details were also included regarding how Jackson's mother and sister responded to the publicly displayed explicit image. By including details regarding the behaviour's impact on readily identifiable social relationships, the ambiguous nature of perceived reputational consequences is grounded in broadly relatable social relationships. In both online and offline variants, participants are able to conceptualise Jackson's social reputation amongst his family being damaged. Although the ultimate extent of this reputational damage is left for the participant to decide, the ambiguity in the extent of this damage was kept consistent across online/offline contexts.


(
Gray et al., 2022;
Schein & Gray, 2018)
) predictor of moral judgement
(Trémolière & De Neys, 2013)
. Rather than having participants focus on any specific type of harm, the use of the broad term 'social harm' left the actual nature of the harm caused open to participant interpretation. Although this somewhat limited the between participant interpretation of this variable (e.g., participant A might conceptualise social harm differently to participant B), it was assumed that an individual participant's interpretation of the term 'social harm'


packages in R. Three network models were estimated, one for each of the three scenario groups. Visual plots of the three network models are provided in Figures 1-3. Within each plot, nodes represent dependent variables in either the online (on) or offline (off) condition. The colour of nodes reflect which type of vignette the variable belonged to (e.g., in Figure 3, red nodes represent responses to the Bridge Jumper vignettes, while green nodes represent responses to the Charity Donation vignettes). Edges (lines between nodes) reflect significant (p < .001) Pearson correlations between two variables. Green edges were used to indicate positive correlations, while red edges would have indicated negative correlations (however no significant negative correlations were identified in any of the models). The weight (thickness) of edges reflects the magnitude of the correlation coefficient, with


Cohen's d was used as a measure of the size of effect on/offline variants had on participant responses to each variable. Notably, while Wilcoxon tests revealed whether on/offline responses to a given variable were significantly different, Cohen's d gave an indication of the actual magnitude of this effect. This meant that if on/offline responses to a vignette pair were found significantly different, but the actual magnitude of this difference was relatively low, the vignette pair may still be a viable candidate for inclusion in subsequent studies.


the social/moral consequences of the behaviour in each scenario. Mean imageability for most scenarios was between 6.0-6.5, with the most 'easily imaginable' scenario being the online version of the 'Fuck the Police' vignette (M = 6.60, SD = 0.70). Althoughmean imageability remained relatively high across the board, mean scores of four vignettes (online/offline Drug Dealer, offline Bridge Jumper, & offline Unfounded Accusation) dipped below the 6.0 mark, with the lowest of these being the offline variant of the Unfounded Accusation vignette (M = 5.93, SD = 1.37). Imageability scores remained largely consistent across online/offline contexts, with the largest discrepancy in means between online/offline variants of the Drug Dealer vignette (online M = 5.60, offline M = 5.98; discrepancy of 0.38). An overview of all key imageability results for each vignette pair can be found in


Insignificant
Wilcoxon results in this case suggested that any differences in participant's ability to visualise the details of online/offline scenarios were not significant. Across Wilcoxon tests for imageability, only Unfounded Accusation (W = 67, p = .01, N = 68), Mean Joke (W = 228, p = .02, N = 69), and Drug Dealer (W = 457, p = .01, N = 69) vignettes were found to be significantly different from one another. In the case of Unfounded Accusation and Mean Joke scenarios, number of ties (i.e., participants who scored exactly the same on both online and offline variants) were relatively high (Unfounded Accusation = 44, Mean Joke = 45), suggesting that although a significant difference was identified by the Wilcoxon tests, this result was based on only a small portion of the actual sample. The size of the effect of on/offline variants on imageability scores remained relatively low across the board (Cohen's d mean = 0.13, min. <.001, max = 0.28). This suggested that the actual effect of online/offline variations on vignette imageability ranged from low to negligible. Notably, Cohen's d values remained low even for those vignettes which the Wilcoxon tests identified as having a significant on/offline difference (Unfounded Accusation d = 0.26, 95% CI [-.08, .60]; Mean Joke d = 0.26, 95% CI [-.60, .08]; and Drug Dealer d = 0.28, 95% CI [


Although all scenarios depicted varying degrees of ostensibly immoral behaviour, ultimately participants were simply reading text-based vignettes, accompanied by a general stock image as a reference. Because of this, emotional response scores were not expected to be significantly skewed towards the 'Very strong emotional response' end of this scale. In line with this expectation, emotional response scores were found to be the most normally distributed scores overall. The online and offline variants of the Bridge Jumper scenarios were the most emotionally responsive vignettes by a relatively large margin, and were the only vignettes with mean emotional response scores greater than 5 (offline Bridge Jumper (M = 5.54, SD = 1.70); onlineBridge Jumper (M = 5.42, SD = 1.59)). This spoke to the veracity of the emotional response measure, as the disparity in emotional response to the Bridge Jumper vignettes reflects the confronting, immediately life-threatening nature of these scenarios. The next highest mean scores after the Bridge Jumper vignettes were online (M = 4.40, SD = 1.76) and offline (M = 4.36, SD = 1.80) variants of the Drug Dealer vignettes, and most mean emotional response scores remained in the 4.00 range. The least emotionally responsive vignettes proved to be the online (M = 3.07, SD = 1.59) and offline (M = 3.19, SD = 1.53) variants of the Fake News vignettes, likely reflecting the arguably mundane nature of sharing Fake News stories or gossip with friends. An overview of all key emotional response results for each vignette pair can be found in Table 3 below. Significant (p < .05) positive correlations were found between emotional response scores across all online/offline pairs. The most strongly correlated emotional response scores were the on/offline Bridge Jumper vignettes, r(64) = 0.83, p < .001. The least strongly correlated vignette pair were the on/offline Drunk Ex vignettes, r(67) = 0.63, p < .001. Wilcoxon tests determined whether differences in emotional response scores across online/offline variants were statistically significant. Vignette pairs with insignificant differences in on/offline emotional response were good potential candidates for use in studies 2 and 3. The Public Fight vignettes were the only on/offline pair for which a significant difference was found (W = 640, p = .001, N = 66). The size of effect of on/offline variants on emotional response scores was small to negligible for most vignette pairs (Cohen's d mean = .08, min. <.001, max = 0.29). The only on/offline pair with a d value greater than 0.20 were the Public Fight vignettes (Public Fight d = 0.29, 95% CI [-.64, .05]), however this result indicated the effect size was still relatively low.


Significant positive correlations(p < .05)  were identified between all but one of the online/offline vignette pairs. The most strongly correlated online/offline pairs were the Fake News (r(64) = 0.88, p < .001) and Sexist Comment (r(67) = 0.88, p < .001) vignettes. The Explicit Content vignettes were the only pair which were not significantly correlated at the level of p < .05.As with imageability and emotional response, Wilcoxon test results which were above the p < .05 threshold indicated insignificant differences between online/offline size of effect, suggesting good equivalence within vignettes pairs. Significant on/offline differences were found across five vignette pairs; Bridge Jumper (W = 179.5, p = .009, N = 66), Charity Donation (W = 138.5, p = .03, N = 66), Fake News (W = 172.5, p = .001, N = 66), Explicit Content (W = 369.5, p = .005, N = 68), and 'Anti-Vax' (W = 163.5, p < .001, N = 68).


Significant (p < .05) positive correlations between social harm scores were identified within each online/offline vignette pair. The most strongly correlated online/offline variants was the 'Fuck the Police' vignette (r(68) = 0.84, p < .001). Wilcoxon tests revealed significant differences in social harm for four of the twelve vignette pairs (Charity Donation, 'Fuck the Police', Unfounded Accusation, and Mean Joke). Of these, the most significant difference was found in the Mean Joke vignette pair (W = 270, p = .01). Despite this, Cohen's d values remained relatively low across the board (Cohen's d mean = 0.09, min. <.001, max = 0.22), suggesting that the actual effect of on/offline conditions on perceived social harm ranged from low to negligible. Cohen's d values also remained suitably low across vignettes identified as having statistically significant differences in on/offline responses (Charity Donation d = 0.22, 95% CI [-0.13, 0.56]; F the Police d = 0.2, 95% CI [-0.54, 0.14]; Unfounded Accusation d = 0.21, 95% CI [-0.13,0.55]; Mean Joke d = 0.2, 95% CI [


, insignificant moral wrongness Wilcoxon results in the pilot should not automatically discount a vignette pair from providing valuable insight in future between-participants approaches (assuming it met other equivalence checks). Statistically significant difference was identified in two of the 12 vignette pairs; Explicit Content (W = 154.5, p = .004, N = 68), and Unfounded Accusation (W = 227, p = .01, N = 68). The size of effect of on/offline conditions on moral wrongness scores were relatively low across the board (Cohen's d mean = .09, min <.001, max = 0.27). This indicated that the actual effect of online/offline vignette conditions on moral wrongness ranged from low to negligible. Cohen's d values remained low for the vignettes which had significant Wilcoxon test values (Explicit Content d = 0.27, 95% CI [-.07, 0.61], Unfounded Accusation d = 0.22, 95% CI [-0.12, 0.56]) suggesting that even in cases where a within participant on/offline discrepancy was significant, the actual extent of this discrepancy was relatively small.


The
Public Fight vignettes were the only pair with a significant on/offline discrepancy in emotional response scores and an effect size (Cohen's d) greater than 0.20. The offline version of the Public Fight vignette involved an actor (Chloe) witnessing and laughing at a fight in the street between two drunk people, while the online version involved Chloe witnessing and laughing at the incident in real-time via live stream.


Bridge
Jumper d = 0.43, F the Police d = 0.47). However, vignette pairs with a Cohen's d value <.40 were deemed reasonable (e.g., Charity Donation d = 0.36), as long as they also performed well across other variables. Despite the less stringent application of exclusion criteria on this variable, analysis of size of effect scores saw the largest amount of vignettes being deemed unsuitable for use in subsequent studies, with Bridge Jumper, Public Fight, Explicit Content, F the Police, Anti-Vax, and Drunk Ex vignettes all meeting exclusion criteria. The vignettes which performed best on this variable (e.g., Unfounded Accusation, Mean Joke, and Drug Dealer) tended to involve an actor behaving inappropriately in the context of a small group of peers. Meanwhile, many of the vignettes which involved an actor behaving badly in a more publicly visible setting (e.g., Public Fight, Explicit Content, F the Police) performed poorly in terms of online/offline size of effect equivalence. This result highlighted the difficulty in designing vignettes which control for the socially noisy nature of offline scenarios with high public visibility, and participant estimates of incidental observers of online behaviours. In the case of the Bridge Jumper, Explicit Content, and F the Police vignettes, mean size of effect


). Recruitment was limited to participants aged 18 years or older, who were based in the United States and for whom English was a first language. Preliminary informal testing amongst colleagues and peers provided a rough estimate of ~15-minute completion time for each participant. This information was then used to adjust compensation for participants to slightly over the U.S.A. federal minimum wage (2.30USD per participant for approximately 15 minutes work). The ip address of potential participants was cross-checked to verify their geographic location, and further screen out any suspicious respondents (e.g., participants using a VPN to mask their location).


Table 1 -
1
Overview of imageability results
Vignette
On M (SD)
Off M (SD)
On/offline Pearson's r
On/offline Wilcoxon W
Cohen's d (effect size)
Cohen's d 95% CI Lower Upper
Bridge Jumper
6.04 (1.51)
5.98 (1.56)
0.83**
131.50
0.04
-0.31
0.38
Charity Donation
6.29 (1.26)
6.29 (1.24)
0.92**
45.50
<.001
-0.34
0.34
Fake News
6.52 (0.93)
6.54 (0.9)
0.67**
42.00
0.03
-0.38
0.31
Public Fight
6.29 (1.17)
6.2 (1.28)
0.81**
76.00
0.07
-0.27
0.42
Explicit Content
6.18 (1.11)
6.12 (1.09)
0.59**
206.00
0.05
-0.29
0.39
F the Police
6.6 (0.69)
6.41 (0.97)
0.58**
114.00
0.23
-0.11
0.57
Anti-Vax
6.37 (0.94)
6.26 (0.92)
0.64**
137.50
0.11
-0.23
0.45
Unfounded Accus.
6.25 (1.07)
5.93 (1.37)
0.66**
233.00*
0.26
-0.08
0.6
Mean Joke
6.17 (1.01)
6.42 (0.86)
0.59**
72.00*
0.26
-0.6
0.08
Drug Dealer
5.61 (1.34)
5.98 (1.36)
0.60**
173.00*
0.28
-0.62
0.06
Sexist Comment
6.2 (1.09)
6.4 (0.94)
0.66**
70.00
0.2
-0.54
0.14
Drunk Ex
6.32 (1.01)
6.23 (1.03)
0.38
276.50
0.09
-0.25
0.42
Note -* p<.05, **p<.001


Table 2 -
2
Overview of emotional response results
Scenario
On M (SD)
Off M (SD)
On/offline Pearson's r
On/offline Wilcoxon W
Cohen's d (effect size)
Cohen's d 95% CI Lower Upper
Bridge Jumper
5.42 (1.57)
5.54 (1.7)
0.83**
228.50
0.07
-0.42
0.27
Charity Donation
3.56 (1.76)
3.88 (1.73)
0.80**
225.00
<.001
-0.34
0.34
Fake News
3.08 (1.59)
3.2 (1.53)
0.78**
270.00
0.08
-0.42
0.27
Public Fight
3.35 (1.73)
3.86 (1.76)
0.79**
180.00*
0.29
-0.64
0.05
Explicit Content
4.07 (1.78)
4.09 (1.88)
0.79**
270.50
0.01
-0.35
0.33
F the Police
3.9 (1.92)
4.19 (1.95)
0.76**
316.50
0.15
-0.49
0.19
Anti-Vax
4.07 (1.86)
4.2 (1.64)
0.82**
244.00
0.08
-0.42
0.26
Unfounded Accus.
3.87 (1.88)
4.03 (1.85)
0.72**
337.50
0.09
-0.43
0.25
Mean Joke
3.74 (1.62)
3.91 (2.59)
0.65**
355.50
0.08
-0.42
0.26
Drug Dealer
4.4 (1.77)
4.36 (1.81)
0.77**
290.00
0.02
-0.31
0.36
Sexist Comment
4.06 (1.75)
4.26 (1.75)
0.76**
286.00
0.12
-0.45
0.22
Drunk Ex
4.01 (1.56)
4.12 (1.35)
0.63**
374.00
0.07
-0.41
0.27
Note -* p<.05, **p<.001


's behaviour in this scenario?[Enter number]. The open-ended nature of this question allowed for greater between participant variation than the other variables reported here. Furthermore, because the relative publicity of hypothetical behaviours varied widely across different vignettes pairs, descriptive comparisons between vignette pairs were less meaningful for the size of effect variable. For example, a mean size of effect score of 84.56 for the online Bridge Jumper vignette reflected the fundamentally public nature of a livestream being broadcast from a busy bridge. In addition, a high standard deviation of 217.8 suggested that there was considerable variation amongst participants regarding the extent of this publicity (i.e., how many bystanders might have witnessed the situation). In contrast, the much lower mean size of effect and standard deviation for the online Mean Joke vignette (M = 1.53, SD = 1.36) reflected the inherently private nature of a group chat amongst a small group of friends. An overview of all key size of effect results for each vignette pair can be found in


Table 3 -
3
Overview of size of effect results
Scenario
On M (SD)
Off M (SD)
On/offline Pearson's r
On/offline Wilcoxon W
Cohen's d
Cohen's d 95% CI Lower Upper
Bridge Jumper
84.56 (217.84)
18.17 (29.78)
0.61**
523.50*
0.43
0.08
0.78
Charity Donation
8.86 (21.49)
3.18 (5.41)
0.67**
357.50*
0.36
0.02
0.71
Fake News
34.86 (65.65)
23.27 (53.42)
0.88**
647.50*
0.19
-0.15
0.54
Public Fight
5.7 (11.02)
3.35 (3.65)
0.43
530.00
0.29
-0.06
0.63
Explicit Content
110.51 (263.65)
29.68 (55.96)
0.19
956.50*
0.42
0.08
0.77
F the Police
114.93 (268.87)
24.48 (32.12)
0.54*
904.00
0.47
0.13
0.82
Anti-Vax
62.47 (131.04)
9.78 (11.76)
0.29
1162.50*
0.57
0.22
0.91
Unfounded Accus. 35.35 (109.07) 22.48 (116.46)
0.71**
477.50
0.11
-0.23
0.45
Mean Joke
1.54 (1.37)
1.55 (1.39)
0.69**
187.00
0.01
-0.35
0.33
Drug Dealer
4.65 (14.09)
2.68 (5.47)
0.48*
149.50
0.18
-0.15
0.52
Sexist Comment
6.4 (14.17)
2.83 (3.91)
0.88**
398.50
0.34
0.01
0.68
Drunk Ex
5.07 (6.49)
4.2 (3.74)
0.41
456.50
0.16
-0.17
0.5
Note -* p<.05, **p<.001


Table 4 -
4
Overview of social harm results
Scenario
On M(SD)
Off M (SD)
On/offline Pearson's r
On/offline Wilcoxon W
Cohen's d (effect size)
Cohen's d 95% CI Lower Upper
Bridge Jumper
6.06 (1.49) 6.06 (1.49)
0.62**
175.50
<.001
-0.34
0.34
Charity Donation
3.33 (1.76) 2.97 (1.59)
0.69**
448.00*
0.22
-0.13
0.56
Fake News
4.09 (1.62) 4.04 (1.69)
0.72**
372.50
0.03
-0.32
0.37
Public Fight
3.94 (1.99) 4.17 (1.79)
0.73**
360.50
0.12
-0.46
0.22
Explicit Content
4.72 (1.62) 4.66 (1.67)
0.72**
620.50
0.04
-0.3
0.37
F the Police
4.22 (1.97) 4.62 (1.93)
0.84**
178.50*
0.2
-0.54
0.14
Anti-Vax
4.51 (1.69)
4.51 (1.4)
0.77**
284.00
<.001
-0.34
0.34
Unfounded Accus.
4.81 (1.67) 4.46 (1.77)
0.70**
585.00*
0.21
-0.13
0.55
Mean Joke
3.93 (1.56) 3.61 (1.64)
0.70**
633.00*
0.2
-0.14
0.54
Drug Dealer
5.32 (1.71)
5.2 (1.8)
0.67**
245.00
0.07
-0.27
0.4
Sexist Comment
4.67 (1.65) 4.74 (1.67)
0.75**
288.00
0.04
-0.38
0.29
Drunk Ex
4.81 (1.5)
4.83 (1.43)
0.43
401.50
0.01
-0.35
0.33
Note -* p<.05, **p<.001


Table 5 -
5
Overview of moral wrongness results
Scenario
On M(SD)
Off M (SD)
On/offline Pearson's r
On/offline Wilcoxon W
Cohen's d (effect size)
Cohen's d 95% CI Lower Upper
Bridge Jumper
6.44 (1.02)
6.44 (1.1)
0.77**
39.00
<.001
-0.34
0.34
Charity Donation
4.82 (1.7)
4.68 (1.7)
0.74**
254.00
0.08
-0.26
0.42
Fake News
4.04 (1.72)
4.14 (1.8)
0.83**
244.00
0.05
-0.4
0.29
Public Fight
4.44 (2.08)
4.68 (1.91)
0.78**
254.50
0.12
-0.47
0.22
Explicit Content
5.09 (1.61)
4.65 (1.69)
0.75**
511.50*
0.27
-0.07
0.61
F the Police
4.18 (2.04)
4.4 (2.03)
0.91**
111.50
0.11
-0.45
0.23
Anti-Vax
4.41 (1.67)
4.35 (1.68)
0.81**
285.50
0.04
-0.3
0.37
Unfounded Accus.
5.13 (1.78)
4.74 (1.76)
0.71**
553.00*
0.22
-0.12
0.56
Mean Joke
4.36 (1.49)
4.19 (1.66)
0.84**
385.50
0.11
-0.23
0.45
Drug Dealer
5.46 (1.74)
5.55 (1.71)
0.85**
139.00
0.05
-0.39
0.29
Sexist Comment
4.8 (1.85)
4.86 (1.83)
0.81**
262.00
0.03
-0.37
0.31
Drunk Ex
4.81 (1.59)
4.74 (1.76)
0.81**
292.00
0.04
-0.29
0.38
Note -* p<.05, **p<.001


Wilcoxon p <   .05, d = 0.43)  and Anti-Vax(Wilcoxon p < .05, d = 0.57)  vignettes. However, on/offline discrepancies in the perceived social harm of these vignettes were not only not significant, but practically non-existent (Bridge Jumper on/offline social harm Wilcoxonp > .05, d < .001, Anti-Vax on/offline social harm Wilcoxon p > .05, d < .001).Explaining this perplexing result 6 may have something to do with the perceived severity of social harm. The on/offline Bridge Jumper vignettes involved an actor (Kate) encouraging a stranger to jump off a bridge and were notable as the vignettes which contained the most extreme example of a morally objectionable behaviour. This was reflected in the fact that average Bridge Jumper social harm scores were considerably higher than in other vignettes. It's possible that these vignettes achieved a ceiling effect, wherein participants considered Kate's behaviour severe enough to be regarded as excessively and unequivocally socially harmful regardless of whether it took place in an online or offline context. This explanation however does not account so well for the Anti-Vax vignette's inconsistency between size of effect and social harm on/offline equivalence. Unlike


A term coined by
Will et al. (2021)
 in reference to Medusa, a mythical creature whose potency is diluted by viewing her image in a reflection.


Note that although the terms are occasionally conflated within the literature, a vignette involving a 'moral decision' (e.g., Alex decides not to donate to a charity) is distinct from a vignette involving a 'moral dilemma' (e.g., the trolley problem).


github.com/BenClassen/PhD---Pilot


Small world indices are reported as means and standard deviations as estimating these involved comparing models to randomly generated models with the same number of nodes and edges. M & SD's are the result of 10,000 iterations of this process.














Intentional Harms Are Worse, Even When They're Not




D
L
Ames






S
T
Fiske








Psychological Science




24


9


















10.1177/0956797613480507














Social Media Recommender Systems: Review and Open Research Issues




A
Anandhan






L
Shuib






M
A
Ismail






G
Mujtaba




10.1109/ACCESS.2018.2810062








IEEE Access




6
















The notion of dyadic morality explains the logic of Zande witchcraft. Religion




A
Annus








Brain & Behavior




11


2


















10.1080/2153599X.2020.1805796














The Use of Vignettes in Qualitative Research




C
Barter






E
Renold










Social Research Update
















Simultaneous and selective inference: Current successes and future challenges




Y
Benjamini








Biometrical Journal




52


6


















10.1002/bimj.200900299














On the statistical properties of viral misinformation in online social media




A
Bessi








Physica A: Statistical Mechanics and Its Applications




469


















10.1016/j.physa.2016.11.012














Network analysis of multivariate data in psychological science




D
Borsboom






M
K
Deserno






M
Rhemtulla






S
Epskamp






E
I
Fried






R
J
Mcnally






D
J
Robinaugh






M
Perugini






J
Dalege






G
Costantini






A.-M
Isvoranu






A
C
Wysocki






C
D
Van Borkulo






R
Van Bork






L
J
Waldorp




10.1038/s43586-021-00055-w








Nature Reviews Methods Primers




1


1














Vignette development and administration: A framework for protecting research participants




C
Bradbury-Jones






J
Taylor






O
R
Herber








International Journal of Social Research Methodology




17


4


















10.1080/13645579.2012.750833














Comfortably numb: Desensitizing effects of violent media on helping others




B
J
Bushman






C
A
Anderson








Psychological Science




20


3
















Don't Be Antisocial: The Politics of the "Anti-Social" in "Social" Media




E
Carmi








The Social Media Debate










Routledge








CMC Is Dead, Long Live CMC!: Situating Computer-Mediated Communication Scholarship Beyond the Digital Age




C
T
Carr




10.1093/jcmc/zmz018








Journal of Computer-Mediated Communication




25


1
















Moral foundations vignettes: A standardized stimulus database of scenarios based on moral foundations theory




S
Clifford






V
Iyengar






R
Cabeza






W
Sinnott-Armstrong








Behavior Research Methods




47


4


















10.3758/s13428-014-0551-2














Statistical Power Analysis for the Behavioral Sciences




J
Cohen




10.4324/9780203771587








Taylor & Francis Group












The Routledge Companion to Phenomenology




R
Cohen




S. Luft & S. Overgaard










Chapter 6-Emmanuel Levinas. Routledge








Deontological and utilitarian inclinations in moral decision making: A process dissociation approach




P
Conway






B
Gawronski




10.1037/a0031021








Journal of Personality and Social Psychology




104


2
















Moral outrage in the digital age




M
J
Crockett




10.1038/s41562-017-0213-3








Nature Human Behaviour




1


11
















The igraph software package for complex network research




G
Csardi






T
Nepusz








InterJournal




5
















Defensive emotions and evaluative judgements: Sensitivity to anger and fear predicts moral judgements, whereas sensitivity to disgust predicts aesthetic judgements




A
Dorado






M
Skov






J
Rosselló






M
Nadal




10.1111/bjop.12590








British Journal of Psychology




114


1
















The relevance of moral norms in distinct relational contexts: Purity versus harm norms regulate self-directed actions




J
A
Dungan






A
Chakroff






L
Young




10.1371/journal.pone.0173405








PLOS ONE




3


12














The Psychology of Morality: A Review and Analysis of Empirical Studies Published From




N
Ellemers






J
Van Der Toorn






Y
Paunov






T
Van Leeuwen








Personality and Social Psychology Review




23


4


















10.1177/1088868318811759














qgraph: Network visualizations of relationships in psychometric data




S
Epskamp






A
O
Cramer






L
J
Waldorp






V
D
Schmittmann






D
Borsboom








Journal of Statistical Software




48
















South Korean YouTuber Dies After Livestreamed Suicide Attempt




K
Ewe




















The network architecture of individual differences: Personality, reward-sensitivity, and values




R
Fischer






J
A
Karl




10.1016/j.paid.2020.109922








Personality and Individual Differences




160


109922














Morality and ethics behind the screen: Young people's perspectives on digital life




A
Flores






C
James








New Media & Society




15


6


















10.1177/1461444812462842














The Problem of Abortion and the Doctrine of the Double Effect




P
Foot








Oxford Review




5
















The outlandish, the realistic, and the real: Contextual manipulation and agent role effects in trolley problems




N
Gold






B
D
Pulford






A
M
Colman








Frontiers in Psychology




5


35














The affective harm account (AHA) of moral judgment: Reconciling cognition and affect, dyadic morality and disgust, harm and purity




K
Gray






J
K
Maccormack






T
Henry






E
Banks






C
Schein






E
Armstrong-Carter






S
Abrams






K
A
Muscatell








Journal of Personality and Social Psychology




123


















10.1037/pspa0000310














The social psychology of morality: Exploring the causes of good and evil




K
Gray






D
M
Wegner




10.1037/13091-006








440 Pages)


M. Mikulincer


Washington, DC, US




American Psychological Association










Morality takes two: Dyadic morality and mind perception








Mind Perception Is the Essence of Morality




K
Gray






L
Young






A
Waytz








Psychological Inquiry




23


2


















10.1080/1047840X.2012.651387














The emotional dog and its rational tail: A social intuitionist approach to moral judgment




J
Haidt








Psychological Review




108


4


814














Trolling ourselves to death? Social media and post-truth politics




J
Hannan








European Journal of Communication




33


2


















10.1177/0267323118760323




















Harmful Digital Communications Act




63














Categorising Person-Based Ethical Constructs using a Framework of Cognitive Skills, Moral Volition, and Personal Values




H
Harris






E
C
Fein






A
Kim






L
Hobson




10.1108/S1529-2096(2012)0000008012








Applied Ethics: Remembering Patrick Primeaux


M. Schwartz & H. Harris




Emerald Group Publishing Limited




8














Moral Decision-making in Real Life: Factors affecting moral orientation and behaviour justification




S
Haviv






P
J
Leman




10.1080/03057240220143241








Journal of Moral Education




31


2
















Morality in everyday life




W
Hofmann






D
C
Wisneski






M
J
Brandt






L
J
Skitka




10.1126/science.1251560








Science




345


6202
















Moral intensity as a predictor of social responsibility




E
D
Jaffe






H
Pasternak








Business Ethics: A European Review




15


1
















The Trolley Problem




J
T
Judith








Yale Law Journal




94


6
















Sidetracked by trolleys: Why sacrificial moral dilemmas tell us little (or nothing) about utilitarian judgment




G
Kahane








Social Neuroscience




10


5


















10.1080/17470919.2015.1023400














How to Compare Psychometric Factor and Network Models




K.-J
Kan






H
De Jonge






H
L J
Van Der Maas






S
Z
Levine






S
Epskamp




10.3390/jintelligence8040035








Journal of Intelligence




8


4














Behavioral norms for condensed moral vignettes




K
M
Knutson






F
Krueger






M
Koenigs






A
Hawley






J
R
Escobedo






V
Vasudeva






R
Adolphs






J
Grafman








Social Cognitive and Affective Neuroscience




5


4


















10.1093/scan/nsq005














Moral Development: Kohlberg's original study of moral development




L
Kohlberg








Taylor & Francis












Moral development: A review of the theory. Theory Into Practice




L
Kohlberg






R
H
Hersh




10.1080/00405847709542675








16














A brief assessment tool for investigating facets of moral judgment from realistic vignettes




M
Kruepke






E
K
Molloy






K
Bresin






A
K
Barbey






E
Verona








Behavior Research Methods




50


3


















10.3758/s13428-017-0917-3














Easy on the mind, easy on the wrongdoer: Discrepantly fluent violations are deemed less morally wrong




S
M
Laham






A
L
Alter






G
P
Goodwin




















10.1016/j.cognition.2009.06.001








Cognition




112


3














Ethics and Infinity: Conversations with Philippe Nemo




E
Levinas








Trans


R. A. Cohen






XanEdu Publishing, Inc






1st edition








Rethinking Emotional Desensitization to Violence: Methodological and Theoretical Insights From Social Media Data




J
Li






D
Conathan






C
Hughes








Proceedings of the 8th International Conference on Social Media & Society


the 8th International Conference on Social Media & Society




















10.1145/3097286.3097333














New Solutions Dramatically Improve Research Data Quality on MTurk




L
Litman


















Analyzing Personality through Social Media Profile Picture Choice




L
Liu






D
Preotiuc-Pietro






Z
R
Samani






M
E
Moghaddam






L
Ungar








Tenth International AAAI Conference on Web and Social Media. Tenth International AAAI Conference on Web and Social Media


















T
Lorenz






Teens Are Being Bullied 'Constantly' on Instagram
















What Experimental Evidence Shows Us about the Role of Emotions in Moral Judgement




H
Maibom








Philosophy Compass




5


11


















10.1111/j.1747-9991.2010.00341.x














Moral judgments




B
F
Malle








Annual Review of Psychology




72
















The baiting crowd in episodes of threatened suicide




L
Mann








Journal of Personality and Social Psychology




41


4


703
















A
Matamoros-Fernández






J
Farkas




Racism, Hate Speech, and Social Media: A Systematic Review and Critique. Television & New Media






22
















10.1177/1527476420982230














Desensitization




A
Miles-Novelo






C
A
Anderson




10.1002/9781119011071.iemp0056








The International Encyclopedia of Media Psychology




John Wiley & Sons
















The Crisis of Presence in Contemporary Culture: Ethics, Privacy and Speech in Mediated Social Life




V
Miller








SAGE Publications






Limited








A Measurement Study of Hate Speech in Social Media




M
Mondal






L
A
Silva






F
Benevenuto




10.1145/3078714.3078723








Proceedings of the 28th ACM Conference on Hypertext and Social Media


the 28th ACM Conference on Hypertext and Social Media


















Social media and the public interest: Media regulation in the disinformation age




P
M
Napoli








Columbia University Press












The limitations of official suicide statistics




I
O'donnell






R
Farmer








The British Journal of Psychiatry




166


4
















Deconstructing witnessed suicide: A portrait of those who die by suicide in front of others




T
H
Ooi






T
H
Irani






K
A
Hermes






C
L
Meyer




10.1007/s12144-020-01143-y








Current Psychology


















The State of Online Harassment






Pew Research Centre
















Suicide baiting in the internet era




J
Phillips






L
Mann








Computers in Human Behavior




92
















A 12-year-old girl live-streamed her suicide. It took two weeks for Facebook to take the video down




K
Phillips








Washington Post












Ethics in Cyberspace




T
Ploug




10.1007/978-90-481-2370-4








Springer












A study of beliefs and behaviors regarding digital technology




D
Poole








New Media & Society




9


5
















The emotional basis of moral judgments




J
Prinz




10.1080/13869790500492466








Philosophical Explorations




9


1
















Inflammatory Comments Elicit Less Outrage When Made in Anonymous Online Contexts




C
Puryear






J
A
Vandello




10.1177/1948550618806350








Social Psychological and Personality Science




10


7
















The Role of Morality in Emotional Reactions to and Enjoyment of Media Entertainment




A
A
Raney








Journal of Media Psychology




23


1


















10.1027/1864-1105/a000027














Imagining wrong: Fictitious contexts mitigate condemnation of harm more than impurity




J
S
Sabo






R
Giner-Sorolla




10.1037/xge0000251








Journal of Experimental Psychology: General




146


1
















Combating disinformation on social media: Multilevel governance and distributed accountability in




F
Saurwein






C
Spencer-Smith








Europe. Digital Journalism




8


6
















Hume's Joke: Ignorance and Moral Judgment




S
Scheall






P
Crutchfield




10.2139/ssrn.3877438


















The importance of context in moral judgments




C
Schein








Perspectives on Psychological Science




15


2
















The Unifying Moral Dyad: Liberals and Conservatives Share the Same Harm-Based Moral Template




C
Schein






K
Gray




10.1177/0146167215591501








Personality and Social Psychology Bulletin




41


8
















The Theory of Dyadic Morality: Reinventing Moral Judgment by Redefining Harm




C
Schein






K
Gray




10.1177/1088868317698288








Personality and Social Psychology Review




22


1
















Disgust as Embodied Moral Judgment




S
Schnall






J
Haidt






G
L
Clore






A
H
Jordan








Personality & Social Psychology Bulletin




34


8


















10.1177/0146167208317771














An analysis of variance test for normality (Complete Samples)




S
S
Shapiro






M
B
Wilk




10.1093/biomet/52.3-4.591








Biometrika




52


3-4
















Media and morality: On the rise of the mediapolis




R
Silverstone








Polity Press












Popular video games: Quantifying the presentation of violence and its context




S
L
Smith






K
Lachlan






R
Tamborini








Journal of Broadcasting & Electronic Media




47


1
















Biggest social media platforms 2023




Statista




















International regulatory frameworks for online content




P
A
Thompson






M
S
Daubs








269






Commissioned by the Department of Internal Affairs (DIA)








Methodological concerns in moral judgement research: Severity of harm shapes moral decisions




B
Trémolière






W
De Neys




10.1080/20445911.2013.841169








Journal of Cognitive Psychology




25


8
















Quarantining online hate speech: Technical and ethical perspectives




S
Ullmann






M
Tomalin








Ethics and Information Technology




22


1


















10.1007/s10676-019-09516-z














Moral judgments and the role of social harm: Differences in automatic versus controlled processing




R
Usoof-Thowfeek






R
Janoff-Bulman






J
Tavernini








Journal of Experimental Social Psychology




47


1


















10.1016/j.jesp.2010.07.016














Collective dynamics of 'small-world' networks




D
J
Watts






S
H
Strogatz




10.1038/30918








Nature




393


6684








Article 6684








Bonferroni Correction




E
W
Weisstein












Text












Wolfram
Mathworld
















Hypnotic Disgust Makes Moral Judgments More Severe




T
Wheatley






J
Haidt




10.1111/j.1467-9280.2005.01614.x








Psychological Science




16


10
















Cyberbullying Via Social Media




E
Whittaker






R
M
Kowalski




10.1080/15388220.2014.949377








Journal of School Violence




14


1
















Individual Comparisons by Ranking Methods




F
Wilcoxon




10.2307/3001968








Biometrics Bulletin




6
















The Use of Vignettes in Qualitative Research into Social Work Values




T
Wilks








Qualitative Social Work




3


1


















10.1177/1473325004041133














The Medusa effect reveals levels of mind perception in pictures




P
Will






E
Merritt






A
Kingstone




10.1073/pnas.210664011








118












Autonomous morals: Inferences of mind predict acceptance of AI behavior in sacrificial moral dilemmas




A
Young






A
E
Monroe




10.1016/j.jesp.2019.103870








Journal of Experimental Social Psychology




85














Investigating emotion in moral cognition: A review of evidence from functional neuroimaging and neuropsychology




L
Young






M
Koenigs




10.1093/bmb/ldm031








British Medical Bulletin




84


1
















Young Adults' Folk Theories of How Social Media Harms Its Users




R
Young






V
Kananovich






B
G
Johnson








Mass Communication and Society


26
















10.1080/15205436.2021.1970186














Ubiquitous harm: Moral judgment in the perspective of the theory of dyadic morality




Z
Ze






W
U
Baopei




10.3724/SP.J.1042.2019.00128








Advances in Psychological Science




27


1














Profile pictures on social media: Gender and regional differences




W
Zheng






C.-H
Yuan






W.-H
Chang






Y.-C
J
Wu




10.1016/j.chb.2016.06.041








Computers in Human Behavior




63

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]