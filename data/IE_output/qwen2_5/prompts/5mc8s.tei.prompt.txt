You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



The Political (A)Symmetry of Metacognitive Insight Into Detecting


Misinformation
Political misinformation poses a major threat to democracies worldwide 
(Lewandowsky et al., 2020;
Porpora & Sekalala, 2019)
. A plethora of research has investigated people's ability to distinguish between accurate political information and falsehoods, the individual-level 
(Ecker et al., 2022)
 and macro-level 
(Grinberg et al., 2019;
Guess et al., 2019;
Guess et al., 2020)
 drivers of this ability, and its political symmetry or asymmetry . However, despite the central role this ability plays in informed electorates and political decision making, surprisingly little is known about people's metacognitive insight into their ability to discern accurate from inaccurate political information (for a recent review of metacognition research on misinformation, see 
Rapp & Withall, 2023)
 Metacognition-thinking about thinking-can manifest itself in the confidence that people have in their own cognition, such as their beliefs 
(Flavell, 1979)
. This aspect of metacognition has several functional roles. First, in the absence of clear cues about who is knowledgeable, people rely on confident others (i.e., they use a confidence heuristic; 
Price & Stone, 2004;
Sah et al., 2013;
Tenney et al., 2008)
. Second, the more confident people are in their beliefs, the more willing and likely they are to defend them 
(Babad et al., 1987;
Compton & Pfau, 2005)
. Third, the less confident people are in their judgments, the less likely they are to act on them and the more likely they are to seek additional information 
(Berner & Graber, 2008;
Fischer et al., 2022;
Locander & Hermann, 1979;
Meyer et al., 2013;
Schulz et al., 2020)
. And finally, confidence translates into real-world action: More confident individuals are more likely to vote 
(Ortoleva & Snowberg, 2015)
 and people with more accurate confidence about their COVID-19 beliefs (i.e., more confident when right and less confident when wrong) were more likely to comply with recommended public health measures during the pandemic 
(Fischer et al., 2023)
.
A particularly promising measure for quantifying people's metacognition in terms of how well their confidence tracks their beliefs is metacognitive efficiency . 1 It is considered the gold standard of all measures of metacognition as it uses signal detection theory (SDT; Overgaard, 2015) to express people's metacognition relative to their level of knowledge. In contrast, a simple measure of metacognition that only quantifies the extent to which confidence discerns between correct and incorrect judgments is confounded by knowledge as well as confidence and knowledge response bias 
(Galvin et al., 2003
; for more information, see Overview of the Reanalyses). Metacognitive efficiency is theoretically optimal when people's levels of knowledge are matched by similar levels of metacognition.
An emerging line of research applies metacognitive efficiency to the study of misinformation in politically contested domains 
Fischer & Said, 2021;
. However, research that quantifies metacognitive efficiency often relies on a limited number of trials (e.g.,  and may therefore be unable to capture between-and within-subject variability in metacognition 
(Rausch & Zehetleitner, 2022)
.
For some general knowledge domains-such as topics within biology and physics-people's knowledge and confidence are aligned: Their levels of knowledge are matched by similar levels of metacognition ). 2 By contrast, in more politicized knowledge domains-such as climate change and COVID-19 3 -people's
1 For a glossary of key terms, see 
Table S1
 in the Supplementary Materials.
2 Note that both  and  administered factual knowledge questions devised by the National Science Foundation on scientific facts that were neither controversial nor politicized.
Moreover, these studies investigated national samples from Germany  and the United Kingdom , where-unlike in the U.S.-biology and physics tend to not be politicized.
confidence does not track the accuracy of their knowledge as well as would be expected based on their knowledge 
Thaller & Brudermann, 2020)
, a phenomenon that has been dubbed metacognitive blind spots 
(Fleming, 2021)
.
Thus far, no research has investigated metacognition in the domain of political misinformation within a single methodologically and theoretically coherent framework.
Here, we fill this gap by using state-of-the-art methods based on SDT to directly compare meta-level (i.e., how well confidence discerns correct from incorrect judgments) and object-level (i.e., how well judgments discern stimulus from noise) performance. Based on the notions that the low-quality information environments of politically contentious topics negatively affect metacognitive efficiency-by not providing reliable feedback on whether confidence is justified, thus making confidence judgments ill-informed-and that information about politics is often characterized by biased reporting or outright misinformation (see, e.g., 
Allcott & Gentzkow, 2017;
Arceneaux & Truex, 2022;
 Washington Post Fact Checker, 2021), we expected to find metacognitive blind spots for detecting political misinformation:
• H1.1 (metacognitive ideal hypothesis): Metacognitive efficiency for political statements is lower than the theoretically optimal metacognitive efficiency.
• H1.2 (domain comparison hypothesis): Metacognitive efficiency for political statements is lower than for non-politicized domains such as biology and physics .
Many studies have examined political (a)symmetries at the object level.
Republicans, relative to Democrats, are both exposed to and share more articles from unreliable websites 
(Grinberg et al., 2019;
Guess et al., 2019;
Guess et al., 2020)
, and there is growing evidence that conservatives are more susceptible to misinformation than liberals (see, e.g., 
Clemm von Hohenberg, 2023;
Dobbs et al., 2023;
Rathje et al., 2020)
. 
Roozenbeek et al., 2022;
van der Linden et al., 2021)
. Similarly, political (a)symmetries in epistemic motives and abilities have also been a central theme in recent literature. Several studies have found that conservatives score higher than liberals on measures of dogmatism, rigidity, and intolerance to ambiguity, whereas liberals score higher on integrative complexity, cognitive reflection, and need for cognition 
(Jost, 2017)
. While meta-analytic evidence suggests that partisan bias-evaluating information that aligns with one's political views more positively-is bipartisan 
(Ditto et al., 2019)
, these conclusions have been challenged for methodological reasons 
(Baron & Jost, 2019)
.
Moreover, despite comparable levels of task performance, conservatives have been found to be more confident than liberals across a range of judgment and decision making tasks 
(Ruisch & Stern, 2021)
. If the quality of the information environment directly affects metacognitive efficiency and Republicans are confronted with more low-quality information 
(Grinberg et al., 2019;
Guess et al., 2019;
Guess et al., 2020)
, it should hold that metacognitive efficiency is lower for Republicans (conservatives) than for Democrats (liberals). 4 Additionally, political extremism-independent of partisanship-is associated with a lower likelihood of confidence discerning correct from incorrect judgments in more basic, perceptual tasks 
(Rollwage et al., 2018)
; political extremists can therefore also be expected to show lower metacognitive efficiency for detecting political misinformation.
Taken together, metacognitive efficiency seems likely to be particularly low for extreme conservatives. We therefore examined these hypotheses:
• H2.1a (asymmetry hypothesis; political party identification): Metacognitive efficiency for political statements is lower for Republicans than for Democrats. 
4
 Political party affiliation and ideological views are related concepts, but exhibit notable distinctions.
While political party affiliation pertains to people's formal or informal membership of a particular political party, ideological views encompass a wider range of beliefs, principles, and values that steer their political cognition and influence their stances on diverse issues. Yet, the two are highly correlated-both in the  sample and in the U.S. population more broadly 
(Twenge et al., 2016)
.
• H2.1b (asymmetry hypothesis; political ideology): Metacognitive efficiency for political statements is lower for conservatives than for liberals.
• H2.2 (ideological extremity hypothesis): Metacognitive efficiency for political statements decreases strictly monotonically with political extremism on both sides of the political spectrum.
• H2.3 (asymmetrical ideological extremity hypothesis): Metacognitive efficiency for political statements decreases more strongly with political extremism for conservatives than for liberals.
Finally, various epistemic beliefs-such as having faith in one's own intuition for facts, believing that truth is political, and having a need for evidence-have been found to predict conspiracist ideation and misinformation discernment 
(Garrett & Weeks, 2017;
Rudloff & Appel, 2022)
. These beliefs may be related to metacognitive insight. For instance, initial judgments that feel correct are less likely to prompt conscious reflection 
(Fletcher & Carruthers, 2012;
Thompson et al., 2011)
. In line with this account, individuals with higher metacognitive efficiency are more likely to overcome initial biases when evaluating external evidence 
(Said et al., 2021)
. Age may also be associated with metacognitive efficiency for detecting political misinformation. For one thing, there is some evidence that metacognitive efficiency decreases with age 
(Culot et al., 2023;
. For another thing, older adults are more likely than younger adults to be exposed to low-quality news on social media 
(Grinberg et al., 2019;
Guess et al., 2020)
, they share it at higher rates 
(Guess et al., 2019)
, and they are more likely to forget corrections 
(Swire et al., 2017)
. The present research therefore also investigates how metacognitive efficiency relates to epistemic beliefs and age by addressing these hypotheses:
• H3.1 (faith in intuition for facts hypothesis): The stronger people's faith in their intuition for identifying facts, the lower their metacognitive efficiency for political statements.
• H3.2 (truth is political hypothesis): The stronger people's belief that truth is political, the lower their metacognitive efficiency for political statements.
• H3.3 (need for evidence hypothesis): The higher people's need for evidence, the higher their metacognitive efficiency for political statements.
• H3.4 (age hypothesis): Metacognitive efficiency for political statements declines with age.


Reanalysis of Garrett & Bond (2021)
To test our hypotheses about people's insight into their ability to discern true from false political information, we reanalyzed data from a longitudinal study (12 waves across 6 months) that surveyed a representative U.S. sample (N = 1,191) on the most widely circulating political (mis)information online at the time of each wave ).


Transparency and Openness
The original data are available on the Harvard Dataverse (https://doi.org/10.7910/DVN/CGV6NP), and our code and preregistration are available on OSF (https://osf.io/veja6/). Data were analyzed using R, version 4.3.1 (R Core Team, 2023). We adopted a two-step preregistration procedure (see Supplement S2 for details):
First, we preregistered our secondary data analysis following the template of Van den Akker et al. (2021). Second, we preregistered our analysis code, which we developed based on a 20% subsample of the data that served as the exploration data set.
After this second step, we ran the same code on all data. All code changes since the code preregistration (i.e., the second step of the preregistration) can be seen as a git-diff on the project's GitHub repository. 
5
 familiar with each of the 20 statements. They then judged whether each statement was true or false (knowledge; "True" or "False") and how confident they were in their decision (confidence; "Definitely" 
[high]
 or "Probably" [low]) on the following scale: (1) Definitely True; (2) Probably True; (3) Probably False; (4) Definitely False.


Overview of the Reanalyses
To measure the accuracy of participants' political knowledge, we used d ′ as specified in an SDT framework 
(Macmillan & Creelman, 2004)
 to quantify participants' ability to discern true from false political statements based on their true-positive and false-positive rates. Recent research has demonstrated that SDT is an important asset to misinformation research, enabling researchers to disentangle discrimination ability and response bias 
Gawronski et al., 2023;
Modirrousta-Galian & Higham, 2023;
Sultan et al., 2022)
.
Analogously, we quantified metacognition as the degree to which participants' confidence judgments differentiated between correct and incorrect accuracy judgments,
given their level of knowledge 
(Maniscalco & Lau, 2012)
. To this end, we computed metacognitive sensitivity at the level of knowledge distributions. This approach defines an additional d ′ -meta-d ′ -as the level of knowledge that a metacognitively ideal respondent would need to produce the observed confidence data. Because d ′ and meta-d ′ are measured on the same signal-to-noise ratio scale, they can be directly compared. Therefore, relative metacognitive sensitivity-metacognitive efficiency-can be calculated as either a ratio
(M ratio = meta-d ′ /d ′ ) or a difference score (M dif f = meta-d ′ − d ′ )
, factoring out the confounding influence of object-level performance (i.e., political knowledge) by quantifying metacognition relative to a given level of knowledge .
When meta-d ′ equals d ′ , participants are metacognitively ideal and can use all of the information available for the object-level task (discerning true from false political statements) when reporting confidence. When meta-d ′ is less than d ′ , participants have a lower ability to report confidence judgments than would be expected given the accuracy of their knowledge. In some cases, meta-d ′ may be higher than d ′ , such as when participants draw on hunches 
Scott et al., 2014)
, engage in deeper analysis of the stimulus information , or possess knowledge about other factors influencing task performance while forming their metacognitive assessments .
Consider two individuals distinguishing between true and false news. Individual A discerns well between accurate information and falsehood (d ′ = 1.1) and their confidence levels accurately reflect their performance: They are often confident when correct and rarely confident when wrong; this indicates high metacognitive sensitivity (meta-d ′ = 1.1).
Their metacognitive efficiency is therefore M ratio = meta-d ′ /d ′ = 1.1/1.1 = 1. Individual B does poorly at distinguishing accurate information from falsehood (d ′ = 0.6), and, because metacognitive sensitivity is inherently confounded with knowledge, their metacognitive sensitivity (meta-d ′ = 0.6) is also diminished: They are only sometimes confident when correct and they are sometimes confident when wrong. Their metacognitive efficiency is M ratio = 0.6/0.6 = 1. In other words, both individuals exhibit different levels of object-level (d ′ ) and meta-level sensitivity (meta-d ′ ), yet-given their different levels of knowledge-they are equally efficient at using their object-level knowledge to inform their confidence judgments (both M ratio = 1). Metacognitive efficiency thus provides a more comprehensive understanding of an individual's metacognitive insight than metacognitive sensitivity alone because it takes into account the confounding effects of knowledge.
We focused on metacognitive efficiency in all main analyses. To compute metacognitive efficiency, we employed a hierarchical Bayesian procedure , adapting the code provided at https://github.com/smfleming/HMeta-d. A hierarchical approach allowed us to estimate metacognitive efficiency at individual and group levels. 6


Results


Overall Insight Into the Accuracy of Truth Judgments
Overall, people's knowledge and confidence for political statements were almost perfectly aligned (H1.1; see 
Fig. 1
). 7 Even though most values of the M ratio distribution were estimated to be below M ratio = 1 (median M ratio = 0.95, 95% CI = 0.92-0.98; see 
Fig. 1
), they were practically indifferent from optimal metacognitive efficiency. The model estimated a 99.9% probability that the average metacognitive efficiency in the study population would lie in a preregistered region of practical equivalence (ROPE) around the theoretically optimal metacognitive efficiency (i.e., M ratio = 1, ROPE = 0.9-1.1; . These results resemble findings from more general knowledge domains such as biology and physics (H1.2; M ratio = 0.99, 95% CI = 0.88-1.16, ; M ratio = 0.98, 95% CI = 0.91-1.05, , and stand in contrast to the 


Political Antecedents of Metacognitive Efficiency
Consistent with , our analysis re-established that political knowledge (i.e., d ′ ) decreases with self-reported level of conservatism (see 
Fig. 2
, Panel A).
The more conservative participants were, the less they correctly distinguished true from false political statements. We also examined the results based on statement concordance and asked to what extent participants' political views were associated with increased accuracy-in terms of discrimination ability (d ′ ), metacognitive sensitivity (meta-d ′ ), and metacognitive efficiency (M ratio)-for concordant statements (i.e., statements where partisan bias facilitated accumulating evidence for the correct answer) and with decreased Region of practical equivalence (ROPE) ranges from M ratio = 0.9-1.1. See the online article for the color version of this figure. accuracy for discordant statements (i.e., statements where partisan bias impeded accumulating evidence for the correct answer; see also . To study whether participants' political views biased their information processing, we operationalized each statement's concordance using the following three factors: (i) a statement's slant (i.e., pro-liberal/-Democrat, pro-conservative/-Republican, or neutral),
a statement's truth (i.e., true or false), and (iii) a participant's political views (i.e., liberal/Democrat or conservative/Republican). This conceptualization led to three statement subgroups (see also 
Table 1
 and Supplement S2):
• Concordant statements: Biased information processing may increase accuracy when what a participant wants (e.g., a liberal participant wanting a pro-conservative statement to be false) aligns with the true state of the world (e.g., false).
• Discordant statements: Biased information processing may decrease accuracy when what a participant wants (e.g., a liberal participant wanting a pro-conservative statement to be false) misaligns with the true state of the world (e.g., true).
• Neutral statements: Biased information processing may have no effect on accuracy when what a participant wants (e.g., a liberal participant not wanting a politically neutral statement to be either true or false) neither aligns nor misaligns with the true state of the world (e.g., true).
Across the ideological spectrum, we found a strong effect for statement concordance:
Participants were significantly better at discerning between accurate information and falsehoods for concordant than for discordant statements, with neutral statements falling in between (see 
Fig. 2
, Panel A; meta-d ′ showed, by and large, results qualitatively similar to those for d ′ , see 
Fig. 2
, Panel B.).
At the metacognitive level, participants across the ideological spectrum were close to the metacognitive ideal of M ratio = 1 (H2.2 and H2.3; see 
Fig. 2
, Panel C). 8 However, we found a striking effect for statement concordance: With increasing conservatism, participants had a harder time judging the accuracy of their own truth judgments on discordant statements challenging their ideological views, manifesting in markedly lower metacognitive efficiency. At the extreme, for conservatives judging discordant statements, 
8
 In particular for M ratio, results (i.e., posterior of the group-level mean and its 95% CI) for all statements do not consistently match the average of the three statement subgroups (i.e., concordant, discordant, and neutral statements). This may be because combining multiple-item difficulty levels in a single analysis can inflate estimates of metacognitive ability 
(Rahnev & Fleming, 2019)
. The full analysis of all statements included both relatively easy and hard items (in this case, concordant and discordant statements), potentially inflating estimated metacognitive insight relative to the statement subgroup analyses.   


S10-S12 for robustness checks).
Previous research on partisan bias and misinformation belief has found that people are more likely to believe pro-ingroup than pro-outgroup information (see, e.g., 
Pennycook & Rand, 2021;
Van Bavel & Pereira, 2018)
. Our results go beyond those findings in two ways. First, we demonstrate another, distinct pathway via which partisan bias influences people's discrimination ability (i.e., d ′ ), namely, by biasing the processing of information in a way that facilitates discrimination ability for concordant statements and impedes it for discordant ones (see also  conceptually similar results in a drift diffusion model analysis). This result is different from, say, Batailler and colleagues' 2022 finding that partisan bias lowers the response threshold and increases discrimination ability for congruent statements (i.e., statements that align with participants' ideology irrespective of statement truth). Second, we show that political views influence information processing not only at the object level (d ′ ), but also at the meta level, that is, both metacognitive sensitivity (meta-d ′ ) and, for conservatives, insight into the accuracy of their judgments (M ratio or metacognitive efficiency).
It is important to note that because the political statements were selected based on virality metrics, they were not equally distributed in terms of their partisan slant: Most of the falsehoods reflected positively on conservatives and were thus discordant for conservatives in our three-way concordance coding. However, this should have no bearing on our results as the analyses account for the different proportions of true/false statements that are pro-ingroup or pro-outgroup across the political spectrum. That is, for H2, we ran separate models for different subgroups of participants and/or statements (e.g., only conservatives judging discordant statements), thus estimating metacognitive efficiency only for these subgroups, without them being influenced by, for example, the distribution of statement slant.


Predictors of Metacognitive Efficiency
Age and several epistemic beliefs were to some extent associated with metacognitive efficiency, but contrary to the predicted directions. As preregistered, we used the difference score (M dif f )-instead of the ratio (M ratio)-of participants' individual-level estimates of metacognitive efficiency in order to explore the relationship of metacognitive efficiency with epistemic beliefs and age because more than 10% of the individual-level M ratio estimates were uninterpretable (i.e., M ratio ≤ 0 or NA). 9 Our results revealed that participants who had higher faith in their intuition for facts (H3.1; rho = .08, p = .004; BF 10 = 3.91; see 
Fig. 3
, Panel A) and belief that truth is political (H3.2; rho = .10, p < .001; BF 10 = 17.3; see 
Fig. 3
, Panel B) had slightly higher metacognitive efficiency.
Participants' need for evidence was not predictive of their metacognitive efficiency (H3.3; rho = −.04, p = .23; BF 10 = 0.14; see 
Fig. 3
, Panel C). Lastly, the older the participants, the slightly higher their metacognitive efficiency (H3.4; rho = .13, p < .001; BF 10 = 2780.6; see 
Fig. 3
, Panel D).


Discussion
How aware are people of whether they are right or wrong when judging the accuracy of political (mis)information? And is this metacognitive insight associated with their political views? Contrary to our hypotheses, we found that, across all statements, people from both the political left and the political right were aware of how well they distinguished accurate information from falsehood: Their confidence tended to match the accuracy with which they distinguished statements as true or false, indicating ideal metacognitive efficiency (i.e., a level of metacognition matching their level of knowledge). However, when evaluating statements that challenged their ideological commitments, people on the political right showed significantly lower levels of metacognitive efficiency, revealing a selective metacognitive failure for discordant news. By combining a large-scale data set and real-world news statements with state-of-the-art SDT analyses, we shed light on the intricate and systematic ways that political preferences are linked to the accuracy with which people gauge their own ability to tell truth from falsehood.


Theoretical Implications
The asymmetry in metacognitive insight for discordant statements may help explain metacognitive blind spots in politicized science (e.g., climate change; 
, Thaller & Brudermann, 2020
and COVID-19;
, where scientific evidence tends to be at odds with conservative worldviews 
(Lewandowsky & Oberauer, 2021)
. The finding that conservatives systematically exhibit lower metacognitive efficiency for discordant political statements suggests that overall metacognitive efficiency in politicized domains may be similarly impaired due to a more general metacognitive blind spot among conservatives for judging discordant (mis)information. In our preregistration, we predicted that overall metacognitive efficiency would be lower than the metacognitive ideal (i.e.,
M ratio = 1) and particularly diminished in individuals from the political right (vs. left).
This prediction was informed by the observation that false and biased information on political issues is rife, with those on the political right being exposed to a disproportionate amount of political misinformation. However, our results suggest that suboptimal metacognitive efficiency is less a function of the low-quality information environments surrounding politically contentious issues, and more a function of a generally lower level of metacognitive insight among people on the political right when confronted with discordant statements. This may explain why our hypotheses for overall metacognitive blind spots (H1.1 and H1.2) and lowered metacognitive efficiency among the politically (extreme) right (H2.1-H2.3) were not confirmed or confirmed only for conservatives judging discordant statements. Consistent with our results, a recent study 
(Dobbs et al., 2023)
 found no notable differences in metacognitive efficiency along U.S. party lines across all statements.
However, the study did not find lower metacognitive efficiency among conservatives judging discordant statements. This discrepancy may be due to different experimental and analysis decisions (e.g., use of different statements and different coding of statement concordance). 10
Our main finding-a political asymmetry for both object-level sensitivity (d ′ ) and metacognitive sensitivity (meta-d ′ )-seems, at first glance, indicative of a Dunning-Kruger effect 
(Kruger & Dunning, 1999
; aka the unskilled-and-unaware phenomenon). This effect posits that people with low ability at a task tend to overestimate their ability, whereas people with high ability may underestimate their ability. In our study, people from the political right, whose ability to distinguish true from false news was relatively low, were also less able to judge whether their decision was correct or incorrect, as reflected in lower metacognitive sensitivity (meta-d ′ ). However, our findings are based on a fundamentally different operationalization of the accuracy-confidence relationship  than are those of 
Kruger and Dunning (1999)
, rendering a comparison problematic. While the Dunning-Kruger effect relies on a global estimate of self-performance (e.g., a one-shot rating of one's percentile within a study population; but see also 
Hartwig & Dunlosky, 2014
), our study examines local confidence within stimuli (i.e., low or high confidence that a single decision is correct); that is, our respondents never assessed their overall performance.
Furthermore, since metacognitive sensitivity (meta-d ′ ) is confounded with object-level performance (d ′ ), only metacognitive efficiency (e.g., M ratio) is an appropriate measure of people's insight into their performance . Following this reasoning, one could conclude that we do not observe a Dunning-Kruger effect because M ratio is not clearly associated with political ideology in our study (except for discordant statements).
However, because assessing one's overall performance and one's confidence in a particular decision are conceptually and empirically distinct 
(Rouault et al., 2019)
, it seems doubtful that this study really assesses the Dunning-Kruger effect in its original conceptualization.


Practical Implications
Our results suggest that conservatives may suffer a triple burden: First, they are more susceptible to the most viral misinformation (d ′ ; see also .
Conservatives are thus more likely to be misinformed, posing a threat to democracy which relies on objective truths to find common ground 
(Lewandowsky et al., 2020;
Porpora & Sekalala, 2019)
.
Second, conservatives' reported confidence is less informative about when they are right or wrong, both overall and especially for discordant statements (meta-d ′ ). Such lowered metacognitive sensitivity suggests that conservatives' confidence is not a reliable indicator for the accuracy of their truth judgments for political statements. Yet the level of confidence that people display is key for information propagation (see, e.g., the confidence heuristic mentioned earlier; 
Price & Stone, 2004)
. Thus, generally lower metacognitive sensitivity for detecting political misinformation among the political right is alarming, as they are not only exposed to more low-quality articles 
(Grinberg et al., 2019)
 but also (confidently) share them at higher rates 
(Guess et al., 2019)
.
Third, conservatives are markedly less efficient in using their metacognition-above and beyond what is to be expected based on their knowledge-to judge discordant statements (M ratio). In other words, conservatives struggle to use internal evidence to inform their metacognition when the information in question is at odds with their political views. This finding may help explain broader societal trends such as political polarization 
(Jost et al., 2022)
. A rich history of research has demonstrated the importance of metacognition for learning 
(Paris & Winograd, 1990
) and belief-updating 
(Fischer et al., 2022
 Finally, the finding that older adults have higher metacognitive insight (M ratio)
when it comes to detecting political misinformation than younger adults suggests that the disproportionate sharing of misinformation by older (vs. younger) adults 
(Grinberg et al., 2019;
Guess et al., 2019)
 is driven by mechanisms other than poor insight into their own misperceptions (for a comprehensive review, see 
Brashier & Schacter, 2020)
.


Future Directions
Future research should investigate metacognition in knowledge domains where the evidence tends to be at odds with liberal (vs. conservative) worldviews. To date, metacognition studies have tended to focus on domains that challenge conservative worldviews (e.g., climate change, COVID-19, or politics) or are relatively politically neutral (e.g., biology or physics). Another promising endeavour for future work is to explore whether metacognitive insight translates into real-world online behaviors (e.g., sharing misinformation) in hybrid lab-field studies 
(Geers, 2023;
Lyons et al., 2021;
Mosleh et al., 2022)
. Investigating people's metacognition with respect to other ways of engaging with political misinformation online, such as distinguishing between low-quality and high-quality partisan websites, may also be beneficial 
(Geers et al., 2024)
. A final open question is to what extent people from the political right are misinformed or simply uninformed about political (mis)information 
(Li & Wagner, 2020)
.


Constraints on Generality
Given the nature of our sample, we expect our results to generalize to the broader U.S. public. Yet it is unclear to what extent they generalize to other knowledge domains (e.g., AI) or time frames (e.g., after Elon Musk's 2022 purchase of X, formerly known as Twitter). Moreover, our results may not apply to countries with different languages, cultures, or media diets. We have no reason to believe that the results depend on other characteristics of the participants, materials, or context. Our preregistration is available on OSF (https://osf.io/veja6/). We adopted a two-step preregistration procedure: In the first step we preregistered our secondary data analysis following the template of Van den Akker et al. (2021). In the second step, we preregistered our analysis code, which we developed based on a 20% subsample of the data that served as the exploration data set. After this second step, we ran the same code again, but this time on all data. All code changes since the code preregistration (i.e., the second step of the two-step preregistration) can be seen as a git-diff on the project's GitHub repository (https: //github.com/stefanherzog/misinformation_and_metacognition/compare/v0.1...v1.0).


Conclusion
Thus, any changes in the approach of the final, second step of the preregistration do not constitute a deviation from the preregistration, but are a proper part of the overall preregistration process. Our preregistration was also informed by Srivastava's 2018
suggestions for how to aspire to the goals of preregistration in the context of research that uses more complex cognitive modeling approaches (see "Part 5: Analyses" of the first step of the preregistration for details). Notable changes between the first and second step of the preregistration include:


Knowledge Accuracy
In the first step, we only formulated metacognition analyses (i.e., meta-d ′ , M ratio,
and M dif f ), as they were the primary focus of this study. However, we conducted additional knowledge analyses (d ′ ) as part of the second preregistration step. Knowledge analyses were primarily aimed at re-establishing the main results in  and to provide a more comprehensive view of the results-comprising accuracy of both knowledge and metacognition.


Statement Coding
In the first step, we planned to code statements based on participants' political party only. In the second step, we also coded statements based on participants' political ideology, such that pro-Democrat statements were coded as congruent for liberals and pro-Republican statements were coded as congruent for conservatives (and vice versa).
In addition to coding statements based on the alignment of a statement's slant and a participant's political views (congruency), in the second step we decided to also examine statement concordance, which additionally considers a statement's truth. For the statement congruency coding, we would expect an effect of partisan bias on response tendency, that is, a more lenient tendency to judge statements that align with one's political views as true, and vice versa (i.e., c in SDT terms; see  Consistent with the congruency coding, we applied this concordance coding only for participants who identified as liberal (Democratic) or conservative (Republican). For all other participants, no statement concordance score could be assigned.


Robustness Checks
As opposed to the first step of the preregistration, in the second step we decided against testing all hypotheses with different subsets of participants (e.g., participants who completed six or more waves vs. all 12 waves) and/or statements (e.g., recognized vs.
non-recognized statements) to keep the number of separate models to be estimated more manageable. Instead, we estimated metacognitive efficiency across different subsets of participants or statements (see 
Fig. S10
, Panel C). We did, however, test hypothesis H2 again separately for statements that were concordant versus discordant, with neutral statements as a benchmark, as we considered statement concordance to be of high theoretical and practical relevance.


Uninterpretable Values
Next to individual-level estimates of Mratio ≤ 0, we also defined NAs as uninterpretable values. In addition, we also considered NAs for M dif f (i.e., meta-
d ′ − d ′ )
as uninterpretable values. The model can produce NAs for M ratio, for instance, if d ′ = 0 or if meta-d ′ > 0 and d ′ < 0, and NAs for M dif f if no value for d ′ or meta-d ′ can be calculated. For all these values, participants were excluded for the respective analysis.


Supplement S3: Participants


Sample Demographics
See 
Table S2
.


Dropout Across Waves
Out of the total 1,191 participants, 1,171 participants provided valid responses in wave 1 (i.e., no satisficing). Valid responses across the remaining 11 (of the total 12) waves ranged from 771 to 888 participants (see 
Fig. S1
; for the number of completed waves across participants, see 
Fig. S2
). Participants were allowed to return after they missed waves.
Almost a third of participants (27%) completed all 12 waves, while three-quarters (75%) of the sample completed at least half of the waves (see    


Supplement S4: Hypothesis Tests
While we broadly outlined the hypotheses tests in the first step of our two-step preregistration procedure, the code of step two implemented its analytic details (https://github.com/stefanherzog/misinformation_and_metacognition).
We focused on metacognitive efficiency (Mratio = meta-
d ′ /d ′ or Mdiff = meta-d ′ − d ′ )
in all our main analyses. When meta-d ′ equals d ′ , participants are metacognitively optimal and can use all of the information available for the object-level task (evaluating political statements) when reporting confidence. When meta-d ′ is less than d ′ , however, participants have a lower ability to report confidence judgments than expected based on the accuracy of their knowledge. In some cases, meta-d ′ may even be higher than d ′ , when participants draw on hunches 
Scott et al., 2014)
, engage in deeper analysis of the stimulus information , or possess knowledge about other factors influencing task performance while forming their metacognitive assessments .


Details on Bayesian Analyses
For the group-level models, we ran three Markov Chain Monte Carlo (MCMC) chains with 10,000 samples each via JAGS (see https://mcmc-jags.sourceforge.io/; before that we ran 10,000 samples for adaptation and 1,000 samples for burn-in, both not used in the analyses). For the individual level models, we ran three MCMC chains with 10,000 samples each via JAGS (see https://mcmc-jags.sourceforge.io/; before that we ran 1,000 samples for adaptation and 1,000 samples for burn-in, both not used in the analyses). We used the default priors specified by  and assessed model convergence by calculating Gelman-Rubin statistics. These values indicated good convergence across chains for most group-level models (i.e., R < 1.01). Some group-level models did, however, yield an R ≥ 1.01. Hence, for these group-level models as well as those with an R right below the 1.01-threshold, we increased the number of adaptation samples from 10,000 to 30,000. This procedure led to just one group-level model with an R ≥ 1.01, that is, Republicans judging neutral statements.


Details on Software Used
Data were analyzed using R, version 4.3.1 (R Core Team, 2023).


H1.1 (metacognitive ideal hypothesis):
Metacognitive efficiency for political statements is lower than the theoretically optimal metacognitive efficiency.
We compared the group-level posterior distribution (Median M ratio + 95% CI)
with a region of practical equivalence (ROPE; . A ROPE defines an area that is considered equal to the target value (here: M ratio = 1) and then allows the researcher to compute the overlap between the posterior and the ROPE. We preregistered the ROPE to be M ratio = 0.9-1.1. Given that the model estimated a 99.9% probability that the average metacognitive efficiency in the study population would lie in our preregistered ROPE, we reject the hypothesis. As the 95% CI (0.88-1.16) in  broadly overlaps with the ROPE (0.9-1.1), we preregistered to employ the same ROPE comparison as for H1.1. Given that the model estimated a 99.9% probability that the average metacognitive efficiency in the study population would lie in our preregistered ROPE, we reject the hypothesis.


H2.1a (asymmetry hypothesis; political party identification): Metacognitive
efficiency for political statements is lower for Republicans than for Democrats.
We visually inspected and compared the 95% CIs of the separate group-level posterior distributions for Democrats and Republicans. As preregistered, if the 95% CI of Republicans is credibly lower than that of Democrats (i.e., non-overlapping 95% CIs), we accept the hypothesis. In all other cases, we reject the hypothesis. Given that the 95% CIs of Republicans were not credibly lower than that of Democrats, we reject the hypothesis.


H2.1b (asymmetry hypothesis; political ideology): Metacognitive efficiency for
political statements is lower for conservatives than for liberals.
We visually inspected and compared the 95% CIs of the separate group-level posterior distributions for liberals and conservatives. As preregistered, if the 95% CI of conservatives is credibly lower than that of liberals (i.e., non-overlapping 95% CIs), we accept the hypothesis. In all other cases, we reject the hypothesis. Given that the 95% CIs of conservatives were not credibly lower than that of liberals, we reject the hypothesis.


H2.2 (ideological extremity hypothesis): Metacognitive efficiency for political
statements decreases strictly monotonically with political extremism on both sides of the political spectrum.
We visually inspected and compared the 95% CIs of the separate group-level posterior distributions for the seven ideological subgroups from 1 = very liberal to 7 = very conservative. As preregistered, if the 95% CIs are credibly lower with increasing political extremism (i.e., non-overlapping 95% CIs going from the midpoint 4 = moderate towards either 1 = very liberal or 7 = very conservative), we accept the hypothesis. In all other cases, we reject the hypothesis. Given that the 95% CIs were not credibly lower with increasing political extremism, we reject the hypothesis.


H2.3 (asymmetrical ideological extremity hypothesis): Metacognitive efficiency
for political statements declines more strongly with political extremism for conservatives than for liberals.
We visually inspected and compared the 95% CIs of the separate group-level posterior distributions for the seven ideological subgroups from 1 = very liberal to 7 = very conservative. As preregistered, if the 95% CIs are credibly lower with increasing political extremism (i.e., non-overlapping 95% CIs going from the midpoint 4 = moderate towards either 1 = very liberal or 7 = very conservative) and the 95% CIs are credibly lower for conservatives compared to liberals of equal extremity (e.g., 5 = somewhat conservative vs.
hypothesis. Given that the 95% CIs were neither credibly lower with increasing political extremism nor credibly lower for conservatives compared to liberals of equal extremity, we reject the hypothesis.


H3.1 (faith in intuition for facts hypothesis):
The stronger people's faith in their intuition for identifying facts, the lower their metacognitive efficiency for political statements.
We visually inspected the robust LOESS smooth and 95% confidence bands, and computed a Spearman correlation. Additionally, we computed a Bayes factor for the correlation. A Bayes factor greater than 1 provides evidence in favor of the alternative hypothesis, while a Bayes factor less than 1 provides evidence in favor of the null hypothesis, with larger Bayes factors indicating stronger evidence 
(Kass & Raftery, 1995)
.
Our results revealed a weak positive association between participants' faith in intuition and their metacognitive efficiency (rho = .08, p = .004; BF 10 = 3.91), leading us to reject the hypothesis.


H3.2 (truth is political hypothesis):
The stronger people's belief that truth is political, the lower their metacognitive efficiency for political statements.
We visually inspected the robust LOESS smooth and 95% confidence bands, and computed a Spearman correlation. Additionally, we computed a Bayes factor for the correlation. A Bayes factor greater than 1 provides evidence in favor of the alternative hypothesis, while a Bayes factor less than 1 provides evidence in favor of the null hypothesis, with larger Bayes factors indicating stronger evidence 
(Kass & Raftery, 1995)
.
Our results revealed a weak positive association between participants' beliefs that truth is political and their metacognitive efficiency (rho = .10, p < .001; BF 10 = 17.3), leading us to reject the hypothesis.


H3.3 (need for evidence hypothesis):
The higher people's need for evidence, the higher their metacognitive efficiency for political statements.
We visually inspected the robust LOESS smooth and 95% confidence bands, and computed a Spearman correlation. Additionally, we computed a Bayes factor for the correlation. A Bayes factor greater than 1 provides evidence in favor of the alternative hypothesis, while a Bayes factor less than 1 provides evidence in favor of the null hypothesis, with larger Bayes factors indicating stronger evidence 
(Kass & Raftery, 1995)
.
Our results revealed no association between participants' need for evidence and their metacognitive efficiency (rho = −.04, p = .23; BF 10 = 0.14), leading us to reject the hypothesis.


H3.4 (age hypothesis): Metacognitive efficiency for political statements declines with age.
We visually inspected the robust LOESS smooth and 95% confidence bands, and computed a Spearman correlation. Additionally, we computed a Bayes factor for the correlation. A Bayes factor greater than 1 provides evidence in favor of the alternative hypothesis, while a Bayes factor less than 1 provides evidence in favor of the null hypothesis, with larger Bayes factors indicating stronger evidence 
(Kass & Raftery, 1995)
.
Our results revealed a weak positive association between participants' age and their metacognitive efficiency (rho = .13, p < .001; BF 10 = 2780.6), leading us to reject the hypothesis.


Supplement S5: Additional Analyses
When examining the political antecedents of metacognitive efficiency using the data from , three analytical decisions need to be made, resulting in 12 potential analyses: 2 (measure of metacognitive efficiency: Mratio vs. Mdiff) x 2 (statement coding: concordance vs. congruency) x 3 (political views: 7-point ideology vs.
political party vs. liberal/conservative pooled). The main finding of this study-that people on the political right exhibit metacognitive blind spots for discordant statements-is found in 11 out of these 12 possible analyses (see the results reported in detail below). The only analysis where the main pattern of results was not observed used
Mdiff as a measure of metacognitive efficiency. Because the literature predominantly relies on Mratio (e.g., 
Said et al., 2023;
Xue et al., 2021)
, we had When coding statements as the alignment of a statement's slant and a participant's political views, participants from the left showed higher object-level (d ′ ) and metacognitive (meta-d ′ ) sensitivity for incongruent (vs. congruent) statements, while this pattern mostly reversed for participants on the right 
(Fig. S5)
. Nonetheless, the pattern of results for metacognitive efficiency (M ratio) remained consistent with our main finding: Participants on the right-unlike those on the left-again had a harder time introspecting on the accuracy of their truth judgments for incongruent statements, as evidenced by markedly lower metacognitive efficiency (M ratio).


Mdiff as an alternative measure of metacognitive efficiency
As an alternative approach to the ratio (i.e., meta-d ′ /d ′ = M ratio), we can also operationalize metacognitive efficiency using the difference score (i.e., meta- . Below, we report the same analyses for metacognitive efficiency as reported in the main manuscript and above, but this time using the difference score (i.e., M dif f ).
d ′ -d ′ = M dif f ;
Participants across the ideological spectrum hovered around the metacognitive ideal of M dif f = 0 
(Fig. S6)
. When coding statements as the alignment of a statement's slant, a statement's truth, and a participant's ideology, we found no clear differences in metacognitive efficiency across statement subgroups. While this finding did not confirm our main result-that conservatives showed lowered metacognitive efficiency for discordant statements-we caution against overinterpreting these M dif f results, given that M ratio is the measure of metacognitive efficiency predominantly used in the literature. On the other hand, when coding statements as the alignment of a statement's slant with a participant's ideology, we again found supporting evidence for our main result: Conservatives showed significantly lower metacognitive efficiency (M dif f ) for incongruent statements 
(Fig. S7
).
Overall, participants from both the political left and the political right showed metacognitive efficiency (M dif f ) close to the theoretical optimum, although Democrats and liberals appeared to have slightly lower metacognitive efficiency than Republicans and conservatives ( 
Fig. S8 + S9
). When coding statements as the alignment of a statement's slant, a statement's truth, and a participant's political views, we once again observed that conservatives displayed lower metacognitive efficiency for discordant statements 
(Fig. S8
).
Finally, when coding statements as the alignment of a statement's slant with a participant's political views, participants from the political right again had a harder time introspecting for incongruent statements, as reflected in markedly lower M dif f estimates 
(Fig. S9
). theoretically optimal metacognitive efficiency (M ratio); the gray band for M ratio marks the region of practical equivalence (ROPE; i.e., M ratio = 0.9-1.1).


Figure S4
Political 
Knowledge ( d'; Panels A and B), Metacognitive Sensitivity (meta-d'; Panels C and D), and Metacognitive Efficiency ( Mratio; Panels E and F)
 


Supplement S6: Robustness Checks


Group-Level
We investigated group-level estimates of d ′ , meta-d ′ , and M ratio across various subgroups of statements 
(Fig. S10)
. Overall, participants demonstrated moderate-low ability to distinguish between true and false news 
(Fig. S10, Panel A)
. They discerned recognized (vs. unrecognized) and non-satire (vs. satire) statements at a higher rate. We also investigated d ′ results based on statement concordance. When conceptualized as a statement's slant and truth aligning with a participant's party/ideology, participants did better at detecting concordant (vs. discordant) statements. By contrast, when conceptualized as a statement's slant only aligning with a participant's party/ideology, there were no noticeable differences between concordant and discordant statements. A very similar pattern of results emerged for participants' meta-d ′ 
(Fig. S10, Panel B)
. Lastly, participants' metacognitive efficiency for all statements hovered around the theoretically optimal value (i.e., M ratio = 1; 
Fig. S10
, Panel C). M ratio was slightly higher for recognized (vs. unrecognized) statements, and substantially higher for satire (vs.
non-satire) statements. We also investigated M ratio results based on statement concordance. When conceptualized as a statement's slant and truth aligning with a participant's party/ideology, participants showed higher M ratio for concordant (vs. discordant) statements. Similarly, when conceptualized as a statement's slant only aligning with a participant's party/ideology, M ratio was higher for concordant 
(vs. discordant)
 statements.


Individual-Level


Participant Attrition
We investigated individual-level estimates of M dif f (used to test H3.1-H3.4) across different subgroups of participant completion rates; 
Fig. S11
). Overall, no substantial differences emerged among all participants, participants who completed six or more waves, and participants who completed 12 waves. Yet, it is worth noting that M dif f appeared to slightly increase with wave completion rates by tendency.


Statement Characteristics
We investigated individual-level estimates of M dif f (used to test H3.1-H3.4) across different subgroups of statements 
(Fig. S12
). Specifically, we compared different estimates of M dif f within participants based on concordance, recognition, and satire. Here, we conceptualized statement concordance as a combination of (i) a statement's truth and (ii) the alignment of its political slant with a participant's political party. We found the following associations between participants' individual-level estimates of M dif f across different statement subgroups:
• Participants' individual-level estimates of M dif f for concordant and discordant statements were not significantly correlated (rho = −.01, p = .795; BF 10 = .10).
• Participants' individual-level estimates of M dif f for concordant and neutral statements were significantly positively correlated (rho = .23, p < .001;
BF 10 = 3.98 × 10 7 ).
• Participants' individual-level estimates of M dif f for discordant and neutral statements were significantly positively correlated (rho = .09, p = .011; BF 10 = 2.23).
• Participants' individual-level estimates of M dif f for recognized and unrecognized statements were significantly positively correlated (rho = .11, p < .001; BF 10 = 41.9).
• Participants' individual-level estimates of M dif f for statements originating in satire and non-satire were significantly positively correlated (rho = .11, p < .001;
BF 10 = 48.5).   
: To what extent are people aware of whether they are right or wrong when judging the accuracy of political (mis)information? Does that level of insight vary by political leaning and ideology or as a function of political extremism? And what psychological factors and demographics are associated with the accuracy of metacognitive insight?


impaired metacognition found in domains such as climate change (M ratio = 0.47, 95% CI = 0.38-0.64, Fischer et al., 2019; M ratio = 0.17, 95% CI = 0.08-0.32, Thaller & Brudermann, 2020, values extracted from figures) and COVID-19 (M ratio = 0.82, 95% CI = 0.77-0.86; Lisi, 2023).


Vertical solid line at M ratio = 1 denotes theoretically optimal metacognitive efficiency; vertical dashed line denotes the point prediction (i.e., posterior median of the group-level mean); gray bar above the x-axis shows the 95% credible interval of that mean.


False
We applied the statement coding only for participants who identified as liberal (Democrat) or conservative (Republican). For all other participants, no statement concordance score could be assigned.


Figure 2
2
Political Knowledge ( d'; Panel A), Metacognitive Sensitivity (meta-d'; Panel B), and Metacognitive Efficiency ( Mratio; Panel C) as a Function of Political Ideology aligned nor misaligned with participants' ideology) Note. Dots represent the posterior medians of the group-level averages for the parameter (d ′ , meta-d ′ , or M ratio), estimated separately for each of the six ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; horizontal dashed lines denote sensitivity at chance level (d ′ and meta-d ′ ) and theoretically optimal metacognitive efficiency (M ratio); the gray band for M ratio marks the region of practical equivalence (ROPE; i.e., M ratio = 0.9-1.1). Moderates were omitted from this analysis as no statement concordance score could be assigned. See the online article for the color version of this figure.median M ratio = 0.12 (95% CI = 0.05 -0.22), suggesting that 88% of the evidence available for their truth judgments was lost when making metacognitive judgments. This pattern of results held when pooling different degrees of self-reported liberalism and conservatism (H2.1b), as well as when comparing Democrats and Republicans (H2.1a; see Supplement S5 and Figs. S3-S9 for additional analyses; see Supplement S6 and Figs.


Figure 3 Metacognitive
3
Efficiency as a Function of Epistemic Beliefs and Age Dots represent individual-level estimates of metacognitive efficiency (operationalized as a difference score, i.e., M dif f = meta-d ′ − d ′ ) as a function of (A) faith in one's intuition for facts, (B) belief that truth is political, (C) need for evidence, and (D) age. Curves are robust LOESS smooths with 95% confidence intervals (shaded); horizontal dashed lines denote theoretically optimal metacognitive efficiency; horizontal and vertical marginal histograms represent the distributions for epistemic beliefs/age and M dif f , respectively. See the online article for the color version of this figure.


Supplemental
Addressing the question of whether metacognitive insight into political misperceptions is ideologically symmetrical can not only help to better understand the psychology of politics, but is also fundamental to the functioning of democratic societies more generally. Overall, we found that people from both the political right (Republicans and conservatives) and the political left (Democrats and liberals) were well aware of how well they distinguished political truth from falsehood. However, results revealed a striking asymmetry for ideologically discordant statements: Republicans and conservatives-but not Democrats and liberals-exhibited metacognitive blind spots for statements that challenged their ideological commitments, which may fuel broader societal trends such as political polarization.Lorenz-Spreen, P.,Geers, M., Pachur, T., Hertwig, R., Lewandowsky, S., & Herzog, S. M.   (2021). Boosting people's ability to detect microtargeted advertising. ScientificReports, 11  (1), Article 15541. https://doi.org/10.1038/s41598-021-94796-z Lyons, B. A., Montgomery, J. M.,Guess, A. M., Nyhan, B., & Reifler, J. (2021).Overconfidence in news judgments is associated with false news susceptibility.Proceedings of the NationalAcademy of Sciences, 118 (23), Article e2019527118. https://doi.org/10.1073/pnas.2019527118 Macmillan, N. A., & Creelman, C. D. (2004). Detection theory: A user's guide. Psychology Press. https://doi.org/10.4324/9781410611147 Maniscalco, B., & Lau, H. (2012). A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings. Consciousness and Cognition, 21 (1), 422-430. https://doi.org/10.1016/j.concog.2011.09.021 Meyer, A. N. D., Payne, V. L., Meeks, D. W., Rao, R., & Singh, H. (2013). Physicians' diagnostic accuracy, confidence, and resource requests: A vignette study. JAMA Internal Medicine, 173 (21), 1952-1958. https://doi.org/10.1001/jamainternmed.2013.10081 Modirrousta-Galian, A., & Higham, P. A. (2023). Gamified inoculation interventions do not improve discrimination between true and fake news: Reanalyzing existing research with receiver operating characteristic analysis. Journal of Experimental Psychology: General, 152 (9), 2411-2437. https://doi.org/10.1037/xge0001395 Mosleh, M., Pennycook, G., & Rand, D. G. (2022). Field experiments on social media. Current Directions in Psychological Science, 31 (1), 69-75. https://doi.org/10.1177/09637214211054761 Ortoleva, P., & Snowberg, E. (2015). Overconfidence in political behavior. American Economic Review, 105 (2), 504-535. https://doi.org/10.1257/aer.20130921 Overgaard, M. (Ed.). (2015). Behavioural methods in consciousness research. Oxford University Press. Said, N., Fischer, H., & Anders, G. (2021). Contested science: Individuals with higher metacognitive insight into interpretation of evidence are less likely to polarize. Psychonomic Bulletin Review, 29, 668-680. https://doi.org/10.3758/s13423-021-01993-y Salovich, N. A., & Rapp, D. N. (2021). Misinformed and unaware? Metacognition and the influence of inaccurate information. Journal of Experimental Psychology: Learning, Memory, and Cognition, 47 (4), 608-624. https://doi.org/10.1037/xlm0000977 Schulz, L., Rollwage, M., Dolan, R. J., & Fleming, S. M. (2020). Dogmatism manifests in lowered information search under uncertainty. Proceedings of the National Academy of Sciences, 117 (49), 31527-31534. https://doi.org/10.1073/pnas.2009641117 Scott, R. B., Dienes, Z., Barrett, A. B., Bor, D., & Seth, A. K. (2014). Blind insight: Metacognitive discrimination despite chance task performance. Psychological Science, 25 (12), 2199-2208. https://doi.org/10.1177/0956797614553944 Sultan, M., Tump, A. N., Geers, M., Lorenz-Spreen, P., Herzog, S. M., & Kurvers, R. H. J. M. (2022). Time pressure reduces misinformation discrimination ability but does not alter response bias. Scientific Reports, 12 (1), Article 22416. https://doi.org/10.1038/s41598-022-26209-8 Swire, B., Berinsky, A. J., Lewandowsky, S., & Ecker, U. K. H. (2017). Processing political misinformation: Comprehending the Trump phenomenon. Royal Society Open Science, 4 (3), Article 160802. https://doi.org/10.1098/rsos.160802 Tenney, E. R., Spellman, B. A., & MacCoun, R. J. (2008). The benefits of knowing what you know (and what you don't): How calibration affects credibility. Journal of Experimental Social Psychology, 44 (5), 1368-1375. https://doi.org/10.1016/j.jesp.2008.04.006 Thaller, A., & Brudermann, T. (2020). "You know nothing, John Doe" -Judgmental overconfidence in lay climate knowledge. Journal of Environmental Psychology, 69, Article 101427. https://doi.org/10.1016/j.jenvp.2020.101427


Fig. S11 showing that our individual-level results are robust to exploring only participants who completed [i] six or more waves and [ii] all 12 waves.).


Figure S1 Number of Participants Across Waves


Figure S2 Number of Completed Waves Across Participants


preregistered the analyses using Mratio (as opposed to Mdiff). Below, we present results for all of the possible analyses-except from the one reported in the main manuscript-to provide a methodologically robust and comprehensive view of our results on political knowledge, metacognitive sensitivity, and metacognitive efficiency as a function of political party and ideology.d', meta-d', and Mratio across different conceptualizations of political views and statement subgroups Conservatism was associated with markedly lower object-level (d ′ ) and metacognitive (meta-d ′ ) sensitivity (Fig. S3). When coding statements as the alignment of a statement's slant with a participant's ideology, liberals exhibited higher object-level (d ′ ) and metacognitive (meta-d ′ ) sensitivity for incongruent (vs. congruent) statements. Conversely, conservatives demonstrated higher metacognitive sensitivity (meta-d ′ ) for congruent statements. For metacognitive efficiency (M ratio), conservatives had a harder time introspecting for inconruent (vs. congruent) statements (i.e., lower M ratio), thus providing support for the pattern of results reported in the main manuscript.Participants on the political left (Democrats and liberals) showed higher object-level (d ′ ) and metacognitive (meta-d ′ ) sensitivity than those on the political right (Republicans and conservatives;Fig. S4). When coding statements as the alignment of a statement's slant, a statment's truth, and a participant's political views, we again found a strong concordance effect: Participants from both left and right showed significantly higher object-level (d ′ ) and metacognitive (meta-d ′ ) sensitivity for concordant(vs. discordant)    statements. Moreover, participants across the politial and ideological spectrum showed metacognitive efficiency (M ratio) close to the theoretical optimum. Yet again, when inspecting different statement subgroups, we observed a striking concordance effect:Participants from the political right-but not left-showed significantly lower metacognitive efficiency (M ratio) for discordant (vs. concordant) statements.


Figure S3 Political
S3
Knowledge ( d'; Panel A), Metacognitive Sensitivity (meta-d'; Panel B), and Metacognitive Efficiency ( Mratio; Panel C) as a Function of Political Ideology for aligned nor misaligned with participants' ideology) Note. Dots represent the posterior medians of the group-level averages for the parameter (d ′ , meta-d ′ , or M ratio), estimated separately for each of the six ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; horizontal dashed lines denote sensitivity at chance level (d ′ and meta-d ′ ) and


FNote.
Dots represent the posterior medians of the group-level averages for the parameter (d ′ , meta-d ′ , or M ratio), estimated separately for each of the party/ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; horizontal dashed lines denote sensitivity at chance level (d ′ and meta-d ′ ) and theoretically optimal metacognitive efficiency (M ratio); the gray band for M ratio marks the region of practical equivalence (ROPE; i.e., M ratio = 0.9-1.1).


Figure S5 PoliticalF
S5
Knowledge ( d'; Panels A and B), Metacognitive Sensitivity(meta-d'; Panels C   and D), and Metacognitive Efficiency ( Mratio; Panels E and F)  as a Function of Political Party and Ideology for Different Levels of Statement CongruencyNote. Dots represent the posterior medians of the group-level averages for the parameter (d ′ , meta-d ′ , or M ratio), estimated separately for each of the party/ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; horizontal dashed lines denote sensitivity at chance level (d ′ and meta-d ′ ) and theoretically optimal metacognitive efficiency (M ratio); the gray band for M ratio marks the region of practical equivalence (ROPE; i.e., M ratio = 0.9-1.1).


misaligned with participants' ideology or false statements aligned with participants' ideology) Neutral (statements neither aligned nor misaligned with participants' ideology)Note. Dots represent the posterior medians of the group-level averages for the parameter (M dif f ), estimated separately for each of the six ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; the horizontal dashed line denotes theoretically optimal metacognitive efficiency.


aligned nor misaligned with participants' ideology)Note. Dots represent the posterior medians of the group-level averages for the parameter (M dif f ), estimated separately for each of the six ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; the horizontal dashed line denotes theoretically optimal metacognitive efficiency.


Figure S8 Metacognitive
S8
Efficiency ( Mdiff) as a Function of Political Party (Panel A) and Ideology (Panel B) for Different Levels of Statement Concordance


BNote.
Dots represent the posterior medians of the group-level averages for the parameter (M dif f ), estimated separately for each of the party/ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; horizontal dashed lines denote theoretically optimal metacognitive efficiency.


Figure S9 Metacognitive
S9
Efficiency ( Mdiff) as a Function of Political Party (Panel A) and Ideology (Panel B) for Different Levels of Statement Congruency Dots represent the posterior medians of the group-level averages for the parameter (M dif f ), estimated separately for each of the party/ideological subgroups and for different sets of statements. Error bars represent the 95% credible interval of the respective posterior distribution; horizontal dashed lines denote theoretically optimal metacognitive efficiency.


Figure S10 Political
S10
Knowledge ( d'; Panel A), Metacognitive Sensitivity (meta-d'; Panel B), and Metacognitive Efficiency ( Mratio; Panel C) across Different Subgroups of Statements o g n i z e d u n r e c o g n i z e d s a t i r e n o n − s a t i r e c o n c o r d a n t ( p a r t y ) d i s c o r d a n t ( p a r t y ) n e u t r a l ( p a r t y ) c o n g r u e n t ( p a r t y ) i n c o n g r u e n t ( p a r t y ) c o n c o r d a n t ( i d e o l o g y ) d i s c o r d a n t ( i d e o l o g y ) n e u t r a l ( i d e o l o g y ) c o n g r u e n t ( i d e o l o g y ) i n c o n g r u e n t ( i d e o l o g y ) c o r d a n t ( p a r t y ) d i s c o r d a n t ( p a r t y ) n e u t r a l ( p a r t y ) c o n g r u e n t ( p a r t y ) i n c o n g r u e n t ( p a r t y ) c o n c o r d a n t ( i d e o l o g y ) d i s c o r d a n t ( i d e o l o g y ) n e u t r a l ( i d e o l o g y ) c o n g r u e n t ( i d e o l o g y ) i n c o n g r u e n t ( i d e o l o g y ) c o r d a n t ( p a r t y ) d i s c o r d a n t ( p a r t y ) n e u t r a l ( p a r t y ) c o n g r u e n t ( p a r t y ) i n c o n g r u e n t ( p a r t y ) c o n c o r d a n t ( i d e o l o g y ) d i s c o r d a n t ( i d e o l o g y ) n e u t r a l ( i d e o l o g y ) c o n g r u e n t ( i d e o l o g y ) i n c o n g r u e n t ( i d e o l o g y ) Mratio C Note. Dots represent the posterior medians of the group-level averages for the parameter (d ′ , meta-d ′ , or M ratio), estimated separately for each of the statement subgroups. Error bars represent the 95% credible interval of the respective posterior distribution; horizontal dashed lines denote sensitivity at chance level (d ′ and meta-d ′ ) and theoretically optimal metacognitiveefficiency (M ratio). The gray band for M ratio marks the region of practical equivalence (ROPE; i.e., M ratio = 0.9-1.1).


Figure S11 Mdiff
S11
Estimated at the Individual Level across Different Subgroups of The horizontal dashed line at M dif f = 0 denotes theoretically optimal metacognitive efficiency.


Figure S12 Mdiff
S12
Estimated at the Individual Level across Different Subgroups of Statements Mdiff for satire statements Mdiff for non−satire statements E Note. Curves are robust LOESS smooths with 95% confidence intervals (shaded). The dashed identity lines denote perfect correlation for M dif f across different statement subgroups.


Table 1
1
Concordance Coding
Statement congruency
True
(statement's slant × participant's political views)
(statement truth)


Accurate metacognition has an important belief-correcting function and as such it can help to afford the common ground of facts that is vital for a healthy democratic discourse. Importantly, interventions at the object level, such as pre-or debunking, may not suffice to improve conservatives' metacognition
(Kozyreva et al., 2023)
. Instead, targeted metacognitive interventions may be needed, such as encouraging conservatives to reassess their truth judgments when confronted with uncomfortable information that challenges their
). If people are unaware that they are wrong, they may not seek further information, thereby remaining misinformed and believing that the other side is wrong.ideological commitments (Lorenz-Spreen et al., 2021; Salovich & Rapp, 2021).


Both true and false statements that are neither pro-ingroup nor pro-outgroup. These are neutral statements for a politically-motivated person in the sense that an information-processing bias that puts more weight on information consistent with one's political views will neither improve nor impair performance for such statements, as the bias does not shift the overall weight put on information pointing either to the correct or the incorrect answer. In short, upweighting information that points to what one wants to be true ends up not affecting accuracy.
to be
true ends up improving accuracy.
• Discordant statements: Pro-ingroup statements that are false and pro-outgroup
statements that are true. These are discordant statements for a politically motivated
person in the sense that an information-processing bias that puts more weight on
information consistent with one's political views ends up putting more weight on
). To be able to study how political views bias information processing (i.e., facilitate or impede discrimination ability or d ′ in SDT terms; see also Derreumaux et al., 2023), we additionally operationalized a statement's concordance as the alignment of three factors: (i) a statement's slant, (ii) a statement's truth, and (iii) a participant's political views. This conceptualization led to three statement subgroups: • Concordant statements: Pro-ingroup statements that are true and pro-outgroup statements that are false. These are concordant statements for a politically motivated person in the sense that an information-processing bias that puts more weight on information consistent with one's political views ends up putting more weight on information that points to the correct answer, thus improving performance for such statements. In short, upweighting information that points to what one wantsinformation that points to the incorrect answer, thus impairing performance for such statements. In short, upweighting information that points to what one wants to be true ends up decreasing accuracy.• Neutral statements:


Table S2
S2
Sample Demographics
No.
Percent
N
1,191
100
Age
18-29
175
14.7
30-44
285
23.9
45-59
295
24.8
60+
436
36.6
Gender
Female
514
43.2
Male
677
56.8
Education
No high school
45
3.8
High school graduate
354
29.7
Some college
287
24.1
2-year college degree
118
9.9
4-year college degree
244
20.5
Post-grad
143
12.0
Political party affiliation
Democrat
404
33.9
Republican
322
27.0
Independent
336
28.2
Other
52
4.4
Not sure
77
6.5
Political ideology
Very liberal
101
8.5
Liberal
155
13.0
Somewhat liberal
137
11.5
Moderate
319
26.8
Somewhat conservative
150
12.6
Conservative
206
17.3
Very conservative
123
10.3


There is evidence that climate change is politicized across countries including the U.S.
(Kennedy, 2020)
 and Germany
(Fischer & Said, 2021;
Kinkartz, 2019)
, and that COVID-19 is politicized in the U.S.(Hart   


The only meaningful differences, beyond using 100% (instead of 20%) of the data, are that we (i)computed Bayes factors to test H3.1-H3.4 and (ii) decided against removing meta-d ′ outliers, because our


For details on the Markov chain Monte Carlo setup, see Supplement S4.


The model can produce NAs for M ratio, for instance, if d ′ = 0 or if meta-d ′ > 0 and d ′ < 0, and NAs for M dif f if no value for d ′ or meta-d ′ can be calculated.


Note that we obtained qualitatively similar-albeit less pronounced-results for reduced metacognitive efficiency among conservatives judging discordant statements when we employed the two-way congruency coding used byDobbs et al. (2023, i.e., considering only a statement's slant and a participant's political views, irrespective of the truth of the statement, seeFigs. S3 and S5).














Social media and fake news in the 2016 election




H
Allcott






M
Gentzkow








Journal of Economic Perspectives




31


2


















10.1257/jep.31.2.211














Donald Trump and the lie




K
Arceneaux






R
Truex




10.1017/s1537592722000901








Perspectives on Politics




21


3
















Perseverance of bias as a function of debriefing conditions and subjects' confidence




E
Y
Babad






A
Ariav






I
Rosen






G
Salomon








Social Behaviour




2


3
















False equivalence: Are liberals and conservatives in the United States equally biased?




J
Baron






J
T
Jost




10.1177/1745691618788876








Perspectives on Psychological Science




14


2
















A signal detection approach to understanding the identification of fake news




C
Batailler






S
M
Brannon






P
E
Teas






B
Gawronski




10.1177/1745691620986135








Perspectives on Psychological Science




17


1
















Overconfidence as a cause of diagnostic error in medicine




E
S
Berner






M
L
Graber








The American Journal of Medicine




121


5


















10.1016/j.amjmed.2008.01.001














Aging in an era of fake news




N
M
Brashier






D
L
Schacter




10.1177/0963721420915872








Current Directions in Psychological Science




29


3
















Distinct brain mechanisms for conscious versus subliminal error detection




L
Charles






F
Van Opstal






S
Marti






S
Dehaene








NeuroImage




73


















10.1016/j.neuroimage.2013.01.054














Truth and bias, left and right: Testing ideological asymmetries with a realistic news supply




B
Clemm Von Hohenberg




10.1093/poq/nfad013








Public Opinion Quarterly




87


2
















Inoculation theory of resistance to influence at maturity: Recent progress in theory development and application and suggestions for future research




J
A
Compton






M
Pfau




10.1080/23808985.2005.11679045








Annals of the International Communication Association




29


1
















Contributions of age and clinical depression to metacognitive performance




C
Culot






T
Lauwers






C
Fantini-Hauwel






Y
Madani






D
Schrijvers






M
Morrens






W
Gevers








Consciousness and Cognition




107
















10.1016/j.concog.2022.103458














Computational underpinnings of partisan information processing biases and associations with depth of cognitive reasoning




Y
Derreumaux






K
Shamsian






B
L
Hughes








Cognition




230
















10.1016/j.cognition.2022.105304














The role of representative design in an ecological approach to cognition




M
K
Dhami






R
Hertwig






U
Hoffrage








Psychological Bulletin




130


6


















10.1037/0033-2909.130.6.959














At least bias is bipartisan: A meta-analytic comparison of partisan bias in liberals and conservatives




P
H
Ditto






B
S
Liu






C
J
Clark






S
P
Wojcik






E
E
Chen






R
H
Grady






J
B
Celniker






J
F
Zinger




10.1177/1745691617746796








Perspectives on Psychological Science




14


2
















Democrats are better than Republicans at discerning true and false news but do not have better metacognitive awareness




M
Dobbs






J
Degutis






J
Morales






K
Joseph






B
Swire-Thompson




10.1038/s44271-023-00040-x








Communications Psychology




46


1








Article








The psychological drivers of misinformation belief and its resistance to correction




U
K
Ecker






S
Lewandowsky






J
Cook






P
Schmid






L
K
Fazio






N
Brashier






P
Kendeou






E
K
Vraga






M
A
Amazeen




10.1038/s44159-021-00006-y








Nature Reviews Psychology




1
















The accuracy of German citizens' confidence in their climate change knowledge




H
Fischer






D
Amelung






N
Said








Nature Climate Change




9


10


















10.1038/s41558-019-0563-0


















H
Fischer






S
M
Herzog






F
Rebitschek






M
Ketzer






N
Fleischhut


















Metacognitive and cultural cognition accounts jointly explain believing, and spreading of contested information


10.31234/osf.io/2n75x














Metacognition, public health compliance, and vaccination willingness




H
Fischer






M
Huff






G
Anders






N
Said








Proceedings of the National Academy of Sciences




120


43


2105425120














Importance of domain-specific metacognition for explaining beliefs about politicized science: The case of climate change. Cognition, 208, Article 104545




H
Fischer






N
Said




10.1016/j.cognition.2020.104545


















Metacognition and cognitive monitoring: A new area of cognitive-developmental inquiry




J
H
Flavell








American Psychologist




34


10


















10.1037/0003-066X.34.10.906














HMeta-d: Hierarchical Bayesian estimation of metacognitive efficiency from confidence ratings




S
M
Fleming




10.1093/nc/nix007








Article nix007






2017












Know thyself: The new science of self-awareness




S
M
Fleming








John Murray












Self-evaluation of decision-making: A general Bayesian framework for metacognitive computation




S
M
Fleming






N
D
Daw




10.1037/rev0000045








Psychological Review




124


1
















How to measure metacognition




S
M
Fleming






H
C
Lau




10.3389/fnhum.2014.00443








Frontiers in Human Neuroscience




8














Metacognition and reasoning




L
Fletcher






P
Carruthers








Philosophical Transactions of the Royal Society B: Biological Sciences




367
















Type 2 tasks in the theory of signal detectability: Discrimination between correct and incorrect decisions




S
J
Galvin






J
V
Podd






V
Drga






J
Whitmore








Psychonomic Bulletin & Review




10


4


















10.3758/BF03196546














Conservatives' susceptibility to political misperceptions




R
K
Garrett






R
M
Bond








Science Advances




7


23








Article eabf1234










10.1126/sciadv.abf1234














Epistemic beliefs' role in promoting misperceptions and conspiracist ideation




R
K
Garrett






B
E
Weeks








PLoS ONE




12


9








Article e0184733










10.1371/journal.pone.0184733














Truth sensitivity and partisan bias in responses to misinformation




B
Gawronski






N
L
Ng






D
M
Luke




10.1037/xge0001381








Journal of Experimental Psychology: General




152


8
















Linking lab and field research




M
Geers




10.1038/s44159-023-00215-7








Nature Reviews Psychology




2


458














The Online Misinformation Engagement Framework




M
Geers






B
Swire-Thompson






P
Lorenz-Spreen






S
M
Herzog






A
Kozyreva






R
Hertwig








Current Opinion in Psychology




55
















10.1016/j.copsyc.2023.101739














Probabilistic mental models: A Brunswikian theory of confidence




G
Gigerenzer






U
Hoffrage






H
Kleinbölting








Psychological Review




98


4


















10.1037/0033-295X.98.4.506














Fake news on Twitter during the 2016 U.S. presidential election




N
Grinberg






K
Joseph






L
Friedland






B
Swire-Thompson






D
Lazer




10.1126/science.aau2706








Science




363


6425
















Less than you think: Prevalence and predictors of fake news dissemination on Facebook




A
M
Guess






J
Nagler






J
Tucker




10.1126/sciadv.aau4586








Article eaau4586






5












Exposure to untrustworthy websites in the 2016 US election




A
M
Guess






B
Nyhan






J
Reifler








Nature Human Behaviour




4


5


















10.1038/s41562-020-0833-x














Politicization and polarization in COVID-19 news coverage




P
S
Hart






S
Chinn






S
Soroka








Science Communication




42


5


















10.1177/1075547020950














The contribution of judgment scale to the unskilled-and-unaware phenomenon: How evaluating others can exaggerate over-(and under-) confidence




M
K
Hartwig






J
Dunlosky








Memory & Cognition




42


















10.3758/s13421-013-0351-4














Ideological asymmetries and the essence of political psychology




J
T
Jost




10.1111/pops.12407








Political Psychology




38


2
















Cognitive-motivational mechanisms of political polarization in social-communicative contexts




J
T
Jost






D
S
Baldassarri






J
N
Druckman




10.1038/s44159-022-00093-5








Nature Reviews Psychology




1


10
















Outliers may not be automatically removed




J
D
Karch




10.1037/xge0001357








Journal of Experimental Psychology: General




152


6


1735














U.S. concern about climate change is rising, but mainly among Democrats




B
Kennedy










Pew Research Center
















Viel mehr Klimaschutz gefordert




S
Kinkartz












Much more climate action needed












Deutsche
Welle














Toolbox of interventions against online misinformation




A
Kozyreva






P
Lorenz-Spreen






S
M
Herzog






U
K H
Ecker






S
Lewandowsky






R
Hertwig




10.31234/osf.io/x8ejt


















Unskilled and unaware of it: How difficulties in recognizing one's own incompetence lead to inflated self-assessments




J
Kruger






D
Dunning








Journal of Personality and Social Psychology




77


6


















10.1037//0022-3514.77.6.1121














Rejecting or accepting parameter values in Bayesian estimation




J
K
Kruschke








Advances in Methods and Practices in Psychological Science




1


2


















10.1177/2515245918771304














Worldview-motivated rejection of science and the norms of science




S
Lewandowsky






K
Oberauer








Cognition




104820


215
















10.1016/j.cognition.2021.104820


















S
Lewandowsky






L
Smillie






D
Garcia






R
Hertwig






J
Weatherall






S
Egidy






R
E
Robertson






C
O'connor






A
Kozyreva






P
Lorenz-Spreen






Blaschke, Y., &












Technology and democracy: Understanding the influence of online technologies on political behaviour and decision-making. Publications Office of the European Union




M
Leiser




https://data.europa.eu/doi/10.2760/709177


















The value of not knowing: Partisan cue-taking and belief updating of the uninformed, the ambiguous, and the misinformed




J
Li






M
W
Wagner




10.1093/joc/jqaa022








Journal of Communication




70


5
















Navigating the COVID-19 infodemic: The influence of metacognitive efficiency on health behaviours and policy attitudes




M
Lisi




10.1098/rsos.230417








Article 230417






10












The effect of self-confidence and anxiety on information seeking in consumer risk reduction




W
B
Locander






P
W
Hermann








Journal of Marketing Research
















Effects of age on metacognitive efficiency




E
C
Palmer






A
S
David






S
M
Fleming








Consciousness and Cognition




28


















10.1016/j.concog.2014.06.007














How metacognition can promote academic learning and instruction




S
G
Paris






P
Winograd








Dimensions of Thinking and Cognitive Instruction


B. F. Jones & L. Idol












North Central Regional Educational Laboratory












The psychology of fake news




G
Pennycook






D
G
Rand




10.1016/j.tics.2021.02.007








Trends in Cognitive Sciences




25


5
















Truth, communication, and democracy




D
Porpora






S
Sekalala








International Journal of Communication




13
















Intuitive evaluation of likelihood judgment producers: Evidence for a confidence heuristic




P
C
Price






E
R
Stone




10.1002/bdm.460








Journal of Behavioral Decision Making




17


1
















R: A language and environment for statistical computing. Foundation for Statistical Computing




R Core Team








Vienna, Austria












Processing a display even after you make a response to it. How perceptual errors can be corrected




P
Rabbitt






S
Vyas




10.1080/14640748108400790








The Quarterly Journal of Experimental Psychology




33


3
















How experimental procedures influence estimates of metacognitive ability




D
Rahnev






S
M
Fleming




10.1093/nc/niz009








Article niz009






2019












Confidence as a metacognitive contributor to and consequence of misinformation experiences. Current Opinion in Psychology, 55, Article 101735




D
N
Rapp






M
M
Withall




10.1016/j.copsyc.2023.101735


















Accuracy and social motivations shape judgements of (mis)information




S
Rathje






J
Roozenbeek






J
J
Van Bavel






S
Van Der Linden








Nature Human Behaviour
















Visibility is not equivalent to confidence in a low contrast orientation discrimination task




M
Rausch






M
Zehetleitner




10.3389/fpsyg.2016.00591








Frontiers in Psychology




7














Evaluating false positive rates of standard and hierarchical measures of metacognitive accuracy




M
Rausch






M
Zehetleitner




10.31234/osf.io/593av


















Metacognitive failure as a feature of those holding radical beliefs




M
Rollwage






R
J
Dolan






S
M
Fleming








Current Biology




28


24


















10.1016/j.cub.2018.10.053














Susceptibility to misinformation is consistent across question framings and response modes and better explained by myside bias and partisanship than analytical thinking




J
Roozenbeek






R
Maertens






S
M
Herzog






M
Geers






R
Kurvers






M
Sultan






S
Van Der Linden




10.1017/S1930297500003570








Judgment and Decision Making




17


3
















Forming global estimates of self-performance from local confidence




M
Rouault






P
Dayan






S
M
Fleming




10.1038/s41467-019-09075-3








Nature Communications




10














When truthiness trumps truth: Epistemic beliefs predict the accurate discernment of fake news




J
P
Rudloff






M
Appel




10.1037/mac0000070








Journal of Applied Research in Memory and Cognition




12


3
















The confident conservative: Ideological differences in judgment and decision-making confidence




B
C
Ruisch






C
Stern




10.1037/xge0000898








Journal of Experimental Psychology: General




150


3
















Cheap talk and credibility: The consequences of confidence and accuracy on advisor credibility and persuasiveness




S
Sah






D
A
Moore






R
J
Maccoun








Organizational Behavior and Human Decision Processes




121


2
















Intuition, reason, and metacognition




V
A
Thompson






J
A P
Turner






G
Pennycook








Cognitive Psychology




63


3


















10.1016/j.cogpsych.2011.06.001














More polarized but more independent: Political party identification and ideological self-categorization among U.S. adults, college students, and late adolescents




J
M
Twenge






N
Honeycutt






R
Prislin






R
A
Sherman








Personality and Social Psychology Bulletin




42


10


















10.1177/0146167216660058














The partisan brain: An identity-based model of political belief




J
J
Van Bavel






A
Pereira








Trends in Cognitive Sciences




22


3


















10.1016/j.tics.2018.01.004














Preregistration of secondary data analysis: A template and tutorial




O
R
Van Den Akker






S
Weston






L
Campbell






B
Chopik






R
Damian






P
Davis-Kean






A
Hall






J
Kosie






E
Kruse






J
Olsen






S
Ritchie






K
D
Valentine






A
Veer






M
Bakker




10.15626/MP.2020.2625


Article MP.2020.2625








Meta-Psychology




5














The paranoid style in American politics revisited: An ideological asymmetry in conspiratorial thinking




S
Van Der Linden






C
Panagopoulos






F
Azevedo






J
T
Jost




10.1111/pops.12681








Political Psychology




42


1
















Tracking all of President Trump's false or misleading claims






Washington Post Fact Checker










The Washington Post








A signal detection approach to understanding the identification of fake news




C
Batailler






S
M
Brannon






P
E
Teas






B
Gawronski




10.1177/1745691620986135








Perspectives on Psychological Science




17


1
















Distinct brain mechanisms for conscious versus subliminal error detection




L
Charles






F
Van Opstal






S
Marti






S
Dehaene








NeuroImage




73


















10.1016/j.neuroimage.2013.01.054














Computational underpinnings of partisan information processing biases and associations with depth of cognitive reasoning




Y
Derreumaux






K
Shamsian






B
L
Hughes








Cognition




230
















10.1016/j.cognition.2022.105304














The accuracy of German citizens' confidence in their climate change knowledge




H
Fischer






D
Amelung






N
Said








Nature Climate Change




9


10


















10.1038/s41558-019-0563-0














HMeta-d: Hierarchical Bayesian estimation of metacognitive efficiency from confidence ratings




S
M
Fleming




10.1093/nc/nix007








Article nix007






2017












Self-evaluation of decision-making: A general Bayesian framework for metacognitive computation




S
M
Fleming






N
D
Daw




10.1037/rev0000045








Psychological Review




124


1
















How to measure metacognition




S
M
Fleming






H
C
Lau




10.3389/fnhum.2014.00443








Frontiers in Human Neuroscience




8














Conservatives' susceptibility to political misperceptions




R
K
Garrett






R
M
Bond








Science Advances




7


23








Article eabf1234










10.1126/sciadv.abf1234














Bayes factors




R
E
Kass






A
E
Raftery




10.1080/01621459.1995.10476572








Journal of the American Statistical Association




90


430
















Rejecting or accepting parameter values in Bayesian estimation




J
K
Kruschke








Advances in Methods and Practices in Psychological Science




1


2


















10.1177/2515245918771304














Navigating the COVID-19 infodemic: The influence of metacognitive efficiency on health behaviours and policy attitudes




M
Lisi




10.1098/rsos.230417








Article 230417






10












Detection theory: A user's guide




N
A
Macmillan






C
D
Creelman




10.4324/9781410611147








Psychology Press












Effects of age on metacognitive efficiency




E
C
Palmer






A
S
David






S
M
Fleming








Consciousness and Cognition




28


















10.1016/j.concog.2014.06.007














R: A language and environment for statistical computing. Foundation for Statistical Computing




R Core Team








Vienna, Austria












Processing a display even after you make a response to it. How perceptual errors can be corrected




P
Rabbitt






S
Vyas




10.1080/14640748108400790








The Quarterly Journal of Experimental Psychology




33


3
















Visibility is not equivalent to confidence in a low contrast orientation discrimination task




M
Rausch






M
Zehetleitner




10.3389/fpsyg.2016.00591








Frontiers in Psychology




7














An artificial intelligence perspective: How knowledge and confidence shape risk and benefit perception




N
Said






A
E
Potinteu






I
Brich






J
Buder






H
Schumm






M
Huff




10.1016/j.chb.2023.107855








Computers in Human Behavior
















Blind insight: Metacognitive discrimination despite chance task performance




R
B
Scott






Z
Dienes






A
B
Barrett






D
Bor






A
K
Seth




10.1177/0956797614553944








Psychological Science




25


12
















Sound inference in complicated research: A multi-strategy approach




S
Srivastava




10.31234/osf.io/bwr48


















Preregistration of secondary data analysis: A template and tutorial




O
R
Van Den Akker






S
Weston






L
Campbell






B
Chopik






R
Damian






P
Davis-Kean






A
Hall






J
Kosie






E
Kruse






J
Olsen






S
Ritchie






K
D
Valentine






A
Veer






M
Bakker




10.15626/MP.2020.2625


Article MP.2020.2625








Meta-Psychology




5














Examining the robustness of the relationship between metacognitive efficiency and metacognitive bias




K
Xue






M
Shekhar






D
Rahnev




10.1016/j.concog.2021.103196








Consciousness and Cognition




95


103196















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]