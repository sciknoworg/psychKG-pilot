You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



human stopping decisions in sequential decision making tasks based on a linear threshold heuristic. The first two studies demonstrate that the linear threshold model accounts better for sequential decision making than existing models. Moreover, we show that the model accurately predicts participants' search behavior in different environments. In the third study, we confirm that the model generalizes to a real-world problem, thus providing an important step towards understanding human sequential decision making.
Decisions that arise in everyday life often have to be made when options are presented sequentially. For example, searching for a parking spot, deciding when to take a vacation day, or finding a partner, all require that the decision maker accepts or rejects an option without knowing if future options will be more attractive. Decisions in such problems involve a trade-off between accepting a possibly suboptimal option prematurely and rejecting the current offer out of false hopes for better options in the future.
Despite the importance of such decisions, relatively little work has been made toward characterizing the process by which humans decide to stop searching in natural settings of this task. Earlier research has focused on a simplified version of optimal stopping problems, the so-called secretary problem, where only the rank of the option relative to those already seen is shown 
(Bearden et al., 2006;
Seale & Rapoport, 1997
, 2000
 and only the overall best alternative is rewarded. In the secretary problem, the optimal strategy is to ascertain the maximum of the first 37% options and choose the next option that exceeds this threshold 
(Gilbert & Mosteller, 1966)
. Empirical studies suggest that in general people follow a similar strategy but usually set the cut-off (i.e., from which point on they will accept an option that exceeds the previous options) earlier than the 37% prescribed by the optimal solution 
(Kahan et al., 1967;
Seale & Rapoport, 1997)
.
Some studies have investigated tasks closer to real sequential choice problems by presenting the actual value of the option to the decision makers 
(Guan & Lee, 2018;
Guan et al., 2015;
Kogut, 1990;
Lee, 2006;
Shu, 2008;
von Helversen & Mata, 2012)
. In this version, the optimal is based on calculating the probability of winning on the later positions. From this probability, a threshold is calculated for each option in the sequence as described by 
Gilbert and Mosteller (Gilbert & Mosteller, 1966, Section 3
).
Lee 
(Lee, 2006
) estimated a family of threshold-based models and showed that most participants decreased their choice thresholds as sequences progress. Although people are overall quite heterogeneous in their search behavior, they tend to cluster around the optimal solution 
(Guan & Lee, 2018;
Guan et al., 2015)
. Importantly, these studies still kept the restriction that only the best alternative is rewarded-a payoff function that does not correspond well with everyday experiences. Humans do find a mate, an apartment to live, or a ticket to fly to their vacation destination, and thus receive some payoff, even if that may not be the highest possible payoff.
In the present research, we propose a model for optimal stopping decisions using payoffs that are based on the actual values. In this variant of the search problem, the optimal decision thresholds are calculated based on the expected reward of the remaining options ( 
(Gilbert & Mosteller, 1966, Section 5b)
 and SI Text A). This leads to a decision threshold that changes notably nonlinear over the sequence. In contrast, we propose that people rely on a mental shortcut and adapt their thresholds linearly over the sequence. We show that a model with this linearity assumption accurately captures when people stop search and accept an option, even in a real-world setting. Furthermore, this model allows us to predict under which conditions people search more or less than the optimal model, making it a useful tool to understand human sequential decision making.
We first sketch a family of cognitive models for describing behavior in optimal stopping problems. We then present results from three behavioral experiments that provide evidence for the validity of the linear model in a laboratory setting as well as in a real-world scenario.


Computational models
We explain the computational models based on a typical optimal stopping problem that we also used in our first two experiments. The decision maker (here a customer) is planing a vacation and decides to buy the plane ticket online. Ticket prices vary randomly from day to day and the customer wants to find the cheapest ticket. The customer checks the ticket price every day and decides if she wants to accept or reject the ticket, without having the option to go back in time to a previously rejected offer.
Search time is limited by her vacation schedule (i.e., 10 decisions per trial) and, once accepted, the search ends.
More formally, we consider a decision maker who encounters a sequence of tickets with values denoted by x 1 , . . . , x 10 and she wants to find the minimum value in the sequence. If the decision maker accepts ticket x i , the sequence terminates and she has to pay x i ; otherwise, she continues to the next ticket. When the last ticket is reached, it must be accepted.
All models assume that the decision maker relies on a probabilistic threshold to make the decision to accept or reject a ticket-i.e., ticket x i on position i is compared to a position dependent threshold t i . This comparison yields an acceptance probability θ i based on a sigmoid choice function with sensitivity parameter β and
θ i = 1 1 + exp{β(x i − t i )} .
(1)
Small values of β produce more stochasticity in decisions, whereas the policy approaches determinism when β → ∞.
We examine the setting of thresholds by comparing the performance of four different models. • The Linear Threshold Model (LTM) postulates that the thresholds are constrained by a linear relation to each other and therefore are completely defined by the first threshold t 0 and the linear increase δ as the sequence progresses:
t i+1 = t i + δ • i,
(2)
This model entails three free parameters, the first threshold t 0 , the increase of the threshold δ and the choice sensitivity β.
• The The Biased Optimal Model (BOM) is based on the Bias-from-Optimal threshold model proposed by 
Guan et al. (Guan et al., 2015)
, assuming that humans are using thresholds that deviate systematically from the optimal thresholds. The optimal thresholds t * i for each position i are derived by determining the expected reward of the remaining options (derivation in 
(Gilbert & Mosteller, 1966, Section 5b)
 and in SI Text A). The model entails a systematic bias parameter γ that reflects the divergence of the human threshold from the optimal one. Additionally, the thresholds depend on a parameter α that determines how much their bias increases or decreases as the sequence progresses.
t i = t * i + γ + α • i,
(3)
When γ and α are set to 0, the thresholds represent the optimal thresholds that lead to best performance. This model is therefore defined by three free parameters, γ, α and the choice sensitivity β.
• The Cut-off Model (CoM) is inspired by the optimal decision rule for the rank information version of the secretary problem where the distribution of the prices is unknown. It assumes that the DM has a fixed cut-off value k that determines how long she explores in the beginning of the sequence. The highest value seen in that initial sample of k tickets is then set as her threshold, and the first value that exceeds this threshold in the remainder of the sequence is chosen. This model has two free parameters, the cut-off value k and the sensitivity parameter β.
Models were implemented in a hierarchical-Bayesian statistical framework using JAGS 
(Lee & Wagenmakers, 2014;
Plummer et al., 2003)
. In a Bayesian framework, information regarding model parameters is represented by probability distributions.
The data is used to update prior distributions resulting in posterior distributions, which were used for inference. A hierarchical implementation allows us to fit data on the individual trial-level, while simultaneously taking into account information shared across participants via group-level distributions. Results reported below are based on the group-level posterior distributions, unless noted otherwise.


Experiment 1
We asked 129 participants to solve a computer-based optimal stopping problem following the ticket-shopping task described above. Tickets were normally distributed with a mean value of $180 and a standard deviation of $20. In the first phase, subjects learned the distribution using a graphical method proposed by 
(Goldstein & Rothschild, 2014
) (Material and Methods). 
Fig. S1A
 shows that this procedure was successful in ensuring participants learned the distribution.
In the second phase, participants performed 200 trials of the ticket-shopping task.
In each trial, participants searched through a sequence of ten ticket prices. For each ticket, they could decide to accept or reject it at their own pace. Participants were aware that they could see up to 10 tickets in each trial, and they were always informed about the actual position and the number of remaining tickets (see 
Fig. S2E
 for a screen shot). It was not possible to go back to an earlier option after it was initially declined. If they reached the last ticket (10th) they were forced to choose this ticket.
When participants accepted the ticket, they received feedback about how much they could have saved if they had chosen the best ticket in the sequence. Performance was incentivized based on the value of the chosen ticket (Material and Methods).


Behavioral results
Subjects earned on average 17.1 points (SD: 4.2) in each trial (maximum points = 20), which represents a 6% loss on optimal earnings. Participants' marginal accept probabilities steadily increased as the sequence progressed ( 
Fig. 1A
, black line), but 
0.0 0.1 0.2 0.3 0.4 0.5 1 2 3 4 5 6 7 8 9 Position P(Accept) Data Optimal A q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q Q1
C q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q Q1 Q2 Q3 Q4 Q5
1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 0.00 Participants' probability to accept. Each line represents ticket prices ranging from the first quantile to the fifth quantile. Q1: Tickets in first quantile, Q2: Tickets ranging from the first to the second quantile etc. The size of circles correspond to the number of data points on each position. (C) Estimated thresholds for the ITM with 9 free threshold parameters (solid blue line), the LTM with 2 free threshold parameters (dashed red line) and the BOM with 2 free threshold parameters (dash-dotted yellow line) (D) Posterior predictive mean and 95% HDI of the LTM (dashed red line) and the BOM (dash-dotted yellow line) for Q1 to Q5, as indicated in (B). Data: solid black lines differed systematically from the optimal agent's accept probability 
(Fig. 1A
 ,yellow line). On the second-to-last (9th) position, participants accepted the ticket only with a 28%, 95%-CI [26%, 29%], probability, whereas following the optimal policy would result in a significantly higher acceptance rate of 50% (χ 2 (1) = 801, p < .0001).
Overall, subjects stopped earlier than optimal. The average position at which a ticket was accepted was 4.7 (SD: 2.9), whereas an optimal agent would have stopped at an average stopping position of 5.2 (SD: 2.8). However, a closer look at 
Fig. 1A
 reveals that whether subjects accept too early or too late depends on the position: on earlier positions they accept options although they should continue to search, whereas, if they get to position 7, they continue searching even for options that should be accepted according to the optimal policy. and Q5 did not reach 50% at position 9, in contrast to the optimal strategy that predicts much higher acceptance probabilities at this position.
Our models did not assume any learning over trials. This assumption was supported by an analysis of performance across trials. A linear mixed model on points per trial with trial number as fixed effect and by-participant random intercepts and random slopes for trial number showed no significant effect of trial number, F (1, 64.00) = 0.02, p = 0.88 
(Singmann et al., 2016)
.


Modeling results and discussion
First, we checked whether the key assumptions of the modeling framework were supported. We calculated, per participant and model, posterior predictive p-values (p pp ) that compared misfit (i.e., deviance) of the observed data with misfit of synthetic generated data from the model. For the baseline model, ITM, this analysis indicated that the absolute fit was very good, and a probabilistic threshold adequately describes participants' responses; p pp < .05 for only 8% of participants 
(Fig. S3A)
. For the vast majority of participants the observed misfit was consistent with the assumptions of the ITM plus sampling variability.
The performance of the LTM was almost identical to the ITM, suggesting that the considerably more parsimonious LTM (three free parameters for LTM compared to ten for ITM) adequately describes behaviour in optimal stopping tasks. The distribution of p pp -values of the LTM was almost identical to the ITM 
(Fig. S3A − B)
. 
Fig. 1D
 provides qualitative evidence of the agreement between LTM and data; the LTM adequately predicts accept probabilities for each quantile at every position (see 
Fig. S4
 for agreement between ITM and data). The absolute fit of the BOM is clearly worse than for ITM/LTM; p pp < .05 for 35% of participants 
(Fig. S3C)
. The source for this increased misfit can be seen in 
Fig. 1D
. Only for Q1 and early positions of Q4 and Q5 did the BOM provide an adequate account. Furthermore, the recovered thresholds 
(Fig. 1C)
 of the BOM clearly differ from the ITM in almost all positions. Results of the CoM are not shown explicitly as its performance was extremely poor. All p pp = 0; there was not a single posterior sample for which the observed misfit of the CoM was smaller than for synthetic data generated from the CoM. Furthermore, choices were essentially random for CoM with β CoM = 0.02 [0.01, 0.06] (for the other models, β ≈ 0.21).
These results suggest that humans use a linear threshold when searching for the best option. In the present tests we found that the human performance is only 6% off from the performance of an optimal agent, indicating that the linear strategy performs quite well. This suggests that using linear thresholds could be an ecologically sensible adaptation to sequential choice tasks. However, it could also mean that the LTMs good performance might not generalize to new task environments, in which the linear model performs less well -an ability that would be crucial for the LTM to be a useful model of human behavior.
Interestingly, search behavior in Experiment 1 indicated that people deviate from the optimal model depending on the price structure of the sequence: In trials with good options in the beginning people tended to accept them too early. However, in trials with few or no good options they continued search longer than the optimal model prescribed 
(Fig. S5)
. Accordingly, in tasks with plenty of good options people might search less than optimal. However, in tasks in which good options are rare they might be tempted to search too long.
To find out and further predict how people will adapt to the tasks, we conducted a simulation study comparing the optimal solution with a best performing linear model (using a grid search to find the best performing parameter values for the linear model) and an empirical study manipulating the distributions of ticket prices across three conditions: (1) a right skewed distribution simulating an environment with plentiful desirable alternatives, (2) a normal distribution as in experiment 1, (3) a left skewed distribution simulating a scarce environment. As illustrated in 
Fig. S6B
, the simulation study showed that the optimal model predicts more search in a plentiful environment, whereas a linear model predicts more search in the scarce environment. Furthermore, the linear model predicts a stronger decline in performance in the scarce environment than the optimal model 
(Fig. S6A)
.


Experiment 2
To show that the LTM can capture people's choice behavior across different tasks and allows us to predict when people will search too much or too little we conducted a second experiment changing the distribution of options. We manipulated the different task environments by sampling tickets from (1) a left skewed (PERT 1 
(40,195,200)
 


Behavioral results
Participants' performance increased from the left-skewed (scarce) environment to the right-skewed (plentiful) environment (F (2, 268) = 114, p < .0001). As predicted by the best performing linear model, the loss compared to optimal performance was largest in the left-skewed condition, where only few good tickets occur 
(Fig. S6A
).
The average search length decreased from the left skewed scarce environment to
1 The PERT distribution is a special case of the beta distribution defined by the minimum (a), most likely (b) and maximum (c) values that a variable can take and an additional assumption that its expected value is µ = a + 4b + c 6 . the right skewed plentiful environment, F (2, 268) = 11.5, p < .0001. This pattern also follows the predictions of the best performing linear model in the simulation study but is in contrast to the optimal model's predictions 
(Fig. S6B)
. Specifically, in the left skewed environment, where good tickets occur very rarely participants searched too long compared to an optimal agent, whereas in the environment where good tickets are abundant, participants ended their search too early compared to the optimal strategy.


Modeling Results and Discussion
Modeling results replicate the results from Experiment 1 and indicate that the LTM but not the BOM performed extremely well (p pp < .05 for 7% to 10% of participants across the three conditions for LTM, but p pp < .05 for 20% to 55% of participants for BOM, 
Fig. S7
). The observed accept probabilities ( 
Fig. 2A-C, black
 lines, where each line represents a ticket price within the specified quantile range) are adequately described by LTM predictions (red lines) on almost all positions and in all three environments. Moreover, the threshold parameters for the ITM are again on top of the threshold parameters estimated by the LTM in all the three environmental conditions 
(Fig. S8A − C)
.
These results indicate that humans use a linear threshold in optimal stopping problems, independent of the distributional characters of the task. However, this does not mean that people do not adapt to the task at all. Participants are responsive to task features and adapt their first threshold and the slope to the distributional characteristics of the task within the constraints of the linear model 
(Fig. S8A − C)
.
Experiment 1 and 2 show that the linear model reflects a robust psychological process when deciding between sequentially presented options. However, in both experiments deciders were explicitly trained on the distribution of options, something not common in real life decision making. The next experiment tests if the linear strategy can also explain choices in a realistic optimal stopping task where initial learning is omitted.


Experiment 3
The decision maker's goal is to buy online products at the lowest rate where prices for this product are presented sequentially. We selected commodity products from different categories (e.g food, leisure, kitchen tools) and collected for each product a set of prices from Amazon.com. Only products with approximately normal price distributions were selected for a final set of 60 products (see 
Table S1
). In the experiment, prices were sampled from a normal distribution, with a mean and standard deviation estimated from the real prices. All participants worked on 120 trials, divided into two blocks of 60 trials. In these two blocks, the 60 products were displayed in a random order (each product was encountered twice). Participants were aware that they could see up to 10 prices in each trial, and we indicated the average price of each product on the screen to reflect that people often have an idea of familiar products' prizes and to minimize individual differences in these.


Behavioral Results
Data from 95 participants were analyzed and replicated the results from Experiments 1 and 2 (normal distribution condition). Again, participants accepted too early, on average at position 4.6 (SD: 2.9). Comparing the performance in detail to the optimal strategy showed that 
(Fig. S9
) participants accepted too frequently at the beginning of the sequence (i.e., too low threshold) and searched too long towards the end of the sequence (i.e., too high threshold). We again found no evidence for learning across trials (linear mixed model on points per trial with trial number as fixed effect and by-participant random intercepts and random slopes for trial number showed no significant effect of trial number F (1, 94) = 0.13, p = 0.72))


Modeling Results
To deal with the prices' variability we normalized all values using mean and SD prior to fitting our models. We could replicate the results from Experiment 1 and 2, despite the fact that participants did not explicitly learn the product's prices beforehand: The LTM (10% of p pp < .05), but not the BOM (31% of p pp < .05), was able to capture the observed accept probabilities accurately on each position and for each quantile 
(Fig. 3B&C
). Furthermore, threshold parameters estimated by the LTM were very similar to threshold parameters estimated by the ITM 
(Fig. S10
).


Discussion
In this paper, we designed a variant of an optimal stopping task that allowed us to quantitatively characterize the deviations of human behaviour from optimality. We found that humans apply a simplifying strategy, where thresholds are linearly increased over time. We implemented this assumption in a computational framework and demonstrated that this model not only provided an excellent fit to the data, it also outperformed other models found in the optimal stopping literature. Furthermore, the linear threshold assumption makes a non-trivial prediction about search length, which we confirmed experimentally: Humans stop earlier in environments with many desirable alternatives compared to scarce environments. These results contrast with the prediction from the optimal model. Finally, in a online product purchase paradigm we could show that our model generalizes to real-world sequential choice problems.
The human bias to infer simple functions is well reported in a diverse set of domains 
(De Bock et al., 2002;
Little & Shiffrin, 2009;
Stango & Yinman, 2009;
Wagenaar & Sagaria, 1975;
Zwick et al., 2003)
 and our studies also correspond well with recent studies demonstrating that human choice behavior in an explore-exploit paradigm is well described by a linear threshold rule 
(Sang et al., 2018;
Song et al., 2019)
. The reinforcement of linearity at numerous occasions from school mathematics to everyday life, along with its intrinsic simplicity, may lead to a tendency to see and apply the linear model in many real life situations.
We have demonstrated that sequential decisions are well predicted when incorporating linearity in humans internal processes, and these insights will help quantify the conditions under which people may succeed or fail in such tasks. In turn, it will provide knowledge necessary for structuring decision problems in order to assist humans in making critical decisions that reflect their fundamental individual preferences.


Material and Methods
Participants. We recruited 438 participants (272 females; age range: 18-62;
N 1 = 144, N 2 left = 92, N 2 normal = 110, N 2 right = 92, N 3 = 100 in Experiments 1, 2 and 3, respectively) on Amazon Mechanical Turk to participate in the experiments.
Participants gave informed consent, and the Harvard Committee on the Use of Human Subjects approved the experiments. Participants were excluded from analysis if they accepted the first option in a trial in more than 95% of the trials. After applying these criteria, we included data from 499 participants in the subsequent analysis (N1 = 129, N2 left = 86, N2 normal = 102, N2 right = 84, N3 = 95).
Task. In Experiments 1 and 2, participants performed the same online ticket shopping task that consisted of a learning and a testing phase. In the learning phase, participants experienced the distribution from which the ticket prices were drawn. In Experiment 1, the distribution from which the values were sampled was normal with N (µ = 180, σ = 20). The procedure was as follows: Participants encountered sequentially 50 ticket prices drawn from the predefined distribution 
(Fig. S2A)
. After every ten tickets, participants had to guess the average value of the tickets seen so far 
(Fig. S2B)
. After each guess, participants were told the correct response. At the end of the learning phase participants were asked to complete a histogram (by dragging the bars) for an additional 100 tickets that were drawn from the same predefined distribution 
(Fig. S1C
 ). Participants received feedback by observing the correct distribution superimposed over their estimate 
(Fig. S1D)
 
(Goldstein & Rothschild, 2014
).
In Experiment 2, we used three conditions to realize three different distributional environments, a left skewed distribution, 
PERT(40,
195,
200)
, a normal distribution, 
PERT(90,
140,
190)
, and a right skewed distribution, 
PERT(120,
125,
400)
. The procedure of the learning phase was identical to Experiment 1 except that we removed the section about reporting the mean during learning in the left and right distribution scenario (section B in 
Fig. S1B
). Visual inspection of the performance in the histogram task suggested that participants learned the target distributions well 
(Fig. S1
).
In the second phase of Experiments 1 and 2, participants performed the ticket-shopping task. It started with a practice trial followed by 200 test trials. In each trial participants searched through a sequence of ten ticket prices randomly drawn from the predefined distribution. For each ticket, they could decide to accept or reject it at their own speed. People were aware that they could see up to 10 tickets in each trial and they were always informed about the actual position and the number of remaining tickets 
(Fig. S1E)
. It was not possible to go back to an earlier option after it was initially declined. If they reached the last (10 th ) ticket they were forced to accept this ticket. When participants accepted the ticket, they received explicit feedback about how much they could have saved by choosing the lowest-priced ticket in the sequence 
(Fig. S1F
 ).
Participants were paid according to their performance. In each of the 200 trials there was a maximum of 20 points to earn. The participants received the maximum number of 20 points if they chose the lowest-priced ticket and 0 points for the worst ticket in the sequence. The payoff for a ticket that lied between the lowest-priced and the highest-priced was calculated proportional to the distance to the lowest-priced ticket in the sequence. The exact calculation for the points in each trial i was as follows:
points i = 20 • (ticket max − ticket chosen ) ticket max − ticket min ,
(4)
where ticket max represents the most expensive ticket in the sequence and ticket min the cheapest ticket in the sequence. Participants received a base payment of $4 and earned between $0 and $4 additionally depending on their performance.
In experiment 3, participants performed an online product shopping task that started with a practice trial followed by 120 test trials divided into two blocks containing the same sixty products. In each trial, they encountered a product and searched trough a sequence of ten prices. Prices were randomly drawn from a normal distribution with a mean and standard deviation estimated from realistic prices collected from Amazon.com. Participants were always aware of the actual position and the number of remaining prices. Participants could collect up to 10 points in each trial,
proportional to the rank of the accepted price. They received a base payment of $2 and earned between $0 and $4 additionally depending on their performance.
nolistsep•
The Independent Threshold Model (ITM) serves as our baseline. It assumes no dependency between the thresholds. It entails N independent threshold parameters t 1 , ..., t N , one for each position in the sequence, where the decision maker can decide to accept or reject an offer (at position N + 1 the ticket must be accepted). The thresholds can take any value across positions. The model maintains maximal flexibility and provides an upper limit how well any threshold model can describe a person's decision given the assumption of a probabilistic threshold.


Figure 1
1
. (A) Probability to accept a ticket on each position across all prices. The dark line represents participant's frequency to accept, the dashed yellow line an optimal agent's probability to accept. (B)


Fig
. 1B shows the accept probabilities conditional on ticket prices, split into the first five quantile ranges Q1 -Q5 (out of a total of ten quantile ranges). Qi is defined as the range of ticket prices from the 0.ith to the (0.i − 0.1)th quantile of the ticket price distribution. In this experiment, the ticket distribution corresponds to a Gaussian distribution with mean 180 and standard deviation of 20. Accept probabilities for Q4


Fig. 1Ccompares the recovered thresholds of ITM and LTM and shows that the ITM thresholds essentially form a straight line lying exactly on top of the LTM thresholds.


),(2)a normal(PERT(90,140,190)) or (3) a right skewed distribution (PERT(120,125,400)), representing a scarce, a normal and a plentiful environment, respectively (seeFig. S1B-D, red lines). Each participant was assigned to only one condition. The final sample included 172 participants. The procedure was identical to Experiment 1, consisting of a learning phase, where participants got acquainted with the distribution (Fig. S1 B-D, participant's estimate in black lines), and a testing phase. In the testing phase, participants had to choose the lowest-priced ticket out of a sequence of 10 tickets with 200 trials (Material and Methods).


Figure 2 .
2
Results of experiment 2: Empirical data appear in black lines and the posterior predictive means of the LTM in red lines. Bars represent the 95% HDI. The different lines represent the tickets ranging in from the Q1 to Q5. Q1: Tickets in first quantile, Q2: Tickets between the first and second quantile etc. (A) Condition 1: Tickets are left skewed distributed(PERT(40,195,200)) corresponding to a scare environment. (B) Condition 2: Tickets are normally distributed(PERT(90,140,190)). (C) Condition 3: Tickets are right skewed distributed (PERT(120,125,400)) corresponding to a plentiful environment.


Figure 3
3
. (A) Screenshot of the product purchasing task. (B and C) Results of experiment 3: (B) Empirical data appear in solid black lines and the posterior predictive means of the LTM in dashed red lines. (C) Empirical data appear in solid black lines and the posterior predictive means of the BOM in dashed yellow lines. Bars represent the 95% HDI. The different lines represent the product prices ranging from the first quantile to the fifth quantile. Q1: Product prices in first quantile, Q2: Porduct prices between the first and second quantile, Q3: Product prices ranging from second to third quantile, etc.














Experimental studies of sequential selection and assignment with relative ranks




J
N
Bearden






A
Rapoport






R
O
Murphy








J Behav Decis Mak




19


3
















Improper use of linear reasoning: An in-depth study of the nature and the irresistibility of secondary school students' errors




De
Bock






D
Van Dooren






W
Janssens






D
Verschaffel






L








Educ Stud Math




50


3
















Recognizing the maximum of a sequence




J
P
Gilbert






F
Mosteller








Journal of the American Statistical Association




313
















Lay understanding of probability distributions




D
G
Goldstein






D
Rothschild








Judgm Decis Mak




9


1














The effect of goals and environments on human performance in optimal stopping problems. Decision




M
Guan






M
D
Lee








5


339












A hierarchical cognitive threshold model of human decision making on different length optimal stopping problems




M
Guan






M
D
Lee






J
Vandekerckhove








Cogsci
















Decision making in a sequential search task




J
P
Kahan






A
Rapoport






L
V
Jones








Percept Psychophys




2


8
















Consumer search behavior and sunk costs




C
A
Kogut








J Econ Behav Organ




14


3
















A hierarchical bayesian model of human decision-making on an optimal stopping problem




M
D
Lee








Cogn Sci




30


3
















Bayesian cognitive modeling: A practical course




M
D
Lee






E.-J
Wagenmakers








Cambridge university press












Simplicity bias in the estimation of causal functions




D
R
Little






R
Shiffrin








Proceedings of the annual meeting of the cognitive science society


the annual meeting of the cognitive science society
















Jags: A program for analysis of bayesian graphical models using gibbs sampling




M
Plummer








Proceedings of the 3rd international workshop on distributed statistical computing


the 3rd international workshop on distributed statistical computing
Vienna, Austria
















Explore/exploit tradeoff strategies in a resource accumulation search task




K
Sang






P
M
Todd






R
L
Goldstone






T
T
Hills














Preprint at








Sequential Decision Making with Relative Ranks : An Experimental Investigation of the " Secretary Problem




D
A
Seale






A
Rapoport








Organ Behav Hum Decis Process




69


3
















Optimal stopping behavior with relative ranks: The secretary problem with unknown population size




D
A
Seale






A
Rapoport








J Behav Decis Mak




13


4
















Future-biased search: the quest for the ideal




S
B
Shu








J Behav Decis Mak




21


4
















Afex: Analysis of factorial experiments




H
Singmann






B
Bolker






J
Westfall






F
Aust


















Sources of suboptimality in a minimalistic explore-exploit task




M
Song






Z
Bnaya






W
J
Ma








Nat Hum Behav




1














Exponential growth bias and household finance




V
Stango






J
Yinman








The Journal of Finance




64


6
















Losing a dime with a satisfied mind: Positive affect predicts less search in sequential decision making




B
Von Helversen






R
Mata








Psychology and aging




27


4


825














Misperception of exponential growth




W
A
Wagenaar






S
D
Sagaria








Percept Psychophys




18


6
















Consumer Sequential Search: Not Enough or Too Much?




R
Zwick






A
Rapoport






A
K C
Lo






Muthukrishnan








Mark Sci




22


4

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]