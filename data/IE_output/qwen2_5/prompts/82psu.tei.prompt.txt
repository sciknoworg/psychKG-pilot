You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Closed-form methods for estimating parameters of response time models
Mental representations of numbers are studied by investigating the various behavioral patterns obtained in cognitive tasks. In the case of symbolic numbers, one popular task is a numerical comparison task, where participants complete a number of trials on which they quickly judge whether each presented number is greater than (or less than) a fixed comparison standard (e.g., 5). A classic finding 
(Moyer & Landauer, 1967)
 is the numerical distance effect, where the response time increases as the numerical distance between the stimulus number and the comparison standard decreases. For example, people typically respond "larger" faster when 9 is presented than when 6 is presented; one classic explanation for this is that the internal magnitude representation is inherently imprecise and variable (i.e., "fuzzy"), and increasing the distance between to-be-compared numbers reduces their representational overlap, resulting in a faster decision 
(Verguts, Fias, & Stevens, 2005
).
In the context of two-digit numbers, we observe similar phenomena. Indeed, 
Hinrichs, Yurko, and Hu (1981)
 found a numerical distance effect for two-digit number comparison; participants' response times decreased as the numerical distance from the to-be-compared number increased from the comparison standard 55. 
Dehaene, Dupoux, and Mehler (1990)
 observed a similar result. In both cases, the observed numerical distance effect was taken as evidence of a holistic representation of two-digit numbers, where the two separate digits (the decade and unit digits) in the two-digit number stimulus are merged into a single representational unit. Despite this simple explanation for the observed numerical comparison behavior, increasing evidence has pointed to a decomposed representation of two-digit numbers. Primary evidence for the decomposed account comes from 
Nuerk, Weger, and Willmes (2001)
, who observed a unitdecade compatibility effect in two-digit number comparison. That is, when the decade and unit digits of one number were both smaller (or both larger) than both digits of the other number (i.e., unit-decade compatible), response times were faster than if the digits were unit-decade incompatible with each other. For example, the comparison of 23 versus 55 would be considered unit-decade compatible, whereas the comparison of 27 versus 55 would be considered unitdecade incompatible (see 
Figure 1
). In the former, the individual comparisons for each digit are in the same ordinal relationship to the digits in the comparison standard. That is, both the decade (2) and unit (3) are less than the corresponding digits from the standard 55. In the latter, the comparisons are reversed; in this case, the decade comparison is less than (i.e., 2 < 5), but the unit comparison is greater than (i.e., 7 > 5). The presence of the unit-decade compatibility effect indicates that people make obligatory comparisons of the decade and unit digits when comparing two-digit numbers, even though (remarkably) the decision can be made entirely by comparing the decade digits alone.
Since the original discovery of the unit-decade compatibility effect, a number of studies have further confirmed the presence of decomposed processing in two-digit number comparison.
For example, while 
Nuerk et al. (2001)
 based their conclusion on a comparison task where pairs of two-digit numbers were presented to be compared, 
Moeller, Nuerk, and Willmes (2009)
 observed a unit-decade compatibility effect for a comparison task where fixed standards (53 and 57) were held in memory and compared to a single presented two-digit number. In such trials, the decision can be made entirely by comparing the decade digits alone, but 
Moeller et al. (2009)
 demonstrated that parallel and separate comparisons of the decade and unit digits occur still.
Further probing of these decomposed processing signatures has indicated that the size and nature of the unit-decade compatibility effect can be manipulated by introducing variations in stimulus properties 
(Macizo & Herrera, 2011)
 or task instructions 
(Reynvoet, Notebaert, & Van den Bussche, 2011;
Faulkenberry, Cruise, & Shaki, 2017
.
Additionally, several researchers have investigated the unit-decade compatibility effect in the context of a general theory of numerical cognition 
Verguts & De Moor, 2005)
, which proposes that such compatibility effects occur due to competition between parallel and partially active responses. This response-competition account has been successful in explaining a variety of phenomena in numerical cognition, including the numerical distance effect 
(Erb, Moher, Song, & Sobel, 2018;
Faulkenberry, 2016)
, SNARC effect 
(Gevers, Verguts, Reynvoet, Caessens, & Fias, 2006;
Faulkenberry, 2014)
, decomposed process in fraction comparisons 
(Faulkenberry, Montgomery, & Tennes, 2015)
, and the size-congruity effect 
(Faulkenberry, Cruise, Lavro, & Shaki, 2016;
Sobel, Puri, & Faulkenberry, 2016;
Sobel, Puri, Faulkenberry, & Dague, 2017)
. One common thread between these studies is that they provide converging evidence that the time course of numerical compatibility effects tends to reflect late interaction (i.e., decision-related effects) rather than early interaction (i.e., encoding/perceptual effects).


Response time modeling
One criticism of the studies described above is that they discard a lot of information with their analytic technique. Most of these studies rely on the common technique of collapsing the distribution of response times observed in each design cell of an experiment (usually using the mean). Given that response times typically exhibit a positive skew, collapsing each cell to a single mean results in a loss of information about the shape of each participant's distribution of response times. An alternative approach is to employ a response time model to describe the observed behavior more fully.
One such model is the ex-Gaussian distribution, which has a long history of use in cognitive psychology, neuroscience, and other experimental behavioral sciences to model response time data in various tasks such as decision-making, memory retrieval, and attention processes 
(Matzke & Wagenmakers, 2009)
. Compared to the Gaussian (normal) distribution, the ex-Gaussian distribution provides a way to better describe the positive skew that is typically This tail parameter τ indexes the skewness of the distribution. For instance, smaller values of τ indicate distributions that are more symmetric around the mean (i.e., less skewed), whereas larger values indicate distributions that are more skewed to the right. In these instances, the larger value of τ predicts a higher probability of observing longer response times in the cognitive task. Altogether, the combination of the distributions captures both the main body of response times as well as the longer response times that contribute to the right-skewed portion.
Over the years, several researchers have proposed cognitive interpretations of the ex-Gaussian parameters, particularly and . For example, 
Balota and Spieler (1988)
 proposed that represented "more stimulus driven automatic (nonanalytic) processes", whereas represented "more central attention demanding (analytic) processes" (p. 34). In the context of mental arithmetic, Penner-Wilger, 
Leth-Steensen, and LeFevre (2002)
 interpreted as an index of memory retrieval and as an index of nonretrieval (i.e., use of procedures). Thus, the ex-Gaussian distribution not only uses normal and exponential distributions to describe the complex nature of response time data, capturing both typical (fast) responses and atypical 
slow
responses, but it also may help to explain the underlying cognitive processes that contribute to the observable response times. This makes it a valuable tool for researchers modeling human behavior in various experimental contexts.
One downside to using response time models such as the ex-Gaussian model is the relative difficulty of estimating model parameters from observed data. Classically, two approaches are typically employed -(1) maximum likelihood estimation (e.g., 
Myung, 2003)
; and (2) Bayesian estimation (e.g., 
Farrell & Ludwig, 2008)
. Both approaches require significant amounts of computer programming and technical mathematical knowledge to implement. In maximum likelihood estimation, the basic workflow is to first define a likelihood function based on the underlying model, and then use computer algorithms to find the parameter value(s) that maximize the likelihood function, conditional on the observed data. In Bayesian modeling, one must derive a posterior distribution via Bayes theorem, then use computer algorithms to sample from the posterior distribution (e.g., Markov chain Monte Carlo methods). Both methods provide a significant barrier to more widespread use of the ex-Gaussian model, making the development of an easy-to-use fitting method a highly desirable goal.


The present study
The goals of the present study were two-fold. First, we describe how to derive closedform equations that compute the ex-Gaussian parameters , , and directly from the summary statistics of a response time distribution (e.g., mean, variance, and skewness). Closed-form equations are just mathematical expressions which give one answer for a given set of inputs.
Their ease of use makes them advantageous over other model-fitting techniques like maximum likelihood estimation which require time-intensive computer algorithms to search a large space of parameter values for the ones which maximize a likelihood function and may or may not actually converge. The second goal was to then apply these closed-form equations to an existing data set from an experiment on two-digit number comparison. This study adds value to the field in two ways. First, we will provide a new, easy-to-use closed-form method for estimating parameters of the ex-Gaussian distribution. Second, we will apply this new computational method to a real data set in the context of numerical cognition and use the results to shed light on the cognitive processes involved in two-digit number representation.


Developing closed-form estimates of ex-Gaussian parameters
Before considering any response time data on two-digit number comparison, our first goal is to develop a set of closed-form equations to estimate the parameters of an ex-Gaussian model: , , and . One way to do this is to use the method of moments technique 
(Mishra & Datta-Gupta, 2018)
, which starts by representing the first three "moments" of the distribution (i.e., mean, variance, skewness) in terms of the model parameters µ, σ, and τ, and then using algebra to solve the resulting system of equations for µ, σ, and τ. For the ex-Gaussian distribution, the mean, variance, and skewness are given as follows 
(Soch et al., 2024)
:
mean = µ + τ variance = σ 2 + τ 2 skewness = !" ! ($ " & " " ) !/" .
From any set of observed response times, the mean, variance, and skewness can be computed and substituted directly into this system of equations. Algebraically, this leaves a system of three equations with three unknowns: , , and . Thus, our goal is to solve this system, which will give the closed-form equations necessary for estimating the ex-Gaussian parameters directly from summary statistics.
The first step involves starting with the equation for the third moment (skewness) and recognizing that the expression for the second moment (variance) is embedded within:
skewness = 2 ( (variance) (/! .
Now we simply solve for ; to do this, we multiply both sides of the equation by the denominator (variance) (/! , resulting in the expression: skewness × (variance) (/! = 2 ( Then we divide by 2 and take the cube root of each side, leaving the final equation for :
= 5 skewness × (variance) (/! 2 ! .
Now that we have a value for , the next step is to solve for using the equation for the first moment (mean):
mean = µ + τ .
Here, we simply subtract from both sides to isolate :
= mean − .
The final step is to solve for using the expression for the second moment, variance:
variance = ! + ! .
First we get ! on one side of the equation:
! = variance − ! .
We then solve for by taking the square root of both sides:
= √variance − ! .
From this preliminary work, we can now describe a step-by-step algorithm of how to use this closed-form approach to estimate ex-Gaussian parameters directly from the summary statistics of any response time distribution:
1. Using the distribution of observed response times, calculate the mean, variance, and skewness.
2. Calculate directly from the observed variance and skewness using the equation:
= 5 skewness × (variance) (/! 2 !
3. Calculate directly from the observed mean and the value for obtained in Step 2, using the equation:
= mean -.
4. Calculate directly from the observed mean and variance and the value for obtained in
Step 3, using the equation:
= √variance − ! .


Application to an existing dataset
Our second goal is to use these closed-form equations to apply the ex-Gaussian model to response times observed in a two-digit number comparison task. For this part, we used an existing unpublished dataset from 
Cipora et al. (2022)
, which we downloaded from https://osf.io/pm4zt. The dataset includes trial-by-trial data from 48 students from Loughborough University (43 females, mean age = 23.2 years, age range 18 to 29 years) who completed a twodigit number comparison task in a single session. The design and procedure of the experiment are fully described in the dataset's metadata, available at https://osf.io/dpjm2, but we will describe it briefly here for convenience. During the task, two-digit number pairs were presented vertically above and below a centrally presented fixation cross. The stimuli were presented in 24point white bolded Courier New font on a black background. Stimuli remained on the screen until a response was recorded or a maximum of 3000 ms elapsed. Each trial was followed by an intertrial interval of 500 ms. Participants were assigned to groups of 6 where they worked individually on assigned laptops. Before the task began, each participant was given 12 practice trials, where they were instructed on the basic guidelines of the task as well as instructed to press T for an upper number stimulus-response and V for lower number stimulus response. All participants used a standard QWERTY keyboard. After the practice trials, there were 4 blocks of 60 trials per participant, and participants were given the option to rest after each block. The trial order was completely randomized for each participant with compatible (e.g., 23 versus 55) and incompatible trials (e.g., 27 versus 55) mixed randomly throughout each block.
Across all participants, the dataset contained a total of 12,720 trials. After removing 17 trials lasting less than 200 ms and an additional 76 trials exceeding 3000 ms, a total of 12,627 trials remained for analysis, retaining 99.3% of the original trials. We applied the closed-form ex-Gaussian equations to the 
Cipora et al. (2022)
  predicting an increase in our dependent measures. We additionally performed sensitivity analyses to assess the impact of specifying different scales on the Cauchy prior.


Response Time Analysis
We conducted two different analyses on the design cells: one using the classical method  
Figure 4
) confirmed that the extremely large Bayes factors we observed did not depend on our choice of prior scale. In all, we have extreme evidence for a unit-decade compatibility effect on the mean response times.
Having observed the expected compatibility effect, we then went further by testing for compatibility effects individually in the ex-Gaussian parameters. For each design cell, we used our new closed-form equations to derive the ex-Gaussian parameters , , from the distribution of response times. We then performed both traditional and Bayesian paired sample t-tests on the collection of means for the and estimates 1 . The normal component means were the first to be considered. Similar to the analysis of mean response times conducted above, there was an effect of compatibility on the estimates for the ex-Gaussian parameter , t(47) = 2.53, p = 0.007.
As can be seen in 
Figure 5
, individual estimates for the ex-Gaussian parameter were larger for incompatible trials (M = 513 ms) than for compatible trials (M = 485 ms). A Bayesian pairedsamples t-test on the mean response times resulted in a Bayes factor of BF 10 = 5.38, indicating that the observed data was approximately 5.4 times more likely under the alternative hypothesis than under the null hypothesis. This is considered moderate evidence for a unit-decade compatibility effect on the ex-Gaussian parameter . As we can see in 
Figure 6
, the posterior distribution for the population-level effect size had a median value of 0.34, with a 95% credible interval of [0.08, 0.63]. Finally, our sensitivity analysis (see 
Figure 7)
 confirmed that the observed level of evidence was consistent across the range of possible values of the Cauchy prior scale. In all, we have moderate evidence for a unit-decade compatibility effect on ex-Gaussian parameter , which implies that the effect may involve nonanalytic processes.
Finally, we performed the same analysis for the tail component means . A pairedsamples t-test did not demonstrate a significant difference between congruent trials and incongruent trials, t(47) = 0.99, p = 0.163. Accordingly, the mean value of the tail component means for compatible trials was M = 201 ms, whereas the mean value of the tail component means for incompatible trials was M = 213 ms (see 
Figure 8
). Critically, a Bayesian paired samples t-test revealed a Bayes factor of BF 01 = 4.01, indicating that the observed data were approximately 4 times more likely under the null hypothesis than under the alternative hypothesis. As we can see in 
Figure 9
, the probability that the population-level effect size = 0 increases by a factor of 4 after observing data. Further, our sensitivity analysis (see 
Figure 10)
 confirmed that the observed level of evidence for the null was moderate across a reasonable range of possible values of the Cauchy prior scale. In all, these data provide positive evidence in favor of a null effect, suggesting that there is no compatibility effect in the tail component means . Overall, the ex-Gaussian analysis demonstrated that the compatibility effect we observed in mean response times occurs primarily in the μ parameter, not the parameter. This implies that the unit-decade compatibility effect appears to be primarily driven by nonanalytic processes, but no such contribution of analytic processes.


Discussion
The first aim of this paper was to develop closed-form equations for estimating parameters in ex-Gaussian response time models. We were able to successfully use the "method of moments" technique to mathematically derive these equations, which resulted in a simple 4step process to compute estimates for the ex-Gaussian parameters , , and directly from summary statistics of the distribution of a response time distribution: mean, variance, and skewness. Importantly, these equations are closed-form, meaning they require only basic operations of arithmetic to compute.
The second aim of this paper was to apply these new closed-form equations to an existing dataset. We chose to focus our application on an example in numerical cognition involving twodigit number representation. In the two-digit number comparison task, participants were instructed to correctly identify the larger number as quickly as possible. There were two trial types imposed: compatible trials, where both the decades and units digit were greater than the comparison standard, and incompatible, where one digit was greater and the other was less than the comparison standard. The known consequence of introducing incompatible trials is a slowdown in the reaction time of individuals, a phenomenon known as the unit-decade compatibility effect. Our analysis not only replicated this well-known effect, but also allowed us to further probe where and how the effect takes place.
In our analysis, we used our closed-form ex-Gaussian equations to decompose the observed response times into components which represent analytic and nonanalytic processes.
This approach makes sense in this context, as a typical observation is a positive skew in response time distribution. The ex-Gaussian model decomposes a given distribution into two components:
a Gaussian component with mean μ and an exponential tail component with mean . The normal mean has been previously discussed in the literature as a parameter representing nonanalytic processes, whereas the exponential component mean has been discussed as a parameter representing analytic processes. Analytic processes can be characterized as mental tasks that require central attention, often observed as attentional lapses, intentional cognitive processes, recall latency, and higher cognitive functioning. Nonanalytic processes, on the other hand, are more instinctual in nature, with an automatic and stimulus-driven process that manifests unconsciously. Both cognitive channels contribute to the overall decision-making process in an individual when a stimulus is presented.
Using the ex-Gaussian model to decompose the observed response times into corresponding analytic and nonanalytic processes adds to the small but emerging literature in numerical cognition that also uses this approach. For example, both Penner-Wilger, 
Leth-Steensen, & LeFevre (2002)
 and 
Campbell & Penner-Wilger (2006)
 used an ex-Gaussian decomposition method to probe the processes involved in simple mental arithmetic tasks. In these studies, Penner-Wilger and colleagues found that retrieval-driven trials exhibited a problem size effect that was prevalent in the parameter, but trials that involved procedures shifted this effect to . They concluded that may reflect memory processes, whereas reflects the use of procedures.
In the present study, the unit-decade compatibility effect was evident only in the parameter of the ex-Gaussian model. The considerable evidence for this observed increase in the estimates between compatible and incompatible trials was quantified by a Bayesian hypothesis test. However, there was no increase found in the tail component means between the two trial types. Subsequent Bayesian analysis confirmed this null effect, finding the data three times more likely under a null model where the unit-decade compatibility effect is not observed in the tail component means. These findings illustrate that the origin of the unit-decade compatibility effect is located in nonanalytic processes, meaning that the reaction time slowdown is due to instinctual stimulus-driven processes in incompatible trials. Using the work of Penner-Wilger and colleagues as a backdrop for the present results, the unit-decade compatibility effect may better reflect nonanalytic memory retrieval processes rather than analytic processes such as procedural calculation. The individual increases in the parameter likely reflect a disruption in memory retrieval of numerical order relations, possibly due to dynamic competition between parallel and partially active memory representations 
(Faulkenberry, 2014;
2016)
. The nature of individual differences in ex-Gaussian parameters is an open question, and recent work in hierarchical Bayesian models of individual differences could prove to be an exciting area of further research (e.g., 
Haaf & Rouder, 2017;
Faulkenberry & Bowman, 2023;
Faulkenberry, 2024)
.
In summary, we developed closed-form equations for estimating ex-Gaussian parameters, which we found to be useful for making inference on the mental processes involved in two-digit number comparisons. Results of these closed-form equations demonstrated the effect is localized in the mean of the normal component of the response time distribution. Therefore, the unitdecade compatibility effect appears to be due entirely to nonanalytic processes, potentially related to memory retrieval rather than procedural calculation.


Figure 1
An illustration of unit-decade compatibility (compatible versus incompatible) in two-digit number comparison.


Figure 2
Raincloud plot demonstrating the difference in reaction times between compatible and incompatible trials.


CLOSED-FORM ESTIMATES OF EX-GAUSSIAN MODELS 25


Figure 3
Prior and posterior plot for the population-level standardized effect size , which indexes the difference in mean response times between incompatible and compatible trials.


Figure 4
Sensitivity plot for mean response times, displaying the range of Bayes factors obtained when varying the scale (width) of the Cauchy prior for the Bayesian t-test. Prior and posterior plot for the population-level standardized effect size , which indexes the difference in estimates of the ex-Gaussian parameter between incompatible and compatible trials.


Figure 7
Sensitivity plot for the ex-Gaussian parameter , displaying the range of Bayes factors obtained when varying the scale (width) of the Cauchy prior for the Bayesian t-test. Prior and posterior plot for the population-level standardized effect size , which indexes the difference in estimates of the ex-Gaussian parameter between incompatible and compatible trials.


Figure 10
Sensitivity plot for the ex-Gaussian parameter , displaying the range of Bayes factors obtained when varying the scale (width) of the Cauchy prior for the Bayesian t-test.
observed in response times. Mathematically, the ex-Gaussian distribution is defined as a convolution, where a Gaussian distribution is combined with an exponential distribution in such a way that the shape of the exponential distribution is appended onto the Gaussian distribution as an upper tail. The Gaussian component of the model has two parameters: μ and σ. The parameter μ represents the mean of the Gaussian component and is a measure of the central tendency for the peaked component of the response time distribution. The σ parameter represents the standard deviation of the Gaussian component and measures the spread or variability of the response times around this peak. The exponential component of the model is characterized by its mean τ.


of collapsing the distribution to a single mean, and another based on our new closed-form ex-Gaussian estimates. First, we collapsed each design cell's distribution of response times into a single mean response time. The paired-samples t-test revealed the expected unit-decade compatibility effect on mean response times, t(47) = 8.38, p < 0.001, Cohen's d = 1.21. The raincloud plot inFigure 2shows that response times were longer for incompatible trials (M = 726 ms) than for compatible trials (M = 686 ms). A Bayesian paired-samples t-test on the mean response times resulted in a Bayes factor of BF 10 = 2.83 × 10 , , indicating that the observed data was 283 million times more likely under the alternative hypothesis than under the null hypothesis. As we can see inFigure 3, the posterior distribution for the population-level effect size had a median value of 1.17, with a 95% credible interval of [0.80, 1.55]. Finally, our sensitivity analysis (see


Figure 5
5
Raincloud plot demonstrating the difference in values of the ex-Gaussian parameter μ between compatible and incompatible trials. CLOSED-FORM ESTIMATES OF EX-GAUSSIAN MODELS 28 Figure 6


Figure 8
8
Raincloud plot demonstrating the difference in values of the ex-Gaussian parameter between compatible and incompatible trials. CLOSED-FORM ESTIMATES OF EX-GAUSSIAN MODELS 31 Figure 9


data using the following workflow. First, retained responses were separated into 106 design cells, formed by crossing the 48 participants with the 2 trial types (compatible, incompatible). In each design cell, we computed the mean, variance, and skewness of the observed response times. Then we applied the closed-form equations to compute values for the ex-Gaussian parameters , , and . JASP Team, 2024). A key detail of the Bayesian paired-samples t-test is the Bayes factor (BF), which expresses the relative likelihood of the observed data under both the null and alternative hypotheses. This method offers several benefits over traditional inference based on p-values,
including providing clear measures of evidence, interpretability, and a balanced analysis which
assesses the fit of data to both hypotheses (Wagenmakers, 2007; Faulkenberry, Ly, &
Wagenmakers, 2020). Unlike a p-value, which only indicates how likely the observed data would
be if the null hypothesis were true, a Bayes factor provides a relative likelihood of the data under
To test for compatibility effects in the parameter estimates, we conducted both traditional frequentist and Bayesian paired-samples t-tests using the open-source software package JASP (both hypotheses. For instance, a Bayes factor of BF10 = 100 would suggest that the observed data is 100 times more likely under the alternative hypothesis, while a BF01 = 100 would imply that the data is 100 times more likely under the null hypothesis. All t-tests were carried out on the difference scores obtained by subtracting each individual's relevant parameter value (e.g., mean RT, , ) for compatible trials from the parameter value for incompatible trials. Given our prior expectation of observing a unit-decade compatibility effect, we performed directional tests predicting positive difference scores under the alternative hypothesis. For the Bayesian tests, we further specified our a priori uncertainty in these (standardized) difference scores as a positively- truncated Cauchy distribution with scale = 0.707. That is, our tests were directional,


As the mean response time is composed only of the ex-Gaussian parameters and , we focused our analyses solely on these two parameters.














Word frequency, repetition, and lexicality effects in word recognition tasks: Beyond measures of central tendency




D
A
Balota






D
H
Spieler




10.1037/0096-3445.128.1.32








Journal of Experimental Psychology: General




128


1
















Calculation latency: The μ of memory and the τ of transformation




J
I D
Campbell






M
Penner-Wilger




10.3758/BF03193400








Memory & Cognition




34
















Prevalence of cognitive phenomena -comparison of four methods




K
Cipora






T
J
Faulkenberry






J
Bahnmueller






H
Connolly






K
Bowman






K
Moeller






H.-C
Nuerk




















Is numerical comparison digital? Analogical and symbolic effects in two-digit number comparison




S
Dehaene






E
Dupoux






J
Mehler




10.1037/0096-1523.16.3.626








Journal of Experimental Psychology: Human Perception and Performance




16


3
















Numerical cognition in action: Reaching behavior reveals numerical distance effects in 5-to 6-yearolds




C
D
Erb






J
Moher






J.-H
Song






D
M
Sobel




10.5964/jnc.v4i2.122








Journal of Numerical Cognition




4


2
















Bayesian and maximum likelihood estimation of hierarchical response time models




S
Farrell






C
J H
Ludwig




10.3758/pbr.15.6.1209








Psychonomic Bulletin & Review




15


6
















Hand movements reflect competitive processing in numerical cognition




T
J
Faulkenberry








Canadian Journal of Experimental Psychology




68


3


















10.1037/cep0000021














Testing a direct mapping versus competition account of response dynamics in number comparison




T
J
Faulkenberry








Journal of Cognitive Psychology




28


7


















10.1080/20445911.2016.1191504














Response trajectories capture the continuous dynamics of the size congruity effect




T
J
Faulkenberry






A
Cruise






D
Lavro






S
Shaki








Acta Psychologica




163


















10.1016/j.actpsy.2015.11.010














Reversing the manual digit bias in two-digit number comparison




T
J
Faulkenberry






A
Cruise






S
Shaki








Experimental Psychology




64


3


















10.1027/1618-3169/a000365














Task instructions modulate unit-decade binding in two-digit number representation




T
J
Faulkenberry






A
Cruise






S
Shaki








Psychological Research




84


2


















10.1007/s00426-018-1057-9














Bayesian statistics in numerical cognition: A tutorial using JASP




T
J
Faulkenberry






A
Ly






E
J
Wagenmakers








Journal of Numerical Cognition




6


















10.5964/jnc.v6i2.288














Bayesian modeling of the latent structure of individual differences in the numerical size-congruity effect




T
J
Faulkenberrry






K
A
Bowman




10.1080/20445911.2022.2136186








Journal of Cognitive Psychology




35


2
















A note on the normality assumption for modeling constraint in cognitive individual differences




T
J
Faulkenberry




10.51936/dtsh6123








Metodoloski Zvezki: Advances in Methodology and Statistics






19














Numbers and space: A computational model of the SNARC effect




W
Gevers






T
Verguts






B
Reynvoet






B
Caessens






W
Fias




10.1037/0096-1523.32.1.32








Journal of Experimental Psychology: Human Perception and Performance




32


1
















Developing constraint in Bayesian mixed models




J
M
Haaf






J
N
Rouder




10.1037/met0000156








Psychological Methods




22


4
















Two-digit number comparison: Use of place information




J
V
Hinrichs






D
S
Yurko






J
Hu




10.1037/0096-1523.7.4.890








Journal of Experimental Psychology: Human Perception and Performance




7


4
















JASP (Version 0




Jasp Team










18






Computer software








Cognitive control in number processing: Evidence from the unit-decade compatibility effect




P
Macizo






A
Herrera








Acta Psychologica




136


1


















10.1016/j.actpsy.2010.10.008














Psychological interpretation of the ex-Gaussian and shifted Wald parameters: A diffusion model analysis




D
Matzke






E
J
Wagenmakers




10.3758/pbr.16.5.798








Psychonomic Bulletin & Review




16
















Applied statistical modeling and data analytics: A practical guide for the petroleum geosciences




S
Mishra






A
Datta-Gupta








Elsevier


New York












Internal number magnitude representation is not holistic, either




K
Moeller






H.-C
Nuerk






K
Willmes








European Journal of Cognitive Psychology




21


5


















10.1080/09541440802311899














Time required for judgements of numerical inequality




R
S
Moyer






T
K
Landauer




10.1038/2151519a0








Nature




215


5109
















Tutorial on maximum likelihood estimation




I
J
Myung




10.1016/s0022-2496(02)00028-7








Journal of Mathematical Psychology




47


1
















Decade breaks in the mental number line? Putting the tens and units back in different bins




H.-C
Nuerk






U
Weger






K
Willmes








Cognition




82


1


















10.1016/s0010-0277(01)00142-1


















Decomposing the problem-size effect: A comparison of response time distributions across cultures




M
Penner-Wilger






C
Leth-Steensen






J.-A
Lefevre




10.3758/bf03194333








Memory & Cognition




30


7
















The processing of two-digit numbers depends on task instructions




B
Reynvoet






K
Notebaert






E
Van Den Bussche








Zeitschrift fur Psychologie






219
















10.1027/2151-2604/a000044














Bottom-up and top-down attentional contributions to the size congruity effect. Attention, Perception, & Psychophysics




K
V
Sobel






A
M
Puri






T
J
Faulkenberry




10.3758/s13414-016-1098-3








78














Visual search for conjunctions of physical and numerical size shows that they are processed independently




K
V
Sobel






A
M
Puri






T
J
Faulkenberry






T
D
Dague




10.1037/xhp0000323








Journal of Experimental Psychology: Human Perception and Performance




43


3
















The Book of Statistical Proofs (version 2023)




Soch




10.5281/zenodo.4305949


















Two-digit comparison: Decomposed, holistic, or hybrid?




T
Verguts






W
De Moor




10.1027/1618-3169.52.3.195








Experimental Psychology




52


3
















A model of exact small-number representation




T
Verguts






W
Fias






M
Stevens




10.3758/bf03196349








Psychonomic Bulletin & Review




12


1
















A practical solution to the pervasive problems of p values




E.-J
Wagenmakers




10.3758/bf03194105






Psychonomic Bulletin & Review




14


5

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]