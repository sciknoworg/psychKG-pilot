You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Why do people prefer an option offering $3 for sure over an option offering $4 with a probability of 80%-even though the latter has a higher expected value? Why do changes in an outcome's probability near the end points of the probability scale (e.g., from 90% to 100% or from 10% to 0%) have a greater impact on people's preferences than changes of the same magnitude in mid-range probabilities (e.g., from 50% to 60%)-a phenomenon referred to as the certainty effect 
(Allais, 1953;
Kahneman & Tversky, 1979;
Tversky & Kahneman, 1986)
? A prominent approach to account for these phenomena is to assume that decision makers evaluating a risky option weight probabilistic events in a way that is distorted relative to the objective probabilities of the events. They thereby violate expected value (EV) maximization and expected utility (EU) maximization-or, generally put, expectation maximization-both of which require weighting of outcomes by objective probabilities. This notion of nonlinear probability weighting has entered cumulative prospect theory (CPT; 
Tversky & Kahneman, 1992)
, arguably the most influential theory of decision making under risk. CPT assumes that the decision weights people attach to probabilistic outcomes are derived from a nonlinear trans-formation of cumulative probabilities, based on an inverse S-shaped probability-weighting function. The shape of this function implies that people overweight small probabilities and underweight large probabilities. 
1
 But nonlinear probability weighting is not the only theoretical construct to account for systematic deviations from expectation maximization. Another approach is rooted in the tradition of sequential sampling models, which describe the decision-making process as an accumulation of evidence over time (e.g., 
Bhatia, 2017;
Brown & Heathcote, 2008;
Busemeyer & Townsend, 1993;
Diederich & Trueblood, 2018;
Ratcliff, 1978;
Ratcliff & Smith, 2004)
. Once the evidence in favor of one option exceeds a threshold, a choice is made. Several variants of sequential sampling models have been proposed, assuming different mechanisms to account for deviations from expectation maximization. One simple and empirically grounded approach that has been successfully applied to several decision-making tasks 
(Smith & Krajbich, 2018)
 is the attentional Drift Diffusion Model (aDDM; 
Krajbich, Armel, & Rangel, 2010;
Krajbich & Rangel, 2011)
. The aDDM explains preferences that violate expectation maximization as consequences of asymmetries in the allocation of attention across options (we discuss sequential sampling models equipped with alternative attentional mechanisms in the Discussion section). Specifically, evidence in favor of an option accumulates at a faster rate when this option is attended to. Attentional biases can therefore make options seem more or less attractive than they objectively are, entailing systematic deviations from expectation maximization. This mechanism allows the aDDM to accommodate the common finding in eye-tracking studies that people are more likely to choose an option if they look at it for longer (e.g., 
Armel, Beaumel, & Rangel, 2008;
Cavanagh, Wiecki, Kochar, & Frank, 2014;
Konovalov & Krajbich, 2016;
Krajbich et al., 2010;
Krajbich & Rangel, 2011;
Shimojo, Simion, Shimojo, & Scheier, 2003;
Stewart, Hermens, & Matthews, 2016
)-even if their attention is exogenously manipulated 
(Armel et al., 2008;
Shimojo et al., 2003)
, and even if the option is objectively inferior.
Systematic deviations from expectation maximization can thus be explained in terms of both nonlinear probability weighting and attention-weighted evidence accumulation. Both modulate the strength and direction of preferences between options by redistributing weights. Despite these parallels, the two theoretical constructs are conceptually very different, and CPT and aDDM-belonging to different formal traditions-are usually studied in isolation from each other. There may, however, be important, yet little understood links between the constructs. For instance, might attentional biases contribute to the emergence of the certainty effect on the process level? Do preferences shaped by asymmetric atten-tion allocation across options have distinctive signatures in CPT's probability-weighting function? Because the respective theories are formulated in distinct conceptual languages, such questions simply do not arise (see 
Broadbent, 1984)
. As a consequence, it remains unclear whether and how probability weighting and attention-weighted evidence accumulation relate to each other (but see 
Johnson & Busemeyer, 2016)
. 
2
 In this article, we present an approach for overcoming this divide. We show that attentional biases in attentionweighted evidence accumulation, as formalized in the aDDM, can lead to behavioral regularities that are reflected in characteristic shapes of the probability-weighting function when the choices are modeled with CPT. That is, nonlinear probability-weighting can arise as a consequence of unequal attention allocation between the options in risky choice. After motivating the possible link, we conduct a cross-theory simulation analysis (see 
Donkin, Brown, Heathcote, & Wagenmakers, 2011;
Luan, Schooler, & Gigerenzer, 2011;
Pachur, Suter, & Hertwig, 2017)
. Specifically, we use the aDDM to generate data in choice problems offering safe and risky options, assuming different degrees of attentional bias to one of the options, and we model the resulting choices with CPT. The results show that the behavioral consequences of varying attentional biases in the aDDM give rise to highly systematic signatures in the shape of CPT's probabilityweighting function. We also extend these analyses to choice problems offering two risky options. We then show that the link between attentional biases in sequential sampling and probability weighting also holds empirically. To that end, we re-analyze data on decisions from experience-a paradigm in which people learn about the options by sampling from their payoff distributions, which makes it possible to measure how they allocate their attention across options-as well as data from eye-tracking studies on risky choice. In both analyses, we find that empirically different degrees of attentional bias toward a safe or a risky option are systematically associated with choice behavior and signatures in probability-weighting functions that are very similar to those identified in the simulations. Because the aDDM also predicts response times, its link to CPT additionally points to a possible association between attention, probability weighting, and response times. We also test this association empirically and find evidence for it. In addition to identifying the points of convergence 3 between the two computational frameworks, we also discuss and quantify where they make distinct predictions.
Our analyses establish links between two major computational frameworks for preferential choice that are commonly studied in isolation from each other. In addition, our findings have several important conceptual implications. For instance, the parameters of CPT's weighting function are often interpreted in terms of probability sensitivity and optimism/pessimism (R. 
Gonzalez & Wu, 1999)
. Our results challenge this view and suggest an alternative psychological interpretation, in terms of imbalances in attention allocation between options. Further, our results suggest novel process-based explanations for several key phenomena in risky choice. For instance, the certainty effect, the fourfold pattern of risk attitudes, and the gap between descriptionbased and experience-based decision making 
(Hertwig, Barron, Weber, & Erev, 2004;
Wulff, Mergenthaler-Canseco, & Hertwig, 2018)
, all of which have often been portrayed in terms of characteristic patterns in probability weighting, may to some extent be consequences of asymmetric attention allocation between options. The mapping between CPT and the aDDM also reveals aspects in which the aDDM may have to be extended, for instance, in order to account for gain-loss asymmetries (e.g., loss aversion). Generally, our analyses contribute to theory integration and foster communication across research traditions within psychology and economics. We start by describing how CPT and the aDDM developed historically, highlighting how theoretical constructs were introduced to account for empirical deviations from normative theories of maximization.


Two Theoretical Accounts of Deviations from Expectation Maximization
In the subsequent description of CPT and the aDDM, an option in a risky choice problem (short: a prospect) is defined as a probability distribution over a finite set of outcomes X = x 1 , ..., x n , where n ≥ 1. Writing a prospect as X = (p 1 , x 1 ; ...; p n , x n ) denotes that each outcome x i can be obtained with probability p i . We further assume p i ≥ 0 and n i=1 p i = 1 (see 
Abdellaoui, l'Haridon, & Zank, 2010)
.


Nonlinear Probability Weighting in Cumulative Prospect Theory
According the theory of mathematical expectationformulated in 1654 by Blaise Pascal and Pierre Fermat (see 
David-Nightingale, 1962
)-the rational way to make decisions under risk is to choose the option with the highest expected value (EV). The EV of an option is calculated by weighting each possible outcome by its objective probability and summing up the results:
EV = n i=1 x i • p i .
(1)
It was soon discovered that people's preferences often vio-late the predictions of EV theory. For instance, people are willing to pay only small amounts of money to play a dice game that, in principle, has infinite EV. To account for this phenomenon, known as the St. Petersburg paradox, Daniel 
Bernoulli (1738
Bernoulli ( /1954
 proposed the expected utility 
(EU)
 principle. In what subsequently became known as EU theory, Bernoulli posited that the desirability of events should be assessed not on the basis of their objective value, but on the basis of the subjective utility that an individual would derive from them. Assuming that the same increase in value would have a lower impact for a more wealthy person, he proposed a transformation of outcomes by a concave utility function, u. Outcomes' subjective utilities are still weighted by their objective probabilities, according to
EU = n i=1 u(x i ) • p i .
(2)
We refer to models descending from EU theory, which revolve around the concept of utility, as neo-Bernoullian models. 
3
 It emerged that EU theory is also violated empirically. For instance, people exhibit the fourfold pattern of risk attitudes: They are risk averse for high-probability gains and low-probability losses, but risk seeking for low-probability gains and high-probability losses 
(Tversky & Fox, 1995;
Tversky & Kahneman, 1992)
. In a further violation of EU theory, most people prefer a small safe gain over a more valuable risky gain, but when offered a choice between two risky gains, they prefer the more valuable one-the certainty effect mentioned above. This suggests that people overweight safe outcomes relative to merely probable ones 
(Allais, 1953;
Kahneman & Tversky, 1979;
Tversky & Kahneman, 1986)
. To account for these and other phenomena, prospect theory (PT; 
Kahneman & Tversky, 1979)
 and its subsequent extension CPT 
(Tversky & Kahneman, 1992)
 diverge from EU theory in several respects. Overall valuations of options in CPT are given by
V CPT = n i=1 v(x i ) • π i .
(3)
Loss and gain outcomes are distinguished by a reference point, and the value function v(x i ) is steeper for losses than for gains (implying loss aversion). Moreover, CPT introduced a nonlinear probability-weighting function, w, which is used to transform cumulative probabilities-that is, the probabilities of obtaining an outcome at least as good Probability p w(p) 
Figure 1
. An example of the inverse S-shaped probabilityweighting function proposed by 
Tversky and Kahneman (1992)
 in the context of CPT. The dashed identity line represents linear weighting, based on objective probabilities (as assumed in EU theory).
(bad) as each outcome-into subjective decision weights, π i (for a detailed historical overview of the development of probability weighting, see 
Pachur & Hertwig, 2019)
. The derivation of cumulative decision weights is a central feature distinguishing CPT from PT. The functional form of the probability-weighting function w evolved over time. When introducing CPT, 
Tversky and Kahneman (1992)
 proposed the following formalization:
w T K92 (p) = p γ (p γ + [1 − p γ ]) 1/γ ,
(4)
where γ is a curvature parameter. As illustrated in 
Figure  1
, the function is inverse S-shaped (for γ < 1); this implies that (depending on their rank) events with small probabilities are overweighted relative to their objective probabilities, whereas events with moderate to large probabilities are underweighted. The function thus captures the fourfold pattern. Moreover, the function implies that changes in probability have less impact, the further away they are from the reference points of certainty and impossibility. For instance, a change in probability from .4 to .5 has less impact on the event's desirability than a change from .9 to 1-although the increment is .1 in both cases. The function thus also captures the certainty effect. Following the formalization suggested by Tversky and Kahneman, the probability-weighting function was refined on formal and empirical grounds (see 
Abdellaoui et al., 2010;
Prelec, 1998;
Stott, 2006;
Tversky & Fox, 1995)
, resulting in several alternative functional forms (e.g., 
Abdellaoui et al., 2010;
Goldstein & Einhorn, 1987;
Prelec, 1998)
. These functions typically have adjustable parameters that can be fitted to empirical data: a curvature parameter, γ, and in some cases an additional elevation parameter, δ. For instance, 
Prelec (1998)
 proposed a commonly used two-parameter probability-weighting function
w PR98 (p) = e −δ(−log(p)) γ .
(5)
The impact of γ and of δ on the shape of Prelec's weighting function is illustrated in more detail below. 4 These parameters are sometimes used to measure distinct psychological constructs. For instance, 
Tversky and Kahneman (1992)
 interpreted the curvature parameter as an indicator of probability sensitivity. The elevation parameter is often understood as a measure of optimism or pessimism (R. 
Gonzalez & Wu, 1999;
Lattimore, Baker, & Witte, 1992)
.


Attentional Weighting in the Attentional Drift Diffusion Model
Sequential sampling models are used in many areas of experimental psychology, including perceptual judgment 
(Link & Heath, 1975;
Ratcliff & Rouder, 1998)
, recognition memory 
(Ratcliff, 1978)
, lexical decisions 
(Ratcliff, Thapar, Gomez, & McKoon, 2004)
, categorization 
(Nosofsky & Palmeri, 1997)
, and-most relevant for our purposesrisky choice (e.g., 
Busemeyer & Townsend, 1993;
Diederich & Trueblood, 2018;
Johnson & Busemeyer, 2005)
. Sequential sampling models are rooted in static signal detection theory (SDT), which describes how ideal observers can maximize accuracy in simple perceptual tasks, such as judging whether a stochastic stimulus contains only noise or some signal component 
(Swets, 1961;
Tanner Jr. & Swets, 1954)
. Sequential probability ratio tests (SPRT; see 
Ashby, 1983;
Stone, 1960;
Wald & Wolfowitz, 1948)
 extend the notion of the optimal observer in SDT along the temporal dimension. Instead of evaluating the signal strength or value of the stimulus in a single step, SPRTs assume that evidence is sampled repeatedly in a discrete random walk. SPRTs behave optimally in the sense that they achieve the highest level of EV maximization for a desired response speed 
(Bogacz, Brown, Moehlis, Holmes, & Cohen, 2006)
. As a consequence, however, SPRTs cannot account for systematic preferences in favor of objectively inferior options that are caused by factors beyond the options' objective values-such as attention.
To explain the finding that people are more likely to choose an option if they look at it for longer than they look at the alternative 
(Armel et al., 2008;
Cavanagh et al., 2014;
Ghaffari & Fiedler, 2018;
Konovalov & Krajbich, 2016;
Krajbich et al., 2010;
Krajbich, Lu, 5
 Criterion   
Figure 2
. An example simulated aDDM process. The relative evidence in favor of the safe versus the risky option accumulates over discrete steps of time. During each time step, evidence in favor of the option currently attended to receives more weight than does evidence in favor of the other option, generating an advantage for the option that is attended to for longer in total (in the example shown, it is the safe option). When the accumulated evidence exceeds one of the thresholds, the corresponding option is chosen.
(A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (A) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (B) Criterion (


B) Criterion (B) A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B B A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A A
Camerer, & Rangel, 2012; 
Krajbich & Rangel, 2011;
Newell & Le Pelley, 2018;
Shimojo et al., 2003;
Stewart et al., 2016)
 in a wide variety of choice domains 
(Smith & Krajbich, 2018)
, the attentional Drift Diffusion Model (aDDM; see 
Krajbich et al., 2012;
Krajbich & Rangel, 2011)
 extends an optimal SPRT by introducing a mechanism of attentional weighting. Here, evidence for an option accumulates at a faster rate while that option is in the focus of attention (which can be measured using methods such as eye-tracking or other methods measuring predecisional information search). As a consequence, the proportion of time spent attending to each option can modulate its relative desirability-and excess time spent attending to an option can increase the probability of its being chosen, even if it is objectively inferior. Imbalances in attention allocation between options can thus entail systematic deviations from expectation maximization. That is, attentional weighting enables the aDDM to account for systematic deviations from the normative benchmark of maximization, as formalized in (non-attentional) SPRTs. Although the aDDM is not typically presented as a theory of choice biases or deviations from optimality, it thus makes an important contribution in this regard. Specifically, it implicitly identifies attentional biases to inferior options as a possible explanation for systematic deviations from expectation maximization. A simulated aDDM process is illustrated in 
Figure 2
.
Commonalities Between CPT and the aDDM Nonlinear probability weighting in CPT and attentional weighting in aDDM thus both capture deviations from expectation maximization. Nonlinear probability weighting in CPT accounts for systematic deviations from EU theoryfor instance, the apparent overweighting of safe outcomes. Attentional weighting in the aDDM accounts for systematic deviations from SPRT-in particular, preference for an option that may be objectively inferior but receives more attention. Like many formal accounts of preferences in decision making under risk, both CPT's decision weights and aDDM's attentional weights generate a systematic advantage for one option that may not be justified by its objective value. Thus, although the constructs are conceptually different, both equip their respective theoretical framework with a similar capacity.
Against this background, it may be possible to establish a link between probability weighting and attentional weighting. Specifically, the preference patterns resulting from different degrees of attentional biases to safe or risky options in the aDDM might give rise to systematic signatures in CPT's probability-weighting function. Conversely, it might be possible to explain key phenomena in risky choice that are associated with characteristic probability-weighting functions (e.g., the fourfold pattern) in terms of systematic attentional biases.
In what follows, we examine whether attentional biases to an option entail systematic signatures in probabil-ity weighting, both theoretically (based on simulations) and empirically (based on a re-analysis of published data). We first focus on problems offering choices between a safe and a risky gain-a paradigm often employed in behavioral experiments on risky choice-and later extend our argument to choices between two risky options, and to the domain of losses. In choice problems offering a safe and a risky gain, each safe option is henceforth defined as offering an outcome x sa f e for sure, and can be written as X sa f e = (1, x sa f e ). Each risky option is henceforth defined as offering a high outcome x high,risky and a low outcome x low,risky < x high,risky with the probabilities p high , assumed to be uniformly sampled from the range [0, 1], and p low = 1 − p high . Such a two-outcome risky option can be written as X risky = (p high , x high,risky ; p low , x low,risky ).


Formalizing the Preference Between a Safe and a Risky Option in the aDDM
According to the aDDM, in a choice between a safe and a risky option the evidence for the safe option, DV sa f e , and the evidence for the risky option, DV risky , accumulate over time (DV is short for decision variable). At each time step, t, of the accumulation process, either the safe or the risky option is in the focus of attention (here we assume t = 100ms). The probability, a t s , of attending to the safe option at each step captures the degree of attentional bias in the process. If a t s = 0.5, both options are equally likely to be inspected. If a t s < 0.5, there is an attentional bias to the risky option, and if a t s > 0.5, there is an attentional bias to the safe option. At a given time step t where the safe option is attended to, evidence for the safe and risky options is given by DV sa f e (t) = DV sa f e (t − 1)
+ d • x sa f e + DV risky (t) = DV risky (t − 1) + d • θ • x i,risky + .
(6)
At a given time step t where the risky option is attended to, evidence for the safe and risky options is given by DV sa f e (t) = DV sa f e (t − 1)
+ d • θ • x sa f e + DV risky (t) = DV risky (t − 1) + d • x i,risky + .
(7)
The parameter θ < 1 indicates that evidence for an option evolves at a slower rate when the other option is attended to. We assume that at each time step, the outcome of the safe option and one outcome of the risky option is sampled as evidence. The sampled outcomes, x sa f e and x i,risky , are scaled by the constant d = 0.01, which controls the speed of integration (in units of t −1 ), and Gaussian noise ∼ N(0, σ 2 ) is added (also in units of t −1 ). The outcomes of the risky option, x i,risky , are sampled proportionally to their probabilities, p i,risky . 5 Given θ < 1, evidence for an option evolves at a slower rate when the other option is attended to. Therefore, over time, evidence in favor of an option accumulates at a faster rate if attention is biased toward that option-a mechanism of option-specific attentional weighting. 6 Note that because the aDDM assumes a multiplicative relationship between θ and the options' outcomes attention tends to have stronger impact on preference formation in choice problems with larger outcomes (see 
Smith & Krajbich, 2019)
.
Once the difference DV sa f e − DV risky reaches the upper or the lower decision boundary, set to +1 and −1, respectively (as in 
Krajbich et al., 2010)
-indicating that the evidence in favor of one option exceeds the evidence in favor of the other option by a sufficient amount-a choice is made. Attentional biases can shift this difference in favor of the option that is in the focus of attention for a larger proportion of time and thus increase the probability of choosing that option. That is, a key factor modulating the preference between a safe and a risky option in the aDDM is the magnitude and direction of attentional bias to one or the other option. Note that the aDDM does not predict when or why (e.g., due to which features of the options) option-specific attentional biases arise, but typically relies on external measures of attention as input (e.g., eye-tracking). That is, the aDDM predicts the consequences of attentional biases-that is, how they affect preferences-but not attentional biases themselves.


Formalizing the Preference Between a Safe and a Risky Option in CPT
In CPT, the overall valuation V of an option is the sum across the subjective values of all outcomes, v(x i ), each weighted by a cumulative decision weight, π i , as described in Eq. 3. The objective values of the outcomes are transformed 
5
 Instead of by sampling individual outcomes proportional to their objective probabilities, this process can also be implemented by sampling the options' EVs. Due to the law of large numbers, both implementations yield the same result-except if the total number of samples preceding the choice is very low. Here, we describe the variant that samples individual outcomes, as it more closely resembles the dynamics of information acquisition in the sampling paradigm in decisions from experience 
(Hertwig & Erev, 2009;
Wulff et al., 2018)
, to which we turn later. 
6
 In the most extreme case, θ is zero, such that when the safe option is inspected only evidence for DV sa f e accumulates, and evidence for DV risky does not systematically change at all. 
Krajbich and Rangel (2011)
 assume that θ can vary within the interval [0,1]. Also note that when θ = 1, the aDDM reduces to a standard DDM, where attention does not affect the relative attractiveness of the options. Here, we use the terms "standard" versus attentional DDM to differentiate a model that does not involve attentional weighting from a model that does, while assuming that they share all other assumptions (e.g., stochastic evidence and a relative evidence threshold). Other authors may use the term "standard" DDM to refer to different models. In the case where the aDDM reduces to a standard DDM, the model can implement an optimal SPRT, where maximization performance is impaired only by nonsystematic noise. That is, for θ = 1, the model predicts no systematic deviations from EV maximization. The impact of θ is addressed in more depth in Supplemental Material S1. 
v v(x i ) =      x α i , if x i ≥ 0 −λ | x i | α , if x i < 0,
(8)
with the outcome sensitivity parameter α ∈ [0, 1]. The value function v is concave for gains and convex for losses. The loss aversion parameter, λ > 1, indicates that losses have a larger impact on the subjective valuation than do gains (in our main analyses, λ is not relevant because we focus on pure-domain choice problems that offer only gains or only losses; we discuss issues regarding loss aversion in more detail below). To derive the predicted probability of choosing the safe over the risky option, researchers typically enter the difference between the valuations V sa f e and V risky of the safe and the risky option into a stochastic choice rule. For instance, the logit choice rule (also known as softmax) defines the probability that the safe option is chosen over the risky option as
p(sa f e, risky) = 1 1 + e −ρ[V sa f e −V risky ] .
(9)
The choice sensitivity parameter, ρ ≥ 0, captures the extent to which choices are determined by the difference between the options' valuations. Under ρ = 0, the choice probability is 0.5 (i.e., choice is random). With higher values of ρ, the probability of choosing the option with the higher valuation increases (i.e., the choices become increasingly deterministic).
A key factor in CPT that modulates the preference between a safe and a risky option is the shape of the probabilityweighting function. The cumulative decision weight, π i , for each positive outcome, x i , is defined as the difference between the probability of obtaining an outcome at least as good as x i and the probability of obtaining a strictly better outcome, both transformed by the probability-weighting function w. The decision weight of a safe outcome equals π sa f e = 1, regardless of the shape of w. Therefore, the valuation of the safe option is unaffected by probability weighting. By contrast, the shape of the probability-weighting function can shift the valuation of the risky option. For a two-outcome risky gamble in the gain domain, the decision weights of the higher and the lower outcome are given by
π high = w(p high ) π low = w(p low + p high ) − w(p high ) = 1 − π high ,
(10)
respectively. The total valuation V risky of such an option is
V risky = π low • v(x low,risky ) + π high • v(x high,risky ) = (1 − π high ) • v(x low,risky ) + π high • v(x high,risky ).
(11)
Because for pure-gain and pure-loss gambles the decision weights of all outcomes of an option add up to 1 (as is evident from Eq. 10), probability weighting redistributes the total probability mass of 1 across the outcomes. If the higher outcome receives more weight under this redistribution than under objective weighting (i.e., π high > p high ), the risky option appears more attractive than it objectively is. If the higher outcome receives less weight than under objective weighting (i.e., π high < p high ), the risky option appears less attractive. Whether the higher outcome receives more or less weight than under objective weighting depends on the shape of the probability-weighting function, which is determined by its parameters.
Consider the probability-weighting function proposed by 
Prelec (1998)
, defined in Eq. 5, which is shaped by two parameters, γ ∈ [0, 2] and δ ≥ 0. 
Figure 3
 illustrates the shape of this function for different parameter settings. If both γ = 1 and δ = 1, the weighting function is linear and the decision weights equal the objective probabilities. That is, π high equals the objective probability p high , and weighting in CPT coincides with that in EU theory, yielding maximization behavior. When γ and δ deviate from 1, the weighting function is nonlinear, such that π high can be larger (smaller) than p high . As a consequence, the higher outcome is assigned more (less) weight than it objectively deserves, making the risky option appear more (less) attractive than under objective weighting. This also means that nonlinear probability weighting can shift the difference in valuation between the risky and the safe option in favor of either one of the options, and thus increase the probability of that option being chosen.
Let us next examine specifically how the two parameters δ and γ affect the attractiveness of risky options. The δ parameter governs the elevation of the weighting function. Under low values of δ (in the range δ < 1), the weighting 
Table 1
 How the Two-Parameter Probability-Weighting Function by 
Prelec (1998)
 is Expected to Reflect Option-Specific Attentional Biases Implemented in the aDDM for Choices Between a Safe and a Risky Option Predicted signatures in parameters of CPT's Attention allocation in aDDM probability-weighting function Attentional bias toward the risky option (a t s < .5) δ < 1, γ > 1; lower δ and higher γ for more extreme biases Unbiased attention (a t s = .5) δ = 1, γ = 1 Attentional bias toward the safe option (a t s > .5) δ > 1, γ < 1; higher δ and lower γ for more extreme biases function tends to run above the identity line across most of the probability range-that is, the function has a high elevation. How does a high elevation affect the attractiveness of risky options? For most risky options-assuming that p high is uniformly drawn from the entire probability range-a highly elevated weighting function implies that the more attractive outcome receives more weight than it objectively deserves, w(p high ) > p high , boosting the risky options' overall valuation. 
7
 Conversely, under higher values of δ (in the range δ > 1), the weighting function runs below the identity line for most probabilities-that is, it has a low elevation. This implies that most risky options appear less attractive than they objectively are, because w(p high ) < p high for most values of p high . How does the parameter γ affect the valuation of risky options in the weighting function proposed by 
Prelec (1998;
 see 
Figure 3
)? The γ parameter determines the curvature of the weighting function. The function assumes an inverse Sshaped (or convex) curvature under γ < 1 and an S-shaped (or concave) curvature under γ > 1. For any level of elevation, an inverse S-shaped weighting function runs below the identity line for a greater proportion of the probability range than an S-shaped one does (see 
Figure 3
). Therefore, most risky options tend to appear less attractive under an inverse S-shaped weighting function (i.e., γ < 1) than under an S-shaped weighting function (i.e., γ > 1)-again, assuming that p high is uniformly drawn from the entire probability range. Supplemental Material S2 describes how to quantify the distortions of the valuation of a risky option due to the different probability-weighting parameters.
In sum, in choices between a safe and a risky option, probability weighting can selectively modulate the valuation of the latter while leaving the valuation of the former unaffected. Therefore, nonlinear probability weighting can shift the difference in valuation in favor of either one of the options, and increase the probability of that option being chosen according to CPT.


Linking Attentional Weighting and Probability Weighting: Predictions
In the previous section, we highlighted that both attentional biases in sequential sampling and nonlinear probability weighting can selectively modulate the subjective attractiveness of a risky option relative to that of a safe option. In the aDDM, attending more to a safe (risky) option increases the probability of choosing this option, even if it is objectively inferior. In CPT, choice biases in favor of a safe (risky) option can be accommodated by assuming nonlinear probability weighting-in particular, a weighting function with a lower (higher) elevation or a weighting function with a more convex/inverse S-shaped (concave/S-shaped) curvature. It is thus possible that, for instance, choice patterns produced by different degrees of attentional biases toward a risky (or safe) option in a sequential sampling process might be reflected by distinctive shapes of CPT's probability-weighting function. More precisely, a greater relative amount of attention to the safe option, and the resulting increase in safe choices predicted by the aDDM, may be reflected in a lower elevation (i.e., higher values on the δ parameter, in the range δ > 1, in Prelec's 1998 weighting function) and in a more convex or more strongly inverse S-shaped curvature (i.e., lower values on the γ parameter, in the range γ < 1, in Prelec's 1998 weighting function). Unbiased attention may be reflected in linear probability weighting, that is, δ = 1 and γ = 1. In what follows, we test these predictions (summarized in 
Table  1
) in simulations and empirical analyses. In Supplemental Material S3, we formulate and test analogous predictions for several other functional forms of the probability-weighting function in CPT.
Before we test the link between attentional weighting in the aDDM and probability weighting in CPT, we should note that a shift in preferences for a safe over a higher-valued risky option due to attentional biases might, in principle, also be captured by CPT's value function, v. However, since v always affects the valuation of both options (unless x sa f e = 0),  . Risk preference and maximization performance in the choice patterns generated by the aDDM for different levels of the probability of attending to the safe option a t s at each step of the diffusion process. X: corresponding posterior predictive choice behavior predicted from CPT parameters fitted to data generated by the aDDM.
it does not modulate the relative attractiveness of a safe versus a risk option as selectively as the probability-weighting function does. Moreover, the commonly assumed concave value function (with α in the range [0,1]) cannot capture preferences for a risky option over a higher-valued safe optionthat is, it cannot accommodate the behavioral consequences of attentional biases toward the risky option. Therefore, we focus primarily on the potential link between probability weighting and attentional biases. We nevertheless also investigated the potential link between attentional biases and the value function; the results are reported below.


Simulation Study on Choices Between a Safe and a Risky Option
To test the hypothesized link between attentional biases and probability weighting, we used the aDDM to generate data for choice problems consisting of a safe and a risky option. This procedure was repeated assuming various levels of attentional bias (i.e., various settings of the probability of attending to the safe rather than the risky option, a t s , at each time step). We then estimated CPT parameters for the simulated choices, separately for each level of attentional bias, using a hierarchical Bayesian implementation of CPT with 
Prelec's (1998)
 two-parameter weighting function.


Methods
Choice problems. We used the following procedure to construct 150 pairs of a safe and a risky option: The outcomes of the risky option, x i,risky , were drawn from a uniform distribution ranging from 0 to 10, and rounded to 2 digits. The probability, p high , of the higher outcome of the risky option was sampled from a uniform distribution ranging from 0.01 to 0.99, and the probability of the lower outcome was set to p low = 1− p high . All safe options consisted of one outcome,
x sa f e , that occurred with certainty (p sa f e = 1). This outcome was drawn from a uniform distribution ranging from the smaller to the larger risky outcome of the same choice problem, and rounded to 2 digits. This approach served to prevent dominated options (i.e., options where all outcomes of one option were smaller than all outcomes of the other option).
Data generation. We generated data with the aDDM and systematically varied the probability, a t s , of attending to the safe option at each step-that is, the attentional bias in the generative process-from .1 to .9 in increments of .1. To increase the resolution for moderate levels of attentional bias, we added two additional levels for a t s in the mid-range (at .45 and .55), resulting in a total of 11 levels of attentional bias. The parameter θ was set to 0.5, such that evidence for each option accumulated at half the speed when it was unattended to (versus attended to). Because θ can, in principle, assume values in the range [0, 1], this constitutes a moderate level of attentional amplification. The noise parameter, σ, was set to 0.075. In Supplemental Material S1, we show that varying θ < 1 and σ does not affect the occurrence or direction of attentional effects on choice; they merely become more or less pronounced. For each level of a t s , choices of 100 synthetic participants for all 150 pairs of gambles were simulated, resulting in 11 data sets with 100×150 = 15, 000 choices each.
Modeling the choices with CPT. Each of the 11 data sets was modeled separately in a hierarchical Bayesian implementation of CPT, with γ and δ as free parameters of the two-parameter probability-weighting function by 
Prelec (1998)
, and α and ρ as free parameters of the value function and the logit choice rule, respectively. To guard against commonly observed parameter interdependencies between α   
Figure 5
. Parameter estimates and probability-weighting functions 
(Prelec, 1998)
 fitted to data generated by the aDDM with varying levels of attentional bias to the safe option. The color gradient represents the probability of attending to the safe option at each step in the diffusion process. As can be seen, a greater attentional bias to the safe option (darker colors) is associated with a less elevated and more extremely curved weighting function, indicating that risky options appear less attractive. Error bars represent 95% posterior intervals.
and ρ (Krefeld-Schwalb, Pachur, & Scheibehenne, in press), we retransformed the options' subjective valuations to the outcome scale before subjecting them to the choice rule, as suggested by 
Stewart, Scheibehenne, and Pachur (2018)
. We supplied the relative frequency of each outcome (in the set of outcomes sampled as evidence in the aDDM on each trial; see Equations 6 and 7) as probability information to CPT. This procedure takes into account that the relative frequencies of the outcomes in the samples drawn by the aDDM can deviate nonsystematically from the outcomes' objective probabilities, due to sampling error. This could lead to apparent distortions in probability weighting (which are not due to attentional biases) if CPT were estimated using the objective probabilities. Estimating CPT using the relative frequencies instead guards against such (non-attentional) distortions. In the hierarchical model, parameters were estimated for each synthetic participant, and these individual-level parameters were assumed to be drawn from a group-level distribution, spanning all synthetic participants in a condition. To make inferences about how the attentional biases implemented in the aDDM were accommodated by CPT, we used the group-level posterior estimates for the weighting function parameters γ and δ. We ran 40 chains of 110,000 samples each, with an initial burn-in period of 10,000 samples. The potential scale reduction factor 
(Gelman & Rubin, 1992)
 wasR ≤ 1.01 for all estimated parameters, indicating good convergence.


Results
Choice patterns resulting from attentional biases. We first describe how the attentional biases simulated in the aDDM affected the resulting choice behavior, in terms of both behavioral risk preferences (i.e., the tendency to choose the safe option) and maximization performance (i.e., the tendency to choose the option with the higher EV). As displayed in the left panel of 
Figure 4
, the proportion of safe (risky) choices increased with the attentional bias toward the safe (risky) option. The proportion of choices of the option with the higher EV decreased with increasingly extreme attentional biases, regardless of whether the bias was toward the safe or the risky option (see right panel of 
Figure 4
). That is, maximization performance was highest when attention was distributed equally across both options (i.e., when a t s = .5), and decreased when attention was biased toward either the risky or the safe option. Remember that in the absence of attentional biases, the aDDM can implement an optimal SPRT. In other words, introducing attentional biases impairs maximization performance because the probability of choosing the option that receives more attention increases, irrespective of whether it is objectively better.
How closely does CPT accommodate choices generated by the aDDM? First, we inspected how well CPT, when used to model the data, captures the behavioral regularities produced by the aDDM. To this end, we conducted posterior predictive checks examining how well choices based on the posterior mean group-level estimates of CPT's parameters coincided with the choices generated based on the aDDM. As can be seen in 
Figure 4
, CPT closely reproduced the qualitative patterns generated by the aDDM. However, the match is not perfect, especially in terms of risk preference (i.e., choice of the safe option, see 
Figure 4
). Specifically, choice biases produced due to attentional biases in the aDDM in terms of risk preference were less pronounced in PROBABILITY WEIGHTING AND ATTENTIONAL BIAS 11 CPT than in the aDDM. Next we analyze how parameters of probability weighting capture the behavioral consequences of attentional biases in the aDDM.
How does CPT's weighting function accommodate attentional biases? How does CPT's probability-weighting function reflect the choice patterns generated based on different levels of attentional bias in the aDDM? 
Figure 5
 shows the means and 95% posterior intervals of the posterior distribution of δ and γ for each level of attentional bias in the generative process, as well as the resulting weighting functions. Attention allocation in the aDDM was systematically reflected the shape of the weighting function. Unbiased attention (i.e., a t s = .5) was reflected in linear probability weighting-that is, a neutral elevation (i.e., δ of approx. 1) and a neutral curvature (i.e., γ of approx. 1). Increasing attentional biases toward the risky option (a t s < .5) were reflected in lower values of δ (in the range δ < 1), and higher values of γ (in the range γ > 1). Increasing attentional biases toward the safe option (i.e., a t s > .5) were reflected in higher values of δ (in the range δ > 1), and lower values of γ (in the range γ < 1). In other words, stronger attentional biases toward the safe option were associated with less elevated and more convex weighting functions; stronger attentional biases toward the risky option were associated with more elevated and more concave weighting functions. These findings are consistent with our predictions 
(Table 1)
: they establish that the effects of attentional biases on choice, predicted by the aDDM, can be reflected in patterns in probability weighting in CPT.
How do the other parameters in CPT reflect the attentional biases? Thus far, we have focused on CPT's probability-weighting function. We next examine whether and how attentional biases in aDDM also affected the estimates for the outcome sensitivity parameter, α, of CPT's value function and the choice sensitivity parameter, ρ, of the logit choice rule. The results are shown in 
Figure 6
.
Outcome sensitivity. Lower values of the α parameter, that is, more concave value functions for gains in CPT, are typically linked to greater risk aversion (i.e., a higher tendency to choose the safe option). Thus, the greater tendency to choose the safe option under attentional biases toward the safe option in the aDDM may be reflected in lower values of α. As it turns out, however, choice patterns generated by the aDDM with increasing attention paid toward the safe option were reflected in higher (rather than lower) values of α. 8 As elaborated in Supplemental Material S5, this perhaps surprising result is attributable to interactive effects of the parameters α and δ on the likelihood of the aDDM data under CPT. Moreover, because the estimates of α for data generated by the aDDM with attentional biases toward the safe option approach the upper bound of α = 1 (see 
Figure 6
), we extended the range of α from 0 to 2 in additional analyses. The  
Figure 6
. Association between attention allocation, a t s , and the parameters α and ρ when modeling choice data generated by the aDDM with CPT. Error bars represent 95% posterior intervals.
resulting patterns of parameter estimates were qualitatively similar to those obtained for the more narrow range, and are reported in Supplemental Material S6. Importantly, the patterns in probability weighting remained the same when the range of α was extended.
Choice sensitivity. Under lower values of the ρ parameter of the logit choice rule (see Eq. 9) choice behavior is more random, that is, the probability of choosing the safe option is closer to 50%. All else being equal, ρ might thus be lower given less extreme attentional biases (toward either option), because the proportion of safe choices in the aDDM is also closer to 50% given less extreme attentional biases (see 
Figure 4
). As shown in 
Figure 6
, however, the ρ parameter did not vary systematically as a function of different levels of attentional bias in the generative process.


Simulation Study on Choices Between Two Risky Options
We next extend the analyses of the link between attentional biases in the aDDM and probability-weighting func- 
8
 In light of this counterintuitive finding, the question arises as to whether CPT was able to appropriately accommodate the choice behavior generated by the aDDM. We conducted further analyses to address this concern. We used posterior predictive choice behavior, generated with CPT using the posterior estimates of all parameters (including α) for each level of attentional bias in the aDDM, and determined the best-fitting value of aDDM's attentional bias parameter for this data. Supplemental Material S4 provides details on these analyses. The results show that the qualitative patterns in the generative attentional bias were recovered well: data sets generated based on CPT's posterior estimates for stronger attentional biases to the safe (risky) option also yielded stronger recovered attentional biases to the safe (risky) option. Quantitatively, the recovered attentional bias overall tended to be less pronounced than the corresponding generative attentional bias. This is a consequence of the previously discussed finding that CPT cannot perfectly match the aDDM in terms of risk preference (see 
Figure 4)
.  
Figure 7
. Preference for the option whose most attractive outcome is more likely (ML option) and maximization performance in the choice patterns generated by the aDDM for different levels of the probability of attending to the ML option a t ml at each step of the diffusion process. X: corresponding posterior predictive choice behavior predicted from CPT parameters fitted to data generated by the aDDM.
tions in CPT to choices between two risky options, each offering two distinct probabilistic gain outcomes. Can a mapping between attentional biases and probability weighting also be established for such problems?
In the context of choice problems offering a choice between two risky options, we refer to the risky option that offers the higher outcome with a higher probability as the "more likely" (ML) option, and to the other option as the "less likely" (LL) option. Supplemental Material S2 quantifies how the probability-weighting function distorts the attractiveness of the ML option relative to the LL option across various combinations of the parameters γ and δ. A key result of these analyses is that the impact of the elevation parameter on the relative attractiveness of options is relatively small in this problem type because it affects the weighting of most probabilistic outcomes in the same direction and to a similar degree. Instead, the curvature parameter now plays a central role. For instance, an inverse S-shaped weighting function can increase the attractiveness of a risky option in which p high is relatively low and at the same time decrease the attractiveness of a risky option in which p high is relatively high. An S-shaped probability-weighting function has the opposite effects. In other words, higher values on γ (that lead to a more concave/S-shaped weighting function) tend to amplify the attractiveness of the ML option relative to the LL option more strongly than lower values on γ (that lead to a more convex/inverse S-shaped weighting function). Therefore, preference patterns that emerge when the probability of attending to the ML option, a t ml , in the aDDM is manipulated may be reflected by systematic patterns in probability weighting. Most importantly, stronger attentional biases toward the ML option over the LL option may be reflected in higher values on the curvature parameter γ, that is, more strongly concave/S-shaped probability-weighting functions.
To test this prediction, we conducted a cross-theory simulation analysis similar to the one for choices between a risky and a safe option, but now involving 150 choices between two risky options. In the generative process (i.e., the aDDM), the relative attention paid to the ML option was systematically varied. The resulting choices were then again modeled with CPT.


Methods
Choice problems. We used the following procedure to construct 150 pairs of two risky options: For each option, both risky outcomes were drawn from a uniform distribution ranging from 0 to 10, and rounded to 2 digits. The higher outcome in each option is labelled x high and the lower outcome x low . Each probability, p high , of the higher outcome was drawn from a uniform distribution ranging from 0.01 to 0.99, and the probability of the lower risky outcome was defined as p low = 1 − p high in each option. We eliminated problems with dominated options (i.e, in which both outcomes of one option were smaller than the other option's outcomes). We also eliminated pairs in which both options had equal probabilities p high , where the labels ML and LL option cannot be assigned. We randomly generated choice problems in this manner until we had obtained 75 problems in which the LL option had the higher EV, and 75 problems in which the ML option had the higher EV.
Simulation and modeling. Using the aDDM, we generated data on these choice problems for 100 synthetic participants and varied the attentional bias toward the ML option (i.e., the probability of attending to the ML option, a t ml , at Attention to ML Option a t ml Posterior Mean 95% PI 
Prelec (1998)
 
Figure 8
. Parameter estimates and weighting functions for 
Prelec's (1998)
 two-parameter weighting function for different levels of the probability of attending to the option whose most attractive outcome is more likely (ML option), a t ml , in choices between two risky options. The color gradient represents the probability of attending to the ML option at each time step. Darker colors represent a greater attentional bias to the the ML option. Error bars represent 95% posterior intervals. each time step) across different conditions. We then applied a hierarchical Bayesian implementation of CPT to the choices, following the same procedures as for the analyses for choices between a safe and a risky option.


Results
We first describe the impact of attentional biases in the aDDM on choice behavior, both in terms of choosing the ML option and in terms of maximization performance (see 
Figure  7)
. As expected, the proportion of choices of the ML option increased with the attentional bias toward this option. Further, an increasingly extreme attentional bias, irrespective of whether it was toward to the ML or the LL option, decreased the proportion of choices of the option with the higher EV (i.e, decision quality). Hence, in terms of choice behavior, attentional biases in the aDDM had similar effects in choices between two risky options as in choices between a safe and a risky option.
We also inspected how well CPT, when used to model the different data sets, captured the behavioral regularities produced by the aDDM, based on posterior predictive checks using the group-level CPT parameters. As 
Figure 7
 shows, CPT again reproduced the qualitative patterns generated by the aDDM relatively well. However, in terms of both preference for the ML option and decision quality, CPT cannot perfectly accommodate the aDDM's behavior, especially for data sets generated with strong attentional biases toward the ML option. This incapacity of CPT to perfectly accommodate the aDDM's behavior for strong attentional biases toward the ML option may be due to the estimates of the parameter γ approaching the upper bound under strong attentional biases toward the ML option (details below).
How did the parameters of CPT's weighting function re-flect attentional biases in choices between two risky options? 
Figure 8
 shows the means and 95% posterior intervals of the posterior distribution of γ and δ for the two-parameter weighting function by 
Prelec (1998)
 and for each level of attentional bias in the generative process, as well as the resulting weighting functions. A more pronounced attentional bias, a t ml , toward the ML option was reflected in higher values on the curvature parameter γ and the elevation parameter δ (although only a relatively small range of values of δ was covered). Note that for strong attentional biases toward the ML option, the curvature parameter γ approaches its upper bound. This ceiling effect may explain the limited capacity of CPT to accommodate the aDDM's behavior when attention is strongly biased toward the ML option (see posterior predictive checks reported earlier). Overall, a more pronounced attentional bias a t ml toward the ML option was reflected in a (slightly) less elevated and more strongly S-shaped weighting function.


Interim Summary
Overall, the results of the cross-theory simulation analyses show that option-specific attentional biases are linked to systematic signatures in probability weighting. Importantly, the relative importance of the two key constructs of CPT's weighting function-the elevation and the curvature-in reflecting different degrees of attentional bias depends on the type of choice problem used. In choices between a safe and a risky option, the elevation plays a key role for accommodating option-specific attentional biases. In choices between two risky options, by contrast, the curvature parameter becomes more important for accommodating preference shifts resulting from attentional biases to the ML option vs. the LL option.
It is important to note that the considerations above and in Supplemental Material S2 focus on cases where attention is biased in the same direction and to the same degree across all choice problems in the choice set. When attention allocation instead differs in systematic ways between choice problems in a choice set, the preference patterns generated by the aDDM can give rise to yet other signatures in probability weighting. Supplemental Material S7 reports further analyses for a situation in which attention allocation is a function of the probability, p high , of the risky option (and hence differs between problems in the choice set). In this case, the aDDM gives rise to (inverse) S-shaped probability-weighting functions in choices between a safe and a risky option-in contrast to the previously reported analyses for choices between a safe and a risky option, which yielded purely convex or purely concave probability-weighting functions.


Are Attentional Biases Also Empirically Linked to
Probability Weighting?
Thus far, we have made a purely theoretical argument: Attentional biases implemented in the aDDM have highly systematic signatures in CPT's probability-weighting function. Does this link also hold empirically? In other words, are attentional biases to options in empirical risky choice behavior also reflected in distinct shapes of the probabilityweighting functions obtained when modeling empirical data with CPT? To address this question, we used data from the sampling paradigm, which is often used to study decisions from experience (e.g., 
Hertwig & Erev, 2009)
. In the sampling paradigm, participants are asked to choose between two options whose payoff distributions are initially unknown. They can sample outcomes from the payoff distributions for as long as they like before making a consequential choice. Recording participants' sampling behavior in this paradigm makes it possible to measure the relative amount of attention that people pay to the available options before making a choice. We test whether option-specific attentional biases during sampling, measured in terms of the proportion of samples drawn from each option on each trial, have systematic signatures in CPT's weighting function when the choices are modeled with CPT-and whether such potential patterns converge with those identified in the simulations.
Note that our main goal here is not to establish a comprehensive theoretical account of behavior in the sampling paradigm (for such an attempt, see 
Markant, Pleskac, Diederich, Pachur, & Hertwig, 2015)
. The key objective is to test whether attentional biases to an option are systematically linked to behavior and probability weighting in decisions from experience. Although several theoretical accounts of decisions from experience have been proposed in the literature (e.g., C. 
Gonzalez & Dutt, 2011;
Plonsky, Teodorescu, & Erev, 2015)
, the impact of option-specific attentional biases in sampling on preferences has not yet been investigated. This illustrates that our approach of building bridges between two theoretical frameworks that have developed separately and are usually treated as competing accounts can foster novel ideas that may otherwise be difficult to formulate. We return to this point in the Discussion.


Choices Between a Safe and a Risky Option
Linking attentional biases and choice. We used data from the free sampling paradigm that were compiled by 
Wulff et al. (2018)
. For comparability with the results of the cross-theory simulation analysis, we first analyzed trials from the domain of gains in which one option was experienced as safe and the other as risky (such that two distinct outcomes were experienced). 9 In total, these analyses included 5,794 sampling sequences and choices from 1,230 participants.
For each trial, we computed the experienced probabilities of the different outcomes of each option and the proportion of samples from the safe option relative to the total number of samples. This proportion served as a measure of attentional bias to the safe versus the risky option. 
Figure  9A
 shows that although on many trials participants allocated their attention evenly to the safe and the risky option, there was considerable variability in attention allocation, ranging from a strong attentional bias to the risky option to a strong attentional bias to the safe option. For each level of attentional bias (rounded to 2 digits), we calculated the proportion of trials in which the safe option was chosen. As 
Figure 9C
 shows, a greater proportion of samples drawn from the safe option was associated with a higher probability of the safe option being chosen. To statistically corroborate this association, we conducted a Bayesian mixed-effect logistic regression (using the rstanarm package in R; Goodrich, Gabry, Ali, & Brilleman, 2018), with the choice of the safe option in each trial as the dependent variable. The model included a fixed effect for the proportion of samples from the safe option in each trial, a fixed effect for the difference in experienced EVs (i.e., observed average payoff) between the safe and the risky option, and random intercepts for each participant and article (i.e., the articles included in the meta-analysis by 
Wulff et al. (2018)
). The analysis showed a credible effect of attentional bias on choice. The stronger the attentional bias to the safe option, the more likely that option was chosen (β = 0.803, 95% PI [0.357; 1.247]). A larger difference in experienced EV between the safe and the risky option was positively linked to the tendency to choose the safe option (β = 0.011, 95% PI [0.010; 0.013]). That is, the more the experienced EV of the safe option exceeded that of the risky 
Figure 9
. Empirical sampling and choice behavior in the sampling paradigm (data compiled by 
Wulff et al. (2018)
). (A) Distribution of attentional biases (measured as proportion of samples from the safe option) for choices between a safe and a risky option. (B) Distribution of attentional biases (measured as proportion of samples from the ML option) for choices between two risky options. (C) Proportion of safe choices (Mean ± 1SEM) as a function of the attentional bias to the safe option in choices between a safe and a risky option. (D) Proportion of ML choices (Mean ± 1SEM) as a function of the attentional bias to the ML option in choices between two risky options. option, the more likely people were to choose the safe option.
Linking attentional biases and probability weighting. We used a hierarchical Bayesian implementation of CPT to model the empirical choices, using the two-parameter probability-weighting function by 
Prelec (1998)
. As probabilities of the outcomes, we supplied to CPT the relative frequencies of the outcomes experienced by participants during sampling (analogous to the modeling of the simulated data, where the relative frequencies of outcomes sampled in the aDDM were used). The trial-level CPT parameters were allowed to covary with the empirically measured attentional bias X bias,s,i in each trial, i, and in each subject, s. X bias,s,i is the proportion of samples from the safe option in each trial. Hence X bias,s,i > 0.5 indicates an attentional bias toward the safe option, X bias,s,i = 0.5 indicates that the both options were sampled equally often, and X bias,s,i < 0.5 indicates an attentional bias toward the risky option. For instance, the trial- 
Figure 10
. (A) Results of the modeling of empirical choices between a safe and a risky option in the sampling paradigm. The left and middle plot display parameter estimates for the probability-weighting functions for different levels of attentional bias toward the safe option in empirical sampling sequences. Gray dots represent trial-level posterior mean estimates for γ and δ. Colored dots represent the average (across trials) estimates for each level of attentional bias. The right plot displays probability-weighting functions for different levels of attentional bias toward the safe option in empirical sampling sequences. Each probability-weighting function is based on the average trial-level estimates of γ and δ for the respective level of attentional bias. (B) Results of the modeling of empirical choices between two risky options in the sampling paradigm. The left and middle plot display parameter estimates for the probability-weighting functions for different levels of attentional bias toward the ML option in empirical sampling sequences. Gray dots represent trial-level posterior mean estimates for γ and δ. Colored dots represent the average (across trials) estimates for each level of attentional bias. The right plot displays probabilityweighting functions for different levels of attentional bias toward the ML option in empirical sampling sequences. Each probability-weighting function is based on the average trial-level estimates of γ and δ for the respective level of attentional bias.
level elevation parameter δ i,s was defined as
δ i,s = β intercept,s,δ + β attention,s,δ * X bias,s,i ,
(12)
where β intercept,s,δ is a subject-specific intercept and β attention,s,δ is a subject-specific slope for the effect of X bias,s,i on the elevation parameter. The parameters γ i,s , α i,s , and ρ i,s were defined in an analogous manner. 10 The subject-specific intercepts and slopes were informed by article-level distributions (of the individual articles included in the meta-analysis by 
Wulff et al., 2018)
, which were in turn informed by a toplevel distribution across all articles. This structure allowed the trial-level parameter estimates to covary with the attentional bias in each trial, thus permitting the model to accommodate the hypothesized link between attentional bias and the shape of CPT's probability-weighting function. It is important to emphasize that this model structure does not enforce, but merely measures, a potential association between attentional bias and parameters of CPT. If the data do not provide evidence for such an association, the estimated parameters will not indicate an association; specifically, the slopes linking the respective CPT parameter to the attentional bias will not differ credibly from zero. In light of the results of the cross-theory simulation analysis, we hypothesized that γ and δ would be systematically associated with attentional biases in sampling. We did not hypothesize such an association for α and ρ. We ran 40 chains of 100,000 samples each, with an initial burn-in period of 10,000 samples that were discarded from analysis. The potential scale reduction factor wasR ≤ 1.01 for all estimated parameters, indicating good convergence.
How does the probability-weighting function reflect empirical attentional biases in sampling behavior? 
Figure 10A
 shows the trial-level posterior estimates for the probabilityweighting parameters γ and δ as a function of the proportion of samples from the safe option on each trial, as well as the resulting weighting functions. As can be seen, there was a clear association between attentional biases in sampling and the probability-weighting parameters. In addition, the association was highly similar to the results of our simulation analyses (see 
Figure 5
). Specifically, unbiased samplingthat is, an equal number of samples from the safe and the risky option-was associated with linear probability weighting (i.e., γ and δ of approx. 1). A stronger attentional bias to the safe option was associated with increases in δ, indicating a lower elevation, and with lower values of the curvature parameter, γ. No such systematic association was observed between attentional biases and the parameter ρ. A very slight positive relationship (similar in direction but less extreme than that in the simulations) was observed between attentional biases and the parameter α (see Supplemental Material S9).


Choices Between Two Risky Options
We also analyzed empirical data for trials from the domain of gains in which both options were experienced as risky (such that two distinct outcomes were experienced). In the context of these analyses, we again distinguished between an ML option and an LL option (defined as above). We investigated whether more attention paid to the ML option during sampling is linked to the tendency to choose the ML option, and to systematic patterns in probability weighting. We used the same methods as for the empirical analyses on choices between a safe and a risky option.
Linking attentional biases and choice. We again drew on data from the sampling paradigm compiled by 
Wulff et al. (2018)
, this time using trials on which two distinct outcomes were experienced for each option, and on which the experienced probability of the more attractive outcome differed be-tween the options (making it possible to specify the ML/LL option). In total, this analysis included 9,815 sampling sequences and choices from 966 participants. We determined the proportion of samples from the ML option relative to the total number of samples on each trial as a measure of attentional bias.
As 
Figure 9B
 shows, although on many trials participants attended evenly to the ML and the LL option, there was considerable variability in attention allocation, ranging from strong attentional biases to the LL option, to balanced attention allocation, to strong attentional biases to the ML option. These patterns are similar to those observed for choices between a safe and a risky option. As 
Figure 9D
 shows, a stronger attentional bias to the ML option was associated with a higher probability of that option being chosen. To statistically corroborate this association, we conducted a Bayesian mixed-effect logistic regression in the rstanarm package in R 
(Goodrich et al., 2018)
, with the choice of the ML option in each trial as the dependent variable. The model included a fixed effect for the proportion of samples from the ML option in each trial, a fixed effect for the difference in experienced EVs (i.e., observed average payoff) between the ML and the LL option, and random intercepts for each participant and article (i.e., the articles included in the meta-analysis by 
Wulff et al. (2018)
). The analysis showed a credible effect of attention allocation on choice. The higher the proportion of samples drawn from the ML option, the more likely that option was chosen (β = 1.494, 95% PI [1.162; 1.817]). That is, option-specific attentional biases were also linked to choices between two risky options. There was a credible and positive link between a higher difference in experienced EV between the ML and the LL option and the tendency to choose the ML option (β = 0.007, 95% PI [0.006; 0.008]).


Linking attentional biases and probability weighting.
To investigate the link between attention allocation and probability weighting, we modeled the data from choices between two risky options with CPT. The hierarchical structure of the model was analogous to that for choices between a safe and a risky option-only this time, the empirically measured attentional bias, X bias,s,i , was the proportion of samples from the ML option (rather than safe option) in each trial. 
Figure 10B
 shows the trial-level posterior estimates for the probabilityweighting parameters γ and δ as a function of the proportion of samples from the ML option on each trial, as well as the resulting weighting functions. As can be seen, there was again a clear association between attentional biases in sampling and the probability-weighting parameters. This association is qualitatively similar to the results of our simulation analyses (see 
Figure 8)
. Specifically, stronger attentional biases were associated with higher values on the curvature parameter γ and the elevation parameter δ. Note in 
Figure 10B
 that there are two clusters of trial-level param-eter estimates for γ (depicted in grey). This heterogeneity is accommodated by the model's random effects structure. In the larger cluster, stronger attentional biases were associated with higher values on the curvature parameter γ, as predicted by the simulations. Also note that the mean value of γ under unbiased attention does not exactly equal 1. This suggests that in empirical data, imbalances in attention do not explain nonlinear probability weighting completely, but that nonlinearities in probability weighting may exist even in the absence of attentional biases. Importantly, there is a positive association between attention and both γ and δ in this type of choice problem, consistent with the simulations in the aDDM. By converging in these central aspects with findings from the simulations, these empirical analyses for choices between two risky options provide further evidence for our core thesis that patterns in probability weighting can systematically reflect the consequences of attentional biases.
These analyses underline that the signatures of attentional biases in probability weighting patterns differ considerably between problems offering a safe and a risky option, and problems offering two risky options. In empirical analyses the experienced features of a choice problem may depend on chance events in the sampling history (e.g., whether a rare event is experienced). Therefore, even given the same ground truth choice problem, different parameter estimates can result, depending on stochastic events in sampling. Notably, the current analyses can help to predict differences in how attentional biases to the (objectively) same option may be reflected in the parameter estimates of CPT, if a choice problem happens to be experienced as offering a safe and a risky option, versus two risky options.


Linking Probability Weighting and Response Times


Simulation-Based Analyses
In establishing a link between the aDDM and CPT, we have focused on the level of choice behavior. Notably, however, the aDDM also predicts response times (RTs), which can be measured in terms of the number of steps in the diffusion process until a boundary is hit. Specifically, as shown in 
Figure 11A
 (for choices between a safe and a risky option) and in 
Figure 11C
 (for choices between two risky options), increasingly extreme attentional biases lead to faster predicted RTs, irrespective of the direction of the bias. This is because increasingly extreme attentional biases entail stronger preferences, that is, a faster drift towards the predominantly attended option. Therefore, the link between attentional biases in the aDDM and patterns of probability weighting in CPT also provides a foundation for exploring potential connections between probability-weighting patterns and qualitative patterns in RTs. 
Figures 11B and  11D
 plot the mean RTs for each level of attentional bias in the cross-theory simulation analysis (for choices between a safe and a risky option and for choices between two risky options, respectively) against the posterior mean parameter estimates for the probability-weighting function parameters. The longest RTs (resulting from unbiased evidence accumulation processes) were associated with linear probability weighting-that is, parameter estimates for γ and δ approximating 1. Conversely, faster RTs (resulting from more biased evidence accumulation processes and hence, stronger preferences) tended to be associated with stronger distortions in probability weighting (γ 1 and δ 1). Together, this yields an inverse U-shaped link between each probability-weighting parameter and RT. That is, although CPT itself makes no predictions about RTs, the connection to the aDDM suggests specific hypotheses regarding a possible link between CPT's probability-weighting functions and RT patterns.


Empirical Analyses
Do the associations between probability weighting and RT via attentional biases suggested by the aDDM also hold empirically? To address this question, we analyzed data from two eye-tracking studies by 
Fiedler and Glöckner (2012)
, which contain information on both attention allocation and time stamps. 11 In these experiments, participants' eye movements were recorded (see the original article for details on eye-tracking) while they made choices between two options on each trial. The possible outcomes and their probabilities were numerically described on the screen. The choice problems consisted of two risky options, each with two possible outcomes and associated probabilities (except for one problem in each study containing safe options). In our analyses, we focused on those trials where an ML option could be identified. We thus excluded trials where p high was identical in both options and the single problem offering safe options. As a measure of option-specific attention allocation, we calculated the proportion of time that each participant spent fixating on the area of interest (AOI) corresponding to the ML option relative to the total time spent fixating on any AOI. As a measure of RT, we calculated the total time spent fixating on any option's AOI.
Behavioral analyses. As 
Figure 12
 shows, participants in both studies displayed a wide range of patterns of attention allocation ( 
Figure 12A
 for Study 1; 
Figure 12B
 for Study 2). Moreover, 
Figure 12
 shows that stronger attentional biases to the ML option were associated with a higher tendency to choose this option ( 
Figure 12C
 for Study 1; 
Figure 12D
 for Study 2). This was statistically corroborated in a Bayesian mixed-effect logistic regression with the choice of the ML option in each trial as the dependent variable. The model included a fixed effect for proportion of time spent attending to the ML option in each trial, a fixed effect for the difference in EVs between the ML and the LL option, and random intercepts for each participant. The positive effect of atten-  
Figure 11
. The link between attention allocation in the aDDM, RTs, and parameters of probability weighting. The color gradient represents the probability, a t s , of attending to the safe option at each step, t, in the aDDM. Darker colors represent more attention paid to the safe option. Error bars on RTs represent 95% confidence intervals. Error bars on parameter estimates represent 95% posterior intervals. (A) RTs simulated in the aDDM in choices between a safe and a risky option, for different levels of attentional biases. (B) Association between RTs generated in the aDDM in choices between a safe and a risky option and parameter estimates for the curvature, γ, and the elevation, δ, resulting from modeling aDDM data with CPT. (C) RTs simulated in the aDDM in choices between two risky options, for different levels of attentional biases. (D) Association between RTs generated in the aDDM in choices between two risky options, and parameter estimates for the curvature, γ, and the elevation, δ, resulting from modeling aDDM data with CPT. tion allocation on choice was credible (β = 2.788, 95% PI [1.932; 3.663] in Study 1; β = 2.505, 95% PI [1.827; 3.214] in Study 2). Although the effect of EV difference was not credible in Study 1 (β = −0.118, 95% PI [−0.718; 0.434]), a larger difference in EV between the ML and the LL option was credibly and positively linked to the tendency to choose the ML option in Study 2 (β = 0.940, 95% PI [0.815; 1.073]). That is, the more the EV of the ML option exceeded that of the LL option in Study 2, the more likely people were to choose the ML option.
Modeling with CPT. The choices were modeled with CPT, again allowing the trial-level probability weighting parameters to covary with the attentional bias, this time measured on the basis of gaze data. Data from Study 1 and Study 2 by 
Fiedler and Glöckner (2012)
 were modeled separately. As can be seen in 
Figure 13A
 (for Study 1) and 
Figure 13B
 (for Study 2), there was a clear link between attentional bias and the curvature parameter, γ, in the same direction as in the cross-theory simulation analysis for choices between two risky options. There was no such link between attentional bias and δ. This is consistent with the earlier notion that δ plays a comparably unimportant role in accommodating attentional biases in choices between two risky options. Moreover, the estimates for δ under unbiased attention did not exactly equal 1, indicating that probability weighting was not perfectly linear in the absence of attentional biases. This is more evident in Study 1 than Study 2, likely reflecting differences between the two samples of participants.
Next, we turn to the RTs: Is there evidence that atten- tional biases and probability weighting are linked to RTs, as suggested by our simulation analyses linking the aDDM and CPT? 
Figure 14
 displays the link between attention allocation and RT ( 
Figure 14A
 for Study 1; 
Figure 14C
 for Study 2). As can be seen, there was an inverse U-shaped link between attentional bias and RT, similar to that observed in the simulations (see 
Figure 11)
: In both studies, balanced attention allocation was linked to relatively slow RTs, whereas stronger attentional biases were linked to faster RTs. How do these patterns relate to the parameter estimates of the probability-weighting function? In 
Figure 14B
 (for Study 1) and 
Figure 14D
 (for Study 2), the mean RT for each level of attention allocation (i.e., proportion of time fixating on the ML option, rounded to 2 digits) is plotted against the mean of the posterior trial-level estimate of γ (or δ) for the same level of attention allocation. Consistent with the patterns obtained in the simulations, there was an inverse U-shaped association between RT and the curvature parameter, γ, in both studies.
Even the color gradient closely resembles that in 
Figure 11
, indicating that the relationships between attention, the curvature γ, and RTs closely resemble those predicted by the simulations. Note that analogous to the simulations, increasingly extreme attentional biases tend to be linked to stronger preferences, which entails faster responses and is reflected in more extreme probability weighting patterns. However, the inverse U-shape predicted by the simulations did not emerge for the elevation parameter, δ. This is because attention was less systematically linked to the δ parameter than to the γ parameter in the empirical data.
In sum, these analyses show that mapping aDDM and CPT onto each other reveals another previously overlooked dimension on which probability weighting is, at least to some extent, linked with cognitive processing, namely in terms of RTs. 
Figure 13
. Results of modeling the data from (A) Study 1 and (B) Study 2 by 
Fiedler and Glöckner (2012)
 with CPT. The leftmost and middle plots display parameter estimates for the probability-weighting functions for different levels of attentional bias toward the ML option in empirical gaze data. Gray dots represent trial-level posterior mean estimates for γ and δ. Colored dots represent the average (across trials) estimates for each level of attentional bias. The rightmost plots display the corresponding probability-weighting functions for different levels of attentional bias toward the ML options. Each probabilityweighting function is based on the average trial-level estimates of γ and δ for the respective level of attentional bias.


Choices in the Loss Domain
The choice problems considered thus far have involved gain outcomes only. Do the results regarding the mapping between attentional bias in aDDM and probability weighting in CPT generalize to the domain of losses? Supplemental Material S10 reports a cross-theory recovery analysis that applies the same methods as employed for the domain of gains to the domain of losses. In the aDDM, attentional biases have opposite effects on preferences in the loss domain than they do in the gain domain. That is, whereas in the gain domain attending more to an option makes this option appear more attractive, in the loss domain attending more to an option makes it appear less attractive (and therefore less likely to be chosen, see 
Figure 15
). This is because attending more to a loss option amplifies the accumulation of negative evidence regarding that option. Importantly, probability weighting also has opposite effects on the modulation of preference in the loss domain than it does in the gain domain. That is, a higher decision weight for the higher absolute outcome of a risky option makes the risky option more attractive in the domain of gains, but less attractive in the domain of losses. For illustration, consider a convex weighting function with a low elevation. This function overweights safe outcomes relative to risky ones, making a safe gain (loss) appear especially attractive (unattractive)-just like attentional biases to a safe gain (loss) make a safe gain (loss) appear especially attractive (unattractive) according to the aDDM. Therefore, the mapping between attentional biases in the aDDM and probability weighting follows the same pattern in the loss domain as in the gain domain. Specifically, the behavioral consequences of paying more attention to the safe option (i.e., an increased tendency to reject safe options) are reflected in lower values on γ and higher values on δ.


Assessing the Overlap Between the aDDM and CPT
We have demonstrated that attention allocation, a key construct in the aDDM, and nonlinear probability weighting, a key construct in CPT, can be systematically linked. Going beyond these specific constructs, in this section we explore 
Figure 14
. (A) RTs in data from Study 1 in 
Fiedler and Glöckner (2012)
, for different levels of attentional bias. (B) Association between RTs in data from Study 1 in 
Fiedler and Glöckner (2012)
 and parameter estimates for the curvature, γ, and the elevation, δ, when the data are modeled with CPT. (C) RTs in data from Study 2 in 
Fiedler and Glöckner (2012)
, for different levels of attentional bias. (D) Association between RTs in data from Study 2 by 
Fiedler and Glöckner (2012)
 and parameter estimates for the curvature, γ, and the elevation, δ, when the data are modeled with CPT. more broadly to which extent the aDDM and CPT overlap as entire formal frameworks-and where they make distinct predictions.


Loss Aversion
Thus far, we have focused on predictions of CPT and the aDDM in pure-domain choice problems (i.e., problems in which all outcomes are either gains or losses). CPT also makes specific predictions for mixed prospects-that is, problems where options offer both potential gains and losses. Specifically, CPT posits loss aversion ("losses loom larger than gains"; 
Kahneman and Tversky, 1979, p. 279)
 in terms of a value function that is steeper for losses than for gains. This implies, for instance, that people will reject the chance to play a mixed gamble with a 50% chance to win an amount x and a 50% chance to lose the same amount x because the loss seems subjectively more important. How does the aDDM handle mixed-domain prospects? In the aDDM, outcomes are weighted based on the attention allocated to the option to which they belong, regardless of their domain. That is, attentional modulation in a mixed gamble affects both outcomes alike. For instance, paying more attention to a mixed gamble implies an overweighting of both its gain outcome and its loss outcome. 12 Therefore, the aDDM in its original form cannot produce loss aversion. This constitutes one divergence between the two frameworks. The aDDM could, however, be modified to produce loss aversion-for instance, by transforming sampled outcomes by a value function that is steeper in the loss than in the gain domain, or by assuming a biased starting point for accumulation (similar to 
Zhao, Walasek, & Bhatia, 2020)
.


How Well Can the aDDM and CPT Accommodate Each Other's Predictions?
The analyses presented thus far have focused primarily on CPT's ability to accommodate behavior generated by the aDDM, and the resulting patterns in CPT's parameters. But  
Figure 15
. Risk preference and maximization performance in the choice patterns generated by the aDDM for different levels of the probability of attending to the safe option, a t s , at each step of the diffusion process for choice problems from the domain of losses. More attention to a safe loss leads to an amplified accumulation of negative evidence regarding this option and results in a reduced tendency to choose this safe loss. Regardless of domain, more extreme attentional biases are associated with decreased maximization performance (i.e., tendency to choose the option with the higher EV). X: corresponding posterior predictive choice behavior predicted from CPT parameters fitted to data generated by the aDDM.
to which extent is the aDDM capable of accommodating CPT's predictions-apart from its inability to produce loss aversion? And can the ability of each model to accommodate the other model's predictions be quantified on a common scale, beyond patterns in particular parameters? To address these questions, we conducted additional analyses inspired by 
He, Zhao, and Bhatia's (2020)
 application of landscaping analysis (see 
Navarro, Pitt, & Myung, 2004)
 that are described in more detail in Supplemental Material S11. These analyses gauge the dissimilarity between the two models by quantifying and minimizing the expected 
Kullback-Leibler (KL)
 divergence 
(Kullback & Leibler, 1951)
 between their predictions about choice behavior across a wide range of parameter settings. The KL divergence measures the (dis-)similarity between probability distributions (in the present case, choice probabilities predicted by each model). Smaller values indicate a higher capacity of one model to accommodate the other model's predictions. Importantly, the measure can be asymmetric (see 
He et al., 2020)
; that is, it can indicate that one model is better able to accommodate the other model's predictions than the other way around.
For both the aDDM and CPT, we generated predicted choice probabilities for various combinations of parameters spanning the entire parameter ranges. 13 For predictions derived using each setting of CPT's parameters, we identified the set of aDDM parameters that minimized the KL divergence to the aDDM's predictions. Conversely, for predictions derived using each setting of aDDM parameters, we identified the set of CPT parameters that minimized the KL divergence to CPT's predictions. We then computed the expected KL divergence across the different parameter settings (for each generative model). The expected minimum (EM) KL divergence for the predictions of CPT under the aDDM was EM CPT,aDDM = 28.78, and the expected minimum KL divergence for the predictions of the aDDM under CPT was EM aDDM,CPT = 38.84. Because EM CPT,aDDM < EM aDDM,CPT , these results indicated that the aDDM is better able to accommodate CPT's predictions than vice versa, suggesting that the aDDM is more flexible than CPT (except for the previously identified issue of loss aversion). More formal details are provided in Supplemental Material S11. The expected KL divergence was not zero in either direction; this means that the aDDM cannot fully absorb any behavior predicted by CPT, or vice versa. Instead, these analyses further underscore that the scope of the two frameworks' predictions is not fully identical. That is, although their constructs can complement each other, it seems unlikely that one framework will render the other superfluous.


Discussion
It is often pointed out that psychological theory is highly fragmented and lacks an overarching framework (see 
Gigerenzer, 2010)
. Others have argued that the replication crisis in psychology (Open Science Collaboration, 2015; Rodgers & Shrout, 2018) is to some extent due to this lack of an overarching theoretical framework 
(Muthukrishna & Henrich, 2019)
. Even within subdisciplines such as decision making research, key constructs are often used and discussed exclusively within their native theoretical framework. For instance, both CPT and the aDDM offer powerful approaches to understanding behavioral regularities in preferential choice, but are usually studied in separation. Our results reveal that their constructs can complement each other. Identifying connections between seemingly disparate theories in this manner can help to gain a richer and more comprehensive understanding of empirical phenomena, and contribute to theory integration. We hypothesized and demonstrated in a cross-theory simulation analysis that the behavioral consequences of attentional biases in choices between a safe and a risky option and in choices between two risky options, as predicted by the aDDM, are reflected in highly systematic patterns in CPT's nonlinear probability-weighting function. We further showed that such links also hold empirically. We also identified a previously overlooked link between attention, probability weighting, and RTs. In these regards, our findings move beyond the common "as-if" view of CPT, according to which the model is mute with regard to the cognitive processes underlying people's decisions. Instead, it is possible to link CPT's constructs to several indicators of information processing (different measures of attention allocation and RT). Finally, we quantified the extent to which the two frameworks can accommodate each other's predictions. What are the broader implications of these results?


Implications for Psychological Interpretations of Probability Weighting
The parameters of CPT's probability-weighting function are often interpreted in terms of psychological constructs, namely, probability sensitivity and optimism/pessimism 
(Abdellaoui et al., 2010;
R. Gonzalez & Wu, 1999;
Kahneman & Tversky, 1979;
Tversky & Kahneman, 1992)
, and used to measure individual differences therein (see 
Abdellaoui et al., 2010;
Booij, Van Praag, & Van De Kuilen, 2010;
Charupat, Deaves, Derouin, Klotzle, & Miu, 2013;
Etchart-Vincent, 2004;
Fehr-Duda, De Gennaro, & Schubert, 2006;
Pachur, Mata, & Hertwig, 2017;
Suter, Pachur, & Hertwig, 2016;
Vieider et al., 2015;
Zilker, Hertwig, & Pachur, 2020)
. Our results suggest that the shape of the weighting function may also reflect features of information acquisition and processing, namely, option-specific attentional biases. More specifically, the shape of the weighting function can reflect the direction and size of these biases. Therefore, differences in estimates of δ or γ obtained by modeling empirical data (e.g., between different experimental conditions or groups of people) may reflect differences in probability sensitivity or optimism/pessimism, patterns of attention allocation, or a combination of both. Complicating the psychological interpretation of these constructs even further, 
Pachur, Suter, and Hertwig (2017)
 demonstrated that CPT parameters can also reflect distinct signatures of heuristic processing strategies.
That is, while we have shown that CPT's decision weights can reflect attention allocation, this does not mean that differences in probability weighting parameters necessarily reflect differences in attention allocation. For instance, individual stability in the elevation parameter over time (see 
Glöckner & Pachur, 2012;
Pachur, Schulte-Mecklenbeck, Murphy, & Hertwig, 2018
) might reflect dispositional optimism or pessimism, or that people have stable individual dispositions for attending to specific types or features of stimuli. Researchers aiming to interpret probability weighting parameters as attentional weights are advised to verify such interpretations with additional, independent (not inferred from parameter estimates) measures (e.g., eye-tracking or sampling behavior). Our empirical analyses exemplify how this can be achieved (see also 
Harrison & Swarthout, 2019;
Pachur et al., 2018)
.


Probability Weighting Without Probabilities?
In their seminal article on prospect theory, 
Kahneman and Tversky (1979, p. 280)
 emphasized that "decision weights measure the impact of events on the desirability of prospects, and not merely the perceived likelihood of these events." That is, decision weights can deviate from objective probabilities even if the decision maker's subjective representations of probabilities are well calibrated to the objective ones. Our findings extend the distinction between decision weights and subjective probabilities in a different direction. Specifically, we have demonstrated that probability-weighting functions can reflect the dynamics of a data-generating mechanism in which probabilities are not explicitly represented in the first place. In the aDDM, as implemented in our simulations, probabilities affect evidence accumulation only indirectly, by determining the relative frequency with which the outcomes are sampled. Probabilities are inherent in the structure of the world, but only the sampled outcomes themselves-not their probabilities-are explicitly represented in the model as evidence for evaluating options. Indeed, it has been pointed out that humans may not represent probabilities explicitly. For instance, 
Sanborn and Chater (2016)
 posited that brains are poorly adapted to represent or calculate probabilities, and are more likely to implement probabilistic reasoning by means of a sampling-based mechanism. It thus remains unclear whether, when, and exactly how decision makers represent probabilities, and our results underline that estimates of the probability-weighting parameters based on empirical data cannot answer this question.


Attentional Explanations for Empirical Phenomena in Risky Choice
Our results suggest novel, process-level explanations for prominent phenomena in risky choice, such as the certainty effect, the fourfold pattern, and the description-experience gap. To date, these phenomena have predominantly been discussed in the neo-Bernoullian terms of probability weighting. However, this dominant perspective does not offer a mechanistic understanding of how these phenomena come about. Our findings may contribute to a more processoriented understanding.
The certainty effect. The certainty effect describes an apparent overweighting of safe outcomes relative to probable ones 
(Kahneman & Tversky, 1979;
Tversky & Kahneman, 1986)
. The effect is classically demonstrated as follows 
(Kahneman & Tversky, 1979)
: In a choice between a safe option offering a 100% chance to win $3,000, and a risky option offering an 80% chance to win $4,000, otherwise nothing, most people prefer the safe option. Dividing the probabilities of all nonzero outcomes in this problem by four gives a second choice problem, now offering two risky options: a 25% chance to win $3,000, otherwise nothing, versus a 20% chance to win $4,000, otherwise nothing. In this second problem, most people prefer the option offering a 20% chance to win $4,000 (the LL option). This preference pattern violates the assumption of linear probability weighting in EU theory, but it can be accounted for by an inverse S-shaped probability-weighting function in CPT.
Our results suggest a novel explanation for this phenomenon in terms of patterns of attention allocation. In the first choice problem, systematic attentional biases toward the safe option could give rise to the predominant preference for the safe option. In CPT, this preference pattern would be captured in a probability-weighting function that underweights the probability of the more attractive outcome in the risky option (80% chance to win $4000)-that is, a weighting function that runs below the diagonal (at least for high probabilities; e.g., 80%). In the choice between the two risky options, in contrast, systematic attentional biases toward the LL option could give rise to the predominant preference for the LL option. In CPT, this would be captured in a probabilityweighting function that overweights the 20% chance to win $4000 more than the 25% chance to win $3000, that is, which runs above the diagonal-at least for low probabilities (e.g., 20%). Taken together, this would yield an inverse S-shaped weighting function-like the one typically assumed to capture the certainty effect. 14 In other words, the preference patterns constituting the certainty effect (and the characteristic probability-weighting function usually assumed to account for it) may be due to systematic attentional biases in favor of the safe option and the LL option (depending on whether or not the choice problem offers a safe option).
A related explanation for the certainty effect is provided by salience theory 
(Bordalo, Gennaioli, & Shleifer, 2012)
. Salience theory assumes that an option's payoffs are weighted by their salience-that is, the extent to which they draw the decision maker's attention. Salience is thought to depend on the difference between the options' more and less attractive outcomes. For instance, when a risky option is paired with a safe option, and the safe outcome differs from the risky option's lower outcome more than it differs from its higher outcome, then the former is considered more salienttriggering risk aversion. In choice between two risky options, each offering one zero outcome and one nonzero outcome, the downside of zero is common to both options and thus not salient. Instead, the decision maker is assumed to focus on the nonzero outcomes (which differ from each other)-triggering risk aversion. Together, these patterns can yield the certainty effect. Notably, by contrast to the aDDM, salience is attached to individual outcomes rather than to entire options here. It may be interesting to explicitly test and contrast these attentional explanations for the certainty effect using both choice behavior and process-tracing in future research.
The fourfold pattern of risk attitudes. The fourfold pattern of risk attitudes describes risk aversion for highprobability gains and low-probability losses accompanied by risk seeking for low-probability gains and high-probability losses 
(Tversky & Fox, 1995;
Tversky & Kahneman, 1992)
. 
Tversky and Kahneman (1992, p. 306
) called it the "most distinctive implication of prospect theory." Can the aDDM reproduce this pattern-and, if so, under which conditions? For such behavior to arise in the aDDM, it is sufficient to assume that attentional biases to the safe versus risky option vary systematically as a function of the probability of the nonzero outcome of the risky option. Specifically, the aDDM can generate the preference patterns constituting the fourfold pattern if attention is biased toward the risky option in problems in which the nonzero outcome of the risky option has a low probability, and toward the safe option in problems in which it has a high probability. Under this attentional pattern, the aDDM produces risk aversion (risk seeking) in a choice between a safe gain (loss) and a high-probability gain (loss), and risk seeking (risk aversion) in a choice between a safe gain (loss) and a low-probability gain (loss). 15 Another cross-theory simulation analysis reported in Supplemental Material S7 demonstrates in more detail how attentional biases in the aDDM that differ between choice problems depending on the probability of the risky option's higher outcome are reflected in different shapes of the weighting function, including the inverse S-shaped probability-weighting function that is associated with the fourfold pattern.
The description-experience gap. Preferences in decision making under risk can differ considerably as a function of whether information about the options' outcomes and 14 Note that whereas the analyses presented in the main text considered choice problems that involved a safe and a risky option and choice problems with two risky options separately, the certainty effect requires both problem types to be considered together.
15 Whereas CPT does not imply perfect reflection between the gain and the loss domain (due to the assumption of loss aversion; 
Tversky & Kahneman, 1992)
, the aDDM does (see also the earlier section on mixed domain prospects), unless additional assumptions are made. their probabilities is provided in a descriptive summary or has to be learned from experience, by sampling from the options' payoff distributions. Specifically, people behave as if they ascribe more weight to rare events in description than in experience. This description-experience gap is often characterized in terms of distinct probability-weighting patterns-as an apparent overweighting (description) and underweighting (experience) of rare events 
(Wulff et al., 2018
; but see 
Regenwetter & Robinson, 2017)
. This conceptualization suggests that the weighting function is more strongly inverse S-shaped (or less strongly S-shaped) in description than in experience. In the light of the results of our analyses, it seems possible that the apparent differences in probability weighting between description and experience are due to differences in option-specific attentional biases. Specifically, participants may predominantly attend to the safe option in description but predominantly sample from the risky option in experience. This idea is supported by findings indicating that visual fixations seem to be biased toward the safe option in decisions from description (at least if the implicit 0% probability of earning an outcome of zero in the safe option is not explicitly displayed; 
Zhou, Zhang, Su, & Liang, 2019)
, whereas the more variable (risky) an option is in decisions from experience, the more people tend to sample from it 
(Lejarraga, Hertwig, & Gonzalez, 2012;
Pachur & Scheibehenne, 2012)
. Such opposite attentional biases may entail systematic differences in choice behavior, which in turn give rise to different patterns in probability weighting. Systematic differences in attention to safe versus risky options between description and experience, and their potential contribution to the description-experience gap, have not yet been explicitly investigated and will be tested in future work. For investigations of attentional underpinnings of preferences in experience and/or description that mainly focus on attention to individual attributes (i.e., outcomes and probabilities), rather than option-specific attentional biases (to the safe or the risky option), see 
Glöckner, Fiedler, Hochman, Ayal, and Hilbig (2012)
 and 
Fiedler and Glöckner (2012)
. Notably, whereas the proposed attentional account may be one important piece in the puzzle, description and experience also differ in other regards (that may affect probability weighting). For instance, attitudes to ambiguity 
(Abdellaoui, Baillon, Placido, & Wakker, 2011)
 may affect description and experience differently, due to probabilities being known or unknown, respectively.


Probability Weighting and Attention in Other Sequential Sampling Models
We focused on the aDDM in exploring the connection between probability weighting and attentional biases in sequential sampling models because this model is empirically grounded and has been successfully applied across many domains of decision making 
(Smith & Krajbich, 2018)
. However, the aDDM is not the only sequential sampling model that incorporates attentional processes (see 
Krajbich, 2019)
. For instance, Decision Field Theory (DFT; 
Busemeyer & Townsend, 1993)
 and, by extension, Multialternative Decision Field Theory (MDFT; 
Roe, Busemeyer, & Townsend, 2001)
, the Leaky Competing Accumulator (LCA; 
Usher & McClelland, 2001
, 2004
, the Multiattribute Linear Ballistic Accumulator (MLBA; 
Trueblood, Brown, & Heathcote, 2014)
, the Multi Attribute Dynamic Decision model (MADD; 
Diederich, 1997)
, and the Multi Attribute Attention Switching model (MAAS; 
Diederich & Oswald, 2014)
 also build on the sequential sampling framework to formalize dynamic deliberation processes, which link attentional constructs to choice behavior. These models differ from the aDDM in some key assumptions, especially regarding the conceptualization of attention-for instance, whether attention is thought to be allocated to individual attributes or to entire options, whether attention allocation is measured empirically or predicted by the model, and whether and how competition among the options for evidence is implemented. Another key feature that distinguishes the aDDM from other models is the assumed direction of causality between attention and preference. Whereas the aDDM posits that attention drives valuation, other models assume that attention can be a consequence of an emerging preference. For instance, 
Gluth, Kern, Kortmann, and Vitali (2020)
 proposed an extension of the aDDM which concerns preferences in tasks posing more than two alternatives (see also 
Krajbich & Rangel, 2011;
Towal, Mormann, & Koch, 2013)
, and in which preference is not only a consequence of, but also drives, the allocation of gaze (see also 
Anderson, Laurent, & Yantis, 2011;
Shimojo et al., 2003)
.
These differences between the aDDM and other models raise the question of to which extent our findings on the link between attention allocation and probability weighting can be generalized. Put differently, could a link between attention allocation and probability weighting also emerge if we used a model other than the aDDM to generate choices? Yes. Such a link can emerge whenever paying more attention to a safe or a risky option is associated with a higher probability of choosing that option on a purely behavioral levelregardless of the underlying causal mechanisms. Hence, if a model predicts that changes in attention allocation are associated with changes in preference in risky choice, then they may also be associated with changes in probability weighting-regardless of whether attention is a consequence or a driver of preference. In other words, CPT's probabilityweighting function is blind to the specific causal mechanisms underlying a behavioral link between attention and choice. Which causal account provides the best explanation of the link between attention and preference-as well as its reflection in probability weighting parameters-has yet to be determined-for instance, by work manipulating attention allocation experimentally.


Conclusion
Insights obtained within different theoretical frameworks are often difficult to relate to each other, and efforts toward theory integration are relatively sparse (but see 
Bhatia, 2014;
Donkin et al., 2011;
Fontanesi, Gluth, Spektor, & Rieskamp, 2019;
He et al., 2020;
Luan et al., 2011;
Pachur, Suter, & Hertwig, 2017)
. Both the neo-Bernoullian framework and the sequential sampling framework have made important contributions to the understanding of decision making, but they have mainly been investigated in isolation from each other. Here we presented an approach to overcome the divide between the two theoretical traditions. In a series of cross-theory simulation analyses, we demonstrated that constructs that seem to have very little to do with each other conceptuallyimbalances in attention allocation between options and nonlinear probability weighting-can nevertheless accommodate similar behavioral regularities. By showing that nonlinear probability weighting can arise from attentional biases in a sequential sampling process these analyses challenge the common view that CPT is cognitively mute. Instead, they suggest ways in which cognitive processing can shape CPT's psychoeconomic functions. Moreover, the finding that CPT's weighting function can closely trace attentional biases demonstrates that it may not always be necessary to extend existing models-or even develop entirely new ones-to transcend the explanatory scope of existing theories. Instead, establishing connections between theoretical frameworks can reveal previously overlooked capacities of existing constructs and thereby advance the theoretical landscape.
Figure 3 .
3
Illustration of the probability-weighting function proposed by
Prelec (1998)
 for various parameter settings.


Figure 4
4
Figure 4. Risk preference and maximization performance in the choice patterns generated by the aDDM for different levels of the probability of attending to the safe option a t s at each step of the diffusion process. X: corresponding posterior predictive choice behavior predicted from CPT parameters fitted to data generated by the aDDM.


Figure 12 .
12
Patterns in attention allocation in (A) Study 1 and (B) Study 2 in Fiedler and Glöckner (2012). Link between attention and proportion of ML choices (Mean ± 1SEM) in (C) Study 1 and (D) Study 2 in Fiedler and Glöckner (2012).


PROBABILITY WEIGHTING AND ATTENTIONAL BIAS 7 into subjective ones by the value function


Some analyses-such as
Johnson and Busemeyer (2016)
have explored possible relationships between attentional dynamics in sequential sampling processes (e.g., which attribute is attended to first; how long individual attributes are attended to) and patterns in probability weighting. However, rather than seeking to identify complementary insights, these analyses treat the sequential sampling and utility-based frameworks as competitors (e.g., by pointing out that attentional sequential sampling models can explain a wider range of qualitative phenomena, and by comparing the approaches' performance in accounting for empirical data).


Note that there are also alternatives to EU theory's account of risk aversion in terms of nonlinear utility, such as the dual theory of choice under risk by
Yaari (1987)
: Whereas EU theory replaces EV theory's assumption of linear treatment of outcomes by the concave utility function u, Yaari's dual theory replaces EV theory's assumption of linear treatment of probabilities by a nonlinearity (while maintaining the assumption of linear treatment of outcomes).


Note that there is also a functional form by
Abdellaoui et al. (2010)
 that completely separates elevation and curvature.


This holds for most, but not all, risky options, because even highly elevated weighting functions may run below the identity line for a small subrange of the probability range. Consider, for instance, the probability-weighting function with δ = 0.1 and γ = 0.1 inFigure3. It runs above the identity line for most probabilities, except those very close to 1. Although this parameter setting yields decision weights that make most risky options appear more attractive than they objectively are, a few risky options with p high very close to 1 appear less attractive than they objectively are. Therefore, in sets of choice problems where p high is uniformly distributed across the probability range, a highly elevated probability-weighting function tends to make most risky options appear more attractive, with some rare exceptions.


In these analyses, the "safe" options thus also included options whose underlying payoff distribution offered several probabilistic outcomes of which only one was encountered during sampling. In Supplemental Material S8, we present analyses that include only cases with an objectively safe option. The results are highly similar to those presented in the main text.


Note that attentional bias itself is not predicted by our model, but measured based on the empirical data on each trial. This empirically observed attentional bias, fed into the model as an input, then serves as a co-variate of probability-weighting parameters (see Equation 12). That is, the model makes no assumptions about possible dependencies in a person's attentional bias from trial to trial; whether such dependencies exist is determined by the person's behavior.


The data on decisions from experience are not useful for this purpose because they contain no RTs.


In a choice set in which the magnitude of the loss is typically larger than the magnitude of the gain, the multiplicative amplification of value by attention in the aDDM may increase the impact of the loss more than that of the gain, and give rise to choice behavior that seems indicative of loss aversion. However, such a pattern is not expected in a balanced choice set in which gain and loss outcomes are, on average, of the same absolute magnitude.


Because these analyses are meant to gauge potential dissimilarities between the models beyond loss aversion, they again drew on the gain-domain choice problems used for previous simulations, making the loss aversion parameter λ irrelevant.








Data and Code Availability
Code to implement all analyses is hosted at https://doi.org/10.17605/OSF.IO/W3E9V 
(Zilker & Pachur, 2021, April 29)
. Data for the empirical analyses is available at https://www.dirkwulff.org/#data and https://www .frontiersin.org/articles/file/downloadfile/ 25643_supplementary-materials_datasheets_1 _zip/octet-stream/Data%20Sheet%201.ZIP/2/25643












The rich domain of uncertainty: Source functions and their experimental implementation




M
Abdellaoui






A
Baillon






L
Placido






P
P
Wakker




10.1257/aer.101.2.695






American Economic Review




101


2
















Separating curvature and elevation: A parametric probability weighting function




M
Abdellaoui






O
Haridon






H
Zank




10.1007/s11166-010-9097-6






Journal of Risk and Uncertainty




41


1
















L'extension des théories de l'équilibre économique général et du rendement social au cas du risque [Extension of the theories of general economic equilibrium and social output to the case of risk




M
Allais




















10.2307/1905539






Econometrica




21














Valuedriven attentional capture




B
A
Anderson






P
A
Laurent






S
Yantis




doi: 10.1073/ pnas.1104047108






Proceedings of the National Academy of Sciences




108


25
















Biasing simple choices by manipulating relative visual attention




K
C
Armel






A
Beaumel






A
Rangel








Judgment and Decision Making




3


5
















A biased random walk model for two choice reaction times




F
G
Ashby




10.1016/0022-2496(83)90011-1






Journal of Mathematical Psychology




27


3
















Exposition of a new theory on the measurement of risk




D
Bernoulli




10.2307/1909829






Econometrica




22


1


1738














Sequential sampling and paradoxes of risky choice




S
Bhatia




10.3758/s13423-014-0650-1






Psychonomic Bulletin & Review




21


5
















Choice rules and accumulator networks




S
Bhatia




10.1037/dec0000038






Decision




4


3
















The physics of optimal decision making: A formal analysis of models of performance in two-alternative forcedchoice tasks




R
Bogacz






E
Brown






J
Moehlis






P
Holmes






J
D
Cohen




10.1037/0033-295X.113.4.700






Psychological Review




113


4
















A parametric analysis of prospect theory's functionals for the general population




A
S
Booij






B
M
Van Praag






G
Van De Kuilen




10.1007/s11238-009-9144-4






Theory and Decision




68


1-2
















Salience theory of choice under risk




P
Bordalo






N
Gennaioli






A
Shleifer




10.1093/qje/qjs018






The Quarterly Journal of Economics




127


3
















The Maltese cross: A new simplistic model for memory




D
E
Broadbent




10.1017/S0140525X00026121






Behavioral and Brain Sciences




7


1
















The simplest complete model of choice response time: Linear ballistic accumulation




S
D
Brown






A
Heathcote




doi: 10.1016/ j.cogpsych.2007.12.002






Cognitive Psychology




57


3
















Decision field theory: A dynamic-cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend




10.1037/0033-295X.100.3.432






Psychological Review




100


3
















Eye tracking and pupillometry are indicators of dissociable latent decision processes




J
F
Cavanagh






T
V
Wiecki






A
Kochar






M
J
Frank




10.1037/a0035813






Journal of Experimental Psychology: General




143


4
















Emotional balance and probability weighting. Theory and Decision




N
Charupat






R
Deaves






T
Derouin






M
Klotzle






P
Miu




10.1007/s11238-012-9348-x






75


















Veronika
Zilker






Thorsten Pachur














Games, gods and gambling: The origins and history of probability and statistical ideas from the earliest times to the Newtonian era




F
David-Nightingale








Griffin


London, UK












Dynamic stochastic models for decision making under time constraints




A
Diederich




10.1006/jmps.1997.1167






Journal of Mathematical Psychology




41


3
















Sequential sampling model for multiattribute choice alternatives with random attention time and processing order




A
Diederich






P
Oswald




10.3389/fnhum.2014.00697






Frontiers in Human Neuroscience




8


697














A dynamic dual process model of risky decision making




A
Diederich






J
S
Trueblood




10.1037/rev0000087






Psychological Review




125


2
















Diffusion versus linear ballistic accumulation: Different models but the same conclusions about psychological processes?




C
Donkin






S
Brown






A
Heathcote






E.-J
Wagenmakers




10.3758/s13423-010-0022-4






Psychonomic Bulletin & Review




18


1
















Is probability weighting sensitive to the magnitude of consequences? An experimental investigation on losses




N
Etchart-Vincent




10.1023/B:RISK.0000026096.48985.a3






Journal of Risk and Uncertainty




28


3
















Gender, financial risk, and probability weights




H
Fehr-Duda






M
De Gennaro






R
Schubert




10.1007/s11238-005-4590-0






Theory and Decision




60


2-3
















The dynamics of decision making in risky choice: An eye-tracking analysis




S
Fiedler






A
Glöckner




10.3389/fpsyg.2012.00335






Frontiers in Psychology




3


335



"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]