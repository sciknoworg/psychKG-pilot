You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1â€“3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Probabilistic information can be expressed in two ways: The first is conveying probabilistic information using numbers (e.g., the chance of rainfall today is 50%). Probability usually refers to the type of numerical expression primarily used in research on judgments and decisions. This study also considers the second way, which involves stating probabilities using verbal expressions such as "It is certain," "It is likely," or "It is unlikely." Hereafter, we refer to the numerical expressions of probability as numerical probability and the verbal expression as verbal probability. As verbal probabilities do not correspond uniquely to numerical probabilities (verbal probabilities are vague and convey numerical information within a certain interval), many studies have been conducted from various perspectives 
(Dhami & Mandel, 2022;
Teigen, 2023
).
Verbal probabilities can be categorized in terms of directionality. This refers to a communicative function that changes the listener's focus. Most verbal probabilities can be classified into two groups: positive and negative 
(Budescu et al., 2003;
Honda & Yamagishi, 2006
Juanchich et al., 2013;
Teigen & Brun, 1995
, 2003a
, 2003b
. For example, when a speaker communicates a low degree of probability, they may use a phrase such as "There is a small chance" or "There is a poor chance." According to 
Teigen and Brun (2003a)
, a positive phrase such as "There is a small chance" is "pointing upward, directing our focus of attention to what might happen" (p. 130). In contrast, a negative phrase such as "There is a poor chance"
is "pointing in a downward direction, asking us to consider that it might not happen after all" (p. 130). In other words, positive verbal probabilities cause listeners to focus on the occurrence of an uncertain event, whereas negative verbal probabilities cause listeners to focus on the nonoccurrence of an event. 
Teigen and Brun (1999)
, 
Yamagishi (2006, 2009)
, and 
Collins et al. (2023)
 showed that people's decisions based on verbal probabilities vary depending on their directionality. In Study 1 of 
Teigen and Brun (1999)
, the effectiveness of a treatment was conveyed with a positive phrase ("It is some possibility that the treatment will be helpful in her case"), a negative phrase ("It is quite uncertain that the treatment will be helpful in her case"), or numerical probability ("The probability is about 30-35% that the treatment will be helpful in her case"). The numerical translations of the positive and negative phrases as estimated by the participants in the numerical translation group were approximately 30% (there was no significant difference between the types of phrases). Participants in the decision group rated the extent to which they would recommend this treatment based on a positive phrase, a negative phrase, or numerical probability. It was found that the degree of recommendation varied depending on the type of presented information (degree of recommendation was positive > numerical > negative). This phenomenon can be interpreted as the framing effect 
(Teigen & Brun, 1999
, 2003b
.


Communication behavior and decision-making based on verbal probabilities
Many studies on the framing effect 
(Keren, 2011;
Tversky & Kahneman, 1981)
 have focused on the psychological mechanisms involved in listeners of information (i.e., how listeners make decisions based on the presented frames). Another approach focuses on the psychological mechanism involved not only in the listener of information but also in the speaker of information.
For example, 
McKenzie and Nelson (2003)
 and 
Sher and McKenzie (2006)
 explained the framing effect using the reference point hypothesis. 
Sher and McKenzie (2006, p. 471
) stated the reference point hypothesis as follows: "(1) In describing a fixed state of proportionate affairs, speakers are more likely to describe the proportion in terms of 'X1' when X1 has increased relative to the reference point proportion (the norm, or what one would have expected) than when X1 has decreased relative to the reference point. (2) Listeners are sensitive to this regularity; that is, listeners are capable of correctly inferring the reference point proportion from the speaker's choice of proportion frame." Various studies have supported this hypothesis 
(Honda et al., 2018;
Leong et al., 2017;
Pander Maat et al., 2021;
Teigen & Karevold, 2005)
.
In addition, the reference point hypothesis can be extended to the context of communication using verbal probabilities. 
Honda and Yamagishi (2017)
 and 
Juanchich et al. (2010)
 have shown that speakers' choices of verbal probability depend on their reference points.
Imagine trying to convey that an uncertain event has an x% chance using verbal expressions.
Speakers tend to prefer a positive phrase when their reference point is lower than x% compared to when their reference point is higher than x%. Furthermore, 
Honda and Yamagishi (2017)
 showed that listeners' inferences about speakers' reference points were in accordance with the speakers' rule of phrase choice: listeners infer that the speaker's reference point for event occurrence is lower than x% when presented with positive phrases compared to when presented with negative phrases. These findings indicate that listeners can infer a speaker's reference points based on expressions chosen by the speaker.
The reference point hypothesis has intriguing implications regarding framing effects.
Decisions affected by frame differences can be interpreted as those that consider the relative status inferred from a reference point 
(Sher & McKenzie, 2006)
. For example, the effect of the directionality of verbal probabilities in 
Teigen and Brun (1999)
 can be interpreted as follows: decision makers infer different reference points when presented with positive or negative phrases (they infer a lower reference point when presented with positive phrases). When a speaker states "some possibility" (positive phrase) for the effectiveness of treatment X, a listener, who is sensitive to speaker's regularity of directionality usage, may refer to another treatment Y which is not as good as the treatment X (i.e., probability of effectiveness is lower than the treatment X). In contrast, when a speaker says "uncertain" (negative phrase) for treatment X, a decision-maker refers to another treatment Z, which is better than the treatment X (i.e., probability of effectiveness is higher than the treatment X). As a result, even if the same degree of probabilistic information is communicated (e.g., "some possibility" and "uncertain" communicate analogous degree of probability), the decision maker evaluates the treatment more favorably (recommends the treatment more) when presented with a positive phrase than when presented with a negative one. That is, when presented with positive (or negative) phrases, it suggests a higher (or lower) probability compared with the reference point, suggesting good (or bad) treatment when considering the shift in relative status from the reference point.
Previous studies have demonstrated that individuals are highly sensitive to trends.
For example, people find trends in very small samples, such as three or even two 
(Carlson & Shu, 2007;
Hohle & Teigen, 2015
. That is, a comparison between the currently stated probability and the reference point [in the example above, the probability that treatment X is effective versus the probability that treatment Y (or Z) is effective] generates psychological feelings about the trends. As a result, people feel strongly about upward trends (i.e., treatment X is good) or downward trends (e.g., treatment X is bad). Thus, previous findings suggest that the psychological basis of sensitivity to the relative comparison with a reference point is involved in the evaluation of targets.


Goal of this study: Model-based analyses of decision-making and communication behavior based on verbal probabilities
The reference point hypothesis provides intriguing insights into decisions and communication based on verbal probabilities. To the best of our knowledge, no previous studies have conducted model-based analyses of this relationship. As many studies have shown that the phenomena involved in decision making can be insightfully understood using quantitative models 
(Kahneman & Tversky, 1979)
, it is important to construct such a model and analyze the psychological functions and mechanisms behind the observed data.
This study aimed to clarify the psychological link between decisions and communication behaviors. Specifically, we 1) analyzed decision behaviors affected by the difference in presented information from a communicative perspective, and 2) examined whether the psychological mechanisms that explain decision behaviors could predict communicative behavior. To examine these issues, we propose a quantitative model that can explain decisions and communicative behaviors. Subsequent sections are organized as follows:
First, we described the proposed model that makes quantitative predictions regarding decisionmaking and communicative behaviors (Section 2). We then reported five experiments, two of which were related to decision-making (Sections 3 and 4), two to communicative behavior (Sections 5 and 6), and one to a detailed examination of decision processes (Section 7).
The protocols for the behavioral experiments in this study conformed to the Declaration of Helsinki and were approved by the Ethics Review Committee for Experimental Research at the University to which the first author belongs. The participants provided informed consent (or online informed consent) to participate in the four behavioral experiments.


Model for decision and communicative behavior:
Decision by Belief Sampling (DbBS)


Background
Our model is based on the Decision by Sampling (DbS) model 
(Stewart, 2009;
Stewart et al., 2006;
Stewart & Simpson, 2008
).
The DbS model constructs subjective attribute values by using a series of binary ordinal comparisons with a sample of attribute values that reflect the immediate decision context and real-world distribution. The subjective value of the target was calculated as follows:
= âˆ’ 1 âˆ’ 1 (1)
where r (0 â‰¤ â‰¤ 1) denotes the subjective value for a target, and R denotes the rank of the target within the decision sample of N items. 
Stewart et al. (2006)
 argued that the DbS model explains why people show nonlinear psychoeconomic functions, such as utility, hyperbolic temporal discounting, and probability weighting functions. Previous studies have also shown that the DbS model can explain various decision behaviors and psychological phenomena 
(Alempaki et al., 2019;
Boyce et al., 2010;
Noguchi & Stewart, 2018;
Olivola & Sagara, 2009;
Sharif & Oppenheimer, 2016;
Stewart et al., 2003
Stewart et al., , 2014
Ungemach et al., 2011;
Walasek & Stewart, 2015;
Wood et al., 2011)
.


Model specification: Decision by Belief Sampling (DbBS)
According to the DbS model, a person's probabilistic beliefs may critically affect their decisionmaking based on probabilistic information. Consider a probability of 30%. When this value indicates a hitter's batting average in baseball, one may think that the probability is considered sufficiently "high." In contrast, when it is the probability of getting heads in flipping a coin, you may think that this probability is "low." These examples suggest that when evaluating the value of 30%, people compare the 30% with their probabilistic beliefs: people believe that most hitters have a batting average of less than 30% and that there is a 50% chance that they will flip a coin and come up with heads. In other words, when evaluating the probabilistic value of an event, probabilistic beliefs can play a critical role in decision samples.
To represent the psychological processes of decision-making mentioned in this example, we proposed the Decision by Belief Sampling (DbBS) model. This model can be applied to any context where a participant is asked to respond based on probabilistic information.
Before introducing the details in the following sections, we specify the terms' meaning in our explanation. Listener is a decision-maker based on the presented probabilistic information.
Speaker indicates the person conveying the probabilistic information.


Scope of the present model
The present model targets two phenomena: (1) decisions based on probabilistic information, and
(2) communication of probabilistic information using verbal probabilities. In (1), as in Teigen probabilistic information in some form ("some possibility," "quite uncertain," or "30%"). In (2), the model targets a situation wherein the speaker conveys probabilistic information using positive or negative verbal probability [e.g., when conveying "10%", either of the two expressions, positive (e.g., "a slight hope") or negative (e.g., little hope) expression, a person prefers]. We proposed a model that explains these two phenomena using the same framework.
We note that the DbBS model treats a binary event, that is, an uncertain event in which the outcome can be defined as "success" or "failure."


Assumptions
Assumption (1): When listeners make decisions relevant to the outcomes for which they have precise or imprecise knowledge, they sample the probabilities from their probabilistic beliefs.
The sampled probabilities are approximated by probabilistic beliefs.


Assumption (2):
The listener's subjective evaluation of a target probability value Ï„ can be represented by the function w(Ï„), and w(Ï„) depends on the probabilistic belief.


Assumption (3):
The Listener's probabilistic belief can be characterized by the two parameters of the beta distribution, ( , ) . In particular, the probability density function (PDF) of the ( , ) represents probabilistic belief.
Assumption 
4
 Assumptions (1) and (2) are extensions of the DbS model. We set more specific Assumptions (3) and (4) for decisions based on probabilistic beliefs. In the DbBS model, the decision sample (probabilistic belief) is represented by a probability density function (PDF) of the beta distributions. The beta distribution has two parameters: Î± and Î². When X follows the Beta distribution, ( , ), its density ( ) is expressed as follows:
( ) = ( + ) ( ) ( ) âˆ’1 (1 âˆ’ ) âˆ’1
(2)
where Î“(z) denotes the gamma function. A beta distribution is often used as a conjugate prior for the probability distribution of a binomial distribution 
(Kruschke, 2014)
. We chose beta distribution for two reasons. First, the range of the beta distribution (0-1) corresponds exactly to the probability or probabilistic belief that we intend to model. Second, the PDF of beta distributions can take several forms, allowing us to qualitatively and quantitatively model different types of probabilistic beliefs. 
( ) = âˆ« âˆ’1 (1 âˆ’ ) âˆ’1 0 âˆ« âˆ’1 (1 âˆ’ ) âˆ’1 1 0 (3)
where w(Ï„) indicates the percentile of the target probability Ï„. Thus, w(Ï„) corresponds to r in Equation 
1
, which is determined by its relative rank (R) within the sampled events (N). 
Figure  1
(B) shows w(Ï„). w(Ï„) depends on probabilistic beliefs; therefore, w(Ï„) can differ, even for the same Ï„.
Finally, Assumption (5) states that decision patterns, such as the effect of a difference in probabilistic information or context, can be explained (or predicted) in terms of decision makers' probabilistic beliefs. These beliefs can be constructed in several manners. For example, if people believe that a dice, which has six sides and numbers from one to six, is fair, they may believe that the probability of landing "1" is 1/6. This is an example of a person with apparent probabilistic beliefs. By contrast, in other cases, they may not have any idea about the probability of an event. Even in such cases, people may hold certain beliefs. Bruine de 
Bruin et al. (2000)
 discussed the meaning of a 50% probability, which is usually regarded as the default value for epistemic and aleatory uncertainties in the case of binary events. For example, if people do not have any idea about the effectiveness of a treatment, they may believe that the probability of the treatment for curing a disease is "50%." Alternatively, people may construct probabilistic beliefs using heuristics such as the risk-reward heuristic 
(Leuker et al., 2018;
Pleskac et al., 2020;
Pleskac & Hertwig, 2014)
. Furthermore, probabilistic beliefs may be independent of the probabilities in question. For example, in the treatment context, as shown in 
Teigen and Brun (1999)
, a probabilistic belief may be constructed from an alternative treatment. In this case, if the treatment in question (Treatment X) is more effective than the alternative treatment (Treatment Y), then Treatment X would be positively evaluated. Thus, a favorable evaluation of treatment X does not derive from its probability of effectiveness but from the comparison of the probability of effectiveness in treatment Y (i.e., probabilistic belief about the effectiveness of treatment Y).


Specific predictions for decisions and communication behavior based on DbBS
As mentioned in the previous section, probabilistic beliefs can be constructed in several ways.
In this study, we hypothesize that probabilistic belief, reference point, and directionality are closely related to each other. Then, we try to model them by DbBS.
We predict that the directionality of verbal probabilities plays an important role in the formation of probabilistic beliefs. 
Honda and Yamagishi (2017)
 
, )
] tries to convey probability p using a verbal probability, they prefer a positive phrase with the probability of w(p) of ( , ).
Prediction (4): The speaker's choice of positive phrase is well predicted from probabilistic beliefs estimated from the listener's decision patterns based on verbal probabilities
( | , | ) or ( | , | )
.
Predictions 
(1) and
(2) are based on previous findings. According to the findings of 
Teigen and Brun (1999)
 and Honda and Yamagishi (2017) (see Section 1.1), we predict that the effect of the directionality of verbal probabilities on decisions can be explained in terms of different decision samples: A listener infers the speaker's probabilistic belief based on the presented phrases, and the decision sample is constructed by such an inferred probabilistic belief.
Prediction (3) is novel based on the properties of the DbBS model. The DbBS model provides the following straightforward prediction of the choice rate of a positive phrase:
Suppose that a speaker, who has a certain probabilistic belief such as 
( , )
 , is trying to convey a certain probability, p, using a verbal probability. Based on the reference point hypothesis and the findings of 
Honda and Yamagishi (2017)
, speakers are predicted to prefer a positive phrase to a negative one to convey probability p when their probabilistic belief is lower than p. As for the quantitative prediction, this case indicates that a random variable (here, representing the speaker's probabilistic belief) is in the region where its value is lower than p.
Based on this, we can assume that the CDF of ) . The present study examined which distribution corresponds to 
( , )
 for the first time. Thus, we could not make clear predictions and required an exploratory approach. However, the candidates can be
( | , | ) or ( | , | )
. Previous studies have shown that numerical probabilities are vague in terms of directionality 
(Teigen & Brun, 1999)
.
Additionally, listeners' inferences about speakers' reference points based on numerical probabilities were nearly random 
(Honda & Yamagishi, 2017)
, suggesting that they cannot make inferences about speakers' probabilistic beliefs based on numerical probabilities. Based on these,
( | , | )
is unlikely to reflect 
( , )
. The critical point is that the probabilistic belief estimated from the listener's decision patterns reflects the speaker's probabilistic beliefs and can accurately predict the speaker's choice of positive phrases.
The DbBS model assumes that the listener infers the entire set of probabilistic beliefs (i.e., probability distributions) held by the speaker. However, some may doubt the validity of this assumption. Can the listener really do so? This assumption is based on the following considerations: The reference point hypothesis states that listeners are sensitive to speakers' conversational regularity 
(Sher & McKenzie, 2006)
. This implies that listeners can accurately capture the probabilistic belief (closely related to conversational regularity) held by speakers.
Of course, it is unlikely that a listener will explicitly understand the probabilistic belief as a form of probability distribution. However, they can perceive this intuitively or implicitly. For example, cognitive systems can accurately capture real-world probability distributions 
(Griffiths & Tenenbaum, 2006)
. This finding does not suggest that people have an explicit understanding of probability distributions, but suggests that people's intuitive perception can be in accordance with the whole sketch of probability distributions. The DbBS model states that when a person the speaker's probabilistic belief, which is represented by a probability distribution, and makes decisions based on it.


Experiment 1: Decisions based on verbal probabilities
In Experiment 1, we examined decisions based on verbal or numerical probabilities to verify Predictions (1) and (2).


Method


Participants and experimental design
Sixty Japanese undergraduates (22 women and 38 men; Mage = 20.650, SDage = 1.706) participated in the study. They received a flat fee of 1000 Japanese yen (approximately 8 U.S.
dollars at the currency rate at the time) for their participation. As explained in the subsequent section, all participants responded to all stimuli in all tasks. Thus, each task was conducted using a within-participants design.
To determine the appropriate sample size, we set a medium effect of d = 0.5 
(Cohen,
 Based on this analysis, the number of participants was set at 60.


Tasks and materials
The two main tasks in the experiments were 1) the decision task and 2) a numerical interpretation task for verbal probabilities 1 .
The decision task was based on Study 1 of 
Teigen and Brun (1999)
. The cover story was as follows:
Your friend has been experiencing periodic migraine headaches and is now considering a new treatment method based on acupuncture. However, treatment is costly and long-lasting. The friend asks if you think the friend should try it. Fortunately, you happen to know a physician with good knowledge of migraine treatment whom you can ask for advice.
Participants were presented with a verbal or numerical probability by the physician (e.g., "It is possible that the treatment will be helpful in that case" or "There is a 40% chance of the treatment being helpful in that case"). Considering this probabilistic information about effectiveness of treatment, participants were asked to rate how much they would recommend this treatment to the friend, using a scale labeled "not at all" on the far left and "absolutely" on the far right.
We conducted a task to measure the membership function of verbal probability to examine the interpretations of verbal probabilities. Previous studies 
(Budescu & Wallsten, 1995;
Wallsten et al., 1986)
 showed that numerical translations of the verbal probability experienced by each participant could be represented by a membership function. In this task, participants were presented with a single verbal probability by the physician and 11 probability values (1%, 10%, 20%,..., 90%, and 99%) simultaneously and asked to rate the degree (membership value)
to which the verbal probability described each probability using a scale labeled "not at all" on the far left and "absolutely" on the far right. This method was based on the multiple stimuli method proposed by 
Budescu et al. (2003)
.
This study used eight positive and eight negative probability phrases as the verbal probabilities. 
Table 1
 presents a list of the 16 phrases. We chose these phrases to cover a range from low to high degrees of certainty, based on Honda and Yamagishi's (2017) work 2 . For the numerical probabilities, we used 11 probability values: 1%, 10%, 20%, â€¦, 80%, 90%, and 99%.


Procedure
Tasks were performed individually using a computer. The order of task implementation was as follows: decision task for 16 verbal probabilities, irrelevant task (approximately 15-20 min) 3 , decision task for 11 numerical probabilities, and a task measuring the membership function.
In the decision task for verbal and numerical probabilities, the participants answered each phrase (or numerical probability) once. The participants answered 16 (or 11) questions regarding verbal (or numerical) probabilities. The decision rating was recorded on a scale of 101 points ranging from 0 (do not recommend at all) to 100 (absolutely). In the task measuring membership functions for verbal probabilities, participants answered the question for each phrase twice; in other words, 32 times in total. Membership value was recorded on a scale of 101 points, ranging from 0 (not at all) to 100 (absolutely). 
4
 In all tasks, the presentation order of the stimuli (verbal and numerical probabilities in the decision task and verbal probabilities in the task measuring membership functions) was randomized for each participant. All experimental tasks, including the irrelevant task, were completed within one hour on average (approximately 45 to 60 minutes).


Results


General trend of probability translation for verbal probabilities and decision
While the primary focus of our analysis was the estimation of probabilistic beliefs based on individual data using the DbBS model, we first reported the average data to capture the general trends of numerical translation for verbal probabilities and decision ratings.
In the numerical translation of verbal probabilities, the peak of the membership function (the probability with the highest membership value) is one of the most discriminative features 
(Budescu et al., 2003;
Juanchich et al., 2013)
. Therefore, we assume that the peak of the membership function represents the numerical translation of the verbal probability for each participant. 5
The left panel of 
Figure 2
 shows the relationship between the mean numerical translations (or probability values) and mean decision ratings for the eight positive phrases, eight negative phrases, and 11 numerical probabilities. It is apparent that decision patterns differ according to the directionality of the verbal probabilities. As 
Teigen and Brun (1999)
 show, decision ratings for positive phrases tend to be higher than those for negative ones, replicating previous findings. Regarding numerical probabilities, the decision ratings lie between the positive and negative phrases when the probability values are lower than 50%. When the probability values are greater than 50%, the decision ratings are analogous for positive expressions and numerical probabilities.


Estimation of probabilistic beliefs in responding to the decision task using the DbBS model and model comparison with other candidate models
We assumed that the participants' responses to the decision task were based on decision samples constructed by probabilistic beliefs. These beliefs were estimated using the DbBS model. We estimated the two parameters, Î± and Î², of the beta distribution, whose CDF best explained the response data based on the hierarchical Bayesian parameter estimation method. Our method is primarily based on the procedure proposed by Nilsson et al. (2011).
In the hierarchical Bayesian framework, we assumed that participant i has its own parameter, Î±i and Î²i, for each type of information presented. Since the parameters Î±i and Î²i can take any value greater than 0, we assume that they come from a group-level lognormal distribution, ~( , ( ) 2 ) and ~( , ( ) 2 ). Further, for participant i's response regarding the target probability Ï„, wi (Ï„) is assumed to follow ( )~( suggests that Î± and Î² will not take extremely high values. Based on this empirical knowledge, we decided that group-level means should be between 0.1 and 10 6 . For lognormal means, this translates into an uninformative prior range between -2.303 and 2.303. For the uninformative uniform priors for the lognormal standard deviations, we assumed a range between 0 and 1.329
(the latter is the standard deviation of the uniform distribution, ranging from -2.303 to 2.303, that is, âˆš (2.303âˆ’(âˆ’2.303)) 2


12
). It is necessary to confirm that the Bayesian hierarchical estimation procedure can accurately recover the parameter values. Therefore, we conducted a parameter recovery test. We found that the present estimation procedure effectively recovered the parameter values to test the hypotheses. Details are presented in the supplementary material. It is possible to explain the observed phenomena using simpler models. One candidate model stated that decisions are made based on the probabilistic meaning represented by each verbal probability. We call this model the Numerical Meaning (NM) model and propose two versions. The first model, NMpeak, assumes a peak in the membership function for the representation of the probabilistic meaning in verbal probability. In this model, participant i 's decision rating for presented probabilistic information (verbal or numerical) PI, DRPI,i is
represented with a liner model as follows:
, = , +
(4)
where NTPI,i indicates the peak of the membership function for the presented verbal probability PI for participant i (in the case of numerical probability, the presented number), and ai and bi indicate the coefficients for the slope and intercept for participant i, respectively. This is the simplest version of an NM model. We also propose another version of the NM model: NMpeakskewness. In this model, the decision rating for the presented probabilistic information (verbal or numerical) PI by participant i, DRPI,i is represented by a linear model as follows:
, = , + , +
(5)
where SKPI,i indicates the skewness of the membership function for the presented verbal probability (in the case of numerical probability, 0), and ai, bi, and ci are the coefficients for the slope and intercept for participant i, respectively. This model is based on previous findings that the meaning of directionality can be represented by peaks and skewness in membership the parameters based on the hierarchical Bayesian parameter estimation method (details described in the supplementary material).
We then conducted a model comparison to select the best model among DbBS, MNpeak, and MNpeak+skewness. We used two selection criteria: WAIC and ELPD 
(Ghaderi-Kangavari et al., 2022;
Vehtari et al., 2017;
Watanabe, 2010)
. A lower (higher) value indicates a better model in the WAIC (ELPD). 
Table 2
 summarizes the results of model comparisons. We
found that the DbBS model performed the best among DbBS, NMpeak, and NMpeak-skewness. 7


Differences in probabilistic beliefs among the information presented
We examined the differences in the estimated probabilistic beliefs based on the information presented. Specifically, we compared the mean of the probabilistic beliefs (the mean of the PDF of the beta distribution) among the positive, negative, and numerical probabilities.
The top panel of 
Table 3 shows
 


Summary of Experiment 1
We examined two predictions related to decisions based on verbal and numerical probabilistic information. Our findings were consistent with these predictions. We compared DbBS with the NM model, which was constructed based on the findings of previous studies. The results showed that the DbBS model had more explanatory power than the NM model. Thus, we can assume that the DbBS model explains decision patterns better than the most promising competitive models.


Experiment 2: Replication of Experiment 1
Experiment 2 aimed to replicate the findings of Experiment 1. We conducted the same tasks as in Experiment 1 for different populations (we recruited general participants other than undergraduate students) and examined the robustness of the findings of Experiment 1.


1. Method


Participants and experimental design
Seventy Japanese people (33 women and 37 men; Mage = 30.66, SDage = 11.35) participated in the experiment. They were recruited via the Internet and paid 1,200 yen (approximately nine US dollars at the current exchange rate) as compensation for participating in the experiment.
We recruited participants via the web using the same policy as in Experiment 1.
Those who applied before the recruitment deadline participated in this study.


Tasks and materials
The tasks and materials used were the same as those used in Experiment 1. However, because the experimental task was conducted on the web, and it would be ideal to reduce the load on participants as much as possible, we conducted a numerical translation task wherein participants were asked about the probability that the verbal probability represented, that is, provide a number (0-100%) instead of measuring the membership function. The numerical translation task has been used to measure how participants interpret verbal probabilities and to provide important findings in research on verbal probabilities 
(Meder et al., 2022;
Teigen & Brun, 1999
).
In addition, previous studies have shown that numerical translation correlates strongly with the peak value of the membership function 
(Honda & Yamagishi, 2009)
.


Procedure
Participants completed the tasks on the Internet. Tasks were performed individually using a computer. The order of task implementation was as follows: a decision task for 16 verbal probabilities, an irrelevant task (approximately 15-20 minutes), a decision task for 11 numerical probabilities, and a numerical translation task. All experimental tasks, including the irrelevant task, were completed within one hour (approximately 40 to 60 minutes).


Results
As the results of Experiment 2 were highly analogous to those obtained in Experiment 1, we have discussed them briefly.
The general trend of decision ratings is shown in the right panel of 
Figure 2
,
indicating that the type of probabilistic information affects decision-making.
We conducted a model comparison to select the best model among the DbBS and NM models. As we measured numerical translations instead of the membership function, we proposed another version, NMNT. NMNT assumes a numerical translation to represent probabilistic information in terms of verbal probability. This model is the same as that in Equation (4), except that NTPI,i is a numerical translation instead of a peak of the membership function for the presented probability. We found that the DbBS model was the better model than NMNT ( 
Table 2
).
The estimated parameters for probabilistic beliefs were consistent with Predictions
(1) and (2). The estimated parameters of beta distribution differed among the three types of probabilistic information, and the mean of probabilistic beliefs, when presented with negative phrases, was higher than when presented with positive phrases in a group level (lower panel of 
Table 3
). This was also observed at the individual level 
(Fig. 4, right panel)
. The means of the estimated probabilistic beliefs were higher when presented with negative phrases than with positive phrases [t (69) = 11.517, p < .001, d = 1.377].
In summary, we obtained results highly analogous to those of Experiment 1, indicating that the findings of Experiments 1 and 2 were robust.


Experiment 3: Choice of directionality in probabilistic communication using verbal probabilities
In Experiment 3, we conducted an experimental probability communication task using verbal probabilities to examine Predictions (3) and (4). We examined which expression (positive or negative) participants preferred to communicate probabilistic information and how well the ,
( | , | )
, and
( | , | )
] make different predictions for speakers' choice rates for positive phrases. To examine Predictions (3) and (4), we examined which estimated probabilistic belief could accurately predict the speakers' directionality choices.


Method


Participants and experimental design
Sixty-three Japanese individuals (31 women and 32 men; Mage = 43.651 years, SDage = 8.543 years) participated in the experiment. They were recruited via the Internet and received redeemable coupons for online shopping in Japan. We recruited participants via the web using the same policy as in Experiment 1. Those who applied before the recruitment deadline participated in this study.


Tasks and materials
We conducted a phrase choice task. The cover story was as follows:
Suppose there is a costly and long-lasting treatment for migraines based on acupuncture, which was administered to 10 patients. The result was
Effective: X people Ineffective: Y people How do you think the probability of the effectiveness of this treatment should be conveyed? Please select the most appropriate phrase from the following 16
phrases.
Participants were asked to choose the phrase out of 16 that would be the most appropriate to convey the probability of treatment effectiveness. The 16 phrases were the same verbal probabilities (eight positive and eight negative expressions) as those used in Experiments 1 and 2. Participants were asked to choose a phrase for nine situations in which the X and Y pairs differed. The nine pairs of (X, Y) were (1, 9), (2, 8), (3, 7), (4, 6), (5, 5), (6, 4), (7, 3), (8, 2), and (9, 1). In other words, the situation differed in the probability of treatment effectiveness (10%, 20%, 30%, â€¦, 70%, 80%, and 90%).


Procedure
Participants completed the tasks via the Internet as part of the experimental tasks. Each situation was presented independently. When the participants chose one phrase for the presented situation and proceeded to the next, a new situation (different pairs of X and Y) was presented. The task was performed using the same procedure until all the responses were completed. The order of presentation of the situations was randomized for each participant.
On average, all experimental tasks, including the irrelevant task 8 , were completed in 20 minutes (approximately 15 to 30 minutes).


Results and discussion
Figure 5 illustrates the relationship between the nine situations and the proportion of positive phrase choices. Negative phrases were preferred when the conveying probabilities were low. By contrast, positive phrases were preferred when the conveying probabilities were high.
Furthermore, we examined which model could better predict positive phrase choice patterns. We compared the DbBS models with the estimated probabilistic beliefs, that is,
. For each of the three models, we used two beliefs estimated in Experiments and (group-level mean of and ). Given that the results obtained in Experiments and 2 were essentially identical, the average of the predictions obtained using the parameters estimated from each experiment was used as the prediction for each model. For the DbBS model-based prediction, we proposed another prediction, called DbBS with intermediate belief (we note "DbBS; IntBelief"). This model assumes that the speaker has a "50%" belief, which is based on the findings of Bruine de Bruin et al. 
2000
as discussed earlier (i.e., the default value for epistemic and aleatory uncertainty in case of the binary events). The model assumes that the mean of the beta distribution is 50% (i.e., Î± = Î²) and predicts choice. Predictions were made using the values of the parameter that best fitted (i.e., when the absolute error in positive phrase choice rates between prediction and observed data was the smallest) when Î± and Î² were varied from 2 to 10, in the increment of 0.1 9 .
Again, as in Experiments 1 and 2, we propose a numerical meaning model called the Membership Function Model (MFM) as one of the competing models. This model makes predictions baesd on the membership values (i.e., how well a verbal probability represents the probability p) measured in Experiment 1. If a verbal probability has a high membership value for a probability x, we can assume that the verbal probability was judged to be appropriate for communicating probability x. The MFM predicts the probability that a positive phrase will be selected to express a probability, â„Ž ( ), in the following way.
â„Ž ( ) = âˆ‘ ( ) âˆ‘ ( ) + âˆ‘ ( )
(6)
where âˆ‘ ( ) [or âˆ‘ ( )] indicates summation of membership values for 8 positive (or negative) phrases for probability x. The model assumes that a verbal probability with a higher membership value for probability x is more likely to be selected when probability x is conveyed using a verbal probability. Thus, it quantitatively predicts that positive phrases will be chosen more often when summation of membership values for positive phrases becomes higher than that for negative phrases.
Additionally, we introduced linear and beta regression 
(Ferrari & Cribari-Neto, 2004)
 models as competitive models. Thus, we compared seven predictions regarding the choice rates of the positive phrases. We examined the prediction accuracy in terms of the mean absolute error between the observed choice rates and the model predictions.
The upper panel of 
Figure 6
 shows the relationship between the observed choice pattern and model predictions, and 
Table 4
 shows the mean absolute error between the observed choice patterns and model predictions. The prediction of the DbBS models with
( | , |
) was the best among the four predictions from the DbBS model. The predictions of the linear and beta regression models were highly comparable to that of the DbBS model with
( | , | )
.


Summary of Experiment 3
Experiment 3 tested whether the DbBS model could predict the choice rate of positive phrases for conveying probabilistic information. The results show that the prediction by the DbBS model
with ( | , |
) was highly consistent with the observed choice pattern of the positive phrases. These results supported Predictions (3) and (4). The two regression models simultaneously explain the observed choice patterns well.
We have the following thoughts about why
( | , |
) was the best predictor of speakers' choice patterns of directionality. When communicating probabilistic information using verbal probabilities, speakers may have a default probabilistic belief. That is,
affects their choice of verbal expressions.
( | , |
) reflects a speaker's default belief of 
( , )
 . Given that people hold certain probabilistic beliefs by default 
(Bruine de Bruin et al., 2000;
Mckenzie et al., 2001;
Mckenzie & Mikkelsen, 2000)
, the present findings provide further evidence about this in the context of probabilistic communication using verbal probabilities. 


Experiment 4: Replication of Experiment 3 and examination with cross-validation method
The results of Experiment 3 showed that speakers' tendency to choose positive phrases when conveying probabilistic information was highly consistent with the predictions of the DbBS model with
( | , | )
. We did not formulate a clear hypothesis regarding this finding prior to conducting the experiments. Therefore, we verified whether these results could be replicated.
Additionally, the linear and beta regression models explained the choice patterns well.
This finding implies that speakers' directionality choices may be explained by different mechanisms. However, we note that the competitive test in Experiment 3 was conducted in a "wicked" environment for the DbBS model. The DbBS model made the so-called "predictions."
In other words, it predicts the positive phrase choice rate without any free parameters. However, the two regression models had free parameters. The parameters were adjusted to best explain the data, and errors between the model predictions and observed data were calculated. In other words, it was "fitting" rather than "prediction." This difference between prediction and fitting is critical for evaluating model validity 
(Gigerenzer & Brighton, 2009;
Roberts & Pashler, 2000)
, and the comparison method used in Experiment 3 may have been unfair.
In Experiment 4, the models were compared using cross-validation. Specifically, we collected sufficient experimental data to split the data into training and test sets. In the training set, fitting was performed as in Experiment 3 (the estimation of parameters for the two regression models). Furthermore, we compared the prediction errors of the estimated models for the choice data in the test set. That is, the DbBS model and two regression models "make predictions" for the test set. Experiment 4 aimed at determining the model that produced the best predictions for the data in the test set.


Method


Participants and experimental design
A total of 203 Japanese participants (56 women and 147 men; Mage = 54.921, SDage = 10.321) participated in the experiment. They received coupons that were redeemable for online shopping in Japan. As noted above, we planned to split the experimental data into training and test sets and conduct many simulations (see Section 6.2.2). We determined 200 data as a "sufficient number" for this analysis plan and recruited participants accordingly.


Tasks, materials, and procedure
Participants completed the tasks via the Internet as part of experimental tasks. The tasks, stimuli, and procedures used in Experiment 4 were the same as those used in Experiment 3.


Results and discussion


General trend of positive phrase choice and prediction of positive phrase choice
The general trends of positive phrase choices ( 
Figure 5)
 and errors between the observed choices and model predictions ( 
Figure 6
 and 
Table 4
) were the same as those in Experiment 3.


Model comparison with cross-validation method
Furthermore, we reported the main topic of Experiment 4: model comparisons using the crossvalidation method. We conducted this comparison using the following procedure:
(1) We randomly sampled 102 participants for the training set and the other participants for the test set.
(2) For each set, we calculated the positive phrase choice rates for the nine probabilistic situations.
(3) The parameters for the linear and beta regression models were estimated using the calculated positive phrase choice rates in the training set. The estimated parameters were used for the linear and beta regression models in Step (4).
(4) The absolute errors between the positive phrase choice rates in the training and test sets and the model predictions were calculated.
(5) Steps (1)-(4) were repeated 10,000 times and the mean of the absolute errors calculated in (4) was used as the performance of each model.
We examined how prediction errors varied between the training and test sets. In this analysis, only the results of the DbBS model with  DbBS model in the training set, this relationship was reversed in the test set. This is because the error increased from the training to the test sets for the regression models, whereas the error barely changed between the two datasets for the DbBS model. This indicates that the regression models overfit the training set, resulting in larger errors in the test set. However, this was not the case in the DbBS model. The DbBS model provided accurate predictions independent of the data sample, suggesting that the model accuracy was robust.


Summary of Experiment 4
Experiment 4 tested whether the choice rate of positive phrases for conveying probabilistic information could be predicted by the DbBS model, using a cross-validation method. The results showed that the prediction errors for the regression models increased from the training to the test sets. By contrast, the prediction errors of the DbBS model did not vary between the two sets.
In addition, the prediction errors of the DbBS model were smaller than those of the regression models in the test set. These results suggest that the DbBS model provides accurate predictions independent of the data sample. Therefore, we can assume that the DbBS model is valid for predicting the choice of directionality when communicating probabilistic information using verbal probability.
It is true that the regression models explained the observed positive phrase choice rates for the training sets very well (i.e., they showed a very good fit). At the same time, they performed quite well in terms of prediction (although not as well as the DbBS model). However, the regression model could not provide unified explanations of the phenomena of decisionmaking and communication, which are different contexts. It is noteworthy that the DbBS model was able to make very good predictions of the phenomena in communicative behaviors observed in Experiments 3 and 4 based on parameters estimated from the phenomena in different contexts (i.e., decision behaviors) in Experiments 1 and 2.


Experiment 5: Effect of local context on probabilistic belief
In Experiment 5, the DbBS model was examined in detail. The DbS model discusses the construction of a decision sample based on the local context. Local context refers to a situation (e.g., the experimental setting) in which people make decisions.  
, $13]
. The evaluation for "10%" may differ between the two situations. 
Stewart et al. (2006)
 showed that the relative ranks [Equation 
1
], calculated based on the probabilities used in the experiment of 
Gonzalez and Wu (1999)
 are highly similar to the shape of the probability weighting function, suggesting that the local context (i.e., the stimuli used in the experiment) affects the formation of the decision samples. As direct evidence of the role of local context in the formation of a decision sample, Walasek and Stewart (2015) reported interesting findings regarding loss aversion. They showed that manipulating the range of gain and loss amounts for gambles used in the experiment (i.e., changing the relative ranks for the same amount of money in the local context) can eliminate or reverse loss aversion.
Thus, the local context may play an important role in the formation of a decision sample. Based on these findings, the presentation of different verbal probabilities during the experiment may have led to differences in probabilistic beliefs (i.e., decision sample). In Experiment 5, we examined how the probabilistic beliefs held by participants differed by changing a set of verbal probabilities. In Experiments 1 and 2, 16 phrases (8 positive and 8 negative) were presented as verbal probabilities. In Experiment 5, we examined the difference in probabilistic beliefs formed when presented with positive phrases by varying the number of negative phrases presented. The number of negative phrases is listed in 
Table 5
. The focus was on whether the difference in the presented negative phrases would affect the probabilistic beliefs when presented with positive phrases. If differences are generated, it follows that the local context affects the formation of probabilistic beliefs, analogous to previous findings on DbB model.


1. Method


Participants and experimental design
A total of 255 Japanese participants (106 women, 147 men, and two participants did not want to answer their gender; Mage = 42.984, SDage = 9.713) participated in the experiment. They were paid 250 yen (approximately 1.8 US dollars at the current exchange rate) as compensation for participating in the experiment. They were randomly allocated to one of the four groups. We denoted the specific number of participants in each group in 
Table 5
. We recruited participants via the web using the same policy as in Experiment 1.


Tasks, materials, and procedure
The tasks, materials, and procedures were the same as those in Experiment 2, with the following numerical probabilities . Second, as previously mentioned, the number of negative phrases varied across the experimental groups, ranging from zero to eight phrases. Third, only numerical translations were asked for the presented verbal probabilities. All experimental tasks were completed within 10-15 min. 
Figure 8
 shows the distribution of the decision ratings for the eight positive phrases. Gray dots show raw data, and the orange points and error bars indicate bootstrapped mean (95% confidence interval). Significant differences were not found among the four groups. This was also true for the numerical translations (details are provided in the supplementary material).


2. Results


General trend of decisions for positive phrases


Differences in probabilistic beliefs among the groups
To examine the effect of local context on probabilistic beliefs, we conducted the following analyses: First, we estimated the probabilistic beliefs of each experimental group using the same method as in Experiments 1 and 2. Then, using the parameters of the estimated and for group-level mean (see 3.2.2), the distance of the probabilistic beliefs (i.e., beta distributions) was measured using Kullback-Leibler divergence (hereafter, KL divergence).
1~Î’ ( 1 , 1 ) and 2~( 2 , 2 ), KL divergence, and ~( 1 , 2 ), are defined as follows:
( 1 , 2 ) = ln ( ( 2 , 2 ) ( 1 , 1 ) ) + ( 1 âˆ’ 2 ) ( 1 ) + ( 1 âˆ’ 2 ) ( 1 ) + ( 2 âˆ’ 1 + 2 âˆ’ 1 ) ( 1 + 1 )
(7)
where Ð’ denotes the beta function, and Ïˆ is the digamma function. When DKL is close to zero, the two beta distributions are very similar; in other words, the estimated probabilistic beliefs are very similar. The more DKL takes a larger value, the more the two beta distributions differ 11 .
Thus, when DKL has a small value, the estimated beliefs are analogous (DKL becomes zero when two decision samples are perfectly matched).
It is difficult to understand the degree of similarity between the two distributions using only KL divergence values. Therefore, we set the KL divergences between the two distributions estimated in Experiments 1 and 2 as benchmarks; [positive and negative phrases  between the beta distributions estimated for the different types of information in Experiments and 2. In contrast, DKL was relatively low between the beta distributions estimated for the two groups. Combined with the fact that there were no significant differences between the groups with respect to decision ratings, this result indicates that the local context did not have a significant effect on the probabilistic beliefs held by the participants in the experiment.


Summary of Experiment 5
We analyzed the effect of local context (varying the set of presented verbal probabilities) on the probabilistic beliefs held by participants, and no significant effects were observed. This experiment was conducted based on discussions of the effect of local context on the decision sample in the DbS model 
(Stewart et al., 2006)
 and the previous findings of 
Walasek and Stewart (2015)
.
The present results seemed inconsistent with the findings of 
Walasek and Stewart (2015)
, in which the local context produced a different decision phenomenon (the local context produced loss aversion, disappearance of loss aversion, or reversals with respect to loss aversion). However, this does not necessarily imply a contradiction. First, the task used in this study differed from that used by 
Walasek and Stewart (2015)
. Therefore, Walasek and Stewart's (2015) findings may not be directly applicable to the present task. In particular, we believe that the effect of the local context may be relatively weak in the context of the communication of probabilistic information using verbal probabilities. When verbal probability is used to communicate probabilistic information, a speaker's probabilistic beliefs may be strongly reflected. As discussed in Section 1.1, the directionality of verbal probabilities conveys a speaker's probabilistic beliefs 
(Honda & Yamagishi, 2017)
. In other words, rather than the local context, the verbal probability itself has a strong effect on the probabilistic beliefs held by the decision maker. Conversely, the effect of the local context on the decision maker's probabilistic belief may be relatively weak. Thus, it is possible that the difference in tasks between the present study and that of 
Walasek and Stewart (2015)
 was directly related to the strength of the effect of the local context.


General discussion


Summary of this study's contributions
This paper discusses decisions and communication based on verbal probabilities. The contributions of this study are summarized as follows.
First, we pointed out the close relationship between two decision-making models (DbS and the reference point hypothesis), which are ostensibly unrelated, and then proposed a model that integrates them. The DbS model can explain various phenomena relevant to decisionmaking, such as value functions, probability weighting functions, or time discounting. By contrast, the reference point hypothesis explains why a framing effect occurs. Thus, the scope of the DbS model and reference point hypothesis differ. However, this study pointed out the close relationship between the DbS model and the reference point hypothesis and proposed a unified model that can make quantitative predictions for decisions and communicative behaviors.
We believe that insights into decisions can be obtained from a new perspective when the common mechanisms among ostensibly different models and hypotheses are identified.
Second, we clarified the relationship between communication behaviors and decision-making. Previous studies addressed this issue. 
Hilton (1995)
 comprehensively discussed cognitive biases in judgments based on 
Grice's (1975)
 maxima of conversations. 
Hilton (1995)
 argued that conversational inference plays an important role in making judgments and that superficial cognitive errors could be due to rational processes of conversational inferences. Similarly, 
McKenzie and Nelson (2003)
 and 
Sher and McKenzie (2006
, 2011
 discussed the importance of considering the framing effect from a communication perspective.
The difference between these previous studies and this study is that the latter proposes a quantitative model for a unified explanation of decision-making and communicative behaviors.
This approach can provide insights into the commonalities between ostensibly unrelated models. incoherence 
(Thaler & Sunstein, 2008;
Tversky & Kahneman, 1986)
. This study showed that the decision bias produced by the directionality of verbal probabilities can be explained in terms of the processes of listeners' inferences about the speaker's probabilistic belief and the series of psychological processes with which the listener reflects the inferred belief in their decisions.
The findings have implications for the rationality of decision-making based on verbal probabilities; whether decisions affected by directionality are rational. At the very least, there is a reasonable reason for the inconsistency between decisions based on positive phrases and those based on negative ones (i.e., decisions change depending on the directionality of verbal probabilities even when positive and negative phrases convey analogous probabilities). It is important to discuss rationality not only from the perspective of inconsistency, but also from the psychological processes behind the inconsistency 
(Arkes et al., 2016)
.
Finally, we discuss the findings of this study and those of the cumulative prospect theory (CPT) research. CPT 
(Gonzalez & Wu, 1999;
Tversky & Kahneman, 1992)
 discuss the probability weighting function (the subjective weighting of probability information denoted by an explicit numerical value). The non-linear curve of the probability weighting function is similar to that of the decision ratings for positive and negative phrases as shown in 
Figure 2
, as well as the positive word choice rate as shown in 
Figure 5
. Further analysis of the relationship between communicating probabilistic information (e.g., the directionality with which a verbal probability is conveyed) and the probability weighting function may reveal a relationship between communication behavior and risk attitudes. For example, a certain risk attitude (represented by a probability weighting function) can predict communication about probabilistic information using verbal probabilities (e.g., preference for positive or negative expressions), and probabilistic beliefs may be mediated here. At the same time, we note that our DbBS-based and CPT-based approaches have different goals. For example, the CPT-based approach can clarify how people make decisions based on probabilistic information in terms of sensitivity to probabilistic information and risk attitude 
(Gonzalez & Wu, 1999)
. We point out that sensitivity to probabilistic information and risk attitude, which are at the essence of explaining decision behaviors in CPT, may not be directly connected to the communicative functions of probabilistic information. For example, the relationship between the communicative function of verbal probabilities (e.g., a speaker with low probabilistic belief tends to use positive phrases, and listeners can infer the speaker's probabilistic belief) and sensitivity of probabilities as well as risk attitude may not be apparent. Therefore, although the similarities between the present findings and probability weighting functions are interesting and may be closely linked (as noted above, it is possible that various phenomena can be explained in a unified manner in terms of probabilistic beliefs), it is necessary to accumulate more evidence in the future research.
In sum, we believe that the findings of the present study will provide a new perspective to clarify the nature of human decision-making.


Quantitative approach for phrase selection in verbal probabilities
The DbBS provides quantitative predictions for positive phrase choices. The results of Experiments 3 and 4 showed that the DbBS model explained the rates of positive phrase selection very well. Previous studies have examined the effect of reference points on the choice of directionality in verbal probabilities from a qualitative perspective (e.g., positive phrases are more likely to be chosen when presented with a low reference point than when presented with a high reference point). Previous approach is a rigorous method of examining the effect of reference points on directionality choice. In addition, the present study provides new explanations for the observed patterns in directionality choices. For example, the model based on the membership function did not explain positive phrase choice very well (see the results in Experiments 3 and 4). In other words, a psychological mechanism exists that cannot be explained solely by the numerical meanings of verbal probabilities, which are well represented by the membership function. The DbBS model is a good candidate for explaining the psychological processes involved in the choice of directionality in verbal probabilities. 
Sher and McKenzie (2006)
 argued that the framing effect is not a so-called "bias," but rather a listener's inference about a recommendation by a speaker. The DbBS model did not directly model the speakers' recommendations. However, we note that the speakers' recommendations are related to their beliefs. For example, when a speaker recommends a certain treatment, they recommend a treatment based on a comparison with others (for a specific discussion, see Section 2.2.2). In the context of probabilistic communication, speakers may hold probabilistic beliefs (with which their recommendations are constructed) and use positive or negative phrases based on their beliefs. Therefore, the DbBS model can represent a speaker's implicit recommendations.


Model assumption and applicability into other contexts


Limitations of this study
We examined the effect of local context on the formation of probabilistic beliefs in Experiment 5. Although we did not find a significant effect of local context, further research is necessary to examine when probabilistic beliefs are susceptible to the effects of local context.
Five experiments were conducted in Japan. Thus, it is an empirical question as to whether the present findings can be observed in other languages. However, we note that the feature of directionality are not limited to Japan. In addition, the reference point hypothesis (the hypothesis about linguistic usage), which is one of the most important bases for the DbBS model, was based on intuitions about usage of the English language 
(McKenzie & Nelson, 2003)
.
Although future research is necessary, we believe that the present findings can be observed in other languages.    
Table 5
. Presented verbal probabilities for each group in Experiment 5.         . DKL between two probabilistic beilefs (beta distributions).


Group type
5 As participants rated membership values twice for each phrase, we regarded the mean of the membership values as the membership value for the phrase. Ratings are assumed to have some fluctuations. Small differences in ratings may not indicate an essential difference. Thus, we assumed that a difference of five points or less does not reflect an essential difference. When some probability values took membership values five or less from the max membership value, we defined the mean of these probability values as the peak. For example, when membership values for 70% and 80% were 98 and 100 respectively, the peak was 75% (i.e., [0.7 + 0.8] / 2). 
6
 To test the robustness of estimation, we conducted the parameter estimation using a different prior distribution. Specifically, we examined the estimation of and , each assumed to be taken over a wider range (0.1~50). We found that the prior distributions had little effect and the estimation results were almost identical. We have reported these details in the supplementary material.
7 Some researchers may be concerned about the effect of the difference in probabilities conveyed by positive and negative phrases on the results obtained here. That is, positive phrases tend to convey higher probabilities (see supplementary material), and this may have affected the results. This possibility is unlikely based on the results of the model recovery test (we have described this in the supplementary material). In the model recovery test, we examined the effect of differences in the probabilities indicated by positive and negative phrases on the estimation of probabilistic beliefs. The results showed that the difference in probabilities indicated by positive and negative phrases had little effect on the estimation of probabilistic beliefs.
Although this task was conducted concurrently with other tasks for other research projects, this task was conducted first (this was true for Experiment 4). Therefore, the effect of other tasks on this task was excluded.
: w(Ï„) can be characterized by the cumulative distribution function (CDF) of the ( , ). The listener decides based on w(Ï„). depending on the information presented, such as positive or negative phrases or numerical probabilities.


Figure 1(A) presents four examples of probabilistic beliefs about uncertain events. The four examples differ in the following respects: Example 1 (4) represents a low (high) probabilistic belief, and the listener believes that there is a low (high) probability that an event will occur. Example 2 shows the vaguest belief about an event, in which the listener has no idea about the probability of an uncertain event. Example 3 represents the belief that an uncertain event will occur approximately 50% of the time. These examples show that beta distributions represent an extensive range of beliefs about uncertain events. In the DbBS model, w(Ï„) is directly related to the cumulative distribution function (CDF) of the beta distribution. When a listener's probabilistic belief is represented with the Beta distribution, ( , ), w(Ï„) is expressed as follows:


(


positive expression, that is, w(p) in Figure 1 (B) corresponds to the expected choice rate of the positive expression because the value of the CDF corresponds to the percentile of probability p. Although we examine Prediction (4) in a novel experimental setting, we have the following rationale, based on previous findings by McKenzie and Nelson (2003): They demonstrated that a listener accurately infers the speaker's reference point based on the presented frame. Accordingly, in the context of communication that uses verbal probabilities, a listener may be able to accurately infer the speaker's probabilistic beliefs. In other words, a listener's probabilistic beliefs may reflect those of the speaker. Here, there are three possible candidates for


represents the beta function, and ( ; , ) represents the incomplete beta function. represents the fluctuation (noise) of the decision for participant i stemming from uninformative uniform priors, ~(0,0.25). To assign priors to group-level priors, we used uninformative uniform priors, ~(âˆ’2.303, 2.303) , ~(âˆ’2.303, 2.303) , ~(0, 1.329), and ~(0, 1.329). Our pre-analysis of maximum likelihood estimation


Figure 3
3
shows examples of model fitting for five participants. As shown in this figure, the decision patterns vary depending on the participant and type of probability. However, the DbBS model captures diverse decision patterns.


summaries of group-level posterior distributions of parameters ( , , and mean of beta distribution). The posterior distributions for the estimated probabilistic beliefs differed among the three types of probabilistic information presented, which is consistent with Prediction (1). Furthermore, consistent with Prediction (2), we found that mean probabilistic beliefs were higher when presented with negative phrases than when presented with positive phrases. For Prediction (2), we examined the estimated probabilistic beliefs at the individual level when presented in positive or negative phrases. The left panel of Figure 4 shows the estimated means of the probabilistic beliefs at the individual level. In this figure, each plot indicates the estimated mean of each participant's probabilistic beliefs for the positive and negative phrases. The means of the estimated probabilistic beliefs were higher when presented with negative phrases than with positive phrases [t (59) = 16.592, p < .001, d = 2.142]. Thus, Prediction (2) was corroborated at the individual level.


The
DbBS model provides new insights into the effects of probabilistic information on decision-making. The model explains this effect as follows: when presented with verbal probabilities, people infer speaker's probabilistic beliefs based on the directionality of verbal probabilities. These inferences create different decision samples, and different decision samples generate different decisions.


Figure 7
7
presents the results of the analysis. The regression and DbBS models exhibited different trends. Although the regression models exhibited smaller errors than the


(
Pos-Neg)], [positive phrase and numerical probability (Pos-Num)], and [negative phrase and numerical probability (Neg-Num)]. As discussed in Experiments 1 and 2, the presentation of different types of probabilistic information led to different types of probabilistic beliefs. Using this difference as a benchmark, we analyzed the effect of local context on the probabilistic beliefs held by decision makers.


Figure
presents the results of the analysis. As is apparent, DKL was relatively high


Sumers et al. (2024)
 provide new insights into rational communication by introducing a decision-theoretic quantitative framework for communicative behaviors. Similarly, we bridged the ostensibly unrelated decision models (DbS and the reference point hypothesis) from the quantitative perspective of the DbBS model. Third, we clarified the psychological mechanisms underlying decision bias produced by the directionality of verbal probabilities. The effect of directionality on decisions is a type of framing effect. Framing effects are often regarded as irrational decisions in terms of decision


Figure 1 .
1
Summaries of the DbBS model. (A) Probabilistic belief regarding an uncertain event, represented by the PDF of the beta distribution. In the DbBS model, decision samples are assumed to be constructed based on probabilistic belief. (B) Subjective value for target probability Ï„, represented by the CDF of the beta distribution.


Figure 2 .
2
Relationship (aggregated) between numerical translations (or probability values) and decision ratings in Experiments 1 and 2.


Figure 3 .
3
Model fitting for five participants. The dots denote observed data [x-axis; numerical translation for verbal probability (or presented probability for numerical probability), y-axis;decision rating] and the solid lines denote prediction by the DbBS model. The results of positive phrases, negative phrases, and numerical probabilities are demonstrated in the top, middle, and lower panel, respectively.


Figure 4 .
4
Means of estimated probabilistic beliefs (beta distribution) when presented with positive or negative phrases. In this figure, each plot indicates the estimated mean of the probabilistic beliefs for each participant for positive and negative phrases.


Figure 5 .
5
Proportion of positive phrase choice as a function of conveying probabilities in Experiments 3 and 4.


Figure 6 .
6
Model fittings for observed choice data. X-axis denotes the nine situations about conveying probabilities, and y-axis denotes proportion of positive phrase choice. In these figures, dots indicate observed data and solid lines indicate model predictions.


Figure 7 .
7
The absolute errors between observed choice rates and model predictions in the training and test sets.


Figure 8 .
8
Decision ratings for the eight positive phrases in Experiment 5. Grey points show raw data, and orange points and error bars indicate bootstrapped mean (95% confidence interval).


Figure 9
9
Figure 9. DKL between two probabilistic beilefs (beta distributions).


Table 2 .
2
Results of model comparison. Lower (or higher) value indicates a better model in WAIC (or ELPD). Highlighted text indicates the best model fit statistic among competitive models.
in
decision
making
under
uncertainty.
Cognition,
175,
186-200.
https://doi.org/10.1016/j.cognition.2018.02.019
McKenzie, C. M., & Nelson, J. (2003). What a speaker's choice of frame reveals: Reference
points, frame selection, and framing effects. Psychonomic Bulletin & Review, 10(3),
596-602. https://doi.org/10.3758/BF03196520
Mckenzie, C. R. M., Ferreira, V. S., Mikkelsen, L. A., McDermott, K., & Skrable, R. P. (2001).
Do conditional hypotheses target rare events? Organizational Behavior and Human
Decision Processes, 85, 291-309. https://doi.org/10.1006/obhd.2000.2947
Mckenzie, C. R. M., & Mikkelsen, L. A. (2000). The psychological side of Hempel's paradox
of confirmation. Psychonomic Bulletin & Review, 7(2), 360-366.
https://doi.org/10.3758/BF03212994
Meder, B., Mayrhofer, R., & Ruggeri, A. (2022). Developmental trajectories in the
understanding of everyday uncertainty terms. Topics in Cognitive Science, 14, 258-281.
https://doi.org/10.1111/tops.12564


Table 3 .
3
Summaries of posterior distributions of parameters at group level. The number in each cell (or numbers in parentheses) represents the median (or 95% credible interval) of the posterior distribution in Bayesian estimation.
Experiment 1
Probability type
Mena of beta distribution
Positive
0.399(0.322-0.498)
0.545(0.462-0.649)
0.422(0.376-0.470)
Negative
1.008(0.775-1.348)
0.391(0.302-0.508)
0.720(0.677-0.764)
Numerical
1.280(1.050-1.556)
1.411(1.222-1.629)
0.475(0.423-0.527)
Experiment 2
Probability type
Mena of beta distribution
Positive
0.983(0.764-1.272)
1.057(0.851-1.299)
0.482(0.434-0.532)
Negative
1.473(1.098-1.995)
0.467(0.340-0.649)
0.759(0.702-0.811)
Numerical
1.624(1.407-1.879)
1.286(1.087-1.523)
0.558(0.511-0.605)


Table 4 .
4
Mean absolute error between observed choice pattern and model prediction.
Mean absolute error:
Mean absolute error:
Model
Choice data in Experiment 3
Choice data in Experiment 4
DbBS: Positive
0.053
0.037
DbBS: Negative
0.317
0.315
DbBS: Numerical
0.112
0.118
DbBS; IntBelief
0.145
0.148
MFM
0.171
0.147
Linear regression
0.057
0.031
Beta regression
0.063
0.038


In the following analyses, the ratings for decision-making and evaluations of probabilities were mapped on a 0-1 scale.


For both data in Experiments 3 and 4, the parameters of Î± and Î² with the smallest errors were when = = 2.10 In Experiments 1 and 2, participants were asked to answer the decision task for verbal probabilities before answering for numerical probabilities. Therefore, the experimental procedure up to decisions based on the verbal probabilities was exactly the same among Experiments 1, 2, and 5.11 As DKL is non-symmetrical (i.e., DKL[X1, X2]  â‰  DKL[X2, X1]), we regard the mean of DKL(X1, X 2 ) and D KL (X 2 , X 1 ) as the D KL for the two distributions.








Positive phrase
Original expression
It is almost certain that* hobo kakuzitsu Note. The order in which the expressions are presented ranges from high to low probability. For the English expressions, we translated the Japanese verbal probabilities in a manner that was the most natural when translated into English. In a previously published paper 
(Honda & Yamagishi, 2017)
, the translation method was rigorously discussed among researchers and native English speakers to determine one-to-one correspondence between Japanese and English. We present expressions based on this.


Footnotes
In addition to these two tasks, we conducted another task about probability values after these two tasks. As results were not essentially relevant to the present discussion about hypotheses, we did not report results in the main text. Refer to the supplementary material for more details.
2 Negative phrases, as a general trend, convey a narrower range of probabilities than positive phrases. This tendency was observed in this study. As to negative phrases, the peak values of the membership function in Experiment 1 and the numerical translations in Experiment 2 were 0.5-0.6 even for expressions indicating high probabilities (around 0.8-0.9 for positive expressions). Thus, it is difficult to compare positive phrases (which cover low to high probabilities) and negative ones in a strictly parallel manner, due to semantic natures of verbal probabilities. This point was also discussed in 
Teigen and Brun (1999)
. However, the membership values indicated that negative phrases were not necessarily inappropriate as expressions for communicating high probabilities. In Experiments 3 and 4, MFM (for details, refer to Experiment 3) did not always predict a very high proportion of a positive phrase choice when conveying high probabilities. Thus, the gap in the range of conveying probabilities between positive and negative phrases may not be as large as it seems.
3 Participants were presented with 35 images of product (snacks) in total and asked to answer how likely they wanted to buy each using a 101-point scale and what impression they got from the product package for each image (We conducted the same task as the irrelevant task in Experiment 2). Therefore, this task was unrelated to the subject of this study.
 










Reexamining How Utility and Weighting Functions Get Their Shapes: A Quasi-Adversarial Collaboration Providing a New Interpretation




D
Alempaki






E
Canic






T
L
Mullett






W
J
Skylark






C
Starmer






N
Stewart






F
Tufano




10.1287/mnsc.2018.3170








Management Science




65


10
















How bad is incoherence?




H
R
Arkes






G
Gigerenzer






R
Hertwig




10.1037/dec0000043








Decisions




3


1
















Money and happiness: rank of income, not income, affects life satisfaction




C
J
Boyce






G
D A
Brown






S
C
Moore








Psychological Science




21


4


















10.1177/0956797610362671














Verbal and Numerical Expressions of Probability




W
Bruine De Bruin






B
Fischhoff






S
G
Millstein






B
L
Halpern-Felsher








Organizational Behavior and Human Decision Processes




81


1










It's a Fifty-Fifty Chance










10.1006/obhd.1999.2868














Predicting the directionality of probability words from their membership functions




D
V
Budescu






T
M
Karelitz






T
S
Wallsten




10.1002/bdm.440








Journal of Behavioral Decision Making




16


3
















Processing linguistic probabilities: General principles and empirical evidence




D
V
Budescu






T
S
Wallsten




10.1016/S0079-7421(08




J. Busemeyer, R. Hastie, & D. L. Medin






Academic Press


32














The rule of three: How the third event signals the emergence of a streak




K
A
Carlson






S
B
Shu








Organizational Behavior and Human Decision Processes




104


1


















10.1016/j.obhdp.2007.03.004














Statistical power analysis for the behavioral sciences second edition




J
Cohen








Lawrence Erlbaum Associate












Verbal and numeric probabilities differentially shape decisions. Thinking and Reasoning




R
N
Collins






D
R
Mandel






B
A
Macleod




















10.1080/13546783.2023.2220971














Communicating uncertainty using words and numbers




M
K
Dhami






D
R
Mandel








Trends in Cognitive Sciences




26


6


















10.1016/j.tics.2022.03.002














Beta regression for modelling rates and proportions




S
Ferrari






F
Cribari-Neto








Journal of Applied Statistics




31


7


















10.1080/0266476042000214501














of single-trial EEG measures describe latent effects of spatial attention during perceptual decision making


10.1016/j.jmp.2022.102725








Journal of Mathematical Psychology




111


102725












Homo heuristics: Why biased minds make better inferences




G
Gigerenzer






H
Brighton




10.1111/j.1756-8765.2008.01006.x








Topics in Cognitive Science




1


1
















On the shape of the probability weighting function




R
Gonzalez






G
Wu




10.1006/cogp.1998.0710








Cognitive Psychology




38


1
















Logic and conversation




H
P
Grice








Syntax and semantics 3: Speech acts


P. Cole & L. Morgan




Academic Press
















Optimal predictions in everyday cognition




T
L
Griffiths






J
B
Tenenbaum




10.1111/j.1467-








Psychological Science




17


9
















The social context of reasoning: Conversational inference and rational judgment




D
J
Hilton




10.1037/0033-2909.118.2.248








Psychological Bulletin




118


2
















Decision Making


10.1017/S1930297500005568






10














When probabilities change: perceptions and implications of trends in uncertain climate forecasts




S
M
Hohle






K
H
Teigen








Journal of Risk Research




22


5


















10.1080/13669877.2018.1459801














Do people explicitly make a frame choice based on the reference point?




H
Honda






M
Shirasuna






T
Matsuka






K
Ueda




10.3389/fpsyg.2018.02552








Frontiers in Psychology




9














Directional verbal probabilities: Inconsistencies between preferential judgments and numerical meanings




H
Honda






K
Yamagishi




10.1027/1618-3169.53.3.161








Experimental Psychology




53


3
















Perceived certainty based on verbal probability phrases: Effect of directionality and its dependence on method




H
Honda






K
Yamagishi




10.1111/j.1468-5884.2009.00409.x








Japanese Psychological Research




4


51














Communicative functions of directional verbal probabilities: Speaker's choice, listener's inference, and reference points




H
Honda






K
Yamagishi








Quarterly Journal of Experimental Psychology




70


10


















10.1080/17470218.2016.1225779














Can membership-functions capture the directionality of verbal probabilities? Thinking and Reasoning




M
Juanchich






M
Sirota






T
M
Karelitz






G
Villejoubert




10.1080/13546783.2013.772538








19














Is guilt 'likely' or 'not certain'?: Contrast with previous probabilities determines choice of verbal terms




M
Juanchich






K
H
Teigen






G
Villejoubert




10.1016/j.actpsy.2010.04.016








Acta Psychologica




135


3
















Prospect theory: An analysis of decision under risk




D
Kahneman






A
Tversky




10.2307/1914185








Econometrica




47


2
















Perspectives on framing




G
Keren








Psychology Press












Doing bayesian data analysis: A tutorial introduction with R, JAGS, and Stan




J
K
Kruschke








Academic Press












The role of inference in attribute framing effects




L
M
Leong






C
R M
Mckenzie






S
Sher






J
MÃ¼ller-Trede




10.1002/bdm.2030








Journal of Behavioral Decision Making




30


5
















estimation for cumulative prospect theory


10.1016/j.jmp.2010.08.006








Journal of Mathematical Psychology




55


1














Multialternative decision by sampling: A model of decision making constrained by process data




T
Noguchi






N
Stewart








Psychological Review




125


4


















10.1037/rev0000102














Distributions of observed death tolls govern sensitivity to human fatalities




C
Y
Olivola






N
Sagara




10.1073/pnas.0908980106








Proceedings of the National Academy of Sciences


the National Academy of Sciences






106














The framing preference for large and increasing components in static and dynamic descriptions




H
Pander Maat






B
Staal






B
Holleman




10.3389/fpsyg.2021.720427








Frontiers in Psychology




12














The ecology of competition: A theory of risk-reward environments in adaptive decision making




T
J
Pleskac






L
Conradt






C
Leuker






R
Hertwig




10.1037/rev0000261








Psychological Review




128


2






















Journal of Experimental Psychology. General




143


5
















10.1037/xge0000013














How persuasive is a good fit? A comment on theory testing




S
Roberts






H
Pashler




10.1037/0033-295x.107.2.358








Psychological Review




107


2
















The effect of relative encoding on memory-based judgments




M
A
Sharif






D
M
Oppenheimer








Psychological Science




27


8


















10.1177/0956797616651973














Information leakage from logically equivalent frames




S
Sher






C
R M
Mckenzie




10.1016/j.cognition.2005.11.001








Cognition




101


3
















The probabilistic mind: Prospects for Bayesian cognitive science




S
Sher






C
R M
Mckenzie




N. Chater & M. Oaksford






Oxford University Press








Framing effects and rationality








Levels of information: A framing hierarchy




S
Sher






C
R M
Mckenzie








Perspectives on framing


G. Keren




Psychology Press






















The Quarterly Journal of Experimental Psychology




62


6
















10.1080/17470210902747112














Decision by sampling




N
Stewart






N
Chater






G
D A
Brown




10.1016/j.cogpsych.2005.10.003








Cognitive Psychology




53


1
















Prospect relativity: How choice options influence decision under risk




N
Stewart






N
Chater






H
P
Stott






S
Reimers








Journal of Experimental Psychology. General




132


1
















On the origin of utility, weighting, and discounting functions: How they get their shapes and how to change their shapes




N
Stewart






S
Reimers






A
J L
Harris




10.1287/mnsc.2013.1853








Management Science




61


3
















A decision-by-sampling account of decision under risk




N
Stewart




N








K
Simpson




N




















Reconciling truthfulness and relevance as epistemic and decision-theoretic utility




T
R
Sumers






M
K
Ho






T
L
Griffiths






R
D
Hawkins










rev0000437 terms and numeric ranges






131








Current Psychology










10.1007/s12144-022-03985-0














Yes, but it is uncertain: Direction and communicative intention of verbal probabilistic terms




K
H
Teigen






W
Brun








Acta Psychologica




88


3


















10.1016/0001-6918


















The directionality of verbal probability expressions: Effects on decisions, predictions, and probabilistic reasoning




K
H
Teigen






W
Brun




10.1006/obhd.1999.2857








Organizational Behavior and Human Decision Processes




80


2
















Verbal expressions of uncertainty and probability




K
H
Teigen




L








W
Brun




L




















Thinking: Psychological perspectives on reasoning and decision making


Macci & D. Hardman




John Wiley & Sons, Ltd














Verbal probabilities: A question of frame




K
H
Teigen






W
Brun




10.1002/bdm.432








Journal of Behavioral Decision Making




16


1
















Looking back versus looking ahead: framing of time and work at different stages of a project




K
H
Teigen






K
I
Karevold




10.1002/bdm.502








Journal of Behavioral Decision Making




18


4
















Nudge: Improving decisions about health, wealth and happiness




R
Thaler






C
R
Sunstein








Simon & Schuster












The framing of decisions and the psychology of choice




A
Tversky






D
Kahneman




10.1126/science.7455683








Science




211


4481
















Rational choice and the framing of decisions




A
Tversky






D
Kahneman










Journal of Business




59


4
















Advances in prospect theory: Cumulative representation of uncertainty




A
Tversky






D
Kahneman








Journal of Risk and Uncertainty




5


















10.1007/BF00122574














How incidental values from the environment affect decisions about money, risk, and delay




C
Ungemach






N
Stewart






S
Reimers








Psychological Science




22


2


















10.1177/0956797610396225














Practical Bayesian model evaluation using leaveone-out cross-validation and WAIC




A
Vehtari






A
Gelman






J
Gabry








Statistics and Computing




27


5


















10.1007/s11222-016-9696-4














the decision by sampling origin of loss aversion


10.1037/xge0000039








Journal of Experimental Psychology. General




144


1














Measuring the vague meanings of probability terms




T
S
Wallsten






D
V
Budescu






A
Rapoport






R
Zwick






B
Forsyth




10.1037/0096-3445.115.4.348








Journal of Experimental Psychology. General




115


4
















Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory




S
Watanabe










Journal of Machine Learning Research




11
















Thanks, but I'm used to better: a relative rank model of gratitude




A
M
Wood






G
D A
Brown






J
Maltby




10.1037/a0021553








Emotion




11


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]