You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Our motivations extend across time. We transition smoothly and efficiently between different motivational states and their attendant behaviors in the service of our current desires and goals. Even when we encounter situations unexpectedly appealing or threatening, we rapidly and efficiently adapt our behavior to meet them, maximising opportunities for reward and minimising probability of harm.
Much of this efficiency is due to the multiple learning and memory systems that allow us to predict, and respond appropriately to, environmental sources of reward and danger.
We have learned much about the organization of these emotional learning and memory systems. Learning to predict and approach rewards depends on midbrain dopamine neurons, amygdala, prefrontal, and dorsal striatal circuitries that encode and store reward associations 
(Everitt et al., 1999;
Everitt and Robbins, 2005;
Holland and Gallagher, 1999)
.
These circuits interface with ventral striatal and hypothalamic circuitries for generation of approach and consummatory behavior 
(Lee et al., 2005;
Petrovich et al., 2005;
Petrovich et al., 2002)
. Learning to predict and respond to danger relies on amygdala, hippocampal and prefrontal circuitries, among others, that encode and store danger associations 
(Grewe et al., 2017;
Maren and Quirk, 2004;
Wolff et al., 2014)
. These circuits interface with hypothalamic and brainstem circuitries for production of withdrawal and protective responses tuned to the spatial and temporal imminence of danger 
(Assareh et al., 2016;
Fanselow, 1991;
Tovote et al., 2016)
.
These learning processes and their expression in behavior allow us to successfully transition between the behaviors required to navigate our environment, selecting rewards appropriate to our needs and/or desires, and avoiding dangers likely to harm us. Yet the existence of multiple learning and memory systems does not guarantee stability. This is underscored by compelling and sophisticated studies identifying significant partitioning -at cellular and circuit levels -between appetitive and aversive forms of motivated behaviors 
(Belova et al., 2008;
Berridge, 2019;
Beyeler et al., 2018;
Beyeler et al., 2016;
Burgos-Robles et al., 2017;
Gore et al., 2015;
Hayes et al., 2014;
Kim et al., 2019;
Kim et al., 2016;
Kim et al., 2013;
Peciña and Berridge, 2005;
Reynolds and Berridge, 2002;
Reynolds and Berridge, 2003;
Smith et al., 2009)
. If appetitive and aversive motivations and their attendant behaviors are largely segregated in terms of their cellular and circuit mechanisms and/or their modes of activity 
(Berridge, 2019)
, how do we smoothly transition between them?
This problem can be brought into focus by considering failures of motivational stability: motivational conflict. These arise whenever there are competing motivational demands for a common resource: behavior. Sometimes conflict is observed within motivational systems -such as when we choose between different items on a menu or when a rat chooses to forage in one patch versus another. At other times conflict is observed between motivational systems -such as a child approaching an abusive caregiver or when animals choose to forage in a patch that brings the risk of predation. Regardless of source, competition between incompatible motivational states must be resolved as a necessary precursor for more complex, context-specific, adaptive behavior. Conflict is ubiquitous in our emotional and motivational life. Moreover, the ubiquity of such conflict and its potentially adverse consequences suggest that mechanisms for its resolution would have been selected for and installed in the mammalian brain. Indeed, conflict resolution is almost certainly a cornerstone of emotional resilience and well-being. Yet just as we lack a coherent understanding of stability in motivation, so too do we lack a coherent understanding motivational conflict.
These concerns are not new 
(Bower and Miller, 1958;
Lewin, 1931
Lewin, , 1935
Margules, 1966;
Miller, 1944;
Miller, 1959;
Roberts, 1958)
. They are receiving renewed interest in other literatures 
(Becker et al., 2015;
Brockmeyer et al., 2015;
Dickson et al., 2016;
Eberl et al., 2013;
Eder et al., 2013;
Field et al., 2008;
Kakoschke et al., 2017;
Korucuoglu et al., 2014;
Nguyen et al., 2015;
Rinck and Becker, 2007;
Wiers et al., 2011;
Wittekind et al., 2015
), yet they receive comparatively little attention in the contemporary behavioral neuroscience literature. Current theoretical and empirical efforts have focussed, with great success, on how learning controls the operation of motivational systems but have largely left unanswered questions about how motivational systems may control behavior. Here we provide a brief overview of the basic properties of motivational conflict as well as historically influential approaches to understanding motivational stability and conflict. This is followed by an outline of a model of motivational stability and conflict (an arbiter model of motivational selection).
This model is inspired by problems of arbitration in digital circuits and theories of perceptual decision making and executive function. It uses a simple architecture to arbiter bistable transitions between motivational states as well as to resolve conflict between demands for these states when they arise. We show how the arbiter model can be applied to understand behavior under a variety of conditions. We also offer a physiological instantiation of this model in paraventricular thalamic control of neuronal ensembles in the accumbens shell and extended amygdala. Finally, we consider the application of the arbiter model to disorders such as clinical anxiety and addictions.


Motivational conflict
Any adequate account of motivational stability and motivational conflict should apply to the various circumstances under which conflict is observed. The basic conditions under which motivational conflict occurs have been known for almost 100 years. Early work by Neal Miller 
(Miller, 1944;
Miller, 1959)
 and Kurt Lewin 
(Lewin, 1931
(Lewin, , 1935
 showed that motivational conflict occurs under a variety of predictable conditions: approach -approach; approach -avoidance; avoidance -avoidance and double approach -avoidance. These conflicts can be represented visually as gradients 
(Figure 1
).
Behaviors or decisions linked to stimuli or goals with the potential for both reward and punishment generate motivational conflict because they pit the opposing tendencies to approach rewards and avoid punishers against each other. Colloquially we call such approach -avoidance conflict as being 'damned if you do, damned if you don't'. Motivational conflict under approach -avoidance is commonplace. In humans, this conflict can appear when weighing the benefits of approaching your employer and asking for promotion yet risking rejection; when a child approaches a dismissing or preoccupied caregiver; or when a drug user chooses between injecting a substance that brings immediate gratification but also delayed adverse effects on health and well-being. In many animals this conflict occurs when deciding to forage in a patch that brings the risk of predation, and this can be exploited in the laboratory 
(Amir et al., 2015;
Choi and Kim, 2010)
. However, there are other common, but less obvious, examples of approach -avoidance conflict. Persisting with behavior in the face of nonreinforcement involves approach -avoidance conflict. For example, the rat whose behavior has been rewarded on some but not other occasions is confronted with a decision whether to engage in the behavior in the hope of reward or to refrain in order to avoid the frustration induced by the absence of the reward 
(Amsel, 1992;
Brown and Wagner, 1964;
Rescorla, 2001
; 
Wasserman et al., 1974)
.
Choosing between two alternative courses of action, neither of which is acceptable, generate motivational conflict because they pit avoidance tendencies against each other.
These are so common that we have several idioms for avoidance -avoidance conflicts:
'being between Scylla and Charybdis', 'jumping out of the frying pan and into the fire', 'being Figure 1. The conditions of motivational conflict and the gradients of approach and avoidance as described by 
Miller
 
(Miller, 1944)
. The gradients show hypothetical motivational strengths as a function of the psychological distance (physical distance, time, similarity etc) to a goal. stuck between a rock and a hard place' or 'between the devil and the deep blue sea'. A high stakes example is the conflict experienced by prey as a predator approaches: should the prey fight or flee?
Behaviors or decisions that involve choices between two outcomes that have both positive and negative values, generate motivational conflict because they pit approach and avoidance tendencies again each other. In humans such double approach -avoidance conflicts appear during choice between rewards with different consequences. For example, the choice between two job offers, one providing an excellent salary but less than ideal working conditions versus another offering a lower salary but better conditions; choosing between spending a Saturday evening reading versus attending a social event; or choosing one desirable dish from a menu and not another. Such choices generate conflict because by choosing one we relinquish the other; they are "forced "or "mutually exclusive" types of choice. Colloquially this is the 'fear of missing out'. Under such conditions we frequently find it difficult to make a decision even when we evaluate the 'pros and cons' of each alternative to resolve conflict.
As Miller noted 
(Miller, 1944;
Miller, 1959)
, our tendencies to approach rewards and avoid punishers -the gradients of approach and avoidance -are dynamic, not fixed ( 
Figure   1
). These tendencies vary with experience, deprivation states (e.g., hunger, thirst), reward magnitude, and distance to reward and punishment. For example, increases and decreases in the magnitude of the reward or punisher cause upward or downward shifts of these gradients in humans and other animals 
(Bach et al., 2014;
Schlund et al., 2016;
Schlund et al., 2017;
Sierra-Mercado et al., 2015)
. Likewise, alterations in value due to changes in internal states cause shifts in these gradients. Under approach-avoidance conflict, the hungry animal is more likely to tolerate danger in order to obtain food than the sated one 
(Padilla et al., 2016)
. The dynamic nature of the gradients of approach and avoidance is exploited by studies in the neuroscience of addiction assessing the tendency of the animal to seek drug rewards under threat of punishment 
(Deroche-Gamonet et al., 2004;
Marchant et al., 2014;
Vanderschuren and Everitt, 2004;
Vanderschuren et al., 2017;
Venniro et al., 2019)
. The slope of these gradients can also change with experience (e.g., instrumental incentive learning) or levels of impulsivity. Moreover, the closer an individual is to the moments of reinforcement (reward or punishment), the greater the strength of approach and avoidance tendencies (the 'goal looms larger'). This effect of imminence has been demonstrated in rats approaching a goal box to obtain food 
(Miller, 1944)
, in humans solving anagrams to earn social reward 
(Forster et al., 1998)
 as well as in rats 
(Fanselow and Lester, 1988)
, mice 
(De Franceschi et al., 2016)
 and humans 
(Coker-Appiah et al., 2013;
Mobbs et al., 2007)
 across predatory distance. Importantly, these gradients are not limited to physical distance. They apply to other dimensions, including time and stimulus similarity. Temporal discounting, a preference for receiving a small reward sooner rather than a larger one later, is observed across mammals 
(Odum, 2011)
 and is an example of the negative slope of approach across time.


Characteristics of behavior under conflict
Behavior during conflict has two signatures: bistability and metastability 
(Miller, 1944;
Miller, 1959)
. Conflict can be resolved by a winner takes all process, so that behavior reflects one demand over the other (it is bistable). Other conflicts are resolved only after a period of instability where behavior is unstable, even oscillating back and forth between the two demands because it is in a state of unstable equilibrium or metastability. There is evidence for both these characteristics in behavior under conflict.


Conflict between motivational systems
Approach -avoidance conflicts have long been studied in the laboratory. In early demonstrations, subjects, typically rats, would traverse a runway from start box to goal box in order to receive food reward. On some trials, rats would receive a footshock in the goal box, creating conflict between tendencies to approach (due to reward) and avoid (due to punishment). Under these conditions, rats would readily run to the goal box in the absence of shock or rarely leave the start box if they had previously received very strong shock in the goal box. Their behavior was bistable. However, at intermediate shock intensities, animals would leave the start box then oscillate back and forth between the two ends of the runway without entering the goal box 
(Miller, 1944)
. Their behavior was metastable. This profile of behavior is quite robust. Similar findings have been reported in rats seeking food under threat of 'attack' from robotic 'predators' 
(Choi and Kim, 2010)
 as well as in punishment tasks 
(Hunt and Brady, 1951;
Verhalen et al., 2019;
Halladay et al., in press
). For example, rats punished for approaching and responding for or consuming a food reward, show 'abortive responses' characterised by bouts of oscillation between approach and withdrawal from the reward source.
Humans under approach -avoidance conflict behave similarly. For example in human participants confronted with the choice of approaching a goal to earn monetary rewards, but risking the threat of punishment (a loud scream and loss of income) at the goal, behavior is bistable at low (approach dominates) and high (avoid dominates) threat levels but metastable (intermixed approach and avoidance) at intermediate threat levels 
(Schlund et al., 2016)
. Moreover, conflict takes longer to resolve at these intermediate threat levels compared to low or high threat levels 
(Aupperle et al., 2015;
Aupperle et al., 2011;
Kirlic et al., 2017;
Schlund et al., 2016)
. That is, decision times (approach or avoid) are equally fast Arbiter model -8 at low (approach) or high (avoid) threat levels but significantly slower at intermediate threat


levels.
Approach -avoidance conflicts are not just triggered by explicitly aversive events.
The absence of an expected reward is also a potent trigger for this conflict. The absence of an expected reward is aversive -it can promote escape 
(Daly, 1972
(Daly, , 1973
, withdrawal/avoidance 
(Wasserman et al., 1974)
 and can function in a manner similar to explicitly aversive events such as footshock 
(Brown and Wagner, 1964;
Dickinson and Dearing, 1979;
Wagner, 1959)
. So, behavior during non-reinforcement, when a reward is expected but not forthcoming (i.e. under conditions of extinction or partial reinforcement), requires resolution of this conflict 
(Amsel, 1962;
Rescorla, 2001
).


Conflict within motivational systems
Similar properties characterise transitions and conflict within motivational states (approach -approach and avoidance -avoidance). Behaviors linked to the same motivational state need not compete with each other. For example, consider the behavioral demands on the animal of concurrently presenting two different stimuli (e.g., a visual CS and an auditory CS) each of which had previously signalled delivery of the food to the same location. Both stimuli direct the animal to the same location. There is no competition in behavior. In fact, the behavioral control exerted by these stimuli positively summates when presented concurrently, and does so even when the CSs signal affectively similar but qualitatively different rewards (e.g., liquid sucrose versus grain pellets) 
(Rescorla, 1999;
Rescorla and Coldwell, 1995)
. However, behaviors linked to the same motivational state can compete with each other when these behaviors are incompatible.
A classic and well-studied experimental demonstration of competition within a motivational system comes from studies of approach behavior during Pavlovian conditioning 
(Brown and Jenkins, 1968;
Hearst and Jenkins, 1974)
. For example, when a localizable visual stimulus is arranged to signal delivery of reward to a receptacle, hungry pigeons approach the visual signal (sign track) or they approach the receptacle to obtain reward (goal track). This tendency to approach a localizable signal persists, even when it comes at the expense of the opportunity to obtain reward 
(Hearst and Jenkins, 1974)
. Sign-tracking and goal tracking occur in rats, with approach to a localizable signal for food and approach to the food source 
(Boakes, 1977;
Cleland and Davey, 1983;
Flagel et al., 2009)
. In both species, the consummatory behaviors expressed towards the localizable signal are appropriate to the identity of the reward and the signal -a finding known since the work of Pavlov 
(Pavlov, 1927)
. For example, if the reward is liquid, they will 'drink' or 'lick' the signal, if the reward is food they will 'eat' or 'bite' the signal, if the reward is warmth, they will show thermoregulatory behavior towards the signal 
(Davey and Cleland, 1982;
Davey et al., 1989;
Jenkins and Moore, 1973)
.
Behavior during this conflict between approaching the signal (sign tracking) and the location of the reward (goal tracking) can be both bistable and metastable. The animals cannot simultaneously approach two different locations, so competition is resolved with one behavior dominating the other. Which behavior dominates (sign tracking or goal tracking) is not fixed. Sign tracking does not universally dominate goal tracking nor does goal tracking universally dominate sign tracking. Rather, which behavior dominates depends on numerous factors including the distance in time between the signal and reward delivery 
(Holland, 1980a)
, the distance in space between the localizable signal and the reward 
(Silva et al., 1992)
, the physical characteristics of the signal 
(Boakes, 1977;
Holland, 1980b;
Tomie, 1996)
, the schedule of reward, deprivation state, among others 
(Boakes, 1977;
Davey and Cleland, 1982;
Hearst, 1975;
Hearst and Jenkins, 1974;
Wasserman, 1973)
. Importantly, behavior under this approach-approach conflict can be metastable, vacillating back and forth between the two types of behavior. This is evidenced by switching between sign-tracking and goal-tracking behaviors during the same signal presentation 
(Haight et al., 2015)
. For example, approach behavior is bistable, favouring either goal or sign tracking; specifically, when the physical distance between the goal and the signal is large or small. However, behavior can also be unstable 
(Holland, 1980b;
Silva et al., 1992)
. At intermediate distances between the signal and goal, animals can vacillate between both goal tracking and sign tracking, moving back and forth between the sign and the goal 
(Silva et al., 1992)
.
Bistability is also observed in aversively motivated behaviors. In mammals, levels of fear and the topography of defensive behavior scale with threat imminence 
(Fanselow and Lester, 1988;
Mobbs et al., 2007;
Schlund et al., 2016)
. For example, in rodents, passive defensive behaviors (post-encounter defense) such as freezing dominate at lower predatory imminence whereas active defensive behaviors (circa-strike defense) such as flight dominate at greater predatory imminence. Transitions between these incompatible active versus passive behaviors are normally rapid and bistable. For example, presentations of a tone CS signalling shock elicits passive freezing behaviors whereas the subsequent delivery of a footshock US promotes a rapid transition to active, circa-strike defense which is then, in turn, replaced by passive freezing behaviors 
(Fanselow et al., 2019;
Fanselow and Lester, 1988
). However, again behavior can be unstable. As predatory imminence increases, animals can oscillate between active (escape) versus passive (immobile) defense prior to active defense dominating 
(Assareh et al., 2016;
Fadok et al., 2017;
Fanselow, 1994)
.
Finally, similar patterns of behavior are observed even in other Pavlovian conditioning experiments. For example, in Pavlovian auditory appetitive conditioning, animals receive pairings of an auditory CS with delivery of a food US. They express topographically distinct conditioned behaviors appropriate to the properties of the CS and the US. They show brief startle responses to the onset of the auditory CS (CS-generated behavior) and head entries to the magazine where the food US is delivered (US-generated behaviors). CS-generated responses dominate behavior shortly after CS presentation whereas US-generated behaviors dominate later 
(Holland, 1979
(Holland, , 1980a
. At intermediate times after CS presentations, animals oscillate between these two behaviors, expressing a distinctive 'head jerking' characterised by short, rapid, head movements (CS-generated) directed towards the magazine (US generated) 
(Han et al., 1999;
Holland, 1980a)
. Similar findings can be observed in single cue Pavlovian fear conditioning. In a typical fear conditioning experiment, rats initially engage in active exploration of the conditioning chamber that is replaced by fear related active and passive behaviors 
(Pliota et al., 2018)
.
Moreover, as in appetitive conditioning, rats can show CS-generated responses to auditory (startle) or visual (rearing) CSs paired with shock and US-generated responses (freezing).
Which response dominates, US-generated freezing or CS-generated startle/rear, depends on both the CS -US contingency and US (shock) intensity 
(Holland, 1979)
. At high US intensities behavior is stable in favour of the US-generated freezing whereas at low US intensities behavior is stable in favour of CS-generated startle or rear. At intermediate US intensities behavior can oscillate, with animals expressing both CS-and US-generated behaviors 
(Holland, 1979)
.


Summary
The principles of conflict are well established in the literature. Yet, with notable exceptions 
(Bach et al., 2014;
Gray and McNaughton, 2000;
Ito and Lee, 2016;
McNaughton et al., 2016;
O'Neil et al., 2015;
Pare and Quirk, 2017)
, they have received less attention in contemporary behavioral neuroscience than the motivational systems on which they are based. One reason for this is that contemporary accounts have focussed primarily on how learning contributes to the operation of motivational systems. This is an important primary question. Its answers dictate when, and by which events, motivational states are controlled.
Significant theoretical and empirical progress has been made in this field such as the attribution of incentive salience 
(Berridge and Robinson, 2016;
Robinson and Berridge, 1993;
Robinson and Berridge, 2003)
, instrumental and Pavlovian incentive learning, modes of instrumental control 
(Balleine and Dickinson, 1998;
Belin et al., 2013;
Dickinson and Balleine, 2002;
Everitt et al., 2008;
Everitt et al., 2001;
Robbins, 2005, 2013)
, model-based versus model-free reinforcement learning 
(Dayan and Balleine, 2002;
Dayan and Berridge, 2014)
 etc. Far less attention has been paid to the problem of changes in behavior. To be sure, the problems of motivational stability and motivational conflict intersect with learning processes; but motivational stability and motivational conflict are fundamentally problems of performance and behavioral selection, not problems of learning. Any adequate explanation of motivation might reasonably be expected to address these.


Theoretical approaches to motivational stability and conflict
There are at least three, theoretically influential approaches to the problem of motivational selection: opponent process models, behavior systems, and value-based learning. Here we review these and highlight their strengths and limitations when applied to understanding behavior under conflict.


Opponent Process models
Perhaps the oldest theoretical solution to the problems of stability and conflict has been to invoke opposing motivations 
(Hoffman and Solomon, 1974;
Miller, 1944;
Miller, 1959;
Solomon and Corbit, 1973;
Solomon and Corbit, 1974)
. Opponent process models have proven extremely useful in the psychology of learning and motivation, explaining behavior under a broad range of conditions 
(Solomon, 1980;
Solomon and Corbit, 1973;
Solomon and Corbit, 1974)
. These models assume that the motivational state of the organism is determined by subtraction of two opposing influences. Opponent process models use motivational subtraction to approximate a point of stable equilibrium between competing demands, delivering a 'Goldilocks' zone of incentive parity. Motivational subtraction was, and remains, favoured by dominant theories of motivational conflict. Neal
Miller 
(Miller, 1944;
Miller, 1959)
 argued that motivational conflict is produced by incompatible motivational demands either between (approach versus avoidance) or within (approach versus approach or avoid versus avoid) motivational systems. More formally,
Miller argued that conflict occurs whenever the gradients in 
Figure 1
 overlap. Critically, Miller
proposed that these opposing motivational tendencies "add up in something resembling algebraic summation" (p. 10) 
(Miller, 1971)
 so that behavior reports the output of the difference between these opposing states. Weakening one state releases the other whereas strengthening one state suppresses the other. Miller's analysis in terms of gradients of approach and avoidance 
(Figure 1
), have been retained, largely unchanged, for almost a century 
(Boyd et al., 2011;
Corr, 2004
Corr, , 2013
Corr and McNaughton, 2012;
Forster et al., 1998;
Kakoschke et al., 2017;
Korucuoglu et al., 2014;
McNaughton, 2014;
McNaughton et al., 2016;
O'Neil et al., 2015)
.
For present purposes, a key prediction of Miller's account is that behavior under approach -avoidance conflict should be characterised by oscillation back and forth as the animal approaches the point of incentive parity followed by a pause as it achieves equilibrium between the competing demands. As noted above, vacillation is indeed a key feature of behavior under motivational conflict 
(Brown, 1948;
Schlund et al., 2016;
Siddle and Mangan, 1968)
. However, behavior during this state is far from stable and Miller himself noted that such vacillation is rarely predictable. In his own experiments, he reported that while approaching a food source co-located with shock, some animals would approach the food source, pause and then stop, others would oscillate back and forth between the start and goal boxes, and still others would return to the start box 
(Miller, 1944)
. The same variation in behavior under approach-avoidance conflict has been observed in contemporary studies 
(Amir et al., 2015;
Choi and Kim, 2010;
Verhalen et al., 2019)
, with animals sometimes pausing midway between their start and a distant goal during approachavoidance conflict, sometimes completely approaching the goal, and sometimes returning to their start. Behavior during conflict rarely seems to achieve incentive parity and is far less stable or predictable than anticipated, indeed, required by opponent process models. Gray 
(Gray, 1987;
Gray and McNaughton, 2000)
 recognised these limitations and proposed instead that there are behavioral activation and behavioral inhibition systems. The behavioral activation system controls approach to rewards whereas the behavioral inhibition system controls not only approach to, and passive avoidance of, aversive stimuli but also risk assessment. Gray and McNaughton noted "we view the behavioral inhibition system as being activated in any approach-avoidance conflict; we equate anxiety with activity in the behavioral inhibition system; and we view anxiolytic drugs as having a selective effect on the behavioral inhibition system" 
(Gray and McNaughton, 2000)
. A key advantage of the activation/inhibition model is that it does not predict that animals will always approximate a point of incentive parity between conflicting demands. However, by adopting this solution to approach -avoidance conflict, the model does not offer a general account of the other forms of conflict resolution, namely approach -approach or avoidance -avoidance.


Behavior systems
A second influential approach constitutes a synthesis of ethology, comparative psychology, and associative learning 
(Timberlake, 1993
(Timberlake, , 1994
. This behavioral systems approach proposes that motivational stability is achieved by pre-organised (i.e. evolutionary determined) hierarchies 
(Timberlake, 1994)
. It assumes that evolutionary pressures have selected for distinct behavioral systems (e.g., predation, feeding, defense, procreate, care of offspring etc) to meet the requirements imposed by the needs to feed, mate, evade predators and so on. Each behavior system is itself comprised of specific modes (e.g., feeding is comprised of general search, focal search, handle/consume modes) that are the motivational substrates organising behavioral repertoires in nested modules (e.g., ingest, reject, hoard). These modules, in turn, dictate specific action-patterns (e.g., ingestion
consists of holding, chew, and swallowing). The behavior systems approach has been profitably applied to understanding feeding 
(Timberlake, 1993
(Timberlake, , 1994
, sexual behavior 
(Domjan, 2005;
Domjan and Gutierrez, 2019)
, and fear 
(Bolles and Fanselow, 1980;
Fanselow, 1991;
Fanselow, 1994;
Fanselow, 2018;
Fanselow and Lester, 1988;
Fanselow and Wassum, 2016)
, among others. The perceptual-defensive-recuperative (PDR) model of fear and pain proposed by 
Bolles and Fanselow (Bolles and Fanselow, 1980)
, and its extensions by Fanselow and colleagues 
(Fanselow, 2018;
Fanselow et al., 2019;
Fanselow and Lester, 1988;
Fanselow and Wassum, 2016)
, are important exemplars of this approach.
In the PDR model, fear is produced by predictors of aversive events (i.e. the expectancy of pain). Fear generates specifies-specific defensive behaviors and the environment in which those predictors are experienced dictates the specific form of defensive behaviors. For example, the topography of defensive responses scales with imminence of the aversive event (e.g., the predator), so that there is a shift in defensive behavior from passive to active defense as the spatial and temporal proximity of the threat increase.
A key strength of this behavior systems approach is that it views learning, motivation, and behavior through the lenses of the fundamental survival problems they have been selected to solve; essentially as Darwinian adaptations. It therefore imposes biological constraints on these processes. However, for present purposes, this approach raises at least two issues. First, it leaves unspecified the mechanism selecting between different behavior systems when these are in competition with each other. In other words, it does not provide a mechanism to resolve conflict. Often, such models suppose some sort of hierarchy. In the PDR model, for example, fear inhibits other motivational systems, such as feeding. Fear "has the top priority" (1980, pp. 291) but the model, and its behavioral systems extensions, are largely agnostic to how inhibition occurs. It could be via response competition, at the level of 'central' motivational states, and/or at the level of perception.
Under high stakes it seems reasonable to suppose that the organism is biologically prepared to ensure that fear supporting defensive behavior subjugates its motivational competitors and generates defensive behaviors that minimise or avoid threat 
(Bolles and Fanselow, 1980)
. A rat that detects a predator at a food patch is well advised to stop foraging and attempt escape. Likewise, when we are sick and/or injured, it seems reasonable to assume that recuperation should take precedence over other behaviors, so that we can effectively recover 
(Bolles, 1967;
Bolles and Fanselow, 1980;
Hart, 1988;
Konsman et al., 2002)
. To be sure, under many conditions fear trumps other motivational states. Fear can suppress food seeking 
(Estes and Skinner, 1941)
, alter foraging patterns 
(Choi and Kim, 2010;
Kim et al., 2018)
, and so forth. However, this dominance is hardly universal. Other motivational states can trump fear 
(Burnett et al., 2016;
Choi et al., 2019;
Choi and McNally, 2017;
Holmes and Westbrook, 2014)
. At some point, the hungry animal is willing to tolerate and then overcome adversity and fear to meet its metabolic need 
(Burnett et al., 2019;
Burnett et al., 2016;
Choi et al., 2019;
Choi and McNally, 2017;
Miller, 1960)
 just as a sick parent interrupts its own recuperation to care for its young 
(Aubert, 1999)
. In addition, such interactions are dynamic, not static. They are influenced by fluctuations in the internal environment (metabolic state, arousal) and the affordances provided by the external environment, e.g., distance of food source and availability of cover 
(Anderson, 1986)
. If they exist at all, hierarchies of behaviors and motivations must be flexible not deterministic. The second issue with the behavior systems approach is that it leaves unanswered the mechanism for transitioning between different modes, modules and actions within a behavior system. As Miller pointed out, conflict extends to competing demands within a motivational system, and recent work addressing the appropriate form, timing, and transitions between different behavioral defense patterns 
(Fanselow et al., 2019)
 as well as the determinants of active versus passive behavioral responses to stressors 
(Pliota et al., 2018)
 underscores this point. So, although powerful and ecologically relevant, the behavior systems approach requires a mechanism to flexibly select between behavior systems and govern transitions within them.


Value-based learning
A third class of solution, and perhaps the most recently influential, is derived from the modern value-based learning literature. This solution places the burden of explanation on the computations of a theoretical expert decision maker 
(Rangel et al., 2008)
. When confronted with different motivational demands, the agent could calculate the expected utilities of the actions or behaviors being considered, then choose the one with the highest expected utility (if one can be identified). These cost-benefit calculations could include separate computations of goal and decision values, accommodate any risk involved, and then be used for action selection. The outcome of action selection can then be critically evaluated to inform future decisions 
(Johnson and Ratcliff, 2018;
Rangel et al., 2008)
. This expert, value-based learning solution is appealing because it can avoid the problem of conflict in behavior all together. There is no concurrent activation of motivational states or competing behaviors. Conflict is resolved first, at the level decision-making. Motivational state is selected second, at the level of responding, to underpin appropriate behaviors.
A deliberative, expert decision maker is clearly desirable. Centralised, complex, strategies for action selection underpin behavior in complex environments 
(Sharpe et al., 2019
) and provide powerful solutions to problems of motivational stability and conflict.
Moreover, the plausibility of this solution is bolstered by a variety of lines of evidence (e.g., neuroimaging studies in humans and single-unit recording studies in monkeys, rats, and mice) identifying dissociable cortical and subcortical regions in the integration of value and probability information to underpin computation of utility, assessment of risk and uncertainty, and in the use of this information to guide behavior 
(Ballard and Knutson, 2009;
Dayan and Yu, 2003;
Juechems et al., 2019;
Kennerley et al., 2011;
Morrison and Salzman, 2009;
 Arbiter model -15 
Morrison and Salzman, 2011;
Padoa-Schioppa and Assad, 2006;
Payzan-LeNestour et al., 2013;
Preuschoff et al., 2008;
Talmi et al., 2009;
Tom et al., 2007;
Yu and Dayan, 2005)
.
However, there are at least four reasons for supposing that additional mechanisms are needed. First, key features of behavior during motivational conflict are inconsistent with these models. In value-based learning, the agent engages a unified utility calculation based on a common neural currency of value and selects a behavioral output based on this calculation. However, as noted above, behavior under conflict is rarely unitary. It is bistable.
It can be metastable. It is often unpredictable. Second, the time taken to resolve conflict depends on the degree of conflict, more specifically on the similarity (in time, value, space etc) of the competing demands 
(Miller, 1944)
. For example, approach-avoidance conflicts take longer to resolve at intermediate threat levels compared to low (when approach wins) or high (when avoidance wins) threat levels 
(Aupperle et al., 2015;
Aupperle et al., 2011;
Kirlic et al., 2017;
Schlund et al., 2016)
. It is not clear why the time taken to perform an expected utility calculation should depend significantly on the actual values involved. Third, decisionmaking of this kind requires significant knowledge and experience. The 'agent as expert' knows, with great precision, the relevant statistical properties of their environment, where they are located in that environment, how the selected state and behavior will change their environment, and then acts accordingly. Such knowledge is clearly desirable and may be possible with extensive training and experience. However, the relevance of this kind of decision making for behavior where the appropriate statistical model of the environment is uncertain, such as encountering a novel, surprising threat whilst foraging, and requiring calculation on the fly, is unclear. Finally, computational, imaging, and lesion based studies show that cortical modules for value-based learning are separate to those for key cognitive control and performance factors such as response inhibition and task switching 
(Botvinick et al., 2001;
Glascher et al., 2012;
Macdonald et al., 2000;
Miller and Cohen, 2001)
. Thus, there is a plausible case to at least consider other mechanisms that may help achieve motivational stability and resolve motivational conflict. Here we propose one such performance-based mechanism.


Multiple mechanisms for stability and conflict
We suggest that motivational selection can involve a performance mechanism that is simple, accurate, and automatic. This selection mechanism enables access to motivational states and their attendant behaviors that can operate in conjunction with other more complex value-based learning and decision-making mechanisms. We identify this selection mechanism with arbitration. Specifically, we describe a simple architecture to arbiter bistable transitions between motivational states and their attendant behaviors as well as resolve conflict between these states and behaviors when they arise. This architecture adopts the Arbiter model -16 assumption common to opponent process models that there are different motivational states with contrasting influences on behavior. However, it rejects the fundamental and defining assumption of these models that motivational states summate to yield a motivational or affective blend. The arbiter architecture we describe could be used to specify a mechanism for selecting between behavior systems as well as stably govern transitions within them.
Alternatively, it could provide a performance mechanism used by a value-based learning system. However, it can also stand independently of these.


An arbiter circuit for controlling transitions in behavior and motivational state
The problems of motivational stability and motivational conflict can be recast as problems of motivational selection. Specifically, they can be viewed as problems of achieving stable selection of motivational states and resolving any conflict between demands for these states as they arise. A similar problem arises in digital circuits when two or more processors compete to access a common resource such as a memory. Here we provide a simple account of abritration of motivational selection broadly modelled on simple arbitration in digital circuits 
(Ginosar, 2011;
Kinniment, 2007;
Kinniment and Woods, 1976)
. We propose that selection of, and transition between and within states, are active processes that necessarily involve both state initiation and state termination. Moreover, we suggest that the same selection process controls these transitions regardless of the states involved. In other words, we propose a general selection mechanism that can be applied to problems in behavior requiring arbitration between two incompatible demands. Incompatible demands could include initiation versus termination of a single behavioral or motivational state (e.g., approach versus pause or avoid versus pause), selection of one motivational state over another (approach -avoidance) or selection between incompatible demands within a single motivational state (approach -approach or avoid -avoid).  Consider the example where the inputs A and B begin at 0. As per the truth table for an AND gate, the output of each AND gate is 0 ( 
Figure 3)
. The output is inverted and fed back to the other gate, so each gate receives one low (0 from A or B) and one inverted high


Motivation as a finite state machine


An arbiter circuit for bistable selection
(1) input. Because the output of an AND gate is 0 whenever one its inputs are 0, each gate is closed and the Finite State Machine is in the previously selected state. An input (1) A arrives at the latch, changing from 0 to 1. Both inputs to Gate 1 are now high. The AND condition for Gate 1 is satisfied so the output of the Gate 1 switches to high and is fed back to the inverter at Gate 2. This inverted input is now low (0) and the second AND gate closed   
(Figure 4
).


Metastability in state selection
Under most conditions, the arbiter results in the stable selection. However, under some conditions selection can become unstable. This occurs when the two inputs, A and B, compete with each other for control of behavior. This is conflict. During conflict, the arbiter can enter a metastable state. In this metastable state, the arbiter functions with positive feedback (feedforward inhibition via the inverters). The output from each gate is fed back to the other via their cross-coupling in an attempt to close the other gate to its input.
Feedback from cross-coupling between the two gates is essential to understanding conflict. Feedback from cross-coupling means that the arbiter can oscillate between the two different outputs, A wins then B wins then A wins etc, or achieve no output at all 
(Ginosar, 2011;
Simen 2012)
. Under these conditions the Finite State Machine is initially unable to stably latch an output to resolve motivational conflict 
(Figure 4
). During this metastability, behavior is not necessarily predictable. It may be characterised by oscillations between behavioral options (approach, avoid, approach, avoid etc), by irregular initiation and termination of single behaviors (approach, stop) and so on. In this way the arbiter instantiates two key features of motivational conflict: bistability (stable selection of one state over another) and metastability (unstable selection).
The time taken for the arbiter to resolve conflict depends on the starting conditions, specifically on the difference between the two inputs (K) 
(Figure 5i
). This could be difference in time, space, or any other relevant stimulus dimension. Indeed, it is precisely the importance of similarity in driving conflict that is exploited by animal models of conflict such as the Geller-Seifter 
(Geller and Seifter, 1960)
 and 
Vogel (Vogel et al., 1971)
 models. The closer the arbiter starts to K = 0, i.e. identical inputs, the longer it takes to resolve into a   
Figure 5i
, conflict is resolved faster from K = 0.6 than 0.15. Likewise, conflict is resolved faster from K = -0.6 than -0.15. So, the arbiter predicts that resolution of conflict is an accelerating function of time, crucially determined by the starting condition, K. In this way, the arbiter instantiates another key feature of conflict: the more similar the competing demands, the more time required for their resolution. Moreover, it follows from the arbiter model that any event that reduces the similarity of the inputs, i.e. increases K (including noise or other external bias),
will speed conflict resolution. The impact of such events will be largest at smaller values of K because normally more time is required to resolve conflict at these smaller values. The arbiter will quickly resolve conflict via selecting one state over another. Indeed, the probability that conflict persists unresolved after any given time (t) can be expressed as a negative exponential, p = e -t/t 
(Figure 5iii
).
The arbiter model provides a reasonable approximation of the time taken to make decisions under motivational conflict. 
Figure 6
 compares experimental data on approachavoidance conflict in humans with the arbiter model. In this experiment, 
Schlund et al. (2016)
 required participants to decide between approaching or avoiding a source of reward under different probabilities of threat at the reward source. Threat probability was indicated to participants using a scale of 1 (no threat) -10 (certain threat). Data shown are the average decision times, averaged across subjects, across three days of training. Decision times (approach or avoid) were equally fast at low (approach dominated) or high (avoid dominated) threat levels but slower at intermediate threat levels so that overall decision time distributions were characterised by a quadratic function. The arbiter model predicts that these data should be well described by two exponential functions, one either side of maximal conflict. To assess this, data were separated based on the midpoint of the threat scale (1 -5, 6 -10) used by Schlund et al. and exponential functions were fitted. These are shown in  Arbiter model -22


Interactions with other mechanisms
Under most conditions, the arbiter can achieve state selection quickly so that across time the probability of a state remaining unselected is increasingly small. There are, however, some conditions under which conflict may persist longer than expected. As K approaches 0 (i.e. no difference between inputs), state selection by the arbiter within a finite amount of time may take long periods of time or be impossible 
(Lamport, 2012;
Lamport and Palais, 1976)
. These conditions are similar to the plight of Buridan's donkey 
(Lamport, 2012
). Buridan's principle asserts that if two choices are judged equal, then will alone cannot break the deadlock. This principle is often portrayed as a hungry donkey placed equidistant between two, identical bales of hale. Being unable to decide which bale to approach, the donkey starves to death. Of course, the probability of encountering K = 0 is small, and the probability of conflict remaining permanently unresolved, is low. However, K = 0 is not impossible 
(Lamport, 2012)
, state selection in a reasonable amount of time may not occur and the arbiter may fail to resolve conflict in a timely manner.
Perhaps the first, if somewhat extreme, experimental demonstration of such a failure was reported by Pavlov 
(Pavlov, 1927
) (pp. 290-291). Pavlov trained dogs that a circle CS signalled food. Next, dogs received differential conditioning between a circle CS and an ellipse CS (semi-axis ratios of 2:1) so that the circle continued to signal food whereas the ellipse did not. Initially, the circle continued to control appetitive behavior and the ellipse did not. However, as the shape of the ellipse was altered to become increasingly similar to the circle (ratios of the semi-axes of 3:2, 4:3, eventually to 9:8), that is as K was reduced experimentally from a larger value to a smaller one, discrimination broke down and conditioned responding failed. Moreover, under these conditions, the animal became increasingly agitated and emotionally hyperreactive. Pavlov termed this emotionally labile state 'experimental neurosis' and there have been other similar reports 
(Wolpe, 1952)
.
This provides a natural point of intersection between the arbiter and other expert decision-making mechanisms. Theories of cognitive control propose that there is continual, online monitoring of behavior for conflict between incompatible responses or actions. When conflict is detected, cognitive control mechanisms for response inhibition and task switching are initiated to resolve it 
(Botvinick, 2007;
Botvinick and Braver, 2015;
Botvinick et al., 2001;
Carter et al., 1998)
. A similar view is shared by 
McNaughton (Gray, 1982, 1987;
Gray and McNaughton, 2000)
, who propose that the detection of conflict recruits a behavioral inhibition system. In both cases, conflict is generated 'bottom -up' and when detected initiates some form of 'top-down' control over behavior.
Although we are agnostic to the nature of other control mechanisms in conflict, we note that the arbiter model provides principled reasons for why, when, and how such intervention may occur if it did occur. The decay curve describing persistence of unresolved selection by the arbiter 
(Figure 5iii
) provides principled reasons for why and when other mechanisms may be important. Other mechanisms could be important when the arbiter fails to achieve stable selection within a certain amount of time. This can be expressed formally as the amount of time that it takes before the probability of remaining metastable reaches some specified, acceptable value of t (t = ln( ) . (− )). This value could differ within and across individuals. The design of the arbiter as a selection mechanism provides a mechanism for how such expert intervention could occur. Unresolved conflict can be resolved, quickly and simply, via external alterations in the weights of the inputs to the gates.


Key characteristics of the arbiter
The arbiter model offers a simple mechanism for achieving motivational stability and resolving conflict. to oscillations between behavioral options (approach, avoid, approach, avoid etc) or by irregular initiation and termination of single behaviors (approach, stop) and so forth. It also predicts that the more similar the competing demands, the more time required for their arbitration. Thus, the arbiter accurately describes key features of behavior under conflict.
The arbiter model provides a general selection mechanism that can be applied to problems in motivation or behavior requiring arbitration between any two incompatible demands. In each case, the logic of the arbiter, and the features of behavior controlled by it, are the same 
(Figure 7)
. However, there are two structural features of the arbiter that are worth further consideration. The first is input priority. The properties of the arbiter, and the key characteristics of behavior determined by it, are independent of how input priority is determined. Input selection appears similar to a decision variable 
(Dayan and Daw, 2008)
. It is tempting to invoke an expert decision maker to determine input priority or input weight.
This is a plausible and important possibility. Equally important is the possibility that such priorities or weights can be changed with learning. The arbiter is a model of performance and behavioral selection that complements models of learning. The functions of the arbiter, 
Figure 7
. The same arbiter circuit can describe the initiation and termination of a single state 
(A)
 or transition between different states (B).
and its determination of behavior, are independent of how input priority is determined. The arbiter selects a winner (and a loser) from inputs and allows that winner to control behavior at that point in time. In this way, the arbiter provides a routine or automatic selection mechanism that is simple and accurate.
The second feature is that the arbiter depends on feedback via inhibitory crosscoupling between gates. The cross-coupling causes both stability and instability in motivational state selection and behavior. between states or a failure to resolve any behavior at all. Moreover, the duration of this metastability/conflict scales with the similarity of the competing demands (i.e. the inputs).
Thus, the resolution of conflict can take time and behavior during this time will be less stable and predictable than in the absence of conflict. These characteristics of behavior and decisions under conflict (behavioral or 'decision' vacillation, more time required for resolution) 
(Corr, 2013;
Miller, 1944;
Schlund et al., 2016)
 are often attributed to the effortful, complex deliberations of an expert value-based learner weighing the pros and cons of a decision. This may be true in many instances. However, in the arbiter model neither indecision nor its resolution require special expertise, deliberation, or instruction. They are both circuit properties of the model.


Relationship to theories of perceptual decision-making and executive function
The arbiter model as described here, was inspired by and is a simplification of, arbitration in digital circuits. However, it shares key features with approaches to perceptual decision making as well as accounts of executive function (see also 
Simen, 2012)
. These similarities are worth considering.
Theories of perceptual decision-making are concerned with predicting performance (reaction times) in tasks requiring forced choices between two alternatives. For example, participants might be required to make a binary decision about some feature of a perceptual input, such as the direction of motion coherence in an array of random dots. There are several influential models of such decisions, including race 
(Vickers, 1970)
, mutual inhibition 
(Usher and McClelland, 2001
), feed-forward inhibition 
(Ditterich et al., 2003)
, and pooled inhibition 
(Wang, 2002)
 models. Under most circumstances 
(Bogacz et al., 2006)
 many of these can be simplified to the more general, diffusion model 
(Johnson and Ratcliff, 2018;
Ratcliff and McKoon, 2008)
. These models apply to forced choices requiring fast (< 2 s) decisions and they predict, with great accuracy, both the speed and distribution of behavioral reaction times as well as neuronal activity under rapid, forced choice conditions.
The arbiter model shares two important features with these theories. First, whereas existing theories of motivation assume that different motivational states are concurrently activated and any competition between them occurs after their selection 
(Dickinson and Dearing, 1979;
Konorski, 1967;
Solomon, 1980)
, the arbiter model separates the mechanism for motivational selection (the arbiter) from the consequences of that selection (states).
Perceptual decision-making models also separate the mechanisms for evidence accumulation (i.e. decision-making) from non-decision variables such as stimulus encoding and response execution. This separation has proved a powerful bridge in cognitive science and cognitive neuroscience between accounts of stimulus encoding, stimulus representation, decision processes, and response execution. In the same way, one advantage of separating the problem of motivational selection from the consequences of that selection is that it may provide a useful starting point for bridging accounts of how inputs (e.g., stimuli) acquire their motivational significance 
(Mackintosh, 1975;
Pearce and Hall, 1980;
Rescorla and Wagner, 1972)
 with accounts of how that significance is expressed in behavior 
(Gallistel, 2003;
Timberlake, 1994)
.
Second, the arbiter model as described here achieves selection via inhibitory crosscoupling. This is a key feature of the model. This is shared with models of perceptual decision making (e.g., 
Shadlen and Newsome, 2001)
. The use of a feedback mechanism to solve the apparently distinct problems of perceptual decision making and motivational selection is unsurprising. Both are selection problems and feedback via mutual inhibition is a straightforward but powerful way to solve selection problems. Indeed, the general view of motivational selection offered here is reminiscent of accounts of the role of attention in the control of action. For example, Norman and Shallice 
(Norman and Shallice, 1986)
 proposed contention scheduling as a relatively automatic but fast and accurate selection mechanism for the control of cognition and action selection. This involves mutual inhibition among different schemas to prevent their simultaneous demands from causing competing actions and states. Moreover, feedback is a core aspect of nervous system function and occurs across multiple levels (genomic, biochemical, circuits) and timescales. Negative (i.e. homeostatic) feedback has historically been central to many models of motivation. Positive feedback, achieved via cross-coupled inhibition in the arbiter model, is an obvious, yet underexplored, mechanism for understanding problems of motivational stability and conflict.


The accumbens and extended amygdala as gates to a motivational finite state machine
The arbiter model provides a circuit motif 
(Figure 3
) that could be instantiated at multiple levels in the nervous system. In this section we consider one potential instantiation involving paraventricular thalamus (PVT) control of distinct neuronal ensembles in the accumbens shell and extended amygdala (  
Heimer, 1999;
de Olmos et al., 2004;
Heimer et al., 2008;
Zahm, 1998
).
The accumbens shell and extended amygdala can be viewed as gates to a motivational Finite State Machine that subserves distinct motivational and behavioral states. Specifically, these regions are organised as distinct neuronal ensembles that gate distinct influences on behavior. These ensembles determine the basic preparatory functions of motivational states 
(Balleine and Killcross, 2006) (approach, pause/interrupt, withdraw)
 and so influence a broad range of learned and unlearned behaviors. They also enable a suite of appropriate behaviors (feeding, drinking, defense, etc) via their outputs to hypothalamus, ventral pallidum, midbrain, and brainstem 
(Swanson, 2005)
. Recruitment of these ensembles can be determined by a variety of inputs. These can be 'bottom up'
(dopaminergic, noradrenergic and other brainstem and midbrain inputs) or 'top down' via glutamatergic inputs from the prefrontal cortex, hippocampus, and basolateral amygdala.
We propose that PVT is a critical component of an arbitration circuitry. It contributes to selection of a 'winner' and 'loser' when inputs compete for control over motivation.
Specifically, PVT contributes to cross-coupling between ensembles within the accumbens and extended amygdala, thereby inhibiting selection of competing states 
(Figure 8
). This feedback in state selection determines the speed and stability of state selection (motivational state transitions). 


Accumbens
The nucleus accumbens (Acb) is a component of the ventral striatum, a principal output nucleus of the basal ganglia 
(Bolam et al., 2000;
Humphries and Prescott, 2010)
. It has long been recognised that the organisation of the basal ganglia makes it ideally suited to solve general problems of behavioral selection 
(McHaffie et al., 2005;
Prescott et al., 2016;
Redgrave et al., 1999)
.
Acb is comprised of two main sub-regions -nucleus accumbens shell (AcbSh) and nucleus accumbens core (AcbC). These receive glutamatergic inputs from prefrontal cortex (PFC), ventral hippocampus, amygdala and thalamus, as well as dopaminergic and
GABAergic input from the midbrain 
(Berendse et al., 1992;
Groenewegen et al., 1999;
Lindvall and Björklund, 1974)
. These projections converge on Acb neurons 
(Bouyer et al., 1984;
Britt et al., 2012;
Goto and Grace, 2008;
O'Donnell and Grace, 1995;
Stuber, 2013)
.
AcbSh, in turn, has a rich and diverse set of output projections, including projections to lateral hypothalamus (LH), ventral pallidum (VP) and ventral tegmental area (VTA) 
(Brog et al., 1993;
Heimer et al., 1991)
. AcbSh is anatomically heterogeneous. Like the rest of the striatum, the vast majority of AcbSh neurons (>90%) are inhibitory, GABAergic spiny projection neurons (SPNs). AcbSh SPNs themselves comprise at least two distinct populations defined by the presence of dopamine 1 or dopamine 2 receptors 
(Meredith et al., 1993)
 and these two different populations form the basis for the major output pathways of the AcbSh. However, in contrast to the rest of the striatum where distinct D1 striatomesencephlic versus D2 striatopallidal pathways predominate, AcbSh output pathways are organised differently. That is, there are D1 and D2 output pathways to the ventral pallidum and further separate D1 output pathways to the midbrain and lateral hypothalamus 
(Gibson et al., 2018;
Kupchik et al., 2015;
O'Connor et al., 2015;
Pardo-Garcia et al., 2019;
Smith et al., 2013)
.
It has long been recognised from the work of Grace and colleagues that the anatomical convergence of multiple glutamatergic inputs onto Acb neurons, combined with the electrophysiological properties of Acb neurons, make these neurons well described as gates. In anaesthetized animals, Acb neuron resting membrane potentials are bistable. Their resting membrane potential can be "down" (hyperpolarized resting membrane potentials), "up" (periodical plateau depolarisations), or oscillating between these two states, 
Grace, 2005, 2008;
Grace, 2016;
O'Donnell and Grace, 1995;
Sesack and Grace, 2010;
West et al., 2003)
. Acb neurons fire action potentials during up, not down, states. Complex and still poorly understood interactions between glutamatergic and dopaminergic synaptic inputs to Acb determine transitions between these states. Regardless, Acb can be viewed as comprising neuronal gates "open" or "closed" to cortical, hippocampal, and amygdala inputs attempting to access midbrain, ventral pallidum, and lateral hypothalamus.
Arbiter model -28
Acb is important for various aspects of appetitive motivation and positive valence 
(Floresco, 2015;
Mogenson et al., 1980)
. Indeed, Acb neurons are strongly recruited during approach to reward 
(Calipari et al., 2016)
 and mediate appetitive influences on decision making 
(Corbit and Balleine, 2016;
Corbit et al., 2001;
Laurent et al., 2014;
Laurent et al., 2012;
Laurent et al., 2015)
. However, Acb also contributes to aversive influences on behavior, especially approach and withdrawal behaviors during conflict, fear, avoidance, and opiate withdrawal 
(Blomeley et al., 2018;
de Jong et al., 2019;
Freels et al., 2019;
Gentry et al., 2016;
Hamel et al., 2017;
Hikida et al., 2016;
Hoebel et al., 2007;
Kim et al., 2017;
Lee et al., 2014;
Li and McNally, 2015a, b;
Nguyen et al., 2018;
Pezze and Feldon, 2004;
Pezze et al., 2002;
Pezze et al., 2001;
Piantadosi et al., 2017;
Prasad et al., 2019;
Ramirez et al., 2015;
Saga et al., 2017;
Saga et al., 2019;
Zhu et al., 2016)
. These contrasting motivational influences are due to valence partitioned, segregated ensembles of Acb neurons. It is well accepted that striatal D1 and D2 populations of SPNs can exert contrasting influences on behavior 
(Kravitz et al., 2012)
. However, in Acb, and especially AcbSh, this functional segregation is not just in terms of D1 v D2 SPN but also in terms of precise anatomical location and output projection. For example, Berridge and colleagues have identified distinct zones in AcbSh for appetitive and aversive influences on behavior 
(Baldo et al., 2003;
Berridge, 1996;
Castro and Berridge, 2014a;
Castro and Berridge, 2014b;
Castro et al., 2015;
Castro et al., 2016;
Peciña and Berridge, 2005;
Reynolds and Berridge, 2002;
Reynolds and Berridge, 2003;
Richard and Berridge, 2011)
. A zone in the rostral AcbSh, comprising dorsomedial AcbSh, contributes to positively valenced or appetitively motivated behaviors including eating and palatability, but extending to intracranial drug-selfadministration 
(Ikemoto et al., 2005;
Shin et al., 2008)
; whereas zones in the caudal portion of the AcbSh contribute to negatively-valenced or aversively motivated behaviors such as defensive behavior and avoidance. Appetitive and aversively motivated behaviors depend on signalling via glutamate, dopamine actions via D1 receptors, with an additional role for opioids and orexin in appetitively motivated behaviors 
(Castro and Berridge, 2014b;
Castro et al., 2016;
Laurent et al., 2014;
Laurent et al., 2012;
Laurent et al., 2015)
 and D2 receptors in caudal shell mediated-aversive behaviors 
(Richard and Berridge, 2011)
. Appetitive and aversive events cause distinct patterns of dopamine release across these regions of the Acb 
(de Jong et al., 2019;
Yuan et al., 2019)
. Cell-type specific optogenetic approaches support the conclusion that distinct Acb ensembles generate distinct motivational states, with photostimulation in different AcbSh regions yielding appetitive versus aversive effects 
(Al-Hasani et al., 2015)
. This evidence extends to learned control of both AcbSh ensembles and their outputs. For example, studies using focal electrical stimulation 
(Martinez-Rivera et al., 2016)
, immediate early gene and pharmacological mapping 
(Marchant et al., 2010;
Marchant et al., 2009;
Millan et al., 2010)
 identified distinct AcbSh regions that have opposing roles in promoting reinstatement versus extinction of drug seeking. Recently, more sophisticated neuronal ensemble specific manipulation techniques by Hope and colleagues have extended this 
(Warren et al., 2017)
, showing that distinct ensembles are recruited to promote versus prevent drug seeking 
(Cruz et al., 2014)
.
These ventral striatal ensembles underpinning preparatory behaviors are strongly linked to distinct, component consummatory behaviors (feeding, drinking, predatory behavior, flight etc) via projections to hypothalamus, ventral pallidum, midbrain, and brainstem circuits. These projections are also functionally and anatomically segregated. For example, AcbSh projections to the VP and VTA initiate appetitive motivational states. These projections possess reinforcing efficacy themselves 
(Yang et al., 2018)
 and mediate a variety of appetitive influences on behavior such as approach behaviors, feeding, reinstatement of extinguished reward seeking 
(Gibson et al., 2018;
Heinsbroek et al., 2017;
Khoo et al., 2015;
McFarland and Kalivas, 2001;
Stefanik et al., 2013)
, as well as environmental influences on choice 
Balleine, 2013, 2015)
. In contrast, AcbSh projections to the LH terminate appetitive states. These projections terminate feeding and approach behavior 
(O'Connor et al., 2015)
 and also mediate the learned inhibition of appetitively-motivated instrumental behavior by extinction 
(Gibson et al., 2018)
.


Central amygdala
The CeA is a major output nucleus of the amygdala, with extensive projections to LH, VTA, substantia nigra, midbrain periaqueductal gray (PAG), among others. Like the Acb, the
CeA is comprised of different populations of GABAergic neurons. CeA GABAergic neurons can be distinguished on the basis of a variety of markers, notably PKCd, somatostatin, and corticotropin releasing hormone, among others 
(Cai et al., 2014;
Fadok et al., 2017;
Pliota et al., 2018)
. CeA is essential for orchestrating defensive responses to threats 
(Davis, 1992;
Fanselow, 1994;
Maren and Quirk, 2004)
.
Different CeA ensembles have different roles in the initiation and termination of defensive behaviors (fear 'on' and fear 'off' cells), so that output neurons in the medial portion of the central nucleus (CeAm) are gated by cell populations in the lateral portion of the central nucleus (CeAl) 
(Ciocchi et al., 2010;
Ehrlich et al., 2009;
Haubensak et al., 2010;
Herry et al., 2008)
. The precise activity of different CeA ensembles determines not just the initiation and termination of defensive behavior but also the topography of defensive behavior to threat. For example, passive defensive behaviors (e.g., freezing) associated with distal threats are linked to CeA somatostatin neurons (SOM) whereas active defensive behaviors (e.g., escape) associated with proximal threats are linked to CeA corticotropinreleasing hormone neurons (CRH) 
(Fadok et al., 2017;
Pliota et al., 2018;
Sanford et al., Arbiter model -30 2016;
Yu et al., 2016)
. Inhibitory interactions between CRH and SOM neurons contribute to the transitions between these distinct defensive behaviors 
(Fadok et al., 2017)
.
The role of CeA is not limited to aversively motivated behavior. It extends to appetitively motivated behavior 
(Cai et al., 2014;
Douglass et al., 2017;
Gallagher and Holland, 1994;
Holland and Gallagher, 1993;
Holland and Gallagher, 1999;
Lee et al., 2010;
Lee et al., 2005;
Robinson et al., 2014)
. Early lesion studies implicated CeA in control of orienting to and learning about stimuli predicting reward, in the influence of these stimuli on choice, as well as in the learned control over feeding 
(Corbit and Balleine, 2005;
Holland and Gallagher, 1993;
Holland and Gallagher, 1999;
Lee et al., 2010;
Lee et al., 2005;
Petrovich et al., 2009;
Petrovich et al., 2002)
. More recent studies have identified distinct CeA populations for the initiation and termination of appetitive behaviors. For example, CeA
PKCd neurons mediate suppression of food consumption in response to a variety of anorexigenic signals, including injections of cholecystokinin, illness, and bitter tastants 
(Cai et al., 2014)
. In contrast, CeA serotonin 2a receptor expressing neurons promote feeding.
Serotonin 2a receptor expressing neurons increase activity prior to meal initiation, excitation of these neurons initiates food consumption and is positively reinforcing 
(Douglass et al., 2017)
. Importantly, just as there are competitive interactions between different CeA ensembles in the control of defensive behavior, so too are there competitive interactions between these CeA PKCd and serotonin 2a receptor ensembles in the control of feeding and appetitive behaviors 
(Douglass et al., 2017)
.


Summary
Together, these findings support the view that Acb and CeA can be viewed as gates controlling contrasting influences on behavior. In general, the behaviors gated by different ensembles are incompatible with each other (approach -withdraw; freeze -flight; meal initiation -meal termination). Similar findings are emerging for the bed nucleus of the stria terminalis 
(Giardino et al., 2018;
Hao et al., 2019;
Jennings et al., 2013;
Pati et al., 2019;
Wang et al., 2019)
. Thus, selection mechanisms are required to determine activity of these ensembles. Moreover, selection mechanisms are required to resolve any conflict between demands for these ensembles as they arise to ensure that incompatible behaviors do not occur at the same time animal (freeze v flight; approach v withdraw; initiate v terminate feeding). Selection mechanisms almost certainly exist in the complex, local inhibitory circuits of the Acb 
(Gerfen and Surmeier, 2011;
Pisansky et al., 2019)
 and CeA 
(Ciocchi et al., 2010;
Douglass et al., 2017)
, but as shown below, there is good evidence that they may also exist in the form of long-range circuits involving the paraventricular thalamus (PVT) and its interface with these local inhibitory circuits.
Arbiter model -31


Paraventricular thalamus as motivational arbiter
We propose that PVT is a critical component of an arbitration circuitry because it contributes to cross-coupling (feed forward inhibition) between ensembles, inhibiting selection of competing states 
(Figure 8
). PVT is located in the dorsal midline thalamus. It receives major inputs from prelimbic cortex, hypothalamus, and brainstem and projects to infralimbic cortex, nucleus accumbens, bed nucleus of the stria terminalis, and central amygdala 
(Dong et al., 2017;
Kirouac, 2015;
Kirouac et al., 2005
Kirouac et al., , 2006
Li and Kirouac, 2008;
Li and Kirouac, 2012;
Parsons et al., 2006
Parsons et al., , 2007
Vertes, 2006;
Vertes and Hoover, 2008;
Vertes et al., 2015)
. PVT neurons are primarily glutamatergic but express neuropeptides including enkephalin and substance P 
(Colavito et al., 2015;
Hsu et al., 2014;
Kirouac, 2015)
. Like other thalamic neurons, PVT neurons display tonic or burst firing modes 
(Kolaj et al., 2014)
. PVT neurons have a rich and diverse neuropharmacology, responsive to GABA, glutamate (via AMPA, NMDA, and mGluRs), and neuropeptides. PVT neurons express a variety of receptors including for corticotropin-releasing hormone, opioids, dopamine, neuropeptide S, VIP, and cannabinoid, among others 
(Colavito et al., 2015;
Kirouac, 2015)
.
There are least three key requirements to be met if PVT contributes to arbitration in motivational selection. First, arbitration is dynamic, not stable. So, PVT should be sensitive to changes in internal states and external demands. Second, arbitration is achieved by controlling access to a motivational finite state machine. So, PVT should have close interactions with Acb and extended amygdala neural ensembles. Third, arbitration involves selection by inhibitory cross-coupling. So, PVT should be involved in selection between these ensembles.


Arbitration must be dynamic, not static
PVT receives extensive inputs from the suprachiasmatic nucleus, the pacemaker essential to circadian timing and sleep/wake regulation 
(Peng and Bentivoglio, 2004)
. PVT neurons show daily oscillations in expression of clock genes (Per1, Per 2, Cry 1) and clock controlled genes (Dbp), entrained to the dark/light cycle and/or phase-shifting in response to meals 
(Angeles-Castellanos et al., 2007;
Feillet et al., 2008;
Mendoza et al., 2005)
. PVT also receives extensive inputs from hypothalamic orexin neurons 
(Kirouac et al., 2005)
 that serve a key role in the regulation of arousal and wakefulness 
(De Lecea et al., 1997;
Sakurai, 2007;
Sakurai et al., 1998)
. PVT contains both orexin 1 and orexin 2 receptors and PVT neurons are depolarised by both orexin A and orexin B 
(Huang et al., 2006)
. Moreover, these orexin actions in PVT influence PFC 
(Huang et al., 2006)
 and Acb projecting PVT neurons as well as Acb dopamine release, feeding, and locomotor behavior 
(Choi et al., 2012;
Li et al., 2009)
.
PVT receives inputs from hypothalamic and brainstem nuclei for regulation of energy homeostasis. 
Kelley (Kelley et al., 2005)
 first noted the key positioning of PVT inside the neural circuits for feeding and energy balance. Food cue-evoked activity of PVT neurons is gated by hunger, with greater excitatory phasic responses during hunger than satiation 
(Meffre et al., 2019)
. PVT receives inputs from the arcuate nucleus, notably AGRP neurons.
AGRP neurons are strongly recruited during fasting and their activation is sufficient to elicit feeding 
(Aponte et al., 2011;
Yang et al., 2011)
. Moreover, AGRP à PVT pathway activation is itself sufficient to elicit feeding and reduce avoidance behaviors in standard tests of anxiety 
(Betley et al., 2013;
Padilla et al., 2016)
. PVT receives projections from dorsomedial hypothalamic neurons that are responsive to leptin 
(Gautron et al., 2010)
. PVT receives inhibitory GABAergic inputs from zona incerta. Zona incerta neurons show increased activity during food deprivation and their activation increases feeding 
(Zhang and van den Pol, 2017)
. Moreover, activation of the ZI à PVT pathway elicits foraging behavior and food intake 
(Zhang and van den Pol, 2017)
. PVT also receives input from preproglucagon neurons in the nucleus of the solitary tract (NTS) that are sensitive to gastric distension, among other signals. These NTS neurons release the glucagon-like peptide 1 (GLP-1) to inhibit PVT neurons via the GLP-1 receptor and reduce feeding 
(Ong et al., 2017)
.
Finally, PVT is densely innervated from the prefrontal cortex, notably prelimbic, infralimbic, and insular cortex as well as receiving projections from the subiculum 
(Li and Kirouac, 2012)
. Neurons in these prefrontal regions have well documented sensitivity to cues, contexts, and behaviors that signal the presence and absence or reward and punishers, including cortical neurons with identified projections to PVT 
(Otis et al., 2017)
.
Moreover, the cortical inputs to PVT are derived from the same cortical regions implicated in conflict resolution and cognitive control processes such as response inhibition, response monitoring, and task switching 
(Botvinick et al., 2001;
Glascher et al., 2012;
Macdonald et al., 2000;
Miller and Cohen, 2001)
.


Arbitration should be achieved by ventral striatal and amygdala ensembles
PVT projects strongly to the extended amygdala and Acb 
(Kirouac, 2015;
Li and Kirouac, 2008)
. PVT neurons project extensively to the medial parts of the AcbSh and, to a lesser extent, the AcbC. Within the Acb, PVT projections preferentially target D1 and D2
receptor expressing SPNs with less innervation of interneurons 
(Kirouac, 2015)
. The precise anatomical and physiological organisation of these inputs is only just being revealed, but PVT inputs do converge onto the same AcbSh neurons as other glutamatergic inputs to
AcbSh 
(Perez and Lodge, 2018)
. These PVT inputs elicit AMPA-dependent excitatory postsynaptic currents (EPSCs) and picrotoxin sensitive inhibitory post-synaptic currents 
(IPSCs)
 in both D1 and D2 SPNs 
(Zhu et al., 2016)
. PVT-evoked IPSCs are delayed, relative to the Arbiter model -33
EPSCs, consistent with PVT inputs evoking feedforward inhibition in local Acb networks 
(Zhu et al., 2016)
. Indeed, Chen and colleagues 
(Keyes et al., 2019)
 have recently shown that PVT inputs target AcbSh D2 SPNs that, in turn, inhibit AcbSh D1 SPN output pathways controlling initiation and termination of appetitive behavior. This PVT control over feedforward inhibition in the AcbSh is precisely the kind of local circuit architecture required to instantiate inhibitory cross-coupling ( 
Figure 8
). PVT may also influence release of dopamine in the Acb. PVT terminals in the Acb are located close to dopamine terminals and PVT electrical stimulation can evoke dopamine release in the Acb independently of the activity of ventral tegmental area cell bodies 
(Parsons et al., 2007;
Pinto et al., 2003)
.
The PVT is similarly closely linked to CeA ensembles. Transsynaptic tracing studies
show that PVT provides monosynaptic inputs to each of the major CeA cell classes implicated in initiation and termination of appetitive (e.g., feeding) and aversive (e.g., defensive) behaviors as well as those involved in gating transitions between defensive behavior as a function of threat imminence 
(Cai et al., 2014;
Douglass et al., 2017;
Fadok et al., 2017;
Pliota et al., 2018)
. At least some of this anatomical connectivity has been confirmed electrophysiologically, with PVT inputs eliciting EPSCs in CRH 
(Pliota et al., 2018)
 and SOM 
(Penzo et al., 2015)
 neurons; but, whether this yields feedforward inhibition over the other (i.e. CRH -| SOM; SOM --| CRH), like it does in Acb, remains to be determined.
Regardless, like the Acb, there is the anatomical basis for PVT control over feedforward inhibition in CeA local inhibitory circuits.


Summary
PVT is remarkably well positioned to serve as a motivational arbiter. It receives inputs from hypothalamic and brainstem regions endowing arbitration with sensitivity to current metabolic needs as well as inputs from the PFC to support influences of learning and memory. It has requisite monosynaptic connectivity to influence the activity of Acb and CeA ensembles that control opposing influences on behavior. Moreover, in Acb at least, there is compelling evidence that PVT controls feedforward inhibition of these ensembles via local circuits. Whether this a general circuit motif for PVT inputs to CeA and BNST remains to be determined. Finally, Kirouac, Li and colleagues have shown that PVT inputs to extended amygdala and Acb are highly collateralised, so that the same PVT neurons have axons terminating in the Acb and extended amygdala 
(Dong et al., 2017)
. The heavy collateralisation of PVT subcortical projections is important because it provides an anatomical substrate for the long-range coordination of ensemble selection across distinct regions of the Acb and extended amygdala.


Paraventricular thalamus manipulations and behavior
PVT has been implicated in a remarkably diverse range of functions including arousal 
(Colavito et al., 2015)
, stress 
(Bhatnagar, 2003;
Bhatnagar and Dallman, 1999;
Bhatnagar et al., 2002;
Hsu et al., 2014)
, fear 
(Beas et al., 2018;
Do-Monte et al., 2015;
Penzo et al., 2015;
Zhu et al., 2018)
, appetitive learning 
(Otis et al., 2017;
Otis et al., 2019;
Zhu et al., 2018)
, incentive salience 
(Campus et al., 2019;
Haight and Flagel, 2014;
Haight et al., 2015;
Haight et al., 2017)
, relapse to drug seeking 
(Dayas et al., 2007;
Dayas et al., 2008;
Hamlin et al., 2009;
James et al., 2011;
James et al., 2010;
James and Dayas, 2013;
Marchant et al., 2010;
Martin-Fardon and Boutrel, 2012;
Matzeu et al., 2017;
Matzeu et al., 2015)
, opiate withdrawal 
(Zhu et al., 2016)
 , drinking and feeding 
(Barson et al., 2015;
Barson et al., 2017;
Ong et al., 2017)
. We argue that PVT is implicated in these diverse functions because they have in common the need for motivational selection and PVT is a key component of the circuitry arbitrating this selection.
This role for PVT is complementary to other inputs to Acb and extended amygdala.
Acb, BNST, and CeA receive extensive excitatory (predominantly glutamatergic) inputs from cortex, ventral hippocampus, basolateral amygdala, among others, as well inputs from midbrain and brainstem, that have well documented roles in initiating and terminating motivated behaviors 
(Britt et al., 2012)
. For example, there is an abundance of evidence that cortical inputs to Acb are critical for initiating or terminating approach and other appetitively motivated behaviors 
(Bobadilla et al., 2017;
Kalivas and Volkow, 2005;
LaLumiere et al., 2010;
Moorman and Aston-Jones, 2015)
. Likewise, Ito, Marchant and others have shown that ventral hippocampus inputs to Acb are crucial to inhibiting appetitive behavior, including during motivational conflict 
(Bossert et al., 2016;
Hamel et al., 2017;
Marchant et al., 2016;
Nguyen et al., 2018;
O'Neil et al., 2015;
Schumacher et al., 2016)
. The proposal here is that PVT serves a complementary role to these other inputs. PVT contributes to selection between these inputs via feed forward inhibition (inhibitory cross-coupling between ensembles) thereby suppressing selection of competing states.
There are unique predictions from the arbiter account of PVT function. First, PVT will have strong contributions to behavior in the presence, but weaker contributions in the absence, of conflict. In the absence of conflict, the influence of cross-coupling inside the arbiter is reduced and the arbiter is still able to achieve relatively stable state selections. So, manipulations of PVT should have their strongest effects on behavior in the presence of conflict. Second, as a general selection mechanism, these PVT contributions should be apparent across different forms of conflict (e.g., approach -avoidance; approachapproach; avoidance -avoidance). Third, in the absence of PVT but the presence of conflict, motivational selection should become less bistable and more metastable. There is compelling evidence in the literature for the first and second predictions, and some evidence for the third.


PVT and conflict between motivational systems
PVT serves a key role in approach -avoidance conflict. PVT neurons are robustly recruited by appetitive (e.g., sucrose; drugs of abuse) and aversive events (e.g., footshock)
as well as by cues that predict these events 
Choi et al., 2019;
Flagel et al., 2011;
Hamlin et al., 2009;
Meffre et al., 2019;
Zhu et al., 2018
) (for review see 
(Millan et al., 2017)
). Although initial studies suggested that PVT may play a role in eliciting defensive or approach behaviors directly 
(Do-Monte et al., 2015;
Padilla-coreano et al., 2011;
Penzo et al., 2015)
, many of these studies involved some form of conflict (e.g., animals were tested for defensive behavior whilst engaged in a food lever pressing task or multiple appetitive cues were presented to animals). More recent findings show that lesions, reversible inactivation, chemogenetic or optogenetic silencing of PVT have little effect on behaviors controlled by appetitive or aversive events and their predictors when these behaviors are assessed in isolation. For example, rats and mice are able to express appropriate behaviors towards a single source of reward (nosepoke, magazine, spout) or express defensive behaviors (e.g., freezing, avoidance) towards a single source of danger despite lesion, chemogenetic or optogenetic silencing of PVT 
(Cheng et al., 2018;
Choi et al., 2019;
Choi and McNally, 2017;
Li et al., 2014;
Zhu et al., 2018)
. So, PVT is not necessary for expression of these behaviors per se.
However, when these approach -avoidance tendencies are pitted against each other, PVT manipulations have pronounced effects. For example, when fear is pitted against reward by presenting a fear CS to animals whilst they lever press for food, PVT silencing profoundly affects behavior, altering either defensive (i.e. freezing) or reward (i.e. lever pressing, magazine entries) behaviors or both 
(Choi and McNally, 2017;
Do-Monte et al., 2015;
Li et al., 2014;
Padilla-Coreano et al., 2011)
. Similar findings are observed in Pavlovian counterconditioning where motivational conflict is generated by transforming the same Pavlovian CS from a predictor of reward into a predictor of danger 
(Choi et al., 2019)
 or when animals forage for food in an open field 
(Cheng et al., 2018)
. For example, PVT silencing has no effect on magazine entries to a CS that signals food pellets or on freezing responses to a CS that signals footshock if these CSs are trained and tested alone. But, when the same CS is first trained to signal food pellets and then signal shock (or vice versa), so that it controls conflicting approach and defensive behaviors, PVT silencing disrupts approach behavior or freezing or both 
(Choi et al., 2019)
. There is also some evidence from these studies that the effect of PVT manipulations is to increase behavioral metastability. For example, during these approach -avoidance conflicts, PVT silencing increased switching Arbiter model -36 between approach (lever press or magazine entries) and defensive (freezing) behaviors without consistently favouring expression of one behavior over the other 
(Choi et al., 2019;
Choi and McNally, 2017)
. As reviewed previously, approach -avoidance conflicts are
widespread. An important prediction of the arbiter model is that PVT will be important to behavioral selection during these conflicts via its projections to Acb and extended amygdala.
This could be a productive area of further research.
Persisting with approach behavior in the face of non-reinforcement involves approach -avoidance conflict because the omission of an expected reward generates frustration promoting withdrawal and avoidance 
(Amsel, 1992;
Brown and Wagner, 1964;
Rescorla, 2001;
Wasserman et al., 1974)
. PVT is essential to behavior under these conditions. For example, the activity of PVT neurons, especially in anterior portions, is sensitive to the unexpected omission of reward. PVT neurons projecting to Acb suppress, whereas PVT neurons projecting to CeA generate, approach behavior to a lever and lever pressing under this conflict 
(Do-Monte et al., 2017)
. Crucially, these same projections have no role in approach behavior or lever pressing in the absence of motivational conflict caused by reward omission (Do-Monte et al., 2017).
Similar findings come from studies of extinction and reinstatement of drug seeking.
Drug self-administration extinction -reinstatement studies involve approach -avoidance conflict because tests for reinstatement involve non-reinforcement of drug-seeking behavior.
The approach behavior of the animal towards the drug-seeking manipulanda (lever, nosepoke) and the drug seeking response (lever press, nosepoke) are not rewarded.
Persisting in non-reinforced behavior (i.e. demonstrating reinstatement) requires resolving this conflict. Under these conditions, manipulations of PVT have pronounced effects on behavior. Lesions, reversible inactivation, or chemogenetic silencing of PVT significantly reduce a variety of forms of reinstatement to seeking a variety of drugs of abuse 
(Giannotti et al., 2018;
Hamlin et al., 2009;
James et al., 2010;
Marchant et al., 2010;
Matzeu et al., 2016;
Matzeu et al., 2015;
Wunsch et al., 2017
) (for review see 
(Millan et al., 2017)
). Again, these same manipulations have little effect on the same behaviors in the absence of the conflict generated by non-reinforcement. The prediction from the arbiter model is that manipulations which reduce PVT function should reduce relapse behaviors, at least in part, because they prevent suppression of competing behaviors. However, this remains to be examined because the studies above typically only measured a single behavior (lever press or nosepoke).
It will be of interest to study PVT contributions to behavior under conditions that better isolate the effects of appetitive non-reinforcement (extinction, partial reinforcement),
as well as to more thoroughly assess multiple behaviors during these tests to better understand the effects of PVT manipulations. Moreover, a prediction of the arbiter model is that PVT normally contributes to selection in approach -avoidance conflict by suppressing competing behaviors. It follows that inhibition and non-selective excitation of PVT may yield the same behavioural effect, but for different reasons. Silencing PVT can disrupt behaviour under approach -avoidance conflict because it prevents suppression of competing behaviours. Excitation of PVT can also disrupt behaviour under this conflict but because it suppresses selection of behaviour. This effect of PVT excitation would be the opposite, but complementary, to the non-selective increases in frequency of normal behavior 
(Yael et al., 2019
) and neural activity 
(Millan et al., 2010)
 observed after non-selectively inhibiting Acb and is worth further investigation (e.g., 
Chisholm et al., 2019)
.


PVT and conflict within motivational systems
PVT is essential to conflict resolution within appetitive motivational states. One example comes from the study of approach behavior in Pavlovian conditioning by 
Flagel and colleagues (Flagel et al., 2011;
Haight and Flagel, 2014;
Haight et al., 2015;
Haight et al., 2017;
Kuhn et al., 2018)
. In these experiments, a lever CS signals delivery of food to magazine and animals can express approach to the lever (sign tracking), the magazine (goal tracking) or vacillate between the two 
(Haight et al., 2015)
. As noted above, PVT is not necessary for approach to a lever or magazine 
(Choi et al., 2019;
Choi and McNally, 2017;
Do-Monte et al., 2017)
; but, when these behaviors compete with each other such as during sign-tracking, PVT is critical to selection between them. Under these conditions, PVT, and PL inputs to PVT, suppress approach to the lever (sign tracking) enabling approach to the magazine (goal tracking) 
(Campus et al., 2019;
Haight et al., 2015)
. Flagel 
(Flagel et al., 2011;
Haight and Flagel, 2014;
Haight et al., 2017)
 has hypothesized that the opposite would be observed for hypothalamic inputs to PVT (i.e. these enable sign-tracking over goal tracking). A second example comes from discriminative Pavlovian appetitive conditioning.
PVT is not critical for magazine approach or licking behavior as conditioned responses. That is, both behaviors as learned responses are unaffected by PVT chemogenetic or optogenetic inhibition 
(Choi et al., 2019;
Zhu et al., 2018)
. However, PVT contributes to discriminative control over these behaviors when such control involves responding to a predictive cue but suppressing this behavior to a non-predictive cue 
(Otis et al., 2017;
Otis et al., 2019)
. Under these conditions, activation of PFCà PVT neurons reduces, whereas silencing of PFCàPVT neurons enhances, the acquisition of responding or the CS+ 
(Otis et al., 2017)
. Moreover, this activation impairs behavioral discrimination between the predictive and non-predictive stimulus and disrupts encoding by PVT à Acb neurons of predictive and non-predictive cues 
(Otis et al., 2019)
. So, PVT is implicated in selection, at least in part, by suppressing behavior. There are other examples where behavior could be viewed through the lens of conflict. An interesting example is the influence of reward predictive cues on choice, as studied by Pavlovian to instrumental transfer. The influences of cues that nonselectively energise instrumental behavior are mediated by the AcbC and CeA whereas predictive information from these cues that biases choice towards actions sharing a common outcome are mediated by the AcbSh and BLA 
(Corbit and Balleine, 2016;
Corbit et al., 2007;
Corbit et al., 2001;
Laurent et al., 2012;
Laurent et al., 2015)
. Theoretical 
(Dickinson and Balleine, 2002)
 and empirical 
(Corbit and Balleine, 2005;
Holland, 2004;
Rescorla, 1994)
 findings from Balleine, Corbit and others suggest that the predictive influences of cues on choice are achieved, in part, by supressing competing behaviors. A prediction from the arbiter model is that PVT should contribute to action selection during specific transfer and that PVT inhibition should impair this transfer.
Finally, there is some, albeit less compelling evidence for a role of PVT in resolving avoidance -avoidance conflict. PVT does not appear necessary for expression of defensive behavior per se. PVT lesion or chemogenetic inhibition do not disrupt the expression of defensive behaviors as conditioned responses, but do when these are in conflict with other behaviours 
(Choi et al., 2019;
Choi and McNally, 2017;
Li et al., 2014)
. As noted above, PVT provides monosynaptic inputs to both CeA CRH and SOM ensembles critical for active versus passive defensive responses to threat. This provides strong anatomical support for a role of PVT in selecting between these responses during conflict. Although this remains to be tested in fear conditioning tasks isolating transitions between active and passive defensive behaviors, there is evidence that PVT contributes to selection between active and passive defensive behaviors under other conditions. PVT has been well implicated in responses to stressors 
(Beas et al., 2018;
Bhatnagar, 2003;
Bhatnagar et al., 2002;
Hsu et al., 2014)
. 
Pliota et al. have
 shown that exposure to footshock shifts coping behavior in an elevated plus maze from active (exploration) to passive (freezing, immobility). PVT inputs to
CeA gate this transition from active to passive behaviors by regulating local release of CRH in the CeA 
(Pliota et al., 2018)
. These and other questions about the role of PVT in selection of defensive behaviors (e.g., role of PVT in generalized versus discriminative fear responding) are important areas for future work.


Summary
PVT has been implicated in a surprisingly diverse range of functions, across a range of tasks from sign and goal tracking, relapse to drug seeking, fear memory retrieval, stress coping, persisting with appetitive behavior during non-reinforcement, Pavlovian counterconditioning, and suppression of reward seeking under threat. A coherent account of why PVT should be linked to these diverse functions has been lacking. The evidence considered here supports the view that a contribution of PVT is likely due to the presence of different forms of conflict, in the form of concurrent competing motivational demands across these various tasks. Moreover, the overall profile of these findings is consistent with predictions from the arbiter model that PVT is important for behavior under conflict because it inhibits selection of competing states. Thus, the arbiter model offers a novel, straightforward, and integrative account of PVT function. Moreover, the model generates predictions about the influence of PVT manipulations across these tasks. Much remains to be learned about how and when PVT contributes to behavior, the role and consequences of plasticity in PVT projections for selection, and there is increasing recognition that PVT is not a homogeneous structure, with anterior and posterior PVT anatomically and functionally distinct 
(Barson et al., 2015;
Choi et al., 2019;
Do-Monte et al., 2017;
Li and Kirouac, 2012)
.
Regardless, the arbiter model offers a useful framework for conceptualising PVT function.


Pathologies in arbitration
It is common in contemporary behavioral neuroscience to view disorders such as anxiety and addictions as pathologies of learning. Fear and anxiety are viewed as pathologies of synaptic plasticity in amygdala and prefrontal circuits for fear and safety learning. Addiction, obesity, and behavioral compulsions are viewed as pathologies of plasticity in corticostriatal circuits for learning, modes of instrumental control, and valuebased decision making. The learning-based tradition to understanding these disorders has been profitable. It has inspired new experimental approaches to studying these disorders, yielded significant knowledge gains about the brain mechanisms for these disorders, and critically, improved knowledge about treatments 
(Davis et al., 2005;
Kalivas and O'Brien, 2007;
Kalivas and Volkow, 2011;
Ressler et al., 2004;
Spencer and Kalivas, 2017
).
The arbiter model suggests a complementary way of thinking about behavior. The arbiter model renews focus on questions of performance. It raises the possibility that, in addition to roles for aberrant learning processes, behavior can involve pathologies of arbitration and selection. These could include failures to terminate or switch states in a timely manner (excessive 'stickiness' in state selection), leading to excessively persistent or focussed behaviour. They could also include premature state termination or excessive switching, resulting in a failure to stably latch motivational states.
Excessively 'sticky' selection could contribute to an excessive focus on drug-related pursuits and narrowing of behavioral repertoires in drug addiction. An emerging body of work by Ahmed, Shaham, Venniro, Marchant, Vandershuren and others supports this possibility in terms of aberrant resolution of approach -avoidance (insensitivity of drug-seeking and taking to adverse consequences) and approach -approach (effects of choice on drugseeking and drug taking) conflicts in animal models of addiction 
(Ahmed et al., 2018;
Ahmed et al., 2013;
Lenoir et al., 2007;
Nguyen et al., 2015;
Pare and Quirk, 2017;
Vandaele et al., 2019;
Venniro et al., 2019;
Venniro et al., 2017;
Venniro et al., 2018)
. So, disorders of appetitive motivation, such as addictions, might be understood not just as problems of reinforcement or value 
(Berridge and Robinson, 2016;
Everitt and Robbins, 2005;
Koob, 2013
Koob, , 2015
Koob and Mason, 2016;
Robinson and Berridge, 1993)
, but also as problems of arbitration. Likewise, it is common in behavioural neuroscience to view pathological anxiety as the product of excessive fear learning or impaired safety learning. Yet, studies in human clinical populations tend to show very modest or no difference in explicit fear or safety learning. Rather, meta-analyses of conditioning in clinically anxious individuals show deficits in switching between fear and safety, leading clinically anxious individuals to exhibit generalized fear responses 
(Beckers et al., 2013;
Duits et al., 2015;
Lissek et al., 2005;
Lissek and van Meurs, 2014
). The arbiter model provides one framework for conceptualizing these deficits in selecting between otherwise normal mechanisms for fear and safety.
From the perspective offered here, pathologies of motivation are not just problems of learning, they are also problems of performance. Contemporary learning-based models of addiction, anxiety, and other disorders largely leave unanswered questions about performance. The arbiter model focusses on these questions of performance and offers one framework in which to consider them.


Conclusions
Competition between motivational demands is pervasive and solving this competition is fundamental to survival and daily function. However, there is rarely a single, permanent, appropriate solution. Rather, the appropriate solutions vary across different time scales (time of day, seasonal) as well as internal states (mood, arousal, sleep) and external (threat salience, presence of food reward, presence of conspecifics) demands. The arbiter model as described here is one solution to the problem of competition. It is a model of performance that yields the characteristics of behavior under conflict and can be applied across a range of problems involving conflict between and within motivational systems. It is a complement to mechanisms for learning, including value-based learning. The arbiter model provides a circuit motif that could be instantiated at multiple levels in the nervous system, including via PVT and its key role as interface between hypothalamic and brainstem centers for feeding and energy balance, and prefrontal, striatal and extended amygdala circuits for responding.
Much remains to be learned about these processes, how they support normal function, and how they may go awry. Regardless of the fate of the arbiter model, it may encourage further empirical and theoretical development on these important issues.
Input driven transitions between states are controlled by an arbiter(Figure 2). The arbiter allocates access to the Finite State Machine. It is akin to a parent allocating the last scoop of ice-cream to one of his children or an officer at an intersection guiding traffic. When there are multiple requests for the same behavior, the arbiter grants one request and not others, thereby ensuring that two


Figure 2 .
2
The arbiter gates transitions in the Finite State Machine. incompatible behaviors do not occur at the same time. The arbiter enables selection of a winner from competing inputs and that winner controls behavior at that point in time. The arbiter may select the same or a different winner at the next point in time. In doing so, the arbiter can be viewed as enabling rapid and stable transitions or switching between motivations and behavioral states. From this perspective, the organism can be viewed as continuously navigating motivational state spaces with arbiter-controlled transitions between these states tuning the animal to, and servicing the demands of, the environment.Various forms of arbitration are possible, but a simple latch-based model (Figure 3) is a powerful starting point. This arbiter is a bistable device capable of storing the value of any input it receives at a given point in time (i.e. 1-bit memory). The arbiter reads two inputs, A and B, and transitions the Finite State Machine into the appropriate State (A or B) corresponding to these inputs. The arbiter comprises two AND gates (Gate 1 and Gate 2) with the outputs of each gate fed back as inverted inputs to the other. In this arrangement the gates are cross-coupled. This arbiter selects a "winner" by latching the output of the circuit on to the winning input (A or B) and transitioning the Finite State Machine into the corresponding State, A or B. The arbiter responds to a valid change in A or B, transitioning or 'latching' the Finite State Machine to A or B, regardless of the duration of the inputs (i.e. it is 'sticky'). The Finite State Machine remains in the selected state until another, different valid input transitions it to another state.


Figure
Figure 3. An arbiter circuit established by inhibitory cross-coupling (via inverters) between two AND gates. The truth tables for the AND gates are shown above or below each gate and the characteristic table for the circuit is shown on the right.


Figure 4 .
4
Bistable and metastable selection in an arbiter circuit.


Figure 5 .
5
The resolution of conflict. i) Time taken for an arbiter circuit to resolve conflict is a function of the similarity of competing demands (t = 0.5, t = 1, for values ofK = 0.15, 0.3, 0.45, and 0.6). ii) Probability of remaining in conflict as a function of time.


Figure 6ii .
6ii
The exponential curves provide not unreasonable fits. It is also possible to approximate the results of Schlund et al. by fitting a quadratic function to intermediate values of K from #/% , such as those used inFigure 5i. Although approximating the findings, this is not ideal because for low values of K (dotted lines on the fitted quadratic function inFigure 6iii), predictions from the arbiter are difficult (see below).


Figure 6 .
6
i) Mean decision times under an approach -avoidance conflict (Data provided by M.W. Schlund(Schlund et al., 2016, Figure 4b)). Participants were required to approach or avoid a source of reward under different probabilities of threat. Data shown are times taken to make a decision for three days of training. ii) The same data, separated by the threat scale midpoint, and fitted with separate exponentials. iii) Time taken for an arbiter to resolve an approach -avoidance conflict for t = 0.5, t = 1,K = 0.3, 0.45, and 0.6.    


Figure 8). The extended amygdala refers to a ring of structures surrounding the internal capsule and comprises the central and medial nuclei of the amygdala, as well as the medial, lateral, and supracapsular nuclei of the bed nucleus. The nucleus accumbens shell is directly contiguous with the extended amygdala and has been included in some but not other descriptions of the extended amygdala (de Olmos and


Figure 8 .
8
An arbiter circuit involving paraventricular thalamic control over accumbens shell and extended amygdala ensembles.


Motivational selection can be viewed as a problem of state selection in a Finite State Machine. A Finite State Machine is a hypothetical machine that can be in one or more states. We consider a Finite State Machine that can be in one of two states, A or B(Figure 1). Specifically, we propose that motivational states are represented separately. Each state is initiated by an appropriate input that transitions the animal to that state. Once in that state, State A, a range of behaviors appropriate to that state, but not other states, are available. This state remains selected until a different input transitions the animal to a different state, State B, thereby permitting new behaviors appropriate to the new state.These transitions could be between initiating and terminating a single motivational state or between different motivational states. For example, behavior systems theorists identify distinct behavior systems whereas associative theorists emphasise that these distinct forms of behavior are underpinned by two general motivational states: appetitive and threats innately activate the aversive (or defensive) system
(De Franceschi et al., 2016;
Yilmaz and Meister, 2013)
. However, inputs can also acquire this ability via experience and learning. Pavlovian learning is a mechanism imbuing environmental stimuli with motivational properties. Instrumental learning is a mechanism imbuing actions or behaviors with such properties. Learning enables the flexible and anticipatory deployment of motivation to service behavior in a dynamic environment. Moreover, it permits stimulus (or action) discrimination and generalisation, to limit or spread such control across a range of similar inputs even when those inputs themselves have not received explicit training.Selection of a state generates preparatory behavior (approach or withdrawal) and behavioral modes appropriate to that state. It also enables component consummatory behaviors linked to that state. For example, in the case of an animal seeking food, activation of the appetitive motivational system is reflected directly by locomotor approach behavior, but it also enables a suite of behaviors (eating, chewing or licking) necessary for consumption of that food (modules and modes in the behavior systems approach). These behaviors are appropriate to an appetitive but are inappropriate to an aversive state. In the case of an animal encountering a predator and seeking safety, activation of the aversive motivation system is reflected directly by changes in eye gaze, posture, and locomotor behavior, but it also enables a suite of behaviors (escape, head dipping etc) appropriate to an aversive, but inappropriate to an appetitive, state.
Figure 1. A hypothetical finite
state machine that can
transition between two
different states.
aversive. Regardless, most theorists assume that states are initiated by an input(s). Inputs can possess this ability innately. For example, sweet tastes innately activate the appetitive (or feeding) system (Berridge, 1996; Berridge, 2004; Berridge, 2019) whereas looming


The truth tables for the AND gates are shown above or below each gate and the characteristic table for the circuit is shown on the right.to any input from B. When the input to A terminates, the output of A is now low and the Finite State Machine remains in State A. Further inputs on A have no effect. The latch can be reset, and the Finite State Machine transitioned to State B, via an input on B. The symmetry of the circuit means that an input on B opens Gate 2, closes Gate 1, and B "wins" access, transitioning the Finite State Machine to State B. Thus, the arbiter uses feedforward
inhibition via cross-coupling
between the gates to
achieve stable transitions
between different states
and, hence, stable
transitions in motivation and
behavior
3. An arbiter circuit established by inhibitory cross-coupling (via inverters) between two AND gates.


stable State A or B. This instantiates another key feature of motivational conflict: the greater the similarity between the competing demands, the greater the conflict.
The time (t) taken for an
arbiter circuit to resolve conflict
by stably latching State A or
State B can be formally defined
by
#/% (Ginosar, 2011). t
describes inertia or the time
constant of the arbiter (if t is
large, the arbiter is slow [inertia
is higher]; if t is small, the
arbiter is fast). This could vary
within and across different
individuals. K is the initial
difference between inputs. For
ease of description, K is constrained here between 1 and -1. For example, in








Acknowledgements
Arbiter model -42












Non-pharmacological factors that determine drug use and addiction




S
H
Ahmed






A
Badiani






K
A
Miczek






C
P
Muller








Neurosci Biobehav Rev




18
















Neurobiology of addiction versus drug use driven by lack of choice




S
H
Ahmed






M
Lenoir






K
Guillem








Curr Opin Neurobiol




23
















Distinct Subpopulations of Nucleus Accumbens Dynorphin Neurons Drive Aversion and Reward




R
Al-Hasani






J
G
Mccall






G
Shin






A
M
Gomez






G
P
Schmitz






J
M
Bernardi






C.-O
Pyo






S
Park






C
M
Marcinkiewcz






N
A
Crowley






M
J
Krashes






B
B
Lowell






T
L
Kash






J
A
Rogers






M
R
Bruchas








Neuron




87
















Amygdala Signaling during Foraging in a Hazardous Environment




A
Amir






S
C
Lee






D
B
Headley






M
M
Herzallah






D
Pare








J Neurosci




35
















Frustrative nonreward in partial reinforcement and discrimination learning: some recent history and a theoretical extension




A
Amsel








Psychological Review




69
















Frustration theory: An analysis of disposotional learning and memory




A
Amsel








Cambridge University Press












Foraging range in mice and voles: the role of risk




P
K
Anderson








Canadian Journal of Zoology




64
















Restricted feeding schedules phase shift daily rhythms of c-Fos and protein Per1 immunoreactivity in corticolimbic regions in rats




M
Angeles-Castellanos






J
Mendoza






C
Escobar








Neuroscience




144
















AGRP neurons are sufficient to orchestrate feeding behavior rapidly and without training




Y
Aponte






D
Atasoy






S
M
Sternson








Nat Neurosci




14
















The organization of defensive behavior elicited by optogenetic excitation of rat lateral or ventrolateral periaqueductal gray




N
Assareh






M
Sarrami






P
Carrive






G
P
Mcnally








Behav Neurosci




130
















Sickness and behavior in animals: A motivational perspective




A
Aubert








Neuroscience and Biobehavioral Reviews




23
















Neural substrates of approach-avoidance conflict decision-making




R
L
Aupperle






A
J
Melrose






A
Francisco






M
P
Paulus






M
B
Stein








Hum Brain Mapp




36
















A reverse translational approach to quantify approach-avoidance conflict in humans




R
L
Aupperle






S
Sullivan






A
J
Melrose






M
P
Paulus






M
B
Stein








Behav Brain Res




225
















Human hippocampus arbitrates approach-avoidance conflict




D
R
Bach






M
Guitart-Masip






P
A
Packard






J
Miro






M
Falip






L
Fuentemilla






R
J
Dolan








Curr Biol




24
















Overlapping distributions of orexin/hypocretin-and dopamine-beta-hydroxylase immunoreactive fibers in rat brain regions mediating arousal, motivation, and stress




B
A
Baldo






R
A
Daniel






C
W
Berridge






A
E
Kelley








The Journal of Comparative Neurology




464
















Dissociable neural representations of future reward magnitude and delay during temporal discounting




K
Ballard






B
Knutson








Neuroimage




45
















Goal-directed instrumental action: contingency and incentive learning and their cortical substrates




B
W
Balleine






A
Dickinson








Neuropharmacology




37
















Parallel incentive processing: an integrated view of amygdala function




B
W
Balleine






S
Killcross








Trends Neurosci




29
















Substance P in the anterior thalamic paraventricular nucleus: promotion of ethanol drinking in response to orexins from the hypothamalus




J
Barson






K
Poon






H
T
Ho






M
I
Alam






L
Sanzalone






S
Leibowitz








Addiction Biology




22
















Anterior thalamic paraventricular nucleus is involved in intermittent access ethanol drinking: role of orexin receptor 2




J
R
Barson






H
T
Ho






S
F
Leibowitz








Addict Biol




20
















The locus coeruleus drives disinhibition in the midline thalamus via a dopaminergic mechanism




B
S
Beas






B
J
Wright






M
Skirzewski






Y
Leng






J
H
Hyun






O
Koita






N
Ringelberg






H.-B
Kwon






A
Buonanno






M
A
Penzo








Nature Neuroscience




54
















Approach avoidance training in the eating domain: testing the effectiveness across three single session studies




D
Becker






N
B
Jostmann






R
W
Wiers






R
W
Holland








Appetite




85
















What's wrong with fear conditioning?




T
Beckers






A
M
Krypotos






Y
Boddez






M
Effting






M
Kindt








Biol Psychol




92
















Addiction: failure of control over maladaptive incentive habits




D
Belin






A
Belin-Rauscent






J
E
Murray






B
J
Everitt








Current Opinion in Neurobiology




23
















Moment-to-moment tracking of state value in the amygdala




M
A
Belova






J
J
Paton






C
D
Salzman








J Neuroscii




28
















Topographical organization and relationship with ventral striatal compartments of prefrontal corticostriatal projections in the rat




H
W
Berendse






Y
Galis-De Graaf






H
J
Groenewegen








The Journal of Comparative Neurology




316
















Food reward: brain substrates of wanting and liking




K
C
Berridge








Neuroscience and Biobehavioral Reviews




20
















Motivation concepts in behavioral neuroscience




K
C
Berridge








Physiology & Behavior




81
















Affective valence in the brain: modules or modes?




K
C
Berridge








Nat Rev Neurosci




20
















Liking, wanting, and the incentive-sensitization theory of addiction




K
C
Berridge






T
E
Robinson








Am Psychol




71
















Parallel, redundant circuit organization for homeostatic control of feeding behavior




J
N
Betley






Z
F
Cao






K
D
Ritola






S
M
Sternson








Cell




155
















Organization of Valence-Encoding and Projection-Defined Neurons in the Basolateral Amygdala




A
Beyeler






C
J
Chang






M
Silvestre






C
Le´veque






P
Namburi






C
P
Wildes






K
M
Tye








Cell Reports




22
















Divergent Routing of Positive and Negative Information from the Amygdala during Memory Retrieval




A
Beyeler






P
Namburi






G
F
Glober






C
Simonnet






G
G
Calhoon






G
F
Conyers






R
Luck






C
P
Wildes






K
M
Tye








Neuron




90
















Chronic stress alters behavior in the conditioned defensive burying test: role of the posterior paraventricular thalamus




S
Bhatnagar








Biochemistry, and Behavior




76










Pharmacology








The paraventricular nucleus of the thalamus alters rhythms in core temperature and energy balance in a state-dependent manner




S
Bhatnagar






M
F
Dallman








Brain Research




851
















Lesions of the Posterior Paraventricular Thalamus Block Habituation of Hypothalamic-Pituitary-Adrenal Responses to Repeated Restraint




S
Bhatnagar






R
Huber






N
Nowak






P
Trotter








Journal of Neuroendocrinology




14
















Defensive reactions in the albino Rat




R
J
Blanchard






D
C
Blanchard








Learning and Motivation




2
















Defensive behaviors of laboratory and wild Rattus norvegicus




R
J
Blanchard






K
J
Flannelly






D
C
Blanchard








Journal of Comparative Psychology




100
















Accumbal D2 cells orchestrate innate risk-avoidance according to orexin signals




C
Blomeley






C
Garau






D
Burdakov








Nat Neurosci




21
















Performance on learning to associate a stimulus with positive reinforcement




R
A
Boakes




Davis, H., Hurwitz, H.M.B.






Lawrence Erlbaum Associates




Hillsdale, N.J.






Operant-Pavlovian interactions








Corticostriatal plasticity, neuronal ensembles, and regulation of drug-seeking behavior




A.-C
Bobadilla






J
A
Heinsbroek






C
D
Gipson






W
C
Griffin






C
D
Fowler






P
J
Kenny






P
W
Kalivas








Prog Brain Res




235
















The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks




R
Bogacz






E
Brown






J
Moehlis






P
Holmes






J
D
Cohen








Psychological Review




113
















Synaptic organisation of the basal ganglia




J
P
Bolam






J
J
Hanley






P
A
Booth






M
D
Bevan








Journal of Anatomy




196
















Theory of Motivation




R
C
Bolles








Harper & Row


New York












A perceptual-defensive-recuperative model of fear and pain




R
C
Bolles






M
S
Fanselow








Behavioral and Brain Sciences




3
















Role of projections from ventral subiculum to nucleus accumbens shell in context-induced reinstatement of heroin seeking in rats




J
M
Bossert






S
Adhikary






R
St Laurent






N
J
Marchant






H.-L
Wang






M
Morales






Y
Shaham








Psychopharmacology




233
















Conflict monitoring and decision making: Reconciling two perspectives on anterio cingulate function




M
Botvinick








Cognitive, Affective & Behavioral Neuroscience




7
















Motivation and cognitive control: from behavior to neural mechanism




M
Botvinick






T
Braver








Annu Rev Psychol




66
















Conflict monitoring and cognitive control




M
Botvinick






T
Braver






D
M
Barch






C
S
Carter






J
D
Cohen








Psychological Review




108
















Chemical and structural analysis of the relation between cortical inputs and tyrosine hydroxylase-containing terminals in rat neostriatum




J
J
Bouyer






D
H
Park






T
H
Joh






P
Vm








Brain Research




302
















Rewarding and punishing effects from stimulating the same place in the rat's brain




G
H
Bower






N
E
Miller








J Comp Physiol Psychol




51
















Miller (1944) revisited: Movement times in relation to approach and avoidance conflicts




R
L
Boyd






M
D
Robinson






A
K
Fetterman








Journal of Experimental Social Psychology




47
















Synaptic and Behavioral Profile of Multiple Glutamatergic Inputs to the Nucleus Accumbens




J
P
Britt






F
Benaliouad






R
A
Mcdevitt






G
D
Stuber






R
A
Wise






A
Bonci




model -45






Neuron




76
















Approach bias and cue reactivity towards food in people with high versus low levels of food craving




T
Brockmeyer






C
Hahn






C
Reetz






U
Schmidt






H
C
Friederich








Appetite




95
















The Patterns of Afferent Innervation of the Core and Shell in the "Accumbens" Part of the Rat Ventral Striatum: Immunohistochemical Detection of Retrogradely Transported Fluoro-Gold




J
S
Brog






A
Salyapongse






A
Y
Deutch






D
S
Zahm








Journal of Comparative Neurology




338
















Gradients of approach and avoidance responses and their relation to level of motivation




J
S
Brown








Journal of Comparative and Physiological Psychology




41
















Auto-shaping of the pigeon's key-peck




P
L
Brown






H
M
Jenkins








J Exp Anal Behav




11
















Resistance to punishment and extinction following training with shock or nonreinforcement




R
T
Brown






A
R
Wagner








Journal of Experimental Psychology




68
















Amygdala inputs to prefrontal cortex guide behavior amid conflicting cues of reward and punishment




A
Burgos-Robles






E
Y
Kimchi






E
M
Izadmehr






M
J
Porzenheim






W
A
Ramos-Guasp






E
H
Nieh






A
C
Felix-Ortiz






P
Namburi






C
A
Leppla






K
N
Presbrey






K
K
Anandalingam






P
A
Pagan-Rivera






M
Anahtar






A
Beyeler






K
M
Tye








Nat Neurosci




20
















Need-based prioritization of behavior




C
J
Burnett






S
C
Funderburk






J
Navarrete






A
Sabol






J
Liang-Guallpa






T
M
Desrochers






M
J
Krashes












Elife 8








Hunger-Driven Motivational State Competition




C
J
Burnett






C
Li






E
Webber






E
Tsaousidou






S
Y
Xue






J
C
Bruning






M
J
Krashes








Neuron




92
















Central amygdala PKC-delta(+) neurons mediate the influence of multiple anorexigenic signals




H
Cai






W
Haubensak






T
E
Anthony






D
J
Anderson








Nat Neurosci




17
















In vivo imaging identifies temporal signature of D1 and D2 medium spiny neurons in cocaine reward




E
S
Calipari






R
C
Bagot






I
Purushothaman






T
J
Davidson






J
T
Yorgason






C
J
Pena






D
M
Walker






S
T
Pirpinias






K
G
Guise






C
Ramakrishnan






K
Deisseroth






E
J
Nestler






Nestler








Proceedings of the National Academy of Sciences




113
















The paraventricular thalamus is a critical mediator of top-down control of cue-motivated behavior in rats




P
Campus






I
R
Covelo






Y
Kim






A
Parsegian






B
N
Kuhn






S
A
Lopez






J
F
Neumaier






S
M
Ferguson






L
C
Solberg Woods






M
Sarter






S
B
Flagel












Elife 8








Anterior cingulate cortex, error detection, and the online monitoring of performance




C
S
Carter






T
Braver






D
M
Barch






M
Botvinick






D
Noll






J
D
Cohen








Science




280
















Advances in the neurobiological bases for food 'liking' versus 'wanting'




D
C
Castro






K
C
Berridge








Physiology & Behavior




136
















Opioid hedonic hotspot in nucleus accumbens shell: mu, delta, and kappa maps for enhancement of sweetness "liking" and "wanting




D
C
Castro






K
C
Berridge








J Neurosci




34
















Lateral hypothalamus, nucleus accumbens, and ventral pallidum roles in eating and hunger: interactions between homeostatic and reward circuitry




D
C
Castro






S
L
Cole






K
C
Berridge








Front Syst Neurosci




9


90














Orexin in Rostral Hotspot of Nucleus Accumbens Enhances Sucrose 'Liking' and Intake but Scopolamine in Caudal Shell Shifts 'Liking' Toward 'Disgust' and 'Fear'




D
C
Castro






R
A
Terry






K
C
Berridge








Neuropsychopharmacology




41
















Anterior Paraventricular Thalamus to Nucleus Accumbens Projection Is Involved in Feeding Behavior in a Novel Environment




J
Cheng






J
Wang






X
Ma






R
Ullah






Y
Shen






Y.-D
Zhou








Frontiers in Molecular Neuroscience




11
















The role of the paraventricular nucleus of the thalamus in the augmentation of heroin seeking induced by chronic food restriction




A
Chisholm






J
Iannuzzi






D
Rizzo






N
Gonzalez






E
Fortin






A
Bumbu






Batallan






A
A
Burrowes






C
A
Chapman






U
Shalev








Addict Biol










in press








The role of orexin-A in food motivation, reward-based feeding behavior and food-induced neuronal activation in rats




D
L
Choi






J
F
Davis






M
E
Fitzgerald






S
C
Benoit








Neuroscience




167
















Orexin signaling in the paraventricular thalamic nucleus modulates mesolimbic dopamine and hedonic feeding in the rat




D
L
Choi






J
F
Davis






I
J
Magrisso






M
E
Fitzgerald






J
W
Lipton






S
C
Benoit








Neuroscience




210
















Paraventricular thalamus controls behavior during motivational conflict




E
A
Choi






P
Jean-Richard-Dit-Bressel






C
W G
Clifford






G
P
Mcnally








J Neurosci




39
















Paraventricular Thalamus Balances Danger and Reward




E
A
Choi






G
P
Mcnally








J Neurosci




37
















Amygdala regulates risk of predation in rats foraging in a dynamic fear environment




J
S
Choi






J
J
Kim








Proc Natl Acad Sci U S A




107
















Encoding of conditioned fear in central amygdala inhibitory circuits




S
Ciocchi






C
Herry






F
C
Grenier






S
B E
Wolff






J
J
Letzkus






I
Vlachos






I
Ehrlich






A
Lüthi








Nature




468
















Autoshaping in the rat: The effects of localizable visual and auditory signals for food




G
G
Cleland






G
C L
Davey








Journal of the Experimental Analysis of Behavior




40
















Looming animate and inanimate threats: The response of the amygdala and periaqueductal gray




D
S
Coker-Appiah






S
F
White






R
Clanton






J
Yang






A
Martin






R
J R
Blair








Social Neuroscience




8
















Limbic thalamus and state-dependent behavior: The paraventricular nucleus of the thalamic midline as a node in circadian timing and sleep/wake-regulatory networks




V
Colavito






C
Tesoriero






A
T
Wirtu






G
Grassi-Zucconi






M
Bentivoglio








Neuroscience and Biobehavioral Reviews




54
















Double dissociation of basolateral and central amygdala lesions on the general and outcome-specific forms of pavlovian-instrumental transfer




L
H
Corbit






B
W
Balleine








J Neurosci




25
















Learning and Motivational Processes Contributing to Pavlovian-Instrumental Transfer and Their Neural Bases: Dopamine and Beyond




L
H
Corbit






B
W
Balleine








Curr Top Behav Neurosci




27
















General and outcome-specific forms of Pavlovianinstrumental transfer: the effect of shifts in motivational state and inactivation of the ventral tegmental area




L
H
Corbit






P
H
Janak






B
W
Balleine








Eur J Neurosci




26
















The role of the nucleus accumbens in instrumental conditioning: Evidence of a functional dissociation between accumbens core and shell




L
H
Corbit






J
L
Muir






B
W
Balleine








J Neurosci




21
















Reinforcement sensitivity theory and personality




P
J
Corr








Neurosci Biobehav Rev




28
















Approach and Avoidance Behavior: Multiple Systems and their Interactions




P
J
Corr








Emotion Review




5
















Neuroscience and approach/avoidance personality traits: A two stage (valuation-motivation) approach




P
J
Corr






N
Mcnaughton








Neuroscience and Biobehavioral Reviews




36
















Role of Nucleus Accumbens Shell Neuronal Ensembles in Context-Induced Reinstatement of Cocaine-Seeking




F
C
Cruz






K
R
Babin






R
M
Leao






E
M
Goldart






J
M
Bossert






Y
Shaham






B
T
Hope








J Neurosci




34
















Learning to escape cues paired with reward reductions following single-or multiplepellet rewards




H
B
Daly








Psycho"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]