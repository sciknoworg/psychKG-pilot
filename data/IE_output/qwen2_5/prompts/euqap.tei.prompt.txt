You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



poor complainant credibility is associated with case attrition in the criminal justice system, preventing complainant distress from influencing credibility judgments should be a research and policy priority.
A meta-analysis of the emotional victim effect for female adult rape complainants: Does distress influence credibility?
On average, 9% of rape allegations made to police in the United States, Europe, and Australia proceed to trial 
(Alderden & Ullman, 2012;
Daly & Balhours, 2010;
Jehle, 2012)
.
In up to 88% of rape cases, the defendant and complainant know each other (acquaintance rape; Australian Bureau of Statistics 
[ABS], 2017;
Flatley, 2018;
Smith et al., 2017)
 and the complainant's testimony about consent is critical 
(Quadara, Fileborn & Parkinson, 2013)
. If the complainant is not perceived to be credible, these cases do not progress through the criminal justice system 
(Brown, Hamilton & O'Neill, 2007;
O'Neal, 2017)
. Distressed complainants are perceived to be more credible than complainants who show other emotions (called the emotional victim effect or EVE; 
Ask & Landström, 2010)
. In this review and meta-analysis of the emotional victim effect, we focus on judgments about female adult rape complainants' credibility, as the majority of reported rape offenses are committed by men against women (e.g., 
Hohl & Stanko, 2015)
.


Complainant Credibility and Case Progression
For a rape case to proceed to trial, there are several phases in the criminal justice system the case must pass through. Attrition occurs at all stages (e.g., 
Cox, 2015;
Jehle, 2012)
. First, the complainant must report the alleged offense to police. The police must investigate the case and choose to charge the alleged offender. The prosecutor's office then must decide to proceed with the case. Finally, a jury and judge hear the trial and make a judgment about the defendant's guilt. If the complainant is deemed credible, the case is more likely to proceed at any of these steps. Complainants who think they will not be believed do not report to authorities (e.g., 
Stern Review, 2010)
. Police officers are more likely to recommend investigating and prosecuting cases 
(Ask, 2010;
Alderden & Ullman, 2012;
Brown et al., 2007;
Kerstetter, 1990;
Morabito, Pattavina & Williams, 2016;
Tasca, Rodriguez, Spohn & Koss, 2013)
, prosecutors are more likely to proceed to trial 
(Frohmann, 1991;
Lievore, 2005;
Spohn & Tellis, 2012)
, and jurors are more likely to convict the defendant (e.g., 
Ellison & Munro, 2009)
 when the complainant is deemed credible. This means it is critical that credibility judgments are made without prejudice.


Judging Complainant Credibility
Perceivers, whether they be police officers, judges or jurors, must form an impression of a rape complainant to judge credibility. The Heuristic-Systematic Model (HSM; 
Chaiken, 1980;
Chaiken & Ledgerwood, 2012;
Chaiken, Liberman & Eagly, 1989
) is a dual process explanation of persuasion that is often used to describe the processing of social information (e.g., 
Reinhard & Sporer, 2010;
Todorov, Chaiken & Henderson, 2002)
. The model suggests that observers may use two information processing styles to judge the credibility of a rape complainant. If observers use systematic processing, then a careful consideration of the available information is undertaken to determine the relevant information to judge credibility 
(Chaiken & Maheswaran, 1994)
. Perceivers must be more motivated and cognitively capable to engage in systematic processing. In heuristic processing, a pre-existing cognitive structure (e.g., stereotype or schema) is used to guide information processing. Heuristic processing is less effortful, and often used by less motivated perceivers, but still requires some cognitive capacity 
(Chen & Chaiken, 1999)
.
Unlike other dual process persuasion models (for example, the Elaboration Likelihood Model; 
Petty & Cacioppo, 1986)
 which assume that perceivers use one style of information processing to make a judgment, the HSM proposes that perceivers can use both heuristic and systematic processing to evaluate information. The level of information processing used by the perceiver to make a judgment depends on the level of confidence the perceiver needs to make this judgment (called the sufficiency threshold). Perceivers will continue to engage in information processing until they reach their sufficiency threshold-if heuristic processing does not produce a judgment the perceiver is confident in then systematic processing will be used until a judgment the perceiver is confident in is made. In rape cases, perceivers are either criminal justice professionals who are motivated to perform their role competently and to assist the community (e.g., 
Raganella & White, 2004;
White, Cooper, Saunders, & Raganella, 2010)
, or community members acting as jurors who aim to make an accurate decision (e.g., 
Thomas, 2010)
.
For motivated perceivers, two predicted ways that heuristic and systematic processing can interact to influence the credibility judgment made are the attenuation and bias hypotheses 
(Chaiken & Maheswaran, 1994)
. Under the attenuation hypothesis, if the judgment arising from initial heuristic processing is at odds with the judgment arising from subsequent systematic processing, then the decision made through systematic processing will override the conclusion from heuristic processing 
(Maheswaran, Mackie & Chaiken, 1992)
.
If attenuation occurs, systematic processing is curative against the biasing effect of heuristics in judgments made by highly motivated perceivers. In contrast, under the bias hypothesis, when the evidence on which the judgment must be made is ambiguous, then the Heuristic-Systematic Model suggests that heuristics can influence subsequent information processing even for highly motivated perceivers (called biased systematic information processing). If bias occurs, then systematic processing does not overcome the influence of heuristics on judgments made by highly motivated perceivers 
(Chen & Chaiken, 1999)
. When bias occurs, the influence of the heuristic can only be reduced if the heuristic is challenged by other evidence considered in systematic processing.
Studies of credibility judgments made of people in everyday social situations (i.e., when subletting an apartment or cancelling a date) show support for the operation of the attenuation hypothesis for motivated perceivers (e.g., 
Reinhard, 2010;
Reinhard & Sporer, 2008;
. Highly motivated perceivers rely on the content of messages provided by the person rather than characteristics about the person to judge that individual's credibility compared to perceivers with low motivation 
(Reinhard & Sporer, 2008;
Reinhard & Sporer, 2010)
. Perceivers who engage in systematic processing provide more reasons for their credibility judgment which focus on the content of the person's statement rather than heuristic cues about the person 
(Reinhard & Sporer, 2008)
. Together, this suggests that subsequent systematic processing, in which the content of statements made by the person are considered carefully, is overcoming the effect of heuristic cues about the person in credibility judgments made about the person (i.e., the attenuation hypothesis). There is some evidence that the attenuation hypothesis may explain information processing for perceivers in rape cases. 
Ask and Landström (2010)
 found that a heuristic cue about the complainant's credibility (i.e., emotional demeanor) influenced judgments about credibility when perceivers were under cognitive load (and likely to engage in heuristic processing), whereas perceivers not under cognitive load (and likely to use systematic processing) were not influenced by the heuristic cue in their credibility judgments.
However, unlike the scenarios used in studies of everyday credibility judgments, rape cases are frequently highly ambiguous, as they commonly involve the complainant's testimony without strong corroborative evidence (e.g., conclusive medical evidence or thirdparty eye-witness testimony; 
Quadara et al., 2013)
. This message ambiguity means that, from a Heuristic-Systematic Model perspective, the bias hypothesis likely explains how motivated perceivers process information to make credibility judgments about rape complainants. If biased information processing occurs for perceivers to make credibility judgments about rape complainants, heuristic cues about the complainant will shape systematic processing of evidence to judge complainant credibility, regardless of the perceiver's motivation 
(Chaiken & Ledgerwood, 2012;
Todorov et al., 2002)
. 
Chaiken and Maheswaran (1994)
 found that highly motivated perceivers who were exposed to an ambiguous message engaged in systematic processing that was biased by the heuristic cue about the person delivering the message. When perceivers viewed a positive heuristic cue about the person delivering the message, subsequent systematic processing focused on the positive persuasive arguments made in the message 
(and vice versa)
. Although 
Ask and Landström (2010)
 found some evidence in support of the attenuation hypotheses in judgments made in rape cases, they did not measure case ambiguity. It is therefore possible that the rape case presented in that study was not viewed as ambiguous by perceivers and thus the conditions to trigger biased systematic information processing were not present. The bias hypothesis suggests that heuristic cues about rape complainants could have an impact on credibility judgments, regardless of perceiver motivation.


Heuristics About Rape Complainants
There are several aspects of complainant behavior that influence the judgments perceivers make about rape complainants and may operate as heuristic cues within information processing. Endorsement of mistaken beliefs about rape events (called rape myths; 
Hockett, Smith, Klausing & Saucier, 2016;
Lonsway & Fitzgerald, 1994)
, the extent to which the assault events match with schemas for rape 
(McKimmie, Masser, Nitschke, Schuller & Goodman-Delahunty, 2018a;
Smith, 1991;
1993)
, and the extent to which the victim conforms with stereotypes about rape complainants (e.g., 
Angelone, Mitchell & Grossi, 2015;
Schuller & Hastings, 2002)
 all affect how rape complainants are judged.
Perceiver attributes, like gender, also influence evaluations of rape complainants.
Men and women tend to evaluate rape complainants differently 
(Anderson, Cooper & Okamura, 1997)
. In general, men tend to have more permissive attitudes towards rape and evaluate rape complainants more negatively than do women (e.g., 
Kleinke & Meyer, 1990;
Newcombe, van der Eynde, Hafner & Jolly, 2008)
. Two meta-analytic reviews of rape myth endorsement suggest that men have greater endorsement of rape myths than women 
(Anderson et al., 1997;
Suarez & Gadalla, 2010)
. In addition, several narrative reviews suggest that men perceive rape complainants to be more to blame for their assault than women (e.g., 
Grubb & Harrower, 2008;
Grubb & Turner, 2012;
van der Bruggen & Grubb, 2014)
. In contrast, a recent review of acquaintance rape literature suggests that the effect of perceiver gender on judgments of victim blame is mixed 
(Gravelin, Biernat & Bucher, 2019)
.
However, as perceiver gender is a natural confound, there is no way to tell if the differences observed are due to perceiver gender or differences between men and women in attitudes or other cognitive structures 
(Kite & Whitley, 2018)
. For example, there is evidence that attitudes towards sexual behavior in romantic relationships mediates the relationship between perceiver gender and judgments that the complainant of an acquaintance sexual assault was to blame for the assault 
(Lynch, Jewell, Wasarhaley, Golding, & Renzetti, 2017)
.
Perceivers might rely on several heuristic cues to assess the complainant's credibility.
These include rape myths, rape schemas or scripts, and the rape victim stereotype. Rape myths are factually inaccurate and include beliefs like "false accusations of rape are common" or "women say no to sex when they really mean yes" (i.e., women exhibit 'token' resistance). As perceivers' endorsement of rape myths increases, rape victims are evaluated more negatively 
(Süssenbach, Bohner & Eyssel, 2012;
Süssenbach, Eyssel & Bohner, 2013)
.
The more an alleged assault conforms to rape myths, the more likely it is perceived as a legitimate assault and the victim is evaluated positively 
(Süssenbach, Albrecht & Bohner, 2017;
Süssenbach, Eyssel, Rees & Bohner, 2017)
. Perceivers who endorse rape myths also tend to see complainants as less credible 
(Bohner & Schapansky, 2018;
Nitschke, Masser, McKimmie & Riachi, 2018)
. Some authors suggest that this means that rape myths are a schema used to make decisions about the legitimacy of a rape allegation 
(Eyssel & Bohner, 2011;
Krahé, 2016)
.
Perceivers' expectations for how rape typically occurs also form schemas that are used to evaluate complainants (e.g., 
Carroll & Clark, 2006;
Littleton & Axsom, 2003
, Littleton, Tabernik, Canales & Backstrom, 2009
. Perceivers typically expect the complainant and perpetrator to be strangers and for the perpetrator to use force to subdue the complainant (e.g., 
Littleton & Axsom, 2003)
. Complainants who are assaulted by a stranger tend to be evaluated more positively by perceivers (e.g., 
Abrams, Viki, Masser & Bohner, 2003;
Bieneck & Krahé, 2011;
Bridges & McGrail, 1989;
Krahé, Temkin & Bieneck, 2007)
.
Perceivers also use the rape victim stereotype to judge the complainant. Perceivers typically expect complainants to vigorously physically and verbally resist the perpetrator, be sober, and report immediately to authorities in a distressed state 
(Carroll & Clark, 2006;
Littleton & Axsom, 2003)
. When complainants do not behave as expected, they tend to be blamed for the assault (e.g., 
Davies, Rogers & Whitelegg, 2009;
Masser, Lee & McKimmie, 2010
) and judged less credible (e.g., 
Angelone, Mitchell & Grossi, 2015
, McKimmie, Masser & Bongiorno, 2014
Schuller & Hastings, 2002)
.
The complainant's emotional demeanor strongly influences credibility judgments 
(Kaufmann, Drevland, Wessel, Overskeid & Magnussen, 2003)
. Perceivers tend to expect rape complainants to experience negative emotions that are much stronger than those experienced by other victims of crime 
(Wrede & Ask, 2015)
. Emotional demeanor also influences perceptions of the complainant's typicality as a rape victim 
(Schuller, McKimmie, Masser & Klippenstine, 2010)
, perhaps indicating demeanor is part of the rape victim stereotype or a schema for rape events. Regardless of whether complainant emotional demeanor is a unique heuristic cue, or part of a rape victim stereotype or rape schema, the bias hypothesis 
(Chaiken, 1980)
 suggests that perceivers may use complainant emotional demeanor to form an impression of the complainant and judge credibility.


Distressed Demeanor and Credibility
A typical study investigating the effect of complainant emotional demeanor on credibility employs an experimental design and a simulated decision-making paradigm. In this paradigm, participants are presented with complainant evidence about an alleged rape event. The complainant (an actress) portrays an emotional state, most frequently distress or controlled affect (e.g., 
Kaufmann et al., 2003;
Klippenstine & Schuller, 2012)
 via a video or written evidence synopsis. Participants make credibility judgments using a questionnaire (e.g., 
Ask & Landström, 2010;
Hackett, Day & Mohr, 2008)
. Studies have reported that complainants who appear distressed (i.e., upset, crying) are perceived to be more credible than their emotionally 'flat' or 'controlled' counterparts 
(Schuller et al., 2010)
. Mock jurors' 
(Peace & Valois, 2014)
, community members' 
(Calhoun, Cann, Selby & Magee, 1981)
 and police officers' 
(Ask & Landström, 2010;
Baldry, 1996)
 judgments of complainant credibility all show this effect.
Several moderators, including perceiver gender and the rape victim stereotype, have been investigated in studies on the effect of complainant emotional demeanor (e.g., 
Peace & Valois, 2014;
Schuller et al., 2010)
. Most studies suggest that perceiver gender has no unique effect on complainant credibility judgments and does not interact with the effect of complainant emotional demeanor on credibility 
(Bollingmo et al., 2007;
Calhoun et al., 1981;
Kaufmann et al., 2003;
Klippenstine, 2010;
Schuller et al., 2010;
Wessel et al., 2006)
.
One study 
(Bohner & Schapansky, 2018)
 found perceiver gender interacted with complainant emotional demeanor to influence credibility judgments. Women high in rape myth endorsement judged distressed complainants as more credible. Women low in rape myth endorsement found the complainant credible irrespective of her emotional demeanor. Men showed no difference in credibility judgments as a function of rape myth endorsement or complainant emotional demeanor. Collectively, perceiver gender does not seem to influence the impact of complainant emotional demeanor on credibility.
Stereotypes about rape victims have also been investigated in studies of complainant emotional demeanor. 
Kaufmann et al. (2003)
 found no effect of strong or weak testimony (manipulated by presence or absence of complainant resistance and perpetrator force during the assault) on judgments of complainant credibility. In contrast, 
Schuller et al. (2010)
 found that when the complainant physically resisted the perpetrator, she was evaluated as more credible than when she only verbally resisted. The complainant's stereotypicality did not interact with the effect of complainant emotional demeanor on credibility in either study.
However, 
Hackett et al. (2008)
 found perceivers who expected rape complainants to become distressed evaluated the distressed complainant as more credible than the neutral complainant. Perceivers who had no expectations about the emotions that complainants should show were not influenced by the complainant's emotional state. Complainant emotional demeanor may operate as one of several heuristic cues available for judging credibility. But should perceivers use distress as a cue to judge complainant credibility accurately?


Emotional Demeanor as a Credibility Cue
Credibility judgments should be about whether the witness is honest and reliable (e.g., in 
Australia and Canada;
Reymond v Township of Bosanquet, 1919;
White v R, 1947)
.
However, emotions (including distress) do not accurately indicate that witnesses are telling the truth 
(Bond & DePaulo, 2006;
DePaulo et al., 2003)
. Perceivers are no more accurate at detecting deception when witnesses display strong emotion compared to when no strong emotion is shown 
(Hartwig & Bond, 2014)
. Rape complainants are also equally likely to appear distressed or with controlled affect 
(Burgess & Carretta, 2016;
Burgess & Holmstrom, 1974;
Caretta & Burgess, 2013)
. Complainants experience post-traumatic stress disorder (PTSD) and depression at high rates 
(Norris & Krysztof, 1994;
Snipes, Calton, Green, Perrin & Benotsch, 2017;
) and often suppress emotion to manage their trauma 
(Burgess & Holmstrom, 1986;
Maddox, Lee & Barker, 2011;
Maddox, Lee & Barker, 2012)
. This means many rape complainants may be unfairly judged as not credible due to their emotional demeanor when giving evidence.
Given that complainant emotional demeanor can adversely affect credibility judgments by criminal justice professionals and jurors, it is critical that we understand the extent and robustness of this effect. We undertook a meta-analytic review of the simulated decision-making literature to investigate this. In our review, we focused on studies comparing distressed and neutral expressions of emotional demeanor by complainants, as these two conditions were used in the majority of EVE studies and these emotions are commonly experienced by rape complainants while giving evidence (e.g., 
Konradi, 1999;
. We explored two potential moderators that may influence the extent to which complainant emotional demeanor influences credibility judgments -stimulus modality and sample typewhich also assess the ecological and external validity of the effect. We used p-curve analysis to determine whether the significant effects in this literature can be explained by selective reporting (e.g., publication bias or p-hacking).


Evidence Stimulus Format
Video and written complainant evidence have been used to investigate the effect of complainant emotional demeanor on credibility judgments (e.g., 
Kaufmann et al., 2003;
Peace & Valois, 2014)
. If perceivers undertake biased systematic information processing to judge complainant credibility, then motivation to engage in information processing will not substantially influence whether complainant emotional demeanor is used to judge credibility 
(Chen & Chaiken, 1999)
. However, stimuli modality may still influence the extent to which complainant emotion influences credibility judgments by increasing the salience and accessibility of complainant emotional demeanor as a heuristic cue. Perceivers evaluate accessible heuristic cues to be more reliable, which increases how relevant the heuristic cue appears to make the judgment 
(Chen & Chaiken, 1999)
. If a heuristic cue like complainant emotional demeanor is viewed as more relevant to judge credibility, then it is unlikely to be challenged in biased systematic processing and will have an effect on credibility judgments.
This means complainant emotional demeanor may have a larger effect on credibility judgments when the modality of complainant evidence makes complainant emotional demeanor more salient. 
Chaiken and Eagly (1983)
 argued that characteristics of the speaker are more salient in video messages, so it is possible that complainant emotional demeanor has a larger impact on credibility judgments when video complainant evidence is presented.
Perceivers typically struggle to differentiate negatively valenced emotions, but video stimulus improves emotion recognition. Sadness is accurately identified around half the time 
(Gitter, Kozel & Mostofsky, 1972)
 and has moderate cross-cultural recognition 
(Elfenbein & Ambady, 2002)
. Police trainees rated distressed rape complainants as experiencing significantly more sadness but also more anger, fear, and disgust 
(Ask & Landström, 2010)
.
Sadness is most accurately recognized when video of the target is provided 
(Gitter et al., 1972)
. Given that angry complainants are sometimes viewed as less credible than distressed complainants (e.g., Bohner & Schapansky, 2018 cf. 
Vrij & Fischer, 1997)
, it is possible that the influence of distress on credibility judgments would be larger when distress is readily recognized (i.e., in studies using video rather than written complainant evidence).
However, complainant emotional demeanor may be more salient in written complainant evidence. In written and spoken communication, perceivers expect others to provide as much information as needed to convey their point and for information to be truthful and relevant (conversational norms or maxims of quantity, quality, and relation; 
Grice, 1975)
. Studies on person perception suggest that perceivers may infer information provided about a target is relevant to form an impression of the target, not because of preexisting heuristics, but because relevance is inferred from conversational norms 
(Kahneman & Tversky, 1973;
Schwarz, Strack, Hilton & Naderer, 1991)
. It is possible complainant emotional demeanor is used to make credibility judgments because the presence of the information in the written experimental synopsis implies, under conversation norms, that this information is relevant and reliable 
(Bless, Strack, & Schwarz, 1993)
. Obvious experimental manipulations can make participants more susceptible to demand characteristics -where participants guess at the study hypotheses and respond accordingly 
(Goodwin & Goodwin, 2013;
Haslam & McGarty, 2008;
Kite & Whitley, 2018)
. If the relevance of complainant emotional demeanor to judge credibility is increased in written complainant evidence, and perceivers use biased systematic information processing, the effect of complainant emotional demeanor on credibility could be larger than when video complainant evidence is presented.
However, perceivers who read complainant evidence have the opportunity to review the evidence as needed, which may facilitate critical systematic information processing and lessen the effect of complainant emotional demeanor as a heuristic cue by providing perceivers an opportunity to challenge emotion as a heuristic cue in systematic processing. This may lessen the effect of complainant emotional demeanor on credibility judgments when biased systematic information processing takes place. Perceivers have higher comprehension of written messages compared to video messages 
(Chaiken & Eagly, 1976)
 and also focus more on message content in their information processing 
(Chaiken & Eagly, 1983
). Perceivers who review notes taken during video messages rely less on heuristic cues to make judgments than perceivers who did not review or take notes during the video message 
(Strub & McKimmie, 2012)
.
Given the variety of explanations about the effect of stimulus modality on the salience of complainant emotional demeanor, it is unclear whether stimulus modality influences the emotional victim effect. To our knowledge, no experimental study has directly examined this.
In rape cases, police officers, lawyers, judges, and jurors experience the complainant's emotional demeanor in person during the investigation and trial proceedings 
(Maddox et al., 2012;
 over hours or even days (e.g., 
Konradi, 2007)
. This means written complainant evidence used in experiments lacks ecological validity 
(Kerr, 2017)
, so examining the effect of stimuli modality also permits an investigation of whether more ecologically valid experimental stimuli (video complainant evidence) influences the emotional victim effect. We therefore investigated the effect of stimulus modality, whether observers read about or saw the complainant, as a moderator in this meta-analysis.


Sample Type
Another potential moderator of the emotional victim effect is the type of perceiver making the credibility judgment about the complainant. Criminal justice professionals (e.g., judges, police officers) and trainees (e.g., police trainees, law students) and community members have participated in studies exploring the effect of complainant emotional demeanor on credibility judgments 
(Hackett et al., 2008;
Wessel et al., 2006)
. Decisions about complainant credibility made by police officers and prosecutors are associated with rape case attrition (e.g., 
Spohn & Tellis, 2012;
Tasca et al., 2013)
, so understanding whether criminal justice professionals are influenced by complainant emotional demeanor in these decisions is critical to understanding how emotional demeanor may be contributing to rape case attrition in the criminal justice system. As such, many researchers have called for further investigation of how criminal justice professionals may differ to lay perceivers in their decision-making about rape complainant credibility (e.g., 
Ask, 2010;
Wessel et al., 2006)
. Some criminal justice professionals and scholars assume that experience and training which judges, lawyers, and police officers receive or training which police trainees or law students receive equips them to make more accurate decisions in cases than jurors or community members (e.g., 
Kahan, 2015
cf. Lidén, Gräns & Juslin, 2018
. Judges often write about how they believe jurors are easily influenced by bias and their emotions (e.g., 
Edwards, 1984;
Hans & Vidmar, 1986)
 and prosecutors often raise jurors' beliefs in victim stereotypes as an impediment to prosecution in rape cases but not necessarily an issue in their own decision-making 
(Bluett-Boyd & Fileborn, 2014;
Temkin, 2000;
.
Similarly, police officers raise jurors' doubts about the complainant's credibility as barriers to convictions in rape trials but maintain that many aspects of the victim stereotype do not influence their own decision-making (e.g., 
Venema, 2013
).
If perceivers engage in biased systematic information processing to decide complainant credibility, then professional training or experience may have a limited impact on whether complainant emotion influences credibility judgments. Factors that may modify criminal justice professionals' motivation to engage in information processing relative to lay perceivers, like feeling more accountable for decisions made (e.g., 
Lerner & Tetlock, 1999;
Ashton, 1992)
, will have a limited effect on how complainant emotional demeanor influences information processing to judge credibility. However, training or experience may encourage criminal justice professionals to challenge the heuristic cue of complainant emotional demeanor with other information during information processing, which would lessen the effect of complainant demeanor on judgments of complainant credibility through biased systematic information processing.
Knowledge and expertise have been identified as cognitive resource factors which modify the nature of information processing within the Heuristic-Systematic Model 
(Todorov et al., 2002)
. Research suggests that familiarity (or knowledge) of the decision context leads perceivers to focus on more complex information presented in the content of messages to judge the credibility of people in every day social situations 
(Reinhard, Scharmach, & Sporer, 2012)
 and to more accurately discriminate between deceptive and honest accounts of an event 
(Reinhard, Sporer, Scharmach, & Marksteiner, 2011)
. Expert decision-makers are able to integrate complex and conflicting information, and attend to relevant information to make judgments more ably than lay perceivers (e.g., Bédard & Chi, 1992; 
Kahneman & Klein, 2009;
Nee & Ward, 2015;
Shanteau, 1992)
, which may allow them to challenge heuristic cues that are influencing systematic processing. Some evidence suggests that criminal justice professionals are more open to dealing with conflicting or complex information. For example, experienced police officers create a greater number of alternative hypotheses and engage in a wider range of investigative actions than novice police officers 
(Fahsing & Ask, 2016)
. However, other studies have found that experienced police officers make fewer alternative hypotheses than lay perceivers in simulated criminal cases 
(Ask & Granhag, 2005)
. Specialized training programs have been found to reduce the extent to which the victim stereotype influences rape case judgments by police officers 
(Ask, 2010;
Darwinkel, Power & Tidmarsh, 2013)
. It is possible that professional training or experience may lessen the effect that complainant emotional demeanor has on credibility judgments.
However, if a heuristic cue is seen as relevant to deciding complainant credibility then it is unlikely it will be challenged within biased systematic information processing. Aspects of the victim stereotype influence criminal justice professionals' judgments of rape complainants. Advanced law students and probationary lawyers evaluate rape complainants who do not match the rape victim stereotype more negatively (e.g., 
Krahé, Temkin, Bieneck & Berger, 2008;
. Barristers and judges are influenced by the rape victim stereotype and rape myths in their court practice (e.g., 
Feldman-Summers & Palmer, 1980;
Gray & Horvath, 2018;
Sleath & Bull, 2015;
Temkin, 2000;
Temkin, Gray & Barrett, 2018)
. Time spent as a police officer, or investigating sexual assault, does not consistently improve judgments of rape complainants including credibility 
(Goodman-Delahunty & Graham, 2011;
Sleath & Bull, 2012;
Wentz & Archbold, 2012
cf. Campbell, 1995
Page, 2007)
. Critically, nearly three-quarters of prosecutors and police officers surveyed agreed (in part or more strongly) that a rape complainant's emotional demeanor was a valid indicator of whether the complainant was being honest 
(Ask, 2010)
. If criminal justice professionals see complainant emotional demeanor as relevant to judge credibility, it is likely it could be relied on and bias systematic information processing. This means it is possible that professional training or expertise may not lessen the effect that complainant emotional demeanor has on credibility judgments.
Given that it is unclear what the effect of professional training or expertise may be on the use of complainant emotional demeanor in judging credibility, we explored sample type as a moderator of the effect of complainant emotion on credibility judgments. The inclusion of sample type as a moderator also allowed us to examine how well the emotional victim effect generalizes across samples 
(Krauss & Lieberman, 2017)
. This addresses an important practical question about whether complainant emotional demeanor, by biasing complainant credibility judgments, is one explanation for rape case attrition across the criminal justice system.


Validity and Reliability of Meta-Analytic Estimates
In a meta-analysis, it is critical to consider whether study validity may cause an effect to be over-or underestimated 
Lakens, Hilgard & Staaks, 2016)
.
By examining whether the stimulus format moderates the effect-size estimate, we can also assess how accurately the experimental paradigm captures the real-life context of the effect of complainant emotional demeanor on credibility (sometimes referred to as ecological validity; 
Kerr, 2017)
. Similarly, we can examine a specific aspect of the external validity -whether the results will generalize to other populations -by exploring sample type as a moderator 
(Krauss & Lieberman, 2017)
.
It is also important to carefully scrutinize internal validity of the studies included in a meta-analysis. An internally valid study uses an adequate method to answer the research question proposed , but biased experimental methodology can threaten this 
(Haslam & McGarty, 2008)
. For example, if study participants systematically differ across conditions (selection bias) this may be a viable alternative explanation for the results 
Kite & Whitley, 2018)
. Performance bias (whether the independent variable was effectively manipulated), detection bias (whether the dependent variable was appropriately sensitive and reliable), and reporting bias (whether the results were selectively reported for publication) also threaten study internal validity 
(Bornstein, 2017;
Kite & Whitley, 2018;
Reeves, Deeks, Higgins & Wells, 2008)
.
The effect of reporting and publication bias on the effect size estimate is of particular concern in meta-analyses, as such analyses rely substantially on published literature to estimate the overall effect size. Even when meta-analysts make efforts to access unpublished literature, the total number of unpublished studies available to include in the analysis can remain small (e.g., 
Bornstein et al., 2017;
Paluck, Green & Green, 2017)
. The published literature tends to over-represent statistically significant findings (e.g., 
Rotton, Foos, Van Meek & Levitt, 1995)
, which in turn can inflate the effect size estimates calculated through meta-analysis 
(Kotiaho & Tomkins, 2002)
.
Some common research practices 
(John, Lowenstein & Prelec, 2012)
, particularly flexibility in data analysis strategies (p-hacking or unconscious analytic tuning; 
Chambers, 2017;
Simmons, Nelson & Simonsohn, 2011)
 and hypothesizing after results are known (HARKing; 
Chambers, 2017;
van Assen, van Aert, Nuijten & Wicherts, 2014)
, might be inflating statistical error rates in the published literature. There may be substantial numbers of false positives in the published literature in psychology and other scientific disciplines 
(Simonsohn, Nelson & Simmons, 2014a;
Simonsohn, Nelson & Simmons, 2014b)
. A metaanalytic effect size estimate based on literature which reports inflated or false positive effects will yield an artificially inflated effect size estimate 
(Lakens et al., 2016)
.
To assess whether publication bias or problematic research practices might influence the findings of this meta-analysis, we conducted a p-curve analysis of the included studies. Pcurve analysis is a diagnostic test of the evidential value of a set of studies 
(Simonsohn et al., 2014a
) that suggests whether selective reporting (via publication bias or p-hacking) is a viable explanation for statistically significant results. P-curve analysis more comprehensively assesses reporting bias than other publication bias assessment methods for meta-analysis.


Aims and Hypotheses
To our knowledge, this is the first meta-analytic review of the effect of female adult rape complainant emotional demeanor on credibility judgments. Our first aim for this metaanalysis, p-curve analysis, and review was to investigate the direction, size, and robustness of the effect. Our second aim was to investigate stimulus modality and sample type as moderators of this effect. We had three hypotheses:
Hypothesis 1 (H1): We expected there would be a significant and positive aggregate effect size for the emotional victim effect, such that a distressed female adult complainant of rape would be perceived as more credible than her emotionally controlled counterpart.
We hypothesized this based on the Heuristic-Systematic Model 
(Chaiken, 1980)
, which suggests that when evidence is ambiguous possible heuristic cues, like complainant emotional demeanor, influence systematic information processing regardless of the perceiver's motivation to engage in information processing (i.e., the bias hypothesis or biased systematic information processing; 
Chaiken & Maheswaran, 1994;
Chen & Chaiken, 1999)
.


Hypothesis 2 (H2):
We expected the effect of complainant emotional demeanor on credibility judgments to be greater when perceivers had viewed video complainant evidence compared to when they had read an evidence synopsis.
We hypothesized this on evidence which suggests that visual displays of emotion are more salient 
(Gitter et al., 1972)
, which may make complainant emotional demeanor more relevant as a heuristic cue to judge complainant credibility 
(Chen & Chaiken, 1999)
. If complainant emotional demeanor is seen as relevant to judging credibility, then it may have larger effect within biased systematic information processing and on credibility judgments 
(Chaiken & Maheswaran, 1994)
.


Hypothesis 3 (H3):
We expected the effect of complainant emotional demeanor on credibility judgments would be less when perceivers had relevant training or experience in the criminal justice system (i.e. police officers, police trainees, law students, judges) compared to when perceivers had no relevant training or experience judging credibility (i.e. mock jurors and community members).
We hypothesized this based on research that suggests that familiarity with the decision context, which professional training or experience may provide, facilitates engaging with more complex and conflicting information within systematic information processing 
(Reinhard et al., 2011;
2012)
. Challenging the relevance of complainant emotional demeanor to judge credibility within systematic processing may lessen the effect of complainant emotion within biased systematic information processing.


Unregistered and Exploratory Analyses
While executing this review, we decided to conduct some additional tests of publication bias, a study quality assessment, and exploratory content analyses to examine the internal validity of included studies in the meta-analysis.
Additional analyses of publication bias. All methods used to detect publication bias have limitations (e.g., 
Bruns & Ioannidis, 2016;
Stanley, 2017)
. In addition to the p-curve analysis, which was pre-registered as part of our analytic strategy, we decided to conduct some additional tests of publication bias. This allowed us to assess the cumulative evidence of the impact of publication bias in our review across multiple analytic methods.


Study quality assessment.
To assess the internal validity of included studies we executed an adapted form of the Cochrane Risk of Bias assessment 
(Higgins et al., 2011;
. The Cochrane tool was developed to assess internal validity of randomized controlled trials, so we adapted it for cross-sectional psychology studies. This assessment enabled us to comprehensively evaluate the internal validity of studies included in the review.
Content analysis. Content analysis is a systematic approach to categorizing qualitative data 
(Krippendorff, 2013;
Weber, 1980)
. In the content analyses, we investigated consistency and face validity in manipulations of complainant emotional demeanor and credibility measures in the included studies. This permitted us to make comprehensive suggestions for improvements to simulation methodology based on a systematic evaluation of the methods reported within the literature.


Method
This meta-analysis, including the hypotheses, search protocol, and analysis plan were pre-registered at the Open Science Framework: https://osf.io/9x58r


Eligibility Criteria
To be included in the review, studies met all of the following inclusion criteria:
(1) Reported in English 


Search Strategy
We executed a scoping review to determine whether any reviews or meta-analyses were registered on this topic. A search of the Centre for Reviews and Dissemination (DARE), the Campbell Collaboration, and the International Prospective Register of Systematic Reviews (PROSPERO) was conducted using the key words victim, rape, sexual assault, and jury. We found no registrations that addressed the aims and hypotheses of this review.
To identify eligible articles, systematic searches of the PsycINFO, Scopus, Web of Science, and ProQuest Social Sciences databases were undertaken. To improve the reliability of the effect size estimate, unpublished studies were included in this meta-analysis 
(Lefebvre, Manheimer & Glanville, 2008)
. To identify unpublished literature, electronic searches of the ProQuest Dissertations and Theses and Open Grey databases were completed. All databases were searched using the following keywords in document title, abstract, and subject or index terms: rape OR sexual assault AND credibility OR emotion. The database searches included studies published and indexed before 8 November 2017.
We engaged in additional search techniques to ensure we identified as many eligible reports as possible. We manually searched the reference lists of eligible articles and conducted 'cited by' searches in Web of Science and Google Scholar to find additional eligible articles. We conducted author searches using Google Scholar to search for further eligible publications produced by authors of eligible articles. To access unpublished data, we circulated requests for unpublished data to relevant psychology email listservs, including the Society for Personality and Social Psychology and the Society of Australasian Social Psychologists. We emailed authors of eligible studies, when we were able to find current contact details, and asked them to share any unpublished data or reports that met our eligibility criteria.


Study Selection
In total, 838 potentially eligible records were identified through database searches and additional search techniques. After duplicate search returns were removed using Endnote, the title and abstract of 516 references were screened for potential eligibility. A total of 449 records were excluded through the title and abstract screening process for failure to meet our eligibility criteria. The full text of 65 articles, reports and research dissertations considered potentially eligible were assessed for eligibility against our five criteria. After full-text screening, a final sample of 20 studies were included in the meta-analysis (see 
Figure 1
).


Meta-Analytic Data Extraction
For the meta-analysis and meta-regression, the following information was extracted for each eligible study: sample size, sample type, study design, and stimulus modality.
Means, standard deviations, and number of participants in each condition (cell sizes) were also extracted to calculate effect sizes for the meta-analysis. We extracted means, standard deviations, and cell sizes associated with main effects of complainant emotional demeanor focusing on conditions where the complainant's emotion was neutral or distressed. Several included studies 
(Ask & Landström, 2010;
Bollingmo et al., 2009;
Hackett et al., 2008;
 Klippenstine 
& Schuller, 2012;
Schuller et al., 2010)
 used factorial designs and found interactions between complainant emotional demeanor and other factors on complainant credibility. As there was no parsimony in the additional factors in these studies (e.g., cognitive load, instructions about the use of complainant emotional demeanor, perpetrator speech style), we decided to extract data associated with the main effect of complainant emotional demeanor only (i.e., we did not extract any significant simple effects).
We scrutinized the sample sizes and outcome measures for studies conducted by the same authors to ensure no duplicate reports were included in the meta-analysis. One potentially eligible study was excluded on the basis that it was duplicate reporting of a study already included.
Transformations. For some studies, cell size and or standard deviation was not reported. If cell size was not reported, cell sizes were calculated based on total sample size, assuming equal distribution of participants to all conditions. If standard deviations were not reported, then they were calculated from F statistics using the transformation procedure from the Cochrane Handbook of Systematic Reviews of Interventions .
Moderator coding. To assess stimulus modality and sample type as moderators of the EVE through meta-regression, two categorical variables were coded. Stimulus modality was coded as a dichotomous variable. Experimental stimuli were coded as video format if participants saw a video of the complainant describing the alleged assault (70.0% or 14 studies). If participants read a description of the complainant's story about the alleged assault events, stimulus modality was coded as text (30.0% or 6 studies). Sample type was also coded as a dichotomous variable. Participants were classed as having professional experience if they worked in the criminal justice system (i.e., judges or police officers) or had relevant professional training (i.e., law students or police trainees; 35% or 7 studies) or no professional experience or training if they did not work in the criminal justice system (i.e., students or community members; 65% or 13 studies).


Meta-Analytic Statistical Methods
The meta-analysis and meta-regression were conducted by calculating the standardized mean difference (Hedges' g) within a random effects model using the metafor package in R 
(Viechtbauer, 2010)
. Standardized mean difference was selected as the aggregate effect size measure as there was variability in complainant credibility measures. As Cohen's d can overestimate the population level effect size in small samples, we used the Hedges' g correction 
(Borenstein, Hedges, Higgins & Rothstein, 2009)
. Positive values for effect size indicated that emotional distress shown by the complainant increased perceptions of complainant credibility.
Heterogeneity was assessed using the Q statistic and the associated p value, I 2 and the associated confidence interval. The Q statistic is a ratio of observed variation (heterogeneity) to within study error or the weighted sums of squares. A significant Q statistic indicates that studies do not share a common effect size and the value of the Q statistic necessarily increases as the number of studies included in the analysis increases 
(Borenstein et al., 2009;
Schwarzer, Carpenter & Rucker, 2015)
. I 2 is the proportion of between-study variation rather than sampling error 
(Borenstein et al., 2009;
Deeks, Higgins & Altman, 2008;
Schwarzer et al., 2015)
.
The effect of the two proposed moderators, stimulus modality and sample type, were assessed through meta-regression using a random effects model and the restricted maximumlikelihood estimation model (REML) for between-study heterogeneity. The REML estimator was selected because it is efficient and unbiased with a modest amount of effect sizes from studies with reasonable power 
(Viechtbauer, 2005)
. Stimulus modality and sample type were entered simultaneously as predictors (moderators) into the model. The outcome variable was the effect size estimate for the EVE.


Assessing Bias Using P-curve Analysis
A p-curve analysis creates a distribution of p values associated with the statistical tests of the key hypotheses reported in a set of articles. The distribution is created for statistically significant p values only. If selective reporting is a viable explanation for the statistically significant results included in the analysis, there will be more high (i.e., close to p = .05) than low p values making the p-curve left-skewed. If selective reporting is not a viable explanation for the results included in the p-curve, there should be more low (i.e., close to p = .01) than high p values and the curve will be right-skewed. Two distributions are created, one for p values under .05 (the full p-curve) and one for p values under .025 (the half p-curve).
The half p-curve is a more rigorous test of whether selective reporting (via the file drawer problem or questionable research practices) can explain the statistically significant results in the analysis 
(Simonsohn, Simmons & Nelson, 2015)
. We conducted a p-curve analysis by specifying a study selection rule and extracting data from published papers using a p-curve disclosure table 
(Simonsohn et al., 2014a)
.
Study selection rule. To be included in our p-curve analysis, studies needed to be included in the meta-analysis and met the guidelines for inclusion in p-curve analysis 
(Simonsohn et al., 2014a;
Simonsohn et al., 2015)
. result from the article. The p-curve guidelines specify which key statistical result testing the hypothesis is entered into the p-curve, depending on the form of interaction predicted by the original study authors in their hypotheses (i.e., in some cases the interaction term is selected and in others the simple effects; 
Simonsohn et al., 2014a)
. We encountered several difficulties as we extracted data for the p-curve analysis using the disclosure table.
First, our meta-analysis focused on the main effect of complainant emotional demeanor on credibility. To test the reliability of the literature included in this analysis, ideally, we would have extracted p-values associated with the main effect of complainant emotional demeanor in all studies. However, some studies included in our meta-analysis used factorial designs and did not make a prediction concerning the main effect of complainant emotional demeanor on credibility. As the p-values included in p-curve analysis must be associated with a prediction made by the original study authors 
(Simonsohn et al., 2014a)
, in these studies we extracted the test statistic associated with the hypothesis about the complainant's emotional demeanor. This was usually a hypothesis about complainant emotional demeanor interacting with other factors included in the design.
Second, some authors reported non-directional exploratory hypotheses and research questions in their paper, which meant that test statistics from these papers could not be extracted for the p-curve analysis according to 
Simonsohn et al.'s (2014a)
 guidelines.
Third, we could not extract the key statistical result for some papers according to 
Simonsohn et al.'s (2014a)
 guidelines. Some papers did not report the key statistic stipulated by the p-curve guidelines for the experimental design and hypothesis. In some papers, the test statistic which corresponded to the hypothesis of interest was non-significant (as p-curve analysis investigates the distribution of p values below the statistical significance criteria of p < .05, these values are excluded from the analysis). Of the 20 studies included in the metaanalysis, we were able to extract data for the p-curve analysis from 9 studies (see 
Table 1
 for the p-curve disclosure table). Studies were excluded from the p-curve analysis because the key result testing the hypothesis was non-significant (n = 5) or the research hypotheses were exploratory (n = 6). We analyzed these data using the p-curve app (http://p-curve.com).
Robustness analyses. We ran additional p-curve analyses when the hypotheses reported by the original study authors addressed more than one dependent variable 
(Simonsohn et al., 2014a)
. To ensure that p-values were statistically independent as required to protect the integrity of the p-curve analyses, we only entered one p-value from any study into each p-curve.


Unregistered Analyses of Publication Bias
In addition to the pre-registered p-curve analyses, we also conducted some further tests of publication bias including a funnel plot and tests of asymmetry 
(Begg & Mazumdar, 1994;
Egger, Smith, Schneider & Minder, 1997)
, a trim and fill analysis 
(Duval & Tweedie, 2000a)
, and fail-safe N analyses 
(Rosenthal, 1979;
Rosenberg, 2005)
.


Funnel plot and tests of asymmetry.
A funnel plot is a scatterplot of standard errors and effect size estimates 
(Sutton, 2009)
. Asymmetry in a funnel plot can indicate that studies are systematically missing from a meta-analysis as a function of study size or effect size (and can be an indication of publication bias however asymmetry can be caused by other factors; 
Sterne, Becker & Egger, 2006;
Sutton, 2009)
. Asymmetry in a funnel plot can be statistically assessed through the rank correlation test 
(Begg & Mazumder, 1994)
 and the linear regression test 
(Egger et al., 1997)
. The linear regression test is generally considered to be more powerful than the rank correlation test 
(Sutton, 2009)
.
Trim and fill analysis. In trim and fill analysis, studies are simulated and imputed to make the funnel plot symmetrical and an adjusted effect size estimate is calculated 
(Duval & Tweedie, 2000a;
2000b)
. This means the analysis assumes that small effects are suppressed by publication bias 
(Sutton, 2009)
 which may not always be the case 
(Simonsohn et al., 2015)
. When high levels of between-study heterogeneity are present, the trim and fill technique does not perform well to estimate the effect of publication bias 
(Peters, Sutton, Jones, Abrams, & Rushton, 2007;
Terrin, Schmid, Lau & Olkin, 2003)
.
Fail-safe N. In the fail-safe N test (or file drawer analysis), the number of null result studies required to reduce the significance of the aggregate effect size estimate is calculated 
(Sutton, 2009)
. The Rosenthal fail-safe N test calculates the number of null effect studies that would be needed in order for the effect size estimate to become just significant at p = .05.
Larger numbers of studies required to reduce the effect is an indicator that the effect is more robust 
(Rosenthal, 1979)
. The weighted fail-safe N test 
(Rosenberg, 2005
) provides a more conservative estimate of the number of studies required to reduce the aggregate effect size estimate to just significant at p = .05 
(Rosenberg, 2005;
Sutton, 2009)
.


Exploratory Study Quality Assessment
Study quality assessment criteria. To assess the internal validity of the studies included in the meta-analysis, we executed an adapted form of the Cochrane risk of bias assessment 
(Higgins et al., 2011;
. The risk of bias assessment focuses on identifying protections against biases that threaten the internal validity of randomized controlled trials including selection, performance, attrition, detection, and reporting bias. As the studies included in this meta-analysis are cross-sectional psychology experiments, it was necessary to adapt the criteria in the assessment tool to make it appropriate to assess the internal validity of these types of studies (as recommended in the Cochrane guidelines; 
Reeves et al., 2008)
. We excluded reporting bias from the assessment as we investigated this through p-curve analysis. We also excluded attrition bias because participant attrition information is not reported for cross-sectional studies. 
Table 2
 displays the criteria from the Cochrane risk of bias assessment and the adapted criteria we used. We adapted the criteria based on scholarship about methodological protections against internal validity threats for cross-sectional psychology studies (e.g., 
Goodwin & Goodwin, 2013;
Haslam & McGarty, 2008;
Kite & Whitley, 2018)
.
Coding procedure. The criteria were coded by two independent raters and inter-rater reliability was assessed using Cohen's measure of agreement (kappa). This measure assesses the similarity of raters' categorizations accounting for chance agreement 
(Neuendorf, 2004)
.
All criteria had acceptable inter-rater reliability (i.e., over .80; 
Krippendorff, 2004
; 2013) on first coding.


Exploratory Content Analysis
We investigated the operationalization of complainant emotional demeanor and the measurement of complainant credibility in studies included in our meta-analysis through content analysis. Content analysis is a method of systematically evaluating and coding the content of text 
(Neuendorf, 2002)
. It can be used to classify the content of text based on frequently occurring words, themes or concepts within text 
(Krippendorff, 2013)
. Categories developed to classify text through content analysis must be reliable, so the analysis can be replicated by independent coders 
(Krippendorff, 2013;
Neuendorf, 2002)
.
We executed two separate content analyses. The first analysis focused on evaluating how the independent variable of complainant emotional demeanor had been operationalized in included studies. We were specifically interested in the behaviors or descriptions of the complainant's behavior used to portray distress and controlled affect by the complainant. The second analysis focused on evaluating the type of questionnaire items used to measure complainant credibility in the included studies to assess the face validity of these measures. Category development. The first coder developed the categories for both content analyses. For the first content analysis, focused on complainant emotional demeanor, each behavior described as part of the operationalization of complainant distress or controlled affect was extracted into a separate category (14 categories in total). For the second content analysis, focused on complainant credibility measures, nine categories were developed addressing the content of sample items and scale anchors reported. Categories for both content analyses were data driven (i.e., based on reports of the operationalization of complainant emotional demeanor and complainant credibility measures respectively).
Coding procedure. The first coder developed the coding categories and coded the data. The second coder was provided with a coding form and explanation of the coding categories. The second coder coded the data according to the coding scheme. Inter-rater reliability, via Cohen's kappa, was calculated to check the reliability of the coding scheme.
Categories which have a Cohen's kappa value of above .80 are considered to have acceptable agreement beyond chance 
(Krippendorff, 2004;
 and values between .40-.75 indicate fair to good agreement beyond chance 
(Banerjee, Capozzoli, McSweeney & Sinha, 1999)
. Categories with agreement in the fair to good range were reviewed by both coders and the definition of the category was revised. After recoding based on the revised category definitions, inter-rater reliability was re-calculated. All reported categories have kappa values above .85, suggesting acceptable reliability 
(Krippendorff, 2013)
. The first coder's ratings were reported for categories where there was disagreement between the first and second coder.


Results


Pre-Registered Analyses
Overall effect size. The final analysis contained 20 effect sizes. To test H1, we conducted a random effects model to estimate the effect size of the EVE. The random effects model resulted in an estimated effect size of g = 0.38 (95% confidence interval, [0.25; 0.51], Q = 47.43, p <.001, I 2 = 59.62%, 95% CI [29.49, 84.34]), which indicated, consistent with H1, that distressed rape complainants were perceived to be more credible than their controlled counterparts. 
Figure 2
 shows the effect size estimates and associated confidence intervals for each study included in the meta-analysis. 
Table 3 displays the sample size,
 sample type, and stimulus modality for all studies included in the meta-analysis. The between-study heterogeneity (I 2 ) was substantial according to the Cochrane guidelines 
(Deeks et al., 2008)
, indicating that it was appropriate to use meta-regression to assess potential moderators.
Moderator analysis. To test the relationship between the effect size estimate and the two proposed moderators, meta-regression was conducted using a random effects model. Contrary to H2, stimulus modality did not moderate the effect size estimate for the EVE (Z = -1.01, p = .313, k = 20). H3 was also not supported. Sample type did not moderate the effect size estimate for the EVE (Z = 0.22, p = .827, k = 20). P-curve analysis. The p-curve was right skewed, suggesting that the studies included in the p-curve had evidential value (see 
Figure 3)
. The continuous tests (using Stouffer's Method) which examine whether the p-curve is significantly right skewed were significant for the full p-curve (Z = -3.61, p < .001) and the half p-curve (Z = -3.59, p < .001). According Robustness p-curve analyses. We ran two robustness p-curve analyses. In the first pcurve analysis, we included p-values associated with dependent variables measuring negative attitudes towards the complainant that were addressed by the focal hypotheses selected. The full (Z = -2.58, p = .005) and half p-curve (Z = -3.90, p = .003) in this analysis were significantly right skewed. In the second analysis, we included p-values associated with dependent variables measuring positive attitudes towards the complainant and again the full (Z = -2.93, p = .002) and half p-curve (Z = -2.72, p = .003) were significantly right skewed. This suggested that the findings of the p-curve analysis were robust.


Unregistered Analyses of Publication Bias
Funnel plot. A scatterplot (funnel plot) of effect size estimate and standard error for all studies included in the meta-analysis is presented in 
Figure 4
. Two statistical tests of funnel plot asymmetry, the nonparametric correlation test (t = 0.11, p = .542) and the regression test (Z = 0.88, p = .380) were both non-significant and suggested that the funnel plot was not asymmetric. This was consistent with the results of the p-curve analyses.
Trim and fill analysis. We conducted a trim and fill analysis 
(Duval & Tweedie, 2000a;
2000b)
. As there was substantial between-study heterogeneity in these data (by the Cochrane guidelines; 
Deeks et al., 2008)
, the results of the trim and fill analysis, particularly concerning the adjusted effect size estimate, should be treated with caution 
(Sterne, Egger & Moher, 2011;
Viechtbauer, 2010)
. The trim and fill analysis resulted in an adjusted effect size estimate of g = 0.34 (95% CI, [0.21; 0.57], Q = 55.94, p <.001, I 2 = 63.39%, 95% CI 
[38.09, 85
.71]). Two simulated studies were imputed into the funnel plot for the adjusted analysis (see 
figure 5)
. The adjusted effect size estimate from a trim and fill analysis should not be considered the true estimate of the effect without publication bias 
(Viechtbauer, 2010)
. There is negligible change in the effect size estimate on the basis of a trim and fill analysis. This was consistent with the results of the p-curve analyses.
Fail-safe N. The 
Rosenthal fail-safe N test (1979)
 indicated that 588 studies averaging a non-significant effect would be needed to reduce the current effect size estimate to just significant (p = .05). 
Rosenthal (1979)
 suggested that if the number of studies needed to reduce the effect size estimate to just significant was over 500 this was an indication that effect was robust. This criterion has been criticized as being arbitrary 
(Rosenberg, 2005;
Sutton, 2009)
. The 
Rosenberg fail-safe N test (2005)
 indicated that 414 studies averaging a non-significant effect would be needed to reduce the overall effect size estimate to just significant (p = .05). This was also consistent with the results of the p-curve analyses.


Exploratory Study Quality Analysis
Overall, the majority of studies (80% or 16 studies) had one or more methodological protections against all three (20% or four studies) or two biases (60% or 12 studies) considered in the risk of bias assessment. Only 20% (or four studies) reported protections against a single form of bias which threatens internal validity. Manipulation checks were the most common protection employed against performance bias (by 12 studies or 60%), reporting a reliability analysis for the credibility measure was the most common protection employed against detection bias (by 11 studies or 55%) and random allocation was used to protect against selection bias in half of studies (11 studies or 55%). The number and proportion of studies that met each risk of bias criteria is reported in 
Table 4
.


Exploratory Content Analyses
Operationalization of complainant emotional demeanor. Two studies were excluded from this analysis as no description of the behaviors used to operationalize complainant distress or controlled affect were reported. Both coders were in agreement that these studies should be excluded. The proportion (and number) of studies, as well as the kappa inter-rater reliability coefficients for each category (i.e., complainant behavior) is presented in 
Table 5
.
All studies described using more than one behavior to operationalize complainant distress (18 studies or 100%). The number of behaviors used to operationalize complainant distress ranged from two to five (mode = 4). All studies but one used crying to operationalize complainant distress. Around half of the studies also used either distressed facial expression, hesitations in speech or trembling voice to manipulate distress. For studies that used text- Two-thirds of studies (12 studies or 66.7%) described using one or more behavior to operationalize controlled emotional demeanor. Of the studies which did not describe any specific behaviors used to operationalize controlled emotional demeanor (6 studies or 33.3%), they provided a general description (e.g., the complainant was calm). The number of behaviors described to operationalize controlled demeanor ranged from one to five (mode = 1). To operationalize controlled affect, half of the studies reported that complainant's demeanor was factual. Just over a quarter of all studies also operationalized controlled affect as having a steady voice or the complainant appearing confident (see 
Table 5
).
Measurement of complainant credibility. The proportion (and number) of all studies to use various items in their complainant credibility measure is reported in 
Table 6
. All studies used one or more items describing a face valid concept related to credibility. The most commonly used face valid concepts were believability, credibility, and/or truthfulness.
Some other concepts used as items in credibility measures were accuracy and whether the complainant had attempted to hide the truth in some way (see 
Table 6
, category hiding truth).
Some complainant credibility measures contained items tapping concepts not directly related to complainant credibility including defendant guilt (which was reversed coded) and the observer's confidence in their decision (see 
Table 6
).


Further Exploratory Analysis
We were unable to include categories from the risk of bias assessment and content analyses as moderators of the EVE because many were skewed (e.g., one or more methodological protections against all three biases; crying to manipulate complainant distress). Meta-regression is sensitive to skew in categorical moderators which can undermine the reliability of the analysis 
(Borenstein et al., 2009;
Schwarzer et al., 2015)
.


Discussion
Our aim in this review was to estimate the size and robustness of the effect of complainant emotional demeanor on credibility judgments for female adult rape complainants. We discuss our pre-registered analyses and suggest conceptual and theoretical directions for future research. Then we discuss our unregistered and exploratory analyses and suggest methodological improvements for future research.


Complainant Distress and Credibility
We expected a significant and positive effect size estimate, such that a distressed rape complainant would be judged more credible than her emotionally controlled counterpart (H1). This hypothesis was supported, and our meta-analysis suggested that there is a small to moderate effect, by 
Cohen's (1988;
 guidelines, of complainant emotional demeanor on credibility judgments. However, a review of effect sizes in social psychology called for empirically based cut-offs on the 25 th , 50 th , and 75 th percentiles of effect sizes to be 0.15, 0.40, and 0.70 for Cohen's d or Hedges' g 
(Lovakov & Agadullina, 2017)
. By these guidelines, our effect size estimate is moderate.
In our review, we used the Heuristic-Systematic Model to explain how complainant emotional demeanor might influence credibility judgments 
(Chaiken, 1980)
. We suggested that perceivers in rape cases were likely to be highly motivated to engage in information processing (e.g., 
Thomas, 2010;
White et al., 2010)
. In everyday credibility judgments, motivated perceivers engage in systematic processing which overrides the effect of heuristic cues, like complainant emotional demeanor, on their judgments (the attenuation hypothesis;
Chaiken 
& Maheswaran, 1994;
Reinhard & Sporer, 2008;
. However, because typical rape cases have ambiguous evidence (i.e., cases lack corroborative evidence; 
Cox, 2015;
Quadara et al., 2013)
, highly motivated perceivers are likely to be influenced by heuristic cues in their systematic processing of information about the case (the bias hypothesis or biased systematic information processing; 
Chaiken & Maheswaran, 1994)
. The bias hypothesis is one plausible explanation for the observed effect of complainant emotional demeanor on perceiver's credibility judgments. The bias hypothesis predicts in rape cases, perceivers may be influenced by a misleading heuristic (complainant emotional demeanor) not because they are not motivated to engage in effortful information processing, but because the available evidence means decision-making is inherently difficult. However, other underlying mechanisms, such as expectancy violation (e.g., 
Hackett et al., 2008;
Ask & Landström, 2010)
, perceivers' emotional responses to the complainant (e.g., 
Ask & Landström, 2010)
, or perceiver empathy 
(Ask, 2018)
 may also explain the relationship between complainant emotional demeanor and credibility judgments.
We extracted data associated with the main effect of complainant emotional demeanor on credibility judgments for our meta-analysis. Several included studies found interactions between complainant emotional demeanor and another factor on credibility. By selecting the main effect, it is possible the effect size was underestimated in these studies. However, selecting main effects allowed us to assess the size of the effect of complainant emotional demeanor on credibility judgments, irrespective of other moderating factors, which was our focus in this review.
We used p-curve analysis to determine whether selective reporting, via publication bias or questionable research practices, could explain the statistically significant findings reported in this literature. The p-curve, and robustness p-curves, were significantly rightskewed, and suggested that selective reporting (via the file drawer problem or questionable research practices) is not a viable explanation for the literature on the effect of female adult complainant emotional demeanor on credibility judgments.


Tests of Moderators
We considered whether stimulus modality or sample type modified the effect size estimate for the emotional victim effect. We expected the effect of complainant emotional demeanor would be stronger when participants watched a video of the complainant compared with reading a synopsis of complainant evidence (H2). This hypothesis was not supported.
This means complainant distress increases credibility judgments even through less ecologically valid experimental paradigms using written complainant evidence. This is consistent with the results of other meta-analytic reviews of jury decision-making studies which suggest that stimulus modality has limited impact on decisions made about the case (e.g., verdict and guilt likelihood; 
Bornstein et al., 2017)
.
We reasoned when complainant emotional demeanor was more salient, it would be a more accessible heuristic cue for perceivers to use to judge credibility 
(Chaiken & Eagly, 1983)
. When a heuristic cue is more accessible, perceivers view it as more reliable and relevant to use to make the judgment 
(Chen & Chaiken, 1999)
. If complainant emotional demeanor is viewed as relevant to judging credibility, then it may have a larger effect on biased systematic information processing by guiding attention in systematic processing to information consistent with the heuristic cue of complainant emotional demeanor. However, some evidence suggested that complainant emotional demeanor may be more salient in video evidence (e.g., 
Chaiken & Eagly, 1976;
1983)
 and other evidence indicated that complainant emotional demeanor may be more salient in written evidence (e.g., 
Bless et al., 1993;
Grice, 1975;
Kite & Whitley, 2018;
Schwarz et al., 1991)
. Our results suggest no difference in the effect of complainant emotional demeanor on credibility between video and written complainant evidence. Our content analysis of complainant emotional demeanor manipulations suggests that many studies using written complainant evidence included the complainant, or another witness, identifying the complainant's emotional demeanor for the perceiver. For example, the complainant would say she was distressed, and complainant emotional demeanor would have been highly salient for perceivers.
We also expected that the effect of complainant emotional demeanor on credibility judgments would be smaller for perceivers with professional experience or training (e.g., police officers or judges) compared to those without professional experience or training (i.e., community members or university students; H3). This hypothesis was not supported. There is debate about whether professional experience or training prevents judges, lawyers, and police officers from relying on heuristic cues to make judgments in their professional roles (e.g., 
Reinhard et al., 2012
cf. Ask, 2010
. Our results suggest that being a member of a professional group does not reduce the influence of potential heuristic cues, like complainant emotional demeanor, on credibility judgments of rape complainants. This is consistent with research which suggests that professional expertise or training does not prevent criminal justice professionals from being influenced by motivated cognition or heuristic cues in their judgments (e.g., 
Ask, Grahag, & Rebelius, 2011;
Miller, 2018;
Rachlinski & Wistrich, 2017)
.
We reasoned that increased familiarity with the judgment context, which criminal justice professionals and trainees possess relative to lay perceivers, may make them more willing to engage with conflicting complex information in making credibility judgments 
(Reinhard et al., 2011;
2012)
. This may make professionals and trainees more likely to challenge the reliability of complainant emotional demeanor to judge credibility within biased systematic information processing, reducing the effect of complainant emotional demeanor on their credibility judgments relative to lay perceivers. However, survey evidence suggests that some police officers and prosecutors view complainant emotional demeanor as relevant and reliable information to judge credibility (e.g., 
Ask, 2010;
Heenan & Murray, 2006
). If complainant emotional demeanor is viewed as a reliable and therefore relevant cue to judge credibility, it is unlikely to be challenged in systematic processing, and biased systematic information processing may take place. Within biased information processing the evidence focused on in information processing will align with the heuristic cue (i.e., when the complainant is distressed perceivers will focus on other evidence in favor of her credibility and vice versa for complainants who present with controlled affect). This may be a viable explanation for why sample type did not moderate the effect of complainant emotional demeanor on credibility judgments.
An alternative explanation is, if experience rather than training encourages professionals to challenge the relevance of complainant emotional demeanor to judge credibility, sample type coded at the study level may not be a sufficiently precise measure of professional expertise. Several included studies used police trainees (e.g., 
Ask & Landström, 2010;
Baldry, Winkel & Enthovan, 1997)
 or law students (i.e., Bohner & Schapansky, 2018).
These types of participants may be too early in their criminal justice careers to have developed a sufficient level of expertise in decision-making, thus reducing the differences between the two groups in expertise. We were unable to do further exploratory sub-group analyses on differences between police trainees and officers or law students and judges as we did not have sufficient studies to power the analysis 
(Schwarzer et al., 2015)
.


Conceptual and Theoretical Issues for Future Research
Our meta-analytic review suggested that there is a substantial amount of betweenstudy heterogeneity present in this literature and there may be powerful unidentified moderators of the effect of complainant emotional demeanor on credibility judgments 
(Deeks et al., 2008)
. We suggest that future research should further investigate moderators and theoretically-derived mediators of the effect of complainant emotional demeanor on credibility judgments. This would move the literature towards a comprehensive understanding of the operation and boundaries of the effect.
Conceptual moderators. Future research should continue to study criminal justice professionals focusing on senior lawyers, judges, and police officers so that any influence of professional experience on the emotional victim effect can be fully understood. We also suggest that future research study trainee groups so the effect of modern professional training (which may include updated specialized training for rape cases) on the emotional victim effect can be understood. The random effect model meta-regression analysis we used to examine professional experience was low powered. This means a non-significant result should not be considered conclusive evidence that the moderator does not have an influence on the effect size 
(Borenstein et al., 2009;
Deeks et al., 2008)
.
Future research should also aim to understand how complainant emotional demeanor interacts with other factors which influence perceptions of rape complainants, like perceiver gender or rape victim stereotypes. Whereas there is limited existing evidence to suggest that perceiver gender influences how complainant emotional demeanor is used to judge credibility 
(Bollingmo et al., 2007;
Calhoun et al., 1981;
Kaufmann et al., 2003;
Klippenstine, 2010;
Schuller et al., 2010;
Wessel et al., 2006
cf. Bohner & Schapansky, 2018
, perceiver gender does influence perceptions of rape complainants more generally (e.g., 
Anderson et al., 1997
cf. Gravelin et al., 2019
. Gender differences in emotion recognition, as suggested by the emotional sensitivity hypothesis, could drive gendered differences in the use of complainant emotion as a reliable and relevant heuristic cue to judge credibility (cf., a recent meta-analytic review did not find support for gendered differences in emotion perception; 
Fischer, Kret & Broekens, 2018)
. Similarly, few studies have investigated or shown that rape victim stereotypes influence the effect of complainant emotional demeanor 
(Kaufmann et al., 2003;
Schuller et al., 2010)
, despite rape victim stereotypes being a strong influence on how rape complainants are perceived generally 
(Davies et al., 2009;
Masser et al., 2010
).
However, existing psychology studies of these effects may be underpowered to detect interactions (Giner-Sorolla, 2018), so properly powered investigations of these potential moderators should be undertaken in future research. Exploring whether other heuristic cues about rape complainants modify the effect of complainant emotional demeanor is critical to a parsimonious understanding of how perceivers judge rape complainant credibility.
Theoretical explanations. In our review, we used the Heuristic-Systematic Model 
(Chaiken, 1980)
 to explain the effect of complainant emotional demeanor on credibility judgments. Although perceivers might be motivated to process information carefully to judge complainant credibility, the bias hypothesis suggests that in the ambiguous context of rape cases heuristic cues, such as complainant emotional demeanor, influence evidence focused on in systematic information processing 
(Chaiken & Maheswaran, 1994)
. Our results suggest that complainant emotional demeanor consistently influences credibility judgments, regardless of sample type or stimulus modality. However, our review cannot provide evidence of the mechanisms which might explain how complainant emotional demeanor is used to judge credibility.
We suggest that future research investigate the bias hypothesis as one possible explanation for the effect that complainant emotional demeanor has on credibility judgments.
The majority of research adopting the Heuristic-Systematic Model has focused on the attenuation hypothesis and demonstrates that systematic processing has a curative effect on the potentially biasing effects of heuristics (e.g., 
Reinhard et al., 2011;
2012)
. By comparison, the bias hypothesis has been investigated in research substantially less 
(Chen & Chaiken, 1999;
Todorov et al., 2002)
. Rape cases offer an inherently ambiguous real-life context in which both the operation and potential boundaries of the bias hypothesis can be investigated and understood. 
Ask and Landström (2010)
 examined mediators of the emotional victim effect in the context of cognitive load, an ecologically valid moderator for criminal justice professionals.
Although not intended as a test of the Heuristic-Systematic Model, by examining the effect of cognitive load and rape complainant emotional demeanor on police trainees' complainant credibility judgments, 
Ask and Landström (2010)
 also provided evidence for the attenuation hypothesis 
(Chaiken, 1980)
. That is, when trainees were not under cognitive load (and likely to systematically process case information), the effect of complainant emotional demeanor on credibility judgments was attenuated.
However, for a complete test of the attenuation hypothesis, which assumes that attenuation of heuristic cues occurs only for highly motivated perceivers 
(Chaiken & Chen, 1999;
Todorov et al., 2002)
, perceivers' motivation to engage in information processing needs to be measured to check this assumption. Perceivers' quality and quantity of information processing also need to be measured to confirm perceivers used systematic information processing to judge complainant credibility. Measuring the quality of perceivers' information processing also allows for confirmation that complainant emotional demeanor had a limited impact on systematic information processing (i.e., attenuation through systematic processing occurred). Neither perceiver motivation to engage in information processing nor quantity and quality of information processing was measured by 
Ask and Landström (2010)
. We suggest that future research should investigate the attenuation hypothesis as a possible explanation for the relationship between complainant emotional demeanor and credibility judgments. We also recommend that future research account for perceiver motivation to engage in information processing (e.g., through survey questions; 
Reinhard & Sporer, 2008)
 and measure quality and quantity of information processing (e.g., through a cognitive response task; 
Chaiken & Maheswaran, 1994)
 to allow for a full examination of the attenuation or bias hypotheses as mechanisms through which the emotional victim effect occurs.
The Heuristic-Systematic Model, and the bias hypothesis specifically, offer one plausible explanation for how complainant emotional demeanor influences credibility judgments. However, there are other plausible explanations for the mechanisms underpinning this effect. Only a few studies to date have empirically investigated possible theoretical mechanisms (e.g., 
Ask, 2018;
Ask & Landström, 2010;
Bohner & Schapansky, 2018;
Hackett et al., 2008)
. Moreover, fewer studies have examined potential mediators of the effect, for example empathy 
(Ask, 2018)
 or expectancy violation 
(Ask & Landström, 2010)
. We suggest that future research focus on investigating theoretically driven mediators of the effect.
Research investigating theoretically driven explanations of how complainant emotional demeanor is influencing credibility judgments is critical. Our review suggests that complainant emotional demeanor could be adversely, and prejudicially, influencing complainant credibility judgments made across the criminal justice system by police officers, lawyers, judges, and jurors. This means complainant emotional demeanor could be, in part, an explanation for rape case attrition 
(Alderden & Ullman, 2012;
Spohn & Tellis, 2012)
.
Understanding the mechanisms through which complainant emotional demeanor influences credibility judgments is the first step in designing effective intervention, by identifying what needs to be targeted in intervention attempts, to prevent complainant emotional demeanor from prejudicing credibility judgments. For example, if future research finds the bias hypothesis adequately explains the link between complainant emotional demeanor and credibility judgments, then interventions will need to focus on reducing or eliminating perceptions of complainant emotional demeanor as a reliable or relevant cue to judge credibility. Interventions like giving directions to jurors to be more accurate or impartial (e.g., in Australia; Queensland Courts, 2017), which affect motivation (e.g., 
Reinhard, 2010;
Reinhard & Sporer, 2008;
Chaiken & Maheswaran, 1994)
, are unlikely to change the use of complainant emotional demeanor as a heuristic cue within biased systematic information processing. Alternatively, if perceiver empathy explains the link between complainant emotional demeanor and credibility judgments, then empathetic responses would need to be targeted in such interventions.


Unregistered Analyses of Publication Bias
There are numerous analyses that can be used as indicators of the effect of publication bias within a particular literature. Many of these analyses make different assumptions about the causes of publication bias. For example, fail-safe N and p-curves, in part, assume publication bias suppresses non-significant findings 
(Rosenthal, 1979)
, whereas funnel plots and the trim and fill analysis assume that small effects are suppressed by publication bias 
(Sutton, 2009)
. All metrics of publication bias also operate poorly under certain conditions.
For example, trim and fill analysis performs poorly to estimate publication bias when between-study heterogeneity is high 
(Peters et al., 2007;
Terrin et al., 2003)
. By examining multiple indicators of publication bias, we were able to look at cumulative evidence for the effect of publication bias on our overall effect size estimate (a strategy used by meta-analysts; e.g., 
Pettigrew & Tropp, 2006)
. The two tests of funnel plot asymmetry and the trim and fill analysis suggest that there is a limited effect of publication bias on our overall effect size estimate. Further, the two tests of fail-safe N suggest that a large number of non-significant studies would be required to reduce the overall effect size estimate to just significant. In combination, these additional analyses and indicators of publication bias support the results of the p-curve and robustness p-curves. Across all these metrics, there is limited evidence to suggest that publication bias has exerted an effect on the meta-analytic results.


Risk of Bias Assessment
The risk of bias assessment suggested that included studies had reasonable internal validity. Most studies had methodological protections against two or three biases which threaten internal validity. Our assessment was based on study reports, which may underestimate internal validity, as sometimes reports omit methodological details . For example, we found half of the reports specified participants were randomly assigned to conditions (which protects against selection bias). However, random assignment to experimental conditions is ubiquitous in psychology experiments (e.g., 
Kite & Whitley, 2018
) so this information may simply have been omitted from the remaining study reports.
Methodological protections against detection bias could be strengthened. Most studies did not report any validity assessment for complainant credibility measures. This is consistent with a recent review of social psychology research, which suggested that validity assessments are under reported 
(Flake, Pek & Hehman, 2017)
. Also, most studies reported Cronbach's alpha to demonstrate measure reliability. Although Cronbach's alpha is used typically as the sole indicator of reliability, it is problematic as a measure of reliability 
(Flake et al., 2017)
 and does not assess measure structure (i.e., unidimensionality or homogeneity; 
Schmitt, 1996;
Sijtsma, 2009)
.
More robust protections against performance bias could be used in future research.
Just half of the studies we examined included information about manipulation checks (and indicated whether the complainant emotional demeanor manipulation was successful). Few studies used a suspicion probe to screen for demand characteristics which can be a viable explanation for the study results 
(Kite & Whitley, 2018)
.


Exploratory Content Analysis
We found that complainant distress was commonly operationalized by crying, distressed facial expression, trembling voice, and speech hesitations. In contrast, controlled affect was operationalized by a factual or confident manner and a steady voice. However, there were several other behaviors used to operationalize distress and controlled affect which varied across studies. We also found variability in complainant credibility measures. All studies used a measure that contained one or more face valid items about the believability, credibility or truthfulness of the complainant. Yet, some less face valid items were also included (for example, items about perpetrator guilt). Few measures included items about the accuracy of the complainant's testimony and no measures contained items about the reliability of the complainant's evidence. This matches a recent review of credibility measures for child sexual abuse complainants, which found that items about accuracy and reliability were rarely used 
(Voogt, Klettle & Crossman, 2016)
. This omission is problematic as jurors are typically directed to consider the complainant's reliability related to credibility 
(e.g., in Australia and Canada;
McKimmie et al., 2014;
Porter & ten Brinke, 2009;
White v R, 1947
).


Improving Simulation Methods for Future Research
We focused on studies which used an experimental methodology in this review. As the effect of complainant emotional demeanor on credibility judgments may inform policy changes, it is particularly important that the methodology used to investigate the effect is rigorous 
(Kerr, 2017)
. We make five suggestions for improving simulated decision-making studies for future research below including increasing internal validity, refining complainant emotion manipulations and credibility measures, performing direct replication studies, implementing ecologically valid protocols, and sharing data and study materials.
Strengthening internal validity. Based on the risk of bias assessment, we recommend increasing protections to prevent performance and detection biases from threatening internal validity. In particular, we suggest that manipulations of complainant emotional demeanor are assessed using manipulation checks (e.g., questions about the emotion portrayed). Suspicion probes, which ask participants to speculate about the study hypotheses, should be included to screen for demand characteristics 
(Kite & Whitley, 2018)
.
Future research should investigate the reliability and validity of complainant credibility measures. For multiple item measures, results of exploratory factor analyses (to investigate the structure of measures) and other reliability assessments (e.g., Cronbach's alpha) should be conducted 
(Haslam & McGarty, 2008)
. Validity assessments of credibility measures should be executed 
(Flake et al., 2017)
. For example, researchers should detail the item development procedure or demonstrate convergent or discriminant validity with other established measures (e.g., the Witness Credibility Scale; 
Brodsky, Griffin & Cramer, 2010)
.
We suggest that authors report all methodological features used to protect internal validity (e.g., randomization to conditions) in publication of the work. This provides the reader with information to assess the strength of evidence the study contributes.
Manipulating emotional demeanor and measuring credibility. Given the variation in the operationalization of complainant distress and controlled affect, we suggest that future research should explore whether changes in the complainant's emotional display modify how complainant emotional demeanor influences credibility. Content of emotional displays can change recognition of emotional states (e.g., tears make sad faces seem sadder to perceivers;
Balsters, Krahmer, Swerts, & Vingerhoets, 2013) and rape complainants who display anger are sometimes viewed as less credible 
(Bohner & Schapansky, 2018
cf. Vrij & Fischer, 1997
. More studies should investigate whether different negative emotional states (e.g., anger, defiance, fear) influence credibility judgments, to explore the extent and reliability of this effect.
We suggest that credibility measures should focus on issues perceivers are legally required to consider when making credibility judgments. For example, if jurors are required to assess the honesty and reliability of the witness to judge credibility, credibility measures should include only these items. This would allow researchers to assess whether perceivers are using legal guidance in their credibility judgments, which is a research priority for criminal justice professionals 
(Kerr, 2017)
.
Performing direct replications. The reproducibility of experimental research findings in psychology (Open Science Collaboration 
[OSC]
, 2015) and other sciences (e.g.,
McNutt, 2014) has been queried. Two large-scale replication projects in psychology suggested that the effect size produced by replication studies is half the original effect size reported 
(Camerer et al., 2018;
OSC, 2015)
. The size of the originally reported effect and the statistical power of the replication study were positively correlated with whether the effect replicates 
(Bakker, van Dijk & Wicherts, 2012;
OSC, 2015)
. As the effect of complainant emotional demeanor on credibility judgments may be used to affect policy change, it is critical the effect is demonstrated to be robust. Our review offers an initial positive assessment of robustness of the emotional victim effect, but we suggest that more properly powered direct replications are needed to further investigate the robustness of the effect.
Using ecologically valid protocols. We recommend that researchers should use ecologically valid experimental protocols to replicate the effect of complainant emotional demeanor on credibility judgments 
(Bornstein, 2017;
Koehler & Meixner, 2017
cf. Kerr, 2017
Kerr & Bray;
. Simulated decision-making study protocols are often criticized for lacking ecological validity, including inadequate sampling, inappropriate measurement of dependent variables or missing investigative interview or trial procedure 
(Bornstein, 1999;
Diamond, 1997;
Koehler & Meixner, 2017)
. Most of the studies we reviewed that used a jury simulation paradigm did not include deliberation (cf. 
Dahl et al., 2007)
 and used short complainant testimony extracts without examination by the prosecutor or cross-examination by defense counsel. Cross-examination can reduce credibility judgments of rape complainants by highlighting complainant behavior that does not match rape victim stereotypes 
(Zajac & Cannan, 2009;
Zydervelt, Zajac, Kaladelfos, & Westera, 2016)
. We suggest that more trial procedures that may influence the credibility judgments of complainants be incorporated in future studies.
Sharing materials and data. Generally, ecological validity is positively correlated with external validity. As the similarity between the experimental context and the real world increases so does the likelihood the effect will reproduce (external validity; 
Wiener, Krauss & Lieberman, 2011)
. However, police investigations and trial procedures vary greatly between different legal jurisdictions. Using more ecologically valid protocols for a particular legal jurisdiction can introduce substantial variation into simulated decision-making studies.
This variation may reduce the prospect of reproducibility 
(Krauss & Lieberman, 2017)
. By sharing materials, research groups would be able to see how other researchers have incorporated specific investigation and trial procedure into materials and adapt these for their own legal jurisdiction (for conceptual replication) or use the materials (for direct replication).
Sharing data and materials would also enable validity assessments of credibility measures.
Data and materials can now be easily shared through online platforms like the Open Science Framework (https://osf.io) or other repositories (see the Registry of Research Data Repositories; https://www.re3data.org). We suggest that researchers make their materials and data available to encourage collaborative work to improve the robustness and usefulness of simulated decision-making research.


Conclusion
The results of this meta-analysis and p-curve analysis suggest that complainant emotional demeanor has a small to moderate effect on credibility judgments and reporting bias is not a likely explanation for significant results reported within this literature.
Complainant emotional demeanor is not diagnostic of witness honesty, the key component of a credibility decision (e.g. in 
Australia and Canada;
McKimmie et al., 2014;
Porter & ten Brinke, 2009)
. That a potentially prejudicial factor influences credibility judgments should be a concern, especially given that complainant credibility is a key determinant of whether a rape case proceeds in the criminal justice system 
(Brown et al., 2007;
O'Neal, 2017)
. Future research should focus on identifying the mechanisms through which rape complainant emotional demeanor influences credibility judgments. This is important so that effective interventions can be designed to target the underlying mechanisms to prevent complainant emotion from influencing credibility judgments made by criminal justice professionals and jurors. 
Ask, K., & Granhag, P. A. (2005)
 *Baldry, A. C., 
Winkel, F., & Enthoven, D. (1997)
. Paralinguistic and nonverbal triggers of biased credibility assessments of rape victims in Dutch police officers: An experimental study of "nonevidentiary" bias. Advances in 
Psychology and Law, 163-174. Balsters, M. J. H., Krahmer, E. J., Swerts, M. G. J., & Vingerhoets, A. J. J. M. (2013)
.
Emotional tears facilitate the recognition of sadness and the perceived need for social support. Evolutionary 
Psychology, 11(1), 147470491301100114. doi:10.1177
/147470491301100114 Banerjee, M., Capozzoli, M., McSweeney, L., & Sinha, D. (1999
 International Journal of Conflict and Violence, 12, 1-13.doi: 10.4119/UNIBI/ijcv.635 
Table 1
 Disclosure  
Winkel, & Enthoven (1997)
 A victim reporting a rape in an emotional way is believed more and held less responsible than a victim reporting the same crime in a controlled way 2 (emotional vs controlled victim) x 2 (powerful vs powerless perpetrator speech style)


Difference between means
This analysis resulted in a main effect -supporting hypothesis 1 -for victim's style of self-presentation (see 
Table 2
). 
Table 2
 suggests that emotional victims were perceived as more credible. Further support for hypothesis 1 comes from an analysis of covariance on groups 5 and 6, here too the perceived credibility of the emotional victim (M = 4.99) is significantly higher (F (1,19) = 17.08, p < .01) than the credibility of a victim exhibiting a controlled style.  
Calhoun, Cann, Selby, & Magee (1981;
Study 1)
 The purpose of the present investigation was to examine the effects of the victim's emotional style on social reactions to the rape victim. Of specific interest were the perceptions of the victim's credibility, the degree to which she would be socially accepted, and the degree to which observers believed the victim found the rape unpleasant.
2 cell design (victim emotion: distressed vs calm)


Difference between means
When the victim was described as expressive she was viewed as significantly more credible (M = 17.36), than when she was described as calm (M = 13.96), F = 10.54, d.f. = 1, 45, p < .002.
F(1, 45) = 10.54, p = .00221 Alternate dependent variable (negative evaluation of complainant; victim's perceived enjoyment of assault) F(1, 45) = 3.04, p = .08806 No significant effect of demeanor on social acceptance and no statistics reported in paper. 
Calhoun, Cann, Selby, & Magee (1981;
Study 2)
 The purpose of the present investigation was to examine the effects of the victim's emotional style on social reactions to the rape victim. Of specific 2 cell design (victim emotion: distressed vs calm)


Difference between means
There also was a significant impact on the perceived credibility of the victim. When the victim was controlled, she was rated as less credible (M = F(5, 47) = 7.31, p = .00004 b Alternate dependent variable (negative evaluation of complainant;
interest were the perceptions of the victim's credibility, the degree to which she would be socially accepted, and the degree to which observers believed the victim found the rape unpleasant.
14.21) than when she was expressed (M = 16.69). F = 7.31, d.f. = 5, 47, p < .009. victim's perceived enjoyment of assault) F(5, 47) = 7.40, p = .00003 Alternate dependent variable (positive attitudes towards complainant; social acceptance) F(5, 47) = 3.71, p = .00652 
Hackett, Day & Mohr (2008)
 Based on the preceding discussion, it is therefore hypothesized that people who expect rape victims to behave in an emotionally expressive way will find an emotionally expressive victim as more credible than a victim who is not emotionally expressive. For people who do not expect rape victims to behave in an emotionally expressive way, it is hypothesized that there 2 (victim emotion: emotional vs unemotional) x 2 (participant expectation for emotion: expects emotion vs does not expect emotion)


x interaction
To test the hypothesis, a 2 (expectation of typical behaviour vs. no expectation of typical behaviour) by 2 (victim emotionally expressive vs. victim not emotionally expressive) ANOVA was conducted. A significant two-way interaction with a moderate effect size was noted, (F(1, 133) = 5.43, p <.05, partial eta squared = .04).
F(1, 133) = 5.43, p = .02130 will be no difference in credibility judgements between an emotionally expressive victim and a victim who is not emotionally expressive. 
Klippenstine & Schuller (2012)
 While past research has not examined the impact of the victim's emotions at multiple points in time, it was expected that a complainant who responded consistently over time, regardless if that response was tearful/upset or calm/controlled, would be more likely to be believed than a complainant who responded inconsistently.
2 (victim emotion day after event: upset vs calm) x 2 (victim emotion at trial: upset vs calm)


Both simple effects
Simple main effects revealed that when the complainant was tearful/upset the day following the assault, participants were more likely to believe her claim of rape when she was also tearful/upset during her testimony compared to when she was calm/controlled at trial. Specifically the complainant's claim of non-consent was more believable, F(1,120) = 4.00, p =0.048, eta squared = 0.07, F(1, 120) = 4.00, p = .04776 a 
Winkel & Koppelaar (1991)
 We hypothesise that rape victims whose selfpresentation is emotional run less risk of secondary victimisation by the environment than do those victims whose selfpresentation is numbed.
2 (victim emotional state: numbed vs controlled) x 2 (participant ethnicity: Dutch vs Turkish)


Difference between means
The numbed victim was less often perceived as credible and more often blamed than the emotional victim. (Statistics provided in 
Table 2)
 F(1, 76) = 14.06, p = .00034 Alternate dependent variable (negative evaluation of complainant; victimizing reactions) F(1, 76) = 13.74, p = .00040
Note. a In Klippenstine & Schuller (2012), the second simple effect was non-significant and not reported in the original article. This does not impact the reliability of the p-curve as non-significant test statistics are excluded from p-curve analysis. b 
Calhoun et al. (1981)
 report the degrees of freedom for this analysis (a univariate ANOVA) as (5, 47) however, these degrees of freedom do not match the reported analysis for the design. If the degrees of freedom are adjusted to match the description of the study design and statistical test reported (i.e., 1, 47), and are included in the p-curve and robustness p-curves, the results of these analyses are unchanged and all p-curves remain significantly right skewed. Was the validity of the dependent variable measured reported? Note. a Cochrane bias definitions and criteria are drawn from  and 
Reeves et al. (2008)
. 
Wessel, Drevland, Eilertsen & Magnussen (2006)
 53
Experienced (Judges) Video 
Winkel & Koppelaar (1991)
 80 No experience (Students) Video
Note. * denotes unpublished works. 
Ask (2018)
 and 
Bohner & Schapansky (2018)
 were unpublished at the time of data analysis and subsequently were accepted for publication. Single item measure 1.00 25.0 (5) Reported reliability analysis 1.00 55.0 (11) Reported validity analysis -0.0 (0) Note. All studies were included in this analysis (N = 20). Number of studies to meet risk of bias criteria is reported in parentheses. 
0.0 (0) Note. Two studies were excluded from this analysis as no description of the behaviors used to operationalize complainant distress or controlled affect were provided (N = 18, n video = 12, n text = 6). Number of studies reported in parentheses.    
(2) Empirical (e.g., no opinion pieces or legal commentary)(3) Sampled adults (18 years of age and older) (4) Manipulated the emotional demeanor of a female adult complainant of sexual assault or rape (sexual intercourse without consent) (5) Measured perceptions of a female adult complainant of rape (i.e., perceived credibility of the witness)


Data extraction. A p-curve disclosure table was used to extract data to perform the p-curve analysis as recommended by Simonsohn et al. (2014a). The disclosure table identifies test statistics selected for inclusion in the p-curve from each article. The disclosure table requires meta-analysts to identify and extract the original research hypothesis of interest, study design, key statistical result testing the hypothesis, and the statement of this


Data extraction. The descriptions of the operationalization of complainant emotional demeanor and complainant credibility measures were extracted from full-text reports of included studies. For questionnaire items, sample items and scale anchors were extracted for coding.


to the criteria provided by
Simonsohn et al. (2015)
, if the half p-curve is significantly right skewed (p < .05) or the half and full p-curve are significantly right skewed (p < .10) then the p-curve indicates that the included studies have evidential value. The p-curve analysis suggested that the literature on included in the p-curve analysis had evidential value as both criteria were met.


based stimulus to manipulate complainant distress, half had the complainant describe herself as distressed or had another person describe the complainant as distressed. No video studies used this form of complainant behavior to operationalize distress.


. Motivational sources of confirmation bias in criminal investigations: the need for cognitive closure. Journal of Investigative Psychology and Offender Profiling, 2(1), 43-63. doi: 10.1002/jip.19 Ask, K., Granhag, P. A., & Rebelius, A. (2011). Investigators under influence: How social norms activate goal-directed processing of criminal evidence. Applied Cognitive Psychology, 25(4), 548-553. doi: 10.1002/acp.1724 *Ask, K., & Landström, S. (2010). Why emotions matter: Expectancy violation and affective response mediate the emotional victim effect. Law and Human Behavior, 34(5), 392-401. doi:10.1007/s10979-009-9208-6 Australian Bureau of Statistics. (2017). Personal Safety in Australia: Key Findings. Report retrieved from https://www.abs.gov.au/ausstats/abs@.nsf/Lookup/by%20Subject/4906.0~2016~Main %20Features~Key%20Findings~1 Bakker, M., van Dijk, A., & Wicherts, J. M. (2012). The rules of the game called psychological science. Perspectives on Psychological Science, 7(6), 543-554. doi:10.1177/1745691612459060 *Baldry, A. C. (1996). Rape victims' risk of secondary victimization by police officers. Issues in Criminological & Legal Psychology, 25, 65-68. *Baldry, A. C., & Winkel, F. W. (1998). Perceptions of the credibility and evidential value of victim and suspect statements in interviews. Psychology and Criminal Justice: International Review of Theory and Practice, 74-82.


. Beyond kappa: A review of interrater agreement measures. Canadian Journal of Statistics, 27(1), 3-23. doi:10.2307/3315487 Bédard, J., & Chi, M. (1992). Expertise. Current Directions in Psychological Science, 1, 135-139. Begg, C. B., & Mazumdar, M. (1994). Operating characteristics of a rank correlation test for publication bias. Biometrics, 50(4), 1088. doi: 10.2307/2533446 Bieneck, S., & Krahé, B. (2011). Blaming the victim and exonerating the perpetrator in cases of rape and robbery: Is there a double standard? Journal of Interpersonal Violence, 26(9), 1785-1797. doi:10.1177/0886260510372945 Bless, H., Strack, F., & Schwarz, N. (1993). The informative functions of research procedures: Bias and the logic of conversation. European Journal of Social Psychology, 23(2), 149-165. https://doi.org/10.1002/ejsp.2420230204 Bluett-Boyd, N., & Fileborn, B. (2014). Victim/survivor focused justice responses and reforms to criminal court practice. Canberra, Australia: Australian Institute of Family Studies. *Bohner, G., & Schapansky, E. (2018). Law students' judgments of a rape victim's statement: The role of displays of emotion and acceptance of sexual aggression myths.


Figure 2 .
2
Forrest plot with effect size estimate and confidence intervals for each study.


Figure 3 .
3
Plot of the distribution of p-values under .05 for published studies included in the p-curve analysis.


Figure 4 .
4
Funnel plot of effect size estimate and standard error for all studies included in the meta-analysis.


Figure 5 .
5
Funnel plot of effect size estimate and standard error for studies included in the meta-analysis and imputed through trim and fill analysis. White circles indicate imputed studies.


Table for
for
self-style is going to be
style of the man)
emotional style of
believed more readily than
x 2 (low vs high
communication, was
P-curve Analysis someone telling the same
empathy) factorial
confirmed (F(1, 122) =
story in a controlled way.
design
4.89, p < .05.
Original Article Baldry,
Quoted text from original
Study design
Key
Quoted text from original
Results
Robustness
article indicating
statistical
article with statistical
results
prediction of interest to
result
results
researchers
Ask & Landström
First, in line with previous
2 (cognitive load:
Difference
A 2 (target demeanor:
F(1, 185) =
(2010)
demonstrations, we
yes vs. no) x 2
between
emotional vs. neutral) x 2
11.45, p =
predicted that a rape
(target demeanor:
means
(cognitive load: yes vs. no)
.00087
victim who behaves in an
emotional vs.
analysis of variance
emotional manner would
neutral) factorial
(ANOVA) revealed a
be believed more readily
design
significant main effect of
than a victim who displays
target demeanor, F(1, 185)
little emotion (Hypothesis
= 11.45, p <.001, partial
1).
eta2 = .06. Thus, in line
with Hypothesis 1,
participants who watched
the emotional demeanor
were more certain (M =
64.42, SD = 22.01) that the
target person had been
raped than did those who
watched the neutral
demeanor (M = 54.36, SD
= 19.49).
Baldry (1996)
On the basis of what we
2 (emotional vs
Difference
Our first hypothesis that a
F(1, 122) =
have said, we then
controlled
between
woman reporting to the
4.89, p =
hypothesized: an alleged
woman) x 2
means
police that she had been
.02888
rape victim reporting to
(powerful vs
raped is believed more
the police in an emotional
powerless speech
when she uses an


Table 2
2
Adapted risk of bias criteria to assess internal validity in cross-sectional experimental psychology studies
Type of bias
Cochrane bias
Cochrane criteria for
Adapted criteria for
definition a
randomized
cross-sectional
controlled trials
experimental
psychology study
Selection bias
Bias present if there
What is the
Were participants
are systematic
procedure for
randomly allocated
differences between
sequence generation
to experiment
participants
and allocation
conditions?
allocated to each
concealment in the
group in trial
trial?
Performance bias
Bias present if there
Whether a procedure
Was a manipulation
is a problem with the
is used to
check used?
intervention fidelity
appropriately blind
participants,
Was the
intervention
manipulation
personnel and
effective?
outcome assessors to
trial condition?
Was a suspicion
probe used to assess
Whether other steps
realism of the
are taken to protect
simulated
internal validity?
testimony?
Detection bias
Bias present if there
Was the outcome
Was the reliability of
are problems in the
accurately assessed?
the dependent
assessment of
variable measured
outcomes
Were outcome
reported?
assessors blind to
trial condition?


Table 4
4
Number and proportion of studies to meet risk of bias assessment criteria
Type of bias
Adapted criteria
k
% of all studies to meet
criteria
Selection bias
Participants randomly
1.00
55.0
allocated to conditions
(11)
Performance bias Reported manipulation
.90
60.0
check
(12)
Manipulation check
.80
55.0
successful
(11)
Reported suspicion probe
1.00
25.0
(5)
Detection bias


Table 5
5
Behaviors used to operationalize complainant distress and controlled affect in all studies
Complainant
Complainant behavior in
k
% of all
% of video
% of text
emotional
stimulus
studies
stimulus
stimulus
state
which use
studies
studies
behavior
which use
which use
behavior
behavior
Distressed
Crying
1.00
94.4
91.7
100.0
(17)
(11)
(6)
Trembling voice
1.00
55.6
58.3
50.0
(10)
(7)
(3)
Hesitations in speech
1.00
55.6
66.7
33.3
(10)
(8)
(2)
Distressed facial
0.89
44.4
58.3
16.7
expression
(8)
(7)
(1)
Struggling to maintain
1.00
44.4
58.3
16.7
control
(8)
(7)
(1)
States or another states
1.00
16.7
0.00
50.0
victim was distressed
(3)
(0)
(3)
Avoiding eye contact
1.00
11.1
8.33
16.7
(2)
(1)
(1)
Speaking quietly
1.00
11.1
8.33
16.7
(2)
(1)
(1)
Shock
1.00
5.56
8.33
0.0
(1)
(1)
(0)
Controlled
Factual manner
0.89
55.6
83.3
0.0
(10)
(10)
(0)
Steady voice
1.00
27.8
25.0
33.3
(5)
(3)
(2)
Confident
0.86
27.8
33.3
16.7
(5)
(4)
(1)
Maintained eye contact
1.00
5.6
8.3
0.0
(1)
(1)
(0)
Hushed voice
1.00
5.6
8.3
(1)








No experience (Students) Text 
Table 6
 Item content for complainant credibility measures in all studies Item type Credibility measure contained an item about k % of all studies with item Face valid items Believability 1.00 50.0 (10) Credibility 1.00 45.0 (9) Truthfulness 1.00 30.0 (6) Hiding truth 1.00 10.0
(2) Honesty 1.00 5.00
(1) Accuracy 1.00 5.00
(1) Other constructs Perpetrator blame or punishment or guilt 1.00 20.0 (4) Complainant distress 1.00 10.0 (2) Decision confidence 1.00 10.0
(2) Note. All studies were included in this analysis (N = 20). Number of studies with item reported in parentheses. Full-text reports assessed for eligibility (n = 67)
Full-text reports excluded (n = 47)
Studies included in meta-analysis (n = 20)
Studies included in p-curve analysis (n = 9)
Studies excluded, with reasons (n = 11)
 










Perceptions of stranger and acquaintance rape: The role of benevolent and hostile sexism in victim blame and rape proclivity




D
Abrams






G
T
Viki






B
Masser






G
Bohner




10.1037/0022-3514.84.1.111






Journal of Personality and Social Psychology




84


1
















Creating a more complete and current picture: examining police and prosecutor decision-making when processing sexual assault cases




M
A
Alderden






S
E
Ullman




10.1177/1077801212453867






Violence Against Women




18


5
















Individual differences and attitudes toward rape: A meta-analytic review




K
B
Anderson






H
Cooper






L
Okamura




10.1177/0146167297233008






Personality and Social Psychology Bulletin




23


3
















Men's perceptions of an acquaintance rape: The role of relationship length, victim resistance, and gender role attitudes




D
J
Angelone






D
Mitchell






L
Grossi




10.1177/0886260514552448






Journal of Interpersonal Violence




30


13
















Effects of justification and a mechanical aid on judgment performance




R
H
Ashton




10.1016/0749-5978(92)90040-E






Organizational Behavior and Human Decision Processes




52


2
















A survey of police officers' and prosecutors' beliefs about crime victim behaviors




K
Ask




10.1177/0886260509340535






Journal of Interpersonal Violence




25


6
















Complainant emotional expressions and perceived credibility: Exploring the role of perceivers' facial mimicry and empathy




K
Ask




10.1111/lcrp.12132






Legal and Criminological Psychology




23


2
















Credibility of the emotional witness: A study of ratings by police investigators




G
C
Bollingmo






E
O
Wessel






D
E
Eilertsen






S
Magnussen




10.1080/10683160701368412






Psychology, Crime & Law




14


1
















The effect of biased and non-biased information on judgments of witness credibility




G
Bollingmo






E
Wessel






Y
Sandvold






D
E
Eilertsen






S
Magnussen




10.1080/10683160802131107






Psychology, Crime & Law




15


1
















Accuracy of deception judgments




C
F
Bond






B
M
Depaulo




10.1207/s15327957pspr1003_2






Personality and Social Psychology Review




10


3
















Introduction to meta-analysis




M
Borenstein






L
V
Hedges






J
P T
Higgins






H
R
Rothstein








John Wiley & Sons


Ltd












The ecological validity of jury simulations: Is the jury still out?




B
H
Bornstein








Law and Human Behavior




23


1
















Jury simulation research: Pros, cons, trends, and alternatives




B
H
Bornstein




M
















The psychology of juries


B. Kovera


Washington, DC




American Psychological Association














Mock juror sampling issues in jury simulation research: A metaanalysis




B
H
Bornstein






J
M
Golding






J
Neuschatz






C
Kimbrough






K
Reed






C
Magyarics






K
Luecht




10.1037/lhb0000223






Law and Human Behavior




41


1
















Attributions of responsibility for date and stranger rape




J
Bridges






C
Mcgrail




10.1007/BF00289907






Sex Roles




21


3-4
















The Witness Credibility Scale: An outcome measure for expert witness research




S
L
Brodsky






M
P
Griffin






R
J
Cramer




10.1002/bsl.917






Behavioral Sciences & the Law




28


6
















Characteristics associated with rape attrition and the role played by skepticism or legal rationality by investigators and prosecutors




J
M
Brown






C
Hamilton






D
Neill




10.1080/10683160601060507






Psychology, Crime & Law




13


4
















p-Curve and p-Hacking in observational research




S
B
Bruns






J
P A
Ioannidis




10.1371/journal.pone.0149144






PLoS ONE




11


2


149144














Rape and its impact on the victim




A
W
Burgess






C
M
Carretta








Practical Aspects of Rape Investigation: A Multidisciplinary Approach


R. R. Hazelwood & A. W. Burgess


United States




Taylor and Francis
















Rape trauma syndrome




A
W
Burgess






L
L
Holmstrom








American Journal of Psychiatry




131


9
















Adaptive strategies and recovery from rape




A
W
Burgess






L
L
Holmstrom








Coping with Life Crises: An Integrated Approach


R. H. Moos






















M
A
Boston






Springer US












Victim emotional response: Effects on social reaction to victims of rape




L
G
Calhoun






A
Cann






J
W
Selby






D
L
Magee




10.1111/j.2044-8309.1981.tb00468.x






British Journal of Social Psychology




20


1
















Evaluating the replicability of social science experiments in Nature and Science between




C
F
Camerer






A
Dreber






F
Holzmeister






T
H
Ho






J
Huber






M
Johannesson






.
.
Altmejd






A








Nature Human Behavior




2


9
















The role of work experience and individual beliefs in police officers' perceptions of date rape: An integration of quantitative and qualitative methods




R
Campbell




















10.1007/BF02506938






American Journal of Community Psychology




23


2














Symptom responses to a continuum of sexual trauma




C
Carretta






A
Burgess




10.1891/0886-6708.vv-d-12-00011






Violence and Victims




28


2
















Men's acquaintance rape scripts: A comparison between a regional university and a military academy




M
H
Carroll






M
D
Clark




10.1007/s11199-006-9102-3






Sex Roles




55


7-8
















Heuristic versus systematic information processing and the use of source versus message cues in persuasion




S
Chaiken








Journal of Personality and Social Psychology




39


5
















Communication modality as a determinant of message persuasiveness and message comprehensibility




S
Chaiken






A
H
Eagly




10.1037/0022-3514.34.4.605








Journal of Personality and Social Psychology




34


4
















Communication modality as a determinant of persuasion: The role of communicator salience




S
Chaiken






A
H
Eagly




10.1037/0022-3514.45.2.241








Journal of Personality and Social Psychology




45


2
















A theory of heuristic and systematic information processing




S
Chaiken






A
Ledgerwood








A handbook of theories of social psychology


P. A. M. V. Lange, A. W. Kruglanski, & E. T. Higgins


London




SAGE Publications














Heuristic and systematic information within and beyond the persuasion context




S
Chaiken






A
Liberman






A
H
Eagly








Unintended thought


J. S. Uleman & J. A. Bargh


New York




Guilford Press
















Heuristic processing can bias systematic processing: Effects of source credibility, argument ambiguity, and task importance on attitude judgment




S
Chaiken






D
Maheswaran




10.1037/0022-3514.66.3.460








Journal of Personality and Social Psychology




66
















The seven deadly sins of psychology




C
Chambers








Princeton University Press


New Jersey












The heuristic-systematic model in its broader context




S
Chen






S
Chaiken








Dual-process theories in social psychology




Guilford Press
















Statistical power analysis for the behavioral sciences




J
Cohen








Lawrence Erlbaum Associates


Hillsdale, New Jersey






2nd ed.








A power primer




J
Cohen




10.1037/0033-2909.112.1.155






Psychological Bulletin




112


1
















Violence against women: Additional analysis of the Australian Bureau of Statistics Personal Safety Survey, 2012. Australia's National Research Organisation for Women's Safety: Sydney




P
Cox


















Displayed emotions and witness credibility: A comparison of judgements by individuals and mock juries




J
Dahl






I
Enemo






G
C B
Drevland






E
Wessel






D
E
Eilertsen






S
Magnussen




10.1002/acp.1320






Applied Cognitive Psychology




21


9
















Rape and attrition in the legal process: A comparative analysis of five countries




K
Daly






B
Bouhours




10.1086/653101






Crime and Justice




39


1
















Improving police officers' perceptions of sexual offending through intensive training




E
Darwinkel






M
Powell






P
Tidmarsh




10.1177/0093854813475348






Criminal Justice and Behavior




40


8
















Effects of victim gender, victim sexual orientation, victim response and respondent gender on judgements of blame in a hypothetical adolescent rape




M
Davies






P
Rogers






L
Whitelegg




10.1348/978185408X386030






Legal and Criminological Psychology




14


2
















Cochrane handbook for systematic reviews of interventions




J
Deeks






J
Higgins






D
G
Altman




J. Higgins & S. Green






John Wiley & Sons




Chichester, United Kingdom






Analysing data and undertaking metaanalyses








Cues to deception




B
M
Depaulo






J
J
Lindsay






B
E
Malone






L
Muhlenbruck






K
Charlton






H
Cooper




10.1037/0033-2909.129.1.74






Psychological Bulletin




129


1
















Illuminations and shadows from jury simulations




S
S
Diamond








Law and Human Behavior




21


5
















Trim and fill: a simple funnel-plot-based method of testing and adjusting for publication bias in meta-analysis




S
Duval






R
Tweedie








Biometrics




56


2
















A nonparametric "trim and fill" method of accounting for publication bias in meta-analysis




S
Duval






R
Tweedie




10.1080/01621459.2000.10473905






Journal of the American Statistical Association




95


449
















A judge's review of juror misconduct




H
D
Edwards








Howard Law Journal




27
















Bias in meta-analysis detected by a simple, graphical test




M
Egger






G
D
Smith






M
Schneider






C
Minder




10.1136/bmj.315.7109.629






BMJ




7109
















On the universality and cultural specificity of emotion recognition: A meta-analysis




H
A
Elfenbein






N
Ambady




10.1037/0033-2909.128.2.203






Psychological Bulletin




128


2
















Reacting to rape: Exploring mock jurors' assessments of complainant credibility




L
Ellison






V
E
Munro




10.1093/bjc/azn077






British Journal of Criminology




49


2
















Schema effects of rape myth acceptance on judgments of guilt and blame in rape cases: The role of perceived entitlement to judge




F
Eyssel






G
Bohner




10.1177/0886260510370593






Journal of Interpersonal Violence




26


8
















The making of an expert detective: the role of experience in English and Norwegian police officers' investigative decision-making




I
Fahsing






K
Ask




10.1080/1068316X.2015.1077249






Psychology, Crime & Law




22


3
















Rape as viewed by judges, prosecutors, and police officers




S
Feldman-Summers






G
Palmer




10.1177/009385488000700103








Criminal Justice and Behavior




7


1
















Social reactions to sexual assault victims from various support sources




H
H
Filipas






S
E
Ullman








Violence and Victims




16


6
















Gender differences in emotion perception and self-reported emotional intelligence: A test of the emotion sensitivity hypothesis




A
H
Fischer






M
E
Kret






J
Broekens




10.1371/journal.pone.0190712






PLoS ONE




1


13














Construct validation in social and personality research




J
K
Flake






J
Pek






E
Hehman




10.1177/1948550617693063






Social Psychological and Personality Science




8


4
















Sexual offences in England and Wales: Year ending




J
Flatley














London: Office for National Statistics: London








Discrediting victims' allegations of sexual assault: Prosecutorial accounts"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]