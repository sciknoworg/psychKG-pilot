You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Abstract: Background: Human learning unfolds under uncertainty. Uncertainty is heterogeneous with different forms exerting distinct influences on learning. While one can be uncertain about what to do to maximize rewarding outcomes, known as policy uncertainty, one can also be uncertain about general world knowledge, known as epistemic uncertainty. In complex and naturalistic environments such as the social world, adaptive learning may hinge on striking a balance between attending to and resolving each type of uncertainty. Prior work illustrates that people with anxiety-those with increased threat and uncertainty sensitivity-learn less from aversive outcomes, particularly as outcomes become more uncertain. How does a learner adaptively trade-off between attending to these distinct sources of uncertainty to successfully learn about their social environment? Methods: We developed a novel eye-tracking method to capture highly granular estimates of policy and epistemic uncertainty based on gaze patterns and pupil diameter (a physiological estimate of arousal). Results: These empirically derived uncertainty measures reveal that humans (N = 94) flexibly switch between resolving policy and epistemic uncertainty to adaptively learn about which individuals can be trusted and which should be avoided. However, those with increased anxiety (N = 49) do not flexibly switch between resolving policy and epistemic uncertainty, and instead express less uncertainty overall. Conclusions: Combining modeling and eye-tracking techniques, we show that altered learning in people with anxiety emerges from an insensitivity to policy uncertainty and rigid choice policies, leading to maladaptive behaviors with untrustworthy people.
Adaptive social functioning requires individuals to efficiently resolve a multitude of uncertainty signals when interacting with others, especially in repeated interactions in which our dynamics with others are constantly evolving 
[1]
[2]
[3]
[4]
[5]
. Imagine, for instance, deciding whether to have a cup of coffee with a friend whom you recently had a disagreement with. In such scenarios, one may focus on reducing policy uncertainty 
[6]
-figuring out which set of actions produce desirable outcomes (i.e., what should I do?). You might weigh the relative costs and benefits of talking to your friend: would meeting for coffee allow both parties to settle their disagreement, or conversely would interacting simply escalate the conflict? To resolve policy uncertainty, one might rely on a prior history of observed outcomes to reach a decision. One can also focus on resolving epistemic uncertainty 
[7,
8]
-acquiring detailed information about others for the sake of knowledge. For example, a learner may also be motivated to gather additional information about their friend, either directly or indirectly, to estimate the exact value (i.e., benefits) of meeting for coffee. While this type of value-based knowledge can increase the precision of one's beliefs 
[8,
9]
, acquiring detailed epistemic knowledge is cognitively taxing 
[7,
10]
 and may not always offer additional benefit for optimizing outcomes 
[11]
.
While efficiently resolving each uncertainty signal provides distinct advantages for learning, overreliance on one signal at the expense of another can maladaptively bias behavior. If we focus too much on minimizing policy uncertainty, our behavior might become too rigid, and we may not learn sufficient information that would allow us to generalize across contexts 
[12,
13]
. If we focus too much on reducing epistemic uncertainty, we might end up investing too many resources gathering irrelevant information, which can ultimately slow learning 
[7,
10]
. While it appears people can strike a delicate balance between optimizing rewarding outcomes and gathering additional knowledge when the opportunity arises, it is unknown how humans effectively manage such tradeoffs.
Reinforcement Learning (RL) frameworks elegantly illustrate this learning dichotomy. While value-based (e.g., Q-learning) models iteratively learn the expected values of each action 
[14,
15]
a form of epistemic knowledge, policy-based models (e.g., actor-critic) directly optimize choice policies that maximize rewards without explicitly learning the expected values 
[15]
[16]
[17]
[18]
[19]
. Although both strategies facilitate learning, it is often more expedient to directly optimize a policy by identifying the best set of actions, given that value-based methods exhibit slowed convergence to reliable expected values 
[12,
20]
. And yet, solely relying on policy optimization can prevent people from gathering value-based information which can be highly useful if one suddenly needs to transfer knowledge to a novel problem 
[12,
13]
. The tension between policy optimization and value-based learning is also observed in classic explore-exploit tradeoffs 
[10,
21]
. Across species and circumstances, agents are often confronted with the dilemma of repeating tried and true choices, or selecting a new option which could provide useful information and potentially better outcomes. Thus, despite the efficiency of policy-optimization, humans should also assign utility to epistemic knowledge 
[11,
[21]
[22]
[23]
-especially in the social world where epistemic information can help learners distinguish between the value of others 
[4,
24]
.
The distinct advantages associated with reducing policy and epistemic uncertainty suggests adaptive behavior may indeed emerge from a combination of policy optimization and value-based learning strategies 
[25,
26]
. Yet, how these strategies are combined to guide learning remains largely unknown 
[27]
. One way to effectively manage this inherent tension is by dynamically orienting attention towards value or policy-based information as new task demands arise 
[28]
, such that information sampling patterns might unveil how distinct uncertainty signals are directly prioritized for learning 
[29]
[30]
[31]
.
In the current study we test the hypothesis that adaptive social learning is characterized by flexible and frequent attention switching between policy and epistemic information to regulate learning rates. Specifically, we evaluate whether people first reduce policy uncertainty to improve task performance, and then flexibly switch to gathering value-based information to further minimize epistemic uncertainty. This requires tracking subjective experiences of policy and epistemic uncertainty in real time as people manage these competing demands. Prior work suggests eye movements can provide a reliable readout of uncertainty 
[32,
33]
, revealing what information is being attended to-i.e., expected values or information related to the choice policy 
[34,
35]
. Moreover, using gaze patterns to measure uncertainty offers the advantage of sidestepping issues with existing measures 
[36,
37]
 which constrain the granularity of subjective uncertainty estimates to a single point estimate (Likert scales), and thereby omit critical details about the degree and type of uncertainty experienced. Given that fluctuations in uncertainty are also accompanied by increased physiological arousal 
[38]
[39]
[40]
, we can further index pupil-based arousal to the rate of learning adjustment 
[41]
[42]
[43]
[44]
.
Finally, we also explore whether increased uncertainty sensitivity disrupts one's ability to leverage policy and epistemic uncertainty to effectively guide learning. It is well known that individuals with increased trait anxiety experience increased distress and intolerance towards uncertainty 
[45]
[46]
[47]
[48]
[49]
, and this hypersensitivity may impact one's ability to swiftly adjust behavior in uncertain environments 
[42,
[50]
[51]
[52]
. Although prior work hints that anxious individuals fail to expediently adjust their behavior when policy uncertainty increases 
[52]
, altered learning could potentially emerge because anxious individuals invest disproportionate cognitive resources gathering social knowledge. Given that the coupling between uncertainty and physiological arousal is blunted in people with increased anxiety 
[42]
, we can additionally leverage gaze patterns and pupillometry to directly test whether failures in tracking policy or epistemic uncertainty impinge on learning.
In the current research we construct empirically-derived estimates of policy and epistemic uncertainty from gaze patterns, allowing us to examine how individuals direct their attention towards policy and epistemic uncertainty signals as social interactions unfold. To dissociate between policy and epistemic uncertainty, we implement a novel eye-tracking procedure in which participants indicate trial-level predictions about another's trustworthiness using their eye gaze. We find that task performance is predicted by how quickly an individual first resolves policy uncertainty and is then able to flexibly switch to resolving residual value-based epistemic uncertainty. Adaptive switching is yoked to how much a partner's behavior changes during the task (i.e., becoming increasingly untrustworthy) and is reflected in pupil-based arousal. However, the behavioral and physiological fingerprint of flexibly switching between resolving different types of uncertainties is altered in highly anxious individuals. We fit a Bayesian RL model which further reveals that people with increased anxiety are slower to adjust their behavior as partners become increasingly untrustworthy because of a tendency to perseverate on prior reward history, even when learned values no longer reflect the statistics of the environment. We find that reduced behavioral adjustment to untrustworthy partners is related to optimistic beliefs that partners will return a greater sum of the investment. Finally, when partners are untrustworthy, highly anxious individuals express less policy uncertainty, as assessed via both gaze-and model-derived measures.


Methods and Materials
Participants. Participants (N = 100, Nfemale = 47, Nmale = 53, mean age = 20.41) were recruited from the subject research pool (SONA) managed by the Cognitive and Psychological Sciences Department at Brown University in Providence, Rhode Island. All participants received either monetary compensation ($15/hour) or course credit, including additional performance-based bonus payment of up to $20. Six participants were excluded from final analyses because they did not adequately perform the task (i.e., no behavioral variability in the choice data) or due to poor gaze and pupil readout from the eye-tracker, resulting in a final sample of 94 participants.
Evaluating Anxiety. Participants were grouped as a function of low and high anxiety levels based on their responses from the Generalized Anxiety Disorder Scale (GAD-7) and the State-Trait Anxiety Inventory (STAI; see Supplement for distribution of anxiety scores). Our low and high anxiety groups are based on established clinical guidelines, in which a score of 10+ on the GAD-7 scale 
[53,
54]
 and a score of 40+ on the trait component of the STAI scale 
[55]
 are reliable predictors of pathological anxiety (i.e., disruptive to one's daily functioning and well-being). For our statistical analyses of group differences, participants were placed into the high anxiety group if they were above the significance cutoff on one or both anxiety inventories, and into the low anxiety group if they were below the cutoff on both the GAD-7 and STAI scale (see Supplement for behavioral analyses using continuous anxiety scores). Based on these criteria, our sample was split into roughly evenly sized high and low anxiety groups (Nlow anxiety = 45, Nhigh anxiety = 49). Note, assessed anxiety levels in our study does not evaluate whether participants meet the criteria for a DSM-5 generalized anxiety disorder.
Task design. Participants completed 96 trials of the Dynamic Trust Game based on the task design developed in our prior work 
[52]
, and interacted with three distinct partners that varied in their trustworthiness. Unbeknownst to participants, their partners were preprogrammed, slowly drifting in their reward rate over the course of the task, thereby requiring participants to continually adjust their choice policy to optimize rewards, the amount of money a partner reciprocated back to the participant ( 
Fig. 1
, A to B; see Supplement for details). The task consisted of two distinct trial types that influenced which type of uncertainty should be more salient at a particular moment. Adjust Policy trials occur when the amount of money returned by the partner has just crossed the outcome boundary 
(Fig. 1C)
. On these trials, one's prior choice policy no longer maximizes their earnings, which naturally increases policy uncertainty until the policy is revised. In contrast, Exploit Policy trials comprise trials where we expect learning to have stabilized (i.e., at the end of a window in which partners were consistently trustworthy or untrustworthy). In these time windows, participants have generally learned the optimal choice policy, and can therefore use this opportunity to resolve residual epistemic uncertainty about partners. Critically, Adjust and Exploit Policy trials were crossed with reward and loss blocks (i.e., when partners were trustworthy or untrustworthy, respectively) to dissociate the effects of policy reliability and outcome valence on behavior (see Supplement for in-depth task details).  Gaze measures of uncertainty. To obtain trial-level estimates of uncertainty, we asked participants to predict their partner's behavior (amount of money reciprocated) before observing trial outcomes 
(Fig. 1D
). Participants indicated their predictions using a response bar which displayed all possible monetary returns given the amount invested 
(Fig. 1E)
. A blue dot on the screen corresponded to the participant's gaze, allowing participants to lock in their predictions of how much money their partners would return by moving the blue dot with their eyes to the predicted monetary outcome. This enabled us to use gaze patterns to evaluate participants' trialby-trial expectations, and their experienced uncertainty about anticipated outcomes which is thought to govern the rate of learning. Thus, by leveraging gaze patterns we derived distinct policy and epistemic uncertainty estimates (see details below). Further, if individuals flexibly switch between resolving policy and epistemic uncertainty, then this attentional reorientation should also be reflected in physiological correlates of arousal. To quantify trial-level estimates of physiological arousal, we measured the % change in pupil diameter (PD) from baseline at the time of feedback ( 
Fig. 1D
; see Methods).
To estimate policy uncertainty, we borrowed insights from prior computational models that adjust learning as a function of policy uncertainty, quantified by entropy (H), over choice probabilities 
[6]
 which reliably captures human choice data in the current task 
[52]
. We derived an analogous measure of policy uncertainty based on gaze patterns, quantified by computing the entropy of the proportion of gazes on either side of the outcome boundary (H-gaze; see Supplement for entropy computation details). The midpoint-which we refer to as the outcome boundary-is not explicitly marked but acts as a psychological boundary indexing whether participants expect to earn or lose money on the current trial, thus determining whether they should invest or not 
(Fig. 1E
). An increase in gaze fixations on both sides of the boundary indicates greater uncertainty about the optimal choice policy and should thus increase learning rates. However, even when one might be relatively certain about what they should do in the task (e.g., invest maximally or minimally), they may still experience residual uncertainty about the specific outcomes on a given trial (i.e., exactly how much their partner will return), motivating the pursuit of epistemic knowledge. Epistemic uncertainty about how much money would be returned was quantified as the standard deviation in gaze patterns over the range of outcomes (EU-gaze), which captures the precision of one's predictions. See example mappings between gaze-trajectories and uncertainty estimates for a prototypical participant in 
Fig. 2A
. Eye-tracking procedures and preprocessing steps are detailed in the Supplement.


Results


People dynamically reorient their attention towards policy and epistemic uncertainty signals.
Using our gaze-derived uncertainty measures, we examined whether knowledge about the optimal policy (i.e., invest minimally or maximally) captures the expression of distinct sources of uncertainty. H-gaze was significantly greater on trials with sub-optimal investments (i.e., choices that were inconsistent with the optimal choice policy) compared to optimal investments (t = -8.05, p < .001). In contrast, epistemic uncertainty, EU-gaze, was greater on trials in which participants selected the optimal response, suggesting participants instead expressed uncertainty about exact monetary outcomes once they knew the optimal choice policy (t = 7.07, p < .001; Supplement, 
Fig. S1
). We next tested whether the physiological expression jof policy and epistemic uncertainty depends on policy reliability (i.e., whether one can exploit or must adjust their current policy) and the trustworthiness of their partner. We observed just this: policy uncertainty was greater during the Adjust Policy trials (main effect of trial type: t = 4.47, p < .001), whereas epistemic uncertainty was greater during the Exploit Policy trials (main effect of trial type: t = -2.89, p < .001; uncertainty type × trial type interaction t = 4.82, p < .001; 
Fig. 2B
-C). Moreover, participants expressed greater policy and epistemic uncertainty when partners were untrustworthy (main effect of outcome valence on H-gaze: t = 12.94, p < .001; and EU-gaze: t = 8.44, p < .001), suggesting participants experienced more uncertainty about what to do when partners were selfish, and were more motivated to gather precise knowledge about untrustworthy people. In sum, although expressed policy and epistemic uncertainty were correlated (t = 30.29, p < .001), we also observed that policy and epistemic uncertainty signals are dissociable when choice policies need to be adjusted.
As an independent validation of the mappings between our theoretically informed gaze metrics and task demands, we evaluated the role of model-free gaze signatures that are analogous to Hgaze and EU-gaze calculations. Using the pattern of eye-movements from the prediction phase, we quantified the number of times the participant's gaze traversed the midpoint of predicted outcomes on each trial. Indeed, the number of switches across the outcome boundary increased during Adjust Policy trials (t=5.57, p < .001), and when partners were untrustworthy (t = 9.50, p < .001), recapitulating H-gaze patterns 
(Fig. 2D
). Information sampling patterns should also vary as participants adeptly learn to predict their partner's behavior, particularly during Exploit Policy trials when choice policies are presumably optimized. Specifically, as participants learn to anticipate their partner's return, they may be motivated to expediently gather information and refine their predictions, thus the rate of sampling may increase during periods of optimized behavior. To test this, we computed the sampling rate (values sampled/sec) as a model-free metric of information sampling expediency. Consistent with this hypothesis, the sampling rate was greater during Exploit versus Adjust trials (t = -2.14, p < .032; 
Fig. 2D
), indicating that the way participants sample information in the task is indeed sensitive to policy reliability, recapitulating our epistemic uncertainty findings. Thus, simple, model-free gaze signatures reliably capture uncertainty about whether anticipated outcomes are worth the investment (policy uncertainty; 
Fig.  2E
) but also how participants accumulate additional knowledge about specific outcomes when choice policies are already optimized (epistemic uncertainty). Anxiety impacts the ability to detect policy uncertainty. Individual variability in tolerance of uncertainty is likely to impact how humans attend to and expediently resolve uncertainty signals. Replicating our prior results 
[52]
, we observed that highly anxious participants invested significantly more money on loss blocks (i.e., when partners were untrustworthy) compared to the low anxiety group (untrustworthy-start partner: valence × group interaction, t = 2.21, p = 0.027; neutral-start partner: valence × group interaction, t = 2.18, p = 0.030; trustworthy-start partner: valence × group interaction, t = 2.05, p = .040; 
Fig. 3A
), resulting in greater monetary losses (valence × group interaction: t = -2.51, p = 0.012; 
Fig 3B)
. We next tested whether investments with untrustworthy partners were accompanied by the belief partners were indeed trustworthy. This hypothesis diverges from social signaling accounts which would predict continued investment, despite having knowledge that partners will not reciprocate-a mechanism for restoring trust. Predicted outcomes derived from gaze measures indicated that high anxiety participants also expressed more optimistic beliefs about partner returns, particularly when their partners were untrustworthy (valence × group interaction: t = 3.16, p = .002; 
Fig. 3C
). Thus, our findings suggest that altered learning profiles do not emerge from a desire to restore trust, but rather, from biased beliefs that partners will reciprocate.


Figure 2. Expressions of uncertainty dynamically adjust with changing task demands. A. Example gaze trajectories. Panels show gaze trajectories from prototypical participant trials. High policy uncertainty was characterized by increased switching across the outcome boundary, whereas high epistemic uncertainty trials were characterized by greater dispersion of eye movements. B. Gaze-derived measures of uncertainty. Epistemic and policy uncertainty estimates
We next evaluated whether anxiety impacts how effectively individuals resolve uncertainty when learning about others. To formally capture the relative weighting between policy and epistemic uncertainty, we quantified the relative difference between gaze-derived policy and epistemic uncertainty estimates on each trial (ε-gaze = H-gaze -EU-gaze), yielding a signed variable that indicates whether policy or epistemic uncertainty dominates at that moment (+ε-gaze: H-gaze greater; -ε-gaze: EU-gaze greater). Comparing ε-gaze differences between high and low anxiety groups, we find that the low anxious group was more unsure of the optimal choice policy when partners were untrustworthy and conversely expressed greater uncertainty about precise values (epistemic knowledge) with trustworthy partners valence × group interaction: t = -2.16, p = 0.031; 
Fig. 3D
). This indicates that low anxiety participants differentially prioritize which type of uncertainty signal to resolve depending on their partner's trustworthiness. Although high anxiety participants expressed a similar profile, valence-dependent expressions of uncertainty did not reach statistical significance.


Figure 3. Impact of anxiety levels on expressions of uncertainty and pupil-based arousal.
A. Mean investment differences across anxiety groups. The high anxiety group invested significantly more money with partners that were untrustworthy leading to greater monetary losses compared to the low anxiety group. Asterisks correspond to valence × group interaction effect for each partner type. B. Net earnings across anxiety level. High anxiety participants lost significantly more money when interacting with untrustworthy partners (loss trials) compared to the low anxiety group. Groups did not differ on earnings when partners were trustworthy. *pint denotes the interaction effect between anxiety level and outcome valence. C. Predicted earnings from gaze by anxiety level. In addition to investing more money with untrustworthy partners, high anxiety participants also expressed more optimistic beliefs about the amount of money that would be returned on loss trials. D. Uncertainty difference by anxiety level. Low anxiety participants expressed greater epistemic uncertainty with trustworthy partners, and greater policy uncertainty with untrustworthy partners. In contrast, high anxiety participants exhibited reduced valenceasymmetric expressions of uncertainty. *pint denotes the interaction effect between anxiety level and outcome valence where the effect of valence on ε-gaze only reaches statistical significance in the low anxiety group. E. Expressions of policy uncertainty from gaze. High anxiety participants expressed less policy uncertainty when interacting with untrustworthy partners compared to low anxiety participants, indicating reduced sensitivity to untrustworthy partners. *pint denotes the interaction effect between anxiety level and outcome valence. F. Pupil arousal and task demands. The low anxiety group showed increased arousal during Adjust Policy trials after partners changed their behavior, whereas the high anxiety group showed suppressed arousal when choice policies needed to be adjusted. Asterisks (*,**,***) denote p < .05, p < .01, p < .001, respectively. Errors bars indicate the standard error of the mean.
Next, we tested whether anxiety levels impacted the expression of distinct sources of uncertainty. Although both groups expressed greater policy uncertainty when interacting with untrustworthy partners (main effect of valence: t = 12.13, p < .001; 
Fig. 3E
), high anxiety participants expressed less policy uncertainty compared to the low anxiety group (valence × group interaction: t = -2.38, p = 0.017). Groups did not vary in their expressions of epistemic uncertainty. Collectively, these findings reveal key differences between high and low anxiety individuals: people with low anxiety exhibit distinct prioritization of uncertainty signals depending on their partner's trustworthiness, a process which is blunted in the high anxiety group. Further, high anxiety participants show reduced policy uncertainty about partners, suggested more entrenched policies when interacting with untrustworthy individuals. The tendency towards fixed policies (and thus reduced policy uncertainty) is mirrored by more optimistic beliefs, indicating that reduced sensitivity to policy uncertainty in the high anxiety group emerges in part from harder-to-undo beliefs once participants learn a partner is trustworthy.
Anxious individuals show blunted arousal to policy uncertainty. Two common threads emerge across our behavioral and gaze-based analyses. First, we find that highly anxious participants are slower to behaviorally adapt to increasingly untrustworthy partners. Second, we find that the relative expression of policy uncertainty is altered in anxious individuals, particularly in the loss domain. It remains unclear, however, whether slower adaptation to untrustworthy people occurs because anxious participants fail to detect policy uncertainty writ large or because they maladaptively respond to policy uncertainty. With the latter, maladaptive responding could be a function of persistently enhanced physiological arousal. To test these competing hypotheses, we compared the relative magnitude of pupil-linked arousal during feedback across Exploit versus Adjust Policy trials. As demonstrated in prior work, increased pupil-based arousal during feedback indexes the magnitude of surprise elicited from outcomes and the rate of learning adjustment 
[43]
. Thus, by linking distinct policy reliability periods with pupil-based arousal, we can identify the extent to which increased arousal serves as a distinct physiological update signal in high and low anxiety groups. Comparing arousal profiles, low anxiety participants demonstrated the predicted pattern of increased arousal after partners' behaviors crossed the outcome boundary, indicating that the choice policy should be updated, whereas highly anxious participants demonstrated reduced arousal during this same time period (trial type × anxiety level interaction: t = -3.13, p = .002; 
Fig. 3F
). These effects were further modulated by valence, such that the low anxiety group exhibited increased arousal when engaging with increasingly untrustworthy partners (policy period × valence interaction: t = 2.24, p = .025), whereas the high anxiety group generally reduced arousal when partners were untrustworthy (main effect of valence: t = -2.52, p = .012). Thus, the arousal pattern from our pupillometry measures suggests that reduced learning in the anxiety group arises, in part, from a failure to physiologically respond to unstable choice policies.
Computational modeling reveals asymmetric reductions in learning from social losses vs. rewards in the anxious group. Flexibly resolving policy and epistemic uncertainty guides successful learning in a dynamic environment-a process that is disrupted by anxiety. To examine the mechanistic link between these uncertainty signals and the rate of learning adjustment we used a computational modeling approach. We tested and compared three Bayesian Reinforcement Learning models (BRL; see Supplement). Our core model, Dynamic-BRL (DBRL), was developed in our prior work 
[52]
 in which trial-level beliefs are adjusted through outcome history. As a Bayesian learner accumulates evidence that a partner is (un)trustworthy, it becomes more confident in that belief. Thus, when a partner changes their behavior, such a model will overly rely on the history of prior outcomes 
[56,
57]
 . To capture how the effect of prior outcomes on posterior beliefs should be adjusted in a nonstationary environment, our dynamic Bayesian model leverages changes in policy uncertainty to modulate decay (i.e., forgetting). By dynamically decaying prior beliefs as policy uncertainty increases, one can prioritize learning from more recent outcomes and quickly accumulate evidence, allowing new choice policies to form. Thus, rather than assuming a constant probability of change at a fixed rate, decay increases when the agent becomes more uncertain about what to do, thereby balancing the tradeoff between stability and flexibility 
[6]
. In the model, policy uncertainty is calculated as the entropy, H, over the agent's choice probabilities, where p1 and p2 refer to the agent's probability of investing maximally ($10) or minimally ($1), respectively.
! = −[ " × # ( " ) − # × # ( # )]
Notably the analogous formulation of H was used to calculate our gaze-derived estimate of policy uncertainty, H-gaze (see Supplement). Gaze and model-derived H were positively correlated (t = 2.69, β = 0.036, p = 0.007), validating our assumption that H and H-gaze index uncertainty about one's current policy.
Consistent with our previous model for this task, decay was modeled separately for gains and losses ( $%& and '() respectively). We further deconstructed γ into a constant γ0 term (baseline beliefs about changeability) and a separate γ1 term to allow decay to further increase or decrease as a function of the learner's change in policy uncertainty from trial to trial, quantified by ΔH.
Note that in our prior work, we constrained " to negative values, reflecting the assumption that as policy uncertainty increases, prior values are decayed. In our current model, DBRL-2, we relaxed this assumption and allowed changes in policy uncertainty to either decay prior reward history or exert the opposite effect of preserving prior knowledge (see Supplement), allowing us to better capture the behavioral profile of anxious participants who show reduced learning when policy uncertainty increases. We tested and compared a set of four nested Bayesian Reinforcement Learning (BRL) models, three of which included additional " terms to dynamically adjust the decay rate (DBRL; see Supplement for details). Across both high and low anxiety groups, the DBRL-2 model best captures behavior (pxp > .99; 
Fig. 4B
, see Supplement for model comparison details), and could reliably reproduce participant choices (see MLE model simulation, 
Fig. 4A
). To validate that policy uncertainty estimates from the model (H) were generally consistent with our gaze-based policy uncertainty measures (H-gaze) we examined the overall profile of trial-level H patterns from the model. Mirroring the physiological gaze-based analyses 
(Fig. 2B)
, model-estimated H was greater during the Adjust versus Exploit Policy trials when choice policies need to be revised (t = 4.94, p < .001; 
Fig. 4C
). Further, model-estimated H also recovered valence-dependent policy uncertainty differences across high and low anxiety groups (valence × anxiety group interaction: t = 6.28, p < .001; 
Fig. 4D
). Specifically, model-estimated policy uncertainty was lower for losses in the high anxiety group, indicating less behavioral variability (i.e., perseveration) when partners are untrustworthy, recapitulating our gaze-based analysis 
(Fig. 3E
).
$%& = * !"# + " !"# • '() = * $%& + " $%& •
Figure
Comparing decay parameters from the winning DBRL-2 model, we observed a significant difference in baseline decay, * , across groups in the loss domain (valence × anxiety group interaction: t = -2.33, p = .0219; 
Fig. 4E
), revealing a learning asymmetry in the anxious group for gains vs. losses. Specifically, decay parameters in the high anxiety group reveal a tendency to disproportionately encode reward history while selectively forgetting the history of losses. This pattern of biased learning generates more precise and entrenched beliefs about a partner's trustworthiness which would consequently produce a pattern of overinvesting.


Discussion
Adaptively functioning in our social world requires integrating across multiple sources of uncertainty so we can expediently refine our beliefs and behaviors. We developed a novel eyetracking procedure premised on information sampling theories which granularly teases out distinct sources of uncertainty in real time, allowing us to evaluate how policy and epistemic uncertainty are differentially prioritized for learning. Our study reveals two key findings: People dynamically reorient their attention towards each source of uncertainty as social interactions unfold, and this attentional flexibility is critical for effectively adjusting one's behavior. In contrast, people with high anxiety show reduced attentional switching between different sources of uncertainty and reduced expressions of policy uncertainty-a signal which is crucial for policy optimization.
Further, while our findings dovetail with prior work showing that highly anxious people learn less from uncertain outcomes 
[42,
[50]
[51]
[52]
, we show that anxiety alters learning through a biased information filter. Specifically, by simultaneously measuring choice, predictions, and physiology, we find that anxious individuals disproportionately encode reward histories, leading to more rigid, optimistic beliefs and inflexible choice policies, particularly in the loss domain. These findings rule out a social signaling explanation, instead suggesting that the locus of maladaptive behavior in our task is rigid beliefs and policies that become insensitive to feedback. Critically, our findings show altered social learning profiles emerging from a reward-encoding bias, which diverges from long-standing threat sensitivity accounts of generalized anxiety 
[58,
59]
. While both perspectives converge on bias information processing and inflexible beliefs that ultimately result in maladaptive behavior, future work should investigate task environments and contexts that elicit altered reward versus threat processing. Along similar lines, a key element of our task design was evoking carefully controlled social rewards and threats through computerized agents which were perceived as believable to varying degrees among participants (see Supplement). Although post-task believability ratings did not significantly predict behavior, the use of social deception remains a fundamental limitation of the current design. Future work should aim to construct computerized agents which are indistinguishable from human partners, or to eliminate the use of deception.
Our study sample was also characterized by a high prevalence of generalized anxiety symptoms. High and low anxiety levels were determined from scores on the GAD-7 scale and the STAI Trait subscale. Within our final sample, approximately half of participant (N = 49, ~52%) indicated symptoms above clinical significance thresholds. Although reported anxiety levels in our study are higher than those observed in a general population (estimated prevalence ~25% 
[60]
), anxiety levels in the current study may be reflective of a unique combination of stressors. Recent highprofile reports have identified steeply increasing rates of mental illness among young adults and college-aged cohorts 
[61,
62]
-the primary demographic of the current study (ages 18-25, mean age: 20.4 years). One study 
[63]
 evaluating the prevalence of mental health disorders in undergraduates reported the majority of students were overwhelmed by their workload (~86%), and felt highly anxious day to day (~65%)-a pattern borne out across similar studies 
[64,
65]
. Thus, the combined effects of an age-skewed sample and academic stress may explain higher reported anxiety levels in our study. Further, we identified high anxiety levels using clinically recommended guidelines; however, it is worth noting that exceeding cutoffs on the GAD-7 or STAI Trait scale is not necessarily diagnostic of pathological anxiety. This highlights the need for increased clinical translation work and methodological innovation to identify when self-reported symptoms and altered learning profiles are associated with maladaptive, real-world beliefs and behavior.
Last, our eye-tracking procedure, which dissociates between different forms of uncertainty in realtime, allows us to evaluate whether altered learning might arise from individual variability in attending to distinct sources of uncertainty. While prior work speculates that reduced learning from losses in people with anxiety might arise from disrupted learning under uncertainty 
[42,
50,
51]
, here we explore the balance in learning from one specific type of uncertainty versus another. Specifically, our findings leave open the possibility that the balance between prioritizing distinct uncertainty signals may be reconfigured in anxiety disorders such that one source of uncertainty can be overly prioritized in the system (e.g., epistemic knowledge), leaving other forms of uncertainty, such as policy uncertainty, unresolved. Future work should consider how the functional utility of adjusting one's attention towards epistemic knowledge or adjusting one's policy might be governed by prefrontal systems (i.e., a hypothetical meta-critic) 
[12]
 conveying the prioritization of uncertainty signals to solve a particular problem, and how biases in this system might alter learning. This account leaves open a new perspective in computational psychiatry approaches towards understanding anxiety-based disorders-one in which disrupted learning and decision-making might reveal a divergent and heterogenous set of goals and motivations of the learner. 


Supplementary Methods
Participants. All recruited participants (N = 100) indicated informed consent prior to behavioral and eye-tracking data collection. The study protocol was approved by Brown University's Institutional Review Board. All participants indicated normal or corrected vision and no prior history of neurological injury that would impact gaze range.
Task stimuli. The task was presented using Psychtoolbox-3 for MATLAB. Prior to data collection, participants were instructed that they would be paired with three different online partners to play a game with, in real time. In actuality, partners were programmed agents set to return predetermined reward rates (see below). Participants were not given any prior knowledge about their partners' identity, such as gender, age, or geographical location. Each participant was assigned a username to represent their identity, which consisted to the first two letters of their first name, the first two letters of their last name, and two numbers of their choosing (e.g., OrFe95). Partner identifies were reciprocally displayed to participants as usernames, with the same three partner identities (AmLa55, KeJo93, JaSo47) assigned to each partner across experimental sessions. Each partner was represented as a distinctly colored avatar (blue, yellow or orange).
Task reward structure. Each partner was randomly assigned to a follow a pre-programmed and distinct outcome trajectory, starting out initially trustworthy, untrustworthy, or neutral and then gradually reversing over the course of the task 
(Fig. 1B)
. On each trial, partners were set up to return a fixed proportion of the invested money between 0-50% (e.g., 25%), with a uniform 5% noise interval around this return rate. For example, if the agent was set to return 25% of the initial investment, the computer randomly selected a value between 22.50-27.50%, which determined the actual amount on that trial. Trials with each partner type elapsed over alternating stable and drifting blocks, with each block consisting of 4 trials per partner type. During stable blocks, the mean return rate stayed fixed for the duration of the block (with some noise around the actual returns). In contrast, partners increased or decreased their mean return rate by 4% on each trial during drifting blocks, requiring participants to keep close track of their returns. On a subset of these drifting blocks, the partner's return rate crossed the 25% outcome boundary, such that they were now returning less than 25% or more than 25%. This change was thus consequential for participants because it would have required an adjustment in one's choice policy (i.e., strategically invest $1 or $10 with this partner) in order to maximize payoffs. Thus, we refer to these blocks as Adjust Policy trials. The experiment also consisted of trial blocks which we refer to as Exploit Policy trials, in which participants could continue using their current investment strategy with no consequence to their current payoffs (assuming they figured out the optimal choice), even if partners were drifting. This design therefore allowed us to fully cross partner outcome valence (i.e., whether trials resulted in net gains or losses) with partner stability so we could systematically examine their distinct effects on learning.
Task sequence. Participants completed 32 rounds of the Trust Game with each partner in rotating trial order (96 trials total), such that they interacted with each partner once every three trials 
(example trial ordering: 1,2,3,2,3,1,1,3,2,3,1,2)
. Pseudo-random trial ordering was chosen to reduce the temporal distance between exposures to each stimulus. A unique trial ordering was generated for each participant within the task program. Each trial consisted of four distinct phases: partner pairing, choice, prediction, and feedback. Behavioral data was collected during the choice phase, and physiological measurements were collected during prediction and feedback (see eyetracking section below). Partner pairing. At the onset of the partner pairing phase, participants were shown the identities of the three partners in a triangular configuration. To avoid task and vision fatigue, participants were given a "select partner" button placed in the center of the screen which initiated the trial sequence whenever participants were ready to begin. Note, participants were not given the option of selecting their partner (they were paired with a partner as described above). The purpose of the select partner button was to indicate when participants were ready to begin the trial, thus allowing for short rest periods between trials as needed. After the spacebar was pressed, there was a brief 2-4 sec. jittered delay while the computer "paired" participants with a partner.
Choice. During the choice phase, participants were shown two choice options, $1 and $10, presented in white boxes on the left and right side of the screen, respectively. Responses were selected using the "f" and "j" keys, with a decision deadline of 4 secs. If a response was not made within the 4 sec. time window, a "MISSED TRIAL" prompt appeared on the screen and participants were immediately taken to the feedback screen which indicated a $0 outcome.
Prediction. After the choice phase, participants indicated their beliefs about the current trial outcomes using a horizontal bar which filled the width of the screen 
(Fig. 1D)
. The bar served as a guide for indicating one's predictions and was marked with 5 equidistantly spaced monetary values. The minimum value on the prediction bar (furthest left) was always $0, as this was the lowest amount that could be returned to the participant, and the maximum value (furthest right) was either $2 or $20 depending on whether the participant invested $1 or $10, respectively. The midpoint on the bar, which we refer to as the outcome boundary, corresponded to exactly what the participant invested (i.e., $1 or $10), and thus represented a $0 net gain or loss. This partitioned the bar into two sections-the left side of the outcome boundary which displayed predicted monetary losses, and the right side which displayed predicted earnings. The intermediate monetary values on the response bar were evenly spaced intervals between the minimum and maximum values (e.g., $0, $0.50, $1.00, $1.50, $2.00).
Gaze-contingent display showed participants their gaze location in real time, which was indicated with a blue dot. Participants were instructed to align the blue dot to the point on the bar that was closest to the predicted trial outcome and were encouraged to also consider values in between the marked intervals. Once they were satisfied with the placement of the blue dot, they were instructed to hit the spacebar. Accuracy during the prediction phase was non-incentivized and there was no finite response deadline, allowing us to capture one's intrinsic motivation to precisely predict trial outcomes (i.e., reduce epistemic uncertainty).
Feedback. Following the prediction phase, participants were shown the outcome of the current trial. Before the actual outcome was displayed, the text displaying the numeric trial outcome was occluded (e.g., JaSo47 returned $XX.XX), for a 1 sec. duration, allowing us to measure pupil size at baseline before the trial outcome were presented. After the 1 sec. baseline calibration period, the filler text, $XX.XX, was replaced with the actual monetary outcome (e.g., JaSo47 returned $9.50), allowing us to control for luminance artifact in the pupil measurement when feedback was displayed. Pupil size was measured for a fixed 3 second period on each trial during which the trial outcome remained on the screen.
Eye-tracker and drift correction. Gaze location and pupil diameter were simultaneously measured using the Eyelink 1000 infrared camera (SR Research; Ottawa, Ontario) at a sampling frequency of 1000 Hz (1000 samples per second). Participants used a chin rest, which was placed approximately 80 cm away from the display screen (44 cm length × 37 cm width). Gaze location was measured and recorded from the left eye in pixel units. As previous methodological papers have noted 
[1,
2]
, infrared eye-trackers are susceptible to drift shift in which measured gaze location will gradually deviate from actual gaze location over time. In line with manufacturer recommendations, all participants completed the standard Eyelink 9-point gaze calibration routine prior to data collection, ensuring that all recorded gaze samples were within 10 pixels of true fixation coordinates. However, because the nature of our task required very precise gaze measurements, particularly along the prediction bar, we implemented a custom drift correction procedure at the start of each trial to accommodate for additional drift over the course of the experiment.
Evaluating arousal from pupil diameter during feedback. We used a baseline subtraction method to index arousal from pupil diameter during the feedback phase. Each feedback phase was trimmed into an event epoch including the 1 sec. baseline calibration period in which the trial outcome was occluded, followed by the feedback display period. To compute change in arousal from baseline, we indexed the first reliable pupil dilation estimate from the baseline calibration period in raw pupil area (pa) units. We then subtracted the baseline value from all subsequent raw pupil diameter measurements. To control for individual variability in average pupil size across participants, we converted raw pa to % change in pupil diameter from baseline using the equation below, where i indexes each eye-tracker sample post feedback onset. Pupil-based arousal as reported in our main text was simply the mean % change in pupil diameter from feedback onset to the end of the trial event epoch.
ℎ + = + − % ℎ + = ℎ + × 100
Evaluating trial outcome predictions from gaze. We constructed trial-level estimates of one's outcome predictions and experienced uncertainty using the pattern of eye movements along the prediction bar. For each trial we created an event epoch for the duration of the prediction phase. Epochs were variable in duration as the prediction phase was self-paced. We next evaluated sampled prediction values along the bar, which could be identified from the pattern of fixations and saccades across the screen (see below). Fixations, broadly defined as stabilized locus of visual attention, vary in duration and frequency depending on a number of factors, such as the task (e.g., reading versus scene perception) and stimulus complexity 
[3]
. Generally, prior studies that have tested and analyzed several conventional fixation identification methods, such as dispersion and area-based algorithms, report that individual fixations are at least 100 milliseconds in duration 
[4]
. Saccades, the ballistic movements between fixation points 
[3]
, also vary in terms of duration and velocity depending on the nature of the task, however, are widely reported to last approximately 30 milliseconds during reading and 40-50 milliseconds during scene perception 
[3]
. Our task required participants to use ocular movements to indicate anticipated outcomes along a bar, thus involving both lateralized and dispersed eye movements analogous to both reading and scene perception, suggesting that fixations and saccades in our task should be in a similar temporal range.
To derive our prediction and uncertainty estimates we analyzed variation in gaze locations along the x-axis of the screen. Gaze coordinates were recorded in pixel units and were then mapped onto prediction values on a 925 x 231pixel prediction bar. Gaze coordinates, down-sampled to 500Hz, were then placed into 40 millisecond temporally contiguous bins and averaged together so that each gaze sample was no greater in length than a saccade.


Areas of interest.
After preprocessing all gaze data, we constructed an area of interest (AOI) around the prediction bar, which was 925 pixels wide and 231 pixels in height, placed in the center of the screen. We then created a 1000 by 332-pixel AOI around the prediction bar, allowing for a measurement buffer between true gaze location and drift from the eye-tracker. These values were chosen by allowing for the full range of gaze fixations across x coordinates on the screen (the full width of the screen is 1000 pixels), and to allow for a 50-pixel buffer above and below the bar along y coordinates. Fixations which fell outside of the prediction bar AOI were omitted from analyses. We then further divided the prediction bar AOI into 100 bins, with exactly 50 bins on each side of the outcome boundary. Each bin consisted of 10 pixels. We chose this bin width because our custom calibration routine ensured that fixations were at least within 30 pixels of true fixation. Thus, 10 pixel bins allowed us to maximize for spatial resolution and confidence in true gaze location. Using these AOIs, we computed how many fixations fell on each side of the outcome boundary for the H-gaze calculation, and the standard deviation over sampled bins for the EUgaze calculation.
Gazes were then range normalized to control for differences in the granularity of the prediction bar depending on the invested amount. If for example, $1 was invested, then the 5 monetary values displayed on the prediction bar increased in $0.50 increments, covering a range of $0 and $2 (the min. and max. return). However, if $10 was invested, then the displayed monetary values increased in $5 increments, covering a range of $0 to $20. Because participants were instructed to also consider values between monetary increments on the bar (e.g., between $0 and $5) participants could consider a larger range of plausible returns in the $10 investment scenario. The correspondence between the number of pixels on the screen associated with a particular value was therefore dependent on the investment, potentially leading to reduced precision when indicating predictions in the $10 scenario. To ensure that the dispersion of gazes (i.e., our main readout of uncertainty) did not depend on the pixel resolution of the display bar, we converted all measurements from pixel units to standardized units between 0 and 1 by applying min-max transformation as shown below (Note: xmin and xmax are the pixel coordinates corresponding to the far left and right edges of the bar, and i indexes each gaze sample).
+ = ( + − ,+' )/( ,+' − ,-. )
Outcome predictions on trial t were then computed from the mean of range normalized values after transforming them into monetary units:
! = ∑( + × ! × 2) )-/( &-,$1(&
Gaze-based estimate of epistemic uncertainty. Measures of epistemic uncertainty, EU-gaze, were simply evaluated as the standard deviation of the min-max normalized gazes on each trial, capturing the predictive precision of one's beliefs about their partner's behavior. Thus, the standard deviation around the mean of participants' gazes allowed us to evaluate whether participants were motivated to precisely track anticipated outcomes from trial to trial, capturing epistemic value information that would not necessarily improve task performance if the choice policy was already optimized. Epistemic uncertainty was calculated from the standard deviation of min-max normalized gazes from each sample, i, for each trial t, where )-/( is the mean of normalized gaze samples.
)-/( ' = M ∑('%4, )-/( ( 56 &)*% ' ) + ' &)*% #)-!.%#
Gaze-based estimates of policy uncertainty. To compute gaze measures of policy uncertaintypeople's tendency to gaze at outcomes that would indicate they are uncertain about what to dowe quantified the proportion of fixations on either side of the outcome boundary using an areabased algorithm. The fixation bar was first divided into hemifields with the outcome boundary serving as the point of separation, such that fixations on the left versus right side of the boundary indicated anticipated monetary losses or gains, respectively. To identify the number of fixations that fell on one or the other side of this boundary, we further divided each hemifield into 50 equidistantly spaced bins, 10 pixels apart. Range-normalized gazes were then placed into respective bins to identify the number fixations on each side of the bar. The proportion of fixations that fell on each side of the outcome boundary, pgain and ploss, were then computed as followed.
)-+' = )-+' 8+.-!+%'& !%!-1 8+.-!+%'& 1%&& = 1 − )-+'
The proportion of gazes on the gain and loss side of the outcome boundary were use used to calculate gazed-based policy entropy-the empirical analogue to entropy, H, calculated from choice probabilities in the Dynamic Bayesian-RL model 
[5,
6]
. Choice variance and policy reliability. We further examined whether patterns of investment were sensitive to within-task manipulations-trial types and outcome valence. If Adjust Policy trials indeed require participants to form alternate policies and participants indeed alter their choice policy as a consequence, we should expect to see increased choice variance on these trials. Indeed, our calculation of policy uncertainty, H, in the Bayesian-RL model assumes H can be estimated from how deterministic versus random one's investments are. Consistent with this assumption, choice variance computed at the block level (every four trials) was greater during Adjust Policy trials, particularly when partners were untrustworthy (trial type × valence interaction; t = 2.11, p = .035 
Fig. S2B
), indicating a greater tendency to switch away from a deterministic choice pattern when one's prior choice policy was no longer reliable. Finally, we tested whether our gaze measure of policy uncertainty (H-gaze) from the prediction phase was associated with increased choice conflict. Across all trials in the task, policy uncertainty was positively correlated with choice RT (t = 5.47, p < .001; 
Fig. S2C
), suggesting that the degree of policy uncertainty measured during prediction preserved experienced of choice conflict when evaluating whether one's partner was trustworthy. 
)-/( ' = −( )-+' × # )-+' − 1%&& × # 1%&& )


Figure S2. Association between choice and policy reliability. A. Distribution of investments across trial types. Histogram shows the distribution of $1 and $10 investments on Exploit versus


Clinical Measures
Treating anxiety as a continuous measure. Generalized anxiety was evaluated using the GAD-7 and State Trait Anxiety Inventory trait subscale. (STAI Trait). The distribution of scores on each scale are plotted below 
(Fig. S3A)
, including the recommended cutoff points for identifying clinically significant levels of anxiety (see Methods). Scores from each scale were positively correlated (t = 11.25, p < .001, 
Fig. S3B)
, demonstrating a high level of consistency across GAD-7 and STAI Trait scales. Due to the constraints of collecting additional eye-tracking measures, our sample size was on the lower end (N = 94) of the power needed to detect individual differences along continuous trait dimensions. We therefore opted to evaluate the effect of anxiety by grouping individuals into high and low anxiety groups based on a priori clinical cutoffs. However, many of our key findings reported in the main text reach statistical significance with the continuous scores.
To evaluate the effect of anxiety on learning using a continuous measure, we created a single composite anxiety score by min-max normalizing scores and computing the average anxiety score across scales. Generalized anxiety using the continuous, composite score predicted investments (composite anxiety score × valence interaction: t = -3.79, p < .001), trial-level predictions (composite anxiety score × valence interaction: t = -3.47, p < .001), and model estimates of the decay intercept parameter for losses ( * $%& ; t = -2.13, p = .036). Composite anxiety scores did not reach statistical significance for gaze or pupillometry measures.


Consistency between generalized anxiety scales and other clinical measures collected.
Our battery of clinical scales also included the STAI State subscale to evaluate state anxiety, the Center for Epidemiologic Studies Depression Scale (CESD), and the Social Interaction Anxiety Scale (SIAS). We included state anxiety in our inventory to assess whether learning differences were driven by increased trait versus state anxiety levels (i.e., long-term versus short-term experiences of anxiety). Given the tight link between generalized anxiety and major depressive disorder, we also included the CESD scale to test whether observed learning effects were selective to generalized anxiety. Last, we examined the effect of social anxiety, again given the strong association between generalized and social anxiety. Here we specifically probed whether learning differences were selective to generalized or social anxiety, especially given the social nature of our task. Correlations between scores on each scale are reported below 
(Fig. S3C)
. As denoted in the correlation matrix, scores on each scale were highly intercorrelated. State anxiety and depression symptoms were highly collinear with generalized anxiety (correlation between composite anxiety and cesd scores: r = .84, p < .001; correlation between composite anxiety and STAI State scores: r = 0.78, p < .001), and predicted investment differences in the loss domain as a function of symptom severity (cesd score × valence interaction: t = -3.64, p < .001; STAI State score × valence interaction: t = -3.93, p <.001). However, when entered into a linear mixed effects model with composite anxiety scores (investments ~ composite anxiety*valence + cesd*valence; investments ~ composite anxiety*valence + STAI State *valence), these terms were no longer significant and caused the effect of generalized anxiety to drop out (p > .1), indicating that there was not enough unique variance between generalized anxiety, depression, and state anxiety to individually estimate their effect on investments. In contrast, although social anxiety scores marginally predicted investment differences in the loss domain (sias score × valence interaction: t = -2.63, p = .0086), when entered into a model with composite anxiety to compete for variance (investments ~ composite anxiety*valence + sias*valence), the effect of social anxiety was not significant while the effect of composite anxiety held (composite anxiety score × valence interaction: t = -2.89, p = .004). This finding suggests that while generalized and social anxiety are correlated, generalized anxiety distinctly drives differences in learning in the trust task. Further, given that t-statistics can be biased by the distribution of values if skewed, we tested whether randomly assigning group identities (high vs. low anxiety) across simulations results in incorrectly rejecting the null more than 5% of the time, the theoretically predicted false discovery rate (FDR) across t-tests. As shown in 
Fig. S5B
, randomizing group membership and testing the difference in group means for the recovered Gamma Difference results in 5% of simulations incorrectly rejecting the null, the expected FDR assuming an unbiased test. In sum, our model validation procedure and additional simulations provide reassurance that gamma parameter differences across high and low anxiety groups are reliable and are unlikely to result from biased testing or statistical artefact.   
Figure 1 .
1
Experimental design and eye-tracking method to empirically estimate uncertainty. A. Trust game. At the start of each trial, participants were paired with one of three presumed online partners, and could invest $1 or $10. The invested money is then quadrupled in value, and the partner receives the quadrupled sum. Partners then decide to return anywhere from 0-50% of the investment such that participants can lose all of the initial investment (0% return), double their investment (50% return), or receive any outcome in between. B.


Figure S3 .
S3
Anxiety scores from clinical battery. A. Distribution of anxiety scores. The GAD-7 and STAI Trait subscale were used to measure generalized anxiety levels. The distribution of individual participants scores is plotted in the top and bottom panels. The dashed vertical line denotes the cutoff score used to place participants into high and low anxiety groups based on clinically recommended guidelines (see Methods). The shaded pink region indicates the range of scores considered high anxiety. Participants were placed into the high anxiety group if their score fell in the high anxiety range on either scale. B. Association between GAD-7 and STAI Trait Scales.Both measures of generalized anxiety were highly associated, indicating high consistency between scales. C. Correlations between generalized anxiety, social anxiety, and depression. Participants also completed STAI State, SIAS, and CESD scales. Responses on each scale were highly intercorrelated as shown in the correlation plot.


Figure S4 .
S4
Parameter recovery. The reliability of all free parameters in the DBRL-2 model was evaluated by comparing the set of MLE-optimized parameters from choice data (x-axis) to the set of parameters evaluated from simulated data (y-axis). All parameters were generally recoverable, indicating that the DBRL-2 model provides reliable fits.


Figure S5 .
S5
Model simulations from MLE-optimized parameters. A.


used to construct estimates of policy and epistemic uncertainty. Policy uncertainty was assessed as the extent to which gaze patterns spanned both sides of the boundary determining the optimal policy, quantified by entropy (H-gaze, see Methods). Epistemic uncertainty was quantified by the variance in gaze patterns irrespective of the outcome boundary.
over values was
Partner payout structure. Social
partners gradually reversed their payouts and drifted towards increasingly fair (trustworthy) or
selfish (untrustworthy) strategies, requiring participants to continually adjust their choice policy.
The dotted black line denotes the outcome boundary determining the optimal policy to maximize
returns: participants should invest maximally ($10) when partners return more than 25%, and
minimally ($1) otherwise to avoid a monetary loss. C. Task trial types. During Adjust Policy trials,
the partner's return rate crossed the 25% outcome boundary, requiring an adjustment in one's
current choice policy. In contrast, during Exploit Policy trials, participants could continue using
their current choice policy with no consequence to their current payoffs (assuming choice was
already optimized). Trial types were orthogonalized to dissociate the effects of each type of
uncertainty and outcome valence on learning. D. Task event sequence. Trials commenced with a
partner pairing phase in which the computer selected a partner for the current round (see
Methods). Participants were then given up to 4 seconds to indicate their investment and then made
a prediction about how much money they believed their partner would return, before observing
trial outcomes. Gaze measures of uncertainty were collected during the prediction phase, and
pupil-linked arousal was measured during the feedback phase. E. Measuring policy and epistemic
uncertainty from gaze patterns. During the prediction phase, participants were instructed to align
their eye gaze (signaled to them with a blue dot) to the anticipated trial outcome. The gaze pattern


were sensitive to valence and trial type. Participants showed greater epistemic uncertainty on Exploit Policy trials and when partners were untrustworthy. In contrast, untrustworthy partners elicited greater policy uncertainty on Adjust Policy trials. C. Expressed policy and epistemic uncertainty shift with changing task demands. Left panel shows mean estimates of policy and epistemic uncertainty dynamically oscillate depending on whether prior choice policies could be exploited or needed to be adjusted. Results for one example partner type are shown. Right panel shows mean estimates of each type of uncertainty aggregated across all partner types. D. Modelfree gaze signatures. Gaze traversed the outcome boundary (i.e., the net gain versus net loss side of the prediction bar) more frequently on loss compared to gain trials, and on adjust versus exploit trials. Sampling rate indicates participants more expediently sampled the search space on exploit compared to adjust trials, suggesting a tendency to narrow one's predictions once the policy was optimized. E. Policy and epistemic uncertainty are associated with model-free gaze signatures. Hgaze tracks the number of switches across the outcome boundary, whereas EU-gaze reliably captures the rate of sampling across multiple possible outcomes. Asterisks (*,**,***) denote p < .05, p < .01, p < .001, respectively. Errors bars indicate the standard error of the mean.


participant estimates of each uncertainty type. Box width shows the standard error of the mean.C. Gaze Location across Prediction Bar. Top and bottom heatmaps shows the pattern from all gaze positions, across trials and participants, along x-coordinates of the screen. The pattern of fixations on Exploit Policy trials cover a larger range of values along the bar, indicating increased value sampling. Adjust Policy trials elicit a narrower range of samples on either side of the
outcome boundary and are characterized by increased switching between high and low values as
shown in the main text (Fig. 2D). Asterisks (*,**,***) denote p < .05, p < .01, p < .001,
respectively. Errors bars indicate the standard error of the mean.


Adjust trial types, and during Reward versus Loss trials. Choice frequencies show reduced variance on exploit trials, and increased variance on adjust trials. Participants were more likely to invest $1 on loss blocks and $10 on reward blocks, the payoff-maximizing investment strategy on these trial types. Associated between Choice RT and Policy Uncertainty. Policy uncertainty measured during the prediction phase from gaze patterns, H-gaze, was positively correlated with choice RT, indicating that uncertainty about outcomes was associated with increased choice conflict.
B. Choice variance across trial types. Block-wise (i.e., every four trials) choice variance increased on Adjust Policy trials and was greater on loss blocks when partners were untrustworthy. C.


Table S3 .
S3
Recovered group differences in gamma parameters. MLE-optimized parameters for each participant (i.e., those reported in the main text) were used to simulate choice data 100 times. Simulated data was then fit to the DBRL-2 model. Group t-tests conducted on high and low anxiety group recovered gamma parameters were performed for each simulation to evaluate the reliability of detecting group differences from the initial generative parameters. The resulting t-distribution for Gamma-Neg and Gamma-Pos reveals robust ordinal differences in recovered parameter fits across groups. The distribution of t-statistics for the Gamma Difference (Gamma-Pos -Gamma-Neg) yields positive values, indicating a reliable valence-based learning asymmetry in the high anxiety group across simulations. B. Test of group difference FDR. In a separate step, group identity was randomly assigned to participants in each simulation to evaluate the FDR when comparing the Gamma Difference across groups. The null hypothesis was incorrectly rejected on 5% of simulations, revealing an unbiased FDR. In the t-statistic panel, dashed lines correspond to the t-threshold, +/-1.98. The dashed line in the p-value panel corresponds to .05, the chosen alpha for rejecting the null. Description of DBRL-2 model parameters. Note, model parameters are identical to the original model developed in our prior work[6], with the exception of the upper bounds of the " parameters. " was constrained to negative values in our original model such that greater entropy could only modulate the decay rate by linearly increasing or deceasing decay as a function of ∆ . This constraint was relaxed in DBRL-2, allowing for the opposite pattern in which ∆ speeds accumulation of values as entropy increases (positive " values).
Model Parameter Parameter Description
Upper-bound
Lower-bound
Inverse
Degree to which participant
20 -highly
1 -always selects at
Temperature
exploits learned decision-rule
deterministic
random
associated with rewarding
behavior
outcomes through
deterministic vs. exploratory
behavior
Bias
Benchmark for investing (i.e.
1.0 -high
0.1 -low benchmark
how much additional value
benchmark for
for investing
does the participant need to
investing
(participant is biased
derive from investing $10 in
(participant is biased
towards always
order to select the choice over
towards never
investing $10)
a preferred strategy to always
investing $10)
invest $1)
Negative Decay
Degree of decay of negative
1.0 -no decay
0.1 -maximal decay
Intercept * $%&
outcomes, which prevents the
(posterior
(added uncertainty
posterior distribution from
distribution is
prevents posterior
becoming overly confident
updated from
distribution from
(certain) from previous
negative outcomes
integrating observed
experience
and previous
negative outcomes
experiences
over experience)
accumulate)
Positive Decay
Degree of decay or uncertainty
1.0-no decay
0.1 -maximal decay
Intercept * !"#
over positive outcomes
(posterior distribution is
(added uncertainty prevents posterior
updated from
distribution from
positive outcomes
integrating observed
and previous
positive outcomes)
experiences
accumulate)
Negative Dynamic
Extent to which negative
2 -Faster
-2.0-maximal
Decay " $%&
outcomes are decayed as a function of change points in
accumulation of values as a function
adjustment of decay rate as a function of
uncertainty
of ∆
∆
Positive Dynamic
Extent to which positive
2 -Faster
-2.0-maximal
Decay " !"#
outcomes are decayed as a function of change points in
accumulation of values as a function
adjustment of decay rate as a function of
uncertainty
of ∆
∆








Acknowledgments. We thank Matthew Nassar for helpful comments and feedback and Eric






Supplementary Results
Validation of gaze-based uncertainty measures. To ensure that gaze-based predictions were reliably tracking estimates of each partner's behavior, we evaluated whether the mean location of fixations on the prediction bar corresponded with actual monetary returns. A mixed-effects regression revealed that gaze location during the prediction phase significantly predicted the percentage of the investment returned during the feedback phase (t = 33.87, p < .001; 
Fig. S1A
), demonstrating that gaze-derived trial predictions were reliably rooted in forthcoming monetary outcomes. Participants also expressed greater policy uncertainty when they were unsure of the optimal choice policy in the task (t = -8.05, p < .001; 
Fig. S1B
). However, once participants knew the optimal policy, they expressed greater epistemic uncertainty (t = 7.07, p < .001), suggesting that periods of optimized behavior were accompanied by a desire to learn more about partners.


Figure S1. Variability in gaze patterns reflects anticipated monetary outcomes and knowledge about the optimal choice policy. A. Using gaze to capture trial outcome predictions. Panel shows correspondence between gaze-based predictions and trial outcomes for an example partner type. Across all partner types, gaze fixations on the bar during the prediction phase tracked the percentage of the investment returned during the feedback phase, validating the use of gaze-based measures to assess beliefs about task outcomes. B. Gaze-based uncertainty measures reliably approximate policy optimization. Participants indicated greater policy uncertainty on trials in which the suboptimal response was selected and greater epistemic uncertainty on trials in which the optimal response was selected, demonstrating that uncertainty estimates from gaze patterns capture knowledge about the optimal choice policy. Individual points correspond to mean


Task Believability
Debriefing protocol and suspicion ratings. At the end of the experiment all participants were debriefed and were told that their partners were not real humans, and all choices were determined by a preprogrammed computer algorithm. Prior to revealing the true nature of the study, we asked participants to indicate whether they had any doubts about whether their partner was in fact a real human at any point during the study. We then used participant suspicion ratings as a covariate in all key analyses reported in our manuscript. Although many participants doubted their partner was real (~ 68.09%), suspicion ratings did not predict behavior, gaze-measures of uncertainty, or model parameter estimates (all Ps > .1).


Model Comparison and Validation
Bayesian Reinforcement Learning models and parameters. We tested and compared a set of 4 nested Bayesian Reinforcement Learning (BRL) models, 3 of which included additional " terms to dynamically adjust the decay rate (DBRL). The set of models considered, and their corresponding free parameters, are shown in 
Table S1
. 
Table S2
 and 
Fig. S3
 show the mean performance of each model, indexed as the mean negative AIC. Mean AIC values show that the DBRL-2 model best captures choice data in the task, which was additionally supported with Bayesian model selection. Descriptions of each free parameter in the DBRL-2 model are provided in 
Table S3
. Parameters were optimized individually for each participant using the fmincon gradient descent function in MATLAB with 20 iterations (i.e., starting points) per model.


Model validation.
We performed MLE and parameter recovery checks to ensure that the winning model, DBRL-2, adequately captures participant behavior in the task and parameter fits are reliable. To ensure that the MLE-optimized parameters could reproduce behavior in the task, we simulated choices from the optimized set of parameters for each participant. As shown in 
Fig. 4A
, the DBRL-2 model captures overall choice profiles in both high and low anxiety groups, and in particular, the slowed learning patterns in the high anxiety group. We assessed parameter recovery by fitting simulated data to the model and comparing the corresponding recovered parameters to the original set of MLE-optimized parameters evaluated from each participant's choice data, shown in 
Fig. S4
.
To further test whether we could reliably detect differences in recovered gamma intercept parameters, the primary parameters of interest, we simulated 100 datasets (i.e., choice behavior) from the model using each subject's MLE-optimized parameters reported in 
Fig. S4
 as the generative parameters. We then fit the model to these simulated datasets and conducted t-tests on the group means (high and low anxiety) of recovered parameters. The resulting t-distributions from our simulations are plotted in 
Fig. S5A
. As shown in this plot, t-tests yield negative t-statistics for recovered Gamma-Neg values across groups, revealing systematically lower values in the reference group (high anxiety). In contrast, we observe positive t-statistics comparing recovered Gamma-Pos parameters, which are larger in the high anxiety group. This valence asymmetry (Gamma Difference: Gamma-Pos -Gamma-Neg) in learning parameters is also observable as a positive t-statistic, indicating the learning asymmetry effect between high and low anxiety groups is reliable across simulations. 


Model


No.


Model
 










Trust, reciprocity, and social history




J
Berg






J
Dickhaut






K
Mccabe








Games Econ Behav




10
















Inferring on the intentions of others by hierarchical Bayesian learning




A
O
Diaconescu






C
Mathys






L
A
Weber






J
Daunizeau






L
Kasper






E
I
Lomakina








PLoS Comput Biol




10


1003810














Neuroeconomic foundations of trust and social preferences: initial evidence




E
Fehr






U
Fischbacher






M
Kosfeld








Am Econ Rev




95
















The computational challenge of social learning




O
Feldmanhall






M
R
Nassar








Trends Cogn Sci




25
















Social uncertainty and the problem of trust in social groups: The social self in doubt




R
M
Kramer






J
Wei








Psychol Soc Self. Psychology Press














A cholinergic feedback circuit to regulate striatal population uncertainty and optimize reinforcement learning




N
T
Franklin






M
J
Frank








Elife




4














Uncertainty, epistemics and active inference




T
Parr






K
J
Friston








J R Soc Interface




14














Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings




E
Payzan-Lenestour






P
Bossaerts








PLoS Comput Biol




7


1001048














Dissociable neural correlates of uncertainty underlie different exploration strategies




M
S
Tomov






V
Q
Truong






R
A
Hundia






S
J
Gershman








Nat Commun




11


2371














Balancing exploration and exploitation with information and randomization




R
C
Wilson






E
Bonawitz






V
D
Costa






R
B
Ebitz








Curr Opin Behav Sci




38
















Active inference, curiosity and insight




K
J
Friston






M
Lin






C
D
Frith






G
Pezzulo






J
A
Hobson






S
Ondobaka








Neural Comput




29
















On the normative advantages of dopamine and striatal opponency for learning and choice




A
Jaskir






M
J
Frank








Elife




12


85107














Contextual modulation of value signals in reward and punishment learning




S
Palminteri






M
Khamassi






M
Joffily






G
Coricelli








Nat Commun




6


8096














Choice values




Y
Niv






N
D
Daw






P
Dayan








Nat Neurosci




9
















Reinforcement learning: An introduction




R
S
Sutton






A
G
Barto








MIT press












Value-free reinforcement learning: policy optimization as a minimal model of operant behavior




D
Bennett






Y
Niv






A
J
Langdon








Curr Opin Behav Sci




41
















Opponent actor learning (OpAL): modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive




A
G
Collins






M
J
Frank








Psychol Rev




121


337














Signals in human striatum are appropriate for policy update rather than value prediction




J
Li






N
D
Daw








J Neurosci




31
















Memoryless policies: Theoretical limitations and practical results




M
L
Littman








MIT Press


238


Cambridge, MA, USA












Human-level control through deep reinforcement learning




V
Mnih






K
Kavukcuoglu






D
Silver






A
A
Rusu






J
Veness






M
G
Bellemare








Nature




518
















Humans use directed and random exploration to solve the explore-exploit dilemma




R
C
Wilson






A
Geana






J
M
White






E
A
Ludvig






J
D
Cohen








J Exp Psychol Gen




143


2074














Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration




J
D
Cohen






S
M
Mcclure






A
J
Yu








Philos Trans R Soc B Biol Sci




362
















The algorithmic architecture of exploration in the human brain




E
Schulz






S
J
Gershman








Curr Opin Neurobiol




55
















Tolerance to ambiguous uncertainty predicts prosocial behavior




M-L
Vives






O
Feldmanhall








Nat Commun




9
















Advances in modeling learning and decision-making in neuroscience




A
G
Collins






A
Shenhav








Neuropsychopharmacology




47
















Reinforcement learning with Marr




Y
Niv






A
Langdon








Curr Opin Behav Sci




11
















Bridging the gap between value and policy based reinforcement learning




O
Nachum






M
Norouzi






K
Xu






D
Schuurmans








Adv Neural Inf Process Syst




30














Attention, reward, and information seeking




J
Gottlieb






M
Hayhoe






O
Hikosaka






A
Rangel








J Neurosci




34
















Pupil size encodes uncertainty during exploration




H
Fan






T
Burke






D
C
Sambrano






E
Dial






E
A
Phelps






S
J
Gershman








J Cogn Neurosci




35
















Information-seeking, curiosity, and attention: computational and neural mechanisms




J
Gottlieb






P-Y
Oudeyer






M
Lopes






A
Baranes








Trends Cogn Sci




17
















Towards a neuroscience of active sampling and curiosity




J
Gottlieb






P-Y
Oudeyer








Nat Rev Neurosci




19
















Eye movements reflect adaptive predictions and predictive precision




L
Bakst






J
T
Mcguire








J Exp Psychol Gen




150


915














Response latencies and eye gaze provide insight on how toddlers gather evidence under uncertainty




S
Leckey






D
Selmeczy






A
Kazemi






E
G
Johnson






E
Hembacher






S
Ghetti








Nat Hum Behav




4
















The relationship between environmental statistics and predictive gaze behaviour during a manual interception task: Eye movements as active inference




D
Harris






S
Vine






M
Wilson






T
Arthur


















Risk and ambiguity in information seeking: Eye gaze patterns reveal contextual behavior in dealing with uncertainty




P
Wittek






Y-H
Liu






S
Darányi






T
Gedeon






I
S
Lim








Front Psychol




7


1790














The mid-point on a rating scale: Is it desirable




R
Garland








Mark Bull




2
















Using Likert type data in social science research: Confusion, issues and challenges




B
P
Subedi








Int J Contemp Appl Sci




3
















Failure to respond autonomically to anticipated future outcomes following damage to prefrontal cortex




A
Bechara






D
Tranel






H
Damasio






A
R
Damasio








Cereb Cortex




6
















Neural activity in the human brain relating to uncertainty and arousal during anticipation




H
D
Critchley






C
J
Mathias






R
J
Dolan








Neuron




29
















Emotion and decision-making under uncertainty: Physiological arousal predicts increased gambling during ambiguity but not risk




O
Feldmanhall






P
Glimcher






A
L
Baker






E
A
Phelps








J Exp Psychol Gen




145


1255














An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance




G
Aston-Jones






J
D
Cohen








Annu Rev Neurosci




28
















Anxious individuals have difficulty learning the causal statistics of aversive environments




M
Browning






T
E
Behrens






G
Jocham






J
X
O'reilly






S
J
Bishop








Nat Neurosci




18
















Rational regulation of learning dynamics by pupil-linked arousal systems




M
R
Nassar






K
M
Rumsey






R
C
Wilson






K
Parikh






B
Heasly






J
I
Gold








Nat Neurosci




15
















Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias




A
E
Urai






A
Braun






T
H
Donner








Nat Commun




8


14637














Neurocognitive mechanisms of anxiety: an integrative account




S
J
Bishop








Trends Cogn Sci




11
















Intolerance of uncertainty and social anxiety




P
A
Boelen






A
Reijntjes








J Anxiety Disord




23
















The role of fear of anxiety and intolerance of uncertainty in worry: An experimental manipulation




K
Buhr






M
J
Dugas








Behav Res Ther




47
















Increasingly certain about uncertainty: Intolerance of uncertainty across anxiety and depression




R
N
Carleton






M
K
Mulvogue






M
A
Thibodeau






R
E
Mccabe






M
M
Antony






G
J
Asmundson








J Anxiety Disord




26
















A cognitive model of generalized anxiety disorder: The role of intolerance of uncertainty. Worry Its Psychol Disord Theory Assess Treat




N
Koerner






M
J
Dugas




















Altered learning under uncertainty in unmedicated mood and anxiety disorders




J
Aylward






V
Valton






W-Y
Ahn






R
L
Bond






P
Dayan






J
P
Roiser








Nat Hum Behav
















Impaired adaptation of learning to contingency volatility in internalizing psychopathology




C
Gagne






O
Zika






P
Dayan






S
J
Bishop








Elife




9


61387














Anxiety impedes adaptive social learning under uncertainty




A
Lamba






M
J
Frank






O
Feldmanhall








Psychol Sci




31
















Validation and standardization of the Generalized Anxiety Disorder Screener (GAD-7) in the general population




B
Löwe






O
Decker






S
Muller






E
Brahler






D
Schellberg






W
Herzog








Med Care




46
















A Brief Measure for Assessing Generalized Anxiety Disorder: The GAD-7




R
L
Spitzer






K
Kroenke






Jbw
Williams






B
Löwe








Arch Intern Med




166
















State-trait anxiety inventory for adults




C
D
Spielberger


















Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control




N
Daw






Y
Niv






P
Dayan








Nat Neurosci




8
















Instructional control of reinforcement learning: a behavioral and neurocomputational investigation




B
B
Doll






W
J
Jacobs






A
G
Sanfey






M
J
Frank








Brain Res




1299
















The role of the amygdala in fear and anxiety




M
Davis








Annu Rev Neurosci




15
















The neurocircuitry of fear, stress, and anxiety disorders




L
M
Shin






I
Liberzon








Neuropsychopharmacology




35
















Anxiety disorders: a review




K
L
Szuhany






N
M
Simon








Jama




328
















Trends in anxiety among adults in the United States




R
D
Goodwin






A
H
Weinberger






J
H
Kim






M
Wu






S
Galea








J Psychiatr Res




130










: Rapid increases among young adults








Social isolation and loneliness in older adults-a mental health/public health challenge




D
Blazer








JAMA Psychiatry




77
















Minding many minds: an assessment of mental health and resilience among undergraduate and graduate students; a mixed methods exploratory study




R
R
Fried






S
Karmali






J
D
Irwin








J Am Coll Health




70
















Prevalence of mental health disorders among undergraduate university students in the United States: A review




H
K
Kang






C
Rhodes






E
Rivers






C
P
Thornton






T
Rodney








J Psychosoc Nurs Ment Health Serv




59
















Prevalence and risk factors for mental health problems in university undergraduate students: A systematic review with meta-analysis




E
Sheldon






M
Simmonds-Buckley






C
Bone






T
Mascarenhas






N
Chan






M
Wincott








J Affect Disord




287
















The Eyelink Toolbox: eye tracking with MATLAB and the Psychophysics Toolbox




F
W
Cornelissen






E
M
Peters






J
Palmer








Behav Res Methods Instrum Comput




34
















Eye tracker data quality: What it is and how to measure it




K
Holmqvist






M
Nyström






F
Mulvey




















Best practices in eye tracking research




B
T
Carter






S
G
Luke








Int J Psychophysiol




155
















Identifying fixations and saccades in eye-tracking protocols




D
D
Salvucci






J
H
Goldberg




















A cholinergic feedback circuit to regulate striatal population uncertainty and optimize reinforcement learning




N
T
Franklin






M
J
Frank








Elife




4














Anxiety impedes adaptive social learning under uncertainty




A
Lamba






M
J
Frank






O
Feldmanhall








Psychol Sci




31

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]