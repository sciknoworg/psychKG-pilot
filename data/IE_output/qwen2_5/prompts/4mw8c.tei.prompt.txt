You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Cognitive sequential dependencies in the wild: Sentiment analysis approach Our decisions do not demonstrate what we really experience. They are somewhat under control of past decisions and these phenomena pondering the new decisions in the context of previous ones is substantially salient. For instance, people are shockingly terrible at rating the absolute magnitude of their inner psychological states. Notwithstanding the task, judgment of the absolute size of an stimulus, experience, or feeling are characteristically correlated to relative data from the array of decisions preceding the present one. 
(Laming, 1984;
Stewart, Brown, and Chater, 2005)
. . This behavior is covered by the way that choices are governed by variables, for example, stimulus, reaction, feedback ((see 
Donkin, Rae, Heathcote, & Brown, 2015
,for a review) These cognitive sequential dependencies (SDs) happen at whatever point manner on a trial is impacted by manner on going before trials. Unless rare events , SDs are omnipresent in cognition, shifting absolute judgment from low-level perception as far as possible up to extremely moral decisions.We see the impact of past experiments on the latency, accuracy, and sorts of mistakes delivered, just as the understanding of vague stimuli. SDs appear to influence all dimensions of the cognitive system, including motor control 
(Dixon, McAnsh, and Read, 2012)
, spatial memory 
(Freyd and Finke, 1984)
, face perception 
(Hsu and Yang, 2013;
Liberman, Fischer, and Whitney, 2014)
, selective attention 
(Kristjánsson,
200o)
, decision making 
(Jesteadt, Luce, and Green, 1977)
, and language analysis 
(Bock and Griffin, 2000)
 and concatenated perception 
(Pascucci et. al.,2019)
 sequential dependencies are primarily examined in the laboratory, or at least with empirically controlled stimuli, and the fact is that it is difficult to test them in everyday life conditions, as a large number of tests are needed to identify its effects. For example, in identifying stimuli, cases that are immediately provided before a test (n-1) in comparison to non-adjacent cases (n-2 ... 7) aare applying two opposing forces in identifying the stimulus provided in the experiment 
( Lockehead, 2004)
. To view this pattern in a reasonable time interval in the laboratory, the stimulus sequences should be designed precisely and this is really hard.While laboratory research is the basis for empirical data collection in cognitive science, a significant amount of researchs has already been done on large-scale digital data(for example see 
Liang et al.,2017)
 Each piece of data is a trace of human behavior and allows us to evaluate the basics of cognitive science. However, we need to be able to match these components in a logical way, which requires both the development of theoretical models and the development of new methodological techniques. In the present study, we seek the footprints of correlation between past decisions on the current decisions of individuals in yelp review data set by natural language processing, and this time the data will overcome the natural barriers to a research in the lab. Initially, we will review the SD patterns saw in standard research trials.


SDs in the laboratory
In a broad view, The contrast effect occurs when there is a correlation between the stimuli and they are sufficiently distinct; and assimilation occurs when the negative relationship disappears and therefore the comparison standards become vague. 
(Stappel et al., 1997;
Staplel et al., 1998)
. In other words, assimilation refers to when the target component is distorted in the context, in this case the perceived difference between the two stimuli is smaller than the actual difference, and therefore the apparent difference between the object and the field is reduced 
(Corn et al. 1982;
Jordan and colleagues, 1985;
Shenk et al., 1986)
.Specifically in our study, assimilation occurs when the judgments of the stimulus n are close to the n-k stimulus judgments and The contrast effect is opposite, when the stimulus judgment n varies from the judgments of the stimulus n-k. In this sense, assimilation can be considered as a gravitational force associated with the previous stimulus, and the contrast can be considered as a rebellion force 
(Zotou et al., 2011)
.A great part of the early work on SDs was psychophysical in nature and included rating stimuli , for example, the tumult of a tone or the length of a line 
(Garner, 1953;
Holland and Lockhead, 1968)
. Recognizing the outright scale of these stimuli (e.g., line length) has been very much considered.while distinguishing stimulus,the tendency in our decisions which assimilates toward the preliminary stimulus n -1 is trackable. Participants are almost certain, while recognizing an stimulous, to assess its greatness as being more like the previous stimulus than to recognize it as less like the former stimulus. Strangely, classification of similar stimuli demonstrate the contrary impact-a contrast effect from the past reaction. At the point when stimuli are grouped into classes and the reaction is labeling the class (e.g., small, medium, huge), stimulus n is bound to be named as having a place when it is classifying as further far from stimulus n -1 on the estimation scale 
(Stewart, Brown, and Chater, 2002;
Ward and Lockhead, 1971)
.The contrast impact (repulsing) of trial n -1 on the class rating of trial n isn't constrained to low-level cognition, yet is seen crosswise over every dimensions of cognition. As a prime example, think about 
Parducci's (1968)
 case of characterizing the occasion of of "poisoning a neighbor's barking dog that was bothering you" on an ethical judgment scale from 1 to 10 (where 10 is amazingly detestable). This sentence was evaluated as being more malicious by members in the event that it was introduces after a gentle judgment (stealing a towel from a hotel) than if it was presented after a nastier judgment (using weapons on striking workers) a contrast impact while grouping moral decisions which reflects the discoveries with low-level perceptual stimuli.This equivalent example can be found in a later report by 
Olivola and Sagara (2009)
, who found that members will choose to endanger more human lives, when contrasted with a less dangerous option (with an equivalent likelihood of sparing a similar number of lives), when the quantity of lives in danger is equivalent to the likelihood of the quantity of lives lost when arbitrarily choosing a watched debacle. The decision is unmistakably opposite with one's experiences.participants are happy to endanger more human lives than normal when there are a bigger number of smaller setback occasions, and more averse to hazard more human lives when a higher number of high-loss occasions happen. Moreover, the double choice (dangerous versus beyond any doubt) decision features, significantly, this can't be credited to a scale interpretation impact (i.e., artifact), a potential analysis of 
Parducci's (1968)
 impact. Their discoveries further stress how statistical properties of our condition are reflected in our cognition.Comparable examples of SDs have been found in many tasks in research centers intended to tap daily situations, incorporating brake commencement latencies in driving habit 
(Doshi, Tran,Wilder, Mozer, and Trivedi, 2012)
, jury proof elucidation 
(Furnham, 1986)
, and clinical evaluations 
(Mumma and Wilson, 1995)
. Furthermore, SDs appear to be insusceptible to exercise-they are seen even in overlearned and master practices 
(Doshi et al., 2012)
.At first look, SDs give off an impression of being a nonsensical bias in leadership(or maybe in episodic memory), and customarily they have been seen as the peripheral common result of low-level cognition, for example, residual neural activity. However,more later hypothetical points of view propose that SDs might be a normal property of any cognitive framework. These records describe SDs as far as a person's adjustment to the statistical regularities of a dynamic environment with related stimuli packs 
(Qian and Aslin, 2014;
Wilder, Jones, and Mozer, 2010;
Yu and Cohen, 2009)
Computational models that clarify how SDs exists in the decision making process are presently being created, in event for low-level perceptual undertakings (e.g., 
Mozer et al., 2010)
. These models have extraordinary guarantee, in that they might be turned around and at that point connected to rating information so as to decontaminate the ratings, basically by creating an increasingly precise estimation of the person's outright involvement of an product or business by expelling the contamination from the relative data. As a initial move toward cleaning data, our thought is mining huge survey datasets, for example, those from Yelp , guided by information from research center investigations, so as to search for these normally happening pollutions that may influence how items and organizations are right now rated by commentators and how they can hope to be evaluated later on.
accounting Yelp, future business request is to a great extent impacted by online review 
(Cantallops and Salvi, 2014;
Mudambi and Schuff,2010)
, which influence a business' income somewhere inside range of 5% and 9%,can be expanded by half for organizations with in excess of 50 review 
(Luca, 2011)
. This has an undeniable advantage to the administration of quality that Yelp expects to give, just as to giving a progressively exact data of the produced items and special businesses being referred to.Sentiment Analysis is an academic discipline that uses NLP techniques to automatically identify and analyze mental representations in natural language texts 
(alaei et al.,2019)
.Probably, as a prime subdomain and wellstudied sentiment analysis, one should name the identifying polarity of emotions. Typically, this is considered a binary issue: according to a text (for example, a customer's view or editor's view), the goal is to determine whether the overall polarity of the text is mainly positive or negative. Or none. For example, does the customer recommend the product or not? Is the editor supporting or opposing a particular view?
Polarity analysis can be done at different levels. It is possible to consider the whole text or to do it at the level of the sentence. specially, when we computationally analyze the polarity of emotions with Stanford coreNLP ,a NLP tools which employed artificial intelligence as deep learning neural networks, we reach five ranked scales that have a neutral , positive , very positive and negative or very negative labels which acquire by analyzing each review at sentence level.Our idea in this research was following previous work for identifying cognitive sequential dependencies in explicit reviews by vinson et al and we we took different perspective and calculated review polarity index(RPI) which stand as implicit rating scale by Stanford CoreNLP tools in java what seems more convenience than other NLP software when taking into account the predefined dependency grammar bank and likert scores outputs for polarity of sentences.
In Yelp, users rate their involvement with an item or business from one to five stars and by writing review about that. Since both the explicit and implicit rating scales show a pattern of sequence like above mentioned laboratory experiment ,we expected What people experience about a product prompt shifts their new decisions about that product in more wild and uncontrolled environment like YELP and specially in . Specifically, we expected that inside reviewers in other free dataset YELP we would see a contrast impact from evaluations over items : For instance, a person's rating based upon extracted RPI would falsely increase if his or her past rating had been lower,and misleadingly would decrease if it had been higher. In this sense, our forecasts for RPI BY were a straightforward generialzion of results from both the perceptual work of 
Zotov et al. (2011)
 and the ethical decisions of 
Parducci (1968)
 or 
Olivola and Sagara (2009)
 and specially uncontrold study of vinson et. al(2019) on challenge version of free YELP dataset.to our current knowledge this the first time that by this specicial dateset and this innovative approach cognitive sequential dependencies are assessed.


Method
The statistical population consists of user's reviews published by the YELP site, which contains 6,685,900 reviews and 1,223,094 tips by 1,637,138 users Over 1.2 million business attributes like hours, parking, availability, and ambience Aggregated check-ins over time for each of the 192,609 businesses.
The Yelp review data are organized in a data format referred to as JSON ("JavaScript Object Notation"), and each line consists of a single JSON entry, for a user,review, and etc.
For our present study, we extracted the Yelp user's unique identifier, their RPI , and the time stamp of each review.in addition by ordering the data by reviewer and date we paved the way for our purposes. Against common j-shape distribution for such distributions (see 
Hu, Zhang, & Pavlou, 2009 )
review polarity indexes(RPI) distributions( presented in 
Fig. 1.)
 don't follow a specific shape and the averages for 3 RPIs are (μ = 2.6,3.7,1.7) corresponding to mean and median and mode of RPI respectively consistent with Moore's law, obviously like previous studies in our dataset review's number grow over 
Yelp's lifetime(vinson et al,2019)
 all available reviews from this version of YELP dataset were considered in our study and only reviews that were illegible and confusing in the identifying date format or content of the reviews, were excluded.
The aim of this investigation was if past review affect present review within a user as cognitive sequential dependencies. Using Stanford CoreNLP for NLP,we extracted sentence polarity for each sentence of each review. This yielded review ratings in terms of median and mode and mean polarity by taking into account all sentences in each review by a user. In yelp dataset, obviously it is beyond possibilities that reviews would have been written in the same time stamp and this spark off some noise in our analysis. We expected that if there were true SD effects, this noise can be ignored 
(vinson et al.,2019)
 Hypothetically, should the individual recent RPI be dependent to previous review polarity, It will manifest a contrast effect and more stepping away the past reviews from the present review, We envisioned that these impacts would disappear(cf. 
Zotov et al., 2011)
.
Like vison et. al. 
2019
, we used deviation of review polarity indexes(RPI as an implicit rating ) from mean of RPI for each user as a measure for changes in reviewers views.


Measures
Stanford CoreNLP is a coordinated system which gives a lot of characteristic language examination tools which can take raw text and give the base forms of words, their part of speech, regardless of whether they are names of organizations, individuals, and so on., and mark up the structure of sentences in terms of phrases and word dependencies, demonstrate which now phrase allude to similar entity, indicate sentiment, etc.
We used Stanford CoreNLP to calculate RPI for each review composed of some sentences and at the next steps Our measure for comparability was based upon Vinson et al. (2019) study, as this formula:
− ( − ),


Where
is the current RPI and ( − ) is the average of RPIs for the reviewer before the current review "x".so it was removed.
In this way we employed deviation of current RPI from the average of previous RPIs as a score To dynamically track the deviation of user decisions for each types of RPI in R .
In fact,we centered the data to compare current RPI to average RPI by user and by assigning k as review distances which is ordinal lag measure of how many reviews is in the scope of current and past reviews. At first for text preprocessing we implemented tokenize, ssplit, pos, lemma, depparse anaotatores by Stanford CoreNLP in java. Afterward we implemented natlog annotator for extracting polarity of sentences for each user's reviews.by the way,we calculated central tendencies indexes as mean, median and mode for each user's review and we assessed the hypothesis that a reviewer's present review was related to one's already review in term of review polarity index(RPI) at distance k. 
Table 1
 , 2 , 3 show that near the current review the contrast effect has taken place and farther from current review this effect has passed from sight softly. For example in table 1 by considering R value from -0.250 To -0.069 ,it seems that by going further from baseline the absolute correlation coefficient decreases and the value become less negative.
In this perspective, the data are really like 
Olivola and Sagara's (2009)
 experiment, which rating tend to be in the opposite direction by considering already results.
To make our findings more tangible and comparable with previous study of (vinson et al,2019), we applied eight linear regression model predicting the current review polarity index(RPI) by the n -k, RPI for each of seven different values of k and by a random review polarity index baseline 
(Fig. 2, 3 ,4
 ).
Observed effect can be resulted from regression to mean and omitting this potential confounding factor by using random review RPI could be feasible.
Considering such baseline, we expected the pattern wasn't be alike at each distance of k, if there wasn't regression to mean effect.
Simplicity of implementation and comparability of results with vinson et al results were the prime reason for choosing linear regression in our statistical methode.it is notwithstanding that there was enormous amount of review data so hypothetically irrelativeness a review on the others couldn't be an issue.
On the other hand By using a baseline composed of reviews shuffled predicting current review RPI,we came to a conclusion that there is no significant effect on the current review polarity indexes and this was in contrast to other findings for other k values , revealing significant negative relationship with current RPI for each user.
As mention above , Stanford CoreNLP tools version 3.9.1 was used to calculate dependency grammar relations in each sentences (de Marneffe; Nivre, 2019) in java to calculate finally the RPIs .in this way the stanford dependencies were the input for our procedure to get the output so frequency of negative and positive words and others in a review sentence couldn't determine the value of sentence,per se. for example if we consider these two sentences : 1. This movie was the worst! And 2. This movie was awful! The sentence 1and 2 ranked as very negative and this for sentence 2 is strange because of neutral value for "awful" in English language and Stanford CoreNLP intelligent algorithm can do his job in a normal way like people for considering overall meaning of sentence(ResearchGate, 2014 ).these reports were consistent with our trial and error implementation of Stanford CoreNLP algorithm version 3.9.1 for random chosen sentences of our dataset and revealing prominence of spelling ,structure and syntax of a sentence for sentiment categorization of it. In the current study we make every possible effort to correct the possible misspellings nevertheless sometimes it wasn't possible to detect what is the root of word ! this imposed some subjectivity in our method .
Stanford corenlp effectively distinguishes the sentiment of words and in our study could effectively recognize the opinion behind a straightforward or a well-organized sentence.
Along these lines, we could evaluate the relative direct effect that each value of k had on the present RPI. We determined this notion in R utilizing lm ([ − ( − )]~ k).All functions and codes were written to examine sequential dependencies in this language, and statistical tests were carried out for the significance of the regression coefficients, and the graphs were drawn by it. In this section, we used the software packages: data.table, ggplot2, reshape, plyr, prodest, lubridate to clean and manipulate the data.


DISCUSSION
The purpose of this study was to investigate effect of cognitive sequential dependency in uncontrolled conditions as real life experiences , with naturally occurring dataset 
(Paxton, A., & Griffiths, T. L., 2017)
 by analyzing textual reviews Recent developments in artificial intelligence technologies(AI) and especially deep learning, combined with accessible large dataset, will put psychologists at an unprecedented opportunity to study theories of cognitive science and psychology outside the ordinary lababritory.For example, the cognitive sequential dependency on high-level cognition has been examined on millions of online reviews published on the site of the Yelp (Vinson, Dale and Jones, 2019). Vinson et al used the stars as a explicit ratings ranked by the users for each business, to model cognitive sequential dependencies, which its rationality can be extended to our complementary research similarly, since it doesn't consider aspects polarity of a business hidden in textual details (implicit rating) for each business' review and only rely on ratings in terms of overall star ratings(explicit rating) . sometimes this overall ranking for a service or business raises conflicts with the text written in the review of that service or business, which it has often mentioned in the studies (for example see 
Knijnenburg et al. ,2012;
Cosley et al., 2003;
Hu, Pu, 2013)
Hence, it does not seem to be enough relying only on the explicit stars provided by each user, for jobs or services.In the present study, the Stanford Natural Language processing tools ,namely Stanford CoreNLP, which has gained satisfactory results for natural language processing in the format of likert scale ranging from 1 star to 5, has been implemented for ranking the polarity of user reviews on the Yelp site. We tried to extract review polarity from 1 to 5 with appropriate textual preprocesses and with the Stanford CoreNLP, therefore in that polarity values, we would seek cognitive sequential dependencies and the effect of previous decisions on the users' current decisions in the virtual world. Such use of the RPI to examine cognitive sequential dependencies based on our present knowledge is used for the first time.In this study, we showed that in terms of polarity indexes if the past decisions are more positive about a service or product, then the current immediate decisions related to that past will be less positive and this trend by moving away from the current decision will reach a nearly level off state.Note that in this research, simple linear regression models between a dependent variable that is deviation from the average of each user's decisions and the independent variable, which is the k distance review were done. The mean, mode, and median of the data obtained from the polarity analyses of textual reviews, based on the Anderson-Darling normality test for large data, have no normal distribution (p-value 2.2e-16) with (μ = 2.6,3.7,1.7).
In our analysis the least squares method is used, which in its assumptions the normality of data distribution, does not matter.There are several reasons behind this none normal distributions.(vinson et al,2019) when we consider explicit ratings ,Usually these non normal distributions depend on the type of online review for example as mentioned in the other studies , The lay reviewers as critics, as the author of an online review of a product or service, are likely to have a single-peak distribution, while the non-critical reviews has a J-shaped distribution for product or services 
(delarocas and Narayan, 2006)
.In addition almost all online reviews, based on star ratings are asymmetric and J-shape bimodal distribution which is due to self-selection biases such as underreporting and purchasing biases which underreporting bias results in a bimodal distribution (U-shaped), and the purchase bias causes an asymmetric and positive distribution (J shape distribution) 
(Deloucas and Narayan, 2006)
for our extracted implicit ratings we must consider the subjective biases related to preprocessing of textual data to remove and correcting misspelling words and defining unknown words and detecting the beginning and finishing of a sentence when dot isn't provided. All of this subjectivity bias is related to theory of minds issue which must be consider in other studies for preprocessing of reviews. As mention above by such biases, the explicit rating considering the stars aren't consistent estimators of like or dislikes and we have introduced in the current study an complementary method to study cognitive sequential dependency but it can be improved in other studies by othe softwares We used Stanford CoreNLP for extraction of RPI which don't judge polarity of textual data only by considering words ,per se, since the whole of a sentence involved in dependency grammar analysis. This procedure can prevent making mistake about polarity of meaning of a sentence by focousing only on words than relationships among words. To decontaminate our decision from effect of previous decisions, we can make computational models to detect and maybe cure them and it is possible from low level decision to high influential decision for example in online businesses 
(Luca, 2011)
.our study follows the ideas of vinson et al(2019) by some creativity in methology by using extracted RPI from relevant textual reviews and it provides some new evidence for design of future online measures for opinion mining.Noise in this type of naturally occurring dataset is inherent. sometimes user's don't write anything about a business and once in while changes of characteristics of bussinuiness is possible. People change their mindset for a specific business after coming across poor services and this can draw more attention of consumer for future apts. Hence in our study we must compromise between uncontrolled condition and noisy data.Big data pave the way for broaden our views in accepted principals and test them in wild. since Stanford CoreNLP computes the polarity of the reviews at the level of the sentence, and we had to compute polarity of each review by calculating mean of mean and median and mode of RPIs. Future research can endeavor to extract RPI by other sentiment analysis software's combined with innovative approaches to acquire more reliable results.the finding in cognitive linguistics may be a solution for more accurate software for sentiment analysis at the review level. Should the bias in human decisions is systematic ,we can feed artificial intelligence by analyzing textual data like this study besides explicit ratins to help business owner for designing more suitable online recommendation systems 
(Knijnenburg et al. ,2012)
 
Fig. 1 (
1
Top left) Frequency of review polarity index mode (RPI mode). (Bottom left) Frequency of review polarity index mean (RPI mean). (Top right) Frequency of review polarity index median (RPI median). (Bottom right) Frequency of words in yelp Fig 3. Deviation of the current review RPI median from the reviewer's average RPI median (y-axis) in relation to the previous RPI (x-axis) at a distance of k reviews, for Yelp reviews Fig 4. Deviation of the current review RPI mode from the reviewer's average RPI mode (y-axis) in relation to the previous RPI (x-axis) at a distance of k reviews, for Yelp reviews








Result
 










Dependency grammar




F
M
Last Name






M
C
Year De Marneffe






J
Nivre








Annual Review of Linguistics




5
















K.C. Patrick Low's Q & A Thread




Researchgate












Research of Sentiment Analysis Tools?', ResearchGate.com Website








Accessed on
















Comparing the performance of different NLP toolkits in formal and social media text




A
Pinto






H
Gonçalo Oliveira






A
Oliveira Alves








5th Symposium on Languages, Applications and Technologies (SLATE'16). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik




















B
P
Knijnenburg






M
C
Willemsen






Z
Gantner






H
Soncu






C
Newell


















Explaining the user experience of recommender systems






User Modeling and User-Adapted Interaction




22


4-5














Exploring Relations between Personality and User Rating Behaviors




R
Hu






P
Pu








UMAP Workshops
















Is seeing believing?: how recommender system interfaces affect users' opinions




D
Cosley






S
K
Lam






I
Albert






J
A
Konstan






J
Riedl








Proceedings of the SIGCHI conference on Human factors in computing systems


the SIGCHI conference on Human factors in computing systems




ACM


















X
Liang






L
Fan






Y
P
Loh






Y
Liu






S
Tong




arXiv:1709.07584


Happy Travelers Take Big Pictures: A Psychological Study with Machine Learning and Big Data










arXiv preprint










A
Paxton






T
L
Griffiths




Finding the traces of behavioral and cognitive processes in big data and naturally occurring datasets. Behavior research methods






49














The persistence of structural priming:Transient activation or implicit learning




K
Bock






Z
M
Griffin








Journal of Experimental Psychology: General




129


















10.1037/0096-3445.129.2.177














New consumer behavior: A review of research on eWOM and hotels




A
S
Cantallops






F
Salvi




10.1016/j.ijhm.2013.08.007








International Journal of Hospitality Management




36
















A statistical measure of a population's propensity to engage in post-purchase online word-of-mouth




C
Dellarocas






R
Narayan








Statistical Science




21
















Repetition effects in grasping




P
Dixon






S
Mcansh






L
Read








Canadian Journal of Experimental Psychology




66
















Why is accurately labelling simple magnitudes so hard? A past, present and future look at simple perceptual judgment




C
Donkin






B
Rae






A
Heathcote






S
D
Brown




J. R
















Oxford handbook of computational and mathematical psychology




Z
Busemeyer






J
T
Wang






Townsend




& A. Eidels




Oxford University Press




Oxford, UK












Sequential dependencies in driving




A
Doshi






C
Tran






M
H
Wilder






M
C
Mozer






M
M
Trivedi








Cognitive Science




36
















Representational momentum




J
J
Freyd






R
A
Finke




10.1037/0278-








Journal of Experimental Psychology: Learning, Memory, and Cognition




10
















The robustness of the recency effect: Studies using legal evidence




A
Furnham








Journal of General Psychology




113
















An informational analysis of absolute judgments of loudness




W
R
Garner




10.1037/h0063212








Journal of Experimental Psychology




46
















Sequential effects in absolute judgments of loudness




M
K
Holland






G
R
Lockhead




















10.3758/BF03205747








Perception & Psychophysics




3














Sequential effects in facial expression categorization




S.-M
Hsu






L.-X
Yang




10.1037/a0027285








Emotion




13
















Overcoming the J-shaped distribution of product reviews




N
Hu






J
Zhang






P
A
Pavlou




10.1145/1562764.1562800








Communications of the ACM




52
















Sequential effects in judgments of loudness




W
Behav Res Jesteadt






R
D
Luce






D
M
Green




10.1037/0096-1523.3.1.92Jones








Journal of Experimental Psychology: Human Perception and Performance




3






Taylor & Francis






Big data in cognitive science








Simultaneous priming along multiple feature dimensions in a visual search task




Á
Kristjánsson








Vision Research




46
















The relativity of Babsolute^ judgements




D
Laming








British Journal of Mathematical and Statistical Psychology




37
















Serial dependence in the perception of faces




A
Liberman






J
Fischer






D
Whitney




10.1016/j.cub.2014.09.025








Current Biology




24
















Reviews, reputation, and revenue: The case of Yelp.com (Harvard Business School NOM Unit Working Paper




M
Luca










Cambridge, MA






Harvard University, School of Business
















M
C
Mozer






H
Pashler






M
Wilder






R
V
Lindsey






M
C
Jones






M
N
Jones


















Decontaminating human judgments by removing sequential dependencies


J. Laffterty, C. K. I














J
Williams






R
S
Shawe-Taylor






Zemel




Advances in neural information processing systems 23


& A. Culota


La Jolla, CA




NIPS Foundation














What makes a helpful online review? A study of customer reviews on Amazon




S
M
Mudambi






D
Schuff








MIS Quarterly




34
















Procedural debiasing of primacy/anchoring effects in clinical-like judgments




G
H
Mumma






S
B
Wilson








Journal of Clinical Psychology




51
















Distributions of observed death tolls govern sensitivity to human fatalities




C
Y
Olivola






N
Sagara








Proceedings of the National Academy of Sciences




106
















The relativism of absolute judgments




A
Parducci








2














Learning bundles of stimuli renders stimulus order as a cue, not a confound




T
Qian






R
N
Aslin








Proceedings of the National Academy of Sciences




111
















Sequence effects in categorization of simple perceptual stimuli




N
Stewart






G
D A
Brown






N
Chater




10.1037/0278-7393.28.1.3








Journal of Experimental Psychology: Learning, Memory, and Cognition




28
















Absolute identification by relative judgment




N
Stewart






G
D A
Brown






N
Chater




10.1037/0033-295X.112.4.881








Psychological Review




112


















L
M
Ward






G
R
Lockhead




Response system processes in absolute judgment


















10.3758/BF03213031








Perception & Psychophysics




9














Sequential effects reflect parallel learning of multiple environmental regularities




M
Wilder






M
Jones






M
C
Mozer




Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, &
















Advances in neural information processing systems 22


A.Culotta


La Jolla, CA




NIPS Foundation














Sequential effects: Superstition or rational behavior?




A
J
Yu






J
D
Cohen








Advances in neural information processing systems 21


La Jolla, CA




NIPS Foundation
















Contrast and assimilation in categorization and exemplar production. Attention, Perception, & Psychophysics




V
Zotov






M
N
Jones






D
J
Mewhort




10.3758/s13414-010-0036-z








73















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]