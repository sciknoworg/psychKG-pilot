You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Abstract
In many real life decisions, options are distributed in space and time, making it necessary to sequentially search through them, often without a chance to return to a rejected option. The optimal strategy in these tasks is to choose the first option that is above a threshold that depends on the current position in the sequence. The implicit decision making strategies by humans vary but largely diverge from this optimal strategy; the reasons for this divergence remain unknown. We present a new model of human stopping decisions in sequential decision making tasks based on a linear threshold heuristic. We show that the new model outperforms existing models for sequential decision making. Moreover, it accurately predicts participants' search length, and how they adapt it to different environments. It thus provides an important step towards understanding human sequential decision making.
Decisions that arise in everyday life often have to be made when options are presented sequentially. For example, searching for a parking spot, deciding when to take a vacation day, or finding a partner, all require that the decision maker accepts or rejects an option without knowing if future options will be more attractive. Decisions in such problems involve a trade-off between accepting a possibly suboptimal option prematurely and rejecting the current offer out of false hopes for better options in the future.
Despite the importance of such decisions, relatively little work has been made toward characterizing the process by which humans decide to stop searching in natural settings of this task. The tasks that have been investigated often make unrealistic assumptions. Moreover, current models of the decision process cannot explain why some studies report that humans make a decision too early (e.g., 
Bearden, Rapoport, & Murphy, 2006;
Kogut, 1990;
Seale & Rapoport, 1997;
Tversky & Kahneman, 1974)
, whereas others report that they search too long 
(Juni, Gureckis, & Maloney, 2016;
Shu, 2008;
Zwick, Rapoport, Lo, & Muthukrishnan, 2003)
 compared to optimal search. Specifically, most research has focused on a simplified version of optimal stopping problems, the so-called secretary problem, where only the rank of the option relative to those already seen is shown 
(Bearden et al., 2006;
Seale & Rapoport, 1997
, 2000
 and only the overall best alternative is rewarded. In the secretary problem, the optimal strategy is to ascertain the maximum of the first 37% options and choose the next option that exceeds this threshold 
(Gilbert & Mosteller, 1966)
. Empirical studies suggest that in general people follow a similar strategy but usually set the cut-off (i.e., from which point on they will accept an option that exceeds the previous options) earlier than the 37% prescribed by the optimal solution 
(Kahan, Rapoport, & Jones, 1967;
Seale & Rapoport, 1997)
.
Some studies have investigated tasks closer to real sequential choice problems by presenting the actual value of the option to the decision makers 
(Guan & Lee, 2017;
Guan, Lee, & Vandekerckhove, 2015;
Kogut, 1990;
Lee, 2006;
Shu, 2008;
von Helversen & Mata, 2012)
. In this version, the optimal solution is based on calculating the expected reward of the remaining outcomes. From this expected reward, a threshold is calculated for each option in the sequence as described by 
Gilbert and Mosteller (Gilbert & Mosteller, 1966)
. Results showed that human behavior was systematically biased away from the optimal threshold 
(Guan & Lee, 2017;
Guan et al., 2015;
Lee, 2006)
. Furthermore, these studies still kept the restriction that only the best alternative is rewarded-a payoff function that does not correspond well with everyday experiences.
Humans do find a mate, an apartment to live, or a ticket to fly to their vacation destination, and thus receive some payoff, even if that may not be the highest possible payoff.
In the present research, we propose a new model for optimal stopping decisions using payoffs that are based on the actual values. According to the model, people make sequential decisions by comparing each option to a threshold that they adapt over time based on a linearity heuristic. Specifically, we assume that people adapt their thresholds over the sequence, but do not follow the optimal nonlinear function. In contrast, we propose that they rely on a mental shortcut and adapt their thresholds linearly over the sequence. We show that the new model accurately captures when people stop search and accept an option. Furthermore, it allows predicting under which conditions people search more or less than the optimal model, making it a useful tool to understand human sequential decision making.
The model is based on the assumption that people use a linearity heuristic to adapt their thresholds over time to circumvent the computationally challenging calculation of the (nonlinear) optimal thresholds. Indeed, the misuse of linearity in non-linear situations is a frequent phenomenon in human cognition, and has been referred to as the illusion of linearity (or proportionality). It is one of the oldest misconceptions in the literature on mathematical thought. It occurs arguably because of their simplicity linear functions readily appeal to the human mind rouche1989. As 
Freudenthal put it in 1983
(Freudenthal, 1986
: "Linearity is such a suggestive property of relations that one readily yields to the seduction to deal with each numerical relation as though it were linear". In line with this idea, research has repeatedly shown that children and adults rely on linear functions even when non-linear functions are more appropriate 
(De Bock, Van Dooren, Janssens, & Verschaffel, 2002;
Schouten, Bolderdijk, & Steg, 2014;
Stango & Yinman, 2009;
Wagenaar & Sagaria, 1975)
.
We first sketch a family of cognitive models for describing behavior in optimal stopping problems. We then present results from two behavioral experiments that provide empirical evidence suggesting that human decision makers use linear thresholds instead of variants of the optimal nonlinear threshold. Finally, we show that the model can predict under which circumstances people will search more or less than predicted by an optimal model.


Computational models
We explain the computational models based on a typical optimal stopping problem that we also used in our experiments. The decision maker (here a customer) is planing a vacation and decides to buy the plane ticket online. Ticket prices vary randomly from day to day and the customer wants to find the cheapest ticket. The customer checks the ticket price every day and decides if she wants to accept or reject the ticket, without having the option to go back in time to a previously rejected offer.
Search time is limited by her vacation schedule (i.e., 10 decisions per trial) and, once accepted, the search ends.
More formally, we consider a decision maker who encounters a sequence of tickets with values denoted by x 1 , . . . , x 10 and she wants to find the minimum value in the sequence. If the decision maker accepts ticket x i , the sequence terminates and she has to pay x i ; otherwise, she continues to the next ticket. When the last ticket is reached, it must be accepted.
All models assume that the decision maker relies on a probabilistic threshold to make the decision to accept or reject a ticket-i.e., she chooses ticket x i when x i is smaller than a position dependent threshold t i . In order to model stochastic decisions, we introduce a logistic sigmoid policy with sensitivity parameter β:
θ i = 1 1 + exp{β(x i − t i )} ,
(1)
where θ i denotes the probability to accept option x i on position i. Small values of β produce more stochasticity in decisions, whereas the policy approaches determinism in the limit β → ∞.
We examine the setting of thresholds by comparing the performance of four different models. • The Linear Threshold Model (LTM) postulates that the thresholds are constrained by a linear relation to each other and therefore are completely defined by the first threshold t 0 and the linear increase δ as the sequence progresses:
t i+1 = t i + δ • i,
(2)
This model entails three free parameters, the first threshold t 0 , the increase of the threshold δ and the choice sensitivity β.
• The Biased Optimal Model (BOM) is based on the finding 
(Guan et al., 2015
) that humans are using thresholds that deviate systematically from the optimal thresholds. The optimal thresholds are denoted as t * i for each position i and calculated by determining the expected reward of the remaining options (see 
(Gilbert & Mosteller, 1966)
 for the mathematical derivation). The model entails a systematic bias parameter γ that reflects the divergence of the human threshold from the optimal one. Additionally, the thresholds depend on a parameter α that determines how much their bias increases or decreases as the sequence progresses.
t i = t * i + γ + αi,
(3)
When γ and α are set to 0, the thresholds represent the optimal thresholds that lead to best performance. This model is therefore defined by three free parameters, γ, α and the choice sensitivity β.
• The Cut-off Model (CoM) is inspired by the optimal decision rule for the rank information version of the secretary problem where the distribution of the values is unknown. It assumes that the DM has a fixed cut-off value k that determines how long she explores in the beginning of the sequence. The highest value seen in that initial sample of k tickets is than set as her threshold, and the first value that exceeds this threshold in the remainder of the sequence is chosen. This model has two free parameters, the cut-off value k and the sensitivity parameter β.
Models were implemented in a hierarchical-Bayesian statistical framework using JAGS 
(Lee & Wagenmakers, 2014;
Plummer et al., 2003)
. In a Bayesian framework, information regarding model parameters is represented by probability distributions.
The data is used to update prior distributions resulting in posterior distributions, which were used for inference. A hierarchical implementation allows us to fit data on the individual trial level, while simultaneously taking into account shared statistical structure across participants via group-level distributions. Fitting involved running four independent chains, each with 2000 samples drawn from the posterior distribution, with a burn-in period of 100 samples. Chain convergence was monitored via the calculation of Gelman-Rubin statistics on the four chains, autocorrelation plots, and visual inspection of the chains.


Experiment 1
We asked 129 participants to solve a computer-based optimal stopping problem following the ticket-shopping task described above. Tickets were normally distributed with a mean value of $180 and a standard deviation of $20. In the first phase, subjects learned the distribution using a graphical method proposed by 
(Goldstein & Rothschild, 2014
) (Methods). 
Fig. 1A
 shows that this procedure was successful in ensuring participants learned the distribution.
In the second phase, participants performed 200 trials of the ticket-shopping task.
In each trial, participants searched through a sequence of ten ticket values. For each ticket, they could decide to accept or reject it at their own pace. Participants were aware that they could see up to 10 tickets in each trial, and they were always informed about the actual position and the number of remaining tickets (see 
Fig. 1S
 for a screen shot). It was not possible to go back to an earlier option after it was initially declined.
Once they reached the last ticket (10th) they were forced to choose this ticket. When participants accepted the ticket, they received feedback about how much they could have saved if they had chosen the best ticket in the sequence. Performance was incentivized based on the value of the chosen ticket (Methods).


Behavioral results
Subjects earned on average 17.1 points (SD: 4.2) in each trial (maximum points = 20), which represents a 6% loss on optimal earnings. Participants' marginal accept probabilities steadily increased as the sequence progressed ( 
Fig. 2A
, black line), but differed systematically from the optimal agent's accept probability ( 
Fig. 2A
 , yellow line). On the second-to-last (9th) position, participants accepted the ticket only with a 28%, 95%-CI [26%, 29%], probability, whereas the optimal policy prescribes a significantly higher acceptance rate of 50% (χ 2 (1) = 801, p < .0001).
Overall, subjects stopped earlier than optimal. The average position at which a ticket was accepted was 4.7 (SD: 2.9), whereas an optimal agent would have stopped at an average stopping position of 5.2 (SD: 2.8). However, a closer look at 
Fig. 2A
 reveals that whether subjects accept too early or too late depends on the position: on earlier positions they accept options although they should continue to search, whereas, if they get to position 7, they continue searching even for options that should be accepted according to the optimal policy. 
Fig. 2B
 shows the accept probabilities conditional on ticket values, split into quantile ranges, where the Qi quantile range is defined as the difference between between the 0.ith and the (0.i − 0.1)th quantiles of the ticket values. Accept probabilities for Q4 and Q5 did not reach 50% at position 9. This again contrasts with the optimal policy, according to which the expected value (i.e., Q5) should be accepted with 50% probability at position 9.
Our models did not assume any learning over trials. This assumption was supported by an analysis of performance across trials. A linear mixed model on points per trial with trial number as fixed effect and by-participant random intercepts and random slopes for trial number 
(Singmann, Bolker, Westfall, & Aust, 2016)
 showed no significant effect of trial number (F (1, 64.00) = 0.02, p = 0.88)).   
Figure 2
 . Results from Experiment 1. (A) Probability to accept a ticket depending on the position across all values. The dark line represents participant's frequency to accept, the dashed green line the optimal agent's probability to accept. (B) Participants' probability to accept, where each line represents ticket values ranging from the first quantile to the sixth quantile. Q1: Tickets in first quantile, Q2: Tickets between the first and second quantile etc. (C) Estimated thresholds for the ITM with 9 free threshold parameters (blue line), the LTM with 2 free threshold parameters (red line) and the BOM with 2 free threshold parameters (yellow line) (D) Posterior predictive mean and 95% HDI of the BOM (yellow line) and the LTM (red line) for each quantile, as indicated in (B). Data: black lines
C q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q Q1 Q2 Q3 Q4


Modeling results and discussion
First, we checked whether the key assumptions of the modeling framework were supported. We calculated, per participant and model, posterior predictive p-values that compared misfit (i.e., deviance) of the observed data with misfit of synthetic generated from the model. For the baseline model, ITM, this analysis indicated that the absolute fit was very good, and a probabilistic threshold can describe participants' responses.
The posterior predictive p-value was < .05 for only 8% of participants 
(Fig. 3B)
. Thus, for the vast majority of participants the observed degree of misfit was consistent with the assumptions of the ITM plus sampling variability.
The performance of the LTM was almost identical to the ITM, suggesting that the considerably more parsimonious LTM (three free parameters for LTM compared to ten for ITM) adequately describes behaviour in optimal stopping tasks. The distribution of posterior predictive p-values of the LTM was almost identical to the ITM 
(Fig. 3A)
. 
Fig. 2D
 provides qualitative evidence of the agreement between LTM and data; the LTM adequately predicts accept probabilities for each quantile at every position (see 
Fig. S2
 for agreement between ITM and data). 
Fig. 2C
 compares the recovered thresholds of ITM and LTM and shows that the ITM thresholds essentially form a straight line lying exactly on top of the LTM thresholds. 
Fig. 3C
 shows that the absolute fit of the BOM is clearly worse than for ITM/LTM; for 35% of participants misfit is larger than expected under BOM with p < .05. The source for this increased misfit can be seen in 
Fig. 2D
. Only for Q1 and early positions of Q4 and Q5 did the BOM provide an adequate account. Furthermore, the recovered thresholds 
(Fig. 2C
) of the BOM clearly differ from the ITM in almost all positions. Results of the CoM are not shown explicitly as its performance was extremely poor. All posterior predictive p-values were 0; there was not a single posterior sample for which the observed misfit of the CoM was smaller than for synthetic data generated from the CoM. Furthermore, choices were essentially random for CoM with β CoM = 0.02 [0.01, 0.06] (for the other models, β ≈ 0.21).
These results suggest that humans use a linear threshold when searching for the best option. In the present tests we found that the human performance is only 6% off from the performance of an optimal agent, indicating that the linear adaptation performs quite well. This suggests that using linear thresholds could be an ecologically sensible adaptation to sequential choice tasks. However, it could also mean that the LTMs good performance might not generalize to new task environments, in which the linear model performs less well -an ability that would be crucial for the LTM to be a useful model of human behavior.
Interestingly, search behavior in Experiment 1 indicated that people deviate from the optimal model depending on the value structure of the sequence: In trials with good options in the beginning people tended to accept them too early. However, in trials with few or no good options they continued search longer than the optimal model prescribed 
(Fig. S3)
. Accordingly, in tasks with plenty good options people might search less than optimal. However, in tasks in which good options are rare they might be tempted to search too long.
To test this assumption and derive predictions how people will adapt to the tasks we conducted a simulation study comparing the optimal solution with a "optimal" linear model (using a grid search to find the best performing parameter values for the linear model) and an empirical study manipulating the distributions of ticket prices across three conditions: (1) a right skewed distribution simulating an environment with plentiful desirable alternatives, (2) a normal distribution as in experiment 1, (3) a left skewed distribution simulating a scarce environment. As illustrated in 
Fig. 5D
, the simulation study showed that the optimal model predicts more search in a plentiful environment, whereas a linear model predicts more search in the scarce environment.
Furthermore, the linear model predicts a stronger decline in performance in the scarce environment than the optimal model. 


Experiment 2
To show that the LTM can capture people's choice behavior across different tasks and allows predicting when people will search too much or too little we conducted a second experiment manipulating the distribution of options. We manipulated the different task environments by sampling tickets from (1) a left skewed 
(PERT 1 (40,
195,
200)
), (2) a normal 
(PERT(90,
140,
190)
) or (3) a right skewed distribution (PERT(120,125,400)), representing a scarce, a normal and a plentiful environment, respectively (see 
Fig. 1 B-D, black lines)
. Each participant was assigned to only one condition. The final sample included 172 participants. The procedure was identical to Experiment 1, consisting of a learning phase, were participants got acquainted with the distribution 
(Fig. 1 B-D, participant's estimate in red lines)
, and a testing phase. In the testing phase, participants had to choose the best ticket out of a sequence of 10 tickets with 200 trials (Methods).


Behavioral results
Participants' performance increased from the left-skewed (scarce) environment to the right-skewed (plentiful) environment 
(Fig. 5A
) (F (2, 268) = 114, p < .0001).
Furthermore, in line with the predictions from the "optimal" linear model, the loss compared to optimal performance was most salient in the left-skewed condition, where only few good tickets occur 
(Fig. 5A
, black line (data) vs. yellow line (optimal model predictions)).
The average search length 
(Fig. 5B
) decreased from the left skewed scarce environment to the right skewed plentiful environment, F (2, 268) = 11.5, p < .0001.
This pattern also follows the predictions of the "optimal" linear model in the simulation study but is in contrast to the optimal model's predictions. Specifically, in the left skewed environment, where good tickets occur very rarely participants searched too long compared to an optimal agent, whereas in the environment where good tickets are abundant, participants ended their search too early compared to the optimal strategy.


Modeling Results
Modeling results replicate the results from Experiment 1 and indicate that the LTM performed extremely well (posterior predictive p-value was < .05 for only 10% of participants in condition 1, 7% of participants in condition 2, and 9% of participants in condition 3, 
Fig. S4 A-C)
. The observed accept probabilities 
(Fig. 4 A-C, black lines,
 where each line represents a ticket price within the specified quantile range) are adequately described by LTM predictions (red lines) on almost all positions and in all three environments. Moreover, the threshold parameters for the ITM are again on top of the threshold parameters estimated by the LTM in all the three environmental conditions 
(Fig. S5 A-C)
.
These results indicate that humans use a linear threshold in optimal stopping problems, independent of the distributional characters of the task. However, this does not mean that people do not adapt to the task at all. As 
Fig. S5
 A-C shows, participants are responsive to task features and adapt their first threshold and the slope to the distributional characteristics of the task within the constraints of the linear model.


Discussion
In this paper, we show that humans appear to solve optimal stopping tasks by applying a simplifying strategy, where thresholds are linearly increased over time. We implemented this assumption in a computational framework and showed that this  
Figure 5
 . (A) Average performance (in points/trial) vs distributional structure of the task. Participants: black line, performance when using optimal thresholds: yellow line, performance when using "optimal" linear thresholds: blue line. (B) Average search length vs distributional structure. Participants: black line, optimal thresholds: yellow line, "optimal" linear thresholds: blue line. Note that model predictions are based solely on distributional characteristics of the environments and not on model fit. model not only provided an adequate description in absolute terms, it also outperformed other models found in the optimal stopping literature. Further, the linear threshold assumption makes a non-trivial prediction about search length, which we confirmed experimentally: Humans stop earlier in environments with many desirable alternatives compared to scarce environments. These correct predictions contrast with the prediction from the optimal model. In a scenario with many desirable alternative, the linear adaptation has little effect on performance compared to the optimal strategy, and therefore may be an efficient shortcut that enables similar performance with less search. However, in an environment with only a few good alternatives, the linear adaptation entails a 20% loss in performance compared to the optimal solution, with an increase in search length showing the importance of understanding how people solve sequential decision tasks and the mental shortcuts they rely on.
We have used a sequential search scenario where the amount of options and the sampling distribution of the options were known. This design allowed us to study human deviation from optimality without intertwined factors such as learning or memorization.
In this setting, the linear threshold model is able to capture the psychological search process accurately. One could imagine more complex scenarios where environments are non-stationary 
(Navarro, Newell, & Schulze, 2016)
 or where the option's distribution is unknown 
(Stoll, Fontanier, & Procyk, 2016)
 and our model serves as an ideal starting point to examine the influence of such factors on human search strategies.
The human bias to simple functions is well reported in a diverse set of domains 
(De Bock et al., 2002;
Little & Shiffrin, 2009;
Stango & Yinman, 2009;
Wagenaar & Sagaria, 1975;
Zwick et al., 2003)
 and our studies also correspond well with recent studies demonstrating that human choice behavior in an explore-exploit paradigm is well described by a linear threshold rule 
(Sang, Todd, Goldstone, & Hills, 2018;
Song, Bnaya, & Ma, 2019)
. The reinforcement of linearity at numerous occasions in school mathematics to adult life, along with its intrinsic simplicity and self-evidence, may lead to a tendency to see and apply the linear model 'everywhere'. Why humans make irrational choices has puzzled economists and psychologists for decades and the findings described here suggest that some violations of choice rationality are a natural consequence of linearity.


Material and Methods
Participants. We recruited 438 participants (172 females; age range: 19-59; N 1 = 144, N 2 cond1 = 92, N 2 cond2 = 110, N 2 cond3 = 92 in experiment 1 and 2, respectively) on Amazon Mechanical Turk to participate in the experiments.
Participants gave informed consent, and the Harvard Committee on the Use of Human Subjects approved the experiments. Participants were excluded from analysis if they accepted the first option in a trial in more than 95% of the trials. After applying these criteria, we included data from 404 participants in the subsequent analysis (N1=129, N2 cond1 = 86, N 2 cond2 = 102, N 2 cond3 = 84).


Task.
In both experiments, participants performed the same online ticket shopping task that consisted of a learning and a testing phase. In the learning phase, participants experienced the distribution from which the ticket values were drawn. In Experiment 1, the distribution from which the value were sampled was a normal distribution with a mean of 180 and standard distribution of 20. The procedure was as follows: Participants encountered sequentially 50 ticket values drawn from the predefined distribution 
(Fig. S1A)
. After every ten tickets, participants had to guess the average value of the tickets seen so far 
(Fig. S1B)
. After each guess, participants were told the correct response. At the end of the learning phase participants were asked to complete a histogram (by dragging the bars) for an additional 100 tickets that were drawn from the same predefined distribution 
(Fig. S1C
 ). Participants received feedback by observing the correct distribution superimposed over their estimate 
(Fig. S1D
) 
(Goldstein & Rothschild, 2014)
.
In Experiment 2, we used three conditions to realize three different distributional environments. In the first condition, tickets were drawn from a left skewed distribution 
(PERT(40,
195,
200)
). In the second condition, tickets were sampled from a normal distribution 
(PERT(90,
140,
190)
), and in the third condition, tickets were sampled from a right skewed distribution(PERT(120,125,400). The procedure of the learning phase was identical to Experiment 1 except that we removed the section about reporting the mean during learning in the left and right distribution scenario (section B in 
Fig. S1B
).
Visual inspection of the performance in the histogram task suggested that participants learned the target distributions well 
(Fig. 1
).
In the second phase of the experiments, participants performed the ticket-shopping task. It started with a practice trial followed by 200 test trials. In each trial participants searched through a sequence of ten ticket values randomly drawn from the predefined distribution. For each ticket, they could decide to accept or reject it at their own speed. People were aware that they could see up to 10 tickets in each trial and they were always informed about the actual position and the number of remaining tickets 
(Fig. S1E)
. It was not possible to go back to an earlier option after it was initially declined. Once they reached the last (10 th ) ticket they were forced to accept this ticket. When participants accepted the ticket, they received explicit feedback about how much they could have saved by choosing the best ticket in the sequence.
Participants were paid according to their performance. In each of the 200 trials there was a maximum of 20 points to earn. The participants received the maximum amount of 20 points if the chose the best ticket and 0 points for the worst ticket in the sequence. The payoff for a ticket between the best and the worst was calculated proportional to the distance to the best ticket in the sequence. The exact calculation for the points in each trial i was as follows:
points i = 20 • (ticket max − ticket chosen ) ticket max − ticket min ,
(4)
where ticket max represents the most expensive ticket in the sequence and ticket min the cheapest ticket in the sequence. Participants received a base payment of $4 and earned between $0 and $4 additionally depending on their performance.
nolistsep•
The Independent Threshold Model (ITM) serves as our baseline. It assumes no dependency between the thresholds. It entails N independent threshold parameters t 1 , ..., t N , one for each position in the sequence, where the decision maker can decide to accept or reject an offer (at position N + 1 the ticket must be accepted). The thresholds can take any value across positions. The model maintains maximal flexibility and provides an upper limit how well any threshold model can describe a person's decision given the assumption of a probabilistic threshold.


Figure 1
1
. A-D: Results of the distribution learning phase: Participants' aggregated responses in the histogram task (details in Methods). Empirical data appear in black lines and the predefined distribution in red lines and generally show good agreement. A: Experiment 1: Predefined distribution is a normal distribution, B-D: Experiment 2. B: Condition 1: Predefined distribution is a left skewed distribution. C: Condition 2: Predefined distribution is a normal distribution. D: Condition 3: Predefined distribution is a right skewed distribution.


Figure 3 .
3
Individual posterior predictive p values for the LTM (A) the ITM (B) and the BOM (C) for each individual.


1Figure 4 .
4
The PERT distribution is a special case of the beta distribution defined by the minimum (a), most likely (b) and maximum (c) values that a variable can take and an additional assumption that its expected value is µ = a + 4b + c 6 . Results of experiment 2: Empirical data appear in black lines and the posterior predictive means of the LTM in red lines. Bars represent the 95% HDI. The different lines represent the tickets ranging in from the Q1 to Q6. Q1: Tickets in first quantile, Q2: Tickets between the first and second quantile etc. (A) Condition 1: Tickets are left skewed distributed(PERT(40,195,200)) corresponding to a scare environment. (B) Condition 2: Tickets are normally distributed(PERT(90,140,190)). (C) Condition 3: Tickets are right skewed distributed (PERT(120,125,400)) corresponding to a plentiful environment.














Experimental studies of sequential selection and assignment with relative ranks




J
N
Bearden






A
Rapoport






R
O
Murphy








J Behav Decis Mak




19


3
















Improper use of linear reasoning: An in-depth study of the nature and the irresistibility of secondary school students' errors




De
Bock






D
Van Dooren






W
Janssens






D
Verschaffel






L








Educ Stud Math




50


3
















Didactical phenomenology of mathematical structures




H
Freudenthal








Springer Science & Business Media












Recognizing the maximum of a sequence




J
P
Gilbert






F
Mosteller








J Am Stat Assoc




61
















Lay understanding of probability distributions




D
G
Goldstein






D
Rothschild








Judgm Decis Mak




9


1














The effect of goals and environments on human performance in optimal stopping problems




M
Guan






M
D
Lee








Decision




5


4
















A hierarchical cognitive threshold model of human decision making on different length optimal stopping problems




M
Guan






M
D
Lee






J
Vandekerckhove








Cogsci
















Information sampling behavior with explicit sampling costs




M
Z
Juni






T
M
Gureckis






L
T
Maloney








Decision




3


3


147














Decision making in a sequential search task




J
P
Kahan






A
Rapoport






L
V
Jones








Percept Psychophys




2


8
















Consumer search behavior and sunk costs




C
A
Kogut








J Econ Behav Organ




14


3
















A hierarchical bayesian model of human decision-making on an optimal stopping problem




M
D
Lee








Cogn Sci




30


3
















Bayesian cognitive modeling: A practical course




M
D
Lee






E.-J
Wagenmakers








Cambridge university press












Simplicity bias in the estimation of causal functions




D
R
Little






R
Shiffrin








Proceedings of the annual meeting of the cognitive science society


the annual meeting of the cognitive science society






31












Learning and choosing in an uncertain world: An investigation of the explore-exploit dilemma in static and dynamic environments




D
J
Navarro






B
R
Newell






C
Schulze








Cognitive psychology




85
















Jags: A program for analysis of bayesian graphical models using gibbs sampling




M
Plummer








Proceedings of the 3rd international workshop on distributed statistical computing


the 3rd international workshop on distributed statistical computing
Vienna, Austria






124


125












Explore/exploit tradeoff strategies in a resource accumulation search task




K
Sang






P
M
Todd






R
L
Goldstone






T
T
Hills












Manuscript resubmitted to Cognitive Science








Framing car fuel efficiency: Linearity heuristic for fuel consumption and fuel-efficiency ratings




T
M
Schouten






J
W
Bolderdijk






L
Steg








Energy Efficiency




7


5
















Sequential Decision Making with Relative Ranks : An Experimental Investigation of the " Secretary Problem




D
A
Seale






A
Rapoport








Organ Behav Hum Decis Process




69


3
















Optimal stopping behavior with relative ranks: The secretary problem with unknown population size




D
A
Seale






A
Rapoport








J Behav Decis Mak




13


4
















Future-biased search: the quest for the ideal




S
B
Shu








J Behav Decis Mak




21


4
















Afex: Analysis of factorial experiments. R package version 0.16-1




H
Singmann






B
Bolker






J
Westfall






F
Aust




















Sources of suboptimality in a minimalistic explore-exploit task




M
Song






Z
Bnaya






W
J
Ma








Nat Hum Behav




1














Exponential growth bias and household finance




V
Stango






J
Yinman








The Journal of Finance




64


6
















Specific frontal neural dynamics contribute to decisions to check




F
M
Stoll






V
Fontanier






E
Procyk








Nature communications




7


11990














Judgment under uncertainty: Heuristics and biases




A
Tversky






D
Kahneman








Science




185


4157
















Losing a dime with a satisfied mind: Positive affect predicts less search in sequential decision making




B
Von Helversen






R
Mata








Psychology and aging




27


4


825














Misperception of exponential growth




W
A
Wagenaar






S
D
Sagaria








Percept Psychophys




18


6
















Consumer sequential search: Not enough or too much?




R
Zwick






A
Rapoport






A
K C
Lo






Muthukrishnan








Mark Sci




22


4

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]