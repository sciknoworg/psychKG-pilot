You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



The world is full of obvious things which nobody by any chance ever observes.


Sir Arthur Conan Doyle The Hound of the Baskervilles
In our everyday lives, we are constantly bombarded with information that we must navigate to make decisions consistent with our goals. Typically, information comes from multiple sources, or dimensions, which can be prioritized according to their relevance in the decision process. The challenge of making choices based on many dimensions can be vastly simplified by selective attention. Ideally, selective attention allows us to focus on dimensions of information that are most relevant to our current goals, while ignoring those that are irrelevant. The benefits of selective attention are clear: By selectively attending to relevant dimensions, we can avoid expending the time and energy involved in considering less relevant dimensions, and therefore make decisions more quickly and efficiently.
The efficient deployment of selective attention is complicated by the fact that we are often initially ignorant about which dimensions are relevant to our goals.
For example, if we take up a new hobby such as painting, we may initially know little about what information can help us choose good quality paint brushes. In these cases, we must instead learn relevance through our experiences, summaries of which are stored in memory. For example, we may acquire experiences with brushes that possess many dimensions (e.g., material, brush shape, price, and manufacturer), observe their quality, and retain associations between dimensions and quality in memory.
How do selective attention, learning, and memory come together to support decisions? The answer to this question is far from straightforward. In one direction, selective attention may be oriented towards dimensions that we have observed to be associated with goal-relevant outcomes. In the other direction, selective attention may guide the dimensions that we encode in memory and learn about. Over the course of experience, influences in both directions may unfold, producing cyclical, dynamic interactions among selective attention, learning, memory, and decision making.
Here, we investigate how dynamic interactions among selective attention, learning, memory, and decision making may not simply bestow benefits of efficiency and consistency. Instead, these same efficiency-promoting dynamics may also impede our ability to detect and use information that is potentially relevant to our goals. One key cost may be incurred when our initial experiences, by chance, convey a spurious association between less relevant dimensions and goal-relevant outcomes. For example, we may initially observe and encode an association between paint brush manufacturer and quality because we happened to try a high-end brush from one manufacturer and a budget brush from another.
By selectively attending to the spuriously relevant dimension (manufacturer), we may never learn the most relevant dimension (cost). We therefore refer to this cost as an "attention" trap. A second key cost may be incurred when the information most relevant to our goals changes over time. For example, high-end brushes may initially be of better quality than budget brushes, but if a cheap, high-quality brush material is invented, price may become irrelevant or even counterproductive for determining quality. However, by learning to selectively attend to price, we may subsequently fail to consider material as a determinant of quality, and therefore never learn this new association between material and quality. Such behavior is similar to an attention trap. However, because the neglected information was once learned to be irrelevant, we will refer to this cost as a "representation" trap because the trap is produced from our learned experiences.
The dynamic, cyclical nature of these interactions and their outcomeswhich we refer to as "cognitive inertia" -poses a tall hurdle in studying how they unfold. The potential difficulty is that the three components of attention, The central thesis of our study is to establish that attention, learning and memory are intertwined, and it is the nature of this dependency that produces both efficient learning and the pitfalls of attention and representation traps 
[4]
.
To examine the extent to which these constructs are intertwined, we develop a computational model, which we refer to as the "Fully Constrained by Representation" model, that assumes each of these constructs are constrained by one another, as illustrated in 
Figure 1A
, and their interaction can be used to make explicit predictions for observable measures. As we will discuss below, the observable measures from our study for decision making (blue node) -as informed by choice response time data -and attention (red node) -as informed by eye fixation data -will constrain the set of possible changes that can occur within the representation node (yellow), which is the only unobservable element in the diagram of 
Figure 1A
. The unobservable constructs of encoding dimensions and their associations with outcomes in memory during the course of learning are encapsulated in the representational component of the model. We will use latent variable modeling to infer the most likely representation that explains the simultaneous changes that occur in the attention and decision making data across time.
To examine the extent to which representation, attention, and decision making are intertwined, we used a three-pronged approach: (1) Experimental design,  
[4]
. To investigate representation traps, we introduced an unannounced switch half-way through the category learning task where the most relevant dimension became irrelevant, and an irrelevant dimension became relevant 
[5]
. This manipulation can cause learners to fall into representation traps:
if participants learn and remember that a dimension is irrelevant, they may have difficulty adapting to the change in relevance.
The second prong of our approach was to collect observable measures that would allow us to mathematically identify dynamic relationships between decision making, representation, and selective attention. In addition to the traditionally observed choice and response time aspects of decision making, we also used eye tracking to acquire a gaze-based measure of selective attention to dimensions 
[6,
7,
8,
9,
10,
11,
12,
13]
. The gaze measure allowed us to specify which dimensions would be encoded in memory and associated with category membership in the representation. The pattern of associations stored in the representation would then contribute to the model's impression of dimension relevance, which in turn would influence how dimensions were weighted when making decisions and allocated during selective attention.
The final, critical prong of our approach was to use a suite of computational models to systematically characterize the dynamic processes that gave rise to the measured categorization decision and selective attention behavior.
The foundation for this set of models was the Fully Constrained by Representation model ( 
Figure 1A
) in which selective attention, representation, and decision making dynamically interact to mutually constrain one another. To test whether these constraints are necessary to account for participants' behavior, we compared how well the Fully Constrained by Representation model predicted behavior against a set of subordinate models, in which each of the constraints were systematically relaxed. To anticipate our results, the Fully Constrained by Representation model provided the best predictions for the majority of participants. By contrast, subordinate models failed to predict patterns of fixations and behavior we observed in the data, such as attention and representation traps.
After establishing that the best description of our data included all constraints among attention, representation, and decision making, we examined the extent to which different constraints gave rise to attention and representation traps. After first confirming the generality of traps, we suggest a prescriptive strategy for avoiding these traps, while simultaneously maintaining accurate and efficient decision-making processes.


Results
The data came from a two-phase category learning task. Participants categorized items with binary-valued dimensions that varied in relevance to category membership: 
(
 between stimulus features and category membership, and (3) our evolving representation maintains a sense of dimension relevance, which ultimately guides how attention will be allocated to dimensions when making decisions. In the results below, we show how disconnecting any of the nodes leads to predictions that mismatch human data, in both qualitative and quantitative ways. However, we also will show how the presence of these connections consistently produces learning traps, and as such, we suggest a prescriptive strategy for avoiding traps despite the default architecture of human learning.
We present the results in five sections. First, we present a summary of the main empirical results as a guide for evaluating subsequent model evaluations.
Second, we provide a qualitative analysis illustrating how different constraints between representation, attention, and decision making affect theoretical predictions for the observable measures of choice, response time, and fixations on features. Third, we provide a quantitative analysis that systematically evaluates the relative plausibility of different constraints among attention, representation and decision making by fitting a set of model variants systematically designed to test counterfactuals to our data. Fourth, we compare the model fits to fixation and choice response time data to ensure that the representation inferred by the model is an accurate description of the key patterns of selective attention and learning in our data. Finally, we show how representations used in our study are susceptible to learning traps, and provide three prescriptive strategies for everyday people who wish to avoid such traps.


Summary of Empirical Results
Data were analyzed to assess the benefits and costs of selective attention to a decision-making task in which the relevance of dimensions to correct decisions had to be learned. Specifically, we first tested whether participants initially experienced benefits of selective attention as characterized by (1) increased attention to the deterministic dimension, and (2) corresponding improvements in decision accuracy and speed during Phase 1. We then tested whether participants incurred costs of selective attention in Phase 2 as characterized by
(1) a failure to identify the newly deterministic dimension that was previously irrelevant, and (2) a failure to achieve previous levels of decision speed and accuracy. 
Figure 4
 provides the most important summaries of the data alongside the model fits (which we discuss below), and Extended Data 
Figure 1
 shows a more in-depth analysis of the data alone.  
Figure 4C
; left panel of Extended Data 
Figure 1C
). Performance on test trials revealed effects of selective attention that were similar to the training trials (Extended Data 
Figure 1B
). Hence, over Phase 1, fewer dimensions were attended through time, and the attended dimensions were more relevant, resulting in both increases in accuracy and decreases in response time. The data confirmed this pattern. Based on the fixation data, upon entering Phase 2, it appeared that participants quickly realized the deterministic dimension had become less relevant, resulting in a reorientation of attention. However, in this phase, attention tended toward probabilistic dimensions rather than the newly deterministic dimension. As the right panel of Extended Data 
Figure 1E
 shows, the newly deterministic dimension was attended approximately equally to the newly irrelevant dimension, and attention to these dimensions was lower than that of the probabilistic dimensions (62.9% of time looking at probabilistic dimensions versus 20.3% and 16.8% for deterministic and irrelevant dimensions, respectively). This failure to reorient attention to the newly deterministic dimension was accompanied by corresponding costs to categorization accuracy and speed. 
Figure 4D
 shows that an immediate drop in accuracy occurred upon entering Phase 2 (also see right panel of Extended Data 
Figure 1A
). Although this accuracy did rise to a value of 0.805 by the end of the Phase 2 category learning trials, this accuracy level was substantially lower than the accuracy level attained at the same point in Phase 1 (0.957). The costs in response time showed a similar pattern, where response times sharply rose at the beginning of Phase 2 ( 
Figure 4C
; right panel of Extended Data 
Figure 1C
), and steadily declined but never reached the speed at the end of Phase 1 (note that longer response times are typically related to greater decision uncertainty 
[15,
16,
17]
).
Performance on test trials revealed similar costs of selective attention (Extended Data 
Figure 1B
).


Links Among Representation, Attention, and Decision Making: Theoretical Predictions
In the introduction, we suggested that dynamic, cyclical processes between attention, representation, and decision making may unfold when the relevance of dimensions to decisions must be learned. First, attention may constrain the representation that learners form about the relevance of different dimensions to decisions. In other words, the relevance of a dimension to decisions may only be represented when the learner has attended to the dimension. Second, this learned representation may constrain attention and decision making. Specifically, learners may attend primarily to dimensions that they have learned are relevant, and the contribution of these dimensions to decisions may depend on their learned relevance. Whereas the results of the experiment suggest that these cyclical processes unfold, they do not shed light on the processes themselves. Specifically, they do not tell us: (1) How the information participants  There are three components of the model: attention, representation, and decision making; as well as two modes of operation: a decision process mode, and an updating mode. In decision mode, the model uses the information contained in the representation ( 
Figure 1B)
 to selectively attend to particular stimulus dimensions. In 
Figure 1B
, the representation is illustrated by a system of nodes corresponding to each feature (x-axis) within a dimension (partitions) and each possible choice response (orange versus blue nodes). These nodes carry weights that describe the relative likelihood that each feature is associated with each choice response (y-axis values). In 
Figure 1C
, eye tracking data overlay an example stimulus where different features (i.e., color/shapes) appear in different dimensions (i.e., body locations) on each trial. On this trial, the participant first prioritized the neck button, then the foot, hand, and head dimensions through time (color coded in Panels C and D). Through the learning process, each stimulus feature becomes associated with the two categories (i.e., a Flurp or Jalet in our experiment), and this information is adjusted and maintained within the representation.
The representation is used in two ways. First, it is used to selectively attend to the specific dimensions on a given trial, and second, it is used to guide the category choice based on the set of features that are attended within a given trial. When fixating on a feature, the past associations of that feature with each category response are remembered, and information is additively accumulated as the observer fixates on different dimensions. 
Figure 1D
 shows many simulations of this accumulation process through time, where the particular fixation pattern in this example initially accumulates more evidence for the Jalet category based on the button, foot, and hand features, but then accumulates rapid information for the opposing Flurp category later in the trial when looking at the head. Eventually a sufficient amount of evidence is collected to trigger a response, and feedback from the experiment provides the correct category label. At this point, the model switches to update mode, where the information that was attended during the decision mode, along with the information about the true category label, is used to update the information in the representation. Updating the representation simply involves increasing the likelihood that the encoded features are associated with the choice corresponding to the feedback, and decreasing the likelihoods for features that were either unattended or inconsistent with the feedback. If, as in this example, feedback informed the participant that the stimulus was a Flurp, the representation values corresponding only to the attended features and the Flurp category would be increased.
Completing the cycle, the newly updated representation would subsequently guide which dimensions will be attended on the next trial.  used in the model is based on reinforcement learning principles, where the likelihood of each category is maintained as a function of each feature value, with adjustments being made on each trial depending on what information was attended in (C). (C) Illustrative stimulus and associated fixation time series (overlaid dots) for the eye tracking data which serves as a proxy for attention in the model. The color gradient reflects time in both Panels C and D. (D) The decision making process on each trial is driven by the evolving representation in (B), and the proportion of fixations during the decision period, shown in (C). Two accumulators representing the choice options race to a threshold amount of evidence (not shown), at which time a choice is made corresponding to the winning accumulator (i.e., a "Flurp" response). In Panels B and D, the Flurp category is represented in blue, and the Jalet category is represented in orange. After a choice is made, feedback about the choice, and the attended features, are used to update the representation, which is used in subsequent trials.


Attention Decision Making
Representation A D • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • •
At this point, we have provided a high-level summary of the model, but we have yet to provide quantitative support for the presence of cyclical loops among attention, representation, and decision making. In this section, we introduce a set of model variants, all of which are systematically derived from the core Fully Constrained by Representation model. Specifically, each model was created by removing one or more connections between the nodes in 
Figure 1A
, which relaxes a set of constraints. We begin by providing the reader with some qualitative intuition about the effects that relaxing each constraint has on the model's predictions for observable data (i.e., either eye tracking, choice, or response time) from our experiment. In later sections, we will provide full quantitative analyses by fitting the set of models to data.    


Description of Model Variants


Theoretical Predictions
To simulate each model, we provided each model variant with the same stimuli used in our experiment, and assumed two phases with training periods only (i.e., no testing, because test trials did not allow participants to revise or update their representations). For each simulation, we randomly chose a stimulus set from the actual experimental design used in our experiment, simulated the model under a specific set of constraints (i.e., a model variant), and recorded key predictions for observed variables. We repeated this process 1000 times for each model variant. To simulate fixations, we assumed that five dimensions were sampled with replacement according to a probability vector that may be informed by the representation, depending on the model variant. To keep the simulation simple, if a dimension were sampled, we assumed it was also encoded and would be used to update the representation. All parameters in the model were held constant across model variants so that the effects of each constraint could be isolated.   


Switchboard Analysis
One approach to validating the Fully Constrained by Representation model would be to simply fit the model to data and visually inspect how well the model captures important trends in the data. However, in our view, it is not enough to develop only one computational model with one specific set of assumptions because such a procedure does not facilitate a systematic evaluation of model mechanisms [e.g., 
31,
32]
. Instead, we constructed a suite of models to factorially test the plausibility of each constraint under consideration, a type of modeling we refer to as "switchboard" modeling 
[33,
34,
27]
.  
Figure 3B
 illustrates the lattice structure that specifies how constraints in the Fully Constrained by Representation models are systematically relaxed to produce the model variants. Systematically relaxing these constraints allows us to evaluate the degree to which each constraint in 
Figure 3A
 is necessary to account for human data. Each node in the lattice represents a specific model variant, and the dimensions of the lattice correspond to dimensions of constraints that were relaxed. In conjunction with 
Figure 3A
, there are two ways in which Link 1 can be applied, two ways in which Link can be applied, and three ways in which Links 2 and 5 can be combined, creating a total of 12 model After fitting each model independently across participants, we used the Bayesian Information Criterion [BIC; 36, 37] to assess how well each model captured each participant's data, while penalizing for complexity. In the BIC, lower scores indicate better model performance. One advantage of these types of switchboard analyses is that they enable one to assess how much a particular mechanism or link contributes to model performance, aggregated across the model variants under consideration. 
Figure 3C
 shows the aggregated performance metrics associated with each link in Panels A and B. Here, we simply averaged the performance score for models with and without a specific constraint, and then calculated the difference in performance between those sets of models, giving us an impression of whether a particular constraint enhanced or harmed model performance. Here, 
Figure 3C
      whereas the translucent squares show participant-level predictions. Here, we generated predictions from the model for all trials, and then determined how often the model predicted when participants would make a specific category response (i.e., "Jalet"). Given these counts, we used the actual responses from the data to bin the predictions. Specifically, we averaged the model predictions for trials in which participants actually made either the "Jalet" response (orange) or the "Flurp" response (blue). Ideally, the orange dots would sit at 1.0 and the blue dots would sit at 0.0 if the model were making perfectly accurate predictions. The model generally performs well at the aggregate level, although it does struggle to predict a few participants' response data from within-trial attentional (i.e., eye-tracking) dynamics (e.g., transparent points near 0.5). Triallevel model predictions for the probability of making a "Jalet" response on trials in which either a "Jalet" response was made (orange; top) or a "Flurp" response was made (blue; bottom). Larger dots reflect across-subject averages, whereas transparent squares are individual trials. Dashed vertical lines represent block transitions, and the dashed horizontal line reflects chance prediction accuracy.


The Effects of Representation on Cognitive Inertia Traps
Having identified the most plausible representation used by the participants in our experiment, we next examine the potential impact that those representations have when learning in our task. Of particular interest are the cognitive inertia traps described in the introduction, which are produced by the dynamic constraints between attention, representation and decision making during the course of learning. Specifically, these constraints confer some advantages, when narrowing attention to only dimensions that have been learned to be relevant improves the efficiency of decision making (see 
Figure 2
). However, these constraints can also incur costs. In "attention traps", when In this section, we investigate how generalizable trapping behavior is. To do so, we used each participant's best-fitting representation to simulate additional realizations of that participant's behavior had they experienced a different set of stimulus sequences (i.e., labeled "Experimental Design" in 
Figure 5
). This analysis creates a 38 (participant) by 38 (design) simulation study, which we then replicated 10 times to better ascertain the variance of our results (i.e., 14,440 simulated experiments). We simulated gaze fixations by assuming participants sampled dimensions to attend when making their decisions, and then used the sequence of samples to identify how often each simulation fell into traps. To identify traps, we specified that a dimension must have the highest perceived relevance for all five of the last trials for a given phase. If a single dimension was not prioritized in these final trials, the representation was not considered to be consistently "trapped", and so we did not include it in the analysis below.
If a single dimension was prioritized, we then calculated the probability that the prioritized dimension either was the most diagnostic dimension (i.e., the deterministic dimension) or was not (i.e., either a probabilistic dimension or an irrelevant one).   
Figure 5D
, is consistent with the Attention Unconstrained by Representation model from the first simulation study (see 
Figure 2
). Due to the random sampling policy, 
Figure 5E
 shows that the Attention Unconstrained by Representation model rarely prioritizes a dimension consistently enough to fall into traps in either Phase 1 or Phase 2, avoiding both attention and representation traps.
However, this failure to use the representation to inform dimension sampling has drastic implications for the overall accuracy level. 
Figure 5F
 shows that the grand average accuracy barely reaches 60% correct. Hence, although the Attention Unconstrained by Representation model is good for avoiding traps, its performance is too inaccurate to be considered a good decision policy.  where the model is forced to randomly sample dimensions that it may not consider relevant throughout the learning process. Learning about these dimensions enables the possibility that another dimension will emerge as the most relevant dimension, thereby avoiding any learning traps. 
Figure 5L
 shows that unlike the random sampling policy in 
Figure 5F
  The results of the present study reveal that fast and frugal heuristics 
[39]
 that ignore dimensions or prioritize particular dimensions in order to obtain more efficient decision-making can sometimes go awry, trapping learners into suboptimal patterns of selective attention that lead to poor decisions from which they seem incapable of recovering (see 
Figure 5)
. 


Stimuli
Stimuli were colorful images of creatures composed of seven discrete-valued dimensions (see 
Figure 6A
) similar to those used previously by Deng and Sloutsky 
[40,
41,
42,
43,
44]
 and Blanco and Sloutsky 
[5]
. The creatures were divided into two categories, which were referred to in the experiment as Flurps and Jalets.
Of the seven dimensions (antenna, head, body, button, hands, feet, and tail), one dimension deterministically predicted category membership (i.e., the deterministic dimension), five dimensions were probabilistically predictive with 80% cue validity (i.e., the probabilistic dimensions), and one dimension was non-predictive-having the same likelihood of occurring across all exemplars of both categories and therefore irrelevant to classification (i.e., the irrelevant dimension). 
Figure 6B
 shows the stimulus structure used in the task.
Stimuli were organized into two pairs of complementary sets for the two phases of the experiment. Each set in a pair was identical to its counterpart except that the deterministic and irrelevant dimensions swapped roles (i.e., deterministic dimensions in one phase became irrelevant in the other, and vice versa). Probabilistic dimensions and the category labels remained the same.
As discussed below, participants learned one set of features in Phase 1 of the experiment (i.e., before the switch), and then the stimuli were unexpectedly replaced with the complementary set for Phase (i.e., after the switch).
The two pairs of sets differed in which dimensions were deterministic/irrelevant:
hands and feet for one set, tail and button for the other. The combination of which probabilistic feature values mapped to each category also varied between the two pairs of sets. Which pair was presented and which set within that pair was learned in Phase 1 were both counterbalanced between participants. This led to four possible conditions defined by the stimuli sets that were encountered (also see 
Figure 4A
).
In addition to the items learned during training (also referred to as "Match" items), each set also contained "Conflict" items, which were hybrid items that possessed the probabilistic dimensions from one category and the deterministic dimension from the other category. These items were presented only during the testing sessions and were designed to test which dimensions controlled categorization behavior. There were 10 Conflict items in each set -one corresponding to each exemplar seen during training (with the same probabilistic dimensions but with the deterministic dimension from the opposite category; 
Figure 6B
).
These items allowed us to determine whether participants' category judgments were based more on the deterministic dimension or on one or more of the probabilistic dimensions.


Procedure
Participants completed a classification learning task while their gaze was tracked.
The experiment was divided into two phases (see 
Figure 6C
). Both phases con-  
Figure 6B
). Participants were given no warning that this switch would occur. Like Phase 1, Phase 2 consisted of training followed by testing.
Instructions at the beginning of the experiment informed participants that they would see two kinds of alien creatures called Flurps and Jalets, and that they needed to figure out which ones were which. They were then given information about the deterministic and probabilistic dimensions. For probabilistic dimensions they were told that most of the members of the category had a particular dimension value, while being shown that dimension in isolation. For the deterministic dimension they were told that all Flurps have one feature value while all Jalets have another feature value, while being shown both features.
The irrelevant dimension was never mentioned in the instructions.
Training in each phase consisted of 30 trials. In each block of 10 trials, the ten training exemplars (the Match items), five from each category, were presented in random order, so participants saw each exemplar three times throughout training. On each training trial, one stimulus was presented in the middle of the screen and participants indicated whether they thought it was a Flurp or a Jalet by pressing a button on a button box. Corrective feedback was then given which tried to equally encourage attention to general appearance (similaritybased responding) and to the deterministic dimension (rule-based responding).
For example, feedback would be "Correct this is a Flurp. It looks like a Flurp and has the Flurp hands.", or "Oops this is actually a Jalet. It looks like a Jalet and has the Jalet hands.", in the case where hands were the deterministic dimension.
In Phase 2, after the unannounced switch, feedback was simplified to mention only the correct category without drawing attention to the dimensions (e.g.   


Eye tracking methods
p(f t |Ω) = k π k N 2 (f t |µ k , Σ k ) + 1 − k π k U(f t |S),
(1)
where f t = {f x (t), f y (t)} denotes the fixation vector (i.e., the x-and y-coor  
Figure 7B
 shows that the means for each region of interest (ROI) are first defined in physical space, but may be subject to some systematic distortions due to miscalibration of the eye-tracking device (see 
Supplementary Materials)
. The end of the vectors in 
Figure 7B
 represent the central locations of each ROI in the distorted space (i.e., not the true physical values), corresponding to the
µ k = (µ (k)
x , µ  
Figure 7E
 shows an example gaze time series from one participant in one trial, and 
Figure 7F
 shows how the generative model converts the fixation information into a probability that each dimension was attended through time.
In 
Figure 7E
, the gaze information is temporally color-coded according to the key in the top panel of 
Figure 7F
. The time series shows that fixation began at the button, moved to the tail, then to the feet, and then to the head. Once the model was fit to the data, we could calculate the probability that each data sample (i.e., each dot in 
Figure 7E
) was associated with every stimulus dimension, as well as the probability that the data sample was not associated with any dimension (i.e., a contaminant). 
Figure 7F
 shows the probabilities at each time point of fixation (x-axis) separately for each stimulus dimension (yaxis). The dimension-fixation probabilities are normalized such that they sum to one, and each moment in time has been color coded with alpha transparency to reflect the probability magnitudes. 
Figure 7F
 shows that at some points in time, the fixation probabilities are clearly on a particular dimension, but at other points in time (e.g., 400-500 milliseconds), the model cannot distinguish clearly between fixations at any particular dimension value. Such ambiguity occurs because these two regions overlap in terms of their uncertainty and spatial proximity. The consequence of this overlap is that the model will weigh both of these dimensions when generating predictions for choice and response time in the Fully Constrained by Representation model, and these moments of attention contribute to the probability that a dimension will be encoded in any of the models that assume attentional encoding. 0 200 400 600 800 1000  The model assumes a variance term to capture the fixation, corresponding to targeting ability. This parameter is assumed to be isotropic, or constant in width along both dimensions. (D) The model also assumes a variance component based on the size dimensions of the ROI, so that smaller ROIs have smaller "hit" regions compared to larger ROIs. (E) Example fixation time series overlaid on an example stimulus, where each point is temporally color coded according the legend in the top panel of (F). (F) Once the model is fit to a participant's full fixation data, we calculated the probability of dimension fixation at every time point. Due to the model structure, each gaze consists of a mixture of dimension processing that depends on spatial proximity and variability associated with either the participant (C) or the ROI size (D).   The model represents new stimuli (left) according to a set of evidence weights (right), which are separately stored for each possible stimulus feature. Here, the set of possible stimulus features are grouped into three dimensions for illustrative purposes, where the tail is the deterministic dimension, the hands are the probabilistic dimension, and the button is the irrelevant dimension. (C,D) On each trial, the stimulus queues the representation to extract a degree of activation and the dimension disparity value (i.e., the summed difference between the orange and blue dots in 
(A,B)
). The right panel shows some example fixation data for each feature value. Based on the encoding component of the model, only features attended for a certain period of time (i.e., represented as the dashed vertical line) get encoded. (E,F) Following a choice, feedback about the stimulus and the set of encoded features are used to update the model's representation.
• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • ••• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • A B C D E F


Computational Modeling
The function mapping the representation to attention is defined to select dimensions that have highest relevancy to the categorization decision 
[45]
. Dimensions whose features are each associated with unique categories are more relevant than dimensions whose features are associated with both categories.
With each new experience, information is gathered and used to respond in ways that are appropriate for task demands, such as categorizing stimuli into one of two groups. As the representation accumulates more information, attention is directed toward each dimension in proportion to the dimension's relevancy.
Panels C and D are associated with key components of the model that either predict where fixation will occur on a trial (i.e., dimension disparity; left) or how the fixation information on a trial determines what information will be encoded and subsequently used to update the representation. Following each response, encoded information about the stimulus is used to update the representation.
For example, 
Figure 8E
 shows how the model would update the representation based on the stimulus shown in 
Figure 8A
, and the encoded information in Starting with 
Figure 8A
, the model may be imbued with an impoverished representation of how well each feature is associated with a particular category label 
[26,
46,
27]
, such as what a participant might learn from the instructions of an experiment. Here, the category "Flurp" is represented as the blue circles, whereas the category "Jalet" is associated with the orange circles. The y-axis
shows the amount of evidence that each stimulus feature (x-axis) is associated with each category label, and we denote this information on the ith trial as P i .
The model does not need to make a clear distinction between a dimension and a feature: all information that a participant may see can be laid out along a single continuum. For our purposes, it is more convenient to assume that P i is partitioned into dimensions, as illustrated by the colors in the background in 
Figure 8A
.
If there are D stimulus dimensions, F d possible feature values within a dimension d, and C categories, the matrix P i would be (C × d F d ), and would appear as
P i =      P 1,1 P 1,2 • • • P 1,D P 2,1 P 2,2 • • • P 2,D . . . . . . . . . . . . P C,1 P C,2 • • • P C,D      ,
where each P c,d is a vector containing information relating features to category c within dimension d:
P c,d = p c,1 p c,2 . . . p c,F d .
Using 
Figure 8
 as a working example, we have the number of categories C = 2, the number of dimensions D = 3, and the number of features per dimension as F = {3, 2, 3}. On Trial 1, the representation weight matrix P 1 (i.e., 
Figure 8A
) would be P 1 = 0.10 0.00 0.00 0.10 0.00 0.00 0.00 0.00 0.00 0.10 0.00 0.00 0.10 0.00 0.00 0.00 , whereas by Trial 51 in 
Figure 8B
, the representation may have evolved to P 51 = 0.70 0.00 0.00 0.54 0.08 0.51 0.00 0.00 0.00 0.67 0.00 0.10 0.61 0.49 0.00 0.00 .


Stimulus Representation and Category Activation
To precisely specify how observers use their evolving representation to make choices about each stimulus, we must specify how information about the stimuli is conveyed to the model. Let all the properties of the stimulus on the ith trial be contained in s i , a row vector of the form
s i = s 1 s 2 • • • s D ,
where each s d is a simple label indicating the particular type of feature used at the dth dimension. In our notation, s d reflects the labels a feature can take. 
s * i = s * 1 s * 2 • • • s * D , where each s * d = [s * d,1 s * d,2 . . . s * d,F d ]
is a vector of length F d , and let
s * d,f = 1 f = s d 0 otherwise.
(2)
With this specification, we can expand s * i to have an appropriate dimension to interact with P i by using a Kronecker product on a column vector of ones with length C:
S * i = 1 (C×1) ⊗ s * i .
(3)
All this operation does is expand the information in s * i . In our running example, if the stimulus on the first trial has the code s 1 = [2 2 1], then
S * i = 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 .
To further clarify, within each partition, the columns of ones correspond to the particular feature value used within that dimension. If a feature value is not used in that dimension on that trial, only zeros will appear. The zeros will be useful later when updating the representation weights because they will negate any information flow because this information is not present.
With Equation 3 specified, we can now describe how the stimulus activates category-level information in the model. Upon the presentation of a stimulus probe, the representation is queued along the relevant dimensions to retrieve information consistent with task demands. Letting A i denote the category activation matrix on the ith trial, activation is computed for every feature value, and so A i is a 
(C × d F d )
 matrix, matching the dimensions of P i and S * i .
To compute activation, we simply perform an element-wise multiplication of the representation and the stimulus, which is executed mathematically by the Hadamard product
A i = P i • 1 (C×1) ⊗ s * i = P i • S * i .
This operation simply activates the relevant columns of the model's representation, which later will be used to generate a prediction for choice and response time. Continuing with our example, activation on the 1st trial would be A 1 = 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.10 0.00 0.00 0.10 0.00 0.00 0.00 , indicating weak evidence that this stimulus is a Jalet in the first and second dimension, and no evidence about membership in the third dimension.


Dimension Disparity
To specify how observers prioritize dimensions in the search for information, we rely on Luce's choice axiom 
[47]
. According to the axiom, when faced with a choice among several alternatives, a decision-maker will exhibit "matching behavior", meaning they will select options with probability in proportion to their utility in the task context, such as in the original applications where utility was defined as the expected reward 
[48,
49]
. Here, we define a measure of utility as the degree to which a given dimension discriminates between the (two)
categories. There are two steps to computing the dimension disparity. The first simply calculates the absolute difference in the evidence values in P i across categories. Given the partition within P i , we can calculate differences between the representations for each category by multiplying P i by a contrast matrix.
For example, if we only have two categories, the absolute difference can be calculated by
V * i = |DP i | , where D = [1 − 1]
and |x| is the element-wise absolute value of the matrix x.
For the first trial, the difference vector would be V * 1 = 0.10 0.10 0.00 0.10 0.10 0.00 0.00 0.00 .
The second step simply combines the elements of V * i so that they reflect aspects of the dimension, rather than the features. To do this, we must multiply V * i by another contrast matrix W , which is an  By contrast, 
Figure 8D
 shows how disparity would be calculated on Trial 51, the first trial after the transition into Phase 2, where the representation is more developed. Assuming judicious attention to dimensions, the absolute difference values would be V * 51 = 0.70 0.67 0.00 0.44 0.53 0.02 0.00 0.00 . In this transition, the participant has yet to see the gold hexagon tail, and so there is no information about this stimulus, making the disparity for this feature zero. Similarly, there is no information about purple triangle or red heart buttons, and so the corresponding disparity values are both zero. To get disparity, we sum these absolute differences up within a dimension such that V 51 = 1.37 0.97 0.02 , which indicates that the disparity value will be high for the deterministic dimension, low for the irrelevant dimension, and somewhere in between for the probabilistic dimensions, reflecting knowledge that is consistent with the relevancy of each dimension.
W =             1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1             .


Hence, the general expression for dimension disparity is
V i = |DP i | W,
To facilitate model evaluation and to keep the model analytically tractable, we chose to model attention to stimulus dimensions with a multinomial likelihood. Hence, to connect the model to the observed data, we required a transformation of V i into a probability vector. For this, we relied on a standard softmax transformation:
DD i = exp(κV i ) d exp(κV i ) ,
where DD i is a probability vector on Trial i of length D, where each element is the probability of fixating on each dimension of the stimulus. This allows us to prospectively predict the likelihood of fixating on a particular stimulus dimension on a new trial based on the past history of stimuli, fixations, and feedback. Hence, the model makes predictions for what a person will choose to look at on a new trial based on their particular history of experiences.


Attentional Encoding
One of the central questions we wish to investigate here is whether using a To incorporate eye-tracking data, we assumed that the time spent looking at a feature would be monotonically related to the probability of encoding it, and assumed the following generic logistic function:
p(x|k, b) = 1 1 + exp [−k(x − b)] ,
(4)
where x is the amount of time spent fixating on a particular feature value, k is a slope parameter, and b is an intercept parameter. We recorded eye-tracking data during both the decision period and during the feedback period where participants were allowed to look at the stimulus again while being told the correct category membership. Because we wanted to avoid biasing the parameters of the feature encoding function, we simply calculated the probability of encoding based on fixation data for both the decision and feedback periods, and set the encoding probabilities to the maximum of these two values. This avoided the possibility of adding two subliminal fixations on a feature to a supraliminal fixation, resulting in encoding that is unlikely given a break in the two fixation segments. Formally, letting g q i,d and g r i,d denote the amount of time fixating on the dth dimension of the ith stimulus during the decision (q) and feedback (r) periods, respectively, we set
e i,d = max p(g q i,d |k, d), p(g r i,d |k, b) .
As an example, the right panel of 
Figure 8C
 shows some fixation data for the stimulus in 
Figure 8A
. Here, the blue tail was fixated for a long time, followed by the black "x" shaped button, followed by the red crescent hands. If we assume that the fixations are thresholded, as could be done by setting k to a very large value (e.g., k = 20) in Equation 4 and set b to some value reflected by the dashed vertical line, then only the blue tail and black button would be fully encoded. In general, the parameter k can be fully estimated which would allow the representation to do "partial" updates for feature dimensions that were fixated upon for some nonzero amount of time. However, to keep the model simple, we have instead assumed k = 20 for all model fits, and instead freely estimated the threshold parameter b.
Although e i,d specifies the probability of encoding a feature, to make our updating equation more compact, we need to represent this information in a way that is consistent with the other elements of the representation, such as the stimulus S * i and evidence weights P i . Letting
E i = e i,1 e i,2 • • • e i,D ,
we can use a similar expansion technique as in Equation 3 to represent that a dimension was encoded, regardless of the particular feature value within that dimension:
E * i = e i,1 ⊗ 1 (C×F1) e i,2 ⊗ 1 (C×F2) • • • e i,D ⊗ 1 (C×F d ) := E i ⊗ 1 (C×F d ) ,
(5)
where the last line in Equation 5 we introduce as a notational shorthand. As an example, in 
Figure 8C
, only the blue tail (deterministic dimension) and black button (irrelevant dimension) were encoded, and so for this first trial, 
E 1 = [1 0 1], making E * 1 = 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 .


Updating the Representation
= 1 −ζ −ζ 1 ,
where ζ is the amount of inhibition that can be applied to the columns of P i .
However, with the expansion of P i to reflect both features and dimensions, the term ζ only applies inhibition to a particular feature value. For example, in were sufficient. The particular dimension that would emerge would however be idiosyncratic, and most likely would be a product of which dimension was encoded and reinforced more often.
The inhibitory matrix R is of dimension (
d F d × d F d ).
In our example, R would take the form
R =             λ −η −η −β −β −β −β −β −η λ −η −β −β −β −β −β −η −η λ −β −β −β −β −β −β −β −β λ −η −β −β −β −β −β −β −η λ −β −β −β −β −β −β −β −β λ −η −η −β −β −β −β −β −η λ −η −β −β −β −β −β −η −η λ             .
Here the term λ pertains to decay in the representation, which allows for the classic effect that experiences in temporally distant time points have a less pronounced effect on the representation than do experiences that are more proximal 
[53,
54,
55,
56]
. There are two additional forms of inhibition: η pertains to inhibition within a dimension, and β pertains to inhibition across dimensions.
Because having within dimension inhibition was not found to improve our fits to data, we have set η = 0 for the present purposes. However, the acrossdimension inhibition term β was found to be crucial in explaining the shift in attention from Phase 1 to Phase 2 (see Supplementary Materials), and so it was freely estimated in the models shown here. Finally, the term λ was also found to be crucial for capturing relevancy of information, and so it too was freely estimated in all of the models shown here.
With all components of the model specified, we can express the model's updating equation in the following recursion:
P i+1 = QP i R + α(S * i • E * i ),
(6)
where term is thought to be more classically connected to memory and attention, where the neural bases might be related to hippocampal function, the left hand term is thought to be associated with aspects of cognitive control, such as dorsallateral and medial frontal cortex 
[14,
57]
. However, because our task was not implemented in a manner that would be conducive to such investigations, we do not speculate on these issues further. 
Figure 8E
 shows an example of the updating process in the model. Here, because only the blue tail and black button were successfully encoded, once receiving feedback that the stimulus in 
Figure 8A
 was a Flurp, the evidence values corresponding to these dimensions are increased by α for the part of the representation corresponding to the Flurp category. 
Figure 8E
 only shows the part of the updating process corresponding to information (i.e., right hand term of Equation 6), and it neither shows the effects of inhibition nor decay.
P


Evidence Accumulation Dynamics
To make a prediction for choice response times on each trial, we need only map the category activation matrix A i into a variable representing the strength of evidence for each choice alternative, which we will henceforth refer to as a drift rate. To test various counterfactuals (see main text), we allowed for three types of maps: (1) the activation matrix plays no role, (2) all features in the activation matrix contribute equally, and (3) features contribute to activation in proportion to how long they were attended. Ultimately, the map must produce a vector of length C, where each element corresponds to how active each category choice is.
Working deductively, we can start by specifying the general function that defines the rate of evidence accumulation on Trial i as
ν i = A i z + V T T i + I 0 1 (C×1) ,
(7)
where settings of each component allows us to complete the three types of maps.
The term I 0 is a baseline level of activation that ensures that both drift rates are always at least as large as I 0 . Although I 0 is estimable, we did not find that freely estimating it dramatically improved the model fits to data, and so we set I 0 = 0.1 for all model variants.
Decision Unconstrained by Representation To complete the first map, we assume that the representation plays no role, and instead, there are two drift rate parameters freely estimated from data, one corresponding to the correct response v + and one corresponding to the incorrect response v − . It is not the case that we presuppose that observers know which choice is correct once the trial begins -this simply allows us to represent the drift rate in a way that is consistent with the category choice. For example, when the stimulus is truly a Flurp, we want the drift rates to take the form
ν i = [v + v − ] T
, and when it is truly a Jalet, we want  
ν i = [v − v + ] T ,
V = v + v − v − v + .
G i = g i,1 g i,2 • • • g i,D .
To convert the fixation durations into fixation proportions, we need only normalize this vector. Following normalization, we can then expand G i with a Kronecker product (see Equation 3) to make G i compatible with A i . Following both of these adjustments, we can set
z = G i ||G i || ⊗ 1 (1×F d ) .
Because A i contains zeros for features that are not relevant to the stimulus, multiplying A i and z in Equation 7 eliminates the irrelevant terms created by the expansion.
With the vector ν specified, we can feed these values into a racing diffusion process 
[58]
, where ν specifies the drift rates. Similar to the expanded Poisson race model 
[59,
60,
61,
62]
 and the Linear Ballistic Accumulator model 
[24]
, the racing diffusion model assumes that each possible choice is represented as a separate accumulator, and each accumulator races toward a common threshold amount of evidence, represented as a parameter θ. To derive a joint probability density function (PDF) for choice response times, we must first consider the diffusion process for a single response alternative. When only one alternative exists, the probability that the accumulator arrives at a level of evidence equal to θ is described by the Wald distribution 
[63,
64,
65]
, which can be parameterized as
f (RT i | θ, ν (1) i , τ ) = θ 2π(RT i − τ ) 3 exp   − ν (1) i (RT i − τ ) − θ 2 2(RT i − τ )    ,
(8)
where
ν i = [ν (1) i ν (2) i ]
T , RT i denotes the response time on the ith trial, and τ represents the effects of nondecision processes, such as motor execution or visual encoding. Equation 8 is the response time density when only considering a "Flurp" response. When choosing among more than one response option, we must take into account the activations of the other response options, by evaluating the joint PDF of choice and response time 
[58]
. For computational convenience, we assume that the race process is independent across the accumulators. The independence assumption greatly simplifies the joint PDF such that an analytic expression can be derived. Denoting RC i as the response choice on
Trial i, the joint PDF of a racing diffusion process is
f (RC i , RT i |θ, ν i , τ ) = p(RT i |RC i )p(RC i ) = f (RT i |θ, ν (RCi) i , τ ) j =RCi 1 − F (RT i |θ, ν (j) i , τ ) ,
where
F (RT i | θ, ν
(j)
i , τ ) is the cumulative density function of the jth accumulator:
F (RT i |θ, ν (j) i , τ ) = Φ θ 2 (RT i − τ ) ν (j) i (RT i − τ ) θ − 1 + exp 2ν (j) i θ Φ − θ 2 (RT i − τ ) ν (j) i (RT i − τ ) θ + 1 ,
and Φ(x) is the cumulative density function of the standard normal distribution at the location x. To avoid mathematical scaling issues, we set the moment-tomoment variability in the racing diffusion process σ w = 1 for all models. For this reason, σ w does not appear in the equations above describing the racing diffusion process.
The use of a racing diffusion process is clearly a simplification; there are likely to be complex interactions among the two response options that are subject to encoding dynamics within a trial. There are also likely to be effects such as trial-to-trial variability in the starting point of the accumulation process 
[58]
 and potentially mechanisms like collapsing bounds 
[66,
67]
 that provide superior fits to data. Indeed, we experimented with a timing mechanism running alongside the racing diffusion process such that if the timer hit a threshold prior to either choice, a random guess was given. Although this did enhance the model's fits to data considerably, we chose not to show those results here because they were not central to our main questions about the cyclical links between representation, attention, and decision making.


Modifications Specific to Our Task
In addition to the model specifications above, we made a few slight adjustments when fitting the model to data to account for experiences that were not so easily cast within the general framework. First, to model the effects of the instruction period, we assumed traces were presented that were empty with the exception of a single feature element in the trace. We then supplied feedback about that feature, analogous to the instructions in the experiment. This process involved some initial information for the deterministic and probabilistic features, but because participants were not told about the irrelevant dimension, we supplied no information about it to the model. When learning about the instructions, we assumed that only learning occurred during this period, and that the updating equations were not subject to either leakage or inhibition by setting λ = 1 and β = 0. We also assumed that all instruction information was perfectly encoded for all models.
During test, because participants did not receive feedback, we assumed that no updating process could occur, which means that nothing could be learned during the testing period. During this time, the representations were not subject to any decay or inhibitory effects. However, to account for the shift in context that separated the training period of Phase 1 from the testing period of Phase 1 and the training period of Phase 2, we performed one update of the representation that involved only decay. In other words, after the last trial of the training period of Phase 1, we updated the representation by simply multiplying P i by R with λ in the diagonals and β = 0. This allowed the model's representation weights to lose some strength, which caused an overall slowing of response time and decrease in accuracy when going into Phase 2. However, we note that decay is not the only mechanism for the increase in response time -the dimensions that are attended on the first trial of Phase 1 also impact the rate of accumulation. Although we could have modeled the decay from one context to another as a free parameter, this simple "single-decay" update strategy was sufficient for our purposes.


Likelihood Function
Our goal was to jointly fit response choice RC i , response time RT i , and fixation durations G i on each trial. We considered these variables to be tied to a single representation (i.e., the model), but that they could be separated into a product of a joint distribution for choice and response time, and a distribution for fixation duration. To this end, the likelihood function for all variables is
p(RC i , RT i , G i ) = i f (RC i , RT i | θ, ν i , τ ) × Multinom G i SE DD i , n ,
where we specified a saccade encoding time of SE = 100 to scale the fixation durations appropriately, n = d G i /SE, and Multinom(x|p, n) is the Multinomial distribution with draws x and probability vector p for the D dimensions of the stimulus:
Multinom(x|p, n) = n! x 1 !x 2 ! . . . x D ! p x1 1 p x2 2 . . . p x D D .
This is a joint likelihood function, which means that fitting the model to data secures the parameter values that lead the best joint explanation of all the data.
This means that the model can prioritize fits to behavior or fixation information, depending on which is more numerous. In our case, the gaze information played a larger role in the model fits, which helps explain why the model provides a compelling match to fixation data, and is relatively worse in explaining the choice response time data.


Priors on Model Parameters
There The Supplementary Materials provide two full recovery studies using both an optimization routine to determine the maximum a posterior (MAP) estimate and fully Bayesian posterior sampling. These studies assured us that the parameters are all identifiable, and that the priors are not overly constraining (i.e., there were substantial differences between the priors and posteriors in those studies) on cases that match the experimental design. Parameters were estimated using a parallelized version of the optim function in R to determine the MAP estimate for each participant, fit independently.


Evaluating Model Performance
We used the Bayesian information criterion [BIC; 
68,
37]
 to compare the models.
The BIC is computed for each model using the equation
BIC = log (N ) p − 2log p Θ | D ,
(9)
where p Θ | D represents the posterior density at the parameter values Θ that maximized it (i.e., the MAP estimate), p represents the number of parameters for a given model, and N is the number of data points for a given participant.
When fitting each model, although we sampled from the full posterior distribution of each hierarchical model, we used only the MAP estimate for calculating the BIC for brevity. For our purposes, the BIC was sufficient as it penalizes models for complexity, where models of higher complexity (i.e., models with more parameters) receive a stronger penalty than models of lower complexity.
As such, the inclusion of additional parameters must substantially improve the fit to the data to overcome the penalty incurred for adding them.


Data Availability
The data that support the findings of this study are available from the corresponding author upon request.


Code Availability
Custom code that supports the findings of this study is available from the corresponding author upon request.


Competing Interests


1626
The authors declare no competing interests.  
learning and memory interact such that changes in one component can produce changes in another. With no observable data, any number of assumptions can be used to explain how changes in one component causes changes in another. Observable measures from experimental data constrain the possible ways in which these changes occur. For example, having observable measures of how individuals make choices, such as their response and the amount of time taken to make that response, might provide constraints on what information was learned in the past and remembered on specific trials [1, 2, 3]. Going one step further, having observable measures of attention would provide direct information about how people seek out information during a deliberation period, given what they have learned about the relevancy of each dimension when making similar decisions.


( 2 )
2
Inferring patterns of attention and decision from behavioral and eye tracking data, and critically (3) Comparing the Fully Constrained by Representation model against less constrained models that systematically relax the dependency between representation, attention, and decision making. First, we conducted an experiment in which participants could fall into different types of information traps while learning the relevance of different dimensions for categorization decisions. Specifically, participants pursued a goal of accurately categorizing stimuli with multiple dimensions that varied in relevance to category membership (from perfectly diagnostic, to moderately relevant, to irrelevant), and received corrective feedback for each categorization decision. If selective attention operates too quickly, learners can fall into attention traps in which their initial experiences lead them to mistakenly overestimate the relevance of only moderately relevant dimensions


1 )
1
One dimension was deterministic (100% associated with category membership), (2) Five dimensions were probabilistic (80% associated with category membership), and (3) One dimension was irrelevant (50% associated with category membership). The first phase started with 30 category learning trials (i.e., categorization decision followed by corrective feedback) and ended with 20 test trials (with no corrective feedback). At the end of the first phase, an unannounced switch occurred in which the formerly deterministic dimension became irrelevant, and vice versa. This reversed set of dimensions constituted the second phase of the experiment (Phase 2), where participants had to adapt to a new choice environment [26, 14]. Similar to Phase 1, Phase 2 consisted of 30 training trials and 20 test trials under this new dimension relevance configuration. Categorization decisions, response times, and gaze to each dimension were recorded throughout, and all data were used when fitting the model. The core model, shown in Figure 1A, assumes that attention, representation, and decision making are all connected, and that observables such as eye fixation, choice and response time are best explained by using a single underlying representation of learned dimension relevance. The interconnectedness of our core model makes three clear predictions: (1) information that we attend drives our decision making processes, (2) feedback about our decisions and features that we encode are used to update our representation of the relationship


Phase 1 .
1
Participants increasingly selectively attended to the deterministic dimension over the course of Phase 1 (Figure 4B; left panel of Extended Data Figure 1). At the same time, the irrelevant dimension became almost completely ignored. This narrowing of selective attention was accompanied by benefits to categorization accuracy and speed. The left panel of Extended Data Figure 1A shows that the average accuracy across participants started low (0.7), then quickly rose and asymptoted at a high level (0.95) by the end of Phase 1. Response times showed similar benefits, where response times during Phase 1 started high and steadily decreased (


Phase 2 .
2
As stated above, an unannounced switch occurred between Phase 1 and Phase 2 such that the initially deterministic dimension became irrelevant, and the initially irrelevant dimension became deterministic. Thus, although it would be just as optimal to prioritize the deterministic dimension in Phase 2 as it was in Phase 1, selective attention might hinder participants' ability to recognize and prioritize the dimension that was irrelevant in Phase 1 when it became deterministic in Phase 2.


observed during learning shaped their representation of the relevance of dimensions to decision making, or (2) How this representation guided their allocation of attention to features, and the decisions they made on the basis of those features.


Figure
1A shows only a schematic of the links assumed by the Fully Constrained by Representation model. In this section, we elaborate on how the components of representation, attention and decision making are connected within the model to produce category learning behavior similar to humans as revealed by our experiment. All mathematical details are provided in the Methods section.


Figure 1 :
1
Essential Model Components. (A) Structural diagram illustrating the connections between representation, attention, and decision making assumed in the Fully Constrained by Representation model. (B) The representation


Figure
2A illustrates the five model variants used in the simulation study. In the center is the Fully Constrained by Representation (blue) model, where bidirectional links connect representation and attention, representation and decision making, and a one-directional link allowing attention to guide decision making. In this model, the representation of the learned relevance of dimensions to category decisions is constrained by attention: that is, in a trial, feedback about the association between a dimension and correct category membership is only encoded if the learner attended a dimension for enough time. At the same time, the representation guides what dimensions are attended on each trial, and how the observed dimensions guide the decision response.


A


Figure 2 :
2
Linking Effects on Observable Variables. (A) Various types of models are produced by specifying links between representation (R), attention (A), and decision making (D). Each model structure is color coded for reference in Panels B and D. (B, D) The mean accuracy (B) and response time (D) values are shown from each of the five models across trials, separated into the two phases of the experiment (panels). (C, E) The mean fixation proportion for the deterministic (D; blue), probabilistic (P; gray), and irrelevant (I; red) dimension for the Representation Unconstrained by Attention model (C) and the Fully Constrained by Representation model (E), split into the two phases of the experiment (panels). In Panel E, only the predictions from the Fully Constrained by Representation model are shown due to the similarities between the Fully Constrained by Representation, Decision Unconstrained by Representation, and Decision Unconstrained by Attention models. The reference line marks the point of equal dimension sampling probability (1/7). Fixation proportion information for the Attention Unconstrained by Representation model is not shown because the proportions are invariant with respect to the learning sequence, and they would always sample each dimension equally (1/7). Simpler models are derived by relaxing constraints between representation, attention, and/or decision making. First, going rightward from the Fully Constrained by Representation model in Figure 2A, we can test whether decision making is constrained by attention and representation. When decision making is unconstrained by attention, all dimensions will be used equally when making a decision, a model we refer to as the Decision Unconstrained by Attention (green) model. Although we could have modeled attention to dimensions atheoretically as well [e.g., 18, 19, 20, 21], we avoided this because it adds many additional parameters and does not help identify a link between attention and decision making. When decision making is unconstrained by either attention or representation, the Decision Unconstrained by Representation (yellow) model is produced, which assumes that two free parameters (i.e., "drift rate" parameters for the correct and incorrect choice) specify the likelihood of each choice about the two categories. Because of this lack of dependence on representation, the Decision Unconstrained by Representation model is related to standard models of choice response time [22, 23, 24]. Both of these unconstrained models allow us to test whether decisions about stimuli are constrained by an evolving representation of the association between their dimensions and goal-relevant outcomes [i.e., category decisions; 25, 2, 26, 27, 28]. Second, going leftward from the Fully Constrained by Representation model in Figure 2A, we can test whether attention and representation mutually constrain each other. First, we can test whether the representation guides the allocation of attention to dimensions by generating the Attention Unconstrained by Representation (red) model. According to this model, attention to dimensions is constant across time, and not influenced by learning the relevance of dimensions. Second, we can test whether the representation is constrained by attention by generating the Representation Unconstrained by Attention (orange) model. According to this model, attention does not influence the information that is used to update the representation. The Representation Unconstrained by Attention assumption is the standard in modeling category learning [1, 29, 2, 25, 3, 30, 27]. In this model, all dimensions and their association with category membership are encoded in the representation on each trial, regardless of what dimensions were attended.


Figure
2B and Figure 2D shows the models' accuracy and response time as a function of time, separated into the two phases of the experiment. Initially, the Decision Unconstrained by Representation model provides the best accuracy but worst response time. However, we note that the particular value of accuracy and response time is purely a consequence of the parameter values used when simulating the model; the important pattern in these simulated variables is that they cannot change across time. Because there is no connection from the representation to the decision, there cannot be changes in the observed variables as a product of learning. Next, the Representation Unconstrained by Attention model leads in accuracy and response time, because all information is being encoded, resulting in better diagnostics when that information is used during the choice. However, by the end of Phase 1, the Fully Constrained by Representation model overtakes the Representation Unconstrained by Attention model in both performance metrics of accuracy and response time. This pattern occurs once the Fully Constrained by Representation model learns to prioritize the deterministic dimension, meaning that it will only sample this dimension when making a choice. It follows then, that after the switch when the deterministic dimension becomes irrelevant, the performance of the Fully Constrained by Representation model is severely compromised because information about other dimensions cannot be meaningfully used (i.e., it was either not encoded toward the later stages of Phase 1, or the earlier experiences in the beginning stages of Phase 1 have decayed away). The other models perform somewhere in between these two extremes, where the Decision Unconstrained by Attention model learns more quickly in Phase 1, but it also incurs more costs during Phase 2 compared to the Attention Unconstrained by Representation model.


Figure
2C and Figure 2E show the models' fixation proportion as a function of time, separated into the two phases of the experiment. The deterministic, probabilistic, and irrelevant dimensions are shown as the blue, gray, and red lines, respectively, where the gray line is the total probability of attending to any of the five probabilistic dimensions. The key result is that changes in attention to dimensions over time depend on whether representation and attention mutually constrain each other. Figure 2E shows how attention to dimensions changes over time when representation and attention constrain each other, as illustrated by the Fully Constrained by Representation model (which makes identical predictions to the other models with this bidirectional constraint). Figure 2C shows attention to dimensions when the representation is instead unconstrained by attention (i.e., the Representation Unconstrained by Attention model). In both panels, the lines represent the actual probabilities of attending to dimensions based on their learned relevance in the representation. In addition, inFigure 2E


only, attention to dimensions also constrains the set of features encoded in the representation. There are key consequences when the representation not only constrains attention, but attention also constrains representation. In Phase 1, when attention constrains representation (Figure 2E), the representation learns the relevance of the deterministic dimension more rapidly, resulting in faster increases in attention to the deterministic dimension. By contrast, when representation is unconstrained by attention (Figure 2C), the model encodes more information about the relevance of probabilistic dimensions, and thus allocates more attention to them. These differences have important consequences for attention in Phase 2. Specifically, because the relevance of probabilistic dimensions was better encoded in Phase 1 in the Representation Unconstrained by Attention, this model takes longer to learn the relevance of the newly deterministic dimension. (See Supplemental Materials for an in-depth analysis of how these dynamics emerge due to the balance of decay and inhibition between dimensions in the representation.) 1.3 Links Among Representation, Attention, and Decision Making: Model Evaluations Although the simulation study above is useful in foreshadowing the effects that various constraints among representation, attention, and decision making will have on behavioral and eye-tracking measurements, each of the model predictions are derived from a single set of parameter values. We chose these parameter values and kept them constant across model variants to isolate the effects of links across attention, representation, and decisions, but they do not reflect the models' best attempt to characterize individual participants' data. Hence, in this section we move away from the qualitative analyses presented above and perform a complete quantitative evaluation of how well each model structure can capture key patterns in our data.


Figure
3A illustrates the Fully Constrained by Representation model, where attention, representation and decision making are depicted as separate nodes in a network. Constraints between nodes are color-coded to associate each constraint to the model variant that is produced when it is relaxed in the other panels.


variants. For Link 1, either the representation can guide attention to dimensions, or attention can be completely unrelated to the representation, meaning that it is constant across time and not influenced by the learned relevance of dimensions. For Link 3, either the attended information on each trial can be used to update the representation (i.e., the link is intact) or attention does not modulate the associations between features and category membership used to update the representation, and the representation updates all associations indiscriminately. Finally, we assume three different ways in which the representation can be used to predict choice and response time. The first is the Decision Unconstrained by Representation model, in which two parameters are freely estimated, one for the correct response and one for the incorrect response. The second is a Decision Unconstrained by Attention model in which Link 2 is intact, and all stimulus dimensions are used equally when making choices, regardless of whether or not they were encoded. The third model variant is the Fully Constrained by Representation model, in which attention to dimensions modulates their importance in the decision. To do this, we calculate the proportion of fixation duration on each trial and use this proportion to weight the dimensions within the representation. Such a model is analogous to using the eye-tracking data to directly drive the accumulators to a decision threshold so long as the particular sequence of fixations is irrelevant [i.e., the pattern of fixations are exchangeable; see, e.g., 35]. In summary, by having the baseline Decision Unconstrained by Representation model, we can evaluate how well the representation improves the fits to choice response time data (i.e., comparing a model with neither Link 2 nor Link 5 to a model with either Link 2 or Links 2 and 5), and how well having the eye-tracking information on each trial improves the fits further still (i.e., comparing a model with only Link 2 to a model with both Links 2 and 5).


shows that all constraints contributed to better model performance, where Constraints 1 and 3 contributed greatly to model performance. Having Constraint 2 did not substantially contribute to model performance, but applying Constraints 2 and 5 in conjunction contributed greatly to model performance relative to the Decision Unconstrained by Representation model. Figure 3D shows model performance scores separated by model variant (rows) and participants (columns), where the Fully Constrained model better accounted for 18 out of our 38 participants. Figure 3E shows the performance scores for each model, aggregated across subjects. Here, the results at the aggregate level are consistent with the individual rankings, where the Fully Constrained by Representation model obtained the lowest BIC score in the set of models investigated here. Together, these two panels show that the Fully Constrained by Representation model outperformed any other combination of constraints between the nodes in Figure 3A, thereby justifying the need for constraints between attention, representation and decision making in learning dynamics. Finally, we emphasize that our conclusions about constraints are not subject to assumptions about the representation itself. In the Supplementary Materials, we consider four alternative representations, such as models with fixed learning rates and no dimension inhibition. Although the representations we tested fit the data to various degrees, within each representation class, the ordering of model performance was identical with respect to how the representation can be used to constrain attention and decision making.


Figure 3 :
3
Switchboard Analysis of Linking Structures. (A) Model diagram illustrating a "Fully Constrained by Representation" structure where links exist between representation, attention, and decision making. Each type of link is number and color coded to facilitate interpretations in other panels. (B) Lattice structure used to generate various combinations of model variants that test counterfactuals in order to establish whether simpler models may be preferred. Each node in the graph represents a specific model, whereas the dimensions represent the combination of assumptions used within the model. (C) Aggregated model performance difference scores across switchboard dimensions. Each bar plot quantifies the degree to which the Bayesian Information Criterion (BIC) decreases when the indicated link is applied. (D) z-transformed BIC statistics separated across model configurations (rows) and participants (columns). The far left panel indicates which type of linking structure was imposed for each model variant. (E) Aggregated BIC scores across subjects. In all relevant panels, lower BIC scores indicated better model performance.1.3.2 Absolute Fits to DataAlthough the Fully Constrained by Representation model provided the best fit for the majority of participants in our data, this result is only a relative comparison to other model variants. In this section, we therefore evaluate the absolute performance of the model by comparing its fits to measures of attention, choice, and response time in our data.


Figure
4A shows the fits of the model (shaded bars) to the eye tracking data (solid bars with error bars), separated by phase (columns) and dimension relevance conditions (rows). In our experiment, conditions only varied in how the stimulus dimensions were assigned relevance. In each panel, blue designates the deterministic dimension, red designates the irrelevant dimension, and gray designates probabilistic dimensions. Across conditions and phases, the model predicts a pattern of attention that is in close agreement with the eye-tracking data. Of particular importance are the probabilistic dimensions, which across panels exhibit appreciably idiosyncratic patterns of dimension attention (i.e., some probabilistic dimensions are attended more than others, even though they are of equal relevance). At a high level, the close match of the model to these idiosyncratic tendencies suggests that the model is capturing underlying representations for individual participants based on their unique experiences.Figure 4Bshows the model's fit to the eye-tracking data differently, where fixation proportion is shown as a function of time and collapsed across conditions. Here, the model predictions are shown as solid lines, whereas the data are shown as dotted lines (i.e., see Extended DataFigure 1E). In general, there is a close agreement between data and model predictions, although the model is slightly slower than participants to adapt to changes that occur in Phase 2.


Figure
4C shows the model predictions for response time data (green lines) against the data (black lines) across time. Here, the response times are shown on the logarithmic scale, and the lines correspond to the 0.1, 0.5, and 0.9 quantiles for visual clarity. Vertical lines represent block transitions (e.g., between training and testing). There are several difficult but key qualitative patterns in the data that are all well captured by the model: (1) decreasing response times with training, (2) large increase in response times when first entering into Phase 2, and (3) average increase in response times from Phase 1 to Phase 2.


Figure
4D shows the model's prediction for choice responses across trials, collapsed across conditions. The filled circles show the average across participants,


Figure 4 :
4
Fully Constrained by Representation Model Fits to Data. (A) Each bar plot shows the looking proportion across stimulus dimensions for each condition (rows) and phase (columns) estimated from eye-tracking data (solid bars with error bars) and predicted by the model (hatched bars). In each condition, deterministic dimensions are shown in blue, irrelevant dimensions are shown in red, and probabilistic dimensions are shown in gray. (B) Fixation proportions from the data (dashed lines) and predicted by the model (solid lines) from (A) are plotted with respect to time, collapsed over subjects and conditions and separated into two phases. (C) Logarithmic transformations of the response times from the data (black lines) and the model (green lines) are shown for each trial, collapsed across subjects and conditions. Vertical lines represent block transitions (i.e., training, testing, Phase 1, Phase 2). (D)


attention constrains representation (Link 3 in the model switchboard), initially selectively attending to a dimension that is only somewhat relevant may lock the learner into continuing to attend to and make decisions based on this dimension, even when a more relevant dimension is available. In "representation traps", when the representation constrains attention and decision making (Links 1 and 2 in the model switchboard), the representation of dimension relevance that is formed during an initial period of learning can prevent learners from adapting to a change in dimension relevance. Specifically, when an initially irrelevant dimension becomes relevant, the representation of the dimension as irrelevant may prevent learners from seeking out this dimension to form category decisions. In summary, Links 1, 2, and 3 generate the cognitive inertia underlying attentional and representational traps.


Figure
5B shows the trapping analysis for the Fully Constrained by Representation model, schematically illustrated in Figure 5A. Here, the simulation is broken into Phase 1 (left) and Phase 2 (right), where the grid of trapping probabilities are organized into the participant's representation (rows) and the experimental design (columns). As a general rule, the Fully Constrained by Representation model tends to produce a pattern of consistent dimension prioritization, such that if a dimension is perceived to be relevant, the model will direct attention toward that dimension. However, the dimension that is prioritized is quite often not the most relevant (i.e., deterministic) dimension. First, several participants are predicted to fall into attention traps on 50% of the experimental designs, in which initial learning causes them to prioritize a probabilistic dimension in Phase 1. Notably, many more participants are predicted to fall into representation traps, in which the representation of the dimension that is irrelevant in Phase 1 prevents the prioritization of this dimension in Phase 2 when it becomes deterministic. This trap is also reflected in the grand average (black line) in Figure 5C, where accuracy climbs quickly in Phase 1, but suffers from a dramatic drop back down to chance (i.e., 50% accuracy) following the transition to Phase 2. Together, the results suggest that the most plausible model of human decision making is susceptible to both attention and representation traps.


1. 4 . 1
41
How Can Humans Avoid Traps? We next evaluated how consequential traps are to decision making. Specifically, we evaluated whether it was possible to alter the Fully Constrained by Representation model to avoid traps while still producing high decision accuracy. To this end, we evaluated modifications to the Fully Constrained by Representation model designed to avoid traps. The first alteration to the Fully Constrained by Representation model allowed attention to be unconstrained by representation. Instead, we simply adjusted the Fully Constrained by Representation model to enforce a completely random dimension sampling process that was invariant to the evolving representation-based levels of dimension relevance. This model, illustrated in


Second, we adjusted
the Fully Constrained by Representation model by assuming that all dimensions were encoded on each trial, regardless of whether or not those dimensions were sampled within that trial. Because of this Representation Unconstrained by Attention assumption, this model will automatically learn to prioritize dimensions that are more relevant because the model has full information about the association between dimensions and category membership. The model, illustrated inFigure 5G, is consistent with the Representation Unconstrained by Attention model from the first simulation study.Figure 5Hshows that in general, the Representation Unconstrained by Attention assumption enables the model to consistently identify the deterministic dimension in both phases.Figure 5Ishows that the accuracy levels are often quite high, with some subjects reaching over 90% in the first phase. Additionally, there is only a small dip in accuracy during the transition into Phase 2, indicating that the model can temporarily rely on probabilistic dimensions until it learns to prioritize the newly deterministic dimension (seeFigure 5H,right panel). This model can therefore avoid attention and representation traps, while still achieving a high level of accuracy. However, this outcome is achieved by encoding all associations between dimensions and category membership, regardless of whether dimensions are even observed. As our analyses above suggest, this assumption is implausible for humans. At this point, all three models discussed so far have some type of deficiency. Either the representation (1) has a tendency to prioritize the wrong dimension, (2) exhibits unreasonably poor accuracy, or (3) incorporates an information search policy to which capacity-limited humans simply cannot adhere (i.e., Representation Unconstrained by Attention of all available information). In an effort to provide a prescriptive model for a good human learning policy [38], we investigated a hybrid of the Fully Constrained by Representation model and the Attention Unconstrained by Representation model policies, which we call the "Partially Constrained by Representation" model, illustrated inFigure 5J. The intuition behind this variant is simple: (1) we allow the model to sample one dimension that it perceives to be relevant, (2) we force the model to sample four other dimensions at random (to resemble the sampling frequency of participants in our experiment), and (3) we allow the model to use its perceived relevance to weight the incoming information appropriately. Such a policy is similar to doing research about a topic where 1/5 of your time is spent in a confirmatory search (i.e., searching for information you think is relevant), and 4/5 of your time is spent exploring new information (e.g., consulting sources that are related but not a priori believed to be relevant). Once all the information is collected, you weigh the information based on its post-collection relevance to the topic.


Figure
5K shows that, like the Fully Constrained by Representation model, this Partially Constrained by Representation variant learns to prioritize dimensions consistently, but does so with great accuracy, with some exceptional participant/design combinations. The model avoids both attention and representation traps, where representation traps occurred slightly more than attention traps. The trap-avoidance behavior stems from the hybrid sampling policy,


Figure 5 :
5
, the Partially Constrained by Representation model exhibits exceptional accuracy, rising higher than either the Representation Unconstrained by Attention model or the Fully Constrained by Representation model. A final important characteristic is that the Partially Constrained by Representation model does not suffer from the dramatic dip in accuracy during the transition into Phase 2 like its counterpart, the Fully Constrained by Representation model. This pattern occurs because, like the Representation Unconstrained by Attention model, other (probabilistic) dimensions are temporarily used at the beginning of Phase 2 until the model can learn about the newly deterministic dimensions contained in the previously irrelevant dimension. The Effects of Representation on Information Traps. Different model structures (A,D,G,J; first column) have direct impacts on the probability of consistently prioritizing a dimension (B,E,H,K; second column) and choice accuracy (C,F,I,L; third column). The first column (A,D,G,J) illustrates the type of connections among representation, decision making, and attention are used to generate the model predictions in the corresponding row. The second column (B,E,H,K) shows the probability of falling into an information trap in Phase 1 (left) and Phase 2 (right), where blue colors indicate the deterministic dimension was consistently prioritized, and red colors indicate that a non-deterministic dimension was prioritized, a situation we refer to as a trap. White cells represent simulations where no dimension was consistently prioritized. Each subject's best fitting parameter values (rows) were used in every other subject's experimental design (columns) to better assess generalizability. The third column (C,F,I,L) shows the choice accuracy for each subject, aggregated over replications and designs. The solid black line represents the further aggregation across all subjects. Reference lines are shown demarcating the transition from Phase 1 to Phase 2 (vertical line) and the chance level of accuracy (horizontal line).


2 Discussion
2
When making decisions, we must often base our choices on only a fraction of the copious information available to us. Although only selectively attending to information relevant to our goals can substantially simplify the challenge of navigating this overabundance of information, it presents its own challenges, as we must often learn what information is most relevant. Here, we investigated this vital aspect of decision making using a combined behavioral, eye-tracking and computational modeling approach.Importantly, our combined approach illuminates how cognitive inertia traps emerge from dynamic interactions between selective attention, learning, and memory. In this multi-pronged approach, we measured gaze and performance as participants pursued a goal to categorize stimuli that possessed multiple dimensions of varying relevance to category membership. We then developed a computational model that uses an individual's gaze to infer the dimensions that they encoded in memory, and therefore the associations between dimen-sions and category membership that they learned. This inferred representation therefore captured the individual's subjective perception of the relevance of the dimensions in making correct categorization decisions. Finally, we used these inferred representations of subjective relevance to predict: (1) How participants oriented selective attention to the different dimensions, and (2) How looking at dimensions contributed to the accumulation of evidence for decision making. This approach therefore gave us key insights into the dynamic interactions between selective attention, memory, and learning in decision making that led to cognitive inertia traps. This study revealed dynamic interactions between selective attention, learning, and memory in which selective attention facilitated efficient decision making, but at the cost of cognitive inertia that caused learners to miss goal-relevant dimensions of information. First, learners fell into representation traps, in which learning the relevance of different dimensions subsequently hindered their abilityto adapt when this relevance changed [also see
26,
4,
27]
. Second, some learners also fell into attention traps, in which they rapidly learned to selectively attend to only moderately goal-relevant dimensions, even though a dimension that could have supported perfectly accurate decisions was readily available.


tained a training section (with feedback) followed by a testing section (with no feedback). In Phase 1, participants learned to classify two categories of alien creatures, and then in Phase 2 an unannounced switch occurred wherein the previously deterministic dimension and the previously irrelevant dimension swapped roles. The formerly deterministic dimension took on a new, previously unseen, value that was fixed across all stimuli of both categories, while the formerly irrelevant dimension now had two new potential values that perfectly predicted category membership (See


"
Correct this is a Flurp."). While this change in feedback may have given participants some indication that a change had occurred, it was necessary so that participants would need to figure out on their own the new contingencies between dimensions and categories. Testing in each phase consisted of 20 trials consisting of Match and Conflict items. Match items consisted of the same category structure as items presented during category learning trials, and (2) Conflict items consisted of the deterministic dimension value of one category, and all five probabilistic dimension values of the opposite category. Again, participants saw the stimuli one at a time and were instructed to indicate whether they thought each creature was a Flurp or Jalet, but no feedback was provided during the test. The 10 items seen during training (i.e., the Match items) and 10 Conflict items were each presented once, in random order. Responses to the Conflict items provided the cornerstone of our analyses related to learned inattention. Prior to the switch, they provided the baseline level that each participant tended to categorize based on the single deterministic dimension. After the switch, responses to the Conflict items told us whether participants learned and used the rule on the new deterministic (formerly irrelevant) dimension.


Figure 6 :
6
Experiment Design. (A) Example stimuli used the task, where Flurps are shown on the top row and Jalets are shown on the bottom row. In this example, the tail and button are deterministic and irrelevant dimensions in the first phase, respectively, and switch diagnosticity in the second phase. (B) Design matrices of example Flurps and Jalets by feature value, in Phase 1 (top) and Phase 2 (bottom). Match items (left) were seen in both training and testing, while Conflict items (right) were seen only during testing. (C) Time series of experimental design with number of trials indicated per each experimental period.


Participants' gaze was
tracked using an EyeLink 1000 eye tracker (SR research, Ontario, Canada) on a hydraulic arm mount with built in speakers. The eye tracker measures eye gaze by computing pupil-corneal reflection at a sampling rate of 500 Hz monocular, with accuracy averaging 0.5 • . The eye-tracking device was located inside a darkened testing room, enclosed by curtains. Once the eye tracking data were collected, we developed a generative model for the fixation data, based on the relative locations of the stimulus dimensions, the fixation variability for each individual participant, and the relative sizes of the stimulus dimensions. The Supplementary Materials provides the complete mathematical details of the model as well as three performance evaluations (i.e., recovery studies in specific scenarios). At its core, the generative model uses a finite mixture model of the form


dinates) at time t, k indexes the region of interest, Ω denotes the full set of model parameters, N 2 (x|a, b) denotes the bivariate normal density at location x with mean vector a and variance-covariance matrix b, and U(x|a) denotes the uniform density at location x along the space of support a (i.e., the bivariate screen dimensions in our case). Figure 7 provides an overview of how this approach provides a natural way to incorporate spatial proximity into the evidence accumulation component of the model. Figure 7A shows an example stimulus, and Figures 7B through Figures 7D illustrate the model components.


Figure 7 :
7
Converting Fixation Data into Attention Weights. (A) An example stimulus. (B) the central locations of each region of interest (ROI) estimated from the model. The central locations may be subject to some systematic distortions, which are examined in the Supplementary Materials. (C)


Figure 8
8
provides an overview of how the representation is updated to form a feature-to-category map. Panels A, C, and E are associated with an early trial where the representation is not fully developed, whereas Panels B, D, and F are associated with a later trial in which the representation has had time to learn the relevance of stimulus dimensions. At its core, the models maintain a representation of the likelihood that each feature in each dimension is associated with each of the (two) decisions -in this case, categories. Figure 8A represents these likelihoods (y-axis) as a function of each feature value (x-axis), where categories are designated by blue and orange circles. The likelihoods of each category across features is how the model executes actions, such as orienting attention toward relevant dimensions and making categorization decisions. Two separate functions operate over the representation to make explicit predictions about observable variables, and these predictions can be optimized by adjusting a set of seven parameters. An important constraint is that the representation is the only component of the model that is evolving through time -the mathematical structure linking the representation to attention and decision making is invariant to new learning experiences.


Figure 8 :
8
Knowledge Representation in our Category Learning Model. Panels (A,C,E) illustrate the model in an early phase of learning, whereas Panels (B,D,F) show the model at a more mature point in the learning phase. (A, B)


Figure 8C. The updated representations are used to guide information search to be used in making responses in the next experience, the representation is updated based on the acquired information, and so on.


For example, s d may take one of three values, so that s d ∈ {1, 2, 3} for d = 1 or d = 3, but s d ∈ {1, 2} for d = 2. An example stimulus on the first trial may be coded as s 1 = [2 2 1], which would indicate that the second of the three possible feature values is used in the first dimension, the second of the feature values is used in the second dimension, and the first of the feature values is used in the third dimension. To connect the stimulus to the representation, we have to transform this numerical code into an appropriately-sized matrix for the equations to be complete. Let s * i be a vector of length d F d , and partition it according to the dimensions of the stimulus:


( d F d × D) matrix consisting of column vectors that isolate the features within a given dimension. In our working example where D = 3 and F = {3, 2, 3}, the contrast matrix would appear as


which is a (1 × D) vector reflecting the summed amount of disparity within each dimension. For example V 1 = 0.20 0.20 0.00 , indicating attention should be allocated equally toward the first and second dimension. Figure 8C illustrates the concept of dimension disparity on an early trial. Here, the dark green bars correspond to the disparity-by-dimension values V 1 , because they aggregate (i.e., sum) disparity values across all features within a dimension. Here, because the representation is immature, the disparity values reflect only the effects of the instruction period, and so the disparity is small across all dimensions.


measure of attention on a feature level can be used to meaningfully constrain a computational model of learning. In the absence of direct measures of attention to guide encoding, any number of episodic memory models may be used here, such as those employing buffer style encoding systems [50, 51, 52]. In our case, we used eye-tracking data as a proxy for attention. This approach departs from other computational learning models where attention is either freely estimated and assumed fixed across time [1], or follows a particular assumption about the direction of attention orientation [e.g., reducing errors; 2, 3, 4]. Instead, eye tracking allows us to directly infer how attention orients in response to a variety of person-specific goals and incentives that are difficult to specify theoretically.Hence, our approach allows us to investigate an interesting question of whether or not participants adapt their attention in a useful way given their representation, rather than adapting attention in an optimal way, based the properties of the stimulus.


Figure 8E ,
8E
this term ζ would only inhibit parts of the representation within the same column. Because this was not found to be particularly useful when fitting the model to data, we have set ζ = 0 in the model variants presented here. To build in the concept of inhibition across dimensions, we need another matrix R to inhibit information across dimensions. The basic notion of dimension inhibition is that once the evidence values for a particular feature dimension become large enough, as they would from learning about the relevancy of a dimension, the amount of evidence itself can suppress changes in evidence learned about in other dimensions. So, even if another dimension becomes diagnostic and more relevant to the task, it may take considerable time for the model's representation to reflect this relevancy if another dimension was already determined to be relevant. Similarly, if two dimensions are considered relevant, inhibition would tend to suppress the need to consult both dimensions if one dimension


i is the matrix containing representation weights, Q pertains to within feature inhibition, R contains decay, within-dimension and across-dimension inhibition, S * i contains the stimulus information, E * i contains the information about what was attended during the trial, and α is a learning rate parameter. Setting α = 1 creates a mathematical equivalence between a strength representation and an instance representation, where episodic traces form the basis of category knowledge in the model. As we discuss in the Supplementary Materials, such a constraint performs well if inhibition is present in the model, but because learning rate effects are classic in the field of reinforcement learning, we freely estimated α in results presented in the main text. Equation 6 expresses the updating process in terms of information pertaining to encoding and the stimulus properties (i.e., right hand term) and dynamics that are not information specific (i.e., left hand term). Whereas the right hand


Finally, to eliminate
the contribution of the representation, we simply set z = 0, where z is a vector of length d F d , filled with zeros. Decision Unconstrained by Attention To implement an Decision Unconstrained by Attention variant, we eliminate the right hand term of Equation by settingv + = v − = 0. Recall that A i is a (C × d F d ) matrix,where only the columns relevant to the stimulus are nonzero. To impose equal attention along all relevant dimensions of A i , we simply set z = 1, where z is a vector of length d F d , filled with ones. Fully Constrained by Representation Similar to the Decision Unconstrained by Attention model, the Fully Constrained by Representation model commits a theoretical constraint by tying the drift rates to the representation by setting v + = v − = 0. As above, we let g i,d denote the amount of time spent fixating on the dth dimension on Trial i. For convenience, we can define a vector containing all of these fixation durations on Trial i, organized by dimension, such that


are a total of seven parameters in the Fully Constrained by Representation model: a learning rate parameter α, a leakage or decay parameter λ, an across-category inhibition parameter β, a softmax temperature parameter κ to convert the dimension disparity values into fixation proportions, a threshold parameter θ for the evidence accumulation process, a nondecision term τ that shifts the predicted choice response time distributions due to motor response times and visual encoding, and a threshold parameter b on absolute time that determines how much fixation is needed to encode a stimulus feature. When the perfect encoding mechanism is used, the parameter b is set to zero and not estimated (e.g., the Representation Unconstrained by Attention model). When the representation is completely disconnected from the decision making component (e.g., the Decision Unconstrained by Representation model), we add two parameters, v + and v − . When dimension disparity is not used (e.g., the Attention Unconstrained by Attention model), the parameter κ is removed and DD i is set to 1/D, where D is the number of dimensions.Because we estimate the model parameters in a Bayesian framework, we must specify priors for each of the parameters. We settled on the following informative priors:α ∼ Beta(3, 2) λ ∼ Beta(5, 1) β ∼ Gamma(1, 5)κ ∼ Gamma
(10,
13)
 θ ∼ Gamma
(5,
1)
 τ ∼ Gamma(5, 0.01) b ∼ Gamma(8, 0.1), andv + , v − ∼ Gamma(4, 1)


Figure 9 :
9
Costs of Selective Attention. (A) Accuracy of responses are shown during Phase 1 (left) and Phase 2 (right). (B) Probability of making a response consistent with the deterministic features for Match (left) and Conflict items (right) are shown for both phases (P1: Phase 1; P2: Phase 2). Match items match the trained category structure on both deterministic and probabilistic dimensions, whereas Conflict items match on the deterministic dimension and mismatch on probabilistic dimensions (i.e., match the opposing category). (C) Response time data are shown during Phase 1 (left) and Phase 2 (right), where the median response time is shown as the black line. (D) Response time data for Match (left) and Conflict (right) items, separated by phase. (E) Probabilities of attending to deterministic (D; blue lines), probabilistic (P; gray lines), and irrelevant (I; red lines) dimensions are shown, separated by phase. Note that the D and I features change roles from Phase 1 to Phase 2. (F) Probabilities of dimension attention for Match (left) and Conflict (right) items are shown, separated by phase.


The notion that the most plausible representation of human learning we investigated is susceptible to traps is indeed quite alarming. Are traps actually unavoidable for most humans? Our final analysis revealed a prescriptive strategy that enabled the same underlying representation to largely avoid traps, while maintaining high levels of accuracy. The key modification was to only allow the representation to partially guide selective attention. By forcing the model to sample more information than it thought was necessary, the model was able to avoid both types of traps because it remained open to learning more about the stimuli than would otherwise naturally occur. These results suggest that caution must be taken when a learner is allowed to sample information, as selective attention narrows the diversity of knowledge that may be required to navigate an ever changing world.
Selective attention keeps us from wasting cognitive resources on elements of
our environment that do not facilitate positive behavior, allowing us to instead
focus on the factors most relevant to our goals. Despite these vital advantages,
selective attention also carries costs that can cripple our ability to perform
optimally. As we demonstrated here, selective attention plays a key role in con-
structing our representations of the world which can then cause our perceptions
to deviate from reality. When selective attention drives representations, peo-
ple often form premature and incomplete perceptions of the world, and when
selective attention is driven by our representations, people may have difficulty
adapting to changes in the environment.
3 Methods
3.1 Participants
The participants were 38 (25 female, 13 male, mean age = 19 years) Ohio State University undergraduate students who participated in exchange for par- tial course credit. We obtained informed consent for all participants in our study. The study was approved by the Institutional Review Board at The Ohio State University. No statistical methods were used to pre-determine sample sizes but our sample sizes are similar to those reported in previous publications [40, 5].


The targeting ability and the dimension size were then fused to create a mixture of two bivariate normal distributions for each stimulus dimension, corresponding to the Σ k terms in Equation 1. In addition, the finite mixture model in Equation 1 considers the possibility of contaminants, which allow us to separate fixations to ROIs from non-fixations, such as saccades between ROIs, blinks, or looks that happen to be off-screen. The relative proportions of fixations to all sources -ROIs and contaminants -are then modeled by coefficients π k , which allows the generative model to capture particularly complex situations where not all dimensions are attended, or a single dimension is split into two different locations (e.g., the hands on opposite sides of the body).
(k) y ) terms in Equation 1. Figures 7C and 7D consider the error
variance associated with intentionally targeting a specific stimulus dimension.
For our analyses, we allowed each participant to have their own specific tar-
geting variance term that describes the amount of variability expected during
a fixation at a specific location µ
k . We assumed that targeting variance was isotropic, meaning that it was of equal width in both x and y directions. Fig- ure 7D considers variance that may come about simply because the ROIs have different sizes. In some cases, such as the body, the variance associated with fixations to an ROI (e.g., along the y dimension) should be much larger than for other ROIs. In our analyses, we assumed a single variance term that was scaled based on the size of each ROI along each dimension. 1


With appropriate representations of the stimulus and attention in place, we can now specify how updates in the model should occur. The update equation is similar to the Adaptive Representation Model [ARM; 27], with some slight adjustments for the specifics of our experiment. First, we assume that within a dimension, the similarity kernel is a simple pattern matcher so that features within a dimension are either matching the stimulus or not. For example, although a blue tail and an orange tail are similar in their dimension location, they are not similar to one another in terms of feature properties. This occurs naturally in the model based on the manner in which the stimuli are coded into discrete labels. Of course, one could recode the stimuli to exhibit primitive properties, such as edges, size dimensions, or color values (e.g., RGB), but this
seemed to be an unnecessary complication for our application. Second, because
we are extending ARM to multiple dimensions, we must consider how these di-
mensions interact on the basis of a set of experiences. Indeed, one of the central
problems we wish to address here is how learning about relevancy of a dimen-
sion can prohibit adaptations in later experiences. For example, if one learns
early on that a dimension is highly predictive of category label, how much will
this information inhibit the search for new information when that dimension
changes in relevancy or is hidden from view?
In the context of a single dimension, Turner [27] used a feedback matrix Q
of dimension (C × C) to incorporate inhibition. For example, Q may take the
form
Q


giving a choice advantage for the correct category response. Although one would typically expect v + > v − , and indeed this will occur if a participant is performing above chance, we do not impose such a restriction when estimating the parameters.To implement the drift rate arrangement above, we define a category label vector T i such that T i = [1 0] when the stimulus on Trial i is a Flurp and T i = [0 1] when it is a Jalet. Further, we can specify


This worked well for our purposes because the ROIs were roughly characterized by ellipsoids.














Attention, similarity, and the identificationcategorization relationship




Robert
M
Nosofsky








Journal of Experimental Psychology: General




115
















ALCOVE: An exemplar-based connectionist model of category learning




John
K
Kruschke








Psychological Review




99
















SUSTAIN: A network model of category learning




B
C
Love






D
L
Medin






T
M
Gureckis








Psychological Review




111
















The limits of learning: Exploration, generalization, and the development of learning traps




A
S
Rich






T
M
Gureckis








Journal of Experimental Psychology: General




147
















Adaptive flexibility in category learning? young children exhibit smaller costs of selective attention than adults




N
J
Blanco






V
M
Sloutsky








Developmental Psychology




55
















Eyetracking and selective attention in category learning




B
Rehder






A
B
Hoffman








Cognitive Psychology




51
















Thirty-something categorization results explained: Selective attention, eyetracking, and models of category learning




B
Rehder






A
B
Hoffman








Journal of Experimental Psychology: Learning, Memory, and Cognition




31
















Extremely selective attention: Eye-tracking studies of the dynamic allocation of attention to stimulus features in categorization




M
R
Blair






M
R
Watson






R
C
Walshe






F
Maj








Journal of Experimental Psychology: Learning, Memory, and Cognition




35
















Gaze bias differences capture individual choice behavior




A
W
Thomas






F
Molter






I
Krajbich






H
R
Heekeren






P
N
Mohr








Nature Human Behaviour




3
















Gaze-informed modeling of preference learning and prediction




S
M
Smith






I
Krajbich








Psychology, and Economics




12










Journal of Neuroscience








Gaze amplifies value in decision making




S
M
Smith






I
Krajbich








Psychological Science




30
















Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based choice




I
Krajbich






A
Rangel








Proceedings of the National Academy of Sciences of the USA


the National Academy of Sciences of the USA






108














Visual fixations and the computation and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel








Nature Neuroscience




13


















M
L
Mack






B
C
Love






A
R
Preston




Dynamic updating of hippocampal object representations reflects new conceptual knowledge. Proceedings of the National Academy of Sciences






113














Response times: Their role in inferring elementary mental organization




R
D
Luce








Oxford University Press


New York












Modeling response times for two-choice decisions




R
Ratcliff






J
N
Rouder








Psychological Science




9
















Two Stage Dynamic Signal Detection Theory: A Dynamic and Stochastic Theory of Confidence, Choice, and Response Time




T
J
Pleskac






J
R
Busemeyer








Psychological Review




117
















Decision Field Theory: A Dynamic-Cognitive Approach to Decision Making in an Uncertain Environment




J
R
Busemeyer






J
T
Townsend








Psychological Review




100
















Multialternative decision field theory: A dynamic connectionist model of decision making




R
M
Roe






J
R
Busemeyer






J
T
Townsend








Psychological Review




108
















Theoretical developments in decision field theory: comment on tsetsos, usher, and chater




J
M
Hotaling






J
R
Busemeyer






J
Li








Psychological Review




117
















A dynamic, stochastic, computational model of preference reversal phenomena




J
G
Johnson






J
R
Busemeyer








Psychological Review




112
















A theory of memory retrieval




R
Ratcliff








Psychological Review




85
















A ballistic model of choice response time




S
Brown






A
Heathcote








Psychological Review




112
















The simplest complete model of choice reaction time: Linear ballistic accumulation




S
Brown






A
Heathcote








Cognitive Psychology




57
















An exemplar-based random walk model of speeded classification




R
M
Nosofsky






T
J
Palmeri








Psychological Review




104
















A dynamic, stimulus-driven model of signal detection




M
Brandon






Trisha
Turner






Scott
D
Van Zandt






Brown








Psychological Review




118
















Toward a common representational framework for adaptation




B
M
Turner








Psychological Review




126
















Simultaneous hierarchical bayesian parameter estimation for reinforcement learning and drift diffusion models: a tutorial and links to neural data




M
L
Pedersen






M
J
Frank








Computational Brain and Behavior
















Toward an instance theory of automatization




G
D
Logan








Psychological Review




95
















Exemplar models as a mechanism for performing bayesian inference




L
Shi






T
L
Griffiths






N
H
Feldman






A
N
Sanborn








Psychonomic Bulletin and Review




17
















How persuasive is a good fit




S
Roberts






Harold
Pashler








Psychological Review




107
















Applying Occam's razor in modeling cognition: A Bayesian approach




I
J
Myung






M
A
Pitt








Psychonomic Bulletin and Review




4
















Competing theories of multialternative, multiattribute preferential choice




B
M
Turner






D
R
Schley






C
Muller






K
Tsetsos








Psychological Review




125
















On the neural and mechanistic bases of self-control




B
M
Turner






C
A
Rodriguez






Q
Liu






M
F
Molloy






M
Hoogendijk






S
M
Mcclure




















Cerebral Cortex


















Estimating the dynamic role of attention via random utility




S
Smith






I
Krajbich






R
Webb








Journal of the Economic Science Association




5
















Estimating the dimension of a model




G
Schwarz








Annals of Statistics




6
















A note on bayes factors for log linear contingency table models with vague prior information




A
E
Raftery








Journal of the Royal Statistical Society: Series B (Methodological)




48


2
















Decision making: Descriptive, normative, and prescriptive interactions




D
E
Bell






H
Raiffa






A
Tversky








Cambridge University Press












Simple heuristics that make us smart




Gerd
Gigerenzer






M
Peter






Todd








Oxford University Press


USA












Carrot-eaters and moving heads: Salient features provide greater support for inductive inference than category labels




W
Deng






V
M
Sloutsky








Psychological Science




23
















The role of linguistic labels in inductive generalization




W
Deng






V
M
Sloutsky








Journal of Experimental Child Psychology




114
















The role of words and dynamic visual features in infant category learning




W
Deng






V
M
Sloutsky








Journal of Experimental Child Psychology




134
















The development of categorization: Effects of classification and inference training on category representation




W
Deng






V
M
Sloutsky








Developmental Psychology




51
















Selective attention, diffused attention, and the development of categorization




W
Deng






V
M
Sloutsky








Cognitive Psychology




91
















Value-based attention but not divisive normalization influences decisions with multiple alternatives




S
Gluth






N
Kern






M
Kortmann






C
L
Vitali








Nature Human Behaviour
















Hierarchical approximate Bayesian computation




M
Brandon






Trisha
Turner






Van Zandt








Psychometrika




79
















Individual choice behavior: A theoretical analysis




R






Duncan
Luce








Wiley Press


New York












Of models and men




W
K
Estes








American Psychologist




12
















Reinforcement Learning: An Introduction




R
S
Sutton






A
G
Barto








The MIT press


Cambridge, MA












Search of associative memory




J
G W
Raaijmakers






R
M
Shiffrin








Psychological Review




88
















A model for recognition memory: REM -retrieving effectively from memory




M
Richard






Mark
Shiffrin






Steyvers








Psychonomic Bulletin and Review




4
















A dynamic approach to recognition memory




G
E
Cox






R
M
Shiffrin








Psychological Review




124
















Effects of similarity and practice on speeded classification response times and accuracies: Further tests of an exemplar-retrieval model




R
M
Nosofsky






L
A
Alfonso-Reese








Memory & Cognition




27
















On the form of forgetting




J
T
Wixted






E
B
Ebbesen








Psychological Science




2
















Short-term memory scanning viewed as exemplar-based categorization




Robert
M
Nosofsky






Daniel
R
Little






Christopher
Donkin






Mario
Fific








Psychological Review




118
















Recognizing spatial patterns: A noisy exemplar approach




M
J
Kahana






R
Sekuler








Vision Research




42
















Ventromedial prefrontal cortex compression during concept learning




M
L
Mack






A
R
Preston






B
C
Love








Nature Communications




11


46














On the ability to inhibit thought and action: General and special theories of an act of control




G
D
Logan






T
Van Zandt






F
Verbruggen






E.-J
Wagenmakers








Psychological Review




121
















Time-dependent Poisson counter models of response latency in simple judgment




L
Philip






Trisha
Smith






Van Zandt








British Journal of Mathematical and Statistical Psychology




53














ROC curves and confidence judgments in recognition memory




T
Van Zandt








Journal of Experimental Psychology: Learning, Memory, and Cognition




26
















Response reversals in recognition memory




T






Van
Zandt






Mildred
M
Mal"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]