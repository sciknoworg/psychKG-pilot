You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Based on theoretical considerations 
(Nosofsky, 1986
(Nosofsky, , 2011
Wallenius et al., 2008)
 we propose that MAVC can serve as a model for value-based choice. In MAVC, we can experimentally manipulate memory representation strength of exemplars through changes of the retention interval between exemplar presentation and choice. This maps to a manipulation of the strength of memorybased goal representations in our framework (see figure 1). Revealed preference theory 
(Houthakker, 1950;
Samuelson, 1938;
Varian, 1982)
 can be used to analyze MAVC consistency without requiring assumptions about attribute weights or the parametric form of an integration function. Therefore, revealed preference theory can provide a general test of adherence to multiattribute integration as formulated by the Generalized Context Model of categorization and multiattribute utility theory. We propose the following hypothesis: H1: As memory representations of exemplars are integral for MAVCs 
(Nosofsky, 2011)
, we expect choice-consistency to decrease for longer retention intervals. That is, we expect an inverse relationship of retention interval between learning of the exemplar and choice, and choiceconsistency across multiple choices. Hence, we will provide experimental evidence on the role of memory representation strength of goals for choice-consistency.
Previous research on the retention of information shows that forgetting curves are nonlinear 
(Averell & Heathcote, 2011
). As we expect choice-consistency to be directly affected by the memory representation, we also expect the relationship of the retention interval and choiceconsistency to be non-linear.


H2:
We expect choice-consistency to decrease exponentially for longer retention intervals.
That is, we expect an exponential model of the relationship of retention interval and choiceconsistency to be more strongly supported by the data than a null model (predicting a truncated normal distribution around the mean of the data). The evidence on H2 will help us to quantify the role of memory representation strength of goals for choice-consistency beyond a directional prediction.
H3: In congruence with H2, we expect the exponential decrease of choice-consistency for longer retention intervals to directly replicate in a new data set. This is important, as replicability is a minimal requirement on the meaningfulness of a psychological phenomenon.


Methods


Why is revealed preference theory necessary
Our main dependent variable is consistency in multi-attribute visual choice. We quantified visual choice-consistency with analysis tools borrowed from revealed preference theory. These are preferable over standard indices used in the visual memory and perception literature for conceptual and methodological reasons, as explained in the following.
Value-based choices usually involve trade-offs of different choice attributes. For example, a customer buying snacks might consider both taste and healthiness. While a chocolate bar is arguably tastier, an orange is healthier. A decision, therefore, requires integrating both choice attributes.
Whether, taste or health is given more weight is subjective. Concludingly, there is no objectively correct choice. A model of value-based choices should, therefore, include similar attribute tradeoffs.
In MAVCs, the choice set stimuli represent a trade-off of similarity to the exemplar regarding multiple attributes. This means that, unlike in traditional memory recognition tasks, such as delayedmatch-to-sample tasks, no visual object in the choice set is most similar to the exemplar with regard to all attributes. For example, consider a 3D exemplar cube whose orientation is tilted along the Xand Y-axes (see figure 2). One object in the choice set might be most similar to the exemplar regarding X-orientation while another one is similar regarding Y-orientation. Therefore, there is no objectively correct or dominating choice. This prohibits the use of traditional accuracy measures of perceptual choice that require a normatively correct choice option. In contrast, revealed preference theory allows to test choice-consistency in the context of attribute trade-offs without making unnecessary assumptions about attribute weights or the form of an integration function 
(Choi et al., 2014)
.


Sample Characteristics and Exclusion criteria
Participants were recruited from undergraduate psychology students at Heinrich-Heine-University Düsseldorf, Germany on campus and by online adverts. Participants were at least 17 years old, had normal or corrected vision, a good level of German, no neuropsychological or psychiatric diseases and gave informed written consent. The study was approved by the local institutional review board of Heinrich-Heine-University and was conducted in accordance with the declaration of Helsinki. Participants were reimbursed by course credit.
Participants were excluded from the analysis if they do not complete the full experimental session. We did not exclude partial data.


Experimental Setup and Procedure
After participants had given their informed written consent, we assessed age, gender and mother-tongue.
Participants then solved a memory-based visual decision task (see 
figure 2)
. In each trial, a 3D exemplar cube was presented for 5 seconds. 1 Each side of the cube was characterized by a unique color in the RGB space 2 from a color scale optimized for color-blind people 
(Wong, 2011)
.
Each side of the cube was 200px long. The exemplar cube had an orientation of 
10,
75,
120,
185,
250
 or 315 degrees on the X-and Y-Axis and an orientation of 0 degrees on the Z-Axis. After presentation of the cube a mask of 10 similar cubes (with random X-and Y-orientations) was presented to the participants for a short retention interval. After the retention interval, a choice set of five cubes with variable X-and Y-orientations was presented, and participants had to select one of the five cubes that had the most similar overall orientation to the exemplar.
The general notion of the task can be compared to that of delayed match-to-sample tasks 
(Habeck et al., 2004;
Steffener et al., 2009
Steffener et al., , 2012
Zarahn, 2004;
Zarahn et al., 2006
Zarahn et al., , 2007
 with the difference that there is never a perfect match to the sample. Instead, the choice set stimuli represented a variable trade-off of orientation similarity to the exemplar regarding the X-and Y-axis.
For example, a particular stimulus from the choice set might have had a similar X-orientation but a different Y-orientation. Another stimulus might have had a different X-orientation but a similar Yorientation. Additionally, there could be trials where the choice set stimuli orientations resembled the exemplar orientation more closely and other trials where all choice set stimuli were quite differently oriented from the target stimuli.
The task of the participants was, therefore, to mentally rotate each stimulus of the choice set until it matches the previously shown exemplar and evaluate which of the stimuli required the least mental rotation overall.
Framed in terms of revealed preference theory, each choice trial was constructed from a budget of = 100 tokens. A pair of prices ' = ( ' )*+,' , ' )*+,' ) was chosen uniform-randomly from a numeric range of 1 to 3 and 1 to 10. The ranges were assigned to the prices randomly for each trial.
In value-based choice, the price of a good is the cost required to obtain a unit of this good.
The budget line then constitutes all combinations of goods affordable spending a fixed budget. Thus, prices and budgets lines are constraints that restrict the possible choice set of combinations of goods out of all available goods. Similarly, the prices and budgets in our multi-attribute choice task constrained the choice set of visual objects out of all possible visual objects characterized by specific attribute values (see figure 3). Given a fixed budget, the prices determined how much 'similarity' to the exemplar a participant could 'purchase' along a given orientation axis. The 'cheaper' a given dimension, the more similarity to the exemplar on that dimension a participant could afford.
The 5 visual objects were then generated as equidistant-points covering the entire budget
line ' 0*+,' = m ' 0*+,' ⁄ − ' )*+,' × ' )*+,' ' 0*+,' 6 .
Consequently, the choice set always included the extreme objects ',7 = 8 ' )*+,' ⁄ , 09 and
',: = 80, ' 0*+,'
⁄ 9
. An attribute value of ' )*+,' = 0 corresponded to an orientation difference of 30 degrees to the exemplar along the X-axis. With increased values of the X-orientation attribute, the choice object was turned towards the exemplar position along the X-axis. A single unit size amounted to 0.3 degree turn. An attribute value of ' )*+,' = 100 corresponded to matching orientation to the exemplar along the X-axis. Likewise, an attribute value of ' 0*+,' = 0
corresponded to an orientation difference of 30 degrees to the exemplar along the Y-axis. With increased values of the Y-orientation attribute, the choice object was turned towards the exemplar position along the Y-axis. A single unit size amounted to 0.3 degree turn. An attribute value of ' ;*+,' = 100 corresponded to matching orientation to the exemplar.
Participants received in-depth instructions about the task (see appendix). Further, they were presented with an animated rotating cube to familiarize with the cube itself. 
3
 Participants then first solved a practice block of 10 trials with a 1 second retention interval. This practice block served for the participants to familiarize with the design. Choices from the practice block were not included in the analysis. After the practice block, participants were asked to turn to the experimenter in case of questions. Then they solved two consecutive blocks of 20 trials each. For each test block, each participant was assigned a uniform-random retention interval between 0 and 30 seconds (please refer to paragraph "Floor and ceiling effects" below for discussion of the optimal interval length). In total, participants made 20 decisions each for two distinct retention intervals.
After participants had completed the second test block, they solved a similar exemplar reconstruction task as a quality control and manipulation check. The first three screens of each trial were equivalent to the procedure of the main task. Each trial started with the presentation of a fixation cross. Next, participants were presented with an exemplar cube with a certain orientation along the X-and Y-axis for 5 seconds. Then, participants were presented with a mask of 10 randomly oriented cubes (see figure 2) for a certain retention interval. Each participant was assigned a retention interval of either 1, 5, 10 or 30 seconds for the memory reconstruction task. After the retention interval, participants were again presented with a single cube similar to the exemplar. The cube randomly matched the exemplar either regarding the X-or the Y-orientation, while the initial complementary orientation was chosen uniform randomly. Participants then had to turn the cube on the screen to match the exemplar regarding the complementary orientation using the arrow keys on the keyboard. Importantly, it was unknown to the participants whether they would have to reconstruct the X-or Y-orientation both during the presentation time and the retention interval.
Participants solved 50 trials of the reconstruction task. Importantly, we did not use the results from the reconstruction task for our main analyses but as a manipulation check.
After completion of the reconstruction task, participants were debriefed about the goals of the study in written form and reimbursed via course credit.
The experimental task was presented with jsPsych (de Leeuw & Motz, 2016). All stimuli were presented on a Lenovo ThinkPad T590 laptop. Subjects were seated 30 cm away from the monitor in a dimly lighted room.


Revealed Preference Theory for MAVC
We measured consistency in MAVC, i.e., the degree of consistency in weighting the two orientation dimensions when comparing the memorized exemplar with the choice set. A participant would act consistent, for example, if they assigned more weight to orientation similarity to the exemplar along one axis when it was expensive, and less weight when it was cheap. Revealed preference theory can be used to quantify the level of inconsistency in weighting the visual attributes in a straight-forward manner.
Let ∈ ℕ be the number of different attributes of a visual object.
MEMORY AND CHOICE CONSISTENCY 13 Following Nosofsky (2011), let = ℝ A B be the non-negative, -dimensional space of visual objects . Let = ℝ A B be the non-negative, -dimensional space of prices of attribute similarities to the exemplar. Let = ℝ A be the non-negative, one-dimensional space of budgets. Let = , … ∈ ℕ denote observations of choice.
Let ' ∈ be the chosen visual object of an observation ∈ . Each visual object ' is adimensional vector of the shape ' = ( ' H , ' I , … , ' B ), with each scalar component ' J representing the similarity of the visual object ' with regard to attribute .
Let ' ∈ be the given prices of attribute similarities of an observation ∈ . Each prices '
are a -dimensional vector of the shape ' = ( ' H , ' I , … , ' B ), with each scalar component ' J representing the price of similarity to the exemplar with regard to attribute per unit size.
Then the scalar product ' L represents the total price of a visual object ' at some prices L . Let ' ∈ be the given budget of an observation ∈ . We assume, that a decision maker spends all her budget so that ' ' = ' ∀ ∈ .  
3)
. A simple example of such an integration function could be that subjective similarity is the weighed sum of the similarity along each attribute dimension. As one anonymous reviewer correctly pointed out, mental rotation may not necessarily be performed in an independent, piecewise fashion but possibly also in a holistic mode 
(Shepard & Metzler, 1971)
, at least for some participants 
(Heil & Jansen-Osmann, 2008)
. We want to emphasize that any concave monotonous similarity function is consistent with revealed preference theory. Hence, an independent (i.e. additive) treatment of the two rotation axes is not required for our model.
However, contrary to Nosofsky (1986), we do not need to make assumptions regarding the parametric form of such an integration function. Conversely, if the data do not pass Axiom 1 no GCM-style integration function of any monotonous concave specification can rationalize the data.


Preprocessing
For each test block and participant, we calculated the critical cost efficiency index (CCEI; 
Afriat, 1972
Afriat, , 1973
Varian, 1991)
. The critical cost efficiency index can be interpreted as how consistently multiple attributes of choice options are integrated into a decision value. The CCEI denotes the "amount by which each budget constraint must be adjusted in order to remove all violations of GARP" 
(Choi et al., 2007
(Choi et al., , p. 1927
. Computationally, the CCEI presents a relaxation of Axiom 1, so that only ' L → ¬8 L L × CCEI > ' L 9 ∀ , ∈ must hold. It ranges from zero to one. A value of one denotes perfect consistency: The attributes are weighed consistently across all choices. The critical cost efficiency index approaches zero as choices become increasingly inconsistent, which means that choice option attributes are weighed inconsistently across different trials. The critical cost efficiency index is the most common indicator of compliance with choiceconsistency as defined by revealed preference theory and has been applied in value based choice in various domains 
(Nitsch & Kalenscher, 2020)
. Further, we explored the robustness of our results using similar indices such as the money pump index (Echenique et al., 2011), the Houtman-Maks-Index 
(Heufer & Hjertstrand, 2015)
 and the minimum cost index 
(Dean & Martin, 2016)
. However, since all of these metrics measure slightly different constructs we restrained our preregistered analysis to the critical cost efficiency index.


Analysis Pipeline
Per participant, the data from one test block was randomly selected for testing for an inverse relationship of retention interval and choice-consistency, Bayes factor model comparison and parameter estimation. We call this data training set. The other test block was used to replicate our results in a new data set. Therefore, this data was not used for other analyses. We call this data test set.
For all analyses, we used a Bayesian framework of inference. Bayesian statistics allows us to express confidence that a parameter is within a certain range, to extend parameter estimation naturally for complicated models, to express evidence for or against hypotheses on a continuous scale and to monitor evidence accumulation 
(Wagenmakers et al., 2018)
.
All our analysis were conducted in RStudio (RStudio 
Team, 2018)
. We used the following R packages: BayesFactor , runjags (Denwood, 2016), Tidyverse 
(Wickham et al., 2019)
 and patchwork 
(Pedersen, 2019)
. Further, we used the JAGS software 
(Plummer, 2003)
 for analysis of Bayesian graphical models.


H1: Test for an inverse relationship of retention interval and choice-consistency.
In order to test for an inverse relationship of retention interval and choice-consistency, we calculated Kendall's Tau in the training set. Compared to Pearson's r, it is robust to outliers and violations of normality and expresses dependence in terms of monotonicity instead of linearity 
(van Doorn et al., 2018)
. This is important, as we neither expected choice-consistency (index ranging from 0 to 1) or the retention interval (uniformly sampled from an interval of 0 to 30 seconds) to be normally distributed, nor both variables to have a linear relationship. We followed the exact procedure proposed by van 
Doorn et al. (2018)
 to test for an inverse relationship of retention interval and choice-consistency using Bayes Factor analysis for Kendall's Tau.


H2: Bayes Factor model comparison of exponential and null model.
In order to gain further insights into the relationship of retention interval and choice-consistency we planned to test which model is supported more strongly by the data of the training set (but see section Interpretative Plan and results for H1 why we did not proceed to test this hypothesis). For this, we planned to use Bayes Factor model comparison via the product space method 
(Lodewyckx et al., 2011)
. We planned to test two candidate models against each other, which are specified in the following sections. We assumed both models to had equal prior probabilities.
[H = [I = 0.5
The first candidate is inspired by forgetting models of item recall 
(Averell & Heathcote, 2011
), the second model is a null model assuming no effect of the retention interval on choiceconsistency. They give rise to observed participant choice-consistency, given a retention interval.
Both candidate models are of the general form:
`~(`, ) ℎ `, ∈ [0,1].
denotes the critical cost efficiency index of a participant for one test block, denotes the assigned retention interval for that block (ranging from 0 to 30 seconds). accounts for random noise in the data. We assume all parameter values for to be equally likely a priori.


~(1,1)
` denotes the expected choice-consistency given a retention interval and is specific to the model candidates.
Exponential Model. The first candidate model assumes that choice-consistency decreases exponentially with retention time. This means that the decreasing rate of consistency is constant over retention time. Following 
Averell & Heathcote (2011)
, the function can be formalized in the following way:
`= + (1 − ) × × *q×`
The parameter ∈ [0,1] determines an asymptotical minimum level of choice-consistency after an infinite retention interval. The parameter ∈ [0,1] determines choice-consistency at = 0, which allows for imperfect choice-consistency unconditional on time-dependent processes when < 1. The parameter ∈ [0,1] determines the retention time-constant decreasing rate of consistency. We assume that all parameter values are equally likely a priori. The parameter ∈ [0,1] determines the expected value of the choice-consistency. We assume that all parameter values for are equally likely a priori.
~(1,1)


H3: Replication for the test set
In order to test whether the relative advantage in support by the data for the exponential model in comparison to the null model replicates to a new data set, we planned to obtain the replication Bayes factor using the held out test set using the method described by Ly et al. 
(Ly et al., 2019
; but see section Interpretative Plan and results for H1 why we did not proceed to test this hypothesis). The replication Bayes factor is given by Bayes Factor for the coerced data set divided by the Bayes factor for the training set (obtained for H2).
H7 (`v w`|`,y'J ) = H7 (`v w`,`,y'J ) H7 (`, y'J )
This evidence updating method does not require approximations and is especially useful for complex models as in our application case.


Interpretative Plan
We followed the usual framework 
(Jeffreys, 1998)
 for interpreting Bayes Factors, which means that we considered a Bayes factor of ≥ 10 as strong evidence for a hypothesis. 
Table 1
 summarizes the interpretative plan for all hypotheses.
We collected further data until we reach a conclusive result for all hypotheses.
H1: Should we find strong support for an inverse relationship of retention interval and choice-consistency, we would conclude that choice-consistency in MAVC depends on the memory representation strength of exemplars. Should we find strong evidence against an inverse relationship of retention interval and choice-consistency, this would question the role of memory representation of exemplars in MAVC. It could be concluded, that choice-consistency is robust to indefinite goal representations. In this case, we would not proceed to test H2 and H3.
H2: Should we find strong evidence, that the exponential model of the relationship of retention interval and choice-consistency is supported more strongly by the data than the null model, we would interpret this as preliminary evidence for the validity of the exponential model.
However, a definitive interpretation would require generalizability of the results for the test set.
Furthermore, our statistical tests would only collect relative evidence for one model over another. It would still be possible, that the true model is outside our model space. Therefore, careful inspection of the visualizations of the model predictions would be required (see figures 5 and 6). Should we find strong evidence in support of the null model, this would question the validity of an exponential model specifically, given positive evidence for H1. Again, a definitive interpretation would require generalizability of the results for the test set.
H3: Should we find strong evidence that the relative advantage in support by the data for the exponential model in comparison to the null model replicates to a new data set, we would interpret this as further evidence for the validity of the exponential model. Should the replication
Bayes factor favor the null model, this would question the validity of an exponential model specifically, given positive evidence for H1. Again, our statistical tests would only collect relative evidence for one model over another. Careful inspection of the visualizations of the model predictions would be required (see figures 5 and 6).
Should we find conflicting evidence for H2 and H3, we would use the Bayes factor for the complete dataset ( H7 (`v w`,`,y'J ) to guide our interpretation. The Bayesian model comparison using the complete dataset quantifies the evidence for or against each model in light of all data. We would use the same interpretation framework as before, which means that we consider a Bayes factor of ≥ 10 as conclusive evidence.


Data Collection Plan / Power Analysis


Inferential power
Our data collection plan is based on a Bayesian stopping rule: We collected data until we reached a Bayes factor of ≥ 10 ∨ ≤ 0.1 or a maximum feasible sample size of = 500.


Sensitivity of choice-consistency test
In order to make meaningful statements about the influence of memory processes it is not only necessary to experimentally manipulate these memory processes with a sufficient effect size but also to measure choice-consistency with sufficiently sensitive measure. The sensitivity of our behavioral task to detect violations of choice-consistency can be approximated using a simulation study 
(Bronars, 1987)
. We simulated a dataset of 1.000 virtual participants that made uniform random choices from 20 choice sets constructed as specified for our experiment (see Procedure).
Results showed that 99% of the virtual participants violated choice-consistency at least once with a median CCEI of 0.389 (see 
figure 7)
.


Specification of Reality Checks
First, to ensure that our retention interval manipulation is effective, we tried to replicate the effect of the retention interval on absolute reconstruction error of exemplars from memory that we found in our pilot experiment (see pilot experiment) in our control task. Specifically, we wanted to find strong evidence (Bayes factor of at least ≥ 10) favoring a one-way ANOVA style model including the 4-step retention interval factor over a null model. Inference was based on the MEMORY AND CHOICE CONSISTENCY 20 replication Bayes factor fully utilizing the evidence from our pilot experiment with H7 8 +,'| 9 = 1000 
(Ly et al., 2019)
.
We used the JAGS software 
(Plummer, 2003)
 to analyze our Bayesian graphical models. To assess convergence we used trace plots of the Markov-Chain-Monte-Carlo simulations and smoothed density plots of the parameter estimates 
(Kruschke, 2014)
.
Following Blaha (2019), we think that visualization is an important reality check to see,
whether the data looks like we expected and hypothesized. Therefore, we planned to create two main plots for visual qualitative checks of the data and models.
First, we created a scatter plot of retention interval and choice-consistency in the training set together with histograms of the marginal distributions. This allowed for a visual inspection of the relationship of both variables as well as the marginal distributions. We did not want to see choiceconsistency increase as a function of retention interval, as such pattern is not covered by our model space. The marginal distribution of the retention interval should, trivially, be uniform (as generated by the experimental task). The marginal distribution of the choice-consistency should, ideally, be a right-tailed Gaussian, meaning a tail for large consistency values. 
Figure 5
 shows such a plot for data simulated from the exponential model.
Second, we planned to create a plot that is overlaying scatter plots of retention interval and choice-consistency in the training set with the posterior predictive distributions of the exponential model and the null model (but see section Interpretative Plan and results for H1 why we did not proceed with our computational modelling). This would allow us to visually inspect how well the models can explain the data and further, if there are any important qualitative differences between predictions and data. This is an important step to inform future modelling efforts and to identify systematic short-comings of a model. Further, we would create the same plots for retention interval and choice-consistency in the test set overlaid with the out-of-sample posterior predictions of both models to qualitatively evaluate the generalizability of the models (but see section Interpretative
Plan and results for H1 why we did not proceed with our computational modelling). 
Figure 6
 shows such plots for data simulated from the exponential model.


Floor and ceiling effects
Should we find that choice-consistency is either near perfect or at very low levels across all retention intervals, this would indicate ceiling or floor effects respectively. While this is theoretically possible (e.g. in case of an ineffective retention interval manipulation), we reduced the likelihood of finding such a pattern by using a continuous manipulation of the retention interval instead of a factorial design. Therefore, our design covered a wide range of retention intervals (interval of 30 seconds) instead of 2 to 3 retention intervals, a factorial design would cover. Still, it was not possible to entirely rule out the possibility of an ineffective retention interval manipulation on theoretical grounds only. Therefore, we conducted a pilot experiment to demonstrate the effectiveness of our manipulation using the control task from our main experiment (see below).


Further limitations
As one anonymous reviewer pointed out, our MAVC paradigm does not include a no-choice option. Intuitively, for some trials it would be difficult for participants to make a similarity judgement. However, we decided not to include a no-choice option in our paradigm as one core assumption of revealed preference theory is that there is a well-defined preference structure 
(Afriat, 1973
) and this also holds for difficult decisions. Therefore, asking participants to make a choice for difficult decisions is part of a rigorous test of revealed preference choice-consistency. Still, practically, this could have introduced additional noise into the decision behavior of participants.
While the current registered report cannot entirely address this aspect of insufficiently defined preferences, future research should provide both theoretical and empirical accounts on the role of non-decisions for choice-consistency.


Pilot Experiment
We conducted a pilot experiment to validate the effectiveness of our retention interval manipulation. Specifically, we wanted to demonstrate that our retention interval manipulation is sufficient to blur the memory representation of the exemplar. Furthermore, we explored the influence of presentation time of the exemplar on the memory representation strength.


Methods
Procedure. The first three screens of each trial were equivalent to the procedure of the experiment for the here described registered report (see 
figure 2)
. Each trial started with the presentation of a fixation cross. Participants were then presented with an exemplar cube with a certain orientation along the X-and Y-axis (see procedure of registered report) for either 1, 5, 10 or 30 seconds. Then, participants were presented with a mask of 10 randomly oriented cubes (see 
figure 2
) for a certain retention interval. Importantly, the retention interval in the pilot experiment was not fixed per participant. The retention interval lasted either 1, 5, 10 or 30 seconds. After the retention interval, participants were again presented with a single cube similar to the exemplar. The cube randomly matched the exemplar either regarding the X-or the Y-orientation, while the initial complementary orientation was chosen uniform randomly. Participants then had to turn the cube on the screen to match the exemplar regarding the complementary orientation using the arrow keys. Importantly, it was unknown to the participants whether they had to reconstruct the X-or Yorientation both during the presentation time and the retention interval. Participants solved 10 for each factorial combination of the presentation times and retention intervals in random order.
Sample characteristics and exclusion criteria. We included a total of 25 participants (21 women, 4 men; age: = 24, = 18 − 39) for our pilot experiment. The sample size was not determined a priori. Instead we used a Bayesian stopping rule, recruiting further participants until we reached a Bayes factor of at least ≥ 10 for our hypothesis test. Importantly, the sample size is smaller than the minimal sample size we plan to recruit for the here described registered report.
Participants were recruited from the same population we target for the here described registered report.
However, the study was conducted as an online experiment due to the ongoing COVID-19 crisis. It is intuitive, that participants might be less attentive during online-experiments than during lab-based experiments due to the uncontrolled in which participants solve the task. Therefore, we assessed reaction times besides task performance and excluded single trials with reaction times deviating more than 3 standard deviations from the grand mean. Note, that this threshold amounted to about 30 seconds for a single trial. Hence, we are confident to not have excluded any meaningful data while considerably reducing measurement noise.
The study was approved by the local ethics board of Heinrich-Heine-University and was conducted in accordance with the declaration of Helsinki. Participants were reimbursed by course credit.
Statistical analysis. We operationalized the memory representation strength of the exemplar as the absolute error with which its orientation could be reconstructed by the participants.
We considered an orientation of 0 degrees and 360 degrees as equivalent. For example, if the orientation of the exemplar cube on the axis of interest is 90 degrees and the orientation of the reconstructed cube on that axis is 360, the absolute error is 90 and not 270. The absolute error can therefore range between 0 degrees and 180 degrees. The exact formula is given by
= † ‡ ‰Šv:‹Sy, − OEv•+Jw`,Ž•`v• ‡ − 180 †.
We calculated a repeated measures Bayesian ANOVA in the 'BayesFactor' R package using the non-informative default priors 
(Rouder et al., 2012)
. We considered a Bayes factor equal or larger than 10 regarding the main effect of the retention interval to be conclusive for or against our hypothesis. To verify the direction of the effect we considered the trend of the means of each factor level. Further, we exploratively inspected the evidence for or against a main effect of the presentation time and a possible interaction effect of both factors.


Results
We found that an ANOVA-style model including both main effects and a random subject intercept but no interaction term to be the most likely model given the data. Specifically, this model was H7 = 895082 (±0.94%) times more likely than the null model (including only the random subject intercept) given the data (see 
figure 8)
.
Retention interval. To quantify the evidence for an effect of the retention interval factor we compared the evidence of the most likely model with the evidence for a model including only the main effect of the presentation time and the random subject intercept. We found that there was H7 = 1000 ± 1.13% times more evidence for the inclusion of the retention interval factor. We interpret this as definitive evidence. Inspection of the trend of means reveals that there is a positive relationship of retention interval and absolute error of reconstruction (see 
figure 8)
.
Presentation time. To quantify the evidence for an effect of the presentation time factor we compared the evidence for the most likely model with the evidence for a model including only the main effect of the retention interval and the random subject intercept. We found that there was H7 = 1005 ± (1.15%) times more evidence for the inclusion of the presentation time factor. We interpret this as definitive evidence. Inspection of the trend of means reveals that there is a negative relationship of presentation time and absolute error of reconstruction (see 
figure 8)
. Note, however, that is was an explorative analysis.
Interaction Retention interval x presentation time. To quantify the evidence against an interaction effect of both factors we compared the evidence of the most likely model with the evidence for a model including both main effects, the random subject intercept and an interaction term. We found that there was 7H = 44446 (±2.11%) times more evidence for the exclusion of the interaction term. We interpret this as definitive evidence. Note, however, that is was an explorative analysis.


Discussion
We conducted a pilot experiment to validate the effectiveness of our retention interval manipulation. We showed that the precision of the orientation reconstruction of an exemplar from memory decreases with retention time over an interval of 30 seconds. Therefore, we are confident that the planned retention interval manipulation of the here described registered report is effective to weaken the memory representation strength of an exemplar. Further, we explored the influence of different presentation times on orientation reconstruction precision. We found that precision increases with presentation time. In the context of our registered report, it is important that the memory representation strength freely varies among different retention intervals for a given presentation time. Descriptively, the variance of the absolute error in reconstruction is highest for a presentation time of 1 second. However, also the mean absolute error is highest for a presentation time of 1 second. A presentation time of 5 seconds represents a compromise with the second highest variance and second highest mean of the absolute error in reconstruction.


Results


Sample Characteristics
For our main experiment, we included 77 participants (56 women, 21 men; age: = 22, = 18 − 40, education: 72 completed high school, 5 completed a university degree)
according to our inclusion criteria until reaching the preregistered stopping rule of our analysis plan.


Preregistered analyses
As outlined above, our statistical analyses use a Bayesian framework of inference, specifically the Bayes Factor approach to model comparison. Bayes factors express the relative degree of evidence for one model over another, that is the ratio of probabilities of observing the data under each model 
(Makowski et al., 2019)
.


Reality check: Effect of retention interval on memory representation
To quantify the evidence for an effect of the retention interval factor on memory representation strength, we compared a one-way ANOVA style model including the 4-step retention interval factor to a null model. We found conclusive evidence for the retention interval model for the new and the full dataset (including our pilot data), as well as for the successful replication ( H7 ( Jv" ) = 32.894 ± 0.01%, H7 ( "ŽSS ) = 46717770 ± 0.01%, OEv‹S'•y`'+J = 44623.3; see figure 9). Hence, we can conclude that our retention interval manipulation was effective.


H1: Test for an inverse relationship of retention interval and choice-consistency
Next, we tested in the training set whether choice-consistency as operationalized by the CCEI decreased with an increasing retention interval. Results showed conclusive evidence against our hypothesis ( H7 = 0.047; see 
figure 10
). The result held for other specifications of choiceconsistency, namely the Houtman-Maks-Index, and approximations of the Money Pump Index and Minimum Cost Index (all H7 < 0.1).


H2 & H3: Bayes Factor model comparison of exponential and null model
Following our interpretation plan (see table 1), we did not proceed to test H2 and H3, given our negative result for H1.


Floor and ceiling effects
As apparent in figure 10, the CCEI of our participants in the training data was overall surprisingly low ( = 0.299, = 0.229). In order to control for a potential floor effect, we used a Bayesian Mann-Whitney-U test to control whether our participants were more consistent than an equal-sized subsample of our random simulated data (see 
figure 11, panel A)
. Results showed strong evidence against this, indicating a potential floor effect in our data ( H7 = 0.094).


Exploratory analysis


Reliability Analysis
In an attempt to further understand the quality of our data beyond our preregistered quality controls, we conducted a descriptive test-retest reliability analysis of the CCEI for the training and test set. As we reported recently elsewhere 
(Nitsch et al., 2021)
, there are concerns regarding the measurement reliability of the CCEI, which is especially problematic for correlational designs such as the one of the current study 
(Hedge et al., 2018)
. Specifically, tasks designed to show robust between-group effects and, thus, low between-subject variability in the outcome measure are at risk for showing low test-retest reliability. Another risk factor specific to the CCEI is that the measure is dependent only on the magnitude of the most severe violation (see Preprocessing) and, thus, vulnerable to outliers. Our results indicated essentially no reliability of the CCEI between training and test set in the current study ( = −0.033). This was not driven by the difference in retention intervals of both measurements, or by low between-subject variability of the measure (see figure 11, panel A and B). A similar result showed for the money pump index ( = 0.023). However, interestingly, the Houtman-Maks-Index and the Minimum-Cost-Index showed a much higher (albeit still poor) test-rest reliability (HMI: = 0.303, MCI: = 0.353; see 
figure 11
, panels C-E), which might be attributed to less vulnerability to outliers.


Task difficulty
Given the results reported above and oral feedback from our participants, we formed the post-hoc hypothesis that the generally low choice-consistency might be driven by a too high difficulty of discriminating the different X-and Y-orientations of the choice objects. To further explore this notion, we compared the mean absolute error in the reconstruction task, as an upper limit to the discriminatory performance, to the mean increment difference of orientation along the X-or Y-axis in the choice set, using bootstrapping. Results showed, that the mean increment difference was generally lower than mean reconstruction error, tentatively suggesting a high difficulty of discriminating between the choice objects (see 
figure 12
).


Discussion
In this registered report, we set out to experimentally test the influence of memory retrieval of exemplars on choice-consistency in a novel visual choice paradigm. After a short retention interval, participants had to select one out of a choice set of five three-dimensional cubes that has the subjectively most similar orientation along the X-and Y-axis to the exemplar. The choice set stimuli represented a variable trade-off of similarity to the exemplar regarding the two attributes Xand Y-orientation. We manipulated memory retrieval by varying the duration of the retention interval between exemplar presentation and choice.
Using a reconstruction task as a manipulation check of our retention interval intervention, we could show and replicate the pattern of decreasing memory accuracy with increasing retention time in a pilot experiment and in our preregistered study, which confirmed the effectiveness and reliability of our manipulation.
Given this, we found strong evidence against our first hypothesis that choice-consistency, as operationalized by the CCEI, decreases with increasing retention time. Further, this result held for robustness checks using three similar choice-consistency indices. Given our preregistered interpretation plan we did not proceed to test our more specific, model-based hypotheses.


Limitations
However, our preregistered quality controls revealed an overall surprisingly low choiceconsistency of our participants even for short retention intervals that proved to be non-discernable from that of simulated random behavior. In addition, an exploratory analysis showed essentially no test-retest reliability of the critical cost efficiency index between the training and the test set. This was not driven by retention time differences between the two measurements. Taken together, this
suggests the presence of a floor effect in our data and, thus, low data quality for conclusively evaluating our hypotheses.
Generally, the lack and low reliability of choice-consistency indicates that our participants did not consistently integrate deviations in the X-and Y-dimensions of the choice set stimuli to the exemplar, meaning there was no well-behaved integration function, and, this was also the case for short retention times. As the performance in the reconstruction task was generally good (perfect reconstruction in about 42% of trials), it is unlikely that the low consistency level was driven by too long retention intervals.
Another explanation for the overall low choice-consistency could be that the discrimination between the different X-and Y-orientations of the choice objects was too difficult. This was also, anecdotally, suggested in oral feedback of our participants during the data collection. To further explore this notion, we compared the mean absolute error in the reconstruction task, as an upper limit to the discriminatory performance, to the mean increment difference of orientation along the X-or Y-axis in the choice set, recovered from the task parameters, using bootstrapping. Results showed that the mean increment difference was generally lower than mean reconstruction error, tentatively suggesting a high difficulty of discriminating between the choice objects. As all choiceconsistency indices quantify performance only relative to the increment orientation differences of choice objects, numerically low choice-consistency levels can correspond to only small inconsistencies in degree orientation.


Future Research
Future studies investigating visual choice-consistency should, therefore, establish a sufficient level of choice-consistency at baseline. This could be achieved, for example, by pilot testing to adjust, in a group-wise fashion, the increment difference of orientation along the X-or Y-axis in the choice, or on an individual-level by using an adaptive staircase procedure.
Another important consideration for the design of future studies is the low reliability of choice-consistency in the present study, but also, generally, in other task domains 
(Nitsch et al., 2021)
. While our correlational design had important benefits for covering a sufficient retention time span and providing rich data for parametric model fitting, factorial designs are more robust to finding effects in low reliability behavioral tasks 
(Hedge et al., 2018)
.


Conclusion
In this registered report, we set out to experimentally test the influence of memory retrieval of exemplars on choice-consistency in a novel visual choice paradigm. Due to unforeseen methodological pitfalls, our data is inconclusive to the preregistered hypotheses. However, our preregistered quality controls and additional exploratory analyses offer important insights for the design of future studies.


Figure 1
Mapping of concepts from GCM Model of Categorization to Query Theory Note. Simplified graphical representation of the decision process in Query Theory 
(Weber et al., 2007)
 and the Generalized Context Model of categorization 
(Nosofsky, 2011)
.  After the retention interval, the choice set of 5 cubes with different orientations were presented.
Each element of the choice set was presented equidistantly around the exemplar. The order of the choice set elements was randomized. Participants had to make a forced a choice on which among the choice set stimuli is most similar in its orientation to the exemplar. x X-ori
x Y-ori


Figure 4
Graphical exponential model of the relationship of retention interval and choice-consistency.
Note. ∈ denotes a single data point corresponding to a test block of a particular participant.
J denotes the retention interval of a given observation. J denotes the expected choiceconsistency of a given observation. J denotes the observed choice-consistency of a given observation. The parameter determines an asymptotical minimum level of choice-consistency after an infinite retention interval. The parameter determines choice-consistency at = 0, which allows for imperfect choice-consistency unconditional on time-dependent processes when < 1. The parameter determines the constant decreasing rate of consistency. We assumed that all parameter values are equally likely a priori. Nodes with dark background represent observed variables, nodes with white background represent latent variables. Nodes with single line borders represent stochastic variables, nodes with double line borders represent deterministic variables.
t n n=1 ,... , N a∼Beta(1,1) b∼Beta(1,1) α ∼Beta(1,1) μ n ← a+(1−a) x e −α x t n σ ∼Beta (1,1) t n ∼Uniform (0,30) CCEI n ∼Gaussian (0,1) (μ n , σ n ) μ n σ CCEI n a b α


Figure 5
Scatterplot of retention interval and choice-consistency with histograms of marginal distributions.
Note. Data was simulated for 300 virtual participants using the exponential model with parameters = 0.4, = 0.9, = 0.3, = 0.1. The marginal distribution of the retention interval is, trivially, uniform. Importantly, the marginal distribution of choice-consistency is a right-tailed Gaussian, meaning a tail for large consistency values. does not predict the trend of the data for small retention intervals. Relatively to the training set performance of each model, the exponential model also generalizes slightly better to the test set.  Histograms of choice-consistency of simulated random behavior Note. We simulated a dataset of 1.000 virtual participants that made uniform random choices from 20 choice sets constructed as specified for our experiment (see Procedure). The upper panel shows the distribution of the number of inconsistent choices. 99% of the virtual participants committed at least one inconsistent choice. The median number if inconsistent choices (16) is indicated by the dashed vertical line. The lower panel shows the distribution of the CCEI. 99% of the virtual participants had a CCEI lower than 0.90. 97% of participants had a CCEI lower than 0.80. The median CCEI (0.37) is indicated by the dashed vertical line. Overall, our experimental task provides sufficient sensitivity to detect inconsistent choices. Note, that of all 1.000 virtual participants only a single one had a CCEI of 1. Importantly, this participant also did not violate the revealed preference axioms (0 inconsistent choices). We are, therefore, confident that our design also minimizes cost-efficient inconsistent choices which would undermine the sensitivity of the CCEI measure specifically 
(Murphy & Banerjee, 2015)
. Retention Interval (in seconds) Absolute Error (in degree)
• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • •


Figure 9
Manipulation check of the retention interval manipulation.
Note. Panel A shows the point range (mean and standard error of the mean) of the absolute reconstruction error for each retention interval level in the full data set (pilot and preregistered experiment, disregarding encoding time for the former). The absolute error in the reconstruction of the exemplar cube orientation is positively related to the retention interval (indicated by the evidence for the pilot data, the new data and the replication). Note, that the retention interval is not presented in scale. Panel B shows the histogram of the absolute reconstruction error for each retention interval level in the full data set (pilot and preregistered experiment, disregarding encoding time for the former). Vertical bars indicate the mean of the data, colored tiles indicate the standard error of the mean. It is eminent that the absolute error distribution has a strong positive skew.


Figure 10
Scatterplot of the empirical retention interval and choice-consistency with histograms of marginal distributions.
Note. Trivially, the marginal distribution of the retention interval was uniform. Further, as expected, the marginal distribution of choice-consistency was a right-tailed Gaussian, meaning a tail for large consistency values. However, contrary to our hypothesis, the bivariate distribution plot revealed no negative relationship of CCEI and retention time.


Figure 11
Empirical choice-consistency and reliablity Note. Panel A shows the empirical distribution of the CCEI compared to an equally-sized subset of simulated random behavior. Choice-consistency, overall, was surprisingly low and not higher than for simulated random behavior. Panel B shows the test-retest reliability of the CCEI for training and test data, which was almost zero. Importantly, this was not driven by the absolute difference in retention time between both measurements. The lower panels (C, D, E) show similar patterns for three other consistency indices.


Figure 12
Exploration of task difficulty Note. Panel A shows the bootstrapped distribution of the mean differences between the empirical absolute reconstruction error and choice task increment difference in the choice set (retrieved from task parameters). Depicted is the histogram of the bootstrap samples distribution (N = 10000). The continuous vertical line indicates the mean of the statistic of interest, the two dashed vertical lines indicate the 95% confidence interval. Results showed, that the mean increment difference was generally lower than mean reconstruction error, indicating a high difficulty of discriminating between the choice objects. 


English translation of instructions for MAVC Task
Dear participant,
In the following task you will be presented with a number of independent decision problems, that share a common format. Each decision problem starts with the presentation of colorful 3D cube. The cube will be presented for 5 seconds. Each side of the cube is identified by a unique color. Your task is to memorize the orientation of the cube as good as possible. After the presentation time of 5 seconds has passed, you will be presented with a visual mask of 10 similar cubes for up to 30 seconds. These cubes are irrelevant for the decision problem and you should not try to memorize their orientation. Finally, you will be present with 5 more cubes in different orientations which will be presented to you in circle. Your task is to select the one of those 5 cubes which has the most similar orientation to the cube which you have been presented with at the beginning of the decision problem. Before each decision problem you will be shortly presented with a fixation cross.
ITI: 0.5-1.5s
PT: 5.0s RI: 0.0-30.0s
Choice MEMORY AND CHOICE CONSISTENCY


51
Carefully evaluate all 5 cubes and try to mentally rotate them until they match the memorized cube. Then select the cube which had to be mentally rotated the least. You have to decide for each decision problem. If you are unsure about your answer, follow your intuition. There are no wrong or correct answers. Before the task begins, please take a moment to familiarize with the colorful cube by inspecting the following animation. All cubes presented in the task will be exact copies of that cube but in different orientations.


[ANIMATION HERE]
Thank you for familiarizing with the colorful cube. You will now be presented with 10 practice decision problems. For these practice problems, the choice options will be presented 1 second after the cube that you have to memorize. Your answers for these practice decisions will not be recorded.
Take your time to familiarize with the task.
You have successfully completed the practice decision problems. Do you have any questions or is there anything unclear about the task at hand? Then please raise your hand and consult with the experimenter.
If you have no further questions, then you can proceed now with the first test block. The test block consists of 20 decision problems. For all 20 decisions you will be assigned a retention interval of up to 30 seconds after the presentation of the initial cube during which you will see the irrelevant visual mask.
MEMORY AND CHOICE CONSISTENCY


52
You have successfully completed the first test block. Take a moment to stretch your legs before continuing.
The next test block again consists of 20 decision problems. For all 20 decisions you will be assigned a different retention interval of up to 30 seconds after the presentation of the initial cube during which you will see the irrelevant visual mask.
Figure 4
4
displays a graphical representation of the model including prior specifications for all parameters. Null Model. The second candidate model assumes that choice-consistency does not decrease as a function of the retention interval. The expected value of the choice-consistency distribution is, therefore, a constant. `=


Nodes with dark background represent observed variables, nodes with white background represent latent variables. Nodes with single line borders represent stochastic variables, nodes with double line borders represent deterministic variables.


From top left to bottom right: 1. The inter-trial interval (ITI) lasted 0.5 to 1.5 seconds. A fixation cross was presented in the middle of the screen. 2. During the presentation time (PT) an exemplar cube was presented for 5 seconds in the middle of the screen. 3. During the retention interval (RI) a mask of cubes in random orientations were presented. The retention interval was randomly selected from an interval 0 to 30 seconds and was fixed per participant per block. 4.


Construction of choice set of multi-attribute visual decision task from budget and pricesNote. Choice sets for four different exemplars and sets of prices. Exemplars are shown for each example in the square in the upper right corner of each panel. From top left to bottom right: H = (1,1), I = (3,10),˜= (10,3), ™ = (3,3). The size of the budget (set to = 100) relative to the prices determines how similar the choice set stimuli are oriented to the exemplar overall.Hence, the choice set stimuli in the top left panel are overall more similarly oriented to their respective exemplar than the choice set stimuli in the bottom right panel. The price ratio of the attributes determines the trade-off ratio of the X-and Y-orientation. Hence, the choice set stimuli in the top right panel are generally more similarly oriented to their respective exemplar along the Y-axis and less similarly oriented along the X-axis compared to the bottom left panel and vice versa. Axiomatic choice theory proposes that subjective similarity increases as a function of how far a choice object is located to the top right (indicated by the dashed line).


Figure 6
6
Scatterplots of retention interval and choice-consistency overlaid with posterior predictionsNote. The black line shows the median predictions, the grey lines show the 95% highest densityintervals. Upper row shows the training set, bottom row shows the test set. Left column shows posterior predictions of the exponential model, right column shows posterior predictions of the null model. Training and test set were simulated for 300 virtual participants using the exponential model with parameters = 0.4, = 0.9, = 0.3, = 0.1. While the exponential model predicts the pattern of the data with relatively little uncertainty, the null model makes very vague predictions with possible values covering almost half of the variable space. Further, the null model


Figure 7
7
Figure 7


The figure shows the point range (mean and standard error of the mean) for each cell of the two-factorial design. The absolute error in the reconstruction of the exemplar cube orientation is positively related to the retention interval and negatively related to the presentation time. There is definitive evidence against an interaction of both factors. Note, that the retention interval is not presented in scale.


Definition 1 (Direct Revealed Visual Preference). A visual object ' is directly revealed preferred to another visual object L if and only if L ' ≤ ' and ' ≠ L . Then we denote ' Q L .
dimension (see figure
Definition 2 (Revealed Visual Preference). A visual object ' is revealed preferred to another
visual object L if there exists a transitive preference relation ' Q R , R Q S … : Q J , J Q L
between both bundles. We denote ' L . is the transitive closure of Q .
Definition 3 (Strict Direct Revealed Visual Preference). A visual object ' is strictly directly
revealed preferred to another visual object L if and only if L ' < ' . Then we denote ' Q L .
Axiom 1 (Generalized Axiom of Revealed Visual Preference). ' L → ¬8 L Q ' 9 ∀ , ∈ .
Axiom 1 allows us to directly test multi-attribute perceptual choices for consistency. It is a
necessary and sufficient condition for the choices to be rationalized by a monotonous concave
attribute integration function and, thus, adherence to the Generalized Context Model (GCM) of
categorization. If the choice data pass Axiom 1, this means that choices are made as if integrated
subjective similarity to the exemplar is a function of objective similarity along each attribute


Table 1
1
Summary of statistical interpretation criteria for each hypothesis
Hypothesis
≥ 10
≤ 0.1
0.1 <
< 10
Strong support
Strong support
H1: Inverse relationship of retention
Inconclusive,
for inverse
against inverse
interval and choice-consistency
larger N required
relationship
relationship
H2: Exponential model is supported
Strong support
Strong support
Inconclusive,
more strongly by the data than null
for exponential
model
model
for null model
larger N required
Strong support
Strong support
H3: The finding of H2 replicates to a
against a
Inconclusive,
for replication to
new data set
replication to a
larger N required
a new dataset
new dataset


We chose this particular presentation time based on a pilot study (see section Pilot Experiment).2 RGB coordinates for each side of the cube. Front: (230, 159, 0). Back:(86, 180, 233). Bottom:(0, 158,   115).Top: (240, 228, 66).Right: (213, 94, 0). Left: (0, 114, 178).


For an impression visit: https://fjnitsch.github.io/files/html/Rotating_Cube.html








Acknowledgements
We thank Alina Keßler, Paul Kramer and Marie Ludes for their support on the pilot data collection. We thank Quentin Gronau and three anonymous reviewers for their helpful criticism MEMORY AND CHOICE CONSISTENCY 30 which led to a greatly improved version of stage 1 manuscript. Further, we thank Ana Hernandez for her support on the data collection of the main experiment.






Ethical statement
All participants gave informed written consent. The study was approved by the local institutional review board of Heinrich-Heine-University and was conducted in accordance with the declaration of Helsinki. Participants were reimbursed by course credit.


Funding statement
The research was supported by a grant from the Deutsche Forschungsgemeinschaft (Bonn, Germany) to Tobias Kalenscher (grant-ID: DFG-KA 2675/4-3).


Data Availability
Raw and processed data, the approved stage 1 manuscript, as well as analysis code for the stage 1 and stage 2 manuscript results and figures are available online: https://osf.io/2vx36/.


Competing Interests Appendix
 










Efficiency Estimation of Production Functions




S
N
Afriat










International Economic Review




13


3






JSTOR












On a system of inequalities in demand analysis: An extension of the classical method




S
N
Afriat










International Economic Review


















The form of the forgetting curve and the fate of memories




L
Averell






A
Heathcote










Journal of Mathematical Psychology




55


1
















We Have Not Looked at Our Results Until We Have Displayed Them Effectively: A Comment on Robust Modeling in Cognitive Science




L
M
Blaha










Computational Brain & Behavior




2


3-4
















Multiattribute Preference Analysis with Performance Targets




R
F
Bordley






C
W
Kirkwood










Operations Research




52


6
















The power of nonparametric tests of preference maximization




S
G
Bronars










Econometrica: Journal of the Econometric Society


















Consistency and heterogeneity of individual behavior under uncertainty




S
Choi






R
Fisman






D
Gale






S
Kariv








American Economic Review




97


5
















Who Is (More) Rational?




S
Choi






S
Kariv






W
Müller






D
Silverman










American Economic Review




104


6


















J
R
De Leeuw






B
A
Motz




Psychophysics in a Web browser? Comparing response times collected with JavaScript and Psychophysics Toolbox in a visual search task. Behavior
















Myopia and discounting




X
Gabaix






D
Laibson












National bureau of economic research












Bounded rationality: The adaptive toolbox




G
Gigerenzer






R
Selten




10.7551/mitpress/1654.001.0001








MIT press












An event-related fMRI study of the neurobehavioral impact of sleep deprivation on performance of a delayed-match-to-sample task




C
Habeck






B
C
Rakitin






J
Moeller






N
Scarmeas






E
Zarahn






T
Brown






Y
Stern










Cognitive Brain Research




18


3
















Changing Tastes and Coherent Dynamic Choice. The Review of Economic Studies




P
J
Hammond










JSTOR


43














The reliability paradox: Why robust cognitive tasks do not produce reliable individual differences




C
Hedge






G
Powell






P
Sumner








Behavior Research Methods




50


3
















Sex Differences in Mental Rotation with Polygons of Different Complexity: Do Men Utilize Holistic Processes whereas Women Prefer Piecemeal Ones?




M
Heil






P
Jansen-Osmann










Quarterly Journal of Experimental Psychology




61


5
















Consistent subsets: Computationally feasible methods to compute the Houtman-Maks-index




J
Heufer






P
Hjertstrand








Economics Letters




128
















Revealed preference and the utility function




H
S
Houthakker










Economica




17


66
















The theory of probability




H
Jeffreys








OUP


Oxford












Aspects of endowment: A query theory of value construction




E
J
Johnson






G
Häubl






A
Keinan










Journal of Experimental Psychology: Learning, Memory, and Cognition




33


3
















MCMC representativeness




J
Kruschke








Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan




Academic Press
















The influence of episodic memory decline on value-based choice




F
Levin






S
Fiedler






B
Weber










Neuropsychology, and Cognition




26


4










Aging








A tutorial on Bayes factor estimation with the product space method




T
Lodewyckx






W
Kim






M
D
Lee






F
Tuerlinckx






P
Kuppens






E.-J
Wagenmakers










Journal of Mathematical Psychology




55


5
















Replication Bayes factors from evidence updating




A
Ly






A
Etz






M
Marsman






E.-J
Wagenmakers










Behavior Research Methods




51


6
















Indices of effect existence and significance in the Bayesian framework




D
Makowski






M
S
Ben-Shachar






S
Chen






D
Lüdecke










Frontiers in Psychology




10














BayesFactor: Computation of bayes factors for common designs




R
D
Morey






J
N
Rouder




















A caveat for the application of the critical cost efficiency index in induced budget experiments




J
H
Murphy






S
Banerjee








Experimental Economics




18


3
















Keeping a cool head at all times. What determines choice consistency?




F
J
Nitsch






T
Kalenscher












Preprint












Psyarxiv




10.31234/osf.io/etyhx














Inconsistently consistent: Rationality is not reliable




F
J
Nitsch






L
M
Lüpken






N
Lüschow






T
Kalenscher




10.31234/osf.io/gd9zs












Preprint








Attention, Similarity, and the Identification-Categorization Relationship




R
M
Nosofsky










Journal of Experimental Psychology: General




115


1
















The generalized context model: An exemplar model of classification




R
M
Nosofsky




E. M.
















10.1017/CBO9780511921322.002




Formal Approaches in Categorization


Pothos & A. J. Wills




Cambridge University Press














patchwork: The Composer of Plots




T
L
Pedersen














R package version 1.0.0) [Computer software








JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling




M
Plummer








124


10












Extending the Bounds of Rationality: Evidence and Theories of Preferential Choice




J
Rieskamp






J
R
Busemeyer






B
A
Mellers








Journal of Economic Literature




44


3
















Default Bayes factors for ANOVA designs




J
N
Rouder






R
D
Morey






P
L
Speckman






J
M
Province








Journal of Mathematical Psychology




56


5




















Rstudio
Team












Integrated Development for R (1.2.1335) [Computer software












Rstudio
















A note on the pure theory of consumer's behaviour




P
A
Samuelson










Economica




5


17
















Mental rotation of three-dimensional objects




R
N
Shepard






J
Metzler










Science




171


3972
















The Impact of Age-Related Changes on Working Memory Functional Activity




J
Steffener






A
M
Brickman






B
C
Rakitin






Y
Gazes






Y
Stern










Brain Imaging and Behavior




3


2
















Age-Related Changes in Task Related Functional Network Connectivity




J
Steffener






C
G
Habeck






Y
Stern










PLoS ONE




7


9














Bayesian Inference for Kendall's Rank Correlation Coefficient




J
Van Doorn






A
Ly






M
Marsman






E.-J
Wagenmakers








The American Statistician




72


4
















The nonparametric approach to demand analysis




H
R
Varian










Econometrica: Journal of the Econometric Society


















Goodness-of-fit for revealed preference tests




H
R
Varian












Department of Economics, University of Michigan Ann Arbor












Intermediate Microeconomics: A Modern Approach: Ninth International Student Edition




H
R
Varian








WW Norton & Company












Revealed preference. Samuelsonian Economics and the Twenty-First Century




H
R
Varian






















Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications




E.-J
Wagenmakers






M
Marsman






T
Jamil






A
Ly






J
Verhagen






J
Love






R
Selker






Q
F
Gronau






M
Šmíra






S
Epskamp






D
Matzke






J
N
Rouder






R
D
Morey










Psychonomic Bulletin & Review




25


1
















Multiple Criteria Decision Making, Multiattribute Utility Theory: Recent Accomplishments and What Lies Ahead




J
Wallenius






J
S
Dyer






P
C
Fishburn






R
E
Steuer






S
Zionts






K
Deb










Management Science




54


7




















E
U
Weber






E
J
Johnson






K
F
Milch






H
Chang






J
C
Brodscholl






D
G
Goldstein


















Asymmetric discounting in intertemporal choice: A query-theory account








Psychological Science




18


6














Welcome to the Tidyverse




H
Wickham






M
Averick






J
Bryan






W
Chang






L
Mcgowan






R
François






G
Grolemund






A
Hayes






L
Henry






J
Hester






M
Kuhn






T
Pedersen






E
Miller






S
Bache






K
Müller






J
Ooms






D
Robinson






D
Seidel






V
Spinu






H
Yutani










Journal of Open Source Software




4


43


1686














Preference by Association: How Memory Mechanisms in the Hippocampus Bias Decisions




G
E
Wimmer






D
Shohamy










Science




338


6104
















Points of view: Color blindness




B
Wong










Nature Methods




8


6
















Positive Evidence against Human Hippocampal Involvement in Working Memory Maintenance of Familiar Stimuli




E
Zarahn










Cerebral Cortex




15


3
















Distinct spatial patterns of brain activity associated with memory storage and search




E
Zarahn






B
C
Rakitin






J
Flynn






Y
Stern








NeuroImage




33


2
















Age-related changes in brain activation during a delayed item recognition task




E
Zarahn






B
C
Rakitin






J
Flynn






Y
Stern








Neurobiology of Aging




28


5

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]