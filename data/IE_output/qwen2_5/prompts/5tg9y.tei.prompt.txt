You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
We use data visualizations-visual representations of data-as a vital source of information during hazard events with uncertainty. For example, when making hurricane evacuation decisions, numerous studies find that Americans depend on television news broadcasts (e.g., 
Driscoll, Salwen, & disasters, 1996;
Lindell, Lu, & Prater, 2005;
Lindell & Perry, 2004)
, which predominantly use visualizations of hurricane data to communicate the risk associated with a storm. Unfortunately, understanding even simple visualizations of uncertainty is challenging for both trained experts and the general public 
(Belia, Fidler, Williams, & Cumming, 2005)
. Given the widespread use of uncertainty visualizations during hazard events, it is vital we understand how they influence our judgments of risk and ultimately our preparatory actions.
Visualization researchers have made significant advancements in developing visualizations that elicit fast and effective judgments. However, despite using best practices, visualizations may still produce unintended judgments (e.g., 
Belia et al., 2005;
Joslyn & LeClerc, 2013;
Padilla, Ruginski, & Creem-Regehr, 2017;
Ruginski et al., 2016)
. For example, when viewing bar charts, people report that points within the bar are more likely to be a member of the distribution than points that are equidistant from the mean but outside the bar 
(Newman & Scholl, 2012)
. One possible cause of unintended visualization interpretations is the influence of the composition of marks (i.e., geometric primitives, such as dots and lines) in relation to visual encoding channels (i.e., the controls of the primitive's appearance, such as color and position; 
Munzner, 2014)
. For example, blurring the marks in a visualization may evoke a feeling of out of focus, which researchers propose intuitively communicates uncertainty in the data 
(Jiang, Ormeling, & Kainz, 1995)
. Although many compositions of marks and encoding channels provide viewers with additional beneficial information, issues may arise when the possible unintended interpretations and subsequent decision-making have not been evaluated.
To examine cases in which seemingly useful visual compositions can distort interpretations, the current study draws on ensemble display visualizations of hurricane track forecasts, shown to be an effective technique when compared to more traditional summary displays 
(Liu, Padilla, Creem-Regehr, & House, 2018;
Ruginski et al., 2016)
, but also susceptible to biases 
(Padilla et al., 2017
) (see 
Figure 1)
. In prior work, we compared hurricane path uncertainty visualizations, which revealed that people misinterpret summary displays of hurricane track forecasts ( 
Figure 1A
, D, and E). We found that people believe that the summary displays show the hurricane increasing in damage over time 
(Ruginski et al., 2016)
. In subsequent research, when participants were asked to explicitly judge the size and intensity of a predicted hurricane, responses were consistent with the previous damage ratings, suggesting that damage ratings incorporate perceptions of both size and intensity of the storm. Participants showed a greater increase in size and intensity ratings with time when viewing the cone display ( 
Figure 1A)
 compared to ensemble display ( 
Figure 1C
) 
(Padilla et al., 2017)
. Additionally, with the ensemble display we found that damage ratings and intensity ratings closely align with the uncertainty in the storm path 
(Padilla et al., 2017;
Ruginski et al., 2016)
. The results of these studies suggest that the ensemble display reduces misinterpretations about the storm path and is a promising alternative to the summarization visualization techniques that are currently used by the National Hurricane Center, which are similar to 
Figure 1A
. 
Figure 1
. Example of the five hurricane track visualizations compared in 
Ruginski et al. (2016)
. Reprinted with permission.
Before recommending adoption of the ensemble hurricane track visualization, we sought to examine whether the seemingly useful composition of marks and encodings tested in 
Ruginski et al. (2016)
 produced any unintended interpretations. Motivated by television forecasts from numerous hurricanes in 2017, we wanted to understand how people reason with ensemble forecasts when one of the ensemble members or paths directly intersects their town. 
Padilla et al. (2017)
 tasked participants with comparing potential damage to two oil platforms-one platform was always collocated with a forecasted hurricane path and the other was not (see 
Figure 2
). This study examined whether viewers believed that oil platforms closer to the center of the distribution of paths (i.e., the area with the most densely populated grouping of lines) would receive more damage, as reported in 
Ruginski et al. (2016)
, or if participants believed there would be greater risk associated with locations that were collocated with an ensemble member. Naïve viewers increased the proportion of trials in which they reported that the location farther from the center of the distribution of paths would receive more damage only when an ensemble member was collocated with the farther location ( 
Figure 2A
). In other words, people overemphasized the importance of a hurricane track when it overlaps an oil rig. We call this the collocation effect. In fact, in the ensemble hurricane forecasts presented, the lines are a subset of runs of the model, with perturbations to speed and bearing based on 5-year historical hurricane data 
(Liu et al., 2016;
Liu et al., 2018;
Padilla et al., 2017;
Ruginski et al., 2016)
. As the lines are a randomly sampled subset of the model runs, each line is not a deterministic path, just one of many possible predicted paths. 
Figure 2
. Hurricane forecast display stimuli used in 
Padilla et al. (2017)
, where the red dots indicate the location of offshore oil platforms. In 
Figure 2A
, location A is collocated. In 
Figure 2B
, location B is collocated.
Given the advantages of the ensemble hurricane visualizations over the current summary display method used by the National Hurricane Center and other proposed visualization techniques 
(Padilla et al., 2017;
Ruginski et al., 2016)
, we sought to understand and reduce the collocation effect to ensure that ensemble displays are as effective to use as possible. Utilizing the cognitive framework for visualization decisionmaking proposed by 
Padilla et al. (2018)
, we identified two key ways to reduce the collocation effect. The 
Padilla et al. (2018)
 framework suggests that both bottom-up and top-down processing can influence decisions with visualizations. Utilizing bottom-up processing we sought to change the visual properties of the ensemble hurricane forecast, which would have downstream effects on all the subsequent decision-making processes.
Drawing on top-down processes, our second approach encouraged viewers to use knowledge-driven processing via instructions to override the collocation effect.


Modifying the Properties of the Visualization
One concept that can help us identify the properties of the ensemble display that could be changed to reduce the collocation effect is that of visual thought, proposed by Tversky (2011). Visual thought suggests that in addition to communicating the relationships in the data, marks and encodings relay additional information that informs how we conceptualize the information. For example, numerous studies have documented a containment bias, where viewers interpret elements within a boundary as more similar than elements outside a boundary 
(Belia et al., 2005;
Boone, Gunalp, & Hegarty, 2018;
McKenzie, Hegarty, Barrett, & Goodchild, 2016;
Newman & Scholl, 2012)
. In one study, 
McKenzie et al. (2016)
 showed that participants who viewed a geospatial uncertainty visualization with a hard boundary were more likely to use a containment heuristic than those who saw the same data but represented with a blurred edge created by a Gaussian fade. 
Freksa and Barkowsky (1996)
 suggest that sharp boundaries denote distinct concepts more than fuzzy boundaries. In hurricane ensemble track displays, the nature of the marks and encodings could be communicating additional information to the viewer that is producing the collocation effect. The properties of the ensemble display that can be changed to potentially reduce the collocation effect are the number of lines plotted (i.e., changing the marks) and color, line width, and line quality (i.e., changing the encodings of the lines). Prior research has successfully used the color of the hurricane tracks to communicate the category of the storm 
(Liu, Padilla, Creem-Regehr, & House, 2019)
. As our long-term goal is to communicate the uncertainty in the category, size, and speed of the storm in addition to the path, here we save the encoding channels of color, line width, and line quality for other data parameters and focus on reducing the collocation effect by modifying the number of ensemble members shown.
The collocation effect may occur, in part, from the way in which the depiction of the ensemble lines leads people to believe that each line is a deterministic path that the hurricane could take rather than representing a sampling from a distribution of paths. 
Savelli and Joslyn (2013)
 have also documented cases where participants assume that probabilistic information is deterministic, entitled a deterministic construal error. When participants view upper and lower confidence intervals from a distribution of temperatures, they assume the intervals represent deterministic forecasted high and low temperatures (see also attribute substitution in 
Kahneman, 2011)
. A deterministic assumption would be appropriate for many visualizations, but it leads to misunderstanding in the case of uncertainty communication. If people assume that each of the hurricane paths represents individual paths the hurricane could take rather than a sampling from a distribution of possible paths, participants may associate a probability with each line. For example, see the cartoon figure of two fictitious hurricane ensemble track forecasts in 
Figure 3
. In both fictitious forecasts, the ensemble tracks are sampled from the same distribution of paths. If a viewer believes that each route is a deterministic path the hurricane could take, he or she might conclude that in forecast A, New Orleans has a 33% chance of being hit by the storm, whereas, in forecast B, New Orleans has only a 10% chance.
The first goal of this work is to attempt to reduce the colocation effect by increasing the number of hurricane paths plotted. This approach takes advantage of the viewer's current conceptualization of the visual display, but does not change it. If we can reduce the colocation effect by changing the number of lines, this would suggest that the visual depiction of paths is partially responsible for the previously observed bias 
(Padilla et al., 2017)
. Further, this work would offer clear recommendations for the number of ensemble members to plot for visualization practitioners. 


Activating Knowledge-Driven Processing via Instructions
The second approach highlighted in the 
Padilla et al. (2018)
 cognitive framework for visualization decision-making is to encourage viewers to use knowledge-driven processing to override the collocation effect. The interpretation that the paths in the ensemble hurricane forecast are a set of all deterministic forecasted paths is reasonable because viewers were given little information about how the ensemble forecasts were generated. For example, the task instructions used in 
Padilla et al. (2017)
 were: Throughout the study you will be presented with an image that represents a hurricane forecast, similar to the image shown above. An oil rig is located at each of the two red dots. Your task is to decide which oil rig will receive more damage based on the depicted forecast of the hurricane path.
In order to encourage viewers to adopt decisions more consistent with the modeling procedure used, at a minimum we need to provide viewers with instructions about how the ensemble visualizations are made. Whereas providing viewers with detailed instructions about a visualization may seem like an obvious necessity, a growing body of research demonstrates inconsistent findings concerning how effectively viewers incorporate additional information, such as instructions or decision aids, into their decisions 
(Boone et al., 2018;
Grounds, Joslyn, & Otsuka, 2017;
Joslyn & LeClerc, 2013;
Pugh, Wickens, Herdener, Clegg, & Smith, 2018;
Savelli & Joslyn, 2013)
. 
Savelli and Joslyn (2013)
 found that participants maintained the incorrect belief that the temperature error bars represented high and low temperature forecasts despite a key that detailed the correct way to interpret the visualizations (see also 
Grounds et al., 2017)
. 
Pugh et al. (2018)
 found that training with a summary hurricane forecast path visualization (similar to 
Figure 1A
) improved hurricane path trajectory judgments only when the visualization was present, and the training had no benefit when the visualization was not present. Further, 
Boone et al. (2018)
 attempted to improve participants' judgments with the summary hurricane path visualization by providing instructions about how the hurricane forecasts were generated. They found that using several types of instructions helped to reduce misconceptions about the size of the storm growing over time, but the instructions did not consistently influence participants' behavioral risk judgments about the storm.
Beyond viewers inconsistently incorporating additional information about a visualization into their decisions in the laboratory, in real-world scenarios people are provided with limited information about how forecasts are created. The majority of Americans receive information about hurricanes in television broadcasts 
(Lindell et al., 2005)
, and newscasters rarely provide information about how they created the forecast visualizations. For example, one day before hurricane Irma made landfall on September 10 th 2017, of the 20 most viewed forecasts archived on Archive.org, none of the newscasters detailed how the storm path models or visualizations were created, and the average running time of a video clip was 1:52 minutes (data available in the supplementary material). Further, three of these forecasts included misleading information concerning how to interpret the summary hurricane path visualization, such as suggesting that areas inside the boundary are in the danger zone whereas areas outside are relatively safe. Additionally, people evaluate many factors when considering evacuation, such as their peers evacuating, businesses closing, living in high risk areas, and official warnings 
(Huang, Lindell, & Prater, 2016)
. For these practical reasons, we sought to identify the minimum amount of instructional information needed to reduce the collocation effect, so as not to require undue amounts of time and energy from the viewer. To this aim, we tested two types of instruction manipulations. In one set of video instructions, participants learned about how the ensemble hurricane forecast visualization was created, similar to instructions provided in 
Boone et al. (2018)
. In the second, we tested more extensive instructions that also explained the collocation effect to participants and gave them practice overcoming it.


Overview of Experiments
Experiment 1 sought to reduce the colocation effect observed in Padilla et al.
(2017) by changing the number of hurricane paths plotted. We hypothesized that increasing the number of lines would significantly reduce the collocation effect if viewers assume each line to be a deterministic forecasted path rather than a sampling from a distribution. To test this hypothesis, we varied whether the target oil rig location intersected a line and the number of ensemble members represented. We predicted that damage ratings would be greater for target locations that are intersected by a hurricane path compared to locations that are not, and damage ratings would be greatest when fewer hurricane paths are shown.
In Experiment 2, we provided participants with several types of video instructions on how to overcome the collocation effect to test whether viewers can use knowledgedriven processing to override the influence of marks and encodings. The first type of instructions included information about how the visualization was created (visualization instructions). The goal of testing the visualization instructions was to determine if information about the modeling technique used and visualization generation procedures is sufficient to help people significantly reduce the colocation effect. Additionally, based on pilot think-aloud trials that provided insight into participants' conscious strategies, we developed a more elaborate task-specific video tutorial with information about the collocation effect and instructions about refraining from increasing damage judgments when an ensemble member was collocated with the point of interest. Given that prior work is inconclusive as to whether viewers can incorporate additional information to interpret a visual display, we tested if instructions that directly explained both how the visualization was created and how to complete the task could help participants overcome the collocation effect (task-specific instructions).


Experiment 1
To test whether increasing the number of lines plotted reduces the colocation effect, we conducted an experiment in which the number of hurricane-simulated ensemble members (9, 17, 33, and 65) was manipulated. Participants viewed a hurricane track visualization with either 9, 17, 33, or 65 tracks and estimated the level of damage that off-shore oil rigs at specified locations would incur, which fell either on or off an ensemble member (see 
Figure 4
 for example stimuli). We predicted that the difference in damage estimates between locations falling on versus off an ensemble member (collocation effect) would decrease as the total number of ensemble members increased.
Prior work has found that damage ratings, although indirect, are reflective of the individual's conceptualization of the trajectory of the storm 
(Padilla et al., 2017)
. In a study in which viewers made damage, size, and intensity ratings using hurricane path forecasts, researchers found that viewers integrate their understanding of the trajectory of the storm with their assumptions about its size and intensity 
(Padilla et al., 2017)
. In this way, damage is a complex judgment that provides information about how people make risk assessments about the path of a storm. Further, we sought to avoid requiring viewers to make probability judgments (i.e., What is the probability that the storm will hit the oil rig?), which are classically challenging and error-prone 
(Gigerenzer & Hoffrage, 1995)
.
For example, 
Belia et al., (2005)
 demonstrated that even experts perform poorly at statistical inference tasks with simple uncertainty visualizations of error bars. 


Methods


Participants.
Based on the effect size described in Padilla et al. (2017), a power analysis was conducted using G*Power 
(Buchner, Erdfelder, Faul, & Lang, 2017)
 to determine an adequate sample size. At an alpha of level 0.05, power of 0.80, and an effect size of f 2 = 0.11, the minimum number of participants needed is 54 for two groups.
Participants were 200 undergraduate students currently attending the University of Utah who completed this study for course credit, of which 73 were male and 127 were female, with a mean age of 22 (SD = 5.58). Each participant completed the task with visualizations that had one quantity of simulated ensemble members (9 tracks n = 52, 17 tracks n = 50, 33 tracks n = 50, and 65 tracks n = 48). Institutional Review Board (IRB) approval for this research was obtained from the University of Utah IRB.
Stimuli. 
Liu et al. (2019)
 proposed a path reconstruction procedure that more effectively represents a distribution of hurricane paths ( 
Figure 5B
) compared to random sampling ( 
Figure 5A
). By separating the paths, additional information can be encoded in the paths using color, line weight, and line quality. For example, Liu et al. (2019) added color to the paths to show the category of the hurricane and found that people demonstrate the same pattern of damage rating as with randomly sampled paths, which indicates they understand the uncertainty in similar ways in both techniques. To examine the collocation effect, code was generated to create artificial hurricane forecast images that mimicked properties suggested by 
Liu et al. (2019)
 and distributions in such a way that one of the ensemble members passed through the center of a black dot used to depict the "oil rig" location (see 
Figure 6A
). The stimuli used in the current study differed from the hurricane forecast tracks tested in 
Liu et al. (2019)
 in a few ways. Specifically, gaps were placed in the distributions and the tracks were straight lines, both of which were important for increasing the experimental control by creating the manipulations in the current study. The gap was specified in the distribution to ensure that only one line would be collocated with the oil rig location. To create trials where no line was collocated with the oil rig, the previously collocated line was moved to the other side of the distribution in such a way that it was equidistant from the center compared to its original location (see 
Figure 6C
). This placement allowed for direct comparison of trials in which a line was and was not collocated with the oil rig, all other factors remaining constant. The transposition of the collocated line was also the reason the lines (a) randomly selected paths (b) reconstruction of paths needed to be straight. Further, the straight lines allowed for the entire distribution of lines to be flipped over the distribution midline to counterbalance any skewing that may occur from moving the collocated line (see 
Figure 6B
 and D). In the code, a dot angle was specified that indicated the angle away from the midline at which the oil rig would be placed. N-2 hurricane track lines were sampled from a clipped normal distribution. No two lines could be oriented within 0.25° of one another. The midline was accidentally also plotted and did not adhere to the minimum angular distance constraint. Lines were excluded from two 1.5° gaps. The first gap was centered around the oil rig position. The second gap was equidistant from the center of the distribution, but in the opposite direction from the oil rig position, which allowed the distribution of paths to be flipped over the distribution midline. One additional line was then specified to intersect with the oil rig, producing one stimuli image (see 
Figure 6A
). A second image was also generated in which the additional line was plotted through the gap that did not contain the oil rig (see 
Figure 6B
). The two resulting images were then flipped over the midline to create a total of four mirrored images, two collocated (referred to subsequently as "on-line" and two noncollocated, referred to as "off-line" (see 
Figure 6C
 and D). Thin line widths for the hurricane tracks and a small diameter for the oil rig were selected to increase the precision of the dot overlap with the line. 
Figure 6
. Example of the 33-track display, where one line was reflected over the mean line of the distribution of simulated ensemble members to make a collocation condition (A) and a noncollocation condition (C). B and D represent the mirror images of A and B, where the underlying map remained constant.
We chose the following distances to place the oil platforms relative to the mean of the distributions: 14° and 12°. In our prior work, we utilized a wide range of distances from the center of the distribution and found correspondingly larger differences in damage ratings 
(Padilla et al., 2017;
Ruginski et al., 2016)
. Our intention here was not to add to the distance finding, but to conceptually replicate it to ensure that the changes we made to the visualization technique did not result in unintended consequences for viewers' perception of the distribution. The distances were chosen to place the gaps in the tails of the distribution, thus reducing the noticeability of the gap by ensuring it was located in less densely populated regions of the distributions. Each simulated ensemble member was a straight line of fixed length, characterized by its slope represented as an angle. Four quantities (9, 17, 33, and 65) of angles were randomly sampled from a clipped normal distribution with a maximum spread of 40°, a standard deviation of 5°, and a line thickness of 1 pixel. These quantities were selected to represent a wide range of values, which were created starting with a base of 8 and using a logarithmic scale to select 16, 32, and 64. Each quantity had an additional ensemble member, which was the transient ensemble member that was either collocated with the oil platform or moved to the other side of the distribution. Sixty-five simulated ensemble members were, subjectively, the upper bounds of reasonable ensemble members to represent, given the standard deviation, max-spread, and thickness of lines that we specified. In our case, more than 65 simulated ensemble members would have resulted in a distribution that would no longer be perceivable. Given that we aimed to test whether we could reduce the collocation effect by increasing the number of simulated ensemble members, we felt it was essential to test a wide range of quantities of ensemble members even if all the versions did not adhere to visualization design recommendations. Finally, to increase the number of trials, each of the permutations was seeded four times (i.e., randomly sampled four times), and each was then displayed with the midline oriented at three different angles (-30, 0, -30), resulting in a total of 96 trials. All simulated ensemble distributions were digitally composited over a map of the U.S. Gulf Coast that had been edited to minimize distracting labeling. These images were displayed to the subjects at a pixel resolution of 960 x 640 pixels. Underneath the forecast, a scale ranging from 1 (no damage) to 7 (severe damage) was displayed. For each trial, participants were shown one display depicting a hurricane path visualization. Stimuli were presented on the Qualtrics web application 
(Qualtrics, 2005)
.
Design. We utilized a 4 (number of simulated ensemble members: 9, 17, 33, and Procedure. Participants completed these studies online for course credit on their personal machines, which were required to have screen sizes of larger than 9.4 inches tall by 6.6 inches wide. Individuals were first given the following instructions for the task and visualization:
In the following experiment, you will view maps showing the forecast path of different hurricanes as they travel over the Gulf of Mexico toward land. The maps will also show the location of one offshore oil platform in the Gulf. Oil platforms are large structures on the surface of the water with components that extend to the ocean floor for drilling and storing oil. See the sample map below. A set of potential forecast paths of where the hurricane will move in the next three days is shown in red, and the location of the oil platform is shown by a small black circle. Your task is to estimate the level of damage that the platform will incur based on the depicted forecast of the hurricane path on a scale of 1 to 7 where 1 is no damage and 7 is severe.
You will make your judgments of potential damage to the oil platform using the damage scale provided below the map, which will be presented to you along with the forecast maps on each trial. To respond, you should check the box (1 through 7) associated with the level of damage that you believe will occur to the oil platform as a result of the forecasted hurricane. The hurricane forecasts and the locations of the oil platforms will vary across trials.
Additionally, each trial included the following text as a reminder of the task: "What is the level of damage that the oil platform will incur?" Following the instructions, participants completed all the trials presented in a different random order for each participant and reported their confidence in their predictions on a Likert scale ranging from 1 (not at all confident) to 7 (very confident) for every trial. Lastly, at the end of the experiment, participants answered three questions related to comprehension of the hurricane forecasts.


Results
Multilevel models (MLM) were fit to the data using the R lme package 
(Bates, Mächler, Bolker, & Walker, 2014)
 with restricted maximum likelihood estimation procedures 
(Raudenbush & Bryk, 2002)
. Multilevel modeling is a generalized form of linear regression that is used to analyze variance in experimental outcomes predicted by both individual (within-participants) and group (between-participants) variables.
Visualization was dummy coded such that the 9-track visualization was the referent.
Collocation was coded such that the coefficients indicated a change from off-line trials to on-line trials, meaning that a significant positive slope reveals a collocation effect.
Collocation (off and on), Visualization (9-track, 17-track, 33-track, and 65-track), Distance (12° and 14°), and the interaction between Collocation and Visualization were entered as fixed effects. Participants were entered as random effects. Self-report measures of experience with hurricanes and hurricane prone regions were also collected. The results of this analysis can be seen in 
Table 1
. The participants were students at the University of Utah, and few had experienced a hurricane (3%) or had lived in hurricaneaffected regions (7%), so we did not include these measures as covariates. 
Table 1
. List of fixed effects with coefficients, standard errors, t-values, p-values, and 95% confidence intervals from the statistical model predicting damage ratings. Collocation was coded such that the effects indicate a change from off-line to on-line.
Our primary hypothesis was that we would see less of a collocation effect for hurricane track visualizations with more simulated ensemble members. To start, there was a main effect of Collocation, meaning that for the 9-track display (the referent) and at the 12° distance (also the referent), damage ratings increased by 1.7 points (on the 7-point Likert scale) when the oil rig was intersected by one of the lines compared to when it was not.
Consistent with our predictions, we also found a significant interaction between collocation and each of the visualizations compared to the 9-track display. The negative coefficient for each of these interactions indicates that the difference between the on-line and off-line trials is significantly smaller for the 17-, 33-, and 65-track displays compared to the 9-track display at the closest distance. The 9-track on-line trials (M = 4.55, SD = 1.56) elicited 1.71 more damage than the off-line trials (M = 2.84, SD = 1.47). The difference between the on-line and off-line trials is 0.42 smaller for the 17-track display   Participants also reported their confidence in their judgments for each trial using a Likert scale ranging from 1 (not at all confident) to 7 (very confident), along with follow-up questions about the visualizations. Using a multilevel model, we evaluated the impact of Visualization and Collocation (fixed effects) on confidence ratings with participants as random effects. This analysis revealed no significant change in confidence from the 9-track display (M = 4.56, SD = 1.63) compared to the 17-(M = 4.65, SD = 1.51), 33-(M = 4.39, SD = 1.54), and 63-track displays (M = 4.87, SD = 1.44). However, the main effect of Collocation showed the participants were more confident about their judgments for the on-line (M = 4.68, SD = 1.50) trials than the off line trials (M = 4.56, SD = 1.58), (b = .117), t(198) = 9.03, p < 0.000, 95% CI [0.09, 0.14]. However, the increased confidence for the online trials was quite small, 1.71%.
The results of the survey questions can be found in 
Table 2
. Using a general linear model, Visualization was used to predict question response with the 9-track display as the referent. Full output of the models can be found in the supplementary materials 1 . For Q1, which references uncertainty in the visualization, no significant differences were found between the 9-track display and other visualization techniques, with participants at chance performance. For Q2, which references the collocation effect, participants viewing the 17-and 33-track displays showed fewer correct responses than those viewing the 9-track display, which is surprising because participants' behavioral judgments were in the opposite direction, where the 17-and 33-track displays show the least collocation effect. For Q3, viewers of the 65-track display were more likely to indicate that the hurricane forecast showed all possible paths the hurricane could take compared to the 9track display. This result suggests that when too many ensemble members are plotted, one unintended effect may be that viewers believe that they represent all of the possible outcomes. To follow-up on this finding, a linear model was conducted with Q3 predicting the damage change score (collocation effect) of the 65-track display. This analysis revealed that participants who answered "no" to Q3 showed significantly less of a collocation effect (M = 1.38, SD = 1.36) compared to those who answered "yes" (M = 1.68, SD = 1.56), (b = -0.30), t(46) = -6.82, p < 0.00, 95% CI 
[-0.38, -0.21]
. for the 65-track display, the collocation effect was greater than for the 17-and 33-track displays (although still less than the 9-track display). The post-survey Q3 suggested that viewers were more likely to believe that the 65-track display represented all the possible paths the hurricane could take. A follow-up analysis provided evidence that, for the 65track display, incorrect beliefs about the visualization representing all of the possible paths increased the collocation effect. It could also be the case that for the 65-track display, the gaps in the distribution of paths were more apparent, which could also influence the collocation effect. In sum, although increasing the number of simulated ensemble members can reduce the collocation effect, evidence suggests that when many ensemble members are represented, more viewers believe that all possible outcomes are
shown.
Importantly, it should be noted that the collocation effect was never completely ameliorated. The 34-track visualization showed the largest (30%) reduction of the collocation effect compared to the 9-track display. Yet, participants still reported, using the Likert scale, that oil platforms that were directly hit by one of the simulated ensemble members would receive 1.28 units of more damage than oil rig locations that were not directly hit.


Experiment 2
In Experiment 2, we provided participants with several types of video instructions on how to overcome the collocation effect to test whether viewers can use knowledgedriven processing to override the influence of marks and encodings.
The first step in developing informative instructions was to identify what types of conscious decision-making strategies participants were aware of using, in order to determine how top-down knowledge may be able to influence the collocation effect.
Based on prior work that examined the use of strategies in a mental rotation task that included visual information (Hegarty, 2017), we used a concurrent verbal protocol and a retrospective protocol to elicit participants' strategies while they completed 10 randomly sampled trials from Experiment 1. The objective of this pilot was to study the processes that participants were aware of, in case they may have been adopting deliberate cognitive strategies that could have contributed to the collocation effect. Twenty undergraduate and graduate students at the University of Utah participated in the pilot for $10 (male = 8, female = 12, and a mean age of 25.75, SD = 4.3). Participants first received instructions on how to complete concurrent verbal protocols, which involved instructing them to verbalize their thoughts as they completed each stage of the study, including the practice trials 
(Ericsson & Simon, 1992)
. In line with recommendations from 
Ericsson and Simon (1992)
, three practice trials were used to help participants become comfortable with verbalizing their thoughts while completing the task. They were then given 10 thinkaloud trials in which they were instructed to verbalize everything that came to mind as they completed all steps of the task. Following recommendations from 
(Ericsson & Simon, 1992)
, participants were encouraged to "keep talking," rather than a social communication request, such as "tell me what you think." Finally, participants completed retrospective protocols for which they reported what they thought while they completed the think-aloud protocols. The entire process was video recorded and transcribed.
Three distinct strategies and a combination of these strategies were observed, including: distance strategy for which participants reported determining their damage rating based on how far the oil rig was from the center of the distribution of simulated ensemble members, collocation for which participants specifically commented on rating oil rig locations that are collocated with a simulated ensemble member as receiving more damage, and surrounding ensemble members where participants reported making their damage judgments based on the distance of the oil rig to the surrounding simulated ensemble members. The results of this pilot provide evidence that some participants strategically increased their damage ratings when the oil rig was collocated with an ensemble member. Given that some participants were aware of the influence of collocation and the surrounding simulated ensemble members, it is possible that if they had been given instructions about how to overcome the collocation effect and interpret the visualizations correctly, they would have been able to incorporate this information into their decisions.
Utilizing the findings of the think-aloud and retrospective protocols, we developed two types of video instructions to test whether participants can use top-down knowledge to overcome the collocation effect. The task-specific instructions included information about how to overcome the collocation effect, and the more general visualization instructions included only information about how simulated ensemble hurricane forecast tracks are generated. We predicted that the task-specific instructions would reduce the colocation effect significantly but, given the influence of visual features, not completely. This finding would suggest that the collocation effect could be influenced by top-down knowledge. Additionally, we predicted that the visualization instructions would reduce the collocation effect but not to the degree of the task-specific instructions.


Methods
Participants. Participants were 83 undergraduate students currently attending the University of Utah who received course credit for participation. Three participants were disqualified for not following instructions. Of the 80 (40 in each instructions group) who were included in the analysis, 23 participants were male, and 57 were female, with a mean age of 21 (SD = 3.7).
Stimuli and Design. The same 9-track display stimuli were utilized along with the same study design as in Experiment 1. However, before receiving the experiment instructions, participants viewed one of two videos. Both videos can be found in the supplementary materials. The task-specific video included narrated instructions about the collocation effect and information about how the simulated ensemble hurricane forecasts were generated along with visual examples (length of 3.13 minutes). The full transcripts of the instructions are in Appendix A. The sequence of the task-specific instructions video was as follows:
1. Overview of the functions of hurricane forecasts 2. Description of how the type of hurricane forecast used in this study was generated 3. Information about uncertainty in hurricane forecasts 4. Instructions on how to identify the center of the distribution of paths and that the center represents the most likely path the hurricane will take 5. Illustration of how static simulated ensemble hurricane forecasts represent a subset of the many possible paths generated by the forecast models 6. Description of the collocation effect 7. Practice overcoming the collocation effect with example questions.
The visualization-instructions video was an edited version of the task-specific video (1.37 minutes) and included elements 1-5 of the list above. Specific information about the collocation effect and practice overcoming the effect was not included.
Procedure. Participants were randomly assigned to one of two groups (taskspecific instructions or visualization-instructions). After consent was obtained, participants viewed the relevant video and then completed the same procedure detailed in Experiment 1 but with only the 9-track visualization. As the 9-track visualization exhibited the largest collocation effect, we utilized it as a baseline to try to reduce the collocation effect with the instruction videos.


Results
As in Experiment 1, we used a multilevel logistic regression model to determine the influence of instructions on the damage ratings. We compared the 9-track display results from Experiment 1 to new data from participants who received the additional instructions. Instruction-type (none, task, and general), Collocation (off and on), Distance (12° and 14°), and the interaction between Collocation and Instructions were entered as fixed effects (see 
Table 3
). Participants were entered as random effects. Collocation was coded such that effects indicate a change from off-line to on-line trials, and the noinstructions condition was specified as the referent.  
Figure 8
. Damage change scores for the 9-track display conditions with no instructions, visualization instructions, and task-specific instructions. Bars represent 95% confidence intervals around the mean.
As illustrated in 
Figure 8
, the participants who viewed the general (M = .96, SD = 1.22) and task-specific instructions (M = .66, SD = 1.01) demonstrated significantly less of a collocation effect compared to those who received no instructions (M = 1.70, SD = 1.56).
The coefficients for the interactions indicate that the task-specific instructions reduced the bias by 1.04 on the Likert scale, which corresponds to a 61% reduction of the collocation effect observed with the 9-track display. For the visualization instructions, the bias was reduced by .74 on the Likert scale or a 44% reduction of the collocation effect observed with the 9-track display. To test whether the task-specific instructions reduced the collocation effect more than the visualization instructions, the same analysis was conducted, but the visualization instructions were specified as the referent. This analysis revealed that the task-specific instructions reduced the collocation effect significantly more than the general instructions, (b = -0.30), t(125) = -6.12, p < 0.00, 95% CI 
[-0.39, -0.20
 who received no instructions (M = 3.7, SD = 1.74). To test whether participants with taskspecific instructions were more confident in their ratings compared to those who received the visualization instructions, the same analysis was conducted, but the visualization instructions were specified as the referent. This analysis revealed participants with the task-specific instructions were not more confident in their responses compared to those with visualization instructions, (b = 0.33), t(125) = 1.35, p = 0.17, 95% CI 
[-.15, .82
].
The results of the survey questions can be found in 
Table 4
. Using a general linear model, instruction-type was used to predict question response with the no-instructions condition as the referent. Full output of the models can be found in the supplementary materials. For Q1, no significant differences were found between no instructions and either of the instruction conditions. For Q2 (collocation), participants with the taskspecific instructions were more likely to answer the question correctly compared to those who received no instructions. For Q3 (all possible paths), participants who received either instruction condition answered the question more correctly than those without instructions. 
Table 4
. Proportion of correct for each visualization condition. *** Indicates p-values = .000, ** p-values < .005, and * p-values < .05.


Discussion
In Experiment 2, we found that the collocation effect was significantly, but not entirely, reduced by instructions. The task-specific instructions attenuated the collocation effect to a greater degree than the visualization instructions, as evidenced by both the objective behavioral measures and the participants' self-report measures of their understanding. This finding illustrates both the effectiveness of instructions and the powerful influence of marks and channels in a visualization, as the collocation effect was never fully reduced by knowledge-driven processing. 


General Discussion
Together, the current experiments explored the influence of visual properties and knowledge-driven processing on the previously observed collocation effect 
(Padilla et al., 2017)
 in hurricane forecast visualizations. We were able to demonstrate two approaches for reducing the collocation effect. In Experiment 1, we reduced the collocation effect by increasing the number of ensemble members plotted. When we increased the number of ensemble members shown, the importance of each ensemble member decreased, resulting in more similar damage judgments when a track directly hit the target compared to when a track just missed the target. Note that this approach does not assume a change in conceptualization from the viewer. Instead, we capitalized on the specifics of how people naturally reason with the information and then changed the visualization to elicit viewers' best possible judgments. Additionally, both the postsurvey questions and the behavioral results suggest that with each of the visualizations viewers do understand the uncertainty communicated by the distributions. The results of this study suggest that ensembles can be used to effectively communicate uncertainty, but caution should be taken when using them for specific tasks for which viewers make judgments about a particular location.
With the second approach executed in Experiment 2, we also showed that the collocation effect could be significantly reduced when viewers used top-down knowledge-driven processing to incorporate instructions. In the second study, we found that viewers were consciously aware of the strategies they used to complete the task, including the influence of a simulated ensemble member when it was collocated with their point of interest. While largely reduced with both approaches, the collocation effect was never completely eliminated. Notably, specific and admittedly frank instructions on how to overcome the collocation effect did not entirely reduce the bias. Our work proposes that the marks and channels in a visualization have a powerful influence on decision-making, which can be resilient to top-down knowledge-driven processing and should be taken seriously.
Other possible explanations for the collocation effect were not directly tested in the current study, such as the use of Gestalt principles of perceptual organization 
(Wertheimer, 1938)
 and object-based attention 
(Scholl, 2001
). In the context of graph comprehension, 
Pinker (1990)
 has argued that we use Gestalt principles of perceptual grouping to constrain how visual features are linked together. Principles of grouping demonstrate that visual elements that are spatially proximal to each other (grouping by proximity), have smooth continuation with one another (grouping by good continuation), or are visually connected (grouping by connectedness) will be perceived as part of a single configuration. Several studies on graph understanding have shown that interpretations are affected by different Gestalt grouping principles. For example, the within-the-bar bias described earlier 
(Newman & Scholl, 2012
; see also Okan, Garcia-Retamero, Cokely, & Maldonado, 2018) can be explained by the "visual chunking" of a bar as a single contained entity. Others have shown that modifying graphs so that certain Gestalt principles are in effect influences our ability to identify global trends in the data 
(Shah, Mayer, & Hegarty, 1999)
 or our accuracy in interpreting statistical interactions 
(Ali & Peebles, 2013
). In the current study, the ensemble display may have evoked various grouping principles that influence viewers' interpretations. A possible explanation based on perceptual grouping could be that viewers perceived the collocated dot-line configuration as a single object, enhanced by object-based attention mechanisms 
(Scholl, 2001)
. With additional lines added, less attention may have been directed at the individual ensemble member that contained the dot. Likewise, the amount of space between the lines changed when additional lines were added, possibly reducing attention to the distinction between on-and off-line trials. Future studies using eye-tracking methods could help to distinguish whether the lines and spaces attract less attention as the number of ensemble members increases. The displays could also be manipulated in terms of the thickness of the lines, the diameter of the dot, and the size of the spaces to test whether these features might affect processes of grouping.
This work also illustrated methods for developing both general and task-specific instructions and showed that instructions could change decisions with visualizations.
Prior work demonstrated inconsistent findings as to whether people could utilize prior knowledge to change their judgments when viewing visualizations 
(Bailey, Carswell, Grant, & Basham, 2007;
Boone et al., 2018;
Joslyn & LeClerc, 2013;
Shen, Carswell, Santhanam, & Bailey, 2012)
. Consistent with the recommendations from Zapata-Rivera, Zwick, and Vezzu, (2016), this work finds that instructions can be used to reduce a specific error in reasoning with visualizations. We believe that the task-specific instructions were more successful than the general instructions because they targeted a specific distortion rather than trying to improve judgments broadly, which may be why other work did not find consistent improvements in visualization decision-making when providing viewers with more information 
(Boone et al., 2018;
Savelli & Joslyn, 2013)
.
Our intention for not providing participants with detailed instructions on how to interpret hurricane forecasts in Experiment 1 was, first, to understand what type of biases were naturally elicited purely by the visualization technique. Further, in real-world contexts, such as in hurricane forecasts on the news, it is rare that viewers are given a full description of how the forecast visualizations were generated and how to effectively interpret the forecasts. We sought to examine how people make judgments about storm damage with limited background information, to better understand what elements of the visualization technique are eliciting biases that would likely be observed in the real world.
The applied contributions of this work are to demonstrate that ensemble hurricane forecasts are effective for intuitively communicating uncertainty in hurricane paths, but also that it is important to consider unintended consequences of the ensemble display itself. We showed that when more simulated ensemble members are plotted, the adverse effects of this visualization technique are reduced, but not completely. Our stimuli showed the largest advantage when displaying about 30 ensemble members, but the maximum number could vary in other displays depending on numerous parameters such as spread and line thickness. We also demonstrated that providing instructions about how the hurricane forecast was generated and the collocation effect significantly reduced the adverse effects of this visualization technique. Additional work is needed to test how these findings generalize to other contexts where ensemble visualizations are used.
Although recent work reveals many merits to reconstructed ensemble paths compared to randomly sampled paths 
(Liu et al., 2019)
, one unconsidered component of randomly sampled paths is that they may convey more uncertainty compared to the smoother and more regularly distributed paths used in the current study. 
Liu et al. (2019)
 found that participants demonstrate a similar pattern of damage ratings between randomly sampled and reconstructed paths, where participants rate greater damage toward the center of the distribution and less damage as the distance from the center increases.
However, damage ratings might not be sensitive enough to pick up on differences in the perception of uncertainty between the two techniques. Future work might consider the impact of the nature of the ensemble paths on the perception of uncertainty.
Additionally, future research might consider how people with different levels of exposure to hurricane forecasts respond to various encodings of ensemble paths. The naive population used in the current study was selected as a baseline so that the influence of exposure to hurricane forecasts could be evaluated. Individuals who live in Florida, for example, might not demonstrate the collocation effect because they have first-hand experiences with the uncertainty of hurricane paths, or they might demonstrate a larger collocation effect, because they might have a greater emotional response to a line overlapping their town. Examining the influence of prior experiences with hazards on the perception of visual elements in a forecast is an open area of exploration.


Conclusions
Ensemble visualizations are an increasingly popular method for visualizing data, because emerging research demonstrates that ensemble visualizations can effectively and intuitively communicate traditionally complex statistical concepts to novice viewers.
Ensemble visualizations are now being used to help local officials make large-scale decisions such as whether to evacuate a town before a hurricane strike. Given their widespread use and impact, we need to understand how ensemble visualizations influence our judgments and actions. We found that simulated ensemble visualizations that include a greater number of ensemble members (but not too many) can be an effective visualization technique for various types of decision-making tasks and that providing instructions about how the visualization is created can help people make more effective decisions. Further, this work demonstrates the importance of evaluating both the lower level perceptual and higher level cognitive processes at work when making decisions with visualizations. By understanding the cognitive processes associated with visualization reasoning, we can make more effective predictions about viewers' judgments and create increasingly targeted visualization improvements and decision aids.
it is more important, to identify the center of the grouping of lines. Areas near the center of the grouping of lines have the highest likelihood of being hit by the storm. Let's try an example. Which location do you think would receive more damage? Keep in mind that these lines do not give you information about the size or intensity of the storm -just the path that it might take. Location A has the highest likelihood of being hit by the storm because it is closer to the center of the grouping of lines. Let's try one more example. Which location would receive the most damage? In this case, Location B has the highest likelihood of being hit by the storm. Remember to not base your judgment on an individual line. To interpret these correctly you must imagine where the center of the storm is, and locations closest to the center have the highest likelihood of being hit by the storm.
To sum up what we've learned today, each line is only a sampling of the many possible lines. So it does not matter if one line overlaps your point of interest or not. Instead, you should focus on the center of the grouping of lines, which shows the most likely path that the hurricane will take.
Figure 3 .
3
Illustration of two fictitious hurricane ensemble track forecasts. A depicts three ensemble members and B depicts ten members.


Figure 4 .
4
Example stimuli, showing the 9-track (A), 17-track (B), 33-track (C), and 65track (D) displays. The black dot indicates the location of the offshore oil rig and none are collocated with a hurricane track.


Figure 5 .
5
Comparison of randomly selected paths (A) and a path reconstruction procedure (B) proposed by
Liu et al. (2019)
. Reprinted with permission.


65)x 2 (collocation: on-and off-line) x 2 (oil rig locations: 12° and 14°) x 2 (side of the distribution: left and right) x 3 (angle of storm: -30, 0, and 30) x 4 (seeds) mixed factorial design. Collocation, oil rig locations, side, angle of storm, and seeding were withinparticipant variables, resulting in a total of 96 trials per participant. Participants were randomly assigned to one of four visualization conditions (9, 17, 33, and 65 simulated ensemble members) as a between-participants factor.


(
on-line: M = 4.27, SD = 1.56, off-line: M = 2.99, SD = 1.56), 0.52 smaller for the 33track display (on-line: M = 3.98, SD = 1.36, off-line: M = 2.80, SD = 1.28), and 0.15 smaller for the 65-track display (on-line: M = 4.24, SD = 1.53, off-line: M = 2.68, SD = 1.47) compared to the 9-track display.To visualize the reduction in the collocation effect, we transformed the dependent variable by calculating the difference between the on-line damage ratings and off-line damage ratings at the same oil platform location, seed, and storm angle. The transformation produced a damage change score where zero indicates no collocation effect, positive values indicate an increase in reported damage for on-line trials compared to off-line trials, and negative values would indicate a decrease in reported damage for on-line trials compared to off-line trials. These data are displayed inFigure 7.


Figure 7 .
7
Damage change scores for the 9-, 17-, 33-, and 65-track displays. Bars represent 95% confidence intervals around the mean.As illustrated inFigure 7, the 17-, 33-, and 65-track visualizations show significantly less of a collocation effect. However, unexpectedly, the 65-track visualization shows more of a collocation effect than the 17-and 33-track displays. A post hoc analysis confirmed that after setting the 65-track visualization as the referent and running the same model as previously described, Collocation and each of the visualizations compared to the 65-track display had significant interactions. The negative coefficients for the interactions between Collocation and the 17-track display (b = -0.27), t(191) = -6.46, p < 0.00, 95% CI[-0.35, -0.19] and the 33-track display (b = -0.37), t(191)    = -8.74, p < 0.000, 95% CI [-0.45, -0.28] indicated that the collocation effect was significantly smaller for the 17-and 33-track displays compared to the 65-track display at the 12° distance.A significant main effect of distance revealed that at the distance closer to the center of the distribution (12°, M = 3.63, SD = 1.06), participants believed that the oil rig would receive more damage compared to the farther oil rig location (14°, M = 3.47, SD = 1.09), which is in line with prior work and indicates that viewers perceived the uncertainty communicated in the distribution. Although significant, a change of .16 is small on a Likert scale from 1-7. In sum, this finding is in line with past work that suggests viewers effectively perceived the probability distribution that the hurricane track simulated ensemble visualization is intended to represent.


Table 2 .
2
Proportion of responses for each visualization condition. *** Indicates p-values < .000, ** p-values < .005, and * p-values < .05 with the 9-track display as the referent.
Discussion
The results of this experiment showed that novice users are less influenced by the
impact of a single simulated ensemble member when more ensemble members are
represented. This finding supports our hypothesis that hurricane ensemble paths evoke an
assumption that each line is a deterministic forecasted path rather than a sampling from a
distribution, and increasing the number of paths decreases the negative impacts of this
effect. Additionally, we found several unpredicted effects relating to visualizing the


Table 3 .
3
List of fixed effects with coefficients, standard errors, p-values, and 95% confidence intervals from the statistical model predicting damage ratings.
Fixed Effects
Coeff. Std. Error
t-value
p-value
95% CI
(Intercept)
4.52
0.19
23.87
0.00
(4.15, 4.89)
Collocation
1.71
0.03
56.07
0.00
) (1.64, 1.76)
Task-specific instruction
-0.18
0.22
-0.82
0.41
(-0.60, 0.24)
Visualization instructions 0.81
0.22
3.74
) 0.0001 (0.38, 1.23)
Distance
-0.13
0.009
-13.46
0.00 (-0.14, -0.10)
Collocation*Task Ins.
-1.04
0.05
-22.54
0.00 (-1.13, -0.95)
Collocation*Vis Ins.
-0.74
0.05
-16.02
0.00 (-0.83, -0.64)


The supplementary materials can be found at: osf.io/j34g5/.








Appendix A
Full instruction videos are in the supplementary materials, which can be found at: https://osf.io/j34g5/ Visualization instructions transcript: Hurricane forecasts can help you understand where a hurricane may go. Meteorologists create mathematical models to predict the path of a hurricane, and sometimes they use polylines to represent the hurricane's predicted path. One line represents one output of the model. While hurricane forecast models are improving, even with these models, meteorologists aren't 100% sure of the exact path that the hurricane will take. Many factors can change the path of the hurricane, such as unexpected weather changes. To show the range of possible paths that the hurricane could take, meteorologists use various techniques to plot multiple lines. The spread and distribution of lines is intended to show you the general direction that the hurricane will go. Here is an animation of a real hurricane forecast, where the scientists plotted many lines based on historical data. Notice where most of the lines are grouped. This is the most likely path that the hurricane will take. Also notice that each line is only one of hundreds of lines produced by the model. For this specific model, this means that any one line isn't very meaningful. Scientists can't always show you animations, like the one you just saw. Sometimes they have to use a single image for print publications such as newspapers or reports. If you see an image like this, it doesn't show you all of the other possible lines, like the animation did. The lines that you see are only a small subset of all possible lines.


Task specific instructions transcript:
Hurricane forecasts can help you understand where a hurricane may go. Meteorologists create mathematical models to predict the path of a hurricane, and sometimes they use polylines to represent the hurricane's predicted path. One line represents one output of the model. While hurricane forecast models are improving, even with these models, meteorologists aren't 100% sure of the exact path that the hurricane will take. Many factors can change the path of the hurricane, such as unexpected weather changes. To show the range of possible paths that the hurricane could take, meteorologists use various techniques to plot multiple lines. The spread and distribution of lines is intended to show you the general direction that the hurricane will go. Here is an animation of a real hurricane forecast, where the scientists plotted many lines based on historical data. Notice where most of the lines are grouped. This is the most likely path that the hurricane will take. Also notice that each line is only one of hundreds of lines produced by the model. For this specific model, this means that any one line isn't very meaningful. Scientists can't always show you animations, like the one you just saw. Sometimes they have to use a single image for print publications such as newspapers or reports. If you see an image like this, it doesn't show you all of the other possible lines, like the animation did. The lines that you see are only a small subset of all possible lines. This means that if you see one line overlapping your town or just missing it that is not meaningful because, as we learned, there are many lines that are not represented. Rather
 










The effect of gestalt laws of perceptual organization on the comprehension of three-variable bar and line graphs




N
Ali






D
Peebles








Human factors




55


1
















Geospatial perspective-taking: how well do decision makers choose their views?




K
Bailey






C
M
Carswell






R
Grant






L
Basham


















Fitting linear mixed-effects models using lme4




D
Bates






M
Mächler






B
Bolker






S
Walker




arXiv:1406.5823










arXiv preprint








Researchers misunderstand confidence intervals and standard error bars




S
Belia






F
Fidler






J
Williams






G
Cumming








Psychological methods




10


4


389














The influence of explaining graphical conventions on interpretation of hurricane forecast visualizations




A
Boone






P
Gunalp






M
Hegarty








Journal of Experimental Psychology: Applied




24


3


275


















A
Buchner






E
Erdfelder






F
Faul






A.-G. ; G*
Lang






Power












Version 3.1.9.3








Riding out the storm: Public evaluations of news coverage of Hurricane Andrew




P
Driscoll






M
B
Salwen








J. I. j. o. m. e., & disasters




14


3


















K
A
Ericsson






H
A
Simon




Protocol Analysis : Verbal Reports As Data


Cambridge, Mass




MIT Press














On the relation between spatial concepts and geographic objects. Geographic objects with indeterminate boundaries




C
Freksa






T
Barkowsky




















How to improve Bayesian reasoning without instruction: frequency formats




G
Gigerenzer






U
Hoffrage








Psychological review




102


4


684














Probabilistic Interval Forecasts: An Individual Differences Approach to Understanding Forecast Communication




M
A
Grounds






S
Joslyn






K
Otsuka








Advances in Meteorology
















Who leaves and who stays? A review and statistical meta-analysis of hurricane evacuation studies




S.-K
Huang






M
K
Lindell






C
S
Prater








Environment and Behavior




48


8
















Visualization support for fuzzy spatial analysis. Paper presented at the In Proc




B
Jiang






F
Ormeling






W
Kainz








ACSM/ASPRS Conference












Decisions with uncertainty: the glass half full




S
Joslyn






J
Leclerc








Current directions in psychological science




22


4
















Thinking, fast and slow




D
Kahneman








Macmillan












Household decision making and evacuation in response to




M
K
Lindell






J.-C
Lu






C
S J N H R
Prater








Hurricane Lili




6


4
















Communicating Environmental Risk in Multiethnic Communities




M
K
Lindell






R
W
Perry








Sage


Thousand Oaks, Calif
















L
Liu






A
Boone






I
Ruginski






L
Padilla






M
Hegarty






S
H
Creem-Regehr














Uncertainty Visualization by Representative Sampling from Prediction Ensembles




D
H
House








IEEE Transactions on Visualization and Computer Graphics
















Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks




L
Liu






L
Padilla






S
Creem-Regehr






D
House








IEEE computer graphics and applications
















Visualizing uncertain tropical cyclone predictions using representative samples from ensembles of forecast tracks




L
Liu






L
Padilla






S
H
Creem-Regehr






D
House








IEEE Transactions on Visualization Computer Graphics Forum




25


1
















Assessing the effectiveness of different visualizations for judgments of positional uncertainty




G
Mckenzie






M
Hegarty






T
Barrett






M
Goodchild








International Journal of Geographical Information Science




30


2
















Visualization Analysis and Design




T
Munzner








CRC Press












Bar graphs depicting averages are perceptually misinterpreted: the within-the-bar bias




G
E
Newman






B
J
Scholl




10.3758/s13423-012-0247-5






Psychonomic Bulletin & Review




19


4




















Y
Okan






R
Garcia-Retamero






E
T
Cokely






A
J Q
Maldonado








J. o. E. P
















Biasing and debiasing health decisions with bar graphs: Costs and benefits of graph literacy




71














Decision making with visualizations: a cognitive framework across disciplines




L
Padilla






S
Creem-Regehr






M
Hegarty






J
Stefanucci








Cognitive research: principles and implications
















Effects of ensemble and summary displays on interpretations of geospatial uncertainty data




L
Padilla






I
T
Ruginski






S
H
Creem-Regehr








Cognitive research: principles and implications






2


40












A theory of graph comprehension. Artificial intelligence and the future of testing




S
Pinker




















Effect of Visualization Training on Uncertain Spatial Trajectory Predictions




A
J
Pugh






C
D
Wickens






N
Herdener






B
A
Clegg






C
Smith








Human Factors




60


3
















Non-expert interpretations of hurricane forecast uncertainty visualizations




I
T
Ruginski






A
P
Boone






L
Padilla






L
Liu






N
Heydari






H
S
Kramer






.
.
Creem-Regehr






S
H








Spatial Cognition & Computation




16


2
















The advantages of predictive interval forecasts for nonexpert users and the impact of visualizations




S
Savelli






S
Joslyn








Applied Cognitive Psychology




27


4
















Objects and attention: The state of the art




B
Scholl








80














Graphs as aids to knowledge construction: Signaling techniques for guiding the process of graph comprehension




P
Shah






R
E
Mayer






M
Hegarty








Journal of Educational Psychology




91


4


690














Emergency management information systems: Could decision makers be supported in choosing display formats? Decision support systems




M
Shen






M
Carswell






R
Santhanam






K
Bailey








52














Laws of organization in perceptual forms




M
Wertheimer


















Exploring the Effectiveness of a Measurement Error Tutorial in Helping Teachers Understand Score Report Results




D
Zapata-Rivera






R
Zwick






M
Vezzu








Educational Assessment




21


3

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]